{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "assured-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "directed-liability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (50000, 32, 32, 3)\n",
      "w1: (3072, 200)\n",
      "b1: (200,)\n",
      "w2: (200, 10)\n",
      "b2: (10,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "print(\"x_train:\", x_train.shape)\n",
    "\n",
    "H = 200\n",
    "K = len(np.unique(y_train)) # Classes\n",
    "Ntr = x_train.shape[0]\n",
    "Nte = x_test.shape[0]\n",
    "Din = 3072 # CIFAR10\n",
    "# Din = 784 # MINIST\n",
    "\n",
    "# Normalize pixel values\n",
    "#x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "x_train = x_train - mean_image\n",
    "x_test = x_test - mean_image\n",
    "\n",
    "#Get the y value\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=K)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=K)\n",
    "\n",
    "# Transform images from (width, width, 3) to 3072-dimensional vectors (width*width*3)\n",
    "x_train = np.reshape(x_train,(Ntr,Din))\n",
    "x_test = np.reshape(x_test,(Nte,Din))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "std=1e-5\n",
    "w1 = std*np.random.randn(Din, H)\n",
    "w2 = std*np.random.randn(H, K)\n",
    "b1 = np.zeros(H)\n",
    "b2 = np.zeros(K)\n",
    "print(\"w1:\", w1.shape)\n",
    "print(\"b1:\", b1.shape)\n",
    "print(\"w2:\", w2.shape)\n",
    "print(\"b2:\", b2.shape)\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expected-genealogy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 300: loss 1.000041\n",
      "iteration 0 / 300: loss 0.932924\n",
      "iteration 0 / 300: loss 0.916289\n",
      "iteration 0 / 300: loss 0.951907\n",
      "iteration 0 / 300: loss 0.979420\n",
      "iteration 0 / 300: loss 0.935033\n",
      "iteration 0 / 300: loss 0.906295\n",
      "iteration 0 / 300: loss 0.890678\n",
      "iteration 0 / 300: loss 0.887232\n",
      "iteration 0 / 300: loss 0.877913\n",
      "iteration 0 / 300: loss 0.868178\n",
      "iteration 0 / 300: loss 0.861804\n",
      "iteration 0 / 300: loss 0.860827\n",
      "iteration 0 / 300: loss 0.862437\n",
      "iteration 0 / 300: loss 0.852670\n",
      "iteration 0 / 300: loss 0.862814\n",
      "iteration 0 / 300: loss 0.859733\n",
      "iteration 0 / 300: loss 0.858648\n",
      "iteration 0 / 300: loss 0.856650\n",
      "iteration 0 / 300: loss 0.841164\n",
      "iteration 0 / 300: loss 0.853565\n",
      "iteration 0 / 300: loss 0.837237\n",
      "iteration 0 / 300: loss 0.849805\n",
      "iteration 0 / 300: loss 0.847911\n",
      "iteration 0 / 300: loss 0.843588\n",
      "iteration 0 / 300: loss 0.850635\n",
      "iteration 0 / 300: loss 0.847653\n",
      "iteration 0 / 300: loss 0.836242\n",
      "iteration 0 / 300: loss 0.839489\n",
      "iteration 0 / 300: loss 0.836349\n",
      "iteration 0 / 300: loss 0.846729\n",
      "iteration 0 / 300: loss 0.847678\n",
      "iteration 0 / 300: loss 0.831822\n",
      "iteration 0 / 300: loss 0.829706\n",
      "iteration 0 / 300: loss 0.832279\n",
      "iteration 0 / 300: loss 0.828804\n",
      "iteration 0 / 300: loss 0.825351\n",
      "iteration 0 / 300: loss 0.825419\n",
      "iteration 0 / 300: loss 0.823365\n",
      "iteration 0 / 300: loss 0.827263\n",
      "iteration 0 / 300: loss 0.824046\n",
      "iteration 0 / 300: loss 0.818095\n",
      "iteration 0 / 300: loss 0.828368\n",
      "iteration 0 / 300: loss 0.817939\n",
      "iteration 0 / 300: loss 0.819503\n",
      "iteration 0 / 300: loss 0.820969\n",
      "iteration 0 / 300: loss 0.808393\n",
      "iteration 0 / 300: loss 0.807275\n",
      "iteration 0 / 300: loss 0.806899\n",
      "iteration 0 / 300: loss 0.825799\n",
      "iteration 0 / 300: loss 0.820504\n",
      "iteration 0 / 300: loss 0.823966\n",
      "iteration 0 / 300: loss 0.805064\n",
      "iteration 0 / 300: loss 0.817989\n",
      "iteration 0 / 300: loss 0.824297\n",
      "iteration 0 / 300: loss 0.821179\n",
      "iteration 0 / 300: loss 0.830663\n",
      "iteration 0 / 300: loss 0.805802\n",
      "iteration 0 / 300: loss 0.818369\n",
      "iteration 0 / 300: loss 0.808606\n",
      "iteration 0 / 300: loss 0.805037\n",
      "iteration 0 / 300: loss 0.808969\n",
      "iteration 0 / 300: loss 0.812422\n",
      "iteration 0 / 300: loss 0.812194\n",
      "iteration 0 / 300: loss 0.813439\n",
      "iteration 0 / 300: loss 0.822015\n",
      "iteration 0 / 300: loss 0.819016\n",
      "iteration 0 / 300: loss 0.818002\n",
      "iteration 0 / 300: loss 0.796750\n",
      "iteration 0 / 300: loss 0.796337\n",
      "iteration 0 / 300: loss 0.805579\n",
      "iteration 0 / 300: loss 0.805235\n",
      "iteration 0 / 300: loss 0.798632\n",
      "iteration 0 / 300: loss 0.799808\n",
      "iteration 0 / 300: loss 0.809953\n",
      "iteration 0 / 300: loss 0.812403\n",
      "iteration 0 / 300: loss 0.804106\n",
      "iteration 0 / 300: loss 0.787910\n",
      "iteration 0 / 300: loss 0.800375\n",
      "iteration 0 / 300: loss 0.812312\n",
      "iteration 0 / 300: loss 0.807436\n",
      "iteration 0 / 300: loss 0.804354\n",
      "iteration 0 / 300: loss 0.811919\n",
      "iteration 0 / 300: loss 0.786917\n",
      "iteration 0 / 300: loss 0.790122\n",
      "iteration 0 / 300: loss 0.822416\n",
      "iteration 0 / 300: loss 0.801538\n",
      "iteration 0 / 300: loss 0.798149\n",
      "iteration 0 / 300: loss 0.814349\n",
      "iteration 0 / 300: loss 0.802949\n",
      "iteration 0 / 300: loss 0.802376\n",
      "iteration 0 / 300: loss 0.792327\n",
      "iteration 0 / 300: loss 0.800823\n",
      "iteration 0 / 300: loss 0.805138\n",
      "iteration 0 / 300: loss 0.798972\n",
      "iteration 0 / 300: loss 0.796727\n",
      "iteration 0 / 300: loss 0.814966\n",
      "iteration 0 / 300: loss 0.795246\n",
      "iteration 0 / 300: loss 0.788916\n",
      "iteration 0 / 300: loss 0.790919\n",
      "iteration 1 / 300: loss 0.782000\n",
      "iteration 1 / 300: loss 0.792234\n",
      "iteration 1 / 300: loss 0.780944\n",
      "iteration 1 / 300: loss 0.785885\n",
      "iteration 1 / 300: loss 0.787550\n",
      "iteration 1 / 300: loss 0.788528\n",
      "iteration 1 / 300: loss 0.801099\n",
      "iteration 1 / 300: loss 0.787679\n",
      "iteration 1 / 300: loss 0.805509\n",
      "iteration 1 / 300: loss 0.787358\n",
      "iteration 1 / 300: loss 0.806768\n",
      "iteration 1 / 300: loss 0.779318\n",
      "iteration 1 / 300: loss 0.785211\n",
      "iteration 1 / 300: loss 0.784661\n",
      "iteration 1 / 300: loss 0.775792\n",
      "iteration 1 / 300: loss 0.795233\n",
      "iteration 1 / 300: loss 0.787310\n",
      "iteration 1 / 300: loss 0.791316\n",
      "iteration 1 / 300: loss 0.798024\n",
      "iteration 1 / 300: loss 0.783697\n",
      "iteration 1 / 300: loss 0.802137\n",
      "iteration 1 / 300: loss 0.788128\n",
      "iteration 1 / 300: loss 0.802309\n",
      "iteration 1 / 300: loss 0.794036\n",
      "iteration 1 / 300: loss 0.790595\n",
      "iteration 1 / 300: loss 0.784162\n",
      "iteration 1 / 300: loss 0.799588\n",
      "iteration 1 / 300: loss 0.778394\n",
      "iteration 1 / 300: loss 0.794897\n",
      "iteration 1 / 300: loss 0.781463\n",
      "iteration 1 / 300: loss 0.794393\n",
      "iteration 1 / 300: loss 0.797444\n",
      "iteration 1 / 300: loss 0.778015\n",
      "iteration 1 / 300: loss 0.781752\n",
      "iteration 1 / 300: loss 0.792033\n",
      "iteration 1 / 300: loss 0.783079\n",
      "iteration 1 / 300: loss 0.778991\n",
      "iteration 1 / 300: loss 0.789811\n",
      "iteration 1 / 300: loss 0.785175\n",
      "iteration 1 / 300: loss 0.789029\n",
      "iteration 1 / 300: loss 0.794186\n",
      "iteration 1 / 300: loss 0.779181\n",
      "iteration 1 / 300: loss 0.779238\n",
      "iteration 1 / 300: loss 0.777934\n",
      "iteration 1 / 300: loss 0.783642\n",
      "iteration 1 / 300: loss 0.774470\n",
      "iteration 1 / 300: loss 0.764691\n",
      "iteration 1 / 300: loss 0.768215\n",
      "iteration 1 / 300: loss 0.757734\n",
      "iteration 1 / 300: loss 0.778148\n",
      "iteration 1 / 300: loss 0.774817\n",
      "iteration 1 / 300: loss 0.781704\n",
      "iteration 1 / 300: loss 0.768411\n",
      "iteration 1 / 300: loss 0.787394\n",
      "iteration 1 / 300: loss 0.795266\n",
      "iteration 1 / 300: loss 0.789516\n",
      "iteration 1 / 300: loss 0.795011\n",
      "iteration 1 / 300: loss 0.769517\n",
      "iteration 1 / 300: loss 0.778336\n",
      "iteration 1 / 300: loss 0.775405\n",
      "iteration 1 / 300: loss 0.771480\n",
      "iteration 1 / 300: loss 0.777473\n",
      "iteration 1 / 300: loss 0.776895\n",
      "iteration 1 / 300: loss 0.774486\n",
      "iteration 1 / 300: loss 0.779157\n",
      "iteration 1 / 300: loss 0.799099\n",
      "iteration 1 / 300: loss 0.793931\n",
      "iteration 1 / 300: loss 0.799885\n",
      "iteration 1 / 300: loss 0.775072\n",
      "iteration 1 / 300: loss 0.769321\n",
      "iteration 1 / 300: loss 0.781207\n",
      "iteration 1 / 300: loss 0.773959\n",
      "iteration 1 / 300: loss 0.772025\n",
      "iteration 1 / 300: loss 0.770914\n",
      "iteration 1 / 300: loss 0.774063\n",
      "iteration 1 / 300: loss 0.780290\n",
      "iteration 1 / 300: loss 0.780886\n",
      "iteration 1 / 300: loss 0.762032\n",
      "iteration 1 / 300: loss 0.777425\n",
      "iteration 1 / 300: loss 0.792106\n",
      "iteration 1 / 300: loss 0.780940\n",
      "iteration 1 / 300: loss 0.776419\n",
      "iteration 1 / 300: loss 0.793857\n",
      "iteration 1 / 300: loss 0.763571\n",
      "iteration 1 / 300: loss 0.768818\n",
      "iteration 1 / 300: loss 0.800940\n",
      "iteration 1 / 300: loss 0.773826\n",
      "iteration 1 / 300: loss 0.773002\n",
      "iteration 1 / 300: loss 0.791523\n",
      "iteration 1 / 300: loss 0.784255\n",
      "iteration 1 / 300: loss 0.775567\n",
      "iteration 1 / 300: loss 0.766427\n",
      "iteration 1 / 300: loss 0.777670\n",
      "iteration 1 / 300: loss 0.780299\n",
      "iteration 1 / 300: loss 0.770608\n",
      "iteration 1 / 300: loss 0.769413\n",
      "iteration 1 / 300: loss 0.786295\n",
      "iteration 1 / 300: loss 0.769854\n",
      "iteration 1 / 300: loss 0.760497\n",
      "iteration 1 / 300: loss 0.765075\n",
      "iteration 2 / 300: loss 0.762411\n",
      "iteration 2 / 300: loss 0.773866\n",
      "iteration 2 / 300: loss 0.755925\n",
      "iteration 2 / 300: loss 0.760611\n",
      "iteration 2 / 300: loss 0.766314\n",
      "iteration 2 / 300: loss 0.768883\n",
      "iteration 2 / 300: loss 0.782613\n",
      "iteration 2 / 300: loss 0.770641\n",
      "iteration 2 / 300: loss 0.790200\n",
      "iteration 2 / 300: loss 0.770517\n",
      "iteration 2 / 300: loss 0.785129\n",
      "iteration 2 / 300: loss 0.758156\n",
      "iteration 2 / 300: loss 0.762104\n",
      "iteration 2 / 300: loss 0.761707\n",
      "iteration 2 / 300: loss 0.754655\n",
      "iteration 2 / 300: loss 0.774839\n",
      "iteration 2 / 300: loss 0.763989\n",
      "iteration 2 / 300: loss 0.771101\n",
      "iteration 2 / 300: loss 0.779268\n",
      "iteration 2 / 300: loss 0.757261\n",
      "iteration 2 / 300: loss 0.777384\n",
      "iteration 2 / 300: loss 0.760314\n",
      "iteration 2 / 300: loss 0.782990\n",
      "iteration 2 / 300: loss 0.776846\n",
      "iteration 2 / 300: loss 0.772603\n",
      "iteration 2 / 300: loss 0.767418\n",
      "iteration 2 / 300: loss 0.776921\n",
      "iteration 2 / 300: loss 0.756275\n",
      "iteration 2 / 300: loss 0.777771\n",
      "iteration 2 / 300: loss 0.762044\n",
      "iteration 2 / 300: loss 0.777299\n",
      "iteration 2 / 300: loss 0.780323\n",
      "iteration 2 / 300: loss 0.754098\n",
      "iteration 2 / 300: loss 0.759506\n",
      "iteration 2 / 300: loss 0.774613\n",
      "iteration 2 / 300: loss 0.766858\n",
      "iteration 2 / 300: loss 0.761243\n",
      "iteration 2 / 300: loss 0.772973\n",
      "iteration 2 / 300: loss 0.764833\n",
      "iteration 2 / 300: loss 0.770464\n",
      "iteration 2 / 300: loss 0.780418\n",
      "iteration 2 / 300: loss 0.756679\n",
      "iteration 2 / 300: loss 0.759016\n",
      "iteration 2 / 300: loss 0.755685\n",
      "iteration 2 / 300: loss 0.766814\n",
      "iteration 2 / 300: loss 0.754656\n",
      "iteration 2 / 300: loss 0.744240\n",
      "iteration 2 / 300: loss 0.750537\n",
      "iteration 2 / 300: loss 0.736060\n",
      "iteration 2 / 300: loss 0.754607\n",
      "iteration 2 / 300: loss 0.757875\n",
      "iteration 2 / 300: loss 0.763434\n",
      "iteration 2 / 300: loss 0.738658\n",
      "iteration 2 / 300: loss 0.766385\n",
      "iteration 2 / 300: loss 0.779630\n",
      "iteration 2 / 300: loss 0.771822\n",
      "iteration 2 / 300: loss 0.774721\n",
      "iteration 2 / 300: loss 0.752899\n",
      "iteration 2 / 300: loss 0.760467\n",
      "iteration 2 / 300: loss 0.757881\n",
      "iteration 2 / 300: loss 0.758258\n",
      "iteration 2 / 300: loss 0.761959\n",
      "iteration 2 / 300: loss 0.758703\n",
      "iteration 2 / 300: loss 0.757297\n",
      "iteration 2 / 300: loss 0.758652\n",
      "iteration 2 / 300: loss 0.777116\n",
      "iteration 2 / 300: loss 0.771817\n",
      "iteration 2 / 300: loss 0.785386\n",
      "iteration 2 / 300: loss 0.757640\n",
      "iteration 2 / 300: loss 0.754335\n",
      "iteration 2 / 300: loss 0.767986\n",
      "iteration 2 / 300: loss 0.756256\n",
      "iteration 2 / 300: loss 0.757682\n",
      "iteration 2 / 300: loss 0.757779\n",
      "iteration 2 / 300: loss 0.756405\n",
      "iteration 2 / 300: loss 0.766677\n",
      "iteration 2 / 300: loss 0.767979\n",
      "iteration 2 / 300: loss 0.747284\n",
      "iteration 2 / 300: loss 0.762227\n",
      "iteration 2 / 300: loss 0.772667\n",
      "iteration 2 / 300: loss 0.765399\n",
      "iteration 2 / 300: loss 0.761030\n",
      "iteration 2 / 300: loss 0.778970\n",
      "iteration 2 / 300: loss 0.745515\n",
      "iteration 2 / 300: loss 0.746257\n",
      "iteration 2 / 300: loss 0.780674\n",
      "iteration 2 / 300: loss 0.757471\n",
      "iteration 2 / 300: loss 0.761609\n",
      "iteration 2 / 300: loss 0.775915\n",
      "iteration 2 / 300: loss 0.769695\n",
      "iteration 2 / 300: loss 0.766145\n",
      "iteration 2 / 300: loss 0.754352\n",
      "iteration 2 / 300: loss 0.766373\n",
      "iteration 2 / 300: loss 0.768736\n",
      "iteration 2 / 300: loss 0.758137\n",
      "iteration 2 / 300: loss 0.752009\n",
      "iteration 2 / 300: loss 0.770977\n",
      "iteration 2 / 300: loss 0.753694\n",
      "iteration 2 / 300: loss 0.742509\n",
      "iteration 2 / 300: loss 0.751385\n",
      "iteration 3 / 300: loss 0.745948\n",
      "iteration 3 / 300: loss 0.759442\n",
      "iteration 3 / 300: loss 0.737876\n",
      "iteration 3 / 300: loss 0.742279\n",
      "iteration 3 / 300: loss 0.755310\n",
      "iteration 3 / 300: loss 0.754928\n",
      "iteration 3 / 300: loss 0.763664\n",
      "iteration 3 / 300: loss 0.748835\n",
      "iteration 3 / 300: loss 0.776550\n",
      "iteration 3 / 300: loss 0.750598\n",
      "iteration 3 / 300: loss 0.769985\n",
      "iteration 3 / 300: loss 0.744034\n",
      "iteration 3 / 300: loss 0.753081\n",
      "iteration 3 / 300: loss 0.750757\n",
      "iteration 3 / 300: loss 0.741852\n",
      "iteration 3 / 300: loss 0.761532\n",
      "iteration 3 / 300: loss 0.746516\n",
      "iteration 3 / 300: loss 0.756480\n",
      "iteration 3 / 300: loss 0.766155\n",
      "iteration 3 / 300: loss 0.743658\n",
      "iteration 3 / 300: loss 0.757798\n",
      "iteration 3 / 300: loss 0.742310\n",
      "iteration 3 / 300: loss 0.765854\n",
      "iteration 3 / 300: loss 0.758463\n",
      "iteration 3 / 300: loss 0.758059\n",
      "iteration 3 / 300: loss 0.755877\n",
      "iteration 3 / 300: loss 0.759730\n",
      "iteration 3 / 300: loss 0.742180\n",
      "iteration 3 / 300: loss 0.769036\n",
      "iteration 3 / 300: loss 0.751211\n",
      "iteration 3 / 300: loss 0.763559\n",
      "iteration 3 / 300: loss 0.773288\n",
      "iteration 3 / 300: loss 0.743584\n",
      "iteration 3 / 300: loss 0.748245\n",
      "iteration 3 / 300: loss 0.759928\n",
      "iteration 3 / 300: loss 0.753800\n",
      "iteration 3 / 300: loss 0.749095\n",
      "iteration 3 / 300: loss 0.759566\n",
      "iteration 3 / 300: loss 0.752128\n",
      "iteration 3 / 300: loss 0.758663\n",
      "iteration 3 / 300: loss 0.767458\n",
      "iteration 3 / 300: loss 0.741645\n",
      "iteration 3 / 300: loss 0.746582\n",
      "iteration 3 / 300: loss 0.739954\n",
      "iteration 3 / 300: loss 0.754610\n",
      "iteration 3 / 300: loss 0.736428\n",
      "iteration 3 / 300: loss 0.728592\n",
      "iteration 3 / 300: loss 0.734857\n",
      "iteration 3 / 300: loss 0.720605\n",
      "iteration 3 / 300: loss 0.741622\n",
      "iteration 3 / 300: loss 0.742232\n",
      "iteration 3 / 300: loss 0.743401\n",
      "iteration 3 / 300: loss 0.723534\n",
      "iteration 3 / 300: loss 0.751948\n",
      "iteration 3 / 300: loss 0.767212\n",
      "iteration 3 / 300: loss 0.761060\n",
      "iteration 3 / 300: loss 0.761969\n",
      "iteration 3 / 300: loss 0.736770\n",
      "iteration 3 / 300: loss 0.747235\n",
      "iteration 3 / 300: loss 0.741322\n",
      "iteration 3 / 300: loss 0.745491\n",
      "iteration 3 / 300: loss 0.750059\n",
      "iteration 3 / 300: loss 0.742161\n",
      "iteration 3 / 300: loss 0.741630\n",
      "iteration 3 / 300: loss 0.740578\n",
      "iteration 3 / 300: loss 0.765052\n",
      "iteration 3 / 300: loss 0.752306\n",
      "iteration 3 / 300: loss 0.765835\n",
      "iteration 3 / 300: loss 0.747209\n",
      "iteration 3 / 300: loss 0.743368\n",
      "iteration 3 / 300: loss 0.754263\n",
      "iteration 3 / 300: loss 0.743344\n",
      "iteration 3 / 300: loss 0.746389\n",
      "iteration 3 / 300: loss 0.740249\n",
      "iteration 3 / 300: loss 0.743618\n",
      "iteration 3 / 300: loss 0.756781\n",
      "iteration 3 / 300: loss 0.756292\n",
      "iteration 3 / 300: loss 0.734995\n",
      "iteration 3 / 300: loss 0.744148\n",
      "iteration 3 / 300: loss 0.759860\n",
      "iteration 3 / 300: loss 0.750645\n",
      "iteration 3 / 300: loss 0.749097\n",
      "iteration 3 / 300: loss 0.769723\n",
      "iteration 3 / 300: loss 0.730530\n",
      "iteration 3 / 300: loss 0.735643\n",
      "iteration 3 / 300: loss 0.770506\n",
      "iteration 3 / 300: loss 0.747862\n",
      "iteration 3 / 300: loss 0.748574\n",
      "iteration 3 / 300: loss 0.763159\n",
      "iteration 3 / 300: loss 0.759508\n",
      "iteration 3 / 300: loss 0.751597\n",
      "iteration 3 / 300: loss 0.739013\n",
      "iteration 3 / 300: loss 0.750165\n",
      "iteration 3 / 300: loss 0.753786\n",
      "iteration 3 / 300: loss 0.745772\n",
      "iteration 3 / 300: loss 0.737000\n",
      "iteration 3 / 300: loss 0.759551\n",
      "iteration 3 / 300: loss 0.741464\n",
      "iteration 3 / 300: loss 0.726866\n",
      "iteration 3 / 300: loss 0.735274\n",
      "iteration 4 / 300: loss 0.730600\n",
      "iteration 4 / 300: loss 0.741469\n",
      "iteration 4 / 300: loss 0.720554\n",
      "iteration 4 / 300: loss 0.730646\n",
      "iteration 4 / 300: loss 0.738501\n",
      "iteration 4 / 300: loss 0.741816\n",
      "iteration 4 / 300: loss 0.750149\n",
      "iteration 4 / 300: loss 0.735244\n",
      "iteration 4 / 300: loss 0.766469\n",
      "iteration 4 / 300: loss 0.739628\n",
      "iteration 4 / 300: loss 0.758810\n",
      "iteration 4 / 300: loss 0.730409\n",
      "iteration 4 / 300: loss 0.738188\n",
      "iteration 4 / 300: loss 0.729770\n",
      "iteration 4 / 300: loss 0.726282\n",
      "iteration 4 / 300: loss 0.749000\n",
      "iteration 4 / 300: loss 0.737454\n",
      "iteration 4 / 300: loss 0.743719\n",
      "iteration 4 / 300: loss 0.755155\n",
      "iteration 4 / 300: loss 0.734869\n",
      "iteration 4 / 300: loss 0.745060\n",
      "iteration 4 / 300: loss 0.731210\n",
      "iteration 4 / 300: loss 0.751700\n",
      "iteration 4 / 300: loss 0.744548\n",
      "iteration 4 / 300: loss 0.748829\n",
      "iteration 4 / 300: loss 0.745633\n",
      "iteration 4 / 300: loss 0.747852\n",
      "iteration 4 / 300: loss 0.732083\n",
      "iteration 4 / 300: loss 0.755454\n",
      "iteration 4 / 300: loss 0.738498\n",
      "iteration 4 / 300: loss 0.750398\n",
      "iteration 4 / 300: loss 0.758689\n",
      "iteration 4 / 300: loss 0.727312\n",
      "iteration 4 / 300: loss 0.736811\n",
      "iteration 4 / 300: loss 0.747120\n",
      "iteration 4 / 300: loss 0.745740\n",
      "iteration 4 / 300: loss 0.740049\n",
      "iteration 4 / 300: loss 0.742288\n",
      "iteration 4 / 300: loss 0.734621\n",
      "iteration 4 / 300: loss 0.749167\n",
      "iteration 4 / 300: loss 0.762484\n",
      "iteration 4 / 300: loss 0.734319\n",
      "iteration 4 / 300: loss 0.737762\n",
      "iteration 4 / 300: loss 0.728064\n",
      "iteration 4 / 300: loss 0.744708\n",
      "iteration 4 / 300: loss 0.725229\n",
      "iteration 4 / 300: loss 0.717621\n",
      "iteration 4 / 300: loss 0.722492\n",
      "iteration 4 / 300: loss 0.709348\n",
      "iteration 4 / 300: loss 0.730607\n",
      "iteration 4 / 300: loss 0.730595\n",
      "iteration 4 / 300: loss 0.730108\n",
      "iteration 4 / 300: loss 0.710571\n",
      "iteration 4 / 300: loss 0.737771\n",
      "iteration 4 / 300: loss 0.756214\n",
      "iteration 4 / 300: loss 0.745510\n",
      "iteration 4 / 300: loss 0.750501\n",
      "iteration 4 / 300: loss 0.727764\n",
      "iteration 4 / 300: loss 0.738441\n",
      "iteration 4 / 300: loss 0.731107\n",
      "iteration 4 / 300: loss 0.738458\n",
      "iteration 4 / 300: loss 0.743181\n",
      "iteration 4 / 300: loss 0.733436\n",
      "iteration 4 / 300: loss 0.731233\n",
      "iteration 4 / 300: loss 0.735130\n",
      "iteration 4 / 300: loss 0.755706\n",
      "iteration 4 / 300: loss 0.739700\n",
      "iteration 4 / 300: loss 0.756264\n",
      "iteration 4 / 300: loss 0.731351\n",
      "iteration 4 / 300: loss 0.730684\n",
      "iteration 4 / 300: loss 0.742945\n",
      "iteration 4 / 300: loss 0.735100\n",
      "iteration 4 / 300: loss 0.739840\n",
      "iteration 4 / 300: loss 0.732509\n",
      "iteration 4 / 300: loss 0.733534\n",
      "iteration 4 / 300: loss 0.742986\n",
      "iteration 4 / 300: loss 0.743169\n",
      "iteration 4 / 300: loss 0.725882\n",
      "iteration 4 / 300: loss 0.738159\n",
      "iteration 4 / 300: loss 0.745839\n",
      "iteration 4 / 300: loss 0.738823\n",
      "iteration 4 / 300: loss 0.737297\n",
      "iteration 4 / 300: loss 0.763983\n",
      "iteration 4 / 300: loss 0.719090\n",
      "iteration 4 / 300: loss 0.721553\n",
      "iteration 4 / 300: loss 0.764143\n",
      "iteration 4 / 300: loss 0.738334\n",
      "iteration 4 / 300: loss 0.740460\n",
      "iteration 4 / 300: loss 0.747824\n",
      "iteration 4 / 300: loss 0.747865\n",
      "iteration 4 / 300: loss 0.738622\n",
      "iteration 4 / 300: loss 0.726959\n",
      "iteration 4 / 300: loss 0.741054\n",
      "iteration 4 / 300: loss 0.743984\n",
      "iteration 4 / 300: loss 0.730280\n",
      "iteration 4 / 300: loss 0.725248\n",
      "iteration 4 / 300: loss 0.746388\n",
      "iteration 4 / 300: loss 0.733100\n",
      "iteration 4 / 300: loss 0.715455\n",
      "iteration 4 / 300: loss 0.727528\n",
      "iteration 5 / 300: loss 0.724088\n",
      "iteration 5 / 300: loss 0.733952\n",
      "iteration 5 / 300: loss 0.709437\n",
      "iteration 5 / 300: loss 0.720333\n",
      "iteration 5 / 300: loss 0.727818\n",
      "iteration 5 / 300: loss 0.734577\n",
      "iteration 5 / 300: loss 0.746069\n",
      "iteration 5 / 300: loss 0.727808\n",
      "iteration 5 / 300: loss 0.764600\n",
      "iteration 5 / 300: loss 0.724718\n",
      "iteration 5 / 300: loss 0.745411\n",
      "iteration 5 / 300: loss 0.718092\n",
      "iteration 5 / 300: loss 0.726878\n",
      "iteration 5 / 300: loss 0.717146\n",
      "iteration 5 / 300: loss 0.713497\n",
      "iteration 5 / 300: loss 0.738580\n",
      "iteration 5 / 300: loss 0.724907\n",
      "iteration 5 / 300: loss 0.734024\n",
      "iteration 5 / 300: loss 0.746150\n",
      "iteration 5 / 300: loss 0.721798\n",
      "iteration 5 / 300: loss 0.736792\n",
      "iteration 5 / 300: loss 0.721566\n",
      "iteration 5 / 300: loss 0.741304\n",
      "iteration 5 / 300: loss 0.735463\n",
      "iteration 5 / 300: loss 0.738350\n",
      "iteration 5 / 300: loss 0.733947\n",
      "iteration 5 / 300: loss 0.739111\n",
      "iteration 5 / 300: loss 0.718486\n",
      "iteration 5 / 300: loss 0.747953\n",
      "iteration 5 / 300: loss 0.727028\n",
      "iteration 5 / 300: loss 0.740830\n",
      "iteration 5 / 300: loss 0.750969\n",
      "iteration 5 / 300: loss 0.717365\n",
      "iteration 5 / 300: loss 0.721880\n",
      "iteration 5 / 300: loss 0.735404\n",
      "iteration 5 / 300: loss 0.733569\n",
      "iteration 5 / 300: loss 0.725930\n",
      "iteration 5 / 300: loss 0.728537\n",
      "iteration 5 / 300: loss 0.721134\n",
      "iteration 5 / 300: loss 0.741058\n",
      "iteration 5 / 300: loss 0.746670\n",
      "iteration 5 / 300: loss 0.720216\n",
      "iteration 5 / 300: loss 0.724137\n",
      "iteration 5 / 300: loss 0.717345\n",
      "iteration 5 / 300: loss 0.732870\n",
      "iteration 5 / 300: loss 0.713281\n",
      "iteration 5 / 300: loss 0.705987\n",
      "iteration 5 / 300: loss 0.711893\n",
      "iteration 5 / 300: loss 0.696858\n",
      "iteration 5 / 300: loss 0.718979\n",
      "iteration 5 / 300: loss 0.722447\n",
      "iteration 5 / 300: loss 0.722732\n",
      "iteration 5 / 300: loss 0.699715\n",
      "iteration 5 / 300: loss 0.726951\n",
      "iteration 5 / 300: loss 0.744939\n",
      "iteration 5 / 300: loss 0.738988\n",
      "iteration 5 / 300: loss 0.743343\n",
      "iteration 5 / 300: loss 0.719331\n",
      "iteration 5 / 300: loss 0.727395\n",
      "iteration 5 / 300: loss 0.723692\n",
      "iteration 5 / 300: loss 0.730537\n",
      "iteration 5 / 300: loss 0.726994\n",
      "iteration 5 / 300: loss 0.724265\n",
      "iteration 5 / 300: loss 0.725019\n",
      "iteration 5 / 300: loss 0.720058\n",
      "iteration 5 / 300: loss 0.737156\n",
      "iteration 5 / 300: loss 0.726111\n",
      "iteration 5 / 300: loss 0.743653\n",
      "iteration 5 / 300: loss 0.720385\n",
      "iteration 5 / 300: loss 0.721843\n",
      "iteration 5 / 300: loss 0.729710\n",
      "iteration 5 / 300: loss 0.726494\n",
      "iteration 5 / 300: loss 0.730061\n",
      "iteration 5 / 300: loss 0.723808\n",
      "iteration 5 / 300: loss 0.722736\n",
      "iteration 5 / 300: loss 0.732231\n",
      "iteration 5 / 300: loss 0.732280\n",
      "iteration 5 / 300: loss 0.713091\n",
      "iteration 5 / 300: loss 0.721312\n",
      "iteration 5 / 300: loss 0.733884\n",
      "iteration 5 / 300: loss 0.733167\n",
      "iteration 5 / 300: loss 0.729242\n",
      "iteration 5 / 300: loss 0.755707\n",
      "iteration 5 / 300: loss 0.713658\n",
      "iteration 5 / 300: loss 0.707632\n",
      "iteration 5 / 300: loss 0.753638\n",
      "iteration 5 / 300: loss 0.723721\n",
      "iteration 5 / 300: loss 0.729518\n",
      "iteration 5 / 300: loss 0.735072\n",
      "iteration 5 / 300: loss 0.731839\n",
      "iteration 5 / 300: loss 0.725574\n",
      "iteration 5 / 300: loss 0.716436\n",
      "iteration 5 / 300: loss 0.729976\n",
      "iteration 5 / 300: loss 0.734018\n",
      "iteration 5 / 300: loss 0.720220\n",
      "iteration 5 / 300: loss 0.718466\n",
      "iteration 5 / 300: loss 0.736830\n",
      "iteration 5 / 300: loss 0.720421\n",
      "iteration 5 / 300: loss 0.704121\n",
      "iteration 5 / 300: loss 0.723783\n",
      "iteration 6 / 300: loss 0.709813\n",
      "iteration 6 / 300: loss 0.724039\n",
      "iteration 6 / 300: loss 0.700039\n",
      "iteration 6 / 300: loss 0.708109\n",
      "iteration 6 / 300: loss 0.717454\n",
      "iteration 6 / 300: loss 0.721807\n",
      "iteration 6 / 300: loss 0.733171\n",
      "iteration 6 / 300: loss 0.716413\n",
      "iteration 6 / 300: loss 0.749948\n",
      "iteration 6 / 300: loss 0.713757\n",
      "iteration 6 / 300: loss 0.737264\n",
      "iteration 6 / 300: loss 0.711605\n",
      "iteration 6 / 300: loss 0.720002\n",
      "iteration 6 / 300: loss 0.699909\n",
      "iteration 6 / 300: loss 0.705614\n",
      "iteration 6 / 300: loss 0.731347\n",
      "iteration 6 / 300: loss 0.714075\n",
      "iteration 6 / 300: loss 0.721701\n",
      "iteration 6 / 300: loss 0.732485\n",
      "iteration 6 / 300: loss 0.711237\n",
      "iteration 6 / 300: loss 0.720023\n",
      "iteration 6 / 300: loss 0.706121\n",
      "iteration 6 / 300: loss 0.730922\n",
      "iteration 6 / 300: loss 0.724401\n",
      "iteration 6 / 300: loss 0.728892\n",
      "iteration 6 / 300: loss 0.725103\n",
      "iteration 6 / 300: loss 0.729782\n",
      "iteration 6 / 300: loss 0.711189\n",
      "iteration 6 / 300: loss 0.739461\n",
      "iteration 6 / 300: loss 0.718913\n",
      "iteration 6 / 300: loss 0.728887\n",
      "iteration 6 / 300: loss 0.738950\n",
      "iteration 6 / 300: loss 0.707102\n",
      "iteration 6 / 300: loss 0.714103\n",
      "iteration 6 / 300: loss 0.723868\n",
      "iteration 6 / 300: loss 0.725831\n",
      "iteration 6 / 300: loss 0.716691\n",
      "iteration 6 / 300: loss 0.716148\n",
      "iteration 6 / 300: loss 0.714566\n",
      "iteration 6 / 300: loss 0.729784\n",
      "iteration 6 / 300: loss 0.733136\n",
      "iteration 6 / 300: loss 0.708223\n",
      "iteration 6 / 300: loss 0.714182\n",
      "iteration 6 / 300: loss 0.707164\n",
      "iteration 6 / 300: loss 0.723306\n",
      "iteration 6 / 300: loss 0.703736\n",
      "iteration 6 / 300: loss 0.694651\n",
      "iteration 6 / 300: loss 0.702444\n",
      "iteration 6 / 300: loss 0.688115\n",
      "iteration 6 / 300: loss 0.711908\n",
      "iteration 6 / 300: loss 0.712373\n",
      "iteration 6 / 300: loss 0.708527\n",
      "iteration 6 / 300: loss 0.688478\n",
      "iteration 6 / 300: loss 0.715486\n",
      "iteration 6 / 300: loss 0.735105\n",
      "iteration 6 / 300: loss 0.727390\n",
      "iteration 6 / 300: loss 0.733329\n",
      "iteration 6 / 300: loss 0.708294\n",
      "iteration 6 / 300: loss 0.713512\n",
      "iteration 6 / 300: loss 0.712614\n",
      "iteration 6 / 300: loss 0.720826\n",
      "iteration 6 / 300: loss 0.713240\n",
      "iteration 6 / 300: loss 0.709801\n",
      "iteration 6 / 300: loss 0.709852\n",
      "iteration 6 / 300: loss 0.710907\n",
      "iteration 6 / 300: loss 0.730813\n",
      "iteration 6 / 300: loss 0.716093\n",
      "iteration 6 / 300: loss 0.741488\n",
      "iteration 6 / 300: loss 0.714247\n",
      "iteration 6 / 300: loss 0.710136\n",
      "iteration 6 / 300: loss 0.723396\n",
      "iteration 6 / 300: loss 0.715471\n",
      "iteration 6 / 300: loss 0.717741\n",
      "iteration 6 / 300: loss 0.712917\n",
      "iteration 6 / 300: loss 0.712565\n",
      "iteration 6 / 300: loss 0.729029\n",
      "iteration 6 / 300: loss 0.726729\n",
      "iteration 6 / 300: loss 0.702919\n",
      "iteration 6 / 300: loss 0.709099\n",
      "iteration 6 / 300: loss 0.723265\n",
      "iteration 6 / 300: loss 0.720281\n",
      "iteration 6 / 300: loss 0.719462\n",
      "iteration 6 / 300: loss 0.741903\n",
      "iteration 6 / 300: loss 0.699394\n",
      "iteration 6 / 300: loss 0.696498\n",
      "iteration 6 / 300: loss 0.746814\n",
      "iteration 6 / 300: loss 0.714829\n",
      "iteration 6 / 300: loss 0.714755\n",
      "iteration 6 / 300: loss 0.722778\n",
      "iteration 6 / 300: loss 0.728909\n",
      "iteration 6 / 300: loss 0.716780\n",
      "iteration 6 / 300: loss 0.708988\n",
      "iteration 6 / 300: loss 0.722134\n",
      "iteration 6 / 300: loss 0.725162\n",
      "iteration 6 / 300: loss 0.711918\n",
      "iteration 6 / 300: loss 0.705460\n",
      "iteration 6 / 300: loss 0.725842\n",
      "iteration 6 / 300: loss 0.711603\n",
      "iteration 6 / 300: loss 0.694066\n",
      "iteration 6 / 300: loss 0.710304\n",
      "iteration 7 / 300: loss 0.694573\n",
      "iteration 7 / 300: loss 0.713615\n",
      "iteration 7 / 300: loss 0.690927\n",
      "iteration 7 / 300: loss 0.699424\n",
      "iteration 7 / 300: loss 0.708002\n",
      "iteration 7 / 300: loss 0.713489\n",
      "iteration 7 / 300: loss 0.725801\n",
      "iteration 7 / 300: loss 0.702339\n",
      "iteration 7 / 300: loss 0.736003\n",
      "iteration 7 / 300: loss 0.705631\n",
      "iteration 7 / 300: loss 0.739647\n",
      "iteration 7 / 300: loss 0.713905\n",
      "iteration 7 / 300: loss 0.723414\n",
      "iteration 7 / 300: loss 0.698461\n",
      "iteration 7 / 300: loss 0.697737\n",
      "iteration 7 / 300: loss 0.721605\n",
      "iteration 7 / 300: loss 0.707163\n",
      "iteration 7 / 300: loss 0.709112\n",
      "iteration 7 / 300: loss 0.724494\n",
      "iteration 7 / 300: loss 0.696910\n",
      "iteration 7 / 300: loss 0.705969\n",
      "iteration 7 / 300: loss 0.695896\n",
      "iteration 7 / 300: loss 0.720436\n",
      "iteration 7 / 300: loss 0.711865\n",
      "iteration 7 / 300: loss 0.723608\n",
      "iteration 7 / 300: loss 0.716625\n",
      "iteration 7 / 300: loss 0.717163\n",
      "iteration 7 / 300: loss 0.702691\n",
      "iteration 7 / 300: loss 0.730037\n",
      "iteration 7 / 300: loss 0.708121\n",
      "iteration 7 / 300: loss 0.716378\n",
      "iteration 7 / 300: loss 0.727442\n",
      "iteration 7 / 300: loss 0.695483\n",
      "iteration 7 / 300: loss 0.704443\n",
      "iteration 7 / 300: loss 0.713729\n",
      "iteration 7 / 300: loss 0.715438\n",
      "iteration 7 / 300: loss 0.705733\n",
      "iteration 7 / 300: loss 0.710124\n",
      "iteration 7 / 300: loss 0.703399\n",
      "iteration 7 / 300: loss 0.716436\n",
      "iteration 7 / 300: loss 0.729106\n",
      "iteration 7 / 300: loss 0.699547\n",
      "iteration 7 / 300: loss 0.702898\n",
      "iteration 7 / 300: loss 0.701098\n",
      "iteration 7 / 300: loss 0.714533\n",
      "iteration 7 / 300: loss 0.693174\n",
      "iteration 7 / 300: loss 0.684437\n",
      "iteration 7 / 300: loss 0.690411\n",
      "iteration 7 / 300: loss 0.673178\n",
      "iteration 7 / 300: loss 0.698773\n",
      "iteration 7 / 300: loss 0.698758\n",
      "iteration 7 / 300: loss 0.699495\n",
      "iteration 7 / 300: loss 0.680661\n",
      "iteration 7 / 300: loss 0.708630\n",
      "iteration 7 / 300: loss 0.725607\n",
      "iteration 7 / 300: loss 0.720943\n",
      "iteration 7 / 300: loss 0.721687\n",
      "iteration 7 / 300: loss 0.700307\n",
      "iteration 7 / 300: loss 0.705191\n",
      "iteration 7 / 300: loss 0.698685\n",
      "iteration 7 / 300: loss 0.709179\n",
      "iteration 7 / 300: loss 0.708233\n",
      "iteration 7 / 300: loss 0.704681\n",
      "iteration 7 / 300: loss 0.701479\n",
      "iteration 7 / 300: loss 0.702506\n",
      "iteration 7 / 300: loss 0.718048\n",
      "iteration 7 / 300: loss 0.705889\n",
      "iteration 7 / 300: loss 0.726027\n",
      "iteration 7 / 300: loss 0.704103\n",
      "iteration 7 / 300: loss 0.703053\n",
      "iteration 7 / 300: loss 0.715222\n",
      "iteration 7 / 300: loss 0.706171\n",
      "iteration 7 / 300: loss 0.706316\n",
      "iteration 7 / 300: loss 0.702357\n",
      "iteration 7 / 300: loss 0.702522\n",
      "iteration 7 / 300: loss 0.719654\n",
      "iteration 7 / 300: loss 0.716347\n",
      "iteration 7 / 300: loss 0.693313\n",
      "iteration 7 / 300: loss 0.701591\n",
      "iteration 7 / 300: loss 0.712740\n",
      "iteration 7 / 300: loss 0.711515\n",
      "iteration 7 / 300: loss 0.707976\n",
      "iteration 7 / 300: loss 0.735030\n",
      "iteration 7 / 300: loss 0.690278\n",
      "iteration 7 / 300: loss 0.688033\n",
      "iteration 7 / 300: loss 0.737924\n",
      "iteration 7 / 300: loss 0.706991\n",
      "iteration 7 / 300: loss 0.704898\n",
      "iteration 7 / 300: loss 0.713319\n",
      "iteration 7 / 300: loss 0.720949\n",
      "iteration 7 / 300: loss 0.705839\n",
      "iteration 7 / 300: loss 0.696307\n",
      "iteration 7 / 300: loss 0.710372\n",
      "iteration 7 / 300: loss 0.714639\n",
      "iteration 7 / 300: loss 0.698173\n",
      "iteration 7 / 300: loss 0.697099\n",
      "iteration 7 / 300: loss 0.717285\n",
      "iteration 7 / 300: loss 0.705759\n",
      "iteration 7 / 300: loss 0.685755\n",
      "iteration 7 / 300: loss 0.701664\n",
      "iteration 8 / 300: loss 0.690100\n",
      "iteration 8 / 300: loss 0.701874\n",
      "iteration 8 / 300: loss 0.679029\n",
      "iteration 8 / 300: loss 0.691493\n",
      "iteration 8 / 300: loss 0.700119\n",
      "iteration 8 / 300: loss 0.705092\n",
      "iteration 8 / 300: loss 0.718071\n",
      "iteration 8 / 300: loss 0.697032\n",
      "iteration 8 / 300: loss 0.733775\n",
      "iteration 8 / 300: loss 0.692746\n",
      "iteration 8 / 300: loss 0.716997\n",
      "iteration 8 / 300: loss 0.688717\n",
      "iteration 8 / 300: loss 0.696553\n",
      "iteration 8 / 300: loss 0.682529\n",
      "iteration 8 / 300: loss 0.689799\n",
      "iteration 8 / 300: loss 0.713064\n",
      "iteration 8 / 300: loss 0.697245\n",
      "iteration 8 / 300: loss 0.700351\n",
      "iteration 8 / 300: loss 0.714932\n",
      "iteration 8 / 300: loss 0.692769\n",
      "iteration 8 / 300: loss 0.699549\n",
      "iteration 8 / 300: loss 0.688091\n",
      "iteration 8 / 300: loss 0.709706\n",
      "iteration 8 / 300: loss 0.701927\n",
      "iteration 8 / 300: loss 0.714716\n",
      "iteration 8 / 300: loss 0.710476\n",
      "iteration 8 / 300: loss 0.710306\n",
      "iteration 8 / 300: loss 0.696063\n",
      "iteration 8 / 300: loss 0.722860\n",
      "iteration 8 / 300: loss 0.698343\n",
      "iteration 8 / 300: loss 0.705302\n",
      "iteration 8 / 300: loss 0.724071\n",
      "iteration 8 / 300: loss 0.689509\n",
      "iteration 8 / 300: loss 0.698188\n",
      "iteration 8 / 300: loss 0.702922\n",
      "iteration 8 / 300: loss 0.707571\n",
      "iteration 8 / 300: loss 0.699296\n",
      "iteration 8 / 300: loss 0.698259\n",
      "iteration 8 / 300: loss 0.694802\n",
      "iteration 8 / 300: loss 0.706560\n",
      "iteration 8 / 300: loss 0.720577\n",
      "iteration 8 / 300: loss 0.690106\n",
      "iteration 8 / 300: loss 0.695569\n",
      "iteration 8 / 300: loss 0.690167\n",
      "iteration 8 / 300: loss 0.705431\n",
      "iteration 8 / 300: loss 0.684841\n",
      "iteration 8 / 300: loss 0.672044\n",
      "iteration 8 / 300: loss 0.678507\n",
      "iteration 8 / 300: loss 0.665784\n",
      "iteration 8 / 300: loss 0.692030\n",
      "iteration 8 / 300: loss 0.692372\n",
      "iteration 8 / 300: loss 0.691255\n",
      "iteration 8 / 300: loss 0.673216\n",
      "iteration 8 / 300: loss 0.697395\n",
      "iteration 8 / 300: loss 0.716958\n",
      "iteration 8 / 300: loss 0.711140\n",
      "iteration 8 / 300: loss 0.715591\n",
      "iteration 8 / 300: loss 0.692776\n",
      "iteration 8 / 300: loss 0.695969\n",
      "iteration 8 / 300: loss 0.692158\n",
      "iteration 8 / 300: loss 0.700263\n",
      "iteration 8 / 300: loss 0.698704\n",
      "iteration 8 / 300: loss 0.693843\n",
      "iteration 8 / 300: loss 0.692311\n",
      "iteration 8 / 300: loss 0.692688\n",
      "iteration 8 / 300: loss 0.710482\n",
      "iteration 8 / 300: loss 0.697378\n",
      "iteration 8 / 300: loss 0.713919\n",
      "iteration 8 / 300: loss 0.693230\n",
      "iteration 8 / 300: loss 0.696040\n",
      "iteration 8 / 300: loss 0.706383\n",
      "iteration 8 / 300: loss 0.691849\n",
      "iteration 8 / 300: loss 0.696929\n",
      "iteration 8 / 300: loss 0.693691\n",
      "iteration 8 / 300: loss 0.690653\n",
      "iteration 8 / 300: loss 0.708933\n",
      "iteration 8 / 300: loss 0.710880\n",
      "iteration 8 / 300: loss 0.686433\n",
      "iteration 8 / 300: loss 0.696315\n",
      "iteration 8 / 300: loss 0.705510\n",
      "iteration 8 / 300: loss 0.701370\n",
      "iteration 8 / 300: loss 0.697693\n",
      "iteration 8 / 300: loss 0.729146\n",
      "iteration 8 / 300: loss 0.681924\n",
      "iteration 8 / 300: loss 0.678430\n",
      "iteration 8 / 300: loss 0.727143\n",
      "iteration 8 / 300: loss 0.694073\n",
      "iteration 8 / 300: loss 0.696753\n",
      "iteration 8 / 300: loss 0.701385\n",
      "iteration 8 / 300: loss 0.704758\n",
      "iteration 8 / 300: loss 0.696376\n",
      "iteration 8 / 300: loss 0.688461\n",
      "iteration 8 / 300: loss 0.702323\n",
      "iteration 8 / 300: loss 0.708356\n",
      "iteration 8 / 300: loss 0.691511\n",
      "iteration 8 / 300: loss 0.685718\n",
      "iteration 8 / 300: loss 0.705249\n",
      "iteration 8 / 300: loss 0.698102\n",
      "iteration 8 / 300: loss 0.679276\n",
      "iteration 8 / 300: loss 0.693662\n",
      "iteration 9 / 300: loss 0.680801\n",
      "iteration 9 / 300: loss 0.692107\n",
      "iteration 9 / 300: loss 0.668007\n",
      "iteration 9 / 300: loss 0.682465\n",
      "iteration 9 / 300: loss 0.691375\n",
      "iteration 9 / 300: loss 0.693355\n",
      "iteration 9 / 300: loss 0.705750\n",
      "iteration 9 / 300: loss 0.683008\n",
      "iteration 9 / 300: loss 0.719910\n",
      "iteration 9 / 300: loss 0.688006\n",
      "iteration 9 / 300: loss 0.711542\n",
      "iteration 9 / 300: loss 0.681403\n",
      "iteration 9 / 300: loss 0.690378\n",
      "iteration 9 / 300: loss 0.672282\n",
      "iteration 9 / 300: loss 0.679863\n",
      "iteration 9 / 300: loss 0.702404\n",
      "iteration 9 / 300: loss 0.686500\n",
      "iteration 9 / 300: loss 0.687311\n",
      "iteration 9 / 300: loss 0.705666\n",
      "iteration 9 / 300: loss 0.684123\n",
      "iteration 9 / 300: loss 0.684694\n",
      "iteration 9 / 300: loss 0.676976\n",
      "iteration 9 / 300: loss 0.710013\n",
      "iteration 9 / 300: loss 0.699005\n",
      "iteration 9 / 300: loss 0.706405\n",
      "iteration 9 / 300: loss 0.703317\n",
      "iteration 9 / 300: loss 0.697527\n",
      "iteration 9 / 300: loss 0.686334\n",
      "iteration 9 / 300: loss 0.714420\n",
      "iteration 9 / 300: loss 0.686719\n",
      "iteration 9 / 300: loss 0.697741\n",
      "iteration 9 / 300: loss 0.717684\n",
      "iteration 9 / 300: loss 0.684877\n",
      "iteration 9 / 300: loss 0.690518\n",
      "iteration 9 / 300: loss 0.694769\n",
      "iteration 9 / 300: loss 0.700500\n",
      "iteration 9 / 300: loss 0.693064\n",
      "iteration 9 / 300: loss 0.690264\n",
      "iteration 9 / 300: loss 0.687006\n",
      "iteration 9 / 300: loss 0.696036\n",
      "iteration 9 / 300: loss 0.707304\n",
      "iteration 9 / 300: loss 0.680220\n",
      "iteration 9 / 300: loss 0.687048\n",
      "iteration 9 / 300: loss 0.682902\n",
      "iteration 9 / 300: loss 0.700122\n",
      "iteration 9 / 300: loss 0.679121\n",
      "iteration 9 / 300: loss 0.665311\n",
      "iteration 9 / 300: loss 0.674118\n",
      "iteration 9 / 300: loss 0.654723\n",
      "iteration 9 / 300: loss 0.684949\n",
      "iteration 9 / 300: loss 0.681708\n",
      "iteration 9 / 300: loss 0.683014\n",
      "iteration 9 / 300: loss 0.664944\n",
      "iteration 9 / 300: loss 0.691404\n",
      "iteration 9 / 300: loss 0.707591\n",
      "iteration 9 / 300: loss 0.703387\n",
      "iteration 9 / 300: loss 0.705185\n",
      "iteration 9 / 300: loss 0.685532\n",
      "iteration 9 / 300: loss 0.689748\n",
      "iteration 9 / 300: loss 0.683803\n",
      "iteration 9 / 300: loss 0.692397\n",
      "iteration 9 / 300: loss 0.690519\n",
      "iteration 9 / 300: loss 0.687656\n",
      "iteration 9 / 300: loss 0.682191\n",
      "iteration 9 / 300: loss 0.683101\n",
      "iteration 9 / 300: loss 0.701549\n",
      "iteration 9 / 300: loss 0.686662\n",
      "iteration 9 / 300: loss 0.707440\n",
      "iteration 9 / 300: loss 0.684139\n",
      "iteration 9 / 300: loss 0.685919\n",
      "iteration 9 / 300: loss 0.698107\n",
      "iteration 9 / 300: loss 0.686155\n",
      "iteration 9 / 300: loss 0.692114\n",
      "iteration 9 / 300: loss 0.684789\n",
      "iteration 9 / 300: loss 0.681627\n",
      "iteration 9 / 300: loss 0.701652\n",
      "iteration 9 / 300: loss 0.702234\n",
      "iteration 9 / 300: loss 0.678514\n",
      "iteration 9 / 300: loss 0.688849\n",
      "iteration 9 / 300: loss 0.692604\n",
      "iteration 9 / 300: loss 0.695003\n",
      "iteration 9 / 300: loss 0.690163\n",
      "iteration 9 / 300: loss 0.718496\n",
      "iteration 9 / 300: loss 0.675379\n",
      "iteration 9 / 300: loss 0.671740\n",
      "iteration 9 / 300: loss 0.720722\n",
      "iteration 9 / 300: loss 0.689013\n",
      "iteration 9 / 300: loss 0.688860\n",
      "iteration 9 / 300: loss 0.692360\n",
      "iteration 9 / 300: loss 0.697741\n",
      "iteration 9 / 300: loss 0.685345\n",
      "iteration 9 / 300: loss 0.680288\n",
      "iteration 9 / 300: loss 0.691662\n",
      "iteration 9 / 300: loss 0.699091\n",
      "iteration 9 / 300: loss 0.681910\n",
      "iteration 9 / 300: loss 0.680345\n",
      "iteration 9 / 300: loss 0.696240\n",
      "iteration 9 / 300: loss 0.687162\n",
      "iteration 9 / 300: loss 0.667461\n",
      "iteration 9 / 300: loss 0.683689\n",
      "iteration 10 / 300: loss 0.669018\n",
      "iteration 10 / 300: loss 0.682324\n",
      "iteration 10 / 300: loss 0.657445\n",
      "iteration 10 / 300: loss 0.677759\n",
      "iteration 10 / 300: loss 0.681429\n",
      "iteration 10 / 300: loss 0.684544\n",
      "iteration 10 / 300: loss 0.699491\n",
      "iteration 10 / 300: loss 0.673913\n",
      "iteration 10 / 300: loss 0.710963\n",
      "iteration 10 / 300: loss 0.677949\n",
      "iteration 10 / 300: loss 0.701355\n",
      "iteration 10 / 300: loss 0.672329\n",
      "iteration 10 / 300: loss 0.684159\n",
      "iteration 10 / 300: loss 0.662842\n",
      "iteration 10 / 300: loss 0.668455\n",
      "iteration 10 / 300: loss 0.693267\n",
      "iteration 10 / 300: loss 0.681065\n",
      "iteration 10 / 300: loss 0.681959\n",
      "iteration 10 / 300: loss 0.700085\n",
      "iteration 10 / 300: loss 0.677188\n",
      "iteration 10 / 300: loss 0.675927\n",
      "iteration 10 / 300: loss 0.670534\n",
      "iteration 10 / 300: loss 0.698418\n",
      "iteration 10 / 300: loss 0.692307\n",
      "iteration 10 / 300: loss 0.701336\n",
      "iteration 10 / 300: loss 0.694873\n",
      "iteration 10 / 300: loss 0.687693\n",
      "iteration 10 / 300: loss 0.677191\n",
      "iteration 10 / 300: loss 0.707822\n",
      "iteration 10 / 300: loss 0.677521\n",
      "iteration 10 / 300: loss 0.689875\n",
      "iteration 10 / 300: loss 0.709154\n",
      "iteration 10 / 300: loss 0.675510\n",
      "iteration 10 / 300: loss 0.683587\n",
      "iteration 10 / 300: loss 0.684647\n",
      "iteration 10 / 300: loss 0.695362\n",
      "iteration 10 / 300: loss 0.680209\n",
      "iteration 10 / 300: loss 0.678028\n",
      "iteration 10 / 300: loss 0.682596\n",
      "iteration 10 / 300: loss 0.688373\n",
      "iteration 10 / 300: loss 0.702465\n",
      "iteration 10 / 300: loss 0.672734\n",
      "iteration 10 / 300: loss 0.678384\n",
      "iteration 10 / 300: loss 0.676837\n",
      "iteration 10 / 300: loss 0.690374\n",
      "iteration 10 / 300: loss 0.669449\n",
      "iteration 10 / 300: loss 0.659876\n",
      "iteration 10 / 300: loss 0.660127\n",
      "iteration 10 / 300: loss 0.646399\n",
      "iteration 10 / 300: loss 0.678902\n",
      "iteration 10 / 300: loss 0.673174\n",
      "iteration 10 / 300: loss 0.676442\n",
      "iteration 10 / 300: loss 0.652949\n",
      "iteration 10 / 300: loss 0.680379\n",
      "iteration 10 / 300: loss 0.698665\n",
      "iteration 10 / 300: loss 0.695027\n",
      "iteration 10 / 300: loss 0.696536\n",
      "iteration 10 / 300: loss 0.674398\n",
      "iteration 10 / 300: loss 0.679819\n",
      "iteration 10 / 300: loss 0.673957\n",
      "iteration 10 / 300: loss 0.688327\n",
      "iteration 10 / 300: loss 0.679940\n",
      "iteration 10 / 300: loss 0.675763\n",
      "iteration 10 / 300: loss 0.671280\n",
      "iteration 10 / 300: loss 0.677505\n",
      "iteration 10 / 300: loss 0.695222\n",
      "iteration 10 / 300: loss 0.680630\n",
      "iteration 10 / 300: loss 0.702266\n",
      "iteration 10 / 300: loss 0.676440\n",
      "iteration 10 / 300: loss 0.680880\n",
      "iteration 10 / 300: loss 0.695005\n",
      "iteration 10 / 300: loss 0.676873\n",
      "iteration 10 / 300: loss 0.681050\n",
      "iteration 10 / 300: loss 0.674723\n",
      "iteration 10 / 300: loss 0.674863\n",
      "iteration 10 / 300: loss 0.692154\n",
      "iteration 10 / 300: loss 0.693782\n",
      "iteration 10 / 300: loss 0.671591\n",
      "iteration 10 / 300: loss 0.682212\n",
      "iteration 10 / 300: loss 0.687921\n",
      "iteration 10 / 300: loss 0.687057\n",
      "iteration 10 / 300: loss 0.679597\n",
      "iteration 10 / 300: loss 0.710405\n",
      "iteration 10 / 300: loss 0.668214\n",
      "iteration 10 / 300: loss 0.664360\n",
      "iteration 10 / 300: loss 0.712341\n",
      "iteration 10 / 300: loss 0.680999\n",
      "iteration 10 / 300: loss 0.681940\n",
      "iteration 10 / 300: loss 0.684003\n",
      "iteration 10 / 300: loss 0.685739\n",
      "iteration 10 / 300: loss 0.678043\n",
      "iteration 10 / 300: loss 0.674870\n",
      "iteration 10 / 300: loss 0.685064\n",
      "iteration 10 / 300: loss 0.691042\n",
      "iteration 10 / 300: loss 0.674521\n",
      "iteration 10 / 300: loss 0.668921\n",
      "iteration 10 / 300: loss 0.687977\n",
      "iteration 10 / 300: loss 0.678770\n",
      "iteration 10 / 300: loss 0.658622\n",
      "iteration 10 / 300: loss 0.675588\n",
      "iteration 11 / 300: loss 0.660294\n",
      "iteration 11 / 300: loss 0.673708\n",
      "iteration 11 / 300: loss 0.649007\n",
      "iteration 11 / 300: loss 0.666283\n",
      "iteration 11 / 300: loss 0.671870\n",
      "iteration 11 / 300: loss 0.674686\n",
      "iteration 11 / 300: loss 0.692492\n",
      "iteration 11 / 300: loss 0.668624\n",
      "iteration 11 / 300: loss 0.707211\n",
      "iteration 11 / 300: loss 0.667618\n",
      "iteration 11 / 300: loss 0.691850\n",
      "iteration 11 / 300: loss 0.662858\n",
      "iteration 11 / 300: loss 0.674408\n",
      "iteration 11 / 300: loss 0.653056\n",
      "iteration 11 / 300: loss 0.658500\n",
      "iteration 11 / 300: loss 0.686259\n",
      "iteration 11 / 300: loss 0.673930\n",
      "iteration 11 / 300: loss 0.668629\n",
      "iteration 11 / 300: loss 0.690559\n",
      "iteration 11 / 300: loss 0.669199\n",
      "iteration 11 / 300: loss 0.667868\n",
      "iteration 11 / 300: loss 0.662255\n",
      "iteration 11 / 300: loss 0.687898\n",
      "iteration 11 / 300: loss 0.681038\n",
      "iteration 11 / 300: loss 0.694223\n",
      "iteration 11 / 300: loss 0.687241\n",
      "iteration 11 / 300: loss 0.681772\n",
      "iteration 11 / 300: loss 0.668667\n",
      "iteration 11 / 300: loss 0.697830\n",
      "iteration 11 / 300: loss 0.670257\n",
      "iteration 11 / 300: loss 0.682938\n",
      "iteration 11 / 300: loss 0.703865\n",
      "iteration 11 / 300: loss 0.665381\n",
      "iteration 11 / 300: loss 0.677383\n",
      "iteration 11 / 300: loss 0.678470\n",
      "iteration 11 / 300: loss 0.686273\n",
      "iteration 11 / 300: loss 0.671740\n",
      "iteration 11 / 300: loss 0.671455\n",
      "iteration 11 / 300: loss 0.676172\n",
      "iteration 11 / 300: loss 0.681459\n",
      "iteration 11 / 300: loss 0.693852\n",
      "iteration 11 / 300: loss 0.664918\n",
      "iteration 11 / 300: loss 0.671423\n",
      "iteration 11 / 300: loss 0.669343\n",
      "iteration 11 / 300: loss 0.683637\n",
      "iteration 11 / 300: loss 0.662159\n",
      "iteration 11 / 300: loss 0.649719\n",
      "iteration 11 / 300: loss 0.653772\n",
      "iteration 11 / 300: loss 0.639089\n",
      "iteration 11 / 300: loss 0.670656\n",
      "iteration 11 / 300: loss 0.661442\n",
      "iteration 11 / 300: loss 0.667399\n",
      "iteration 11 / 300: loss 0.644188\n",
      "iteration 11 / 300: loss 0.670826\n",
      "iteration 11 / 300: loss 0.692221\n",
      "iteration 11 / 300: loss 0.689832\n",
      "iteration 11 / 300: loss 0.694938\n",
      "iteration 11 / 300: loss 0.667274\n",
      "iteration 11 / 300: loss 0.673482\n",
      "iteration 11 / 300: loss 0.666430\n",
      "iteration 11 / 300: loss 0.678894\n",
      "iteration 11 / 300: loss 0.672066\n",
      "iteration 11 / 300: loss 0.669573\n",
      "iteration 11 / 300: loss 0.663657\n",
      "iteration 11 / 300: loss 0.667950\n",
      "iteration 11 / 300: loss 0.686200\n",
      "iteration 11 / 300: loss 0.671985\n",
      "iteration 11 / 300: loss 0.695126\n",
      "iteration 11 / 300: loss 0.669989\n",
      "iteration 11 / 300: loss 0.672286\n",
      "iteration 11 / 300: loss 0.687922\n",
      "iteration 11 / 300: loss 0.671912\n",
      "iteration 11 / 300: loss 0.673505\n",
      "iteration 11 / 300: loss 0.668672\n",
      "iteration 11 / 300: loss 0.666816\n",
      "iteration 11 / 300: loss 0.686052\n",
      "iteration 11 / 300: loss 0.687258\n",
      "iteration 11 / 300: loss 0.665464\n",
      "iteration 11 / 300: loss 0.674983\n",
      "iteration 11 / 300: loss 0.678963\n",
      "iteration 11 / 300: loss 0.681646\n",
      "iteration 11 / 300: loss 0.673716\n",
      "iteration 11 / 300: loss 0.703875\n",
      "iteration 11 / 300: loss 0.659632\n",
      "iteration 11 / 300: loss 0.656312\n",
      "iteration 11 / 300: loss 0.707295\n",
      "iteration 11 / 300: loss 0.675420\n",
      "iteration 11 / 300: loss 0.675851\n",
      "iteration 11 / 300: loss 0.674318\n",
      "iteration 11 / 300: loss 0.679201\n",
      "iteration 11 / 300: loss 0.669041\n",
      "iteration 11 / 300: loss 0.667774\n",
      "iteration 11 / 300: loss 0.678516\n",
      "iteration 11 / 300: loss 0.685152\n",
      "iteration 11 / 300: loss 0.666325\n",
      "iteration 11 / 300: loss 0.662857\n",
      "iteration 11 / 300: loss 0.681128\n",
      "iteration 11 / 300: loss 0.671957\n",
      "iteration 11 / 300: loss 0.651620\n",
      "iteration 11 / 300: loss 0.670038\n",
      "iteration 12 / 300: loss 0.654228\n",
      "iteration 12 / 300: loss 0.665806\n",
      "iteration 12 / 300: loss 0.640857\n",
      "iteration 12 / 300: loss 0.658718\n",
      "iteration 12 / 300: loss 0.666405\n",
      "iteration 12 / 300: loss 0.668075\n",
      "iteration 12 / 300: loss 0.688524\n",
      "iteration 12 / 300: loss 0.662397\n",
      "iteration 12 / 300: loss 0.698538\n",
      "iteration 12 / 300: loss 0.660095\n",
      "iteration 12 / 300: loss 0.686340\n",
      "iteration 12 / 300: loss 0.659494\n",
      "iteration 12 / 300: loss 0.667914\n",
      "iteration 12 / 300: loss 0.646522\n",
      "iteration 12 / 300: loss 0.651565\n",
      "iteration 12 / 300: loss 0.677351\n",
      "iteration 12 / 300: loss 0.667609\n",
      "iteration 12 / 300: loss 0.661543\n",
      "iteration 12 / 300: loss 0.683699\n",
      "iteration 12 / 300: loss 0.660235\n",
      "iteration 12 / 300: loss 0.660122\n",
      "iteration 12 / 300: loss 0.656846\n",
      "iteration 12 / 300: loss 0.681445\n",
      "iteration 12 / 300: loss 0.672359\n",
      "iteration 12 / 300: loss 0.687542\n",
      "iteration 12 / 300: loss 0.679047\n",
      "iteration 12 / 300: loss 0.670877\n",
      "iteration 12 / 300: loss 0.663358\n",
      "iteration 12 / 300: loss 0.692267\n",
      "iteration 12 / 300: loss 0.665238\n",
      "iteration 12 / 300: loss 0.675222\n",
      "iteration 12 / 300: loss 0.697876\n",
      "iteration 12 / 300: loss 0.661031\n",
      "iteration 12 / 300: loss 0.670928\n",
      "iteration 12 / 300: loss 0.670455\n",
      "iteration 12 / 300: loss 0.678041\n",
      "iteration 12 / 300: loss 0.667172\n",
      "iteration 12 / 300: loss 0.664975\n",
      "iteration 12 / 300: loss 0.666228\n",
      "iteration 12 / 300: loss 0.676296\n",
      "iteration 12 / 300: loss 0.688029\n",
      "iteration 12 / 300: loss 0.658164\n",
      "iteration 12 / 300: loss 0.663843\n",
      "iteration 12 / 300: loss 0.664148\n",
      "iteration 12 / 300: loss 0.675715\n",
      "iteration 12 / 300: loss 0.654222\n",
      "iteration 12 / 300: loss 0.644303\n",
      "iteration 12 / 300: loss 0.646984\n",
      "iteration 12 / 300: loss 0.631591\n",
      "iteration 12 / 300: loss 0.666129\n",
      "iteration 12 / 300: loss 0.653262\n",
      "iteration 12 / 300: loss 0.658841\n",
      "iteration 12 / 300: loss 0.638255\n",
      "iteration 12 / 300: loss 0.665915\n",
      "iteration 12 / 300: loss 0.684873\n",
      "iteration 12 / 300: loss 0.681453\n",
      "iteration 12 / 300: loss 0.684556\n",
      "iteration 12 / 300: loss 0.657552\n",
      "iteration 12 / 300: loss 0.665628\n",
      "iteration 12 / 300: loss 0.661310\n",
      "iteration 12 / 300: loss 0.671163\n",
      "iteration 12 / 300: loss 0.664117\n",
      "iteration 12 / 300: loss 0.660356\n",
      "iteration 12 / 300: loss 0.656348\n",
      "iteration 12 / 300: loss 0.664520\n",
      "iteration 12 / 300: loss 0.682374\n",
      "iteration 12 / 300: loss 0.665282\n",
      "iteration 12 / 300: loss 0.686425\n",
      "iteration 12 / 300: loss 0.666655\n",
      "iteration 12 / 300: loss 0.667335\n",
      "iteration 12 / 300: loss 0.682243\n",
      "iteration 12 / 300: loss 0.664401\n",
      "iteration 12 / 300: loss 0.664884\n",
      "iteration 12 / 300: loss 0.660704\n",
      "iteration 12 / 300: loss 0.661515\n",
      "iteration 12 / 300: loss 0.677656\n",
      "iteration 12 / 300: loss 0.680614\n",
      "iteration 12 / 300: loss 0.657234\n",
      "iteration 12 / 300: loss 0.666505\n",
      "iteration 12 / 300: loss 0.673854\n",
      "iteration 12 / 300: loss 0.675501\n",
      "iteration 12 / 300: loss 0.668297\n",
      "iteration 12 / 300: loss 0.696571\n",
      "iteration 12 / 300: loss 0.652684\n",
      "iteration 12 / 300: loss 0.649761\n",
      "iteration 12 / 300: loss 0.699675\n",
      "iteration 12 / 300: loss 0.668548\n",
      "iteration 12 / 300: loss 0.670551\n",
      "iteration 12 / 300: loss 0.667597\n",
      "iteration 12 / 300: loss 0.674522\n",
      "iteration 12 / 300: loss 0.661790\n",
      "iteration 12 / 300: loss 0.661238\n",
      "iteration 12 / 300: loss 0.672271\n",
      "iteration 12 / 300: loss 0.678716\n",
      "iteration 12 / 300: loss 0.661045\n",
      "iteration 12 / 300: loss 0.657606\n",
      "iteration 12 / 300: loss 0.675430\n",
      "iteration 12 / 300: loss 0.664040\n",
      "iteration 12 / 300: loss 0.646174\n",
      "iteration 12 / 300: loss 0.663854\n",
      "iteration 13 / 300: loss 0.646578\n",
      "iteration 13 / 300: loss 0.660364\n",
      "iteration 13 / 300: loss 0.633570\n",
      "iteration 13 / 300: loss 0.654099\n",
      "iteration 13 / 300: loss 0.661093\n",
      "iteration 13 / 300: loss 0.663282\n",
      "iteration 13 / 300: loss 0.679002\n",
      "iteration 13 / 300: loss 0.656347\n",
      "iteration 13 / 300: loss 0.690826\n",
      "iteration 13 / 300: loss 0.654566\n",
      "iteration 13 / 300: loss 0.679445\n",
      "iteration 13 / 300: loss 0.652809\n",
      "iteration 13 / 300: loss 0.659766\n",
      "iteration 13 / 300: loss 0.638770\n",
      "iteration 13 / 300: loss 0.645576\n",
      "iteration 13 / 300: loss 0.672014\n",
      "iteration 13 / 300: loss 0.661585\n",
      "iteration 13 / 300: loss 0.655169\n",
      "iteration 13 / 300: loss 0.677088\n",
      "iteration 13 / 300: loss 0.653179\n",
      "iteration 13 / 300: loss 0.653074\n",
      "iteration 13 / 300: loss 0.651251\n",
      "iteration 13 / 300: loss 0.675428\n",
      "iteration 13 / 300: loss 0.664842\n",
      "iteration 13 / 300: loss 0.682444\n",
      "iteration 13 / 300: loss 0.673794\n",
      "iteration 13 / 300: loss 0.666516\n",
      "iteration 13 / 300: loss 0.656729\n",
      "iteration 13 / 300: loss 0.687261\n",
      "iteration 13 / 300: loss 0.656949\n",
      "iteration 13 / 300: loss 0.668895\n",
      "iteration 13 / 300: loss 0.690073\n",
      "iteration 13 / 300: loss 0.653638\n",
      "iteration 13 / 300: loss 0.666440\n",
      "iteration 13 / 300: loss 0.660170\n",
      "iteration 13 / 300: loss 0.671227\n",
      "iteration 13 / 300: loss 0.660145\n",
      "iteration 13 / 300: loss 0.654503\n",
      "iteration 13 / 300: loss 0.660595\n",
      "iteration 13 / 300: loss 0.669157\n",
      "iteration 13 / 300: loss 0.683131\n",
      "iteration 13 / 300: loss 0.650124\n",
      "iteration 13 / 300: loss 0.657318\n",
      "iteration 13 / 300: loss 0.654251\n",
      "iteration 13 / 300: loss 0.669516\n",
      "iteration 13 / 300: loss 0.650456\n",
      "iteration 13 / 300: loss 0.636622\n",
      "iteration 13 / 300: loss 0.639587\n",
      "iteration 13 / 300: loss 0.624542\n",
      "iteration 13 / 300: loss 0.659482\n",
      "iteration 13 / 300: loss 0.646251\n",
      "iteration 13 / 300: loss 0.651137\n",
      "iteration 13 / 300: loss 0.630724\n",
      "iteration 13 / 300: loss 0.657732\n",
      "iteration 13 / 300: loss 0.676223\n",
      "iteration 13 / 300: loss 0.674883\n",
      "iteration 13 / 300: loss 0.679937\n",
      "iteration 13 / 300: loss 0.651469\n",
      "iteration 13 / 300: loss 0.659288\n",
      "iteration 13 / 300: loss 0.654668\n",
      "iteration 13 / 300: loss 0.665742\n",
      "iteration 13 / 300: loss 0.657922\n",
      "iteration 13 / 300: loss 0.655296\n",
      "iteration 13 / 300: loss 0.649677\n",
      "iteration 13 / 300: loss 0.656490\n",
      "iteration 13 / 300: loss 0.673729\n",
      "iteration 13 / 300: loss 0.659029\n",
      "iteration 13 / 300: loss 0.678551\n",
      "iteration 13 / 300: loss 0.658044\n",
      "iteration 13 / 300: loss 0.659845\n",
      "iteration 13 / 300: loss 0.673232\n",
      "iteration 13 / 300: loss 0.657031\n",
      "iteration 13 / 300: loss 0.661218\n",
      "iteration 13 / 300: loss 0.653164\n",
      "iteration 13 / 300: loss 0.656336\n",
      "iteration 13 / 300: loss 0.670040\n",
      "iteration 13 / 300: loss 0.673747\n",
      "iteration 13 / 300: loss 0.651839\n",
      "iteration 13 / 300: loss 0.661974\n",
      "iteration 13 / 300: loss 0.668117\n",
      "iteration 13 / 300: loss 0.668784\n",
      "iteration 13 / 300: loss 0.664026\n",
      "iteration 13 / 300: loss 0.691176\n",
      "iteration 13 / 300: loss 0.646637\n",
      "iteration 13 / 300: loss 0.645515\n",
      "iteration 13 / 300: loss 0.693811\n",
      "iteration 13 / 300: loss 0.662620\n",
      "iteration 13 / 300: loss 0.663612\n",
      "iteration 13 / 300: loss 0.660294\n",
      "iteration 13 / 300: loss 0.668912\n",
      "iteration 13 / 300: loss 0.653277\n",
      "iteration 13 / 300: loss 0.654637\n",
      "iteration 13 / 300: loss 0.664723\n",
      "iteration 13 / 300: loss 0.673252\n",
      "iteration 13 / 300: loss 0.654321\n",
      "iteration 13 / 300: loss 0.650885\n",
      "iteration 13 / 300: loss 0.667755\n",
      "iteration 13 / 300: loss 0.656076\n",
      "iteration 13 / 300: loss 0.640687\n",
      "iteration 13 / 300: loss 0.657794\n",
      "iteration 14 / 300: loss 0.641004\n",
      "iteration 14 / 300: loss 0.653903\n",
      "iteration 14 / 300: loss 0.627564\n",
      "iteration 14 / 300: loss 0.647551\n",
      "iteration 14 / 300: loss 0.656162\n",
      "iteration 14 / 300: loss 0.657003\n",
      "iteration 14 / 300: loss 0.671511\n",
      "iteration 14 / 300: loss 0.648130\n",
      "iteration 14 / 300: loss 0.686738\n",
      "iteration 14 / 300: loss 0.649216\n",
      "iteration 14 / 300: loss 0.674110\n",
      "iteration 14 / 300: loss 0.647173\n",
      "iteration 14 / 300: loss 0.653105\n",
      "iteration 14 / 300: loss 0.633967\n",
      "iteration 14 / 300: loss 0.638802\n",
      "iteration 14 / 300: loss 0.666453\n",
      "iteration 14 / 300: loss 0.658080\n",
      "iteration 14 / 300: loss 0.648450\n",
      "iteration 14 / 300: loss 0.671942\n",
      "iteration 14 / 300: loss 0.648330\n",
      "iteration 14 / 300: loss 0.648903\n",
      "iteration 14 / 300: loss 0.645638\n",
      "iteration 14 / 300: loss 0.668914\n",
      "iteration 14 / 300: loss 0.658677\n",
      "iteration 14 / 300: loss 0.677240\n",
      "iteration 14 / 300: loss 0.668958\n",
      "iteration 14 / 300: loss 0.660907\n",
      "iteration 14 / 300: loss 0.651432\n",
      "iteration 14 / 300: loss 0.681123\n",
      "iteration 14 / 300: loss 0.652822\n",
      "iteration 14 / 300: loss 0.661877\n",
      "iteration 14 / 300: loss 0.684364\n",
      "iteration 14 / 300: loss 0.648500\n",
      "iteration 14 / 300: loss 0.660790\n",
      "iteration 14 / 300: loss 0.653276\n",
      "iteration 14 / 300: loss 0.664923\n",
      "iteration 14 / 300: loss 0.656270\n",
      "iteration 14 / 300: loss 0.648039\n",
      "iteration 14 / 300: loss 0.653813\n",
      "iteration 14 / 300: loss 0.662863\n",
      "iteration 14 / 300: loss 0.676319\n",
      "iteration 14 / 300: loss 0.644532\n",
      "iteration 14 / 300: loss 0.650243\n",
      "iteration 14 / 300: loss 0.647291\n",
      "iteration 14 / 300: loss 0.663544\n",
      "iteration 14 / 300: loss 0.644032\n",
      "iteration 14 / 300: loss 0.631747\n",
      "iteration 14 / 300: loss 0.632025\n",
      "iteration 14 / 300: loss 0.618860\n",
      "iteration 14 / 300: loss 0.654614\n",
      "iteration 14 / 300: loss 0.639914\n",
      "iteration 14 / 300: loss 0.643969\n",
      "iteration 14 / 300: loss 0.624758\n",
      "iteration 14 / 300: loss 0.652617\n",
      "iteration 14 / 300: loss 0.670250\n",
      "iteration 14 / 300: loss 0.668766\n",
      "iteration 14 / 300: loss 0.673256\n",
      "iteration 14 / 300: loss 0.644202\n",
      "iteration 14 / 300: loss 0.653398\n",
      "iteration 14 / 300: loss 0.650759\n",
      "iteration 14 / 300: loss 0.659548\n",
      "iteration 14 / 300: loss 0.651386\n",
      "iteration 14 / 300: loss 0.650729\n",
      "iteration 14 / 300: loss 0.644880\n",
      "iteration 14 / 300: loss 0.651095\n",
      "iteration 14 / 300: loss 0.667948\n",
      "iteration 14 / 300: loss 0.654302\n",
      "iteration 14 / 300: loss 0.673253\n",
      "iteration 14 / 300: loss 0.651396\n",
      "iteration 14 / 300: loss 0.653845\n",
      "iteration 14 / 300: loss 0.666638\n",
      "iteration 14 / 300: loss 0.651777\n",
      "iteration 14 / 300: loss 0.653987\n",
      "iteration 14 / 300: loss 0.647673\n",
      "iteration 14 / 300: loss 0.650676\n",
      "iteration 14 / 300: loss 0.664146\n",
      "iteration 14 / 300: loss 0.666779\n",
      "iteration 14 / 300: loss 0.646767\n",
      "iteration 14 / 300: loss 0.655506\n",
      "iteration 14 / 300: loss 0.661378\n",
      "iteration 14 / 300: loss 0.662603\n",
      "iteration 14 / 300: loss 0.657992\n",
      "iteration 14 / 300: loss 0.685926\n",
      "iteration 14 / 300: loss 0.639996\n",
      "iteration 14 / 300: loss 0.640594\n",
      "iteration 14 / 300: loss 0.687721\n",
      "iteration 14 / 300: loss 0.656614\n",
      "iteration 14 / 300: loss 0.657518\n",
      "iteration 14 / 300: loss 0.654153\n",
      "iteration 14 / 300: loss 0.662251\n",
      "iteration 14 / 300: loss 0.649576\n",
      "iteration 14 / 300: loss 0.649087\n",
      "iteration 14 / 300: loss 0.658352\n",
      "iteration 14 / 300: loss 0.667327\n",
      "iteration 14 / 300: loss 0.647781\n",
      "iteration 14 / 300: loss 0.646018\n",
      "iteration 14 / 300: loss 0.662486\n",
      "iteration 14 / 300: loss 0.650106\n",
      "iteration 14 / 300: loss 0.635831\n",
      "iteration 14 / 300: loss 0.652135\n",
      "iteration 15 / 300: loss 0.636018\n",
      "iteration 15 / 300: loss 0.648075\n",
      "iteration 15 / 300: loss 0.620814\n",
      "iteration 15 / 300: loss 0.643072\n",
      "iteration 15 / 300: loss 0.650507\n",
      "iteration 15 / 300: loss 0.651955\n",
      "iteration 15 / 300: loss 0.666225\n",
      "iteration 15 / 300: loss 0.641743\n",
      "iteration 15 / 300: loss 0.681819\n",
      "iteration 15 / 300: loss 0.644389\n",
      "iteration 15 / 300: loss 0.669191\n",
      "iteration 15 / 300: loss 0.641019\n",
      "iteration 15 / 300: loss 0.647768\n",
      "iteration 15 / 300: loss 0.628043\n",
      "iteration 15 / 300: loss 0.632833\n",
      "iteration 15 / 300: loss 0.661169\n",
      "iteration 15 / 300: loss 0.652599\n",
      "iteration 15 / 300: loss 0.642146\n",
      "iteration 15 / 300: loss 0.666227\n",
      "iteration 15 / 300: loss 0.642746\n",
      "iteration 15 / 300: loss 0.644349\n",
      "iteration 15 / 300: loss 0.639707\n",
      "iteration 15 / 300: loss 0.662407\n",
      "iteration 15 / 300: loss 0.652022\n",
      "iteration 15 / 300: loss 0.671279\n",
      "iteration 15 / 300: loss 0.663857\n",
      "iteration 15 / 300: loss 0.654594\n",
      "iteration 15 / 300: loss 0.646784\n",
      "iteration 15 / 300: loss 0.677215\n",
      "iteration 15 / 300: loss 0.646883\n",
      "iteration 15 / 300: loss 0.657329\n",
      "iteration 15 / 300: loss 0.680195\n",
      "iteration 15 / 300: loss 0.643529\n",
      "iteration 15 / 300: loss 0.655938\n",
      "iteration 15 / 300: loss 0.648154\n",
      "iteration 15 / 300: loss 0.659513\n",
      "iteration 15 / 300: loss 0.650797\n",
      "iteration 15 / 300: loss 0.642364\n",
      "iteration 15 / 300: loss 0.648554\n",
      "iteration 15 / 300: loss 0.657628\n",
      "iteration 15 / 300: loss 0.670779\n",
      "iteration 15 / 300: loss 0.639531\n",
      "iteration 15 / 300: loss 0.645183\n",
      "iteration 15 / 300: loss 0.641178\n",
      "iteration 15 / 300: loss 0.659339\n",
      "iteration 15 / 300: loss 0.638764\n",
      "iteration 15 / 300: loss 0.626036\n",
      "iteration 15 / 300: loss 0.627189\n",
      "iteration 15 / 300: loss 0.613694\n",
      "iteration 15 / 300: loss 0.650304\n",
      "iteration 15 / 300: loss 0.635622\n",
      "iteration 15 / 300: loss 0.638461\n",
      "iteration 15 / 300: loss 0.620429\n",
      "iteration 15 / 300: loss 0.647224\n",
      "iteration 15 / 300: loss 0.664319\n",
      "iteration 15 / 300: loss 0.663032\n",
      "iteration 15 / 300: loss 0.668061\n",
      "iteration 15 / 300: loss 0.638701\n",
      "iteration 15 / 300: loss 0.647763\n",
      "iteration 15 / 300: loss 0.645709\n",
      "iteration 15 / 300: loss 0.655534\n",
      "iteration 15 / 300: loss 0.646638\n",
      "iteration 15 / 300: loss 0.644030\n",
      "iteration 15 / 300: loss 0.638397\n",
      "iteration 15 / 300: loss 0.644731\n",
      "iteration 15 / 300: loss 0.660046\n",
      "iteration 15 / 300: loss 0.648713\n",
      "iteration 15 / 300: loss 0.667943\n",
      "iteration 15 / 300: loss 0.646952\n",
      "iteration 15 / 300: loss 0.648639\n",
      "iteration 15 / 300: loss 0.661515\n",
      "iteration 15 / 300: loss 0.646122\n",
      "iteration 15 / 300: loss 0.646262\n",
      "iteration 15 / 300: loss 0.643204\n",
      "iteration 15 / 300: loss 0.646776\n",
      "iteration 15 / 300: loss 0.659280\n",
      "iteration 15 / 300: loss 0.661641\n",
      "iteration 15 / 300: loss 0.642905\n",
      "iteration 15 / 300: loss 0.651297\n",
      "iteration 15 / 300: loss 0.657110\n",
      "iteration 15 / 300: loss 0.657912\n",
      "iteration 15 / 300: loss 0.653149\n",
      "iteration 15 / 300: loss 0.680323\n",
      "iteration 15 / 300: loss 0.634676\n",
      "iteration 15 / 300: loss 0.634673\n",
      "iteration 15 / 300: loss 0.681351\n",
      "iteration 15 / 300: loss 0.650763\n",
      "iteration 15 / 300: loss 0.654030\n",
      "iteration 15 / 300: loss 0.649399\n",
      "iteration 15 / 300: loss 0.656831\n",
      "iteration 15 / 300: loss 0.644038\n",
      "iteration 15 / 300: loss 0.643038\n",
      "iteration 15 / 300: loss 0.654447\n",
      "iteration 15 / 300: loss 0.663860\n",
      "iteration 15 / 300: loss 0.643764\n",
      "iteration 15 / 300: loss 0.641154\n",
      "iteration 15 / 300: loss 0.657348\n",
      "iteration 15 / 300: loss 0.644920\n",
      "iteration 15 / 300: loss 0.631924\n",
      "iteration 15 / 300: loss 0.647069\n",
      "iteration 16 / 300: loss 0.631383\n",
      "iteration 16 / 300: loss 0.642998\n",
      "iteration 16 / 300: loss 0.615236\n",
      "iteration 16 / 300: loss 0.639129\n",
      "iteration 16 / 300: loss 0.645758\n",
      "iteration 16 / 300: loss 0.648037\n",
      "iteration 16 / 300: loss 0.662582\n",
      "iteration 16 / 300: loss 0.638907\n",
      "iteration 16 / 300: loss 0.677020\n",
      "iteration 16 / 300: loss 0.638590\n",
      "iteration 16 / 300: loss 0.663609\n",
      "iteration 16 / 300: loss 0.634548\n",
      "iteration 16 / 300: loss 0.641768\n",
      "iteration 16 / 300: loss 0.622740\n",
      "iteration 16 / 300: loss 0.629167\n",
      "iteration 16 / 300: loss 0.657273\n",
      "iteration 16 / 300: loss 0.647554\n",
      "iteration 16 / 300: loss 0.635855\n",
      "iteration 16 / 300: loss 0.661933\n",
      "iteration 16 / 300: loss 0.637461\n",
      "iteration 16 / 300: loss 0.638875\n",
      "iteration 16 / 300: loss 0.634984\n",
      "iteration 16 / 300: loss 0.658594\n",
      "iteration 16 / 300: loss 0.645350\n",
      "iteration 16 / 300: loss 0.666797\n",
      "iteration 16 / 300: loss 0.659714\n",
      "iteration 16 / 300: loss 0.649555\n",
      "iteration 16 / 300: loss 0.642348\n",
      "iteration 16 / 300: loss 0.671301\n",
      "iteration 16 / 300: loss 0.643500\n",
      "iteration 16 / 300: loss 0.654011\n",
      "iteration 16 / 300: loss 0.675417\n",
      "iteration 16 / 300: loss 0.638360\n",
      "iteration 16 / 300: loss 0.650645\n",
      "iteration 16 / 300: loss 0.644705\n",
      "iteration 16 / 300: loss 0.654749\n",
      "iteration 16 / 300: loss 0.646452\n",
      "iteration 16 / 300: loss 0.636889\n",
      "iteration 16 / 300: loss 0.643912\n",
      "iteration 16 / 300: loss 0.651992\n",
      "iteration 16 / 300: loss 0.665789\n",
      "iteration 16 / 300: loss 0.634503\n",
      "iteration 16 / 300: loss 0.640241\n",
      "iteration 16 / 300: loss 0.637884\n",
      "iteration 16 / 300: loss 0.654636\n",
      "iteration 16 / 300: loss 0.634213\n",
      "iteration 16 / 300: loss 0.622090\n",
      "iteration 16 / 300: loss 0.621909\n",
      "iteration 16 / 300: loss 0.609493\n",
      "iteration 16 / 300: loss 0.647073\n",
      "iteration 16 / 300: loss 0.630683\n",
      "iteration 16 / 300: loss 0.633977\n",
      "iteration 16 / 300: loss 0.615496\n",
      "iteration 16 / 300: loss 0.641536\n",
      "iteration 16 / 300: loss 0.659453\n",
      "iteration 16 / 300: loss 0.659276\n",
      "iteration 16 / 300: loss 0.663585\n",
      "iteration 16 / 300: loss 0.633572\n",
      "iteration 16 / 300: loss 0.642268\n",
      "iteration 16 / 300: loss 0.642098\n",
      "iteration 16 / 300: loss 0.651236\n",
      "iteration 16 / 300: loss 0.641946\n",
      "iteration 16 / 300: loss 0.639063\n",
      "iteration 16 / 300: loss 0.633154\n",
      "iteration 16 / 300: loss 0.639116\n",
      "iteration 16 / 300: loss 0.654673\n",
      "iteration 16 / 300: loss 0.644161\n",
      "iteration 16 / 300: loss 0.663854\n",
      "iteration 16 / 300: loss 0.642874\n",
      "iteration 16 / 300: loss 0.644207\n",
      "iteration 16 / 300: loss 0.655674\n",
      "iteration 16 / 300: loss 0.641644\n",
      "iteration 16 / 300: loss 0.641975\n",
      "iteration 16 / 300: loss 0.638826\n",
      "iteration 16 / 300: loss 0.642050\n",
      "iteration 16 / 300: loss 0.653059\n",
      "iteration 16 / 300: loss 0.657837\n",
      "iteration 16 / 300: loss 0.637428\n",
      "iteration 16 / 300: loss 0.646319\n",
      "iteration 16 / 300: loss 0.651301\n",
      "iteration 16 / 300: loss 0.652961\n",
      "iteration 16 / 300: loss 0.649272\n",
      "iteration 16 / 300: loss 0.676053\n",
      "iteration 16 / 300: loss 0.630237\n",
      "iteration 16 / 300: loss 0.630372\n",
      "iteration 16 / 300: loss 0.676374\n",
      "iteration 16 / 300: loss 0.646342\n",
      "iteration 16 / 300: loss 0.648990\n",
      "iteration 16 / 300: loss 0.643425\n",
      "iteration 16 / 300: loss 0.650897\n",
      "iteration 16 / 300: loss 0.638997\n",
      "iteration 16 / 300: loss 0.637965\n",
      "iteration 16 / 300: loss 0.650803\n",
      "iteration 16 / 300: loss 0.659608\n",
      "iteration 16 / 300: loss 0.637787\n",
      "iteration 16 / 300: loss 0.636707\n",
      "iteration 16 / 300: loss 0.652608\n",
      "iteration 16 / 300: loss 0.641086\n",
      "iteration 16 / 300: loss 0.627445\n",
      "iteration 16 / 300: loss 0.641932\n",
      "iteration 17 / 300: loss 0.627986\n",
      "iteration 17 / 300: loss 0.638040\n",
      "iteration 17 / 300: loss 0.610922\n",
      "iteration 17 / 300: loss 0.635098\n",
      "iteration 17 / 300: loss 0.641700\n",
      "iteration 17 / 300: loss 0.643574\n",
      "iteration 17 / 300: loss 0.657228\n",
      "iteration 17 / 300: loss 0.634812\n",
      "iteration 17 / 300: loss 0.673631\n",
      "iteration 17 / 300: loss 0.634414\n",
      "iteration 17 / 300: loss 0.659568\n",
      "iteration 17 / 300: loss 0.629923\n",
      "iteration 17 / 300: loss 0.637477\n",
      "iteration 17 / 300: loss 0.618170\n",
      "iteration 17 / 300: loss 0.624998\n",
      "iteration 17 / 300: loss 0.652966\n",
      "iteration 17 / 300: loss 0.643376\n",
      "iteration 17 / 300: loss 0.631091\n",
      "iteration 17 / 300: loss 0.658641\n",
      "iteration 17 / 300: loss 0.633562\n",
      "iteration 17 / 300: loss 0.633968\n",
      "iteration 17 / 300: loss 0.630726\n",
      "iteration 17 / 300: loss 0.653725\n",
      "iteration 17 / 300: loss 0.639589\n",
      "iteration 17 / 300: loss 0.661798\n",
      "iteration 17 / 300: loss 0.654858\n",
      "iteration 17 / 300: loss 0.645490\n",
      "iteration 17 / 300: loss 0.638044\n",
      "iteration 17 / 300: loss 0.666058\n",
      "iteration 17 / 300: loss 0.638760\n",
      "iteration 17 / 300: loss 0.649042\n",
      "iteration 17 / 300: loss 0.670446\n",
      "iteration 17 / 300: loss 0.634719\n",
      "iteration 17 / 300: loss 0.646427\n",
      "iteration 17 / 300: loss 0.640571\n",
      "iteration 17 / 300: loss 0.650505\n",
      "iteration 17 / 300: loss 0.641892\n",
      "iteration 17 / 300: loss 0.632410\n",
      "iteration 17 / 300: loss 0.639387\n",
      "iteration 17 / 300: loss 0.647934\n",
      "iteration 17 / 300: loss 0.661857\n",
      "iteration 17 / 300: loss 0.630438\n",
      "iteration 17 / 300: loss 0.635965\n",
      "iteration 17 / 300: loss 0.634313\n",
      "iteration 17 / 300: loss 0.650727\n",
      "iteration 17 / 300: loss 0.629600\n",
      "iteration 17 / 300: loss 0.618844\n",
      "iteration 17 / 300: loss 0.617594\n",
      "iteration 17 / 300: loss 0.604446\n",
      "iteration 17 / 300: loss 0.642627\n",
      "iteration 17 / 300: loss 0.626714\n",
      "iteration 17 / 300: loss 0.630048\n",
      "iteration 17 / 300: loss 0.612672\n",
      "iteration 17 / 300: loss 0.636511\n",
      "iteration 17 / 300: loss 0.655320\n",
      "iteration 17 / 300: loss 0.654451\n",
      "iteration 17 / 300: loss 0.659141\n",
      "iteration 17 / 300: loss 0.629354\n",
      "iteration 17 / 300: loss 0.637839\n",
      "iteration 17 / 300: loss 0.638428\n",
      "iteration 17 / 300: loss 0.647321\n",
      "iteration 17 / 300: loss 0.637257\n",
      "iteration 17 / 300: loss 0.634784\n",
      "iteration 17 / 300: loss 0.629750\n",
      "iteration 17 / 300: loss 0.634405\n",
      "iteration 17 / 300: loss 0.649736\n",
      "iteration 17 / 300: loss 0.640155\n",
      "iteration 17 / 300: loss 0.660495\n",
      "iteration 17 / 300: loss 0.638550\n",
      "iteration 17 / 300: loss 0.640471\n",
      "iteration 17 / 300: loss 0.651285\n",
      "iteration 17 / 300: loss 0.637002\n",
      "iteration 17 / 300: loss 0.637591\n",
      "iteration 17 / 300: loss 0.633834\n",
      "iteration 17 / 300: loss 0.638802\n",
      "iteration 17 / 300: loss 0.648456\n",
      "iteration 17 / 300: loss 0.654370\n",
      "iteration 17 / 300: loss 0.632090\n",
      "iteration 17 / 300: loss 0.641758\n",
      "iteration 17 / 300: loss 0.646789\n",
      "iteration 17 / 300: loss 0.648286\n",
      "iteration 17 / 300: loss 0.645333\n",
      "iteration 17 / 300: loss 0.671969\n",
      "iteration 17 / 300: loss 0.626101\n",
      "iteration 17 / 300: loss 0.625943\n",
      "iteration 17 / 300: loss 0.671616\n",
      "iteration 17 / 300: loss 0.641565\n",
      "iteration 17 / 300: loss 0.644815\n",
      "iteration 17 / 300: loss 0.639291\n",
      "iteration 17 / 300: loss 0.645592\n",
      "iteration 17 / 300: loss 0.635612\n",
      "iteration 17 / 300: loss 0.633440\n",
      "iteration 17 / 300: loss 0.647281\n",
      "iteration 17 / 300: loss 0.655764\n",
      "iteration 17 / 300: loss 0.633778\n",
      "iteration 17 / 300: loss 0.632092\n",
      "iteration 17 / 300: loss 0.648112\n",
      "iteration 17 / 300: loss 0.637773\n",
      "iteration 17 / 300: loss 0.623419\n",
      "iteration 17 / 300: loss 0.637724\n",
      "iteration 18 / 300: loss 0.624026\n",
      "iteration 18 / 300: loss 0.633616\n",
      "iteration 18 / 300: loss 0.606917\n",
      "iteration 18 / 300: loss 0.630720\n",
      "iteration 18 / 300: loss 0.637784\n",
      "iteration 18 / 300: loss 0.639238\n",
      "iteration 18 / 300: loss 0.653277\n",
      "iteration 18 / 300: loss 0.631938\n",
      "iteration 18 / 300: loss 0.670493\n",
      "iteration 18 / 300: loss 0.630067\n",
      "iteration 18 / 300: loss 0.655350\n",
      "iteration 18 / 300: loss 0.626155\n",
      "iteration 18 / 300: loss 0.634029\n",
      "iteration 18 / 300: loss 0.613617\n",
      "iteration 18 / 300: loss 0.620555\n",
      "iteration 18 / 300: loss 0.649214\n",
      "iteration 18 / 300: loss 0.639675\n",
      "iteration 18 / 300: loss 0.626582\n",
      "iteration 18 / 300: loss 0.655236\n",
      "iteration 18 / 300: loss 0.629868\n",
      "iteration 18 / 300: loss 0.628907\n",
      "iteration 18 / 300: loss 0.627338\n",
      "iteration 18 / 300: loss 0.649210\n",
      "iteration 18 / 300: loss 0.634957\n",
      "iteration 18 / 300: loss 0.656947\n",
      "iteration 18 / 300: loss 0.650458\n",
      "iteration 18 / 300: loss 0.641162\n",
      "iteration 18 / 300: loss 0.633837\n",
      "iteration 18 / 300: loss 0.662664\n",
      "iteration 18 / 300: loss 0.635020\n",
      "iteration 18 / 300: loss 0.644101\n",
      "iteration 18 / 300: loss 0.666141\n",
      "iteration 18 / 300: loss 0.630119\n",
      "iteration 18 / 300: loss 0.644230\n",
      "iteration 18 / 300: loss 0.635890\n",
      "iteration 18 / 300: loss 0.646746\n",
      "iteration 18 / 300: loss 0.638520\n",
      "iteration 18 / 300: loss 0.628634\n",
      "iteration 18 / 300: loss 0.635314\n",
      "iteration 18 / 300: loss 0.644320\n",
      "iteration 18 / 300: loss 0.657327\n",
      "iteration 18 / 300: loss 0.627044\n",
      "iteration 18 / 300: loss 0.632267\n",
      "iteration 18 / 300: loss 0.630781\n",
      "iteration 18 / 300: loss 0.646711\n",
      "iteration 18 / 300: loss 0.625366\n",
      "iteration 18 / 300: loss 0.615206\n",
      "iteration 18 / 300: loss 0.613882\n",
      "iteration 18 / 300: loss 0.600442\n",
      "iteration 18 / 300: loss 0.638527\n",
      "iteration 18 / 300: loss 0.621756\n",
      "iteration 18 / 300: loss 0.625441\n",
      "iteration 18 / 300: loss 0.610118\n",
      "iteration 18 / 300: loss 0.632676\n",
      "iteration 18 / 300: loss 0.651364\n",
      "iteration 18 / 300: loss 0.650606\n",
      "iteration 18 / 300: loss 0.654192\n",
      "iteration 18 / 300: loss 0.625729\n",
      "iteration 18 / 300: loss 0.633329\n",
      "iteration 18 / 300: loss 0.634953\n",
      "iteration 18 / 300: loss 0.643711\n",
      "iteration 18 / 300: loss 0.633458\n",
      "iteration 18 / 300: loss 0.630623\n",
      "iteration 18 / 300: loss 0.626437\n",
      "iteration 18 / 300: loss 0.629482\n",
      "iteration 18 / 300: loss 0.644785\n",
      "iteration 18 / 300: loss 0.635975\n",
      "iteration 18 / 300: loss 0.657287\n",
      "iteration 18 / 300: loss 0.634368\n",
      "iteration 18 / 300: loss 0.637600\n",
      "iteration 18 / 300: loss 0.647039\n",
      "iteration 18 / 300: loss 0.633175\n",
      "iteration 18 / 300: loss 0.633101\n",
      "iteration 18 / 300: loss 0.629602\n",
      "iteration 18 / 300: loss 0.635261\n",
      "iteration 18 / 300: loss 0.643952\n",
      "iteration 18 / 300: loss 0.650608\n",
      "iteration 18 / 300: loss 0.627204\n",
      "iteration 18 / 300: loss 0.637742\n",
      "iteration 18 / 300: loss 0.642985\n",
      "iteration 18 / 300: loss 0.643895\n",
      "iteration 18 / 300: loss 0.641941\n",
      "iteration 18 / 300: loss 0.668256\n",
      "iteration 18 / 300: loss 0.623395\n",
      "iteration 18 / 300: loss 0.622001\n",
      "iteration 18 / 300: loss 0.667321\n",
      "iteration 18 / 300: loss 0.637402\n",
      "iteration 18 / 300: loss 0.641011\n",
      "iteration 18 / 300: loss 0.635679\n",
      "iteration 18 / 300: loss 0.640426\n",
      "iteration 18 / 300: loss 0.632156\n",
      "iteration 18 / 300: loss 0.629104\n",
      "iteration 18 / 300: loss 0.643818\n",
      "iteration 18 / 300: loss 0.652105\n",
      "iteration 18 / 300: loss 0.629675\n",
      "iteration 18 / 300: loss 0.628077\n",
      "iteration 18 / 300: loss 0.643747\n",
      "iteration 18 / 300: loss 0.634766\n",
      "iteration 18 / 300: loss 0.619595\n",
      "iteration 18 / 300: loss 0.634007\n",
      "iteration 19 / 300: loss 0.620512\n",
      "iteration 19 / 300: loss 0.629675\n",
      "iteration 19 / 300: loss 0.602909\n",
      "iteration 19 / 300: loss 0.626972\n",
      "iteration 19 / 300: loss 0.633897\n",
      "iteration 19 / 300: loss 0.635262\n",
      "iteration 19 / 300: loss 0.649443\n",
      "iteration 19 / 300: loss 0.628975\n",
      "iteration 19 / 300: loss 0.667284\n",
      "iteration 19 / 300: loss 0.626101\n",
      "iteration 19 / 300: loss 0.650945\n",
      "iteration 19 / 300: loss 0.622431\n",
      "iteration 19 / 300: loss 0.630311\n",
      "iteration 19 / 300: loss 0.610148\n",
      "iteration 19 / 300: loss 0.617093\n",
      "iteration 19 / 300: loss 0.646378\n",
      "iteration 19 / 300: loss 0.636199\n",
      "iteration 19 / 300: loss 0.622189\n",
      "iteration 19 / 300: loss 0.652672\n",
      "iteration 19 / 300: loss 0.626549\n",
      "iteration 19 / 300: loss 0.624527\n",
      "iteration 19 / 300: loss 0.624033\n",
      "iteration 19 / 300: loss 0.645129\n",
      "iteration 19 / 300: loss 0.630996\n",
      "iteration 19 / 300: loss 0.653180\n",
      "iteration 19 / 300: loss 0.646587\n",
      "iteration 19 / 300: loss 0.636917\n",
      "iteration 19 / 300: loss 0.629843\n",
      "iteration 19 / 300: loss 0.658916\n",
      "iteration 19 / 300: loss 0.631339\n",
      "iteration 19 / 300: loss 0.639853\n",
      "iteration 19 / 300: loss 0.662438\n",
      "iteration 19 / 300: loss 0.625957\n",
      "iteration 19 / 300: loss 0.641255\n",
      "iteration 19 / 300: loss 0.631419\n",
      "iteration 19 / 300: loss 0.643318\n",
      "iteration 19 / 300: loss 0.634950\n",
      "iteration 19 / 300: loss 0.625005\n",
      "iteration 19 / 300: loss 0.631712\n",
      "iteration 19 / 300: loss 0.640571\n",
      "iteration 19 / 300: loss 0.652528\n",
      "iteration 19 / 300: loss 0.623829\n",
      "iteration 19 / 300: loss 0.628745\n",
      "iteration 19 / 300: loss 0.627455\n",
      "iteration 19 / 300: loss 0.643657\n",
      "iteration 19 / 300: loss 0.621874\n",
      "iteration 19 / 300: loss 0.611742\n",
      "iteration 19 / 300: loss 0.610052\n",
      "iteration 19 / 300: loss 0.596751\n",
      "iteration 19 / 300: loss 0.634469\n",
      "iteration 19 / 300: loss 0.618008\n",
      "iteration 19 / 300: loss 0.621993\n",
      "iteration 19 / 300: loss 0.606937\n",
      "iteration 19 / 300: loss 0.628693\n",
      "iteration 19 / 300: loss 0.647312\n",
      "iteration 19 / 300: loss 0.647205\n",
      "iteration 19 / 300: loss 0.649685\n",
      "iteration 19 / 300: loss 0.622368\n",
      "iteration 19 / 300: loss 0.629395\n",
      "iteration 19 / 300: loss 0.631767\n",
      "iteration 19 / 300: loss 0.640445\n",
      "iteration 19 / 300: loss 0.630044\n",
      "iteration 19 / 300: loss 0.626746\n",
      "iteration 19 / 300: loss 0.623439\n",
      "iteration 19 / 300: loss 0.624951\n",
      "iteration 19 / 300: loss 0.640676\n",
      "iteration 19 / 300: loss 0.632209\n",
      "iteration 19 / 300: loss 0.653480\n",
      "iteration 19 / 300: loss 0.630901\n",
      "iteration 19 / 300: loss 0.635107\n",
      "iteration 19 / 300: loss 0.643167\n",
      "iteration 19 / 300: loss 0.629163\n",
      "iteration 19 / 300: loss 0.628852\n",
      "iteration 19 / 300: loss 0.625956\n",
      "iteration 19 / 300: loss 0.631927\n",
      "iteration 19 / 300: loss 0.639941\n",
      "iteration 19 / 300: loss 0.646212\n",
      "iteration 19 / 300: loss 0.623451\n",
      "iteration 19 / 300: loss 0.634425\n",
      "iteration 19 / 300: loss 0.639776\n",
      "iteration 19 / 300: loss 0.640182\n",
      "iteration 19 / 300: loss 0.639189\n",
      "iteration 19 / 300: loss 0.664706\n",
      "iteration 19 / 300: loss 0.620465\n",
      "iteration 19 / 300: loss 0.618267\n",
      "iteration 19 / 300: loss 0.663709\n",
      "iteration 19 / 300: loss 0.633628\n",
      "iteration 19 / 300: loss 0.637878\n",
      "iteration 19 / 300: loss 0.632284\n",
      "iteration 19 / 300: loss 0.636194\n",
      "iteration 19 / 300: loss 0.628797\n",
      "iteration 19 / 300: loss 0.625264\n",
      "iteration 19 / 300: loss 0.640294\n",
      "iteration 19 / 300: loss 0.648709\n",
      "iteration 19 / 300: loss 0.625902\n",
      "iteration 19 / 300: loss 0.625007\n",
      "iteration 19 / 300: loss 0.640125\n",
      "iteration 19 / 300: loss 0.632229\n",
      "iteration 19 / 300: loss 0.616202\n",
      "iteration 19 / 300: loss 0.630590\n",
      "iteration 20 / 300: loss 0.617248\n",
      "iteration 20 / 300: loss 0.626096\n",
      "iteration 20 / 300: loss 0.599611\n",
      "iteration 20 / 300: loss 0.623815\n",
      "iteration 20 / 300: loss 0.630235\n",
      "iteration 20 / 300: loss 0.631247\n",
      "iteration 20 / 300: loss 0.646183\n",
      "iteration 20 / 300: loss 0.625878\n",
      "iteration 20 / 300: loss 0.664387\n",
      "iteration 20 / 300: loss 0.622429\n",
      "iteration 20 / 300: loss 0.647089\n",
      "iteration 20 / 300: loss 0.619439\n",
      "iteration 20 / 300: loss 0.627045\n",
      "iteration 20 / 300: loss 0.606648\n",
      "iteration 20 / 300: loss 0.614603\n",
      "iteration 20 / 300: loss 0.643482\n",
      "iteration 20 / 300: loss 0.633091\n",
      "iteration 20 / 300: loss 0.618359\n",
      "iteration 20 / 300: loss 0.650265\n",
      "iteration 20 / 300: loss 0.623233\n",
      "iteration 20 / 300: loss 0.620509\n",
      "iteration 20 / 300: loss 0.621257\n",
      "iteration 20 / 300: loss 0.640518\n",
      "iteration 20 / 300: loss 0.627917\n",
      "iteration 20 / 300: loss 0.649616\n",
      "iteration 20 / 300: loss 0.643093\n",
      "iteration 20 / 300: loss 0.633384\n",
      "iteration 20 / 300: loss 0.626690\n",
      "iteration 20 / 300: loss 0.656159\n",
      "iteration 20 / 300: loss 0.627947\n",
      "iteration 20 / 300: loss 0.636040\n",
      "iteration 20 / 300: loss 0.659429\n",
      "iteration 20 / 300: loss 0.622458\n",
      "iteration 20 / 300: loss 0.637765\n",
      "iteration 20 / 300: loss 0.627732\n",
      "iteration 20 / 300: loss 0.639960\n",
      "iteration 20 / 300: loss 0.631498\n",
      "iteration 20 / 300: loss 0.621961\n",
      "iteration 20 / 300: loss 0.628513\n",
      "iteration 20 / 300: loss 0.637046\n",
      "iteration 20 / 300: loss 0.648588\n",
      "iteration 20 / 300: loss 0.620690\n",
      "iteration 20 / 300: loss 0.625390\n",
      "iteration 20 / 300: loss 0.624515\n",
      "iteration 20 / 300: loss 0.640834\n",
      "iteration 20 / 300: loss 0.618861\n",
      "iteration 20 / 300: loss 0.608858\n",
      "iteration 20 / 300: loss 0.606256\n",
      "iteration 20 / 300: loss 0.593947\n",
      "iteration 20 / 300: loss 0.631007\n",
      "iteration 20 / 300: loss 0.614181\n",
      "iteration 20 / 300: loss 0.618466\n",
      "iteration 20 / 300: loss 0.604302\n",
      "iteration 20 / 300: loss 0.624930\n",
      "iteration 20 / 300: loss 0.643616\n",
      "iteration 20 / 300: loss 0.644137\n",
      "iteration 20 / 300: loss 0.645499\n",
      "iteration 20 / 300: loss 0.618838\n",
      "iteration 20 / 300: loss 0.626323\n",
      "iteration 20 / 300: loss 0.629079\n",
      "iteration 20 / 300: loss 0.637119\n",
      "iteration 20 / 300: loss 0.626785\n",
      "iteration 20 / 300: loss 0.623399\n",
      "iteration 20 / 300: loss 0.620992\n",
      "iteration 20 / 300: loss 0.621096\n",
      "iteration 20 / 300: loss 0.637412\n",
      "iteration 20 / 300: loss 0.629277\n",
      "iteration 20 / 300: loss 0.649579\n",
      "iteration 20 / 300: loss 0.628195\n",
      "iteration 20 / 300: loss 0.632887\n",
      "iteration 20 / 300: loss 0.639938\n",
      "iteration 20 / 300: loss 0.625893\n",
      "iteration 20 / 300: loss 0.625071\n",
      "iteration 20 / 300: loss 0.622748\n",
      "iteration 20 / 300: loss 0.629627\n",
      "iteration 20 / 300: loss 0.636871\n",
      "iteration 20 / 300: loss 0.642238\n",
      "iteration 20 / 300: loss 0.619781\n",
      "iteration 20 / 300: loss 0.630870\n",
      "iteration 20 / 300: loss 0.636930\n",
      "iteration 20 / 300: loss 0.636881\n",
      "iteration 20 / 300: loss 0.636676\n",
      "iteration 20 / 300: loss 0.661728\n",
      "iteration 20 / 300: loss 0.617857\n",
      "iteration 20 / 300: loss 0.614845\n",
      "iteration 20 / 300: loss 0.660111\n",
      "iteration 20 / 300: loss 0.630788\n",
      "iteration 20 / 300: loss 0.635172\n",
      "iteration 20 / 300: loss 0.628744\n",
      "iteration 20 / 300: loss 0.632800\n",
      "iteration 20 / 300: loss 0.625839\n",
      "iteration 20 / 300: loss 0.621808\n",
      "iteration 20 / 300: loss 0.636819\n",
      "iteration 20 / 300: loss 0.645608\n",
      "iteration 20 / 300: loss 0.622470\n",
      "iteration 20 / 300: loss 0.622242\n",
      "iteration 20 / 300: loss 0.636932\n",
      "iteration 20 / 300: loss 0.629614\n",
      "iteration 20 / 300: loss 0.612965\n",
      "iteration 20 / 300: loss 0.627473\n",
      "iteration 21 / 300: loss 0.614315\n",
      "iteration 21 / 300: loss 0.622191\n",
      "iteration 21 / 300: loss 0.597085\n",
      "iteration 21 / 300: loss 0.620942\n",
      "iteration 21 / 300: loss 0.627302\n",
      "iteration 21 / 300: loss 0.627400\n",
      "iteration 21 / 300: loss 0.642697\n",
      "iteration 21 / 300: loss 0.622695\n",
      "iteration 21 / 300: loss 0.661728\n",
      "iteration 21 / 300: loss 0.619040\n",
      "iteration 21 / 300: loss 0.643557\n",
      "iteration 21 / 300: loss 0.616706\n",
      "iteration 21 / 300: loss 0.624283\n",
      "iteration 21 / 300: loss 0.602982\n",
      "iteration 21 / 300: loss 0.612295\n",
      "iteration 21 / 300: loss 0.640678\n",
      "iteration 21 / 300: loss 0.630209\n",
      "iteration 21 / 300: loss 0.614305\n",
      "iteration 21 / 300: loss 0.647894\n",
      "iteration 21 / 300: loss 0.620080\n",
      "iteration 21 / 300: loss 0.616655\n",
      "iteration 21 / 300: loss 0.618847\n",
      "iteration 21 / 300: loss 0.636703\n",
      "iteration 21 / 300: loss 0.624811\n",
      "iteration 21 / 300: loss 0.646198\n",
      "iteration 21 / 300: loss 0.640307\n",
      "iteration 21 / 300: loss 0.629896\n",
      "iteration 21 / 300: loss 0.623656\n",
      "iteration 21 / 300: loss 0.653164\n",
      "iteration 21 / 300: loss 0.624761\n",
      "iteration 21 / 300: loss 0.632766\n",
      "iteration 21 / 300: loss 0.656847\n",
      "iteration 21 / 300: loss 0.619119\n",
      "iteration 21 / 300: loss 0.634439\n",
      "iteration 21 / 300: loss 0.624690\n",
      "iteration 21 / 300: loss 0.636553\n",
      "iteration 21 / 300: loss 0.628425\n",
      "iteration 21 / 300: loss 0.618856\n",
      "iteration 21 / 300: loss 0.625979\n",
      "iteration 21 / 300: loss 0.633730\n",
      "iteration 21 / 300: loss 0.645829\n",
      "iteration 21 / 300: loss 0.617319\n",
      "iteration 21 / 300: loss 0.622235\n",
      "iteration 21 / 300: loss 0.621596\n",
      "iteration 21 / 300: loss 0.638077\n",
      "iteration 21 / 300: loss 0.616021\n",
      "iteration 21 / 300: loss 0.605886\n",
      "iteration 21 / 300: loss 0.602701\n",
      "iteration 21 / 300: loss 0.591176\n",
      "iteration 21 / 300: loss 0.627535\n",
      "iteration 21 / 300: loss 0.610667\n",
      "iteration 21 / 300: loss 0.615241\n",
      "iteration 21 / 300: loss 0.601535\n",
      "iteration 21 / 300: loss 0.621895\n",
      "iteration 21 / 300: loss 0.640241\n",
      "iteration 21 / 300: loss 0.641028\n",
      "iteration 21 / 300: loss 0.642027\n",
      "iteration 21 / 300: loss 0.615624\n",
      "iteration 21 / 300: loss 0.623164\n",
      "iteration 21 / 300: loss 0.626564\n",
      "iteration 21 / 300: loss 0.633832\n",
      "iteration 21 / 300: loss 0.624070\n",
      "iteration 21 / 300: loss 0.619950\n",
      "iteration 21 / 300: loss 0.618500\n",
      "iteration 21 / 300: loss 0.617709\n",
      "iteration 21 / 300: loss 0.634368\n",
      "iteration 21 / 300: loss 0.626424\n",
      "iteration 21 / 300: loss 0.645793\n",
      "iteration 21 / 300: loss 0.625545\n",
      "iteration 21 / 300: loss 0.630652\n",
      "iteration 21 / 300: loss 0.636788\n",
      "iteration 21 / 300: loss 0.623018\n",
      "iteration 21 / 300: loss 0.621754\n",
      "iteration 21 / 300: loss 0.619885\n",
      "iteration 21 / 300: loss 0.626978\n",
      "iteration 21 / 300: loss 0.634236\n",
      "iteration 21 / 300: loss 0.638910\n",
      "iteration 21 / 300: loss 0.616457\n",
      "iteration 21 / 300: loss 0.627677\n",
      "iteration 21 / 300: loss 0.633738\n",
      "iteration 21 / 300: loss 0.633874\n",
      "iteration 21 / 300: loss 0.634153\n",
      "iteration 21 / 300: loss 0.658919\n",
      "iteration 21 / 300: loss 0.615505\n",
      "iteration 21 / 300: loss 0.611930\n",
      "iteration 21 / 300: loss 0.656760\n",
      "iteration 21 / 300: loss 0.628497\n",
      "iteration 21 / 300: loss 0.632597\n",
      "iteration 21 / 300: loss 0.625586\n",
      "iteration 21 / 300: loss 0.629671\n",
      "iteration 21 / 300: loss 0.623222\n",
      "iteration 21 / 300: loss 0.618718\n",
      "iteration 21 / 300: loss 0.633411\n",
      "iteration 21 / 300: loss 0.642913\n",
      "iteration 21 / 300: loss 0.619446\n",
      "iteration 21 / 300: loss 0.620085\n",
      "iteration 21 / 300: loss 0.634139\n",
      "iteration 21 / 300: loss 0.627169\n",
      "iteration 21 / 300: loss 0.610156\n",
      "iteration 21 / 300: loss 0.624650\n",
      "iteration 22 / 300: loss 0.611587\n",
      "iteration 22 / 300: loss 0.618648\n",
      "iteration 22 / 300: loss 0.594283\n",
      "iteration 22 / 300: loss 0.618226\n",
      "iteration 22 / 300: loss 0.624620\n",
      "iteration 22 / 300: loss 0.623966\n",
      "iteration 22 / 300: loss 0.639324\n",
      "iteration 22 / 300: loss 0.620052\n",
      "iteration 22 / 300: loss 0.659201\n",
      "iteration 22 / 300: loss 0.616088\n",
      "iteration 22 / 300: loss 0.640440\n",
      "iteration 22 / 300: loss 0.614014\n",
      "iteration 22 / 300: loss 0.621746\n",
      "iteration 22 / 300: loss 0.599723\n",
      "iteration 22 / 300: loss 0.609810\n",
      "iteration 22 / 300: loss 0.638221\n",
      "iteration 22 / 300: loss 0.627564\n",
      "iteration 22 / 300: loss 0.610492\n",
      "iteration 22 / 300: loss 0.645441\n",
      "iteration 22 / 300: loss 0.617514\n",
      "iteration 22 / 300: loss 0.613172\n",
      "iteration 22 / 300: loss 0.616760\n",
      "iteration 22 / 300: loss 0.633482\n",
      "iteration 22 / 300: loss 0.622068\n",
      "iteration 22 / 300: loss 0.643297\n",
      "iteration 22 / 300: loss 0.637759\n",
      "iteration 22 / 300: loss 0.626863\n",
      "iteration 22 / 300: loss 0.620796\n",
      "iteration 22 / 300: loss 0.650545\n",
      "iteration 22 / 300: loss 0.621784\n",
      "iteration 22 / 300: loss 0.629703\n",
      "iteration 22 / 300: loss 0.654206\n",
      "iteration 22 / 300: loss 0.615979\n",
      "iteration 22 / 300: loss 0.631501\n",
      "iteration 22 / 300: loss 0.621870\n",
      "iteration 22 / 300: loss 0.633647\n",
      "iteration 22 / 300: loss 0.625494\n",
      "iteration 22 / 300: loss 0.616029\n",
      "iteration 22 / 300: loss 0.623901\n",
      "iteration 22 / 300: loss 0.630946\n",
      "iteration 22 / 300: loss 0.643324\n",
      "iteration 22 / 300: loss 0.614375\n",
      "iteration 22 / 300: loss 0.619346\n",
      "iteration 22 / 300: loss 0.618763\n",
      "iteration 22 / 300: loss 0.635516\n",
      "iteration 22 / 300: loss 0.613486\n",
      "iteration 22 / 300: loss 0.603034\n",
      "iteration 22 / 300: loss 0.599450\n",
      "iteration 22 / 300: loss 0.588497\n",
      "iteration 22 / 300: loss 0.624423\n",
      "iteration 22 / 300: loss 0.607732\n",
      "iteration 22 / 300: loss 0.612605\n",
      "iteration 22 / 300: loss 0.598938\n",
      "iteration 22 / 300: loss 0.619054\n",
      "iteration 22 / 300: loss 0.637237\n",
      "iteration 22 / 300: loss 0.638213\n",
      "iteration 22 / 300: loss 0.638746\n",
      "iteration 22 / 300: loss 0.612483\n",
      "iteration 22 / 300: loss 0.619958\n",
      "iteration 22 / 300: loss 0.624096\n",
      "iteration 22 / 300: loss 0.631184\n",
      "iteration 22 / 300: loss 0.621872\n",
      "iteration 22 / 300: loss 0.616782\n",
      "iteration 22 / 300: loss 0.616113\n",
      "iteration 22 / 300: loss 0.614447\n",
      "iteration 22 / 300: loss 0.631419\n",
      "iteration 22 / 300: loss 0.623911\n",
      "iteration 22 / 300: loss 0.642397\n",
      "iteration 22 / 300: loss 0.622934\n",
      "iteration 22 / 300: loss 0.628324\n",
      "iteration 22 / 300: loss 0.633960\n",
      "iteration 22 / 300: loss 0.620440\n",
      "iteration 22 / 300: loss 0.618954\n",
      "iteration 22 / 300: loss 0.617106\n",
      "iteration 22 / 300: loss 0.624413\n",
      "iteration 22 / 300: loss 0.631779\n",
      "iteration 22 / 300: loss 0.636196\n",
      "iteration 22 / 300: loss 0.613336\n",
      "iteration 22 / 300: loss 0.625013\n",
      "iteration 22 / 300: loss 0.630715\n",
      "iteration 22 / 300: loss 0.631362\n",
      "iteration 22 / 300: loss 0.631870\n",
      "iteration 22 / 300: loss 0.656104\n",
      "iteration 22 / 300: loss 0.613111\n",
      "iteration 22 / 300: loss 0.609322\n",
      "iteration 22 / 300: loss 0.653712\n",
      "iteration 22 / 300: loss 0.626328\n",
      "iteration 22 / 300: loss 0.629945\n",
      "iteration 22 / 300: loss 0.622704\n",
      "iteration 22 / 300: loss 0.626833\n",
      "iteration 22 / 300: loss 0.620790\n",
      "iteration 22 / 300: loss 0.616064\n",
      "iteration 22 / 300: loss 0.630722\n",
      "iteration 22 / 300: loss 0.640365\n",
      "iteration 22 / 300: loss 0.616827\n",
      "iteration 22 / 300: loss 0.618380\n",
      "iteration 22 / 300: loss 0.631498\n",
      "iteration 22 / 300: loss 0.624898\n",
      "iteration 22 / 300: loss 0.607466\n",
      "iteration 22 / 300: loss 0.622029\n",
      "iteration 23 / 300: loss 0.609501\n",
      "iteration 23 / 300: loss 0.615714\n",
      "iteration 23 / 300: loss 0.591690\n",
      "iteration 23 / 300: loss 0.615340\n",
      "iteration 23 / 300: loss 0.621792\n",
      "iteration 23 / 300: loss 0.621045\n",
      "iteration 23 / 300: loss 0.636270\n",
      "iteration 23 / 300: loss 0.617448\n",
      "iteration 23 / 300: loss 0.656933\n",
      "iteration 23 / 300: loss 0.613319\n",
      "iteration 23 / 300: loss 0.637737\n",
      "iteration 23 / 300: loss 0.611433\n",
      "iteration 23 / 300: loss 0.619584\n",
      "iteration 23 / 300: loss 0.596941\n",
      "iteration 23 / 300: loss 0.607606\n",
      "iteration 23 / 300: loss 0.635682\n",
      "iteration 23 / 300: loss 0.624851\n",
      "iteration 23 / 300: loss 0.607514\n",
      "iteration 23 / 300: loss 0.642981\n",
      "iteration 23 / 300: loss 0.615127\n",
      "iteration 23 / 300: loss 0.610340\n",
      "iteration 23 / 300: loss 0.614606\n",
      "iteration 23 / 300: loss 0.630755\n",
      "iteration 23 / 300: loss 0.619582\n",
      "iteration 23 / 300: loss 0.640719\n",
      "iteration 23 / 300: loss 0.635353\n",
      "iteration 23 / 300: loss 0.624019\n",
      "iteration 23 / 300: loss 0.618421\n",
      "iteration 23 / 300: loss 0.648072\n",
      "iteration 23 / 300: loss 0.619141\n",
      "iteration 23 / 300: loss 0.626783\n",
      "iteration 23 / 300: loss 0.651890\n",
      "iteration 23 / 300: loss 0.613178\n",
      "iteration 23 / 300: loss 0.628895\n",
      "iteration 23 / 300: loss 0.619076\n",
      "iteration 23 / 300: loss 0.631010\n",
      "iteration 23 / 300: loss 0.623076\n",
      "iteration 23 / 300: loss 0.613495\n",
      "iteration 23 / 300: loss 0.621772\n",
      "iteration 23 / 300: loss 0.628630\n",
      "iteration 23 / 300: loss 0.641099\n",
      "iteration 23 / 300: loss 0.611918\n",
      "iteration 23 / 300: loss 0.616781\n",
      "iteration 23 / 300: loss 0.616099\n",
      "iteration 23 / 300: loss 0.633333\n",
      "iteration 23 / 300: loss 0.611047\n",
      "iteration 23 / 300: loss 0.600310\n",
      "iteration 23 / 300: loss 0.596664\n",
      "iteration 23 / 300: loss 0.585756\n",
      "iteration 23 / 300: loss 0.621765\n",
      "iteration 23 / 300: loss 0.604885\n",
      "iteration 23 / 300: loss 0.610184\n",
      "iteration 23 / 300: loss 0.596593\n",
      "iteration 23 / 300: loss 0.616650\n",
      "iteration 23 / 300: loss 0.634336\n",
      "iteration 23 / 300: loss 0.635707\n",
      "iteration 23 / 300: loss 0.635566\n",
      "iteration 23 / 300: loss 0.609636\n",
      "iteration 23 / 300: loss 0.616988\n",
      "iteration 23 / 300: loss 0.621737\n",
      "iteration 23 / 300: loss 0.628796\n",
      "iteration 23 / 300: loss 0.619893\n",
      "iteration 23 / 300: loss 0.614014\n",
      "iteration 23 / 300: loss 0.613961\n",
      "iteration 23 / 300: loss 0.611566\n",
      "iteration 23 / 300: loss 0.628836\n",
      "iteration 23 / 300: loss 0.621784\n",
      "iteration 23 / 300: loss 0.639559\n",
      "iteration 23 / 300: loss 0.620738\n",
      "iteration 23 / 300: loss 0.625995\n",
      "iteration 23 / 300: loss 0.631294\n",
      "iteration 23 / 300: loss 0.618164\n",
      "iteration 23 / 300: loss 0.616637\n",
      "iteration 23 / 300: loss 0.614399\n",
      "iteration 23 / 300: loss 0.621949\n",
      "iteration 23 / 300: loss 0.629594\n",
      "iteration 23 / 300: loss 0.633726\n",
      "iteration 23 / 300: loss 0.610402\n",
      "iteration 23 / 300: loss 0.622585\n",
      "iteration 23 / 300: loss 0.628226\n",
      "iteration 23 / 300: loss 0.629057\n",
      "iteration 23 / 300: loss 0.629887\n",
      "iteration 23 / 300: loss 0.653243\n",
      "iteration 23 / 300: loss 0.611053\n",
      "iteration 23 / 300: loss 0.606944\n",
      "iteration 23 / 300: loss 0.651217\n",
      "iteration 23 / 300: loss 0.624421\n",
      "iteration 23 / 300: loss 0.627248\n",
      "iteration 23 / 300: loss 0.620352\n",
      "iteration 23 / 300: loss 0.624283\n",
      "iteration 23 / 300: loss 0.618556\n",
      "iteration 23 / 300: loss 0.613695\n",
      "iteration 23 / 300: loss 0.628498\n",
      "iteration 23 / 300: loss 0.638226\n",
      "iteration 23 / 300: loss 0.614574\n",
      "iteration 23 / 300: loss 0.616773\n",
      "iteration 23 / 300: loss 0.629088\n",
      "iteration 23 / 300: loss 0.622847\n",
      "iteration 23 / 300: loss 0.605012\n",
      "iteration 23 / 300: loss 0.619768\n",
      "iteration 24 / 300: loss 0.607709\n",
      "iteration 24 / 300: loss 0.613406\n",
      "iteration 24 / 300: loss 0.589441\n",
      "iteration 24 / 300: loss 0.612706\n",
      "iteration 24 / 300: loss 0.618997\n",
      "iteration 24 / 300: loss 0.618371\n",
      "iteration 24 / 300: loss 0.633541\n",
      "iteration 24 / 300: loss 0.614977\n",
      "iteration 24 / 300: loss 0.654948\n",
      "iteration 24 / 300: loss 0.610492\n",
      "iteration 24 / 300: loss 0.635459\n",
      "iteration 24 / 300: loss 0.608973\n",
      "iteration 24 / 300: loss 0.617548\n",
      "iteration 24 / 300: loss 0.594499\n",
      "iteration 24 / 300: loss 0.605686\n",
      "iteration 24 / 300: loss 0.633199\n",
      "iteration 24 / 300: loss 0.622413\n",
      "iteration 24 / 300: loss 0.605027\n",
      "iteration 24 / 300: loss 0.640545\n",
      "iteration 24 / 300: loss 0.612983\n",
      "iteration 24 / 300: loss 0.607835\n",
      "iteration 24 / 300: loss 0.612723\n",
      "iteration 24 / 300: loss 0.628422\n",
      "iteration 24 / 300: loss 0.617446\n",
      "iteration 24 / 300: loss 0.638361\n",
      "iteration 24 / 300: loss 0.633146\n",
      "iteration 24 / 300: loss 0.621380\n",
      "iteration 24 / 300: loss 0.616224\n",
      "iteration 24 / 300: loss 0.645685\n",
      "iteration 24 / 300: loss 0.617079\n",
      "iteration 24 / 300: loss 0.624367\n",
      "iteration 24 / 300: loss 0.649904\n",
      "iteration 24 / 300: loss 0.610737\n",
      "iteration 24 / 300: loss 0.626438\n",
      "iteration 24 / 300: loss 0.616504\n",
      "iteration 24 / 300: loss 0.628591\n",
      "iteration 24 / 300: loss 0.621052\n",
      "iteration 24 / 300: loss 0.611387\n",
      "iteration 24 / 300: loss 0.619377\n",
      "iteration 24 / 300: loss 0.626328\n",
      "iteration 24 / 300: loss 0.639305\n",
      "iteration 24 / 300: loss 0.609672\n",
      "iteration 24 / 300: loss 0.614825\n",
      "iteration 24 / 300: loss 0.613725\n",
      "iteration 24 / 300: loss 0.631407\n",
      "iteration 24 / 300: loss 0.609148\n",
      "iteration 24 / 300: loss 0.597928\n",
      "iteration 24 / 300: loss 0.594099\n",
      "iteration 24 / 300: loss 0.583243\n",
      "iteration 24 / 300: loss 0.619370\n",
      "iteration 24 / 300: loss 0.602519\n",
      "iteration 24 / 300: loss 0.608232\n",
      "iteration 24 / 300: loss 0.594488\n",
      "iteration 24 / 300: loss 0.614645\n",
      "iteration 24 / 300: loss 0.631717\n",
      "iteration 24 / 300: loss 0.633620\n",
      "iteration 24 / 300: loss 0.632666\n",
      "iteration 24 / 300: loss 0.607089\n",
      "iteration 24 / 300: loss 0.614195\n",
      "iteration 24 / 300: loss 0.619557\n",
      "iteration 24 / 300: loss 0.626500\n",
      "iteration 24 / 300: loss 0.618042\n",
      "iteration 24 / 300: loss 0.611406\n",
      "iteration 24 / 300: loss 0.612047\n",
      "iteration 24 / 300: loss 0.609122\n",
      "iteration 24 / 300: loss 0.626479\n",
      "iteration 24 / 300: loss 0.619813\n",
      "iteration 24 / 300: loss 0.637205\n",
      "iteration 24 / 300: loss 0.618872\n",
      "iteration 24 / 300: loss 0.624093\n",
      "iteration 24 / 300: loss 0.628754\n",
      "iteration 24 / 300: loss 0.616170\n",
      "iteration 24 / 300: loss 0.614571\n",
      "iteration 24 / 300: loss 0.611892\n",
      "iteration 24 / 300: loss 0.619750\n",
      "iteration 24 / 300: loss 0.627580\n",
      "iteration 24 / 300: loss 0.631376\n",
      "iteration 24 / 300: loss 0.607819\n",
      "iteration 24 / 300: loss 0.620432\n",
      "iteration 24 / 300: loss 0.626052\n",
      "iteration 24 / 300: loss 0.626970\n",
      "iteration 24 / 300: loss 0.628091\n",
      "iteration 24 / 300: loss 0.650587\n",
      "iteration 24 / 300: loss 0.609097\n",
      "iteration 24 / 300: loss 0.604840\n",
      "iteration 24 / 300: loss 0.648920\n",
      "iteration 24 / 300: loss 0.622454\n",
      "iteration 24 / 300: loss 0.625066\n",
      "iteration 24 / 300: loss 0.618293\n",
      "iteration 24 / 300: loss 0.622001\n",
      "iteration 24 / 300: loss 0.616555\n",
      "iteration 24 / 300: loss 0.611537\n",
      "iteration 24 / 300: loss 0.626419\n",
      "iteration 24 / 300: loss 0.636278\n",
      "iteration 24 / 300: loss 0.612672\n",
      "iteration 24 / 300: loss 0.615232\n",
      "iteration 24 / 300: loss 0.626891\n",
      "iteration 24 / 300: loss 0.620990\n",
      "iteration 24 / 300: loss 0.602985\n",
      "iteration 24 / 300: loss 0.617889\n",
      "iteration 25 / 300: loss 0.606103\n",
      "iteration 25 / 300: loss 0.611603\n",
      "iteration 25 / 300: loss 0.587354\n",
      "iteration 25 / 300: loss 0.610389\n",
      "iteration 25 / 300: loss 0.616490\n",
      "iteration 25 / 300: loss 0.616024\n",
      "iteration 25 / 300: loss 0.631027\n",
      "iteration 25 / 300: loss 0.612738\n",
      "iteration 25 / 300: loss 0.653027\n",
      "iteration 25 / 300: loss 0.607785\n",
      "iteration 25 / 300: loss 0.633357\n",
      "iteration 25 / 300: loss 0.606670\n",
      "iteration 25 / 300: loss 0.615504\n",
      "iteration 25 / 300: loss 0.592410\n",
      "iteration 25 / 300: loss 0.604031\n",
      "iteration 25 / 300: loss 0.630934\n",
      "iteration 25 / 300: loss 0.620507\n",
      "iteration 25 / 300: loss 0.602884\n",
      "iteration 25 / 300: loss 0.638266\n",
      "iteration 25 / 300: loss 0.611108\n",
      "iteration 25 / 300: loss 0.605607\n",
      "iteration 25 / 300: loss 0.611080\n",
      "iteration 25 / 300: loss 0.626273\n",
      "iteration 25 / 300: loss 0.615532\n",
      "iteration 25 / 300: loss 0.636126\n",
      "iteration 25 / 300: loss 0.631202\n",
      "iteration 25 / 300: loss 0.619095\n",
      "iteration 25 / 300: loss 0.614285\n",
      "iteration 25 / 300: loss 0.643437\n",
      "iteration 25 / 300: loss 0.615400\n",
      "iteration 25 / 300: loss 0.622251\n",
      "iteration 25 / 300: loss 0.648042\n",
      "iteration 25 / 300: loss 0.608543\n",
      "iteration 25 / 300: loss 0.624189\n",
      "iteration 25 / 300: loss 0.614152\n",
      "iteration 25 / 300: loss 0.626633\n",
      "iteration 25 / 300: loss 0.619170\n",
      "iteration 25 / 300: loss 0.609699\n",
      "iteration 25 / 300: loss 0.617301\n",
      "iteration 25 / 300: loss 0.624113\n",
      "iteration 25 / 300: loss 0.637681\n",
      "iteration 25 / 300: loss 0.607650\n",
      "iteration 25 / 300: loss 0.613037\n",
      "iteration 25 / 300: loss 0.611323\n",
      "iteration 25 / 300: loss 0.629550\n",
      "iteration 25 / 300: loss 0.607421\n",
      "iteration 25 / 300: loss 0.595819\n",
      "iteration 25 / 300: loss 0.591691\n",
      "iteration 25 / 300: loss 0.581031\n",
      "iteration 25 / 300: loss 0.617356\n",
      "iteration 25 / 300: loss 0.600457\n",
      "iteration 25 / 300: loss 0.606479\n",
      "iteration 25 / 300: loss 0.592638\n",
      "iteration 25 / 300: loss 0.612826\n",
      "iteration 25 / 300: loss 0.629422\n",
      "iteration 25 / 300: loss 0.631767\n",
      "iteration 25 / 300: loss 0.629975\n",
      "iteration 25 / 300: loss 0.604856\n",
      "iteration 25 / 300: loss 0.611621\n",
      "iteration 25 / 300: loss 0.617428\n",
      "iteration 25 / 300: loss 0.624334\n",
      "iteration 25 / 300: loss 0.616465\n",
      "iteration 25 / 300: loss 0.609029\n",
      "iteration 25 / 300: loss 0.610387\n",
      "iteration 25 / 300: loss 0.607028\n",
      "iteration 25 / 300: loss 0.624275\n",
      "iteration 25 / 300: loss 0.618029\n",
      "iteration 25 / 300: loss 0.635147\n",
      "iteration 25 / 300: loss 0.617234\n",
      "iteration 25 / 300: loss 0.622524\n",
      "iteration 25 / 300: loss 0.626441\n",
      "iteration 25 / 300: loss 0.614332\n",
      "iteration 25 / 300: loss 0.612756\n",
      "iteration 25 / 300: loss 0.609648\n",
      "iteration 25 / 300: loss 0.617860\n",
      "iteration 25 / 300: loss 0.625577\n",
      "iteration 25 / 300: loss 0.629339\n",
      "iteration 25 / 300: loss 0.605437\n",
      "iteration 25 / 300: loss 0.618357\n",
      "iteration 25 / 300: loss 0.624060\n",
      "iteration 25 / 300: loss 0.624956\n",
      "iteration 25 / 300: loss 0.626323\n",
      "iteration 25 / 300: loss 0.648034\n",
      "iteration 25 / 300: loss 0.607310\n",
      "iteration 25 / 300: loss 0.602918\n",
      "iteration 25 / 300: loss 0.646839\n",
      "iteration 25 / 300: loss 0.620687\n",
      "iteration 25 / 300: loss 0.623150\n",
      "iteration 25 / 300: loss 0.616368\n",
      "iteration 25 / 300: loss 0.620012\n",
      "iteration 25 / 300: loss 0.614693\n",
      "iteration 25 / 300: loss 0.609610\n",
      "iteration 25 / 300: loss 0.624529\n",
      "iteration 25 / 300: loss 0.634377\n",
      "iteration 25 / 300: loss 0.610973\n",
      "iteration 25 / 300: loss 0.613831\n",
      "iteration 25 / 300: loss 0.624777\n",
      "iteration 25 / 300: loss 0.619405\n",
      "iteration 25 / 300: loss 0.601015\n",
      "iteration 25 / 300: loss 0.616370\n",
      "iteration 26 / 300: loss 0.604744\n",
      "iteration 26 / 300: loss 0.609934\n",
      "iteration 26 / 300: loss 0.585371\n",
      "iteration 26 / 300: loss 0.608464\n",
      "iteration 26 / 300: loss 0.614261\n",
      "iteration 26 / 300: loss 0.614036\n",
      "iteration 26 / 300: loss 0.628736\n",
      "iteration 26 / 300: loss 0.610731\n",
      "iteration 26 / 300: loss 0.651267\n",
      "iteration 26 / 300: loss 0.605221\n",
      "iteration 26 / 300: loss 0.631368\n",
      "iteration 26 / 300: loss 0.604763\n",
      "iteration 26 / 300: loss 0.613484\n",
      "iteration 26 / 300: loss 0.590556\n",
      "iteration 26 / 300: loss 0.602428\n",
      "iteration 26 / 300: loss 0.628760\n",
      "iteration 26 / 300: loss 0.619089\n",
      "iteration 26 / 300: loss 0.601044\n",
      "iteration 26 / 300: loss 0.636139\n",
      "iteration 26 / 300: loss 0.609382\n",
      "iteration 26 / 300: loss 0.603921\n",
      "iteration 26 / 300: loss 0.609784\n",
      "iteration 26 / 300: loss 0.624377\n",
      "iteration 26 / 300: loss 0.613746\n",
      "iteration 26 / 300: loss 0.634214\n",
      "iteration 26 / 300: loss 0.629289\n",
      "iteration 26 / 300: loss 0.617082\n",
      "iteration 26 / 300: loss 0.612310\n",
      "iteration 26 / 300: loss 0.641401\n",
      "iteration 26 / 300: loss 0.613733\n",
      "iteration 26 / 300: loss 0.620422\n",
      "iteration 26 / 300: loss 0.646423\n",
      "iteration 26 / 300: loss 0.606585\n",
      "iteration 26 / 300: loss 0.622270\n",
      "iteration 26 / 300: loss 0.611906\n",
      "iteration 26 / 300: loss 0.624915\n",
      "iteration 26 / 300: loss 0.617353\n",
      "iteration 26 / 300: loss 0.608137\n",
      "iteration 26 / 300: loss 0.615412\n",
      "iteration 26 / 300: loss 0.622258\n",
      "iteration 26 / 300: loss 0.636173\n",
      "iteration 26 / 300: loss 0.605811\n",
      "iteration 26 / 300: loss 0.611406\n",
      "iteration 26 / 300: loss 0.609102\n",
      "iteration 26 / 300: loss 0.627973\n",
      "iteration 26 / 300: loss 0.605828\n",
      "iteration 26 / 300: loss 0.593896\n",
      "iteration 26 / 300: loss 0.589336\n",
      "iteration 26 / 300: loss 0.579248\n",
      "iteration 26 / 300: loss 0.615490\n",
      "iteration 26 / 300: loss 0.598487\n",
      "iteration 26 / 300: loss 0.604869\n",
      "iteration 26 / 300: loss 0.590930\n",
      "iteration 26 / 300: loss 0.611202\n",
      "iteration 26 / 300: loss 0.627411\n",
      "iteration 26 / 300: loss 0.630083\n",
      "iteration 26 / 300: loss 0.627684\n",
      "iteration 26 / 300: loss 0.602866\n",
      "iteration 26 / 300: loss 0.609344\n",
      "iteration 26 / 300: loss 0.615347\n",
      "iteration 26 / 300: loss 0.622301\n",
      "iteration 26 / 300: loss 0.615165\n",
      "iteration 26 / 300: loss 0.606942\n",
      "iteration 26 / 300: loss 0.609050\n",
      "iteration 26 / 300: loss 0.605106\n",
      "iteration 26 / 300: loss 0.622306\n",
      "iteration 26 / 300: loss 0.616439\n",
      "iteration 26 / 300: loss 0.633431\n",
      "iteration 26 / 300: loss 0.615780\n",
      "iteration 26 / 300: loss 0.621009\n",
      "iteration 26 / 300: loss 0.624379\n",
      "iteration 26 / 300: loss 0.612671\n",
      "iteration 26 / 300: loss 0.611123\n",
      "iteration 26 / 300: loss 0.607760\n",
      "iteration 26 / 300: loss 0.616198\n",
      "iteration 26 / 300: loss 0.623651\n",
      "iteration 26 / 300: loss 0.627641\n",
      "iteration 26 / 300: loss 0.603516\n",
      "iteration 26 / 300: loss 0.616395\n",
      "iteration 26 / 300: loss 0.622218\n",
      "iteration 26 / 300: loss 0.623075\n",
      "iteration 26 / 300: loss 0.624609\n",
      "iteration 26 / 300: loss 0.645618\n",
      "iteration 26 / 300: loss 0.605606\n",
      "iteration 26 / 300: loss 0.601145\n",
      "iteration 26 / 300: loss 0.644918\n",
      "iteration 26 / 300: loss 0.619170\n",
      "iteration 26 / 300: loss 0.621450\n",
      "iteration 26 / 300: loss 0.614669\n",
      "iteration 26 / 300: loss 0.618299\n",
      "iteration 26 / 300: loss 0.612994\n",
      "iteration 26 / 300: loss 0.607898\n",
      "iteration 26 / 300: loss 0.622792\n",
      "iteration 26 / 300: loss 0.632505\n",
      "iteration 26 / 300: loss 0.609459\n",
      "iteration 26 / 300: loss 0.612557\n",
      "iteration 26 / 300: loss 0.622659\n",
      "iteration 26 / 300: loss 0.617942\n",
      "iteration 26 / 300: loss 0.599153\n",
      "iteration 26 / 300: loss 0.615037\n",
      "iteration 27 / 300: loss 0.603432\n",
      "iteration 27 / 300: loss 0.608319\n",
      "iteration 27 / 300: loss 0.583575\n",
      "iteration 27 / 300: loss 0.606762\n",
      "iteration 27 / 300: loss 0.612235\n",
      "iteration 27 / 300: loss 0.612325\n",
      "iteration 27 / 300: loss 0.626804\n",
      "iteration 27 / 300: loss 0.609069\n",
      "iteration 27 / 300: loss 0.649689\n",
      "iteration 27 / 300: loss 0.602890\n",
      "iteration 27 / 300: loss 0.629376\n",
      "iteration 27 / 300: loss 0.603213\n",
      "iteration 27 / 300: loss 0.611576\n",
      "iteration 27 / 300: loss 0.588816\n",
      "iteration 27 / 300: loss 0.600928\n",
      "iteration 27 / 300: loss 0.626763\n",
      "iteration 27 / 300: loss 0.617907\n",
      "iteration 27 / 300: loss 0.599519\n",
      "iteration 27 / 300: loss 0.634328\n",
      "iteration 27 / 300: loss 0.607566\n",
      "iteration 27 / 300: loss 0.602302\n",
      "iteration 27 / 300: loss 0.608665\n",
      "iteration 27 / 300: loss 0.622561\n",
      "iteration 27 / 300: loss 0.612203\n",
      "iteration 27 / 300: loss 0.632537\n",
      "iteration 27 / 300: loss 0.627587\n",
      "iteration 27 / 300: loss 0.615356\n",
      "iteration 27 / 300: loss 0.610541\n",
      "iteration 27 / 300: loss 0.639579\n",
      "iteration 27 / 300: loss 0.612259\n",
      "iteration 27 / 300: loss 0.618702\n",
      "iteration 27 / 300: loss 0.644941\n",
      "iteration 27 / 300: loss 0.604880\n",
      "iteration 27 / 300: loss 0.620536\n",
      "iteration 27 / 300: loss 0.609922\n",
      "iteration 27 / 300: loss 0.623261\n",
      "iteration 27 / 300: loss 0.615538\n",
      "iteration 27 / 300: loss 0.606580\n",
      "iteration 27 / 300: loss 0.613717\n",
      "iteration 27 / 300: loss 0.620693\n",
      "iteration 27 / 300: loss 0.634746\n",
      "iteration 27 / 300: loss 0.604150\n",
      "iteration 27 / 300: loss 0.609913\n",
      "iteration 27 / 300: loss 0.607100\n",
      "iteration 27 / 300: loss 0.626610\n",
      "iteration 27 / 300: loss 0.604275\n",
      "iteration 27 / 300: loss 0.592227\n",
      "iteration 27 / 300: loss 0.587071\n",
      "iteration 27 / 300: loss 0.577746\n",
      "iteration 27 / 300: loss 0.613825\n",
      "iteration 27 / 300: loss 0.596704\n",
      "iteration 27 / 300: loss 0.603378\n",
      "iteration 27 / 300: loss 0.589352\n",
      "iteration 27 / 300: loss 0.609840\n",
      "iteration 27 / 300: loss 0.625613\n",
      "iteration 27 / 300: loss 0.628530\n",
      "iteration 27 / 300: loss 0.625759\n",
      "iteration 27 / 300: loss 0.601095\n",
      "iteration 27 / 300: loss 0.607381\n",
      "iteration 27 / 300: loss 0.613424\n",
      "iteration 27 / 300: loss 0.620358\n",
      "iteration 27 / 300: loss 0.613876\n",
      "iteration 27 / 300: loss 0.605125\n",
      "iteration 27 / 300: loss 0.607869\n",
      "iteration 27 / 300: loss 0.603308\n",
      "iteration 27 / 300: loss 0.620638\n",
      "iteration 27 / 300: loss 0.615033\n",
      "iteration 27 / 300: loss 0.631935\n",
      "iteration 27 / 300: loss 0.614553\n",
      "iteration 27 / 300: loss 0.619600\n",
      "iteration 27 / 300: loss 0.622559\n",
      "iteration 27 / 300: loss 0.611211\n",
      "iteration 27 / 300: loss 0.609546\n",
      "iteration 27 / 300: loss 0.606063\n",
      "iteration 27 / 300: loss 0.614773\n",
      "iteration 27 / 300: loss 0.621898\n",
      "iteration 27 / 300: loss 0.626185\n",
      "iteration 27 / 300: loss 0.601907\n",
      "iteration 27 / 300: loss 0.614626\n",
      "iteration 27 / 300: loss 0.620485\n",
      "iteration 27 / 300: loss 0.621387\n",
      "iteration 27 / 300: loss 0.623001\n",
      "iteration 27 / 300: loss 0.643380\n",
      "iteration 27 / 300: loss 0.604013\n",
      "iteration 27 / 300: loss 0.599430\n",
      "iteration 27 / 300: loss 0.643146\n",
      "iteration 27 / 300: loss 0.617832\n",
      "iteration 27 / 300: loss 0.619963\n",
      "iteration 27 / 300: loss 0.613194\n",
      "iteration 27 / 300: loss 0.616765\n",
      "iteration 27 / 300: loss 0.611440\n",
      "iteration 27 / 300: loss 0.606420\n",
      "iteration 27 / 300: loss 0.621150\n",
      "iteration 27 / 300: loss 0.630759\n",
      "iteration 27 / 300: loss 0.608132\n",
      "iteration 27 / 300: loss 0.611445\n",
      "iteration 27 / 300: loss 0.620703\n",
      "iteration 27 / 300: loss 0.616564\n",
      "iteration 27 / 300: loss 0.597420\n",
      "iteration 27 / 300: loss 0.613897\n",
      "iteration 28 / 300: loss 0.602176\n",
      "iteration 28 / 300: loss 0.606804\n",
      "iteration 28 / 300: loss 0.582049\n",
      "iteration 28 / 300: loss 0.605228\n",
      "iteration 28 / 300: loss 0.610398\n",
      "iteration 28 / 300: loss 0.610808\n",
      "iteration 28 / 300: loss 0.625274\n",
      "iteration 28 / 300: loss 0.607613\n",
      "iteration 28 / 300: loss 0.648252\n",
      "iteration 28 / 300: loss 0.600831\n",
      "iteration 28 / 300: loss 0.627483\n",
      "iteration 28 / 300: loss 0.601876\n",
      "iteration 28 / 300: loss 0.609829\n",
      "iteration 28 / 300: loss 0.587230\n",
      "iteration 28 / 300: loss 0.599514\n",
      "iteration 28 / 300: loss 0.625077\n",
      "iteration 28 / 300: loss 0.616720\n",
      "iteration 28 / 300: loss 0.598169\n",
      "iteration 28 / 300: loss 0.632817\n",
      "iteration 28 / 300: loss 0.606010\n",
      "iteration 28 / 300: loss 0.600744\n",
      "iteration 28 / 300: loss 0.607573\n",
      "iteration 28 / 300: loss 0.620950\n",
      "iteration 28 / 300: loss 0.610882\n",
      "iteration 28 / 300: loss 0.631001\n",
      "iteration 28 / 300: loss 0.625949\n",
      "iteration 28 / 300: loss 0.613859\n",
      "iteration 28 / 300: loss 0.608876\n",
      "iteration 28 / 300: loss 0.637926\n",
      "iteration 28 / 300: loss 0.610961\n",
      "iteration 28 / 300: loss 0.617083\n",
      "iteration 28 / 300: loss 0.643626\n",
      "iteration 28 / 300: loss 0.603404\n",
      "iteration 28 / 300: loss 0.618969\n",
      "iteration 28 / 300: loss 0.608185\n",
      "iteration 28 / 300: loss 0.621671\n",
      "iteration 28 / 300: loss 0.613820\n",
      "iteration 28 / 300: loss 0.605258\n",
      "iteration 28 / 300: loss 0.612220\n",
      "iteration 28 / 300: loss 0.619310\n",
      "iteration 28 / 300: loss 0.633495\n",
      "iteration 28 / 300: loss 0.602741\n",
      "iteration 28 / 300: loss 0.608583\n",
      "iteration 28 / 300: loss 0.605333\n",
      "iteration 28 / 300: loss 0.625375\n",
      "iteration 28 / 300: loss 0.602921\n",
      "iteration 28 / 300: loss 0.590865\n",
      "iteration 28 / 300: loss 0.585085\n",
      "iteration 28 / 300: loss 0.576294\n",
      "iteration 28 / 300: loss 0.612356\n",
      "iteration 28 / 300: loss 0.595101\n",
      "iteration 28 / 300: loss 0.602075\n",
      "iteration 28 / 300: loss 0.587956\n",
      "iteration 28 / 300: loss 0.608705\n",
      "iteration 28 / 300: loss 0.623965\n",
      "iteration 28 / 300: loss 0.627102\n",
      "iteration 28 / 300: loss 0.624146\n",
      "iteration 28 / 300: loss 0.599545\n",
      "iteration 28 / 300: loss 0.605701\n",
      "iteration 28 / 300: loss 0.611754\n",
      "iteration 28 / 300: loss 0.618550\n",
      "iteration 28 / 300: loss 0.612622\n",
      "iteration 28 / 300: loss 0.603513\n",
      "iteration 28 / 300: loss 0.606794\n",
      "iteration 28 / 300: loss 0.601657\n",
      "iteration 28 / 300: loss 0.619123\n",
      "iteration 28 / 300: loss 0.613802\n",
      "iteration 28 / 300: loss 0.630596\n",
      "iteration 28 / 300: loss 0.613444\n",
      "iteration 28 / 300: loss 0.618245\n",
      "iteration 28 / 300: loss 0.620935\n",
      "iteration 28 / 300: loss 0.609921\n",
      "iteration 28 / 300: loss 0.608083\n",
      "iteration 28 / 300: loss 0.604588\n",
      "iteration 28 / 300: loss 0.613503\n",
      "iteration 28 / 300: loss 0.620376\n",
      "iteration 28 / 300: loss 0.624883\n",
      "iteration 28 / 300: loss 0.600569\n",
      "iteration 28 / 300: loss 0.613063\n",
      "iteration 28 / 300: loss 0.618844\n",
      "iteration 28 / 300: loss 0.619996\n",
      "iteration 28 / 300: loss 0.621550\n",
      "iteration 28 / 300: loss 0.641393\n",
      "iteration 28 / 300: loss 0.602475\n",
      "iteration 28 / 300: loss 0.597751\n",
      "iteration 28 / 300: loss 0.641530\n",
      "iteration 28 / 300: loss 0.616720\n",
      "iteration 28 / 300: loss 0.618749\n",
      "iteration 28 / 300: loss 0.611785\n",
      "iteration 28 / 300: loss 0.615350\n",
      "iteration 28 / 300: loss 0.609963\n",
      "iteration 28 / 300: loss 0.605132\n",
      "iteration 28 / 300: loss 0.619564\n",
      "iteration 28 / 300: loss 0.629161\n",
      "iteration 28 / 300: loss 0.606897\n",
      "iteration 28 / 300: loss 0.610502\n",
      "iteration 28 / 300: loss 0.619031\n",
      "iteration 28 / 300: loss 0.615318\n",
      "iteration 28 / 300: loss 0.595851\n",
      "iteration 28 / 300: loss 0.612927\n",
      "iteration 29 / 300: loss 0.600919\n",
      "iteration 29 / 300: loss 0.605498\n",
      "iteration 29 / 300: loss 0.580755\n",
      "iteration 29 / 300: loss 0.603845\n",
      "iteration 29 / 300: loss 0.608783\n",
      "iteration 29 / 300: loss 0.609440\n",
      "iteration 29 / 300: loss 0.623929\n",
      "iteration 29 / 300: loss 0.606318\n",
      "iteration 29 / 300: loss 0.646871\n",
      "iteration 29 / 300: loss 0.599052\n",
      "iteration 29 / 300: loss 0.625803\n",
      "iteration 29 / 300: loss 0.600687\n",
      "iteration 29 / 300: loss 0.608247\n",
      "iteration 29 / 300: loss 0.585793\n",
      "iteration 29 / 300: loss 0.598128\n",
      "iteration 29 / 300: loss 0.623624\n",
      "iteration 29 / 300: loss 0.615476\n",
      "iteration 29 / 300: loss 0.596888\n",
      "iteration 29 / 300: loss 0.631518\n",
      "iteration 29 / 300: loss 0.604721\n",
      "iteration 29 / 300: loss 0.599298\n",
      "iteration 29 / 300: loss 0.606482\n",
      "iteration 29 / 300: loss 0.619636\n",
      "iteration 29 / 300: loss 0.609764\n",
      "iteration 29 / 300: loss 0.629667\n",
      "iteration 29 / 300: loss 0.624388\n",
      "iteration 29 / 300: loss 0.612571\n",
      "iteration 29 / 300: loss 0.607295\n",
      "iteration 29 / 300: loss 0.636413\n",
      "iteration 29 / 300: loss 0.609828\n",
      "iteration 29 / 300: loss 0.615668\n",
      "iteration 29 / 300: loss 0.642475\n",
      "iteration 29 / 300: loss 0.602083\n",
      "iteration 29 / 300: loss 0.617571\n",
      "iteration 29 / 300: loss 0.606618\n",
      "iteration 29 / 300: loss 0.620154\n",
      "iteration 29 / 300: loss 0.612334\n",
      "iteration 29 / 300: loss 0.604135\n",
      "iteration 29 / 300: loss 0.611062\n",
      "iteration 29 / 300: loss 0.618107\n",
      "iteration 29 / 300: loss 0.632450\n",
      "iteration 29 / 300: loss 0.601533\n",
      "iteration 29 / 300: loss 0.607409\n",
      "iteration 29 / 300: loss 0.603773\n",
      "iteration 29 / 300: loss 0.624183\n",
      "iteration 29 / 300: loss 0.601739\n",
      "iteration 29 / 300: loss 0.589757\n",
      "iteration 29 / 300: loss 0.583400\n",
      "iteration 29 / 300: loss 0.575015\n",
      "iteration 29 / 300: loss 0.610969\n",
      "iteration 29 / 300: loss 0.593695\n",
      "iteration 29 / 300: loss 0.600938\n",
      "iteration 29 / 300: loss 0.586752\n",
      "iteration 29 / 300: loss 0.607788\n",
      "iteration 29 / 300: loss 0.622513\n",
      "iteration 29 / 300: loss 0.625752\n",
      "iteration 29 / 300: loss 0.622779\n",
      "iteration 29 / 300: loss 0.598164\n",
      "iteration 29 / 300: loss 0.604255\n",
      "iteration 29 / 300: loss 0.610352\n",
      "iteration 29 / 300: loss 0.616905\n",
      "iteration 29 / 300: loss 0.611456\n",
      "iteration 29 / 300: loss 0.602067\n",
      "iteration 29 / 300: loss 0.605809\n",
      "iteration 29 / 300: loss 0.600190\n",
      "iteration 29 / 300: loss 0.617681\n",
      "iteration 29 / 300: loss 0.612732\n",
      "iteration 29 / 300: loss 0.629400\n",
      "iteration 29 / 300: loss 0.612411\n",
      "iteration 29 / 300: loss 0.616887\n",
      "iteration 29 / 300: loss 0.619464\n",
      "iteration 29 / 300: loss 0.608811\n",
      "iteration 29 / 300: loss 0.606773\n",
      "iteration 29 / 300: loss 0.603336\n",
      "iteration 29 / 300: loss 0.612354\n",
      "iteration 29 / 300: loss 0.619130\n",
      "iteration 29 / 300: loss 0.623810\n",
      "iteration 29 / 300: loss 0.599470\n",
      "iteration 29 / 300: loss 0.611669\n",
      "iteration 29 / 300: loss 0.617312\n",
      "iteration 29 / 300: loss 0.618879\n",
      "iteration 29 / 300: loss 0.620092\n",
      "iteration 29 / 300: loss 0.639674\n",
      "iteration 29 / 300: loss 0.601147\n",
      "iteration 29 / 300: loss 0.596175\n",
      "iteration 29 / 300: loss 0.640142\n",
      "iteration 29 / 300: loss 0.615729\n",
      "iteration 29 / 300: loss 0.617606\n",
      "iteration 29 / 300: loss 0.610505\n",
      "iteration 29 / 300: loss 0.613980\n",
      "iteration 29 / 300: loss 0.608564\n",
      "iteration 29 / 300: loss 0.604024\n",
      "iteration 29 / 300: loss 0.618076\n",
      "iteration 29 / 300: loss 0.627751\n",
      "iteration 29 / 300: loss 0.605762\n",
      "iteration 29 / 300: loss 0.609726\n",
      "iteration 29 / 300: loss 0.617639\n",
      "iteration 29 / 300: loss 0.614227\n",
      "iteration 29 / 300: loss 0.594402\n",
      "iteration 29 / 300: loss 0.612053\n",
      "iteration 30 / 300: loss 0.599758\n",
      "iteration 30 / 300: loss 0.604299\n",
      "iteration 30 / 300: loss 0.579628\n",
      "iteration 30 / 300: loss 0.602566\n",
      "iteration 30 / 300: loss 0.607304\n",
      "iteration 30 / 300: loss 0.608211\n",
      "iteration 30 / 300: loss 0.622714\n",
      "iteration 30 / 300: loss 0.605164\n",
      "iteration 30 / 300: loss 0.645529\n",
      "iteration 30 / 300: loss 0.597512\n",
      "iteration 30 / 300: loss 0.624393\n",
      "iteration 30 / 300: loss 0.599691\n",
      "iteration 30 / 300: loss 0.606839\n",
      "iteration 30 / 300: loss 0.584521\n",
      "iteration 30 / 300: loss 0.596799\n",
      "iteration 30 / 300: loss 0.622329\n",
      "iteration 30 / 300: loss 0.614251\n",
      "iteration 30 / 300: loss 0.595737\n",
      "iteration 30 / 300: loss 0.630382\n",
      "iteration 30 / 300: loss 0.603678\n",
      "iteration 30 / 300: loss 0.598051\n",
      "iteration 30 / 300: loss 0.605472\n",
      "iteration 30 / 300: loss 0.618517\n",
      "iteration 30 / 300: loss 0.608800\n",
      "iteration 30 / 300: loss 0.628478\n",
      "iteration 30 / 300: loss 0.622972\n",
      "iteration 30 / 300: loss 0.611485\n",
      "iteration 30 / 300: loss 0.605860\n",
      "iteration 30 / 300: loss 0.635017\n",
      "iteration 30 / 300: loss 0.608839\n",
      "iteration 30 / 300: loss 0.614499\n",
      "iteration 30 / 300: loss 0.641494\n",
      "iteration 30 / 300: loss 0.600932\n",
      "iteration 30 / 300: loss 0.616399\n",
      "iteration 30 / 300: loss 0.605172\n",
      "iteration 30 / 300: loss 0.618685\n",
      "iteration 30 / 300: loss 0.611011\n",
      "iteration 30 / 300: loss 0.603062\n",
      "iteration 30 / 300: loss 0.610132\n",
      "iteration 30 / 300: loss 0.617022\n",
      "iteration 30 / 300: loss 0.631544\n",
      "iteration 30 / 300: loss 0.600439\n",
      "iteration 30 / 300: loss 0.606456\n",
      "iteration 30 / 300: loss 0.602396\n",
      "iteration 30 / 300: loss 0.623019\n",
      "iteration 30 / 300: loss 0.600650\n",
      "iteration 30 / 300: loss 0.588930\n",
      "iteration 30 / 300: loss 0.581923\n",
      "iteration 30 / 300: loss 0.573901\n",
      "iteration 30 / 300: loss 0.609639\n",
      "iteration 30 / 300: loss 0.592456\n",
      "iteration 30 / 300: loss 0.599913\n",
      "iteration 30 / 300: loss 0.585666\n",
      "iteration 30 / 300: loss 0.606995\n",
      "iteration 30 / 300: loss 0.621275\n",
      "iteration 30 / 300: loss 0.624494\n",
      "iteration 30 / 300: loss 0.621574\n",
      "iteration 30 / 300: loss 0.596947\n",
      "iteration 30 / 300: loss 0.602990\n",
      "iteration 30 / 300: loss 0.609186\n",
      "iteration 30 / 300: loss 0.615388\n",
      "iteration 30 / 300: loss 0.610389\n",
      "iteration 30 / 300: loss 0.600799\n",
      "iteration 30 / 300: loss 0.604866\n",
      "iteration 30 / 300: loss 0.598865\n",
      "iteration 30 / 300: loss 0.616331\n",
      "iteration 30 / 300: loss 0.611792\n",
      "iteration 30 / 300: loss 0.628317\n",
      "iteration 30 / 300: loss 0.611450\n",
      "iteration 30 / 300: loss 0.615576\n",
      "iteration 30 / 300: loss 0.618070\n",
      "iteration 30 / 300: loss 0.607853\n",
      "iteration 30 / 300: loss 0.605667\n",
      "iteration 30 / 300: loss 0.602211\n",
      "iteration 30 / 300: loss 0.611339\n",
      "iteration 30 / 300: loss 0.618112\n",
      "iteration 30 / 300: loss 0.622898\n",
      "iteration 30 / 300: loss 0.598564\n",
      "iteration 30 / 300: loss 0.610534\n",
      "iteration 30 / 300: loss 0.615878\n",
      "iteration 30 / 300: loss 0.617772\n",
      "iteration 30 / 300: loss 0.618684\n",
      "iteration 30 / 300: loss 0.638270\n",
      "iteration 30 / 300: loss 0.600006\n",
      "iteration 30 / 300: loss 0.594818\n",
      "iteration 30 / 300: loss 0.638993\n",
      "iteration 30 / 300: loss 0.614847\n",
      "iteration 30 / 300: loss 0.616506\n",
      "iteration 30 / 300: loss 0.609414\n",
      "iteration 30 / 300: loss 0.612717\n",
      "iteration 30 / 300: loss 0.607304\n",
      "iteration 30 / 300: loss 0.602975\n",
      "iteration 30 / 300: loss 0.616722\n",
      "iteration 30 / 300: loss 0.626507\n",
      "iteration 30 / 300: loss 0.604869\n",
      "iteration 30 / 300: loss 0.609023\n",
      "iteration 30 / 300: loss 0.616429\n",
      "iteration 30 / 300: loss 0.613269\n",
      "iteration 30 / 300: loss 0.593033\n",
      "iteration 30 / 300: loss 0.611265\n",
      "iteration 31 / 300: loss 0.598654\n",
      "iteration 31 / 300: loss 0.603042\n",
      "iteration 31 / 300: loss 0.578652\n",
      "iteration 31 / 300: loss 0.601411\n",
      "iteration 31 / 300: loss 0.606008\n",
      "iteration 31 / 300: loss 0.607102\n",
      "iteration 31 / 300: loss 0.621706\n",
      "iteration 31 / 300: loss 0.604118\n",
      "iteration 31 / 300: loss 0.644264\n",
      "iteration 31 / 300: loss 0.596132\n",
      "iteration 31 / 300: loss 0.623218\n",
      "iteration 31 / 300: loss 0.598845\n",
      "iteration 31 / 300: loss 0.605569\n",
      "iteration 31 / 300: loss 0.583370\n",
      "iteration 31 / 300: loss 0.595588\n",
      "iteration 31 / 300: loss 0.621180\n",
      "iteration 31 / 300: loss 0.613064\n",
      "iteration 31 / 300: loss 0.594684\n",
      "iteration 31 / 300: loss 0.629324\n",
      "iteration 31 / 300: loss 0.602839\n",
      "iteration 31 / 300: loss 0.597012\n",
      "iteration 31 / 300: loss 0.604558\n",
      "iteration 31 / 300: loss 0.617505\n",
      "iteration 31 / 300: loss 0.607981\n",
      "iteration 31 / 300: loss 0.627358\n",
      "iteration 31 / 300: loss 0.621639\n",
      "iteration 31 / 300: loss 0.610601\n",
      "iteration 31 / 300: loss 0.604574\n",
      "iteration 31 / 300: loss 0.633712\n",
      "iteration 31 / 300: loss 0.607945\n",
      "iteration 31 / 300: loss 0.613543\n",
      "iteration 31 / 300: loss 0.640709\n",
      "iteration 31 / 300: loss 0.599978\n",
      "iteration 31 / 300: loss 0.615520\n",
      "iteration 31 / 300: loss 0.603839\n",
      "iteration 31 / 300: loss 0.617258\n",
      "iteration 31 / 300: loss 0.609745\n",
      "iteration 31 / 300: loss 0.602070\n",
      "iteration 31 / 300: loss 0.609302\n",
      "iteration 31 / 300: loss 0.616020\n",
      "iteration 31 / 300: loss 0.630761\n",
      "iteration 31 / 300: loss 0.599432\n",
      "iteration 31 / 300: loss 0.605600\n",
      "iteration 31 / 300: loss 0.601213\n",
      "iteration 31 / 300: loss 0.621961\n",
      "iteration 31 / 300: loss 0.599687\n",
      "iteration 31 / 300: loss 0.588290\n",
      "iteration 31 / 300: loss 0.580648\n",
      "iteration 31 / 300: loss 0.572902\n",
      "iteration 31 / 300: loss 0.608387\n",
      "iteration 31 / 300: loss 0.591340\n",
      "iteration 31 / 300: loss 0.599018\n",
      "iteration 31 / 300: loss 0.584672\n",
      "iteration 31 / 300: loss 0.606275\n",
      "iteration 31 / 300: loss 0.620243\n",
      "iteration 31 / 300: loss 0.623344\n",
      "iteration 31 / 300: loss 0.620494\n",
      "iteration 31 / 300: loss 0.595873\n",
      "iteration 31 / 300: loss 0.601887\n",
      "iteration 31 / 300: loss 0.608188\n",
      "iteration 31 / 300: loss 0.613943\n",
      "iteration 31 / 300: loss 0.609382\n",
      "iteration 31 / 300: loss 0.599709\n",
      "iteration 31 / 300: loss 0.603986\n",
      "iteration 31 / 300: loss 0.597597\n",
      "iteration 31 / 300: loss 0.615068\n",
      "iteration 31 / 300: loss 0.610957\n",
      "iteration 31 / 300: loss 0.627334\n",
      "iteration 31 / 300: loss 0.610562\n",
      "iteration 31 / 300: loss 0.614355\n",
      "iteration 31 / 300: loss 0.616837\n",
      "iteration 31 / 300: loss 0.606958\n",
      "iteration 31 / 300: loss 0.604730\n",
      "iteration 31 / 300: loss 0.601195\n",
      "iteration 31 / 300: loss 0.610430\n",
      "iteration 31 / 300: loss 0.617308\n",
      "iteration 31 / 300: loss 0.622040\n",
      "iteration 31 / 300: loss 0.597879\n",
      "iteration 31 / 300: loss 0.609557\n",
      "iteration 31 / 300: loss 0.614644\n",
      "iteration 31 / 300: loss 0.616753\n",
      "iteration 31 / 300: loss 0.617402\n",
      "iteration 31 / 300: loss 0.636982\n",
      "iteration 31 / 300: loss 0.599000\n",
      "iteration 31 / 300: loss 0.593612\n",
      "iteration 31 / 300: loss 0.637968\n",
      "iteration 31 / 300: loss 0.614134\n",
      "iteration 31 / 300: loss 0.615510\n",
      "iteration 31 / 300: loss 0.608401\n",
      "iteration 31 / 300: loss 0.611552\n",
      "iteration 31 / 300: loss 0.606107\n",
      "iteration 31 / 300: loss 0.601979\n",
      "iteration 31 / 300: loss 0.615409\n",
      "iteration 31 / 300: loss 0.625389\n",
      "iteration 31 / 300: loss 0.604080\n",
      "iteration 31 / 300: loss 0.608404\n",
      "iteration 31 / 300: loss 0.615392\n",
      "iteration 31 / 300: loss 0.612428\n",
      "iteration 31 / 300: loss 0.591827\n",
      "iteration 31 / 300: loss 0.610555\n",
      "iteration 32 / 300: loss 0.597649\n",
      "iteration 32 / 300: loss 0.601765\n",
      "iteration 32 / 300: loss 0.577755\n",
      "iteration 32 / 300: loss 0.600400\n",
      "iteration 32 / 300: loss 0.604913\n",
      "iteration 32 / 300: loss 0.606108\n",
      "iteration 32 / 300: loss 0.620808\n",
      "iteration 32 / 300: loss 0.603165\n",
      "iteration 32 / 300: loss 0.643060\n",
      "iteration 32 / 300: loss 0.594892\n",
      "iteration 32 / 300: loss 0.622196\n",
      "iteration 32 / 300: loss 0.598105\n",
      "iteration 32 / 300: loss 0.604402\n",
      "iteration 32 / 300: loss 0.582336\n",
      "iteration 32 / 300: loss 0.594491\n",
      "iteration 32 / 300: loss 0.620183\n",
      "iteration 32 / 300: loss 0.611917\n",
      "iteration 32 / 300: loss 0.593732\n",
      "iteration 32 / 300: loss 0.628301\n",
      "iteration 32 / 300: loss 0.602133\n",
      "iteration 32 / 300: loss 0.596089\n",
      "iteration 32 / 300: loss 0.603659\n",
      "iteration 32 / 300: loss 0.616579\n",
      "iteration 32 / 300: loss 0.607200\n",
      "iteration 32 / 300: loss 0.626375\n",
      "iteration 32 / 300: loss 0.620387\n",
      "iteration 32 / 300: loss 0.609844\n",
      "iteration 32 / 300: loss 0.603381\n",
      "iteration 32 / 300: loss 0.632498\n",
      "iteration 32 / 300: loss 0.607112\n",
      "iteration 32 / 300: loss 0.612754\n",
      "iteration 32 / 300: loss 0.640050\n",
      "iteration 32 / 300: loss 0.599156\n",
      "iteration 32 / 300: loss 0.614901\n",
      "iteration 32 / 300: loss 0.602610\n",
      "iteration 32 / 300: loss 0.615924\n",
      "iteration 32 / 300: loss 0.608604\n",
      "iteration 32 / 300: loss 0.601211\n",
      "iteration 32 / 300: loss 0.608580\n",
      "iteration 32 / 300: loss 0.615083\n",
      "iteration 32 / 300: loss 0.630104\n",
      "iteration 32 / 300: loss 0.598506\n",
      "iteration 32 / 300: loss 0.604737\n",
      "iteration 32 / 300: loss 0.600194\n",
      "iteration 32 / 300: loss 0.621020\n",
      "iteration 32 / 300: loss 0.598827\n",
      "iteration 32 / 300: loss 0.587739\n",
      "iteration 32 / 300: loss 0.579561\n",
      "iteration 32 / 300: loss 0.571991\n",
      "iteration 32 / 300: loss 0.607222\n",
      "iteration 32 / 300: loss 0.590305\n",
      "iteration 32 / 300: loss 0.598203\n",
      "iteration 32 / 300: loss 0.583787\n",
      "iteration 32 / 300: loss 0.605579\n",
      "iteration 32 / 300: loss 0.619402\n",
      "iteration 32 / 300: loss 0.622283\n",
      "iteration 32 / 300: loss 0.619532\n",
      "iteration 32 / 300: loss 0.594909\n",
      "iteration 32 / 300: loss 0.600906\n",
      "iteration 32 / 300: loss 0.607305\n",
      "iteration 32 / 300: loss 0.612592\n",
      "iteration 32 / 300: loss 0.608450\n",
      "iteration 32 / 300: loss 0.598753\n",
      "iteration 32 / 300: loss 0.603169\n",
      "iteration 32 / 300: loss 0.596391\n",
      "iteration 32 / 300: loss 0.613892\n",
      "iteration 32 / 300: loss 0.610217\n",
      "iteration 32 / 300: loss 0.626457\n",
      "iteration 32 / 300: loss 0.609750\n",
      "iteration 32 / 300: loss 0.613210\n",
      "iteration 32 / 300: loss 0.615805\n",
      "iteration 32 / 300: loss 0.606104\n",
      "iteration 32 / 300: loss 0.603910\n",
      "iteration 32 / 300: loss 0.600307\n",
      "iteration 32 / 300: loss 0.609577\n",
      "iteration 32 / 300: loss 0.616660\n",
      "iteration 32 / 300: loss 0.621214\n",
      "iteration 32 / 300: loss 0.597355\n",
      "iteration 32 / 300: loss 0.608667\n",
      "iteration 32 / 300: loss 0.613637\n",
      "iteration 32 / 300: loss 0.615793\n",
      "iteration 32 / 300: loss 0.616239\n",
      "iteration 32 / 300: loss 0.635742\n",
      "iteration 32 / 300: loss 0.598087\n",
      "iteration 32 / 300: loss 0.592481\n",
      "iteration 32 / 300: loss 0.637018\n",
      "iteration 32 / 300: loss 0.613553\n",
      "iteration 32 / 300: loss 0.614598\n",
      "iteration 32 / 300: loss 0.607468\n",
      "iteration 32 / 300: loss 0.610470\n",
      "iteration 32 / 300: loss 0.605060\n",
      "iteration 32 / 300: loss 0.601081\n",
      "iteration 32 / 300: loss 0.614127\n",
      "iteration 32 / 300: loss 0.624341\n",
      "iteration 32 / 300: loss 0.603312\n",
      "iteration 32 / 300: loss 0.607827\n",
      "iteration 32 / 300: loss 0.614503\n",
      "iteration 32 / 300: loss 0.611682\n",
      "iteration 32 / 300: loss 0.590759\n",
      "iteration 32 / 300: loss 0.609957\n",
      "iteration 33 / 300: loss 0.596734\n",
      "iteration 33 / 300: loss 0.600504\n",
      "iteration 33 / 300: loss 0.576928\n",
      "iteration 33 / 300: loss 0.599545\n",
      "iteration 33 / 300: loss 0.603993\n",
      "iteration 33 / 300: loss 0.605227\n",
      "iteration 33 / 300: loss 0.619972\n",
      "iteration 33 / 300: loss 0.602260\n",
      "iteration 33 / 300: loss 0.641897\n",
      "iteration 33 / 300: loss 0.593767\n",
      "iteration 33 / 300: loss 0.621272\n",
      "iteration 33 / 300: loss 0.597414\n",
      "iteration 33 / 300: loss 0.603360\n",
      "iteration 33 / 300: loss 0.581418\n",
      "iteration 33 / 300: loss 0.593501\n",
      "iteration 33 / 300: loss 0.619298\n",
      "iteration 33 / 300: loss 0.610848\n",
      "iteration 33 / 300: loss 0.592885\n",
      "iteration 33 / 300: loss 0.627335\n",
      "iteration 33 / 300: loss 0.601498\n",
      "iteration 33 / 300: loss 0.595274\n",
      "iteration 33 / 300: loss 0.602753\n",
      "iteration 33 / 300: loss 0.615745\n",
      "iteration 33 / 300: loss 0.606394\n",
      "iteration 33 / 300: loss 0.625573\n",
      "iteration 33 / 300: loss 0.619276\n",
      "iteration 33 / 300: loss 0.609170\n",
      "iteration 33 / 300: loss 0.602252\n",
      "iteration 33 / 300: loss 0.631390\n",
      "iteration 33 / 300: loss 0.606344\n",
      "iteration 33 / 300: loss 0.612095\n",
      "iteration 33 / 300: loss 0.639463\n",
      "iteration 33 / 300: loss 0.598388\n",
      "iteration 33 / 300: loss 0.614441\n",
      "iteration 33 / 300: loss 0.601546\n",
      "iteration 33 / 300: loss 0.614762\n",
      "iteration 33 / 300: loss 0.607574\n",
      "iteration 33 / 300: loss 0.600445\n",
      "iteration 33 / 300: loss 0.607964\n",
      "iteration 33 / 300: loss 0.614258\n",
      "iteration 33 / 300: loss 0.629510\n",
      "iteration 33 / 300: loss 0.597721\n",
      "iteration 33 / 300: loss 0.603896\n",
      "iteration 33 / 300: loss 0.599306\n",
      "iteration 33 / 300: loss 0.620131\n",
      "iteration 33 / 300: loss 0.597977\n",
      "iteration 33 / 300: loss 0.587253\n",
      "iteration 33 / 300: loss 0.578637\n",
      "iteration 33 / 300: loss 0.571164\n",
      "iteration 33 / 300: loss 0.606160\n",
      "iteration 33 / 300: loss 0.589310\n",
      "iteration 33 / 300: loss 0.597436\n",
      "iteration 33 / 300: loss 0.582999\n",
      "iteration 33 / 300: loss 0.604904\n",
      "iteration 33 / 300: loss 0.618680\n",
      "iteration 33 / 300: loss 0.621307\n",
      "iteration 33 / 300: loss 0.618657\n",
      "iteration 33 / 300: loss 0.594022\n",
      "iteration 33 / 300: loss 0.599992\n",
      "iteration 33 / 300: loss 0.606524\n",
      "iteration 33 / 300: loss 0.611355\n",
      "iteration 33 / 300: loss 0.607598\n",
      "iteration 33 / 300: loss 0.597899\n",
      "iteration 33 / 300: loss 0.602393\n",
      "iteration 33 / 300: loss 0.595276\n",
      "iteration 33 / 300: loss 0.612803\n",
      "iteration 33 / 300: loss 0.609536\n",
      "iteration 33 / 300: loss 0.625662\n",
      "iteration 33 / 300: loss 0.609005\n",
      "iteration 33 / 300: loss 0.612156\n",
      "iteration 33 / 300: loss 0.614938\n",
      "iteration 33 / 300: loss 0.605280\n",
      "iteration 33 / 300: loss 0.603195\n",
      "iteration 33 / 300: loss 0.599543\n",
      "iteration 33 / 300: loss 0.608760\n",
      "iteration 33 / 300: loss 0.616113\n",
      "iteration 33 / 300: loss 0.620452\n",
      "iteration 33 / 300: loss 0.596916\n",
      "iteration 33 / 300: loss 0.607858\n",
      "iteration 33 / 300: loss 0.612789\n",
      "iteration 33 / 300: loss 0.614942\n",
      "iteration 33 / 300: loss 0.615209\n",
      "iteration 33 / 300: loss 0.634608\n",
      "iteration 33 / 300: loss 0.597250\n",
      "iteration 33 / 300: loss 0.591432\n",
      "iteration 33 / 300: loss 0.636162\n",
      "iteration 33 / 300: loss 0.613008\n",
      "iteration 33 / 300: loss 0.613764\n",
      "iteration 33 / 300: loss 0.606627\n",
      "iteration 33 / 300: loss 0.609501\n",
      "iteration 33 / 300: loss 0.604153\n",
      "iteration 33 / 300: loss 0.600276\n",
      "iteration 33 / 300: loss 0.612905\n",
      "iteration 33 / 300: loss 0.623343\n",
      "iteration 33 / 300: loss 0.602592\n",
      "iteration 33 / 300: loss 0.607293\n",
      "iteration 33 / 300: loss 0.613746\n",
      "iteration 33 / 300: loss 0.611019\n",
      "iteration 33 / 300: loss 0.589798\n",
      "iteration 33 / 300: loss 0.609489\n",
      "iteration 34 / 300: loss 0.595913\n",
      "iteration 34 / 300: loss 0.599294\n",
      "iteration 34 / 300: loss 0.576180\n",
      "iteration 34 / 300: loss 0.598816\n",
      "iteration 34 / 300: loss 0.603193\n",
      "iteration 34 / 300: loss 0.604493\n",
      "iteration 34 / 300: loss 0.619221\n",
      "iteration 34 / 300: loss 0.601407\n",
      "iteration 34 / 300: loss 0.640779\n",
      "iteration 34 / 300: loss 0.592763\n",
      "iteration 34 / 300: loss 0.620416\n",
      "iteration 34 / 300: loss 0.596741\n",
      "iteration 34 / 300: loss 0.602440\n",
      "iteration 34 / 300: loss 0.580613\n",
      "iteration 34 / 300: loss 0.592605\n",
      "iteration 34 / 300: loss 0.618511\n",
      "iteration 34 / 300: loss 0.609857\n",
      "iteration 34 / 300: loss 0.592130\n",
      "iteration 34 / 300: loss 0.626436\n",
      "iteration 34 / 300: loss 0.600894\n",
      "iteration 34 / 300: loss 0.594568\n",
      "iteration 34 / 300: loss 0.601900\n",
      "iteration 34 / 300: loss 0.614975\n",
      "iteration 34 / 300: loss 0.605624\n",
      "iteration 34 / 300: loss 0.624881\n",
      "iteration 34 / 300: loss 0.618309\n",
      "iteration 34 / 300: loss 0.608563\n",
      "iteration 34 / 300: loss 0.601198\n",
      "iteration 34 / 300: loss 0.630382\n",
      "iteration 34 / 300: loss 0.605624\n",
      "iteration 34 / 300: loss 0.611507\n",
      "iteration 34 / 300: loss 0.638961\n",
      "iteration 34 / 300: loss 0.597621\n",
      "iteration 34 / 300: loss 0.614086\n",
      "iteration 34 / 300: loss 0.600590\n",
      "iteration 34 / 300: loss 0.613691\n",
      "iteration 34 / 300: loss 0.606651\n",
      "iteration 34 / 300: loss 0.599743\n",
      "iteration 34 / 300: loss 0.607422\n",
      "iteration 34 / 300: loss 0.613562\n",
      "iteration 34 / 300: loss 0.628937\n",
      "iteration 34 / 300: loss 0.597115\n",
      "iteration 34 / 300: loss 0.603119\n",
      "iteration 34 / 300: loss 0.598511\n",
      "iteration 34 / 300: loss 0.619296\n",
      "iteration 34 / 300: loss 0.597159\n",
      "iteration 34 / 300: loss 0.586823\n",
      "iteration 34 / 300: loss 0.577818\n",
      "iteration 34 / 300: loss 0.570383\n",
      "iteration 34 / 300: loss 0.605198\n",
      "iteration 34 / 300: loss 0.588364\n",
      "iteration 34 / 300: loss 0.596724\n",
      "iteration 34 / 300: loss 0.582278\n",
      "iteration 34 / 300: loss 0.604321\n",
      "iteration 34 / 300: loss 0.618039\n",
      "iteration 34 / 300: loss 0.620413\n",
      "iteration 34 / 300: loss 0.617852\n",
      "iteration 34 / 300: loss 0.593207\n",
      "iteration 34 / 300: loss 0.599137\n",
      "iteration 34 / 300: loss 0.605800\n",
      "iteration 34 / 300: loss 0.610189\n",
      "iteration 34 / 300: loss 0.606800\n",
      "iteration 34 / 300: loss 0.597143\n",
      "iteration 34 / 300: loss 0.601630\n",
      "iteration 34 / 300: loss 0.594257\n",
      "iteration 34 / 300: loss 0.611796\n",
      "iteration 34 / 300: loss 0.608877\n",
      "iteration 34 / 300: loss 0.624913\n",
      "iteration 34 / 300: loss 0.608305\n",
      "iteration 34 / 300: loss 0.611197\n",
      "iteration 34 / 300: loss 0.614171\n",
      "iteration 34 / 300: loss 0.604472\n",
      "iteration 34 / 300: loss 0.602557\n",
      "iteration 34 / 300: loss 0.598870\n",
      "iteration 34 / 300: loss 0.607992\n",
      "iteration 34 / 300: loss 0.615629\n",
      "iteration 34 / 300: loss 0.619771\n",
      "iteration 34 / 300: loss 0.596529\n",
      "iteration 34 / 300: loss 0.607132\n",
      "iteration 34 / 300: loss 0.612050\n",
      "iteration 34 / 300: loss 0.614214\n",
      "iteration 34 / 300: loss 0.614312\n",
      "iteration 34 / 300: loss 0.633614\n",
      "iteration 34 / 300: loss 0.596490\n",
      "iteration 34 / 300: loss 0.590504\n",
      "iteration 34 / 300: loss 0.635408\n",
      "iteration 34 / 300: loss 0.612472\n",
      "iteration 34 / 300: loss 0.613028\n",
      "iteration 34 / 300: loss 0.605872\n",
      "iteration 34 / 300: loss 0.608639\n",
      "iteration 34 / 300: loss 0.603323\n",
      "iteration 34 / 300: loss 0.599543\n",
      "iteration 34 / 300: loss 0.611779\n",
      "iteration 34 / 300: loss 0.622405\n",
      "iteration 34 / 300: loss 0.601924\n",
      "iteration 34 / 300: loss 0.606807\n",
      "iteration 34 / 300: loss 0.613080\n",
      "iteration 34 / 300: loss 0.610438\n",
      "iteration 34 / 300: loss 0.588935\n",
      "iteration 34 / 300: loss 0.609120\n",
      "iteration 35 / 300: loss 0.595185\n",
      "iteration 35 / 300: loss 0.598156\n",
      "iteration 35 / 300: loss 0.575503\n",
      "iteration 35 / 300: loss 0.598187\n",
      "iteration 35 / 300: loss 0.602463\n",
      "iteration 35 / 300: loss 0.603897\n",
      "iteration 35 / 300: loss 0.618555\n",
      "iteration 35 / 300: loss 0.600639\n",
      "iteration 35 / 300: loss 0.639721\n",
      "iteration 35 / 300: loss 0.591845\n",
      "iteration 35 / 300: loss 0.619632\n",
      "iteration 35 / 300: loss 0.596069\n",
      "iteration 35 / 300: loss 0.601618\n",
      "iteration 35 / 300: loss 0.579896\n",
      "iteration 35 / 300: loss 0.591780\n",
      "iteration 35 / 300: loss 0.617782\n",
      "iteration 35 / 300: loss 0.608916\n",
      "iteration 35 / 300: loss 0.591477\n",
      "iteration 35 / 300: loss 0.625598\n",
      "iteration 35 / 300: loss 0.600318\n",
      "iteration 35 / 300: loss 0.593950\n",
      "iteration 35 / 300: loss 0.601125\n",
      "iteration 35 / 300: loss 0.614253\n",
      "iteration 35 / 300: loss 0.604915\n",
      "iteration 35 / 300: loss 0.624247\n",
      "iteration 35 / 300: loss 0.617470\n",
      "iteration 35 / 300: loss 0.608017\n",
      "iteration 35 / 300: loss 0.600229\n",
      "iteration 35 / 300: loss 0.629458\n",
      "iteration 35 / 300: loss 0.604925\n",
      "iteration 35 / 300: loss 0.610949\n",
      "iteration 35 / 300: loss 0.638548\n",
      "iteration 35 / 300: loss 0.596859\n",
      "iteration 35 / 300: loss 0.613799\n",
      "iteration 35 / 300: loss 0.599713\n",
      "iteration 35 / 300: loss 0.612684\n",
      "iteration 35 / 300: loss 0.605807\n",
      "iteration 35 / 300: loss 0.599104\n",
      "iteration 35 / 300: loss 0.606906\n",
      "iteration 35 / 300: loss 0.612969\n",
      "iteration 35 / 300: loss 0.628395\n",
      "iteration 35 / 300: loss 0.596659\n",
      "iteration 35 / 300: loss 0.602435\n",
      "iteration 35 / 300: loss 0.597796\n",
      "iteration 35 / 300: loss 0.618542\n",
      "iteration 35 / 300: loss 0.596421\n",
      "iteration 35 / 300: loss 0.586425\n",
      "iteration 35 / 300: loss 0.577036\n",
      "iteration 35 / 300: loss 0.569676\n",
      "iteration 35 / 300: loss 0.604315\n",
      "iteration 35 / 300: loss 0.587533\n",
      "iteration 35 / 300: loss 0.596056\n",
      "iteration 35 / 300: loss 0.581616\n",
      "iteration 35 / 300: loss 0.603820\n",
      "iteration 35 / 300: loss 0.617440\n",
      "iteration 35 / 300: loss 0.619552\n",
      "iteration 35 / 300: loss 0.617111\n",
      "iteration 35 / 300: loss 0.592470\n",
      "iteration 35 / 300: loss 0.598361\n",
      "iteration 35 / 300: loss 0.605126\n",
      "iteration 35 / 300: loss 0.609091\n",
      "iteration 35 / 300: loss 0.606031\n",
      "iteration 35 / 300: loss 0.596515\n",
      "iteration 35 / 300: loss 0.600858\n",
      "iteration 35 / 300: loss 0.593325\n",
      "iteration 35 / 300: loss 0.610863\n",
      "iteration 35 / 300: loss 0.608207\n",
      "iteration 35 / 300: loss 0.624177\n",
      "iteration 35 / 300: loss 0.607622\n",
      "iteration 35 / 300: loss 0.610315\n",
      "iteration 35 / 300: loss 0.613471\n",
      "iteration 35 / 300: loss 0.603689\n",
      "iteration 35 / 300: loss 0.601972\n",
      "iteration 35 / 300: loss 0.598260\n",
      "iteration 35 / 300: loss 0.607275\n",
      "iteration 35 / 300: loss 0.615166\n",
      "iteration 35 / 300: loss 0.619162\n",
      "iteration 35 / 300: loss 0.596167\n",
      "iteration 35 / 300: loss 0.606493\n",
      "iteration 35 / 300: loss 0.611377\n",
      "iteration 35 / 300: loss 0.613600\n",
      "iteration 35 / 300: loss 0.613527\n",
      "iteration 35 / 300: loss 0.632760\n",
      "iteration 35 / 300: loss 0.595804\n",
      "iteration 35 / 300: loss 0.589695\n",
      "iteration 35 / 300: loss 0.634751\n",
      "iteration 35 / 300: loss 0.611962\n",
      "iteration 35 / 300: loss 0.612368\n",
      "iteration 35 / 300: loss 0.605199\n",
      "iteration 35 / 300: loss 0.607849\n",
      "iteration 35 / 300: loss 0.602555\n",
      "iteration 35 / 300: loss 0.598864\n",
      "iteration 35 / 300: loss 0.610762\n",
      "iteration 35 / 300: loss 0.621548\n",
      "iteration 35 / 300: loss 0.601300\n",
      "iteration 35 / 300: loss 0.606363\n",
      "iteration 35 / 300: loss 0.612481\n",
      "iteration 35 / 300: loss 0.609916\n",
      "iteration 35 / 300: loss 0.588163\n",
      "iteration 35 / 300: loss 0.608795\n",
      "iteration 36 / 300: loss 0.594527\n",
      "iteration 36 / 300: loss 0.597114\n",
      "iteration 36 / 300: loss 0.574885\n",
      "iteration 36 / 300: loss 0.597642\n",
      "iteration 36 / 300: loss 0.601785\n",
      "iteration 36 / 300: loss 0.603393\n",
      "iteration 36 / 300: loss 0.617948\n",
      "iteration 36 / 300: loss 0.599975\n",
      "iteration 36 / 300: loss 0.638730\n",
      "iteration 36 / 300: loss 0.590965\n",
      "iteration 36 / 300: loss 0.618900\n",
      "iteration 36 / 300: loss 0.595417\n",
      "iteration 36 / 300: loss 0.600870\n",
      "iteration 36 / 300: loss 0.579235\n",
      "iteration 36 / 300: loss 0.591016\n",
      "iteration 36 / 300: loss 0.617082\n",
      "iteration 36 / 300: loss 0.608005\n",
      "iteration 36 / 300: loss 0.590933\n",
      "iteration 36 / 300: loss 0.624827\n",
      "iteration 36 / 300: loss 0.599767\n",
      "iteration 36 / 300: loss 0.593406\n",
      "iteration 36 / 300: loss 0.600426\n",
      "iteration 36 / 300: loss 0.613575\n",
      "iteration 36 / 300: loss 0.604262\n",
      "iteration 36 / 300: loss 0.623640\n",
      "iteration 36 / 300: loss 0.616729\n",
      "iteration 36 / 300: loss 0.607524\n",
      "iteration 36 / 300: loss 0.599359\n",
      "iteration 36 / 300: loss 0.628609\n",
      "iteration 36 / 300: loss 0.604238\n",
      "iteration 36 / 300: loss 0.610412\n",
      "iteration 36 / 300: loss 0.638195\n",
      "iteration 36 / 300: loss 0.596128\n",
      "iteration 36 / 300: loss 0.613544\n",
      "iteration 36 / 300: loss 0.598896\n",
      "iteration 36 / 300: loss 0.611775\n",
      "iteration 36 / 300: loss 0.605067\n",
      "iteration 36 / 300: loss 0.598546\n",
      "iteration 36 / 300: loss 0.606408\n",
      "iteration 36 / 300: loss 0.612449\n",
      "iteration 36 / 300: loss 0.627881\n",
      "iteration 36 / 300: loss 0.596302\n",
      "iteration 36 / 300: loss 0.601885\n",
      "iteration 36 / 300: loss 0.597156\n",
      "iteration 36 / 300: loss 0.617916\n",
      "iteration 36 / 300: loss 0.595770\n",
      "iteration 36 / 300: loss 0.586027\n",
      "iteration 36 / 300: loss 0.576312\n",
      "iteration 36 / 300: loss 0.569057\n",
      "iteration 36 / 300: loss 0.603501\n",
      "iteration 36 / 300: loss 0.586806\n",
      "iteration 36 / 300: loss 0.595409\n",
      "iteration 36 / 300: loss 0.580994\n",
      "iteration 36 / 300: loss 0.603353\n",
      "iteration 36 / 300: loss 0.616838\n",
      "iteration 36 / 300: loss 0.618734\n",
      "iteration 36 / 300: loss 0.616394\n",
      "iteration 36 / 300: loss 0.591778\n",
      "iteration 36 / 300: loss 0.597683\n",
      "iteration 36 / 300: loss 0.604500\n",
      "iteration 36 / 300: loss 0.608112\n",
      "iteration 36 / 300: loss 0.605260\n",
      "iteration 36 / 300: loss 0.595994\n",
      "iteration 36 / 300: loss 0.600106\n",
      "iteration 36 / 300: loss 0.592474\n",
      "iteration 36 / 300: loss 0.609988\n",
      "iteration 36 / 300: loss 0.607530\n",
      "iteration 36 / 300: loss 0.623454\n",
      "iteration 36 / 300: loss 0.606963\n",
      "iteration 36 / 300: loss 0.609485\n",
      "iteration 36 / 300: loss 0.612849\n",
      "iteration 36 / 300: loss 0.602945\n",
      "iteration 36 / 300: loss 0.601429\n",
      "iteration 36 / 300: loss 0.597701\n",
      "iteration 36 / 300: loss 0.606595\n",
      "iteration 36 / 300: loss 0.614703\n",
      "iteration 36 / 300: loss 0.618618\n",
      "iteration 36 / 300: loss 0.595806\n",
      "iteration 36 / 300: loss 0.605938\n",
      "iteration 36 / 300: loss 0.610737\n",
      "iteration 36 / 300: loss 0.613072\n",
      "iteration 36 / 300: loss 0.612842\n",
      "iteration 36 / 300: loss 0.632032\n",
      "iteration 36 / 300: loss 0.595185\n",
      "iteration 36 / 300: loss 0.588992\n",
      "iteration 36 / 300: loss 0.634187\n",
      "iteration 36 / 300: loss 0.611494\n",
      "iteration 36 / 300: loss 0.611747\n",
      "iteration 36 / 300: loss 0.604597\n",
      "iteration 36 / 300: loss 0.607126\n",
      "iteration 36 / 300: loss 0.601855\n",
      "iteration 36 / 300: loss 0.598227\n",
      "iteration 36 / 300: loss 0.609841\n",
      "iteration 36 / 300: loss 0.620787\n",
      "iteration 36 / 300: loss 0.600719\n",
      "iteration 36 / 300: loss 0.605958\n",
      "iteration 36 / 300: loss 0.611936\n",
      "iteration 36 / 300: loss 0.609443\n",
      "iteration 36 / 300: loss 0.587471\n",
      "iteration 36 / 300: loss 0.608492\n",
      "iteration 37 / 300: loss 0.593919\n",
      "iteration 37 / 300: loss 0.596187\n",
      "iteration 37 / 300: loss 0.574325\n",
      "iteration 37 / 300: loss 0.597176\n",
      "iteration 37 / 300: loss 0.601157\n",
      "iteration 37 / 300: loss 0.602955\n",
      "iteration 37 / 300: loss 0.617380\n",
      "iteration 37 / 300: loss 0.599407\n",
      "iteration 37 / 300: loss 0.637809\n",
      "iteration 37 / 300: loss 0.590118\n",
      "iteration 37 / 300: loss 0.618186\n",
      "iteration 37 / 300: loss 0.594801\n",
      "iteration 37 / 300: loss 0.600175\n",
      "iteration 37 / 300: loss 0.578620\n",
      "iteration 37 / 300: loss 0.590310\n",
      "iteration 37 / 300: loss 0.616419\n",
      "iteration 37 / 300: loss 0.607141\n",
      "iteration 37 / 300: loss 0.590482\n",
      "iteration 37 / 300: loss 0.624125\n",
      "iteration 37 / 300: loss 0.599230\n",
      "iteration 37 / 300: loss 0.592925\n",
      "iteration 37 / 300: loss 0.599787\n",
      "iteration 37 / 300: loss 0.612938\n",
      "iteration 37 / 300: loss 0.603650\n",
      "iteration 37 / 300: loss 0.623051\n",
      "iteration 37 / 300: loss 0.616054\n",
      "iteration 37 / 300: loss 0.607059\n",
      "iteration 37 / 300: loss 0.598585\n",
      "iteration 37 / 300: loss 0.627840\n",
      "iteration 37 / 300: loss 0.603562\n",
      "iteration 37 / 300: loss 0.609897\n",
      "iteration 37 / 300: loss 0.637864\n",
      "iteration 37 / 300: loss 0.595467\n",
      "iteration 37 / 300: loss 0.613286\n",
      "iteration 37 / 300: loss 0.598148\n",
      "iteration 37 / 300: loss 0.610976\n",
      "iteration 37 / 300: loss 0.604420\n",
      "iteration 37 / 300: loss 0.598060\n",
      "iteration 37 / 300: loss 0.605966\n",
      "iteration 37 / 300: loss 0.611988\n",
      "iteration 37 / 300: loss 0.627399\n",
      "iteration 37 / 300: loss 0.595997\n",
      "iteration 37 / 300: loss 0.601450\n",
      "iteration 37 / 300: loss 0.596558\n",
      "iteration 37 / 300: loss 0.617429\n",
      "iteration 37 / 300: loss 0.595181\n",
      "iteration 37 / 300: loss 0.585629\n",
      "iteration 37 / 300: loss 0.575670\n",
      "iteration 37 / 300: loss 0.568498\n",
      "iteration 37 / 300: loss 0.602763\n",
      "iteration 37 / 300: loss 0.586146\n",
      "iteration 37 / 300: loss 0.594781\n",
      "iteration 37 / 300: loss 0.580429\n",
      "iteration 37 / 300: loss 0.602911\n",
      "iteration 37 / 300: loss 0.616219\n",
      "iteration 37 / 300: loss 0.617973\n",
      "iteration 37 / 300: loss 0.615705\n",
      "iteration 37 / 300: loss 0.591118\n",
      "iteration 37 / 300: loss 0.597097\n",
      "iteration 37 / 300: loss 0.603895\n",
      "iteration 37 / 300: loss 0.607242\n",
      "iteration 37 / 300: loss 0.604478\n",
      "iteration 37 / 300: loss 0.595535\n",
      "iteration 37 / 300: loss 0.599381\n",
      "iteration 37 / 300: loss 0.591710\n",
      "iteration 37 / 300: loss 0.609163\n",
      "iteration 37 / 300: loss 0.606880\n",
      "iteration 37 / 300: loss 0.622746\n",
      "iteration 37 / 300: loss 0.606316\n",
      "iteration 37 / 300: loss 0.608710\n",
      "iteration 37 / 300: loss 0.612266\n",
      "iteration 37 / 300: loss 0.602240\n",
      "iteration 37 / 300: loss 0.600916\n",
      "iteration 37 / 300: loss 0.597180\n",
      "iteration 37 / 300: loss 0.605950\n",
      "iteration 37 / 300: loss 0.614226\n",
      "iteration 37 / 300: loss 0.618124\n",
      "iteration 37 / 300: loss 0.595437\n",
      "iteration 37 / 300: loss 0.605469\n",
      "iteration 37 / 300: loss 0.610115\n",
      "iteration 37 / 300: loss 0.612578\n",
      "iteration 37 / 300: loss 0.612235\n",
      "iteration 37 / 300: loss 0.631409\n",
      "iteration 37 / 300: loss 0.594618\n",
      "iteration 37 / 300: loss 0.588377\n",
      "iteration 37 / 300: loss 0.633683\n",
      "iteration 37 / 300: loss 0.611062\n",
      "iteration 37 / 300: loss 0.611149\n",
      "iteration 37 / 300: loss 0.604042\n",
      "iteration 37 / 300: loss 0.606466\n",
      "iteration 37 / 300: loss 0.601218\n",
      "iteration 37 / 300: loss 0.597636\n",
      "iteration 37 / 300: loss 0.609005\n",
      "iteration 37 / 300: loss 0.620106\n",
      "iteration 37 / 300: loss 0.600176\n",
      "iteration 37 / 300: loss 0.605579\n",
      "iteration 37 / 300: loss 0.611426\n",
      "iteration 37 / 300: loss 0.609019\n",
      "iteration 37 / 300: loss 0.586851\n",
      "iteration 37 / 300: loss 0.608201\n",
      "iteration 38 / 300: loss 0.593347\n",
      "iteration 38 / 300: loss 0.595376\n",
      "iteration 38 / 300: loss 0.573827\n",
      "iteration 38 / 300: loss 0.596785\n",
      "iteration 38 / 300: loss 0.600581\n",
      "iteration 38 / 300: loss 0.602564\n",
      "iteration 38 / 300: loss 0.616837\n",
      "iteration 38 / 300: loss 0.598924\n",
      "iteration 38 / 300: loss 0.636964\n",
      "iteration 38 / 300: loss 0.589309\n",
      "iteration 38 / 300: loss 0.617485\n",
      "iteration 38 / 300: loss 0.594228\n",
      "iteration 38 / 300: loss 0.599527\n",
      "iteration 38 / 300: loss 0.578049\n",
      "iteration 38 / 300: loss 0.589658\n",
      "iteration 38 / 300: loss 0.615806\n",
      "iteration 38 / 300: loss 0.606344\n",
      "iteration 38 / 300: loss 0.590093\n",
      "iteration 38 / 300: loss 0.623487\n",
      "iteration 38 / 300: loss 0.598704\n",
      "iteration 38 / 300: loss 0.592493\n",
      "iteration 38 / 300: loss 0.599209\n",
      "iteration 38 / 300: loss 0.612343\n",
      "iteration 38 / 300: loss 0.603065\n",
      "iteration 38 / 300: loss 0.622472\n",
      "iteration 38 / 300: loss 0.615433\n",
      "iteration 38 / 300: loss 0.606590\n",
      "iteration 38 / 300: loss 0.597884\n",
      "iteration 38 / 300: loss 0.627134\n",
      "iteration 38 / 300: loss 0.602919\n",
      "iteration 38 / 300: loss 0.609400\n",
      "iteration 38 / 300: loss 0.637540\n",
      "iteration 38 / 300: loss 0.594875\n",
      "iteration 38 / 300: loss 0.612995\n",
      "iteration 38 / 300: loss 0.597464\n",
      "iteration 38 / 300: loss 0.610269\n",
      "iteration 38 / 300: loss 0.603837\n",
      "iteration 38 / 300: loss 0.597627\n",
      "iteration 38 / 300: loss 0.605585\n",
      "iteration 38 / 300: loss 0.611575\n",
      "iteration 38 / 300: loss 0.626969\n",
      "iteration 38 / 300: loss 0.595730\n",
      "iteration 38 / 300: loss 0.601080\n",
      "iteration 38 / 300: loss 0.595967\n",
      "iteration 38 / 300: loss 0.617070\n",
      "iteration 38 / 300: loss 0.594640\n",
      "iteration 38 / 300: loss 0.585249\n",
      "iteration 38 / 300: loss 0.575098\n",
      "iteration 38 / 300: loss 0.567979\n",
      "iteration 38 / 300: loss 0.602098\n",
      "iteration 38 / 300: loss 0.585545\n",
      "iteration 38 / 300: loss 0.594175\n",
      "iteration 38 / 300: loss 0.579922\n",
      "iteration 38 / 300: loss 0.602493\n",
      "iteration 38 / 300: loss 0.615596\n",
      "iteration 38 / 300: loss 0.617291\n",
      "iteration 38 / 300: loss 0.615053\n",
      "iteration 38 / 300: loss 0.590492\n",
      "iteration 38 / 300: loss 0.596558\n",
      "iteration 38 / 300: loss 0.603282\n",
      "iteration 38 / 300: loss 0.606470\n",
      "iteration 38 / 300: loss 0.603729\n",
      "iteration 38 / 300: loss 0.595105\n",
      "iteration 38 / 300: loss 0.598666\n",
      "iteration 38 / 300: loss 0.591041\n",
      "iteration 38 / 300: loss 0.608387\n",
      "iteration 38 / 300: loss 0.606261\n",
      "iteration 38 / 300: loss 0.622061\n",
      "iteration 38 / 300: loss 0.605690\n",
      "iteration 38 / 300: loss 0.607987\n",
      "iteration 38 / 300: loss 0.611698\n",
      "iteration 38 / 300: loss 0.601579\n",
      "iteration 38 / 300: loss 0.600417\n",
      "iteration 38 / 300: loss 0.596678\n",
      "iteration 38 / 300: loss 0.605336\n",
      "iteration 38 / 300: loss 0.613733\n",
      "iteration 38 / 300: loss 0.617669\n",
      "iteration 38 / 300: loss 0.595056\n",
      "iteration 38 / 300: loss 0.605071\n",
      "iteration 38 / 300: loss 0.609523\n",
      "iteration 38 / 300: loss 0.612100\n",
      "iteration 38 / 300: loss 0.611681\n",
      "iteration 38 / 300: loss 0.630864\n",
      "iteration 38 / 300: loss 0.594100\n",
      "iteration 38 / 300: loss 0.587840\n",
      "iteration 38 / 300: loss 0.633206\n",
      "iteration 38 / 300: loss 0.610644\n",
      "iteration 38 / 300: loss 0.610599\n",
      "iteration 38 / 300: loss 0.603516\n",
      "iteration 38 / 300: loss 0.605857\n",
      "iteration 38 / 300: loss 0.600639\n",
      "iteration 38 / 300: loss 0.597099\n",
      "iteration 38 / 300: loss 0.608264\n",
      "iteration 38 / 300: loss 0.619480\n",
      "iteration 38 / 300: loss 0.599667\n",
      "iteration 38 / 300: loss 0.605220\n",
      "iteration 38 / 300: loss 0.610938\n",
      "iteration 38 / 300: loss 0.608632\n",
      "iteration 38 / 300: loss 0.586294\n",
      "iteration 38 / 300: loss 0.607910\n",
      "iteration 39 / 300: loss 0.592803\n",
      "iteration 39 / 300: loss 0.594667\n",
      "iteration 39 / 300: loss 0.573385\n",
      "iteration 39 / 300: loss 0.596456\n",
      "iteration 39 / 300: loss 0.600055\n",
      "iteration 39 / 300: loss 0.602202\n",
      "iteration 39 / 300: loss 0.616314\n",
      "iteration 39 / 300: loss 0.598510\n",
      "iteration 39 / 300: loss 0.636205\n",
      "iteration 39 / 300: loss 0.588543\n",
      "iteration 39 / 300: loss 0.616797\n",
      "iteration 39 / 300: loss 0.593700\n",
      "iteration 39 / 300: loss 0.598919\n",
      "iteration 39 / 300: loss 0.577516\n",
      "iteration 39 / 300: loss 0.589060\n",
      "iteration 39 / 300: loss 0.615231\n",
      "iteration 39 / 300: loss 0.605625\n",
      "iteration 39 / 300: loss 0.589740\n",
      "iteration 39 / 300: loss 0.622900\n",
      "iteration 39 / 300: loss 0.598199\n",
      "iteration 39 / 300: loss 0.592086\n",
      "iteration 39 / 300: loss 0.598690\n",
      "iteration 39 / 300: loss 0.611783\n",
      "iteration 39 / 300: loss 0.602509\n",
      "iteration 39 / 300: loss 0.621902\n",
      "iteration 39 / 300: loss 0.614862\n",
      "iteration 39 / 300: loss 0.606107\n",
      "iteration 39 / 300: loss 0.597234\n",
      "iteration 39 / 300: loss 0.626471\n",
      "iteration 39 / 300: loss 0.602325\n",
      "iteration 39 / 300: loss 0.608921\n",
      "iteration 39 / 300: loss 0.637228\n",
      "iteration 39 / 300: loss 0.594328\n",
      "iteration 39 / 300: loss 0.612662\n",
      "iteration 39 / 300: loss 0.596814\n",
      "iteration 39 / 300: loss 0.609626\n",
      "iteration 39 / 300: loss 0.603296\n",
      "iteration 39 / 300: loss 0.597226\n",
      "iteration 39 / 300: loss 0.605248\n",
      "iteration 39 / 300: loss 0.611183\n",
      "iteration 39 / 300: loss 0.626584\n",
      "iteration 39 / 300: loss 0.595486\n",
      "iteration 39 / 300: loss 0.600739\n",
      "iteration 39 / 300: loss 0.595364\n",
      "iteration 39 / 300: loss 0.616823\n",
      "iteration 39 / 300: loss 0.594146\n",
      "iteration 39 / 300: loss 0.584887\n",
      "iteration 39 / 300: loss 0.574586\n",
      "iteration 39 / 300: loss 0.567502\n",
      "iteration 39 / 300: loss 0.601491\n",
      "iteration 39 / 300: loss 0.585002\n",
      "iteration 39 / 300: loss 0.593590\n",
      "iteration 39 / 300: loss 0.579460\n",
      "iteration 39 / 300: loss 0.602091\n",
      "iteration 39 / 300: loss 0.614977\n",
      "iteration 39 / 300: loss 0.616685\n",
      "iteration 39 / 300: loss 0.614428\n",
      "iteration 39 / 300: loss 0.589920\n",
      "iteration 39 / 300: loss 0.596044\n",
      "iteration 39 / 300: loss 0.602687\n",
      "iteration 39 / 300: loss 0.605772\n",
      "iteration 39 / 300: loss 0.603041\n",
      "iteration 39 / 300: loss 0.594713\n",
      "iteration 39 / 300: loss 0.598000\n",
      "iteration 39 / 300: loss 0.590438\n",
      "iteration 39 / 300: loss 0.607647\n",
      "iteration 39 / 300: loss 0.605656\n",
      "iteration 39 / 300: loss 0.621391\n",
      "iteration 39 / 300: loss 0.605075\n",
      "iteration 39 / 300: loss 0.607297\n",
      "iteration 39 / 300: loss 0.611135\n",
      "iteration 39 / 300: loss 0.600965\n",
      "iteration 39 / 300: loss 0.599919\n",
      "iteration 39 / 300: loss 0.596182\n",
      "iteration 39 / 300: loss 0.604745\n",
      "iteration 39 / 300: loss 0.613237\n",
      "iteration 39 / 300: loss 0.617234\n",
      "iteration 39 / 300: loss 0.594655\n",
      "iteration 39 / 300: loss 0.604715\n",
      "iteration 39 / 300: loss 0.608974\n",
      "iteration 39 / 300: loss 0.611641\n",
      "iteration 39 / 300: loss 0.611173\n",
      "iteration 39 / 300: loss 0.630373\n",
      "iteration 39 / 300: loss 0.593622\n",
      "iteration 39 / 300: loss 0.587357\n",
      "iteration 39 / 300: loss 0.632742\n",
      "iteration 39 / 300: loss 0.610211\n",
      "iteration 39 / 300: loss 0.610118\n",
      "iteration 39 / 300: loss 0.603005\n",
      "iteration 39 / 300: loss 0.605297\n",
      "iteration 39 / 300: loss 0.600094\n",
      "iteration 39 / 300: loss 0.596597\n",
      "iteration 39 / 300: loss 0.607592\n",
      "iteration 39 / 300: loss 0.618886\n",
      "iteration 39 / 300: loss 0.599188\n",
      "iteration 39 / 300: loss 0.604885\n",
      "iteration 39 / 300: loss 0.610482\n",
      "iteration 39 / 300: loss 0.608277\n",
      "iteration 39 / 300: loss 0.585796\n",
      "iteration 39 / 300: loss 0.607607\n",
      "iteration 40 / 300: loss 0.592288\n",
      "iteration 40 / 300: loss 0.594053\n",
      "iteration 40 / 300: loss 0.572982\n",
      "iteration 40 / 300: loss 0.596176\n",
      "iteration 40 / 300: loss 0.599572\n",
      "iteration 40 / 300: loss 0.601852\n",
      "iteration 40 / 300: loss 0.615805\n",
      "iteration 40 / 300: loss 0.598149\n",
      "iteration 40 / 300: loss 0.635524\n",
      "iteration 40 / 300: loss 0.587829\n",
      "iteration 40 / 300: loss 0.616131\n",
      "iteration 40 / 300: loss 0.593219\n",
      "iteration 40 / 300: loss 0.598341\n",
      "iteration 40 / 300: loss 0.577014\n",
      "iteration 40 / 300: loss 0.588520\n",
      "iteration 40 / 300: loss 0.614684\n",
      "iteration 40 / 300: loss 0.604978\n",
      "iteration 40 / 300: loss 0.589409\n",
      "iteration 40 / 300: loss 0.622356\n",
      "iteration 40 / 300: loss 0.597723\n",
      "iteration 40 / 300: loss 0.591688\n",
      "iteration 40 / 300: loss 0.598215\n",
      "iteration 40 / 300: loss 0.611258\n",
      "iteration 40 / 300: loss 0.601988\n",
      "iteration 40 / 300: loss 0.621347\n",
      "iteration 40 / 300: loss 0.614340\n",
      "iteration 40 / 300: loss 0.605610\n",
      "iteration 40 / 300: loss 0.596625\n",
      "iteration 40 / 300: loss 0.625835\n",
      "iteration 40 / 300: loss 0.601782\n",
      "iteration 40 / 300: loss 0.608462\n",
      "iteration 40 / 300: loss 0.636932\n",
      "iteration 40 / 300: loss 0.593820\n",
      "iteration 40 / 300: loss 0.612304\n",
      "iteration 40 / 300: loss 0.596183\n",
      "iteration 40 / 300: loss 0.609031\n",
      "iteration 40 / 300: loss 0.602788\n",
      "iteration 40 / 300: loss 0.596837\n",
      "iteration 40 / 300: loss 0.604948\n",
      "iteration 40 / 300: loss 0.610800\n",
      "iteration 40 / 300: loss 0.626223\n",
      "iteration 40 / 300: loss 0.595253\n",
      "iteration 40 / 300: loss 0.600410\n",
      "iteration 40 / 300: loss 0.594739\n",
      "iteration 40 / 300: loss 0.616660\n",
      "iteration 40 / 300: loss 0.593689\n",
      "iteration 40 / 300: loss 0.584538\n",
      "iteration 40 / 300: loss 0.574117\n",
      "iteration 40 / 300: loss 0.567068\n",
      "iteration 40 / 300: loss 0.600932\n",
      "iteration 40 / 300: loss 0.584514\n",
      "iteration 40 / 300: loss 0.593028\n",
      "iteration 40 / 300: loss 0.579031\n",
      "iteration 40 / 300: loss 0.601699\n",
      "iteration 40 / 300: loss 0.614370\n",
      "iteration 40 / 300: loss 0.616136\n",
      "iteration 40 / 300: loss 0.613811\n",
      "iteration 40 / 300: loss 0.589399\n",
      "iteration 40 / 300: loss 0.595554\n",
      "iteration 40 / 300: loss 0.602122\n",
      "iteration 40 / 300: loss 0.605129\n",
      "iteration 40 / 300: loss 0.602425\n",
      "iteration 40 / 300: loss 0.594355\n",
      "iteration 40 / 300: loss 0.597399\n",
      "iteration 40 / 300: loss 0.589911\n",
      "iteration 40 / 300: loss 0.606963\n",
      "iteration 40 / 300: loss 0.605077\n",
      "iteration 40 / 300: loss 0.620741\n",
      "iteration 40 / 300: loss 0.604477\n",
      "iteration 40 / 300: loss 0.606639\n",
      "iteration 40 / 300: loss 0.610576\n",
      "iteration 40 / 300: loss 0.600389\n",
      "iteration 40 / 300: loss 0.599423\n",
      "iteration 40 / 300: loss 0.595685\n",
      "iteration 40 / 300: loss 0.604173\n",
      "iteration 40 / 300: loss 0.612740\n",
      "iteration 40 / 300: loss 0.616806\n",
      "iteration 40 / 300: loss 0.594237\n",
      "iteration 40 / 300: loss 0.604390\n",
      "iteration 40 / 300: loss 0.608469\n",
      "iteration 40 / 300: loss 0.611196\n",
      "iteration 40 / 300: loss 0.610700\n",
      "iteration 40 / 300: loss 0.629919\n",
      "iteration 40 / 300: loss 0.593172\n",
      "iteration 40 / 300: loss 0.586907\n",
      "iteration 40 / 300: loss 0.632288\n",
      "iteration 40 / 300: loss 0.609756\n",
      "iteration 40 / 300: loss 0.609688\n",
      "iteration 40 / 300: loss 0.602510\n",
      "iteration 40 / 300: loss 0.604780\n",
      "iteration 40 / 300: loss 0.599566\n",
      "iteration 40 / 300: loss 0.596124\n",
      "iteration 40 / 300: loss 0.606968\n",
      "iteration 40 / 300: loss 0.618307\n",
      "iteration 40 / 300: loss 0.598735\n",
      "iteration 40 / 300: loss 0.604572\n",
      "iteration 40 / 300: loss 0.610054\n",
      "iteration 40 / 300: loss 0.607945\n",
      "iteration 40 / 300: loss 0.585348\n",
      "iteration 40 / 300: loss 0.607286\n",
      "iteration 41 / 300: loss 0.591804\n",
      "iteration 41 / 300: loss 0.593524\n",
      "iteration 41 / 300: loss 0.572609\n",
      "iteration 41 / 300: loss 0.595933\n",
      "iteration 41 / 300: loss 0.599129\n",
      "iteration 41 / 300: loss 0.601505\n",
      "iteration 41 / 300: loss 0.615308\n",
      "iteration 41 / 300: loss 0.597825\n",
      "iteration 41 / 300: loss 0.634913\n",
      "iteration 41 / 300: loss 0.587175\n",
      "iteration 41 / 300: loss 0.615493\n",
      "iteration 41 / 300: loss 0.592781\n",
      "iteration 41 / 300: loss 0.597793\n",
      "iteration 41 / 300: loss 0.576542\n",
      "iteration 41 / 300: loss 0.588036\n",
      "iteration 41 / 300: loss 0.614166\n",
      "iteration 41 / 300: loss 0.604400\n",
      "iteration 41 / 300: loss 0.589089\n",
      "iteration 41 / 300: loss 0.621842\n",
      "iteration 41 / 300: loss 0.597281\n",
      "iteration 41 / 300: loss 0.591294\n",
      "iteration 41 / 300: loss 0.597769\n",
      "iteration 41 / 300: loss 0.610765\n",
      "iteration 41 / 300: loss 0.601508\n",
      "iteration 41 / 300: loss 0.620811\n",
      "iteration 41 / 300: loss 0.613865\n",
      "iteration 41 / 300: loss 0.605107\n",
      "iteration 41 / 300: loss 0.596047\n",
      "iteration 41 / 300: loss 0.625224\n",
      "iteration 41 / 300: loss 0.601281\n",
      "iteration 41 / 300: loss 0.608023\n",
      "iteration 41 / 300: loss 0.636647\n",
      "iteration 41 / 300: loss 0.593348\n",
      "iteration 41 / 300: loss 0.611946\n",
      "iteration 41 / 300: loss 0.595574\n",
      "iteration 41 / 300: loss 0.608475\n",
      "iteration 41 / 300: loss 0.602310\n",
      "iteration 41 / 300: loss 0.596441\n",
      "iteration 41 / 300: loss 0.604673\n",
      "iteration 41 / 300: loss 0.610424\n",
      "iteration 41 / 300: loss 0.625862\n",
      "iteration 41 / 300: loss 0.595016\n",
      "iteration 41 / 300: loss 0.600084\n",
      "iteration 41 / 300: loss 0.594095\n",
      "iteration 41 / 300: loss 0.616545\n",
      "iteration 41 / 300: loss 0.593261\n",
      "iteration 41 / 300: loss 0.584203\n",
      "iteration 41 / 300: loss 0.573685\n",
      "iteration 41 / 300: loss 0.566676\n",
      "iteration 41 / 300: loss 0.600416\n",
      "iteration 41 / 300: loss 0.584077\n",
      "iteration 41 / 300: loss 0.592497\n",
      "iteration 41 / 300: loss 0.578625\n",
      "iteration 41 / 300: loss 0.601322\n",
      "iteration 41 / 300: loss 0.613794\n",
      "iteration 41 / 300: loss 0.615634\n",
      "iteration 41 / 300: loss 0.613200\n",
      "iteration 41 / 300: loss 0.588926\n",
      "iteration 41 / 300: loss 0.595091\n",
      "iteration 41 / 300: loss 0.601592\n",
      "iteration 41 / 300: loss 0.604544\n",
      "iteration 41 / 300: loss 0.601883\n",
      "iteration 41 / 300: loss 0.594030\n",
      "iteration 41 / 300: loss 0.596853\n",
      "iteration 41 / 300: loss 0.589470\n",
      "iteration 41 / 300: loss 0.606349\n",
      "iteration 41 / 300: loss 0.604537\n",
      "iteration 41 / 300: loss 0.620120\n",
      "iteration 41 / 300: loss 0.603909\n",
      "iteration 41 / 300: loss 0.606014\n",
      "iteration 41 / 300: loss 0.610027\n",
      "iteration 41 / 300: loss 0.599841\n",
      "iteration 41 / 300: loss 0.598940\n",
      "iteration 41 / 300: loss 0.595192\n",
      "iteration 41 / 300: loss 0.603623\n",
      "iteration 41 / 300: loss 0.612246\n",
      "iteration 41 / 300: loss 0.616387\n",
      "iteration 41 / 300: loss 0.593809\n",
      "iteration 41 / 300: loss 0.604083\n",
      "iteration 41 / 300: loss 0.608005\n",
      "iteration 41 / 300: loss 0.610763\n",
      "iteration 41 / 300: loss 0.610252\n",
      "iteration 41 / 300: loss 0.629491\n",
      "iteration 41 / 300: loss 0.592740\n",
      "iteration 41 / 300: loss 0.586478\n",
      "iteration 41 / 300: loss 0.631843\n",
      "iteration 41 / 300: loss 0.609290\n",
      "iteration 41 / 300: loss 0.609288\n",
      "iteration 41 / 300: loss 0.602033\n",
      "iteration 41 / 300: loss 0.604291\n",
      "iteration 41 / 300: loss 0.599054\n",
      "iteration 41 / 300: loss 0.595672\n",
      "iteration 41 / 300: loss 0.606388\n",
      "iteration 41 / 300: loss 0.617746\n",
      "iteration 41 / 300: loss 0.598307\n",
      "iteration 41 / 300: loss 0.604277\n",
      "iteration 41 / 300: loss 0.609646\n",
      "iteration 41 / 300: loss 0.607627\n",
      "iteration 41 / 300: loss 0.584943\n",
      "iteration 41 / 300: loss 0.606950\n",
      "iteration 42 / 300: loss 0.591349\n",
      "iteration 42 / 300: loss 0.593067\n",
      "iteration 42 / 300: loss 0.572259\n",
      "iteration 42 / 300: loss 0.595718\n",
      "iteration 42 / 300: loss 0.598722\n",
      "iteration 42 / 300: loss 0.601155\n",
      "iteration 42 / 300: loss 0.614824\n",
      "iteration 42 / 300: loss 0.597524\n",
      "iteration 42 / 300: loss 0.634363\n",
      "iteration 42 / 300: loss 0.586580\n",
      "iteration 42 / 300: loss 0.614885\n",
      "iteration 42 / 300: loss 0.592382\n",
      "iteration 42 / 300: loss 0.597280\n",
      "iteration 42 / 300: loss 0.576104\n",
      "iteration 42 / 300: loss 0.587602\n",
      "iteration 42 / 300: loss 0.613683\n",
      "iteration 42 / 300: loss 0.603887\n",
      "iteration 42 / 300: loss 0.588773\n",
      "iteration 42 / 300: loss 0.621352\n",
      "iteration 42 / 300: loss 0.596874\n",
      "iteration 42 / 300: loss 0.590904\n",
      "iteration 42 / 300: loss 0.597342\n",
      "iteration 42 / 300: loss 0.610299\n",
      "iteration 42 / 300: loss 0.601070\n",
      "iteration 42 / 300: loss 0.620293\n",
      "iteration 42 / 300: loss 0.613433\n",
      "iteration 42 / 300: loss 0.604606\n",
      "iteration 42 / 300: loss 0.595496\n",
      "iteration 42 / 300: loss 0.624642\n",
      "iteration 42 / 300: loss 0.600812\n",
      "iteration 42 / 300: loss 0.607602\n",
      "iteration 42 / 300: loss 0.636366\n",
      "iteration 42 / 300: loss 0.592909\n",
      "iteration 42 / 300: loss 0.611600\n",
      "iteration 42 / 300: loss 0.594994\n",
      "iteration 42 / 300: loss 0.607947\n",
      "iteration 42 / 300: loss 0.601859\n",
      "iteration 42 / 300: loss 0.596034\n",
      "iteration 42 / 300: loss 0.604407\n",
      "iteration 42 / 300: loss 0.610057\n",
      "iteration 42 / 300: loss 0.625493\n",
      "iteration 42 / 300: loss 0.594761\n",
      "iteration 42 / 300: loss 0.599753\n",
      "iteration 42 / 300: loss 0.593450\n",
      "iteration 42 / 300: loss 0.616448\n",
      "iteration 42 / 300: loss 0.592858\n",
      "iteration 42 / 300: loss 0.583879\n",
      "iteration 42 / 300: loss 0.573280\n",
      "iteration 42 / 300: loss 0.566324\n",
      "iteration 42 / 300: loss 0.599941\n",
      "iteration 42 / 300: loss 0.583683\n",
      "iteration 42 / 300: loss 0.591999\n",
      "iteration 42 / 300: loss 0.578238\n",
      "iteration 42 / 300: loss 0.600970\n",
      "iteration 42 / 300: loss 0.613263\n",
      "iteration 42 / 300: loss 0.615180\n",
      "iteration 42 / 300: loss 0.612613\n",
      "iteration 42 / 300: loss 0.588503\n",
      "iteration 42 / 300: loss 0.594647\n",
      "iteration 42 / 300: loss 0.601098\n",
      "iteration 42 / 300: loss 0.604022\n",
      "iteration 42 / 300: loss 0.601408\n",
      "iteration 42 / 300: loss 0.593733\n",
      "iteration 42 / 300: loss 0.596359\n",
      "iteration 42 / 300: loss 0.589098\n",
      "iteration 42 / 300: loss 0.605799\n",
      "iteration 42 / 300: loss 0.604041\n",
      "iteration 42 / 300: loss 0.619535\n",
      "iteration 42 / 300: loss 0.603380\n",
      "iteration 42 / 300: loss 0.605428\n",
      "iteration 42 / 300: loss 0.609495\n",
      "iteration 42 / 300: loss 0.599317\n",
      "iteration 42 / 300: loss 0.598476\n",
      "iteration 42 / 300: loss 0.594714\n",
      "iteration 42 / 300: loss 0.603099\n",
      "iteration 42 / 300: loss 0.611763\n",
      "iteration 42 / 300: loss 0.615979\n",
      "iteration 42 / 300: loss 0.593380\n",
      "iteration 42 / 300: loss 0.603785\n",
      "iteration 42 / 300: loss 0.607582\n",
      "iteration 42 / 300: loss 0.610345\n",
      "iteration 42 / 300: loss 0.609824\n",
      "iteration 42 / 300: loss 0.629086\n",
      "iteration 42 / 300: loss 0.592325\n",
      "iteration 42 / 300: loss 0.586066\n",
      "iteration 42 / 300: loss 0.631408\n",
      "iteration 42 / 300: loss 0.608834\n",
      "iteration 42 / 300: loss 0.608913\n",
      "iteration 42 / 300: loss 0.601574\n",
      "iteration 42 / 300: loss 0.603817\n",
      "iteration 42 / 300: loss 0.598563\n",
      "iteration 42 / 300: loss 0.595236\n",
      "iteration 42 / 300: loss 0.605846\n",
      "iteration 42 / 300: loss 0.617210\n",
      "iteration 42 / 300: loss 0.597903\n",
      "iteration 42 / 300: loss 0.603999\n",
      "iteration 42 / 300: loss 0.609250\n",
      "iteration 42 / 300: loss 0.607318\n",
      "iteration 42 / 300: loss 0.584572\n",
      "iteration 42 / 300: loss 0.606608\n",
      "iteration 43 / 300: loss 0.590921\n",
      "iteration 43 / 300: loss 0.592672\n",
      "iteration 43 / 300: loss 0.571931\n",
      "iteration 43 / 300: loss 0.595525\n",
      "iteration 43 / 300: loss 0.598347\n",
      "iteration 43 / 300: loss 0.600801\n",
      "iteration 43 / 300: loss 0.614361\n",
      "iteration 43 / 300: loss 0.597236\n",
      "iteration 43 / 300: loss 0.633863\n",
      "iteration 43 / 300: loss 0.586042\n",
      "iteration 43 / 300: loss 0.614310\n",
      "iteration 43 / 300: loss 0.592013\n",
      "iteration 43 / 300: loss 0.596810\n",
      "iteration 43 / 300: loss 0.575703\n",
      "iteration 43 / 300: loss 0.587214\n",
      "iteration 43 / 300: loss 0.613240\n",
      "iteration 43 / 300: loss 0.603430\n",
      "iteration 43 / 300: loss 0.588456\n",
      "iteration 43 / 300: loss 0.620885\n",
      "iteration 43 / 300: loss 0.596500\n",
      "iteration 43 / 300: loss 0.590524\n",
      "iteration 43 / 300: loss 0.596927\n",
      "iteration 43 / 300: loss 0.609858\n",
      "iteration 43 / 300: loss 0.600673\n",
      "iteration 43 / 300: loss 0.619799\n",
      "iteration 43 / 300: loss 0.613036\n",
      "iteration 43 / 300: loss 0.604118\n",
      "iteration 43 / 300: loss 0.594967\n",
      "iteration 43 / 300: loss 0.624091\n",
      "iteration 43 / 300: loss 0.600369\n",
      "iteration 43 / 300: loss 0.607201\n",
      "iteration 43 / 300: loss 0.636088\n",
      "iteration 43 / 300: loss 0.592501\n",
      "iteration 43 / 300: loss 0.611270\n",
      "iteration 43 / 300: loss 0.594445\n",
      "iteration 43 / 300: loss 0.607443\n",
      "iteration 43 / 300: loss 0.601433\n",
      "iteration 43 / 300: loss 0.595616\n",
      "iteration 43 / 300: loss 0.604144\n",
      "iteration 43 / 300: loss 0.609702\n",
      "iteration 43 / 300: loss 0.625115\n",
      "iteration 43 / 300: loss 0.594480\n",
      "iteration 43 / 300: loss 0.599414\n",
      "iteration 43 / 300: loss 0.592826\n",
      "iteration 43 / 300: loss 0.616346\n",
      "iteration 43 / 300: loss 0.592479\n",
      "iteration 43 / 300: loss 0.583562\n",
      "iteration 43 / 300: loss 0.572893\n",
      "iteration 43 / 300: loss 0.566007\n",
      "iteration 43 / 300: loss 0.599502\n",
      "iteration 43 / 300: loss 0.583323\n",
      "iteration 43 / 300: loss 0.591536\n",
      "iteration 43 / 300: loss 0.577868\n",
      "iteration 43 / 300: loss 0.600647\n",
      "iteration 43 / 300: loss 0.612783\n",
      "iteration 43 / 300: loss 0.614774\n",
      "iteration 43 / 300: loss 0.612066\n",
      "iteration 43 / 300: loss 0.588124\n",
      "iteration 43 / 300: loss 0.594224\n",
      "iteration 43 / 300: loss 0.600636\n",
      "iteration 43 / 300: loss 0.603560\n",
      "iteration 43 / 300: loss 0.600989\n",
      "iteration 43 / 300: loss 0.593460\n",
      "iteration 43 / 300: loss 0.595914\n",
      "iteration 43 / 300: loss 0.588777\n",
      "iteration 43 / 300: loss 0.605299\n",
      "iteration 43 / 300: loss 0.603588\n",
      "iteration 43 / 300: loss 0.618994\n",
      "iteration 43 / 300: loss 0.602897\n",
      "iteration 43 / 300: loss 0.604878\n",
      "iteration 43 / 300: loss 0.608990\n",
      "iteration 43 / 300: loss 0.598816\n",
      "iteration 43 / 300: loss 0.598034\n",
      "iteration 43 / 300: loss 0.594260\n",
      "iteration 43 / 300: loss 0.602601\n",
      "iteration 43 / 300: loss 0.611297\n",
      "iteration 43 / 300: loss 0.615583\n",
      "iteration 43 / 300: loss 0.592954\n",
      "iteration 43 / 300: loss 0.603490\n",
      "iteration 43 / 300: loss 0.607196\n",
      "iteration 43 / 300: loss 0.609944\n",
      "iteration 43 / 300: loss 0.609412\n",
      "iteration 43 / 300: loss 0.628703\n",
      "iteration 43 / 300: loss 0.591924\n",
      "iteration 43 / 300: loss 0.585672\n",
      "iteration 43 / 300: loss 0.630984\n",
      "iteration 43 / 300: loss 0.608404\n",
      "iteration 43 / 300: loss 0.608564\n",
      "iteration 43 / 300: loss 0.601133\n",
      "iteration 43 / 300: loss 0.603358\n",
      "iteration 43 / 300: loss 0.598098\n",
      "iteration 43 / 300: loss 0.594816\n",
      "iteration 43 / 300: loss 0.605335\n",
      "iteration 43 / 300: loss 0.616707\n",
      "iteration 43 / 300: loss 0.597518\n",
      "iteration 43 / 300: loss 0.603735\n",
      "iteration 43 / 300: loss 0.608862\n",
      "iteration 43 / 300: loss 0.607018\n",
      "iteration 43 / 300: loss 0.584228\n",
      "iteration 43 / 300: loss 0.606270\n",
      "iteration 44 / 300: loss 0.590516\n",
      "iteration 44 / 300: loss 0.592325\n",
      "iteration 44 / 300: loss 0.571623\n",
      "iteration 44 / 300: loss 0.595348\n",
      "iteration 44 / 300: loss 0.597999\n",
      "iteration 44 / 300: loss 0.600445\n",
      "iteration 44 / 300: loss 0.613921\n",
      "iteration 44 / 300: loss 0.596957\n",
      "iteration 44 / 300: loss 0.633403\n",
      "iteration 44 / 300: loss 0.585553\n",
      "iteration 44 / 300: loss 0.613768\n",
      "iteration 44 / 300: loss 0.591670\n",
      "iteration 44 / 300: loss 0.596384\n",
      "iteration 44 / 300: loss 0.575338\n",
      "iteration 44 / 300: loss 0.586863\n",
      "iteration 44 / 300: loss 0.612835\n",
      "iteration 44 / 300: loss 0.603020\n",
      "iteration 44 / 300: loss 0.588142\n",
      "iteration 44 / 300: loss 0.620443\n",
      "iteration 44 / 300: loss 0.596154\n",
      "iteration 44 / 300: loss 0.590159\n",
      "iteration 44 / 300: loss 0.596525\n",
      "iteration 44 / 300: loss 0.609443\n",
      "iteration 44 / 300: loss 0.600314\n",
      "iteration 44 / 300: loss 0.619335\n",
      "iteration 44 / 300: loss 0.612670\n",
      "iteration 44 / 300: loss 0.603649\n",
      "iteration 44 / 300: loss 0.594461\n",
      "iteration 44 / 300: loss 0.623573\n",
      "iteration 44 / 300: loss 0.599947\n",
      "iteration 44 / 300: loss 0.606819\n",
      "iteration 44 / 300: loss 0.635813\n",
      "iteration 44 / 300: loss 0.592123\n",
      "iteration 44 / 300: loss 0.610955\n",
      "iteration 44 / 300: loss 0.593929\n",
      "iteration 44 / 300: loss 0.606963\n",
      "iteration 44 / 300: loss 0.601027\n",
      "iteration 44 / 300: loss 0.595197\n",
      "iteration 44 / 300: loss 0.603883\n",
      "iteration 44 / 300: loss 0.609359\n",
      "iteration 44 / 300: loss 0.624733\n",
      "iteration 44 / 300: loss 0.594178\n",
      "iteration 44 / 300: loss 0.599069\n",
      "iteration 44 / 300: loss 0.592233\n",
      "iteration 44 / 300: loss 0.616232\n",
      "iteration 44 / 300: loss 0.592124\n",
      "iteration 44 / 300: loss 0.583247\n",
      "iteration 44 / 300: loss 0.572517\n",
      "iteration 44 / 300: loss 0.565718\n",
      "iteration 44 / 300: loss 0.599093\n",
      "iteration 44 / 300: loss 0.582989\n",
      "iteration 44 / 300: loss 0.591105\n",
      "iteration 44 / 300: loss 0.577514\n",
      "iteration 44 / 300: loss 0.600346\n",
      "iteration 44 / 300: loss 0.612347\n",
      "iteration 44 / 300: loss 0.614417\n",
      "iteration 44 / 300: loss 0.611560\n",
      "iteration 44 / 300: loss 0.587781\n",
      "iteration 44 / 300: loss 0.593827\n",
      "iteration 44 / 300: loss 0.600204\n",
      "iteration 44 / 300: loss 0.603148\n",
      "iteration 44 / 300: loss 0.600614\n",
      "iteration 44 / 300: loss 0.593206\n",
      "iteration 44 / 300: loss 0.595510\n",
      "iteration 44 / 300: loss 0.588489\n",
      "iteration 44 / 300: loss 0.604837\n",
      "iteration 44 / 300: loss 0.603174\n",
      "iteration 44 / 300: loss 0.618499\n",
      "iteration 44 / 300: loss 0.602458\n",
      "iteration 44 / 300: loss 0.604365\n",
      "iteration 44 / 300: loss 0.608519\n",
      "iteration 44 / 300: loss 0.598341\n",
      "iteration 44 / 300: loss 0.597616\n",
      "iteration 44 / 300: loss 0.593834\n",
      "iteration 44 / 300: loss 0.602131\n",
      "iteration 44 / 300: loss 0.610853\n",
      "iteration 44 / 300: loss 0.615199\n",
      "iteration 44 / 300: loss 0.592537\n",
      "iteration 44 / 300: loss 0.603196\n",
      "iteration 44 / 300: loss 0.606842\n",
      "iteration 44 / 300: loss 0.609564\n",
      "iteration 44 / 300: loss 0.609019\n",
      "iteration 44 / 300: loss 0.628340\n",
      "iteration 44 / 300: loss 0.591537\n",
      "iteration 44 / 300: loss 0.585297\n",
      "iteration 44 / 300: loss 0.630571\n",
      "iteration 44 / 300: loss 0.608005\n",
      "iteration 44 / 300: loss 0.608246\n",
      "iteration 44 / 300: loss 0.600709\n",
      "iteration 44 / 300: loss 0.602915\n",
      "iteration 44 / 300: loss 0.597664\n",
      "iteration 44 / 300: loss 0.594413\n",
      "iteration 44 / 300: loss 0.604853\n",
      "iteration 44 / 300: loss 0.616240\n",
      "iteration 44 / 300: loss 0.597151\n",
      "iteration 44 / 300: loss 0.603482\n",
      "iteration 44 / 300: loss 0.608482\n",
      "iteration 44 / 300: loss 0.606725\n",
      "iteration 44 / 300: loss 0.583904\n",
      "iteration 44 / 300: loss 0.605942\n",
      "iteration 45 / 300: loss 0.590131\n",
      "iteration 45 / 300: loss 0.592017\n",
      "iteration 45 / 300: loss 0.571335\n",
      "iteration 45 / 300: loss 0.595183\n",
      "iteration 45 / 300: loss 0.597674\n",
      "iteration 45 / 300: loss 0.600092\n",
      "iteration 45 / 300: loss 0.613505\n",
      "iteration 45 / 300: loss 0.596685\n",
      "iteration 45 / 300: loss 0.632975\n",
      "iteration 45 / 300: loss 0.585109\n",
      "iteration 45 / 300: loss 0.613262\n",
      "iteration 45 / 300: loss 0.591349\n",
      "iteration 45 / 300: loss 0.595997\n",
      "iteration 45 / 300: loss 0.575007\n",
      "iteration 45 / 300: loss 0.586547\n",
      "iteration 45 / 300: loss 0.612464\n",
      "iteration 45 / 300: loss 0.602646\n",
      "iteration 45 / 300: loss 0.587832\n",
      "iteration 45 / 300: loss 0.620028\n",
      "iteration 45 / 300: loss 0.595832\n",
      "iteration 45 / 300: loss 0.589813\n",
      "iteration 45 / 300: loss 0.596137\n",
      "iteration 45 / 300: loss 0.609055\n",
      "iteration 45 / 300: loss 0.599989\n",
      "iteration 45 / 300: loss 0.618905\n",
      "iteration 45 / 300: loss 0.612328\n",
      "iteration 45 / 300: loss 0.603204\n",
      "iteration 45 / 300: loss 0.593978\n",
      "iteration 45 / 300: loss 0.623087\n",
      "iteration 45 / 300: loss 0.599547\n",
      "iteration 45 / 300: loss 0.606457\n",
      "iteration 45 / 300: loss 0.635541\n",
      "iteration 45 / 300: loss 0.591773\n",
      "iteration 45 / 300: loss 0.610655\n",
      "iteration 45 / 300: loss 0.593447\n",
      "iteration 45 / 300: loss 0.606506\n",
      "iteration 45 / 300: loss 0.600641\n",
      "iteration 45 / 300: loss 0.594784\n",
      "iteration 45 / 300: loss 0.603627\n",
      "iteration 45 / 300: loss 0.609030\n",
      "iteration 45 / 300: loss 0.624354\n",
      "iteration 45 / 300: loss 0.593863\n",
      "iteration 45 / 300: loss 0.598722\n",
      "iteration 45 / 300: loss 0.591675\n",
      "iteration 45 / 300: loss 0.616106\n",
      "iteration 45 / 300: loss 0.591792\n",
      "iteration 45 / 300: loss 0.582934\n",
      "iteration 45 / 300: loss 0.572150\n",
      "iteration 45 / 300: loss 0.565452\n",
      "iteration 45 / 300: loss 0.598708\n",
      "iteration 45 / 300: loss 0.582675\n",
      "iteration 45 / 300: loss 0.590705\n",
      "iteration 45 / 300: loss 0.577176\n",
      "iteration 45 / 300: loss 0.600064\n",
      "iteration 45 / 300: loss 0.611951\n",
      "iteration 45 / 300: loss 0.614100\n",
      "iteration 45 / 300: loss 0.611096\n",
      "iteration 45 / 300: loss 0.587468\n",
      "iteration 45 / 300: loss 0.593459\n",
      "iteration 45 / 300: loss 0.599798\n",
      "iteration 45 / 300: loss 0.602779\n",
      "iteration 45 / 300: loss 0.600274\n",
      "iteration 45 / 300: loss 0.592967\n",
      "iteration 45 / 300: loss 0.595142\n",
      "iteration 45 / 300: loss 0.588222\n",
      "iteration 45 / 300: loss 0.604404\n",
      "iteration 45 / 300: loss 0.602795\n",
      "iteration 45 / 300: loss 0.618050\n",
      "iteration 45 / 300: loss 0.602059\n",
      "iteration 45 / 300: loss 0.603890\n",
      "iteration 45 / 300: loss 0.608083\n",
      "iteration 45 / 300: loss 0.597892\n",
      "iteration 45 / 300: loss 0.597218\n",
      "iteration 45 / 300: loss 0.593434\n",
      "iteration 45 / 300: loss 0.601687\n",
      "iteration 45 / 300: loss 0.610436\n",
      "iteration 45 / 300: loss 0.614830\n",
      "iteration 45 / 300: loss 0.592134\n",
      "iteration 45 / 300: loss 0.602907\n",
      "iteration 45 / 300: loss 0.606516\n",
      "iteration 45 / 300: loss 0.609206\n",
      "iteration 45 / 300: loss 0.608644\n",
      "iteration 45 / 300: loss 0.627995\n",
      "iteration 45 / 300: loss 0.591165\n",
      "iteration 45 / 300: loss 0.584942\n",
      "iteration 45 / 300: loss 0.630171\n",
      "iteration 45 / 300: loss 0.607637\n",
      "iteration 45 / 300: loss 0.607956\n",
      "iteration 45 / 300: loss 0.600305\n",
      "iteration 45 / 300: loss 0.602491\n",
      "iteration 45 / 300: loss 0.597263\n",
      "iteration 45 / 300: loss 0.594028\n",
      "iteration 45 / 300: loss 0.604398\n",
      "iteration 45 / 300: loss 0.615810\n",
      "iteration 45 / 300: loss 0.596801\n",
      "iteration 45 / 300: loss 0.603237\n",
      "iteration 45 / 300: loss 0.608111\n",
      "iteration 45 / 300: loss 0.606441\n",
      "iteration 45 / 300: loss 0.583598\n",
      "iteration 45 / 300: loss 0.605627\n",
      "iteration 46 / 300: loss 0.589768\n",
      "iteration 46 / 300: loss 0.591740\n",
      "iteration 46 / 300: loss 0.571065\n",
      "iteration 46 / 300: loss 0.595025\n",
      "iteration 46 / 300: loss 0.597370\n",
      "iteration 46 / 300: loss 0.599746\n",
      "iteration 46 / 300: loss 0.613116\n",
      "iteration 46 / 300: loss 0.596419\n",
      "iteration 46 / 300: loss 0.632577\n",
      "iteration 46 / 300: loss 0.584704\n",
      "iteration 46 / 300: loss 0.612792\n",
      "iteration 46 / 300: loss 0.591049\n",
      "iteration 46 / 300: loss 0.595645\n",
      "iteration 46 / 300: loss 0.574707\n",
      "iteration 46 / 300: loss 0.586263\n",
      "iteration 46 / 300: loss 0.612123\n",
      "iteration 46 / 300: loss 0.602305\n",
      "iteration 46 / 300: loss 0.587531\n",
      "iteration 46 / 300: loss 0.619639\n",
      "iteration 46 / 300: loss 0.595529\n",
      "iteration 46 / 300: loss 0.589484\n",
      "iteration 46 / 300: loss 0.595764\n",
      "iteration 46 / 300: loss 0.608694\n",
      "iteration 46 / 300: loss 0.599693\n",
      "iteration 46 / 300: loss 0.618512\n",
      "iteration 46 / 300: loss 0.612008\n",
      "iteration 46 / 300: loss 0.602787\n",
      "iteration 46 / 300: loss 0.593522\n",
      "iteration 46 / 300: loss 0.622634\n",
      "iteration 46 / 300: loss 0.599169\n",
      "iteration 46 / 300: loss 0.606115\n",
      "iteration 46 / 300: loss 0.635273\n",
      "iteration 46 / 300: loss 0.591448\n",
      "iteration 46 / 300: loss 0.610367\n",
      "iteration 46 / 300: loss 0.592997\n",
      "iteration 46 / 300: loss 0.606072\n",
      "iteration 46 / 300: loss 0.600274\n",
      "iteration 46 / 300: loss 0.594383\n",
      "iteration 46 / 300: loss 0.603378\n",
      "iteration 46 / 300: loss 0.608716\n",
      "iteration 46 / 300: loss 0.623983\n",
      "iteration 46 / 300: loss 0.593541\n",
      "iteration 46 / 300: loss 0.598378\n",
      "iteration 46 / 300: loss 0.591152\n",
      "iteration 46 / 300: loss 0.615971\n",
      "iteration 46 / 300: loss 0.591480\n",
      "iteration 46 / 300: loss 0.582624\n",
      "iteration 46 / 300: loss 0.571794\n",
      "iteration 46 / 300: loss 0.565207\n",
      "iteration 46 / 300: loss 0.598346\n",
      "iteration 46 / 300: loss 0.582380\n",
      "iteration 46 / 300: loss 0.590332\n",
      "iteration 46 / 300: loss 0.576853\n",
      "iteration 46 / 300: loss 0.599796\n",
      "iteration 46 / 300: loss 0.611590\n",
      "iteration 46 / 300: loss 0.613817\n",
      "iteration 46 / 300: loss 0.610672\n",
      "iteration 46 / 300: loss 0.587180\n",
      "iteration 46 / 300: loss 0.593121\n",
      "iteration 46 / 300: loss 0.599417\n",
      "iteration 46 / 300: loss 0.602446\n",
      "iteration 46 / 300: loss 0.599961\n",
      "iteration 46 / 300: loss 0.592740\n",
      "iteration 46 / 300: loss 0.594805\n",
      "iteration 46 / 300: loss 0.587970\n",
      "iteration 46 / 300: loss 0.603996\n",
      "iteration 46 / 300: loss 0.602446\n",
      "iteration 46 / 300: loss 0.617646\n",
      "iteration 46 / 300: loss 0.601693\n",
      "iteration 46 / 300: loss 0.603454\n",
      "iteration 46 / 300: loss 0.607682\n",
      "iteration 46 / 300: loss 0.597470\n",
      "iteration 46 / 300: loss 0.596841\n",
      "iteration 46 / 300: loss 0.593058\n",
      "iteration 46 / 300: loss 0.601270\n",
      "iteration 46 / 300: loss 0.610046\n",
      "iteration 46 / 300: loss 0.614478\n",
      "iteration 46 / 300: loss 0.591750\n",
      "iteration 46 / 300: loss 0.602626\n",
      "iteration 46 / 300: loss 0.606215\n",
      "iteration 46 / 300: loss 0.608870\n",
      "iteration 46 / 300: loss 0.608287\n",
      "iteration 46 / 300: loss 0.627669\n",
      "iteration 46 / 300: loss 0.590811\n",
      "iteration 46 / 300: loss 0.584607\n",
      "iteration 46 / 300: loss 0.629787\n",
      "iteration 46 / 300: loss 0.607296\n",
      "iteration 46 / 300: loss 0.607690\n",
      "iteration 46 / 300: loss 0.599921\n",
      "iteration 46 / 300: loss 0.602088\n",
      "iteration 46 / 300: loss 0.596893\n",
      "iteration 46 / 300: loss 0.593662\n",
      "iteration 46 / 300: loss 0.603969\n",
      "iteration 46 / 300: loss 0.615416\n",
      "iteration 46 / 300: loss 0.596468\n",
      "iteration 46 / 300: loss 0.603000\n",
      "iteration 46 / 300: loss 0.607751\n",
      "iteration 46 / 300: loss 0.606165\n",
      "iteration 46 / 300: loss 0.583308\n",
      "iteration 46 / 300: loss 0.605324\n",
      "iteration 47 / 300: loss 0.589424\n",
      "iteration 47 / 300: loss 0.591486\n",
      "iteration 47 / 300: loss 0.570812\n",
      "iteration 47 / 300: loss 0.594872\n",
      "iteration 47 / 300: loss 0.597084\n",
      "iteration 47 / 300: loss 0.599411\n",
      "iteration 47 / 300: loss 0.612752\n",
      "iteration 47 / 300: loss 0.596160\n",
      "iteration 47 / 300: loss 0.632206\n",
      "iteration 47 / 300: loss 0.584335\n",
      "iteration 47 / 300: loss 0.612357\n",
      "iteration 47 / 300: loss 0.590769\n",
      "iteration 47 / 300: loss 0.595323\n",
      "iteration 47 / 300: loss 0.574435\n",
      "iteration 47 / 300: loss 0.586007\n",
      "iteration 47 / 300: loss 0.611809\n",
      "iteration 47 / 300: loss 0.601991\n",
      "iteration 47 / 300: loss 0.587243\n",
      "iteration 47 / 300: loss 0.619276\n",
      "iteration 47 / 300: loss 0.595244\n",
      "iteration 47 / 300: loss 0.589173\n",
      "iteration 47 / 300: loss 0.595409\n",
      "iteration 47 / 300: loss 0.608358\n",
      "iteration 47 / 300: loss 0.599421\n",
      "iteration 47 / 300: loss 0.618157\n",
      "iteration 47 / 300: loss 0.611709\n",
      "iteration 47 / 300: loss 0.602400\n",
      "iteration 47 / 300: loss 0.593096\n",
      "iteration 47 / 300: loss 0.622212\n",
      "iteration 47 / 300: loss 0.598816\n",
      "iteration 47 / 300: loss 0.605792\n",
      "iteration 47 / 300: loss 0.635009\n",
      "iteration 47 / 300: loss 0.591149\n",
      "iteration 47 / 300: loss 0.610092\n",
      "iteration 47 / 300: loss 0.592578\n",
      "iteration 47 / 300: loss 0.605662\n",
      "iteration 47 / 300: loss 0.599926\n",
      "iteration 47 / 300: loss 0.594000\n",
      "iteration 47 / 300: loss 0.603138\n",
      "iteration 47 / 300: loss 0.608418\n",
      "iteration 47 / 300: loss 0.623624\n",
      "iteration 47 / 300: loss 0.593220\n",
      "iteration 47 / 300: loss 0.598041\n",
      "iteration 47 / 300: loss 0.590664\n",
      "iteration 47 / 300: loss 0.615829\n",
      "iteration 47 / 300: loss 0.591187\n",
      "iteration 47 / 300: loss 0.582322\n",
      "iteration 47 / 300: loss 0.571452\n",
      "iteration 47 / 300: loss 0.564979\n",
      "iteration 47 / 300: loss 0.598006\n",
      "iteration 47 / 300: loss 0.582101\n",
      "iteration 47 / 300: loss 0.589985\n",
      "iteration 47 / 300: loss 0.576546\n",
      "iteration 47 / 300: loss 0.599541\n",
      "iteration 47 / 300: loss 0.611262\n",
      "iteration 47 / 300: loss 0.613562\n",
      "iteration 47 / 300: loss 0.610283\n",
      "iteration 47 / 300: loss 0.586914\n",
      "iteration 47 / 300: loss 0.592811\n",
      "iteration 47 / 300: loss 0.599062\n",
      "iteration 47 / 300: loss 0.602146\n",
      "iteration 47 / 300: loss 0.599672\n",
      "iteration 47 / 300: loss 0.592527\n",
      "iteration 47 / 300: loss 0.594497\n",
      "iteration 47 / 300: loss 0.587732\n",
      "iteration 47 / 300: loss 0.603614\n",
      "iteration 47 / 300: loss 0.602126\n",
      "iteration 47 / 300: loss 0.617286\n",
      "iteration 47 / 300: loss 0.601357\n",
      "iteration 47 / 300: loss 0.603055\n",
      "iteration 47 / 300: loss 0.607314\n",
      "iteration 47 / 300: loss 0.597077\n",
      "iteration 47 / 300: loss 0.596483\n",
      "iteration 47 / 300: loss 0.592706\n",
      "iteration 47 / 300: loss 0.600881\n",
      "iteration 47 / 300: loss 0.609684\n",
      "iteration 47 / 300: loss 0.614146\n",
      "iteration 47 / 300: loss 0.591388\n",
      "iteration 47 / 300: loss 0.602356\n",
      "iteration 47 / 300: loss 0.605938\n",
      "iteration 47 / 300: loss 0.608556\n",
      "iteration 47 / 300: loss 0.607949\n",
      "iteration 47 / 300: loss 0.627363\n",
      "iteration 47 / 300: loss 0.590479\n",
      "iteration 47 / 300: loss 0.584292\n",
      "iteration 47 / 300: loss 0.629419\n",
      "iteration 47 / 300: loss 0.606980\n",
      "iteration 47 / 300: loss 0.607445\n",
      "iteration 47 / 300: loss 0.599560\n",
      "iteration 47 / 300: loss 0.601711\n",
      "iteration 47 / 300: loss 0.596552\n",
      "iteration 47 / 300: loss 0.593317\n",
      "iteration 47 / 300: loss 0.603567\n",
      "iteration 47 / 300: loss 0.615054\n",
      "iteration 47 / 300: loss 0.596152\n",
      "iteration 47 / 300: loss 0.602769\n",
      "iteration 47 / 300: loss 0.607403\n",
      "iteration 47 / 300: loss 0.605900\n",
      "iteration 47 / 300: loss 0.583035\n",
      "iteration 47 / 300: loss 0.605036\n",
      "iteration 48 / 300: loss 0.589102\n",
      "iteration 48 / 300: loss 0.591253\n",
      "iteration 48 / 300: loss 0.570574\n",
      "iteration 48 / 300: loss 0.594722\n",
      "iteration 48 / 300: loss 0.596815\n",
      "iteration 48 / 300: loss 0.599090\n",
      "iteration 48 / 300: loss 0.612413\n",
      "iteration 48 / 300: loss 0.595910\n",
      "iteration 48 / 300: loss 0.631862\n",
      "iteration 48 / 300: loss 0.583997\n",
      "iteration 48 / 300: loss 0.611957\n",
      "iteration 48 / 300: loss 0.590508\n",
      "iteration 48 / 300: loss 0.595027\n",
      "iteration 48 / 300: loss 0.574188\n",
      "iteration 48 / 300: loss 0.585776\n",
      "iteration 48 / 300: loss 0.611518\n",
      "iteration 48 / 300: loss 0.601701\n",
      "iteration 48 / 300: loss 0.586971\n",
      "iteration 48 / 300: loss 0.618940\n",
      "iteration 48 / 300: loss 0.594975\n",
      "iteration 48 / 300: loss 0.588880\n",
      "iteration 48 / 300: loss 0.595074\n",
      "iteration 48 / 300: loss 0.608043\n",
      "iteration 48 / 300: loss 0.599167\n",
      "iteration 48 / 300: loss 0.617838\n",
      "iteration 48 / 300: loss 0.611430\n",
      "iteration 48 / 300: loss 0.602041\n",
      "iteration 48 / 300: loss 0.592701\n",
      "iteration 48 / 300: loss 0.621822\n",
      "iteration 48 / 300: loss 0.598486\n",
      "iteration 48 / 300: loss 0.605487\n",
      "iteration 48 / 300: loss 0.634752\n",
      "iteration 48 / 300: loss 0.590873\n",
      "iteration 48 / 300: loss 0.609830\n",
      "iteration 48 / 300: loss 0.592188\n",
      "iteration 48 / 300: loss 0.605277\n",
      "iteration 48 / 300: loss 0.599597\n",
      "iteration 48 / 300: loss 0.593637\n",
      "iteration 48 / 300: loss 0.602908\n",
      "iteration 48 / 300: loss 0.608139\n",
      "iteration 48 / 300: loss 0.623282\n",
      "iteration 48 / 300: loss 0.592905\n",
      "iteration 48 / 300: loss 0.597714\n",
      "iteration 48 / 300: loss 0.590213\n",
      "iteration 48 / 300: loss 0.615683\n",
      "iteration 48 / 300: loss 0.590911\n",
      "iteration 48 / 300: loss 0.582030\n",
      "iteration 48 / 300: loss 0.571124\n",
      "iteration 48 / 300: loss 0.564767\n",
      "iteration 48 / 300: loss 0.597687\n",
      "iteration 48 / 300: loss 0.581837\n",
      "iteration 48 / 300: loss 0.589663\n",
      "iteration 48 / 300: loss 0.576255\n",
      "iteration 48 / 300: loss 0.599298\n",
      "iteration 48 / 300: loss 0.610965\n",
      "iteration 48 / 300: loss 0.613329\n",
      "iteration 48 / 300: loss 0.609928\n",
      "iteration 48 / 300: loss 0.586666\n",
      "iteration 48 / 300: loss 0.592528\n",
      "iteration 48 / 300: loss 0.598731\n",
      "iteration 48 / 300: loss 0.601873\n",
      "iteration 48 / 300: loss 0.599402\n",
      "iteration 48 / 300: loss 0.592325\n",
      "iteration 48 / 300: loss 0.594215\n",
      "iteration 48 / 300: loss 0.587506\n",
      "iteration 48 / 300: loss 0.603257\n",
      "iteration 48 / 300: loss 0.601831\n",
      "iteration 48 / 300: loss 0.616968\n",
      "iteration 48 / 300: loss 0.601046\n",
      "iteration 48 / 300: loss 0.602694\n",
      "iteration 48 / 300: loss 0.606976\n",
      "iteration 48 / 300: loss 0.596710\n",
      "iteration 48 / 300: loss 0.596146\n",
      "iteration 48 / 300: loss 0.592378\n",
      "iteration 48 / 300: loss 0.600517\n",
      "iteration 48 / 300: loss 0.609348\n",
      "iteration 48 / 300: loss 0.613836\n",
      "iteration 48 / 300: loss 0.591052\n",
      "iteration 48 / 300: loss 0.602100\n",
      "iteration 48 / 300: loss 0.605681\n",
      "iteration 48 / 300: loss 0.608265\n",
      "iteration 48 / 300: loss 0.607630\n",
      "iteration 48 / 300: loss 0.627077\n",
      "iteration 48 / 300: loss 0.590170\n",
      "iteration 48 / 300: loss 0.583997\n",
      "iteration 48 / 300: loss 0.629069\n",
      "iteration 48 / 300: loss 0.606686\n",
      "iteration 48 / 300: loss 0.607217\n",
      "iteration 48 / 300: loss 0.599222\n",
      "iteration 48 / 300: loss 0.601358\n",
      "iteration 48 / 300: loss 0.596238\n",
      "iteration 48 / 300: loss 0.592993\n",
      "iteration 48 / 300: loss 0.603193\n",
      "iteration 48 / 300: loss 0.614723\n",
      "iteration 48 / 300: loss 0.595856\n",
      "iteration 48 / 300: loss 0.602545\n",
      "iteration 48 / 300: loss 0.607070\n",
      "iteration 48 / 300: loss 0.605647\n",
      "iteration 48 / 300: loss 0.582778\n",
      "iteration 48 / 300: loss 0.604763\n",
      "iteration 49 / 300: loss 0.588801\n",
      "iteration 49 / 300: loss 0.591037\n",
      "iteration 49 / 300: loss 0.570349\n",
      "iteration 49 / 300: loss 0.594575\n",
      "iteration 49 / 300: loss 0.596562\n",
      "iteration 49 / 300: loss 0.598785\n",
      "iteration 49 / 300: loss 0.612098\n",
      "iteration 49 / 300: loss 0.595671\n",
      "iteration 49 / 300: loss 0.631543\n",
      "iteration 49 / 300: loss 0.583686\n",
      "iteration 49 / 300: loss 0.611589\n",
      "iteration 49 / 300: loss 0.590265\n",
      "iteration 49 / 300: loss 0.594754\n",
      "iteration 49 / 300: loss 0.573962\n",
      "iteration 49 / 300: loss 0.585566\n",
      "iteration 49 / 300: loss 0.611248\n",
      "iteration 49 / 300: loss 0.601434\n",
      "iteration 49 / 300: loss 0.586714\n",
      "iteration 49 / 300: loss 0.618627\n",
      "iteration 49 / 300: loss 0.594720\n",
      "iteration 49 / 300: loss 0.588604\n",
      "iteration 49 / 300: loss 0.594760\n",
      "iteration 49 / 300: loss 0.607748\n",
      "iteration 49 / 300: loss 0.598928\n",
      "iteration 49 / 300: loss 0.617553\n",
      "iteration 49 / 300: loss 0.611171\n",
      "iteration 49 / 300: loss 0.601711\n",
      "iteration 49 / 300: loss 0.592339\n",
      "iteration 49 / 300: loss 0.621461\n",
      "iteration 49 / 300: loss 0.598180\n",
      "iteration 49 / 300: loss 0.605199\n",
      "iteration 49 / 300: loss 0.634502\n",
      "iteration 49 / 300: loss 0.590617\n",
      "iteration 49 / 300: loss 0.609582\n",
      "iteration 49 / 300: loss 0.591827\n",
      "iteration 49 / 300: loss 0.604916\n",
      "iteration 49 / 300: loss 0.599288\n",
      "iteration 49 / 300: loss 0.593295\n",
      "iteration 49 / 300: loss 0.602687\n",
      "iteration 49 / 300: loss 0.607877\n",
      "iteration 49 / 300: loss 0.622960\n",
      "iteration 49 / 300: loss 0.592598\n",
      "iteration 49 / 300: loss 0.597402\n",
      "iteration 49 / 300: loss 0.589796\n",
      "iteration 49 / 300: loss 0.615534\n",
      "iteration 49 / 300: loss 0.590650\n",
      "iteration 49 / 300: loss 0.581751\n",
      "iteration 49 / 300: loss 0.570812\n",
      "iteration 49 / 300: loss 0.564570\n",
      "iteration 49 / 300: loss 0.597390\n",
      "iteration 49 / 300: loss 0.581588\n",
      "iteration 49 / 300: loss 0.589365\n",
      "iteration 49 / 300: loss 0.575981\n",
      "iteration 49 / 300: loss 0.599067\n",
      "iteration 49 / 300: loss 0.610695\n",
      "iteration 49 / 300: loss 0.613116\n",
      "iteration 49 / 300: loss 0.609603\n",
      "iteration 49 / 300: loss 0.586436\n",
      "iteration 49 / 300: loss 0.592268\n",
      "iteration 49 / 300: loss 0.598424\n",
      "iteration 49 / 300: loss 0.601625\n",
      "iteration 49 / 300: loss 0.599150\n",
      "iteration 49 / 300: loss 0.592135\n",
      "iteration 49 / 300: loss 0.593956\n",
      "iteration 49 / 300: loss 0.587294\n",
      "iteration 49 / 300: loss 0.602925\n",
      "iteration 49 / 300: loss 0.601562\n",
      "iteration 49 / 300: loss 0.616687\n",
      "iteration 49 / 300: loss 0.600760\n",
      "iteration 49 / 300: loss 0.602367\n",
      "iteration 49 / 300: loss 0.606664\n",
      "iteration 49 / 300: loss 0.596370\n",
      "iteration 49 / 300: loss 0.595827\n",
      "iteration 49 / 300: loss 0.592074\n",
      "iteration 49 / 300: loss 0.600178\n",
      "iteration 49 / 300: loss 0.609038\n",
      "iteration 49 / 300: loss 0.613549\n",
      "iteration 49 / 300: loss 0.590744\n",
      "iteration 49 / 300: loss 0.601860\n",
      "iteration 49 / 300: loss 0.605445\n",
      "iteration 49 / 300: loss 0.607996\n",
      "iteration 49 / 300: loss 0.607329\n",
      "iteration 49 / 300: loss 0.626812\n",
      "iteration 49 / 300: loss 0.589886\n",
      "iteration 49 / 300: loss 0.583722\n",
      "iteration 49 / 300: loss 0.628740\n",
      "iteration 49 / 300: loss 0.606412\n",
      "iteration 49 / 300: loss 0.607004\n",
      "iteration 49 / 300: loss 0.598907\n",
      "iteration 49 / 300: loss 0.601030\n",
      "iteration 49 / 300: loss 0.595949\n",
      "iteration 49 / 300: loss 0.592691\n",
      "iteration 49 / 300: loss 0.602845\n",
      "iteration 49 / 300: loss 0.614421\n",
      "iteration 49 / 300: loss 0.595578\n",
      "iteration 49 / 300: loss 0.602328\n",
      "iteration 49 / 300: loss 0.606755\n",
      "iteration 49 / 300: loss 0.605406\n",
      "iteration 49 / 300: loss 0.582538\n",
      "iteration 49 / 300: loss 0.604507\n",
      "iteration 50 / 300: loss 0.588521\n",
      "iteration 50 / 300: loss 0.590836\n",
      "iteration 50 / 300: loss 0.570137\n",
      "iteration 50 / 300: loss 0.594432\n",
      "iteration 50 / 300: loss 0.596325\n",
      "iteration 50 / 300: loss 0.598498\n",
      "iteration 50 / 300: loss 0.611806\n",
      "iteration 50 / 300: loss 0.595442\n",
      "iteration 50 / 300: loss 0.631248\n",
      "iteration 50 / 300: loss 0.583400\n",
      "iteration 50 / 300: loss 0.611253\n",
      "iteration 50 / 300: loss 0.590039\n",
      "iteration 50 / 300: loss 0.594502\n",
      "iteration 50 / 300: loss 0.573755\n",
      "iteration 50 / 300: loss 0.585374\n",
      "iteration 50 / 300: loss 0.610999\n",
      "iteration 50 / 300: loss 0.601186\n",
      "iteration 50 / 300: loss 0.586473\n",
      "iteration 50 / 300: loss 0.618337\n",
      "iteration 50 / 300: loss 0.594480\n",
      "iteration 50 / 300: loss 0.588345\n",
      "iteration 50 / 300: loss 0.594467\n",
      "iteration 50 / 300: loss 0.607472\n",
      "iteration 50 / 300: loss 0.598701\n",
      "iteration 50 / 300: loss 0.617297\n",
      "iteration 50 / 300: loss 0.610930\n",
      "iteration 50 / 300: loss 0.601407\n",
      "iteration 50 / 300: loss 0.592008\n",
      "iteration 50 / 300: loss 0.621128\n",
      "iteration 50 / 300: loss 0.597895\n",
      "iteration 50 / 300: loss 0.604927\n",
      "iteration 50 / 300: loss 0.634260\n",
      "iteration 50 / 300: loss 0.590380\n",
      "iteration 50 / 300: loss 0.609349\n",
      "iteration 50 / 300: loss 0.591492\n",
      "iteration 50 / 300: loss 0.604578\n",
      "iteration 50 / 300: loss 0.598999\n",
      "iteration 50 / 300: loss 0.592974\n",
      "iteration 50 / 300: loss 0.602475\n",
      "iteration 50 / 300: loss 0.607633\n",
      "iteration 50 / 300: loss 0.622658\n",
      "iteration 50 / 300: loss 0.592304\n",
      "iteration 50 / 300: loss 0.597106\n",
      "iteration 50 / 300: loss 0.589414\n",
      "iteration 50 / 300: loss 0.615386\n",
      "iteration 50 / 300: loss 0.590403\n",
      "iteration 50 / 300: loss 0.581485\n",
      "iteration 50 / 300: loss 0.570519\n",
      "iteration 50 / 300: loss 0.564386\n",
      "iteration 50 / 300: loss 0.597114\n",
      "iteration 50 / 300: loss 0.581354\n",
      "iteration 50 / 300: loss 0.589091\n",
      "iteration 50 / 300: loss 0.575723\n",
      "iteration 50 / 300: loss 0.598848\n",
      "iteration 50 / 300: loss 0.610450\n",
      "iteration 50 / 300: loss 0.612921\n",
      "iteration 50 / 300: loss 0.609307\n",
      "iteration 50 / 300: loss 0.586222\n",
      "iteration 50 / 300: loss 0.592032\n",
      "iteration 50 / 300: loss 0.598140\n",
      "iteration 50 / 300: loss 0.601398\n",
      "iteration 50 / 300: loss 0.598916\n",
      "iteration 50 / 300: loss 0.591957\n",
      "iteration 50 / 300: loss 0.593718\n",
      "iteration 50 / 300: loss 0.587096\n",
      "iteration 50 / 300: loss 0.602619\n",
      "iteration 50 / 300: loss 0.601317\n",
      "iteration 50 / 300: loss 0.616441\n",
      "iteration 50 / 300: loss 0.600498\n",
      "iteration 50 / 300: loss 0.602072\n",
      "iteration 50 / 300: loss 0.606378\n",
      "iteration 50 / 300: loss 0.596055\n",
      "iteration 50 / 300: loss 0.595530\n",
      "iteration 50 / 300: loss 0.591795\n",
      "iteration 50 / 300: loss 0.599863\n",
      "iteration 50 / 300: loss 0.608752\n",
      "iteration 50 / 300: loss 0.613284\n",
      "iteration 50 / 300: loss 0.590462\n",
      "iteration 50 / 300: loss 0.601636\n",
      "iteration 50 / 300: loss 0.605227\n",
      "iteration 50 / 300: loss 0.607748\n",
      "iteration 50 / 300: loss 0.607048\n",
      "iteration 50 / 300: loss 0.626568\n",
      "iteration 50 / 300: loss 0.589627\n",
      "iteration 50 / 300: loss 0.583466\n",
      "iteration 50 / 300: loss 0.628431\n",
      "iteration 50 / 300: loss 0.606157\n",
      "iteration 50 / 300: loss 0.606805\n",
      "iteration 50 / 300: loss 0.598615\n",
      "iteration 50 / 300: loss 0.600728\n",
      "iteration 50 / 300: loss 0.595683\n",
      "iteration 50 / 300: loss 0.592409\n",
      "iteration 50 / 300: loss 0.602523\n",
      "iteration 50 / 300: loss 0.614144\n",
      "iteration 50 / 300: loss 0.595319\n",
      "iteration 50 / 300: loss 0.602119\n",
      "iteration 50 / 300: loss 0.606457\n",
      "iteration 50 / 300: loss 0.605178\n",
      "iteration 50 / 300: loss 0.582315\n",
      "iteration 50 / 300: loss 0.604267\n",
      "iteration 51 / 300: loss 0.588262\n",
      "iteration 51 / 300: loss 0.590650\n",
      "iteration 51 / 300: loss 0.569936\n",
      "iteration 51 / 300: loss 0.594294\n",
      "iteration 51 / 300: loss 0.596102\n",
      "iteration 51 / 300: loss 0.598229\n",
      "iteration 51 / 300: loss 0.611537\n",
      "iteration 51 / 300: loss 0.595227\n",
      "iteration 51 / 300: loss 0.630975\n",
      "iteration 51 / 300: loss 0.583136\n",
      "iteration 51 / 300: loss 0.610947\n",
      "iteration 51 / 300: loss 0.589830\n",
      "iteration 51 / 300: loss 0.594268\n",
      "iteration 51 / 300: loss 0.573565\n",
      "iteration 51 / 300: loss 0.585197\n",
      "iteration 51 / 300: loss 0.610768\n",
      "iteration 51 / 300: loss 0.600956\n",
      "iteration 51 / 300: loss 0.586249\n",
      "iteration 51 / 300: loss 0.618070\n",
      "iteration 51 / 300: loss 0.594253\n",
      "iteration 51 / 300: loss 0.588104\n",
      "iteration 51 / 300: loss 0.594196\n",
      "iteration 51 / 300: loss 0.607212\n",
      "iteration 51 / 300: loss 0.598485\n",
      "iteration 51 / 300: loss 0.617070\n",
      "iteration 51 / 300: loss 0.610707\n",
      "iteration 51 / 300: loss 0.601128\n",
      "iteration 51 / 300: loss 0.591708\n",
      "iteration 51 / 300: loss 0.620822\n",
      "iteration 51 / 300: loss 0.597630\n",
      "iteration 51 / 300: loss 0.604671\n",
      "iteration 51 / 300: loss 0.634027\n",
      "iteration 51 / 300: loss 0.590160\n",
      "iteration 51 / 300: loss 0.609129\n",
      "iteration 51 / 300: loss 0.591183\n",
      "iteration 51 / 300: loss 0.604264\n",
      "iteration 51 / 300: loss 0.598731\n",
      "iteration 51 / 300: loss 0.592674\n",
      "iteration 51 / 300: loss 0.602273\n",
      "iteration 51 / 300: loss 0.607406\n",
      "iteration 51 / 300: loss 0.622377\n",
      "iteration 51 / 300: loss 0.592024\n",
      "iteration 51 / 300: loss 0.596826\n",
      "iteration 51 / 300: loss 0.589063\n",
      "iteration 51 / 300: loss 0.615239\n",
      "iteration 51 / 300: loss 0.590171\n",
      "iteration 51 / 300: loss 0.581235\n",
      "iteration 51 / 300: loss 0.570244\n",
      "iteration 51 / 300: loss 0.564214\n",
      "iteration 51 / 300: loss 0.596859\n",
      "iteration 51 / 300: loss 0.581135\n",
      "iteration 51 / 300: loss 0.588839\n",
      "iteration 51 / 300: loss 0.575483\n",
      "iteration 51 / 300: loss 0.598640\n",
      "iteration 51 / 300: loss 0.610227\n",
      "iteration 51 / 300: loss 0.612741\n",
      "iteration 51 / 300: loss 0.609036\n",
      "iteration 51 / 300: loss 0.586023\n",
      "iteration 51 / 300: loss 0.591815\n",
      "iteration 51 / 300: loss 0.597879\n",
      "iteration 51 / 300: loss 0.601190\n",
      "iteration 51 / 300: loss 0.598696\n",
      "iteration 51 / 300: loss 0.591791\n",
      "iteration 51 / 300: loss 0.593499\n",
      "iteration 51 / 300: loss 0.586912\n",
      "iteration 51 / 300: loss 0.602339\n",
      "iteration 51 / 300: loss 0.601093\n",
      "iteration 51 / 300: loss 0.616225\n",
      "iteration 51 / 300: loss 0.600257\n",
      "iteration 51 / 300: loss 0.601806\n",
      "iteration 51 / 300: loss 0.606114\n",
      "iteration 51 / 300: loss 0.595765\n",
      "iteration 51 / 300: loss 0.595252\n",
      "iteration 51 / 300: loss 0.591541\n",
      "iteration 51 / 300: loss 0.599570\n",
      "iteration 51 / 300: loss 0.608488\n",
      "iteration 51 / 300: loss 0.613041\n",
      "iteration 51 / 300: loss 0.590206\n",
      "iteration 51 / 300: loss 0.601427\n",
      "iteration 51 / 300: loss 0.605026\n",
      "iteration 51 / 300: loss 0.607520\n",
      "iteration 51 / 300: loss 0.606785\n",
      "iteration 51 / 300: loss 0.626345\n",
      "iteration 51 / 300: loss 0.589392\n",
      "iteration 51 / 300: loss 0.583230\n",
      "iteration 51 / 300: loss 0.628143\n",
      "iteration 51 / 300: loss 0.605920\n",
      "iteration 51 / 300: loss 0.606617\n",
      "iteration 51 / 300: loss 0.598345\n",
      "iteration 51 / 300: loss 0.600450\n",
      "iteration 51 / 300: loss 0.595437\n",
      "iteration 51 / 300: loss 0.592149\n",
      "iteration 51 / 300: loss 0.602226\n",
      "iteration 51 / 300: loss 0.613892\n",
      "iteration 51 / 300: loss 0.595078\n",
      "iteration 51 / 300: loss 0.601919\n",
      "iteration 51 / 300: loss 0.606179\n",
      "iteration 51 / 300: loss 0.604963\n",
      "iteration 51 / 300: loss 0.582107\n",
      "iteration 51 / 300: loss 0.604044\n",
      "iteration 52 / 300: loss 0.588022\n",
      "iteration 52 / 300: loss 0.590477\n",
      "iteration 52 / 300: loss 0.569747\n",
      "iteration 52 / 300: loss 0.594161\n",
      "iteration 52 / 300: loss 0.595894\n",
      "iteration 52 / 300: loss 0.597978\n",
      "iteration 52 / 300: loss 0.611289\n",
      "iteration 52 / 300: loss 0.595024\n",
      "iteration 52 / 300: loss 0.630723\n",
      "iteration 52 / 300: loss 0.582892\n",
      "iteration 52 / 300: loss 0.610667\n",
      "iteration 52 / 300: loss 0.589636\n",
      "iteration 52 / 300: loss 0.594052\n",
      "iteration 52 / 300: loss 0.573391\n",
      "iteration 52 / 300: loss 0.585032\n",
      "iteration 52 / 300: loss 0.610556\n",
      "iteration 52 / 300: loss 0.600743\n",
      "iteration 52 / 300: loss 0.586041\n",
      "iteration 52 / 300: loss 0.617823\n",
      "iteration 52 / 300: loss 0.594041\n",
      "iteration 52 / 300: loss 0.587879\n",
      "iteration 52 / 300: loss 0.593945\n",
      "iteration 52 / 300: loss 0.606970\n",
      "iteration 52 / 300: loss 0.598279\n",
      "iteration 52 / 300: loss 0.616866\n",
      "iteration 52 / 300: loss 0.610501\n",
      "iteration 52 / 300: loss 0.600872\n",
      "iteration 52 / 300: loss 0.591436\n",
      "iteration 52 / 300: loss 0.620541\n",
      "iteration 52 / 300: loss 0.597385\n",
      "iteration 52 / 300: loss 0.604429\n",
      "iteration 52 / 300: loss 0.633804\n",
      "iteration 52 / 300: loss 0.589954\n",
      "iteration 52 / 300: loss 0.608924\n",
      "iteration 52 / 300: loss 0.590898\n",
      "iteration 52 / 300: loss 0.603972\n",
      "iteration 52 / 300: loss 0.598483\n",
      "iteration 52 / 300: loss 0.592394\n",
      "iteration 52 / 300: loss 0.602080\n",
      "iteration 52 / 300: loss 0.607195\n",
      "iteration 52 / 300: loss 0.622117\n",
      "iteration 52 / 300: loss 0.591759\n",
      "iteration 52 / 300: loss 0.596565\n",
      "iteration 52 / 300: loss 0.588744\n",
      "iteration 52 / 300: loss 0.615097\n",
      "iteration 52 / 300: loss 0.589952\n",
      "iteration 52 / 300: loss 0.580999\n",
      "iteration 52 / 300: loss 0.569989\n",
      "iteration 52 / 300: loss 0.564054\n",
      "iteration 52 / 300: loss 0.596624\n",
      "iteration 52 / 300: loss 0.580932\n",
      "iteration 52 / 300: loss 0.588609\n",
      "iteration 52 / 300: loss 0.575260\n",
      "iteration 52 / 300: loss 0.598444\n",
      "iteration 52 / 300: loss 0.610024\n",
      "iteration 52 / 300: loss 0.612576\n",
      "iteration 52 / 300: loss 0.608789\n",
      "iteration 52 / 300: loss 0.585838\n",
      "iteration 52 / 300: loss 0.591618\n",
      "iteration 52 / 300: loss 0.597640\n",
      "iteration 52 / 300: loss 0.601000\n",
      "iteration 52 / 300: loss 0.598491\n",
      "iteration 52 / 300: loss 0.591635\n",
      "iteration 52 / 300: loss 0.593298\n",
      "iteration 52 / 300: loss 0.586740\n",
      "iteration 52 / 300: loss 0.602083\n",
      "iteration 52 / 300: loss 0.600890\n",
      "iteration 52 / 300: loss 0.616034\n",
      "iteration 52 / 300: loss 0.600037\n",
      "iteration 52 / 300: loss 0.601566\n",
      "iteration 52 / 300: loss 0.605872\n",
      "iteration 52 / 300: loss 0.595498\n",
      "iteration 52 / 300: loss 0.594996\n",
      "iteration 52 / 300: loss 0.591309\n",
      "iteration 52 / 300: loss 0.599299\n",
      "iteration 52 / 300: loss 0.608245\n",
      "iteration 52 / 300: loss 0.612817\n",
      "iteration 52 / 300: loss 0.589975\n",
      "iteration 52 / 300: loss 0.601235\n",
      "iteration 52 / 300: loss 0.604840\n",
      "iteration 52 / 300: loss 0.607310\n",
      "iteration 52 / 300: loss 0.606541\n",
      "iteration 52 / 300: loss 0.626141\n",
      "iteration 52 / 300: loss 0.589178\n",
      "iteration 52 / 300: loss 0.583012\n",
      "iteration 52 / 300: loss 0.627874\n",
      "iteration 52 / 300: loss 0.605701\n",
      "iteration 52 / 300: loss 0.606441\n",
      "iteration 52 / 300: loss 0.598097\n",
      "iteration 52 / 300: loss 0.600194\n",
      "iteration 52 / 300: loss 0.595211\n",
      "iteration 52 / 300: loss 0.591910\n",
      "iteration 52 / 300: loss 0.601953\n",
      "iteration 52 / 300: loss 0.613661\n",
      "iteration 52 / 300: loss 0.594856\n",
      "iteration 52 / 300: loss 0.601728\n",
      "iteration 52 / 300: loss 0.605919\n",
      "iteration 52 / 300: loss 0.604762\n",
      "iteration 52 / 300: loss 0.581915\n",
      "iteration 52 / 300: loss 0.603837\n",
      "iteration 53 / 300: loss 0.587801\n",
      "iteration 53 / 300: loss 0.590315\n",
      "iteration 53 / 300: loss 0.569569\n",
      "iteration 53 / 300: loss 0.594033\n",
      "iteration 53 / 300: loss 0.595700\n",
      "iteration 53 / 300: loss 0.597746\n",
      "iteration 53 / 300: loss 0.611061\n",
      "iteration 53 / 300: loss 0.594835\n",
      "iteration 53 / 300: loss 0.630491\n",
      "iteration 53 / 300: loss 0.582667\n",
      "iteration 53 / 300: loss 0.610414\n",
      "iteration 53 / 300: loss 0.589456\n",
      "iteration 53 / 300: loss 0.593852\n",
      "iteration 53 / 300: loss 0.573230\n",
      "iteration 53 / 300: loss 0.584878\n",
      "iteration 53 / 300: loss 0.610361\n",
      "iteration 53 / 300: loss 0.600545\n",
      "iteration 53 / 300: loss 0.585849\n",
      "iteration 53 / 300: loss 0.617595\n",
      "iteration 53 / 300: loss 0.593843\n",
      "iteration 53 / 300: loss 0.587671\n",
      "iteration 53 / 300: loss 0.593713\n",
      "iteration 53 / 300: loss 0.606745\n",
      "iteration 53 / 300: loss 0.598083\n",
      "iteration 53 / 300: loss 0.616683\n",
      "iteration 53 / 300: loss 0.610311\n",
      "iteration 53 / 300: loss 0.600637\n",
      "iteration 53 / 300: loss 0.591190\n",
      "iteration 53 / 300: loss 0.620284\n",
      "iteration 53 / 300: loss 0.597158\n",
      "iteration 53 / 300: loss 0.604203\n",
      "iteration 53 / 300: loss 0.633592\n",
      "iteration 53 / 300: loss 0.589762\n",
      "iteration 53 / 300: loss 0.608733\n",
      "iteration 53 / 300: loss 0.590636\n",
      "iteration 53 / 300: loss 0.603702\n",
      "iteration 53 / 300: loss 0.598254\n",
      "iteration 53 / 300: loss 0.592132\n",
      "iteration 53 / 300: loss 0.601895\n",
      "iteration 53 / 300: loss 0.607000\n",
      "iteration 53 / 300: loss 0.621878\n",
      "iteration 53 / 300: loss 0.591511\n",
      "iteration 53 / 300: loss 0.596320\n",
      "iteration 53 / 300: loss 0.588453\n",
      "iteration 53 / 300: loss 0.614959\n",
      "iteration 53 / 300: loss 0.589748\n",
      "iteration 53 / 300: loss 0.580778\n",
      "iteration 53 / 300: loss 0.569753\n",
      "iteration 53 / 300: loss 0.563904\n",
      "iteration 53 / 300: loss 0.596408\n",
      "iteration 53 / 300: loss 0.580743\n",
      "iteration 53 / 300: loss 0.588400\n",
      "iteration 53 / 300: loss 0.575053\n",
      "iteration 53 / 300: loss 0.598260\n",
      "iteration 53 / 300: loss 0.609839\n",
      "iteration 53 / 300: loss 0.612424\n",
      "iteration 53 / 300: loss 0.608563\n",
      "iteration 53 / 300: loss 0.585667\n",
      "iteration 53 / 300: loss 0.591438\n",
      "iteration 53 / 300: loss 0.597420\n",
      "iteration 53 / 300: loss 0.600825\n",
      "iteration 53 / 300: loss 0.598300\n",
      "iteration 53 / 300: loss 0.591489\n",
      "iteration 53 / 300: loss 0.593112\n",
      "iteration 53 / 300: loss 0.586582\n",
      "iteration 53 / 300: loss 0.601850\n",
      "iteration 53 / 300: loss 0.600706\n",
      "iteration 53 / 300: loss 0.615866\n",
      "iteration 53 / 300: loss 0.599835\n",
      "iteration 53 / 300: loss 0.601350\n",
      "iteration 53 / 300: loss 0.605649\n",
      "iteration 53 / 300: loss 0.595254\n",
      "iteration 53 / 300: loss 0.594759\n",
      "iteration 53 / 300: loss 0.591099\n",
      "iteration 53 / 300: loss 0.599049\n",
      "iteration 53 / 300: loss 0.608021\n",
      "iteration 53 / 300: loss 0.612612\n",
      "iteration 53 / 300: loss 0.589766\n",
      "iteration 53 / 300: loss 0.601059\n",
      "iteration 53 / 300: loss 0.604668\n",
      "iteration 53 / 300: loss 0.607117\n",
      "iteration 53 / 300: loss 0.606313\n",
      "iteration 53 / 300: loss 0.625957\n",
      "iteration 53 / 300: loss 0.588986\n",
      "iteration 53 / 300: loss 0.582811\n",
      "iteration 53 / 300: loss 0.627624\n",
      "iteration 53 / 300: loss 0.605497\n",
      "iteration 53 / 300: loss 0.606276\n",
      "iteration 53 / 300: loss 0.597868\n",
      "iteration 53 / 300: loss 0.599959\n",
      "iteration 53 / 300: loss 0.595002\n",
      "iteration 53 / 300: loss 0.591691\n",
      "iteration 53 / 300: loss 0.601704\n",
      "iteration 53 / 300: loss 0.613451\n",
      "iteration 53 / 300: loss 0.594649\n",
      "iteration 53 / 300: loss 0.601548\n",
      "iteration 53 / 300: loss 0.605678\n",
      "iteration 53 / 300: loss 0.604573\n",
      "iteration 53 / 300: loss 0.581738\n",
      "iteration 53 / 300: loss 0.603646\n",
      "iteration 54 / 300: loss 0.587598\n",
      "iteration 54 / 300: loss 0.590165\n",
      "iteration 54 / 300: loss 0.569402\n",
      "iteration 54 / 300: loss 0.593911\n",
      "iteration 54 / 300: loss 0.595520\n",
      "iteration 54 / 300: loss 0.597531\n",
      "iteration 54 / 300: loss 0.610853\n",
      "iteration 54 / 300: loss 0.594659\n",
      "iteration 54 / 300: loss 0.630278\n",
      "iteration 54 / 300: loss 0.582459\n",
      "iteration 54 / 300: loss 0.610183\n",
      "iteration 54 / 300: loss 0.589289\n",
      "iteration 54 / 300: loss 0.593668\n",
      "iteration 54 / 300: loss 0.573082\n",
      "iteration 54 / 300: loss 0.584734\n",
      "iteration 54 / 300: loss 0.610181\n",
      "iteration 54 / 300: loss 0.600363\n",
      "iteration 54 / 300: loss 0.585672\n",
      "iteration 54 / 300: loss 0.617386\n",
      "iteration 54 / 300: loss 0.593658\n",
      "iteration 54 / 300: loss 0.587479\n",
      "iteration 54 / 300: loss 0.593501\n",
      "iteration 54 / 300: loss 0.606536\n",
      "iteration 54 / 300: loss 0.597899\n",
      "iteration 54 / 300: loss 0.616519\n",
      "iteration 54 / 300: loss 0.610136\n",
      "iteration 54 / 300: loss 0.600421\n",
      "iteration 54 / 300: loss 0.590969\n",
      "iteration 54 / 300: loss 0.620049\n",
      "iteration 54 / 300: loss 0.596948\n",
      "iteration 54 / 300: loss 0.603991\n",
      "iteration 54 / 300: loss 0.633390\n",
      "iteration 54 / 300: loss 0.589583\n",
      "iteration 54 / 300: loss 0.608555\n",
      "iteration 54 / 300: loss 0.590396\n",
      "iteration 54 / 300: loss 0.603452\n",
      "iteration 54 / 300: loss 0.598044\n",
      "iteration 54 / 300: loss 0.591888\n",
      "iteration 54 / 300: loss 0.601719\n",
      "iteration 54 / 300: loss 0.606819\n",
      "iteration 54 / 300: loss 0.621658\n",
      "iteration 54 / 300: loss 0.591279\n",
      "iteration 54 / 300: loss 0.596093\n",
      "iteration 54 / 300: loss 0.588188\n",
      "iteration 54 / 300: loss 0.614827\n",
      "iteration 54 / 300: loss 0.589558\n",
      "iteration 54 / 300: loss 0.580573\n",
      "iteration 54 / 300: loss 0.569537\n",
      "iteration 54 / 300: loss 0.563765\n",
      "iteration 54 / 300: loss 0.596210\n",
      "iteration 54 / 300: loss 0.580569\n",
      "iteration 54 / 300: loss 0.588209\n",
      "iteration 54 / 300: loss 0.574862\n",
      "iteration 54 / 300: loss 0.598087\n",
      "iteration 54 / 300: loss 0.609671\n",
      "iteration 54 / 300: loss 0.612284\n",
      "iteration 54 / 300: loss 0.608356\n",
      "iteration 54 / 300: loss 0.585509\n",
      "iteration 54 / 300: loss 0.591274\n",
      "iteration 54 / 300: loss 0.597220\n",
      "iteration 54 / 300: loss 0.600664\n",
      "iteration 54 / 300: loss 0.598123\n",
      "iteration 54 / 300: loss 0.591353\n",
      "iteration 54 / 300: loss 0.592941\n",
      "iteration 54 / 300: loss 0.586436\n",
      "iteration 54 / 300: loss 0.601639\n",
      "iteration 54 / 300: loss 0.600539\n",
      "iteration 54 / 300: loss 0.615717\n",
      "iteration 54 / 300: loss 0.599652\n",
      "iteration 54 / 300: loss 0.601155\n",
      "iteration 54 / 300: loss 0.605444\n",
      "iteration 54 / 300: loss 0.595031\n",
      "iteration 54 / 300: loss 0.594542\n",
      "iteration 54 / 300: loss 0.590909\n",
      "iteration 54 / 300: loss 0.598819\n",
      "iteration 54 / 300: loss 0.607815\n",
      "iteration 54 / 300: loss 0.612425\n",
      "iteration 54 / 300: loss 0.589577\n",
      "iteration 54 / 300: loss 0.600897\n",
      "iteration 54 / 300: loss 0.604510\n",
      "iteration 54 / 300: loss 0.606939\n",
      "iteration 54 / 300: loss 0.606102\n",
      "iteration 54 / 300: loss 0.625789\n",
      "iteration 54 / 300: loss 0.588813\n",
      "iteration 54 / 300: loss 0.582627\n",
      "iteration 54 / 300: loss 0.627394\n",
      "iteration 54 / 300: loss 0.605309\n",
      "iteration 54 / 300: loss 0.606122\n",
      "iteration 54 / 300: loss 0.597659\n",
      "iteration 54 / 300: loss 0.599743\n",
      "iteration 54 / 300: loss 0.594808\n",
      "iteration 54 / 300: loss 0.591490\n",
      "iteration 54 / 300: loss 0.601475\n",
      "iteration 54 / 300: loss 0.613259\n",
      "iteration 54 / 300: loss 0.594459\n",
      "iteration 54 / 300: loss 0.601377\n",
      "iteration 54 / 300: loss 0.605455\n",
      "iteration 54 / 300: loss 0.604396\n",
      "iteration 54 / 300: loss 0.581574\n",
      "iteration 54 / 300: loss 0.603469\n",
      "iteration 55 / 300: loss 0.587412\n",
      "iteration 55 / 300: loss 0.590024\n",
      "iteration 55 / 300: loss 0.569246\n",
      "iteration 55 / 300: loss 0.593796\n",
      "iteration 55 / 300: loss 0.595353\n",
      "iteration 55 / 300: loss 0.597333\n",
      "iteration 55 / 300: loss 0.610662\n",
      "iteration 55 / 300: loss 0.594495\n",
      "iteration 55 / 300: loss 0.630082\n",
      "iteration 55 / 300: loss 0.582266\n",
      "iteration 55 / 300: loss 0.609974\n",
      "iteration 55 / 300: loss 0.589135\n",
      "iteration 55 / 300: loss 0.593497\n",
      "iteration 55 / 300: loss 0.572945\n",
      "iteration 55 / 300: loss 0.584599\n",
      "iteration 55 / 300: loss 0.610018\n",
      "iteration 55 / 300: loss 0.600193\n",
      "iteration 55 / 300: loss 0.585509\n",
      "iteration 55 / 300: loss 0.617195\n",
      "iteration 55 / 300: loss 0.593487\n",
      "iteration 55 / 300: loss 0.587303\n",
      "iteration 55 / 300: loss 0.593306\n",
      "iteration 55 / 300: loss 0.606342\n",
      "iteration 55 / 300: loss 0.597725\n",
      "iteration 55 / 300: loss 0.616372\n",
      "iteration 55 / 300: loss 0.609976\n",
      "iteration 55 / 300: loss 0.600224\n",
      "iteration 55 / 300: loss 0.590769\n",
      "iteration 55 / 300: loss 0.619834\n",
      "iteration 55 / 300: loss 0.596754\n",
      "iteration 55 / 300: loss 0.603793\n",
      "iteration 55 / 300: loss 0.633200\n",
      "iteration 55 / 300: loss 0.589415\n",
      "iteration 55 / 300: loss 0.608389\n",
      "iteration 55 / 300: loss 0.590176\n",
      "iteration 55 / 300: loss 0.603222\n",
      "iteration 55 / 300: loss 0.597851\n",
      "iteration 55 / 300: loss 0.591662\n",
      "iteration 55 / 300: loss 0.601552\n",
      "iteration 55 / 300: loss 0.606653\n",
      "iteration 55 / 300: loss 0.621457\n",
      "iteration 55 / 300: loss 0.591064\n",
      "iteration 55 / 300: loss 0.595883\n",
      "iteration 55 / 300: loss 0.587948\n",
      "iteration 55 / 300: loss 0.614702\n",
      "iteration 55 / 300: loss 0.589381\n",
      "iteration 55 / 300: loss 0.580382\n",
      "iteration 55 / 300: loss 0.569339\n",
      "iteration 55 / 300: loss 0.563635\n",
      "iteration 55 / 300: loss 0.596028\n",
      "iteration 55 / 300: loss 0.580409\n",
      "iteration 55 / 300: loss 0.588036\n",
      "iteration 55 / 300: loss 0.574685\n",
      "iteration 55 / 300: loss 0.597926\n",
      "iteration 55 / 300: loss 0.609517\n",
      "iteration 55 / 300: loss 0.612156\n",
      "iteration 55 / 300: loss 0.608168\n",
      "iteration 55 / 300: loss 0.585362\n",
      "iteration 55 / 300: loss 0.591125\n",
      "iteration 55 / 300: loss 0.597036\n",
      "iteration 55 / 300: loss 0.600517\n",
      "iteration 55 / 300: loss 0.597957\n",
      "iteration 55 / 300: loss 0.591226\n",
      "iteration 55 / 300: loss 0.592784\n",
      "iteration 55 / 300: loss 0.586301\n",
      "iteration 55 / 300: loss 0.601448\n",
      "iteration 55 / 300: loss 0.600388\n",
      "iteration 55 / 300: loss 0.615584\n",
      "iteration 55 / 300: loss 0.599484\n",
      "iteration 55 / 300: loss 0.600980\n",
      "iteration 55 / 300: loss 0.605256\n",
      "iteration 55 / 300: loss 0.594828\n",
      "iteration 55 / 300: loss 0.594344\n",
      "iteration 55 / 300: loss 0.590737\n",
      "iteration 55 / 300: loss 0.598608\n",
      "iteration 55 / 300: loss 0.607627\n",
      "iteration 55 / 300: loss 0.612254\n",
      "iteration 55 / 300: loss 0.589407\n",
      "iteration 55 / 300: loss 0.600749\n",
      "iteration 55 / 300: loss 0.604364\n",
      "iteration 55 / 300: loss 0.606776\n",
      "iteration 55 / 300: loss 0.605907\n",
      "iteration 55 / 300: loss 0.625638\n",
      "iteration 55 / 300: loss 0.588657\n",
      "iteration 55 / 300: loss 0.582458\n",
      "iteration 55 / 300: loss 0.627180\n",
      "iteration 55 / 300: loss 0.605135\n",
      "iteration 55 / 300: loss 0.605978\n",
      "iteration 55 / 300: loss 0.597468\n",
      "iteration 55 / 300: loss 0.599546\n",
      "iteration 55 / 300: loss 0.594630\n",
      "iteration 55 / 300: loss 0.591307\n",
      "iteration 55 / 300: loss 0.601267\n",
      "iteration 55 / 300: loss 0.613084\n",
      "iteration 55 / 300: loss 0.594283\n",
      "iteration 55 / 300: loss 0.601217\n",
      "iteration 55 / 300: loss 0.605248\n",
      "iteration 55 / 300: loss 0.604231\n",
      "iteration 55 / 300: loss 0.581422\n",
      "iteration 55 / 300: loss 0.603307\n",
      "iteration 56 / 300: loss 0.587241\n",
      "iteration 56 / 300: loss 0.589893\n",
      "iteration 56 / 300: loss 0.569100\n",
      "iteration 56 / 300: loss 0.593687\n",
      "iteration 56 / 300: loss 0.595198\n",
      "iteration 56 / 300: loss 0.597150\n",
      "iteration 56 / 300: loss 0.610488\n",
      "iteration 56 / 300: loss 0.594344\n",
      "iteration 56 / 300: loss 0.629903\n",
      "iteration 56 / 300: loss 0.582088\n",
      "iteration 56 / 300: loss 0.609784\n",
      "iteration 56 / 300: loss 0.588992\n",
      "iteration 56 / 300: loss 0.593339\n",
      "iteration 56 / 300: loss 0.572818\n",
      "iteration 56 / 300: loss 0.584473\n",
      "iteration 56 / 300: loss 0.609868\n",
      "iteration 56 / 300: loss 0.600037\n",
      "iteration 56 / 300: loss 0.585360\n",
      "iteration 56 / 300: loss 0.617019\n",
      "iteration 56 / 300: loss 0.593328\n",
      "iteration 56 / 300: loss 0.587141\n",
      "iteration 56 / 300: loss 0.593128\n",
      "iteration 56 / 300: loss 0.606164\n",
      "iteration 56 / 300: loss 0.597563\n",
      "iteration 56 / 300: loss 0.616239\n",
      "iteration 56 / 300: loss 0.609830\n",
      "iteration 56 / 300: loss 0.600044\n",
      "iteration 56 / 300: loss 0.590590\n",
      "iteration 56 / 300: loss 0.619639\n",
      "iteration 56 / 300: loss 0.596576\n",
      "iteration 56 / 300: loss 0.603610\n",
      "iteration 56 / 300: loss 0.633021\n",
      "iteration 56 / 300: loss 0.589259\n",
      "iteration 56 / 300: loss 0.608235\n",
      "iteration 56 / 300: loss 0.589976\n",
      "iteration 56 / 300: loss 0.603010\n",
      "iteration 56 / 300: loss 0.597675\n",
      "iteration 56 / 300: loss 0.591453\n",
      "iteration 56 / 300: loss 0.601393\n",
      "iteration 56 / 300: loss 0.606499\n",
      "iteration 56 / 300: loss 0.621272\n",
      "iteration 56 / 300: loss 0.590865\n",
      "iteration 56 / 300: loss 0.595688\n",
      "iteration 56 / 300: loss 0.587729\n",
      "iteration 56 / 300: loss 0.614584\n",
      "iteration 56 / 300: loss 0.589217\n",
      "iteration 56 / 300: loss 0.580204\n",
      "iteration 56 / 300: loss 0.569158\n",
      "iteration 56 / 300: loss 0.563516\n",
      "iteration 56 / 300: loss 0.595862\n",
      "iteration 56 / 300: loss 0.580263\n",
      "iteration 56 / 300: loss 0.587878\n",
      "iteration 56 / 300: loss 0.574523\n",
      "iteration 56 / 300: loss 0.597776\n",
      "iteration 56 / 300: loss 0.609376\n",
      "iteration 56 / 300: loss 0.612038\n",
      "iteration 56 / 300: loss 0.607996\n",
      "iteration 56 / 300: loss 0.585227\n",
      "iteration 56 / 300: loss 0.590989\n",
      "iteration 56 / 300: loss 0.596869\n",
      "iteration 56 / 300: loss 0.600381\n",
      "iteration 56 / 300: loss 0.597804\n",
      "iteration 56 / 300: loss 0.591108\n",
      "iteration 56 / 300: loss 0.592639\n",
      "iteration 56 / 300: loss 0.586178\n",
      "iteration 56 / 300: loss 0.601276\n",
      "iteration 56 / 300: loss 0.600251\n",
      "iteration 56 / 300: loss 0.615465\n",
      "iteration 56 / 300: loss 0.599331\n",
      "iteration 56 / 300: loss 0.600821\n",
      "iteration 56 / 300: loss 0.605084\n",
      "iteration 56 / 300: loss 0.594643\n",
      "iteration 56 / 300: loss 0.594162\n",
      "iteration 56 / 300: loss 0.590581\n",
      "iteration 56 / 300: loss 0.598414\n",
      "iteration 56 / 300: loss 0.607453\n",
      "iteration 56 / 300: loss 0.612097\n",
      "iteration 56 / 300: loss 0.589254\n",
      "iteration 56 / 300: loss 0.600615\n",
      "iteration 56 / 300: loss 0.604229\n",
      "iteration 56 / 300: loss 0.606625\n",
      "iteration 56 / 300: loss 0.605726\n",
      "iteration 56 / 300: loss 0.625500\n",
      "iteration 56 / 300: loss 0.588517\n",
      "iteration 56 / 300: loss 0.582303\n",
      "iteration 56 / 300: loss 0.626984\n",
      "iteration 56 / 300: loss 0.604975\n",
      "iteration 56 / 300: loss 0.605844\n",
      "iteration 56 / 300: loss 0.597292\n",
      "iteration 56 / 300: loss 0.599365\n",
      "iteration 56 / 300: loss 0.594466\n",
      "iteration 56 / 300: loss 0.591140\n",
      "iteration 56 / 300: loss 0.601078\n",
      "iteration 56 / 300: loss 0.612925\n",
      "iteration 56 / 300: loss 0.594121\n",
      "iteration 56 / 300: loss 0.601068\n",
      "iteration 56 / 300: loss 0.605058\n",
      "iteration 56 / 300: loss 0.604077\n",
      "iteration 56 / 300: loss 0.581282\n",
      "iteration 56 / 300: loss 0.603158\n",
      "iteration 57 / 300: loss 0.587085\n",
      "iteration 57 / 300: loss 0.589772\n",
      "iteration 57 / 300: loss 0.568965\n",
      "iteration 57 / 300: loss 0.593584\n",
      "iteration 57 / 300: loss 0.595056\n",
      "iteration 57 / 300: loss 0.596983\n",
      "iteration 57 / 300: loss 0.610329\n",
      "iteration 57 / 300: loss 0.594204\n",
      "iteration 57 / 300: loss 0.629738\n",
      "iteration 57 / 300: loss 0.581923\n",
      "iteration 57 / 300: loss 0.609612\n",
      "iteration 57 / 300: loss 0.588860\n",
      "iteration 57 / 300: loss 0.593194\n",
      "iteration 57 / 300: loss 0.572701\n",
      "iteration 57 / 300: loss 0.584355\n",
      "iteration 57 / 300: loss 0.609732\n",
      "iteration 57 / 300: loss 0.599893\n",
      "iteration 57 / 300: loss 0.585224\n",
      "iteration 57 / 300: loss 0.616859\n",
      "iteration 57 / 300: loss 0.593182\n",
      "iteration 57 / 300: loss 0.586992\n",
      "iteration 57 / 300: loss 0.592966\n",
      "iteration 57 / 300: loss 0.605999\n",
      "iteration 57 / 300: loss 0.597412\n",
      "iteration 57 / 300: loss 0.616119\n",
      "iteration 57 / 300: loss 0.609697\n",
      "iteration 57 / 300: loss 0.599879\n",
      "iteration 57 / 300: loss 0.590428\n",
      "iteration 57 / 300: loss 0.619462\n",
      "iteration 57 / 300: loss 0.596411\n",
      "iteration 57 / 300: loss 0.603440\n",
      "iteration 57 / 300: loss 0.632854\n",
      "iteration 57 / 300: loss 0.589113\n",
      "iteration 57 / 300: loss 0.608093\n",
      "iteration 57 / 300: loss 0.589793\n",
      "iteration 57 / 300: loss 0.602816\n",
      "iteration 57 / 300: loss 0.597514\n",
      "iteration 57 / 300: loss 0.591260\n",
      "iteration 57 / 300: loss 0.601244\n",
      "iteration 57 / 300: loss 0.606357\n",
      "iteration 57 / 300: loss 0.621104\n",
      "iteration 57 / 300: loss 0.590681\n",
      "iteration 57 / 300: loss 0.595508\n",
      "iteration 57 / 300: loss 0.587531\n",
      "iteration 57 / 300: loss 0.614473\n",
      "iteration 57 / 300: loss 0.589066\n",
      "iteration 57 / 300: loss 0.580041\n",
      "iteration 57 / 300: loss 0.568994\n",
      "iteration 57 / 300: loss 0.563405\n",
      "iteration 57 / 300: loss 0.595710\n",
      "iteration 57 / 300: loss 0.580130\n",
      "iteration 57 / 300: loss 0.587736\n",
      "iteration 57 / 300: loss 0.574375\n",
      "iteration 57 / 300: loss 0.597636\n",
      "iteration 57 / 300: loss 0.609248\n",
      "iteration 57 / 300: loss 0.611930\n",
      "iteration 57 / 300: loss 0.607839\n",
      "iteration 57 / 300: loss 0.585103\n",
      "iteration 57 / 300: loss 0.590865\n",
      "iteration 57 / 300: loss 0.596716\n",
      "iteration 57 / 300: loss 0.600256\n",
      "iteration 57 / 300: loss 0.597661\n",
      "iteration 57 / 300: loss 0.590998\n",
      "iteration 57 / 300: loss 0.592506\n",
      "iteration 57 / 300: loss 0.586064\n",
      "iteration 57 / 300: loss 0.601120\n",
      "iteration 57 / 300: loss 0.600127\n",
      "iteration 57 / 300: loss 0.615358\n",
      "iteration 57 / 300: loss 0.599192\n",
      "iteration 57 / 300: loss 0.600678\n",
      "iteration 57 / 300: loss 0.604925\n",
      "iteration 57 / 300: loss 0.594475\n",
      "iteration 57 / 300: loss 0.593997\n",
      "iteration 57 / 300: loss 0.590440\n",
      "iteration 57 / 300: loss 0.598237\n",
      "iteration 57 / 300: loss 0.607295\n",
      "iteration 57 / 300: loss 0.611955\n",
      "iteration 57 / 300: loss 0.589115\n",
      "iteration 57 / 300: loss 0.600493\n",
      "iteration 57 / 300: loss 0.604105\n",
      "iteration 57 / 300: loss 0.606486\n",
      "iteration 57 / 300: loss 0.605560\n",
      "iteration 57 / 300: loss 0.625375\n",
      "iteration 57 / 300: loss 0.588391\n",
      "iteration 57 / 300: loss 0.582161\n",
      "iteration 57 / 300: loss 0.626804\n",
      "iteration 57 / 300: loss 0.604828\n",
      "iteration 57 / 300: loss 0.605719\n",
      "iteration 57 / 300: loss 0.597132\n",
      "iteration 57 / 300: loss 0.599200\n",
      "iteration 57 / 300: loss 0.594314\n",
      "iteration 57 / 300: loss 0.590988\n",
      "iteration 57 / 300: loss 0.600906\n",
      "iteration 57 / 300: loss 0.612780\n",
      "iteration 57 / 300: loss 0.593972\n",
      "iteration 57 / 300: loss 0.600929\n",
      "iteration 57 / 300: loss 0.604883\n",
      "iteration 57 / 300: loss 0.603934\n",
      "iteration 57 / 300: loss 0.581154\n",
      "iteration 57 / 300: loss 0.603020\n",
      "iteration 58 / 300: loss 0.586942\n",
      "iteration 58 / 300: loss 0.589658\n",
      "iteration 58 / 300: loss 0.568839\n",
      "iteration 58 / 300: loss 0.593487\n",
      "iteration 58 / 300: loss 0.594926\n",
      "iteration 58 / 300: loss 0.596829\n",
      "iteration 58 / 300: loss 0.610184\n",
      "iteration 58 / 300: loss 0.594075\n",
      "iteration 58 / 300: loss 0.629588\n",
      "iteration 58 / 300: loss 0.581770\n",
      "iteration 58 / 300: loss 0.609456\n",
      "iteration 58 / 300: loss 0.588737\n",
      "iteration 58 / 300: loss 0.593061\n",
      "iteration 58 / 300: loss 0.572592\n",
      "iteration 58 / 300: loss 0.584245\n",
      "iteration 58 / 300: loss 0.609609\n",
      "iteration 58 / 300: loss 0.599759\n",
      "iteration 58 / 300: loss 0.585100\n",
      "iteration 58 / 300: loss 0.616713\n",
      "iteration 58 / 300: loss 0.593047\n",
      "iteration 58 / 300: loss 0.586857\n",
      "iteration 58 / 300: loss 0.592817\n",
      "iteration 58 / 300: loss 0.605849\n",
      "iteration 58 / 300: loss 0.597271\n",
      "iteration 58 / 300: loss 0.616010\n",
      "iteration 58 / 300: loss 0.609575\n",
      "iteration 58 / 300: loss 0.599729\n",
      "iteration 58 / 300: loss 0.590283\n",
      "iteration 58 / 300: loss 0.619301\n",
      "iteration 58 / 300: loss 0.596260\n",
      "iteration 58 / 300: loss 0.603283\n",
      "iteration 58 / 300: loss 0.632698\n",
      "iteration 58 / 300: loss 0.588978\n",
      "iteration 58 / 300: loss 0.607962\n",
      "iteration 58 / 300: loss 0.589628\n",
      "iteration 58 / 300: loss 0.602638\n",
      "iteration 58 / 300: loss 0.597368\n",
      "iteration 58 / 300: loss 0.591082\n",
      "iteration 58 / 300: loss 0.601104\n",
      "iteration 58 / 300: loss 0.606227\n",
      "iteration 58 / 300: loss 0.620951\n",
      "iteration 58 / 300: loss 0.590512\n",
      "iteration 58 / 300: loss 0.595343\n",
      "iteration 58 / 300: loss 0.587350\n",
      "iteration 58 / 300: loss 0.614369\n",
      "iteration 58 / 300: loss 0.588928\n",
      "iteration 58 / 300: loss 0.579890\n",
      "iteration 58 / 300: loss 0.568846\n",
      "iteration 58 / 300: loss 0.563304\n",
      "iteration 58 / 300: loss 0.595572\n",
      "iteration 58 / 300: loss 0.580009\n",
      "iteration 58 / 300: loss 0.587607\n",
      "iteration 58 / 300: loss 0.574239\n",
      "iteration 58 / 300: loss 0.597507\n",
      "iteration 58 / 300: loss 0.609131\n",
      "iteration 58 / 300: loss 0.611832\n",
      "iteration 58 / 300: loss 0.607695\n",
      "iteration 58 / 300: loss 0.584988\n",
      "iteration 58 / 300: loss 0.590752\n",
      "iteration 58 / 300: loss 0.596577\n",
      "iteration 58 / 300: loss 0.600141\n",
      "iteration 58 / 300: loss 0.597530\n",
      "iteration 58 / 300: loss 0.590896\n",
      "iteration 58 / 300: loss 0.592384\n",
      "iteration 58 / 300: loss 0.585959\n",
      "iteration 58 / 300: loss 0.600979\n",
      "iteration 58 / 300: loss 0.600014\n",
      "iteration 58 / 300: loss 0.615261\n",
      "iteration 58 / 300: loss 0.599065\n",
      "iteration 58 / 300: loss 0.600548\n",
      "iteration 58 / 300: loss 0.604780\n",
      "iteration 58 / 300: loss 0.594322\n",
      "iteration 58 / 300: loss 0.593847\n",
      "iteration 58 / 300: loss 0.590312\n",
      "iteration 58 / 300: loss 0.598074\n",
      "iteration 58 / 300: loss 0.607150\n",
      "iteration 58 / 300: loss 0.611825\n",
      "iteration 58 / 300: loss 0.588990\n",
      "iteration 58 / 300: loss 0.600382\n",
      "iteration 58 / 300: loss 0.603991\n",
      "iteration 58 / 300: loss 0.606359\n",
      "iteration 58 / 300: loss 0.605408\n",
      "iteration 58 / 300: loss 0.625262\n",
      "iteration 58 / 300: loss 0.588278\n",
      "iteration 58 / 300: loss 0.582032\n",
      "iteration 58 / 300: loss 0.626638\n",
      "iteration 58 / 300: loss 0.604692\n",
      "iteration 58 / 300: loss 0.605603\n",
      "iteration 58 / 300: loss 0.596985\n",
      "iteration 58 / 300: loss 0.599049\n",
      "iteration 58 / 300: loss 0.594175\n",
      "iteration 58 / 300: loss 0.590849\n",
      "iteration 58 / 300: loss 0.600750\n",
      "iteration 58 / 300: loss 0.612648\n",
      "iteration 58 / 300: loss 0.593836\n",
      "iteration 58 / 300: loss 0.600799\n",
      "iteration 58 / 300: loss 0.604723\n",
      "iteration 58 / 300: loss 0.603802\n",
      "iteration 58 / 300: loss 0.581035\n",
      "iteration 58 / 300: loss 0.602894\n",
      "iteration 59 / 300: loss 0.586811\n",
      "iteration 59 / 300: loss 0.589553\n",
      "iteration 59 / 300: loss 0.568723\n",
      "iteration 59 / 300: loss 0.593396\n",
      "iteration 59 / 300: loss 0.594806\n",
      "iteration 59 / 300: loss 0.596689\n",
      "iteration 59 / 300: loss 0.610053\n",
      "iteration 59 / 300: loss 0.593957\n",
      "iteration 59 / 300: loss 0.629450\n",
      "iteration 59 / 300: loss 0.581630\n",
      "iteration 59 / 300: loss 0.609315\n",
      "iteration 59 / 300: loss 0.588624\n",
      "iteration 59 / 300: loss 0.592938\n",
      "iteration 59 / 300: loss 0.572490\n",
      "iteration 59 / 300: loss 0.584143\n",
      "iteration 59 / 300: loss 0.609497\n",
      "iteration 59 / 300: loss 0.599637\n",
      "iteration 59 / 300: loss 0.584986\n",
      "iteration 59 / 300: loss 0.616579\n",
      "iteration 59 / 300: loss 0.592924\n",
      "iteration 59 / 300: loss 0.586733\n",
      "iteration 59 / 300: loss 0.592681\n",
      "iteration 59 / 300: loss 0.605710\n",
      "iteration 59 / 300: loss 0.597142\n",
      "iteration 59 / 300: loss 0.615912\n",
      "iteration 59 / 300: loss 0.609465\n",
      "iteration 59 / 300: loss 0.599592\n",
      "iteration 59 / 300: loss 0.590153\n",
      "iteration 59 / 300: loss 0.619155\n",
      "iteration 59 / 300: loss 0.596122\n",
      "iteration 59 / 300: loss 0.603139\n",
      "iteration 59 / 300: loss 0.632554\n",
      "iteration 59 / 300: loss 0.588853\n",
      "iteration 59 / 300: loss 0.607841\n",
      "iteration 59 / 300: loss 0.589477\n",
      "iteration 59 / 300: loss 0.602476\n",
      "iteration 59 / 300: loss 0.597235\n",
      "iteration 59 / 300: loss 0.590918\n",
      "iteration 59 / 300: loss 0.600972\n",
      "iteration 59 / 300: loss 0.606107\n",
      "iteration 59 / 300: loss 0.620811\n",
      "iteration 59 / 300: loss 0.590358\n",
      "iteration 59 / 300: loss 0.595191\n",
      "iteration 59 / 300: loss 0.587187\n",
      "iteration 59 / 300: loss 0.614272\n",
      "iteration 59 / 300: loss 0.588801\n",
      "iteration 59 / 300: loss 0.579751\n",
      "iteration 59 / 300: loss 0.568711\n",
      "iteration 59 / 300: loss 0.563210\n",
      "iteration 59 / 300: loss 0.595445\n",
      "iteration 59 / 300: loss 0.579899\n",
      "iteration 59 / 300: loss 0.587490\n",
      "iteration 59 / 300: loss 0.574114\n",
      "iteration 59 / 300: loss 0.597387\n",
      "iteration 59 / 300: loss 0.609023\n",
      "iteration 59 / 300: loss 0.611742\n",
      "iteration 59 / 300: loss 0.607564\n",
      "iteration 59 / 300: loss 0.584882\n",
      "iteration 59 / 300: loss 0.590650\n",
      "iteration 59 / 300: loss 0.596450\n",
      "iteration 59 / 300: loss 0.600036\n",
      "iteration 59 / 300: loss 0.597408\n",
      "iteration 59 / 300: loss 0.590801\n",
      "iteration 59 / 300: loss 0.592272\n",
      "iteration 59 / 300: loss 0.585863\n",
      "iteration 59 / 300: loss 0.600852\n",
      "iteration 59 / 300: loss 0.599912\n",
      "iteration 59 / 300: loss 0.615174\n",
      "iteration 59 / 300: loss 0.598949\n",
      "iteration 59 / 300: loss 0.600430\n",
      "iteration 59 / 300: loss 0.604648\n",
      "iteration 59 / 300: loss 0.594184\n",
      "iteration 59 / 300: loss 0.593710\n",
      "iteration 59 / 300: loss 0.590196\n",
      "iteration 59 / 300: loss 0.597926\n",
      "iteration 59 / 300: loss 0.607017\n",
      "iteration 59 / 300: loss 0.611707\n",
      "iteration 59 / 300: loss 0.588877\n",
      "iteration 59 / 300: loss 0.600282\n",
      "iteration 59 / 300: loss 0.603886\n",
      "iteration 59 / 300: loss 0.606241\n",
      "iteration 59 / 300: loss 0.605267\n",
      "iteration 59 / 300: loss 0.625160\n",
      "iteration 59 / 300: loss 0.588177\n",
      "iteration 59 / 300: loss 0.581915\n",
      "iteration 59 / 300: loss 0.626488\n",
      "iteration 59 / 300: loss 0.604568\n",
      "iteration 59 / 300: loss 0.605496\n",
      "iteration 59 / 300: loss 0.596851\n",
      "iteration 59 / 300: loss 0.598912\n",
      "iteration 59 / 300: loss 0.594048\n",
      "iteration 59 / 300: loss 0.590724\n",
      "iteration 59 / 300: loss 0.600609\n",
      "iteration 59 / 300: loss 0.612528\n",
      "iteration 59 / 300: loss 0.593711\n",
      "iteration 59 / 300: loss 0.600680\n",
      "iteration 59 / 300: loss 0.604576\n",
      "iteration 59 / 300: loss 0.603680\n",
      "iteration 59 / 300: loss 0.580927\n",
      "iteration 59 / 300: loss 0.602779\n",
      "iteration 60 / 300: loss 0.586693\n",
      "iteration 60 / 300: loss 0.589456\n",
      "iteration 60 / 300: loss 0.568617\n",
      "iteration 60 / 300: loss 0.593312\n",
      "iteration 60 / 300: loss 0.594697\n",
      "iteration 60 / 300: loss 0.596560\n",
      "iteration 60 / 300: loss 0.609933\n",
      "iteration 60 / 300: loss 0.593848\n",
      "iteration 60 / 300: loss 0.629325\n",
      "iteration 60 / 300: loss 0.581500\n",
      "iteration 60 / 300: loss 0.609186\n",
      "iteration 60 / 300: loss 0.588519\n",
      "iteration 60 / 300: loss 0.592826\n",
      "iteration 60 / 300: loss 0.572396\n",
      "iteration 60 / 300: loss 0.584048\n",
      "iteration 60 / 300: loss 0.609396\n",
      "iteration 60 / 300: loss 0.599524\n",
      "iteration 60 / 300: loss 0.584883\n",
      "iteration 60 / 300: loss 0.616457\n",
      "iteration 60 / 300: loss 0.592810\n",
      "iteration 60 / 300: loss 0.586620\n",
      "iteration 60 / 300: loss 0.592557\n",
      "iteration 60 / 300: loss 0.605584\n",
      "iteration 60 / 300: loss 0.597022\n",
      "iteration 60 / 300: loss 0.615823\n",
      "iteration 60 / 300: loss 0.609365\n",
      "iteration 60 / 300: loss 0.599467\n",
      "iteration 60 / 300: loss 0.590035\n",
      "iteration 60 / 300: loss 0.619023\n",
      "iteration 60 / 300: loss 0.595996\n",
      "iteration 60 / 300: loss 0.603007\n",
      "iteration 60 / 300: loss 0.632420\n",
      "iteration 60 / 300: loss 0.588737\n",
      "iteration 60 / 300: loss 0.607729\n",
      "iteration 60 / 300: loss 0.589341\n",
      "iteration 60 / 300: loss 0.602328\n",
      "iteration 60 / 300: loss 0.597114\n",
      "iteration 60 / 300: loss 0.590768\n",
      "iteration 60 / 300: loss 0.600850\n",
      "iteration 60 / 300: loss 0.605997\n",
      "iteration 60 / 300: loss 0.620684\n",
      "iteration 60 / 300: loss 0.590216\n",
      "iteration 60 / 300: loss 0.595051\n",
      "iteration 60 / 300: loss 0.587038\n",
      "iteration 60 / 300: loss 0.614182\n",
      "iteration 60 / 300: loss 0.588684\n",
      "iteration 60 / 300: loss 0.579623\n",
      "iteration 60 / 300: loss 0.568590\n",
      "iteration 60 / 300: loss 0.563124\n",
      "iteration 60 / 300: loss 0.595330\n",
      "iteration 60 / 300: loss 0.579799\n",
      "iteration 60 / 300: loss 0.587384\n",
      "iteration 60 / 300: loss 0.574001\n",
      "iteration 60 / 300: loss 0.597277\n",
      "iteration 60 / 300: loss 0.608926\n",
      "iteration 60 / 300: loss 0.611660\n",
      "iteration 60 / 300: loss 0.607445\n",
      "iteration 60 / 300: loss 0.584786\n",
      "iteration 60 / 300: loss 0.590556\n",
      "iteration 60 / 300: loss 0.596334\n",
      "iteration 60 / 300: loss 0.599940\n",
      "iteration 60 / 300: loss 0.597296\n",
      "iteration 60 / 300: loss 0.590713\n",
      "iteration 60 / 300: loss 0.592169\n",
      "iteration 60 / 300: loss 0.585775\n",
      "iteration 60 / 300: loss 0.600737\n",
      "iteration 60 / 300: loss 0.599819\n",
      "iteration 60 / 300: loss 0.615094\n",
      "iteration 60 / 300: loss 0.598843\n",
      "iteration 60 / 300: loss 0.600324\n",
      "iteration 60 / 300: loss 0.604527\n",
      "iteration 60 / 300: loss 0.594059\n",
      "iteration 60 / 300: loss 0.593586\n",
      "iteration 60 / 300: loss 0.590090\n",
      "iteration 60 / 300: loss 0.597791\n",
      "iteration 60 / 300: loss 0.606897\n",
      "iteration 60 / 300: loss 0.611600\n",
      "iteration 60 / 300: loss 0.588775\n",
      "iteration 60 / 300: loss 0.600192\n",
      "iteration 60 / 300: loss 0.603789\n",
      "iteration 60 / 300: loss 0.606134\n",
      "iteration 60 / 300: loss 0.605139\n",
      "iteration 60 / 300: loss 0.625067\n",
      "iteration 60 / 300: loss 0.588085\n",
      "iteration 60 / 300: loss 0.581807\n",
      "iteration 60 / 300: loss 0.626351\n",
      "iteration 60 / 300: loss 0.604455\n",
      "iteration 60 / 300: loss 0.605396\n",
      "iteration 60 / 300: loss 0.596728\n",
      "iteration 60 / 300: loss 0.598786\n",
      "iteration 60 / 300: loss 0.593930\n",
      "iteration 60 / 300: loss 0.590610\n",
      "iteration 60 / 300: loss 0.600481\n",
      "iteration 60 / 300: loss 0.612419\n",
      "iteration 60 / 300: loss 0.593596\n",
      "iteration 60 / 300: loss 0.600569\n",
      "iteration 60 / 300: loss 0.604441\n",
      "iteration 60 / 300: loss 0.603567\n",
      "iteration 60 / 300: loss 0.580827\n",
      "iteration 60 / 300: loss 0.602673\n",
      "iteration 61 / 300: loss 0.586584\n",
      "iteration 61 / 300: loss 0.589366\n",
      "iteration 61 / 300: loss 0.568519\n",
      "iteration 61 / 300: loss 0.593233\n",
      "iteration 61 / 300: loss 0.594597\n",
      "iteration 61 / 300: loss 0.596443\n",
      "iteration 61 / 300: loss 0.609825\n",
      "iteration 61 / 300: loss 0.593749\n",
      "iteration 61 / 300: loss 0.629210\n",
      "iteration 61 / 300: loss 0.581380\n",
      "iteration 61 / 300: loss 0.609070\n",
      "iteration 61 / 300: loss 0.588422\n",
      "iteration 61 / 300: loss 0.592723\n",
      "iteration 61 / 300: loss 0.572309\n",
      "iteration 61 / 300: loss 0.583960\n",
      "iteration 61 / 300: loss 0.609305\n",
      "iteration 61 / 300: loss 0.599420\n",
      "iteration 61 / 300: loss 0.584788\n",
      "iteration 61 / 300: loss 0.616346\n",
      "iteration 61 / 300: loss 0.592706\n",
      "iteration 61 / 300: loss 0.586517\n",
      "iteration 61 / 300: loss 0.592444\n",
      "iteration 61 / 300: loss 0.605469\n",
      "iteration 61 / 300: loss 0.596912\n",
      "iteration 61 / 300: loss 0.615742\n",
      "iteration 61 / 300: loss 0.609274\n",
      "iteration 61 / 300: loss 0.599352\n",
      "iteration 61 / 300: loss 0.589929\n",
      "iteration 61 / 300: loss 0.618903\n",
      "iteration 61 / 300: loss 0.595881\n",
      "iteration 61 / 300: loss 0.602886\n",
      "iteration 61 / 300: loss 0.632297\n",
      "iteration 61 / 300: loss 0.588630\n",
      "iteration 61 / 300: loss 0.607626\n",
      "iteration 61 / 300: loss 0.589217\n",
      "iteration 61 / 300: loss 0.602193\n",
      "iteration 61 / 300: loss 0.597004\n",
      "iteration 61 / 300: loss 0.590631\n",
      "iteration 61 / 300: loss 0.600736\n",
      "iteration 61 / 300: loss 0.605896\n",
      "iteration 61 / 300: loss 0.620568\n",
      "iteration 61 / 300: loss 0.590087\n",
      "iteration 61 / 300: loss 0.594923\n",
      "iteration 61 / 300: loss 0.586903\n",
      "iteration 61 / 300: loss 0.614098\n",
      "iteration 61 / 300: loss 0.588578\n",
      "iteration 61 / 300: loss 0.579506\n",
      "iteration 61 / 300: loss 0.568480\n",
      "iteration 61 / 300: loss 0.563045\n",
      "iteration 61 / 300: loss 0.595224\n",
      "iteration 61 / 300: loss 0.579708\n",
      "iteration 61 / 300: loss 0.587288\n",
      "iteration 61 / 300: loss 0.573898\n",
      "iteration 61 / 300: loss 0.597176\n",
      "iteration 61 / 300: loss 0.608836\n",
      "iteration 61 / 300: loss 0.611585\n",
      "iteration 61 / 300: loss 0.607337\n",
      "iteration 61 / 300: loss 0.584697\n",
      "iteration 61 / 300: loss 0.590471\n",
      "iteration 61 / 300: loss 0.596228\n",
      "iteration 61 / 300: loss 0.599851\n",
      "iteration 61 / 300: loss 0.597192\n",
      "iteration 61 / 300: loss 0.590632\n",
      "iteration 61 / 300: loss 0.592075\n",
      "iteration 61 / 300: loss 0.585694\n",
      "iteration 61 / 300: loss 0.600633\n",
      "iteration 61 / 300: loss 0.599735\n",
      "iteration 61 / 300: loss 0.615022\n",
      "iteration 61 / 300: loss 0.598747\n",
      "iteration 61 / 300: loss 0.600228\n",
      "iteration 61 / 300: loss 0.604416\n",
      "iteration 61 / 300: loss 0.593945\n",
      "iteration 61 / 300: loss 0.593473\n",
      "iteration 61 / 300: loss 0.589994\n",
      "iteration 61 / 300: loss 0.597667\n",
      "iteration 61 / 300: loss 0.606786\n",
      "iteration 61 / 300: loss 0.611502\n",
      "iteration 61 / 300: loss 0.588682\n",
      "iteration 61 / 300: loss 0.600110\n",
      "iteration 61 / 300: loss 0.603700\n",
      "iteration 61 / 300: loss 0.606035\n",
      "iteration 61 / 300: loss 0.605021\n",
      "iteration 61 / 300: loss 0.624982\n",
      "iteration 61 / 300: loss 0.588003\n",
      "iteration 61 / 300: loss 0.581710\n",
      "iteration 61 / 300: loss 0.626226\n",
      "iteration 61 / 300: loss 0.604351\n",
      "iteration 61 / 300: loss 0.605304\n",
      "iteration 61 / 300: loss 0.596616\n",
      "iteration 61 / 300: loss 0.598672\n",
      "iteration 61 / 300: loss 0.593823\n",
      "iteration 61 / 300: loss 0.590506\n",
      "iteration 61 / 300: loss 0.600365\n",
      "iteration 61 / 300: loss 0.612321\n",
      "iteration 61 / 300: loss 0.593492\n",
      "iteration 61 / 300: loss 0.600468\n",
      "iteration 61 / 300: loss 0.604318\n",
      "iteration 61 / 300: loss 0.603463\n",
      "iteration 61 / 300: loss 0.580735\n",
      "iteration 61 / 300: loss 0.602576\n",
      "iteration 62 / 300: loss 0.586486\n",
      "iteration 62 / 300: loss 0.589283\n",
      "iteration 62 / 300: loss 0.568429\n",
      "iteration 62 / 300: loss 0.593160\n",
      "iteration 62 / 300: loss 0.594505\n",
      "iteration 62 / 300: loss 0.596337\n",
      "iteration 62 / 300: loss 0.609726\n",
      "iteration 62 / 300: loss 0.593658\n",
      "iteration 62 / 300: loss 0.629105\n",
      "iteration 62 / 300: loss 0.581271\n",
      "iteration 62 / 300: loss 0.608964\n",
      "iteration 62 / 300: loss 0.588333\n",
      "iteration 62 / 300: loss 0.592629\n",
      "iteration 62 / 300: loss 0.572229\n",
      "iteration 62 / 300: loss 0.583878\n",
      "iteration 62 / 300: loss 0.609222\n",
      "iteration 62 / 300: loss 0.599325\n",
      "iteration 62 / 300: loss 0.584703\n",
      "iteration 62 / 300: loss 0.616245\n",
      "iteration 62 / 300: loss 0.592610\n",
      "iteration 62 / 300: loss 0.586423\n",
      "iteration 62 / 300: loss 0.592341\n",
      "iteration 62 / 300: loss 0.605364\n",
      "iteration 62 / 300: loss 0.596811\n",
      "iteration 62 / 300: loss 0.615669\n",
      "iteration 62 / 300: loss 0.609191\n",
      "iteration 62 / 300: loss 0.599248\n",
      "iteration 62 / 300: loss 0.589834\n",
      "iteration 62 / 300: loss 0.618795\n",
      "iteration 62 / 300: loss 0.595777\n",
      "iteration 62 / 300: loss 0.602775\n",
      "iteration 62 / 300: loss 0.632183\n",
      "iteration 62 / 300: loss 0.588532\n",
      "iteration 62 / 300: loss 0.607532\n",
      "iteration 62 / 300: loss 0.589105\n",
      "iteration 62 / 300: loss 0.602071\n",
      "iteration 62 / 300: loss 0.596905\n",
      "iteration 62 / 300: loss 0.590506\n",
      "iteration 62 / 300: loss 0.600631\n",
      "iteration 62 / 300: loss 0.605803\n",
      "iteration 62 / 300: loss 0.620462\n",
      "iteration 62 / 300: loss 0.589969\n",
      "iteration 62 / 300: loss 0.594806\n",
      "iteration 62 / 300: loss 0.586781\n",
      "iteration 62 / 300: loss 0.614021\n",
      "iteration 62 / 300: loss 0.588481\n",
      "iteration 62 / 300: loss 0.579399\n",
      "iteration 62 / 300: loss 0.568380\n",
      "iteration 62 / 300: loss 0.562973\n",
      "iteration 62 / 300: loss 0.595128\n",
      "iteration 62 / 300: loss 0.579625\n",
      "iteration 62 / 300: loss 0.587201\n",
      "iteration 62 / 300: loss 0.573803\n",
      "iteration 62 / 300: loss 0.597083\n",
      "iteration 62 / 300: loss 0.608755\n",
      "iteration 62 / 300: loss 0.611516\n",
      "iteration 62 / 300: loss 0.607238\n",
      "iteration 62 / 300: loss 0.584615\n",
      "iteration 62 / 300: loss 0.590393\n",
      "iteration 62 / 300: loss 0.596132\n",
      "iteration 62 / 300: loss 0.599770\n",
      "iteration 62 / 300: loss 0.597098\n",
      "iteration 62 / 300: loss 0.590557\n",
      "iteration 62 / 300: loss 0.591989\n",
      "iteration 62 / 300: loss 0.585620\n",
      "iteration 62 / 300: loss 0.600540\n",
      "iteration 62 / 300: loss 0.599658\n",
      "iteration 62 / 300: loss 0.614956\n",
      "iteration 62 / 300: loss 0.598660\n",
      "iteration 62 / 300: loss 0.600141\n",
      "iteration 62 / 300: loss 0.604315\n",
      "iteration 62 / 300: loss 0.593842\n",
      "iteration 62 / 300: loss 0.593371\n",
      "iteration 62 / 300: loss 0.589907\n",
      "iteration 62 / 300: loss 0.597554\n",
      "iteration 62 / 300: loss 0.606686\n",
      "iteration 62 / 300: loss 0.611414\n",
      "iteration 62 / 300: loss 0.588599\n",
      "iteration 62 / 300: loss 0.600037\n",
      "iteration 62 / 300: loss 0.603619\n",
      "iteration 62 / 300: loss 0.605944\n",
      "iteration 62 / 300: loss 0.604914\n",
      "iteration 62 / 300: loss 0.624905\n",
      "iteration 62 / 300: loss 0.587929\n",
      "iteration 62 / 300: loss 0.581621\n",
      "iteration 62 / 300: loss 0.626113\n",
      "iteration 62 / 300: loss 0.604256\n",
      "iteration 62 / 300: loss 0.605219\n",
      "iteration 62 / 300: loss 0.596513\n",
      "iteration 62 / 300: loss 0.598568\n",
      "iteration 62 / 300: loss 0.593725\n",
      "iteration 62 / 300: loss 0.590412\n",
      "iteration 62 / 300: loss 0.600260\n",
      "iteration 62 / 300: loss 0.612231\n",
      "iteration 62 / 300: loss 0.593396\n",
      "iteration 62 / 300: loss 0.600374\n",
      "iteration 62 / 300: loss 0.604206\n",
      "iteration 62 / 300: loss 0.603368\n",
      "iteration 62 / 300: loss 0.580652\n",
      "iteration 62 / 300: loss 0.602487\n",
      "iteration 63 / 300: loss 0.586397\n",
      "iteration 63 / 300: loss 0.589207\n",
      "iteration 63 / 300: loss 0.568346\n",
      "iteration 63 / 300: loss 0.593093\n",
      "iteration 63 / 300: loss 0.594422\n",
      "iteration 63 / 300: loss 0.596240\n",
      "iteration 63 / 300: loss 0.609637\n",
      "iteration 63 / 300: loss 0.593574\n",
      "iteration 63 / 300: loss 0.629009\n",
      "iteration 63 / 300: loss 0.581170\n",
      "iteration 63 / 300: loss 0.608868\n",
      "iteration 63 / 300: loss 0.588251\n",
      "iteration 63 / 300: loss 0.592543\n",
      "iteration 63 / 300: loss 0.572154\n",
      "iteration 63 / 300: loss 0.583804\n",
      "iteration 63 / 300: loss 0.609148\n",
      "iteration 63 / 300: loss 0.599238\n",
      "iteration 63 / 300: loss 0.584625\n",
      "iteration 63 / 300: loss 0.616153\n",
      "iteration 63 / 300: loss 0.592523\n",
      "iteration 63 / 300: loss 0.586337\n",
      "iteration 63 / 300: loss 0.592248\n",
      "iteration 63 / 300: loss 0.605268\n",
      "iteration 63 / 300: loss 0.596718\n",
      "iteration 63 / 300: loss 0.615602\n",
      "iteration 63 / 300: loss 0.609117\n",
      "iteration 63 / 300: loss 0.599154\n",
      "iteration 63 / 300: loss 0.589748\n",
      "iteration 63 / 300: loss 0.618696\n",
      "iteration 63 / 300: loss 0.595682\n",
      "iteration 63 / 300: loss 0.602674\n",
      "iteration 63 / 300: loss 0.632079\n",
      "iteration 63 / 300: loss 0.588441\n",
      "iteration 63 / 300: loss 0.607445\n",
      "iteration 63 / 300: loss 0.589004\n",
      "iteration 63 / 300: loss 0.601959\n",
      "iteration 63 / 300: loss 0.596814\n",
      "iteration 63 / 300: loss 0.590392\n",
      "iteration 63 / 300: loss 0.600534\n",
      "iteration 63 / 300: loss 0.605718\n",
      "iteration 63 / 300: loss 0.620366\n",
      "iteration 63 / 300: loss 0.589861\n",
      "iteration 63 / 300: loss 0.594699\n",
      "iteration 63 / 300: loss 0.586670\n",
      "iteration 63 / 300: loss 0.613950\n",
      "iteration 63 / 300: loss 0.588392\n",
      "iteration 63 / 300: loss 0.579301\n",
      "iteration 63 / 300: loss 0.568291\n",
      "iteration 63 / 300: loss 0.562907\n",
      "iteration 63 / 300: loss 0.595041\n",
      "iteration 63 / 300: loss 0.579551\n",
      "iteration 63 / 300: loss 0.587122\n",
      "iteration 63 / 300: loss 0.573718\n",
      "iteration 63 / 300: loss 0.596997\n",
      "iteration 63 / 300: loss 0.608681\n",
      "iteration 63 / 300: loss 0.611454\n",
      "iteration 63 / 300: loss 0.607148\n",
      "iteration 63 / 300: loss 0.584541\n",
      "iteration 63 / 300: loss 0.590323\n",
      "iteration 63 / 300: loss 0.596045\n",
      "iteration 63 / 300: loss 0.599697\n",
      "iteration 63 / 300: loss 0.597010\n",
      "iteration 63 / 300: loss 0.590488\n",
      "iteration 63 / 300: loss 0.591911\n",
      "iteration 63 / 300: loss 0.585551\n",
      "iteration 63 / 300: loss 0.600455\n",
      "iteration 63 / 300: loss 0.599588\n",
      "iteration 63 / 300: loss 0.614895\n",
      "iteration 63 / 300: loss 0.598580\n",
      "iteration 63 / 300: loss 0.600061\n",
      "iteration 63 / 300: loss 0.604223\n",
      "iteration 63 / 300: loss 0.593749\n",
      "iteration 63 / 300: loss 0.593278\n",
      "iteration 63 / 300: loss 0.589827\n",
      "iteration 63 / 300: loss 0.597452\n",
      "iteration 63 / 300: loss 0.606595\n",
      "iteration 63 / 300: loss 0.611334\n",
      "iteration 63 / 300: loss 0.588522\n",
      "iteration 63 / 300: loss 0.599970\n",
      "iteration 63 / 300: loss 0.603544\n",
      "iteration 63 / 300: loss 0.605861\n",
      "iteration 63 / 300: loss 0.604816\n",
      "iteration 63 / 300: loss 0.624835\n",
      "iteration 63 / 300: loss 0.587862\n",
      "iteration 63 / 300: loss 0.581540\n",
      "iteration 63 / 300: loss 0.626010\n",
      "iteration 63 / 300: loss 0.604169\n",
      "iteration 63 / 300: loss 0.605141\n",
      "iteration 63 / 300: loss 0.596419\n",
      "iteration 63 / 300: loss 0.598473\n",
      "iteration 63 / 300: loss 0.593635\n",
      "iteration 63 / 300: loss 0.590327\n",
      "iteration 63 / 300: loss 0.600165\n",
      "iteration 63 / 300: loss 0.612150\n",
      "iteration 63 / 300: loss 0.593310\n",
      "iteration 63 / 300: loss 0.600289\n",
      "iteration 63 / 300: loss 0.604103\n",
      "iteration 63 / 300: loss 0.603281\n",
      "iteration 63 / 300: loss 0.580575\n",
      "iteration 63 / 300: loss 0.602406\n",
      "iteration 64 / 300: loss 0.586315\n",
      "iteration 64 / 300: loss 0.589137\n",
      "iteration 64 / 300: loss 0.568271\n",
      "iteration 64 / 300: loss 0.593030\n",
      "iteration 64 / 300: loss 0.594347\n",
      "iteration 64 / 300: loss 0.596151\n",
      "iteration 64 / 300: loss 0.609556\n",
      "iteration 64 / 300: loss 0.593498\n",
      "iteration 64 / 300: loss 0.628922\n",
      "iteration 64 / 300: loss 0.581077\n",
      "iteration 64 / 300: loss 0.608780\n",
      "iteration 64 / 300: loss 0.588175\n",
      "iteration 64 / 300: loss 0.592464\n",
      "iteration 64 / 300: loss 0.572086\n",
      "iteration 64 / 300: loss 0.583735\n",
      "iteration 64 / 300: loss 0.609080\n",
      "iteration 64 / 300: loss 0.599158\n",
      "iteration 64 / 300: loss 0.584553\n",
      "iteration 64 / 300: loss 0.616069\n",
      "iteration 64 / 300: loss 0.592443\n",
      "iteration 64 / 300: loss 0.586260\n",
      "iteration 64 / 300: loss 0.592162\n",
      "iteration 64 / 300: loss 0.605181\n",
      "iteration 64 / 300: loss 0.596634\n",
      "iteration 64 / 300: loss 0.615542\n",
      "iteration 64 / 300: loss 0.609049\n",
      "iteration 64 / 300: loss 0.599068\n",
      "iteration 64 / 300: loss 0.589670\n",
      "iteration 64 / 300: loss 0.618607\n",
      "iteration 64 / 300: loss 0.595595\n",
      "iteration 64 / 300: loss 0.602582\n",
      "iteration 64 / 300: loss 0.631983\n",
      "iteration 64 / 300: loss 0.588358\n",
      "iteration 64 / 300: loss 0.607366\n",
      "iteration 64 / 300: loss 0.588912\n",
      "iteration 64 / 300: loss 0.601858\n",
      "iteration 64 / 300: loss 0.596733\n",
      "iteration 64 / 300: loss 0.590288\n",
      "iteration 64 / 300: loss 0.600444\n",
      "iteration 64 / 300: loss 0.605641\n",
      "iteration 64 / 300: loss 0.620278\n",
      "iteration 64 / 300: loss 0.589763\n",
      "iteration 64 / 300: loss 0.594602\n",
      "iteration 64 / 300: loss 0.586569\n",
      "iteration 64 / 300: loss 0.613885\n",
      "iteration 64 / 300: loss 0.588311\n",
      "iteration 64 / 300: loss 0.579212\n",
      "iteration 64 / 300: loss 0.568209\n",
      "iteration 64 / 300: loss 0.562847\n",
      "iteration 64 / 300: loss 0.594962\n",
      "iteration 64 / 300: loss 0.579483\n",
      "iteration 64 / 300: loss 0.587051\n",
      "iteration 64 / 300: loss 0.573640\n",
      "iteration 64 / 300: loss 0.596920\n",
      "iteration 64 / 300: loss 0.608613\n",
      "iteration 64 / 300: loss 0.611398\n",
      "iteration 64 / 300: loss 0.607066\n",
      "iteration 64 / 300: loss 0.584473\n",
      "iteration 64 / 300: loss 0.590259\n",
      "iteration 64 / 300: loss 0.595965\n",
      "iteration 64 / 300: loss 0.599629\n",
      "iteration 64 / 300: loss 0.596931\n",
      "iteration 64 / 300: loss 0.590424\n",
      "iteration 64 / 300: loss 0.591839\n",
      "iteration 64 / 300: loss 0.585489\n",
      "iteration 64 / 300: loss 0.600378\n",
      "iteration 64 / 300: loss 0.599525\n",
      "iteration 64 / 300: loss 0.614840\n",
      "iteration 64 / 300: loss 0.598507\n",
      "iteration 64 / 300: loss 0.599990\n",
      "iteration 64 / 300: loss 0.604139\n",
      "iteration 64 / 300: loss 0.593665\n",
      "iteration 64 / 300: loss 0.593194\n",
      "iteration 64 / 300: loss 0.589755\n",
      "iteration 64 / 300: loss 0.597358\n",
      "iteration 64 / 300: loss 0.606512\n",
      "iteration 64 / 300: loss 0.611261\n",
      "iteration 64 / 300: loss 0.588454\n",
      "iteration 64 / 300: loss 0.599910\n",
      "iteration 64 / 300: loss 0.603476\n",
      "iteration 64 / 300: loss 0.605786\n",
      "iteration 64 / 300: loss 0.604726\n",
      "iteration 64 / 300: loss 0.624772\n",
      "iteration 64 / 300: loss 0.587801\n",
      "iteration 64 / 300: loss 0.581467\n",
      "iteration 64 / 300: loss 0.625917\n",
      "iteration 64 / 300: loss 0.604090\n",
      "iteration 64 / 300: loss 0.605069\n",
      "iteration 64 / 300: loss 0.596333\n",
      "iteration 64 / 300: loss 0.598387\n",
      "iteration 64 / 300: loss 0.593553\n",
      "iteration 64 / 300: loss 0.590249\n",
      "iteration 64 / 300: loss 0.600079\n",
      "iteration 64 / 300: loss 0.612077\n",
      "iteration 64 / 300: loss 0.593231\n",
      "iteration 64 / 300: loss 0.600210\n",
      "iteration 64 / 300: loss 0.604010\n",
      "iteration 64 / 300: loss 0.603201\n",
      "iteration 64 / 300: loss 0.580505\n",
      "iteration 64 / 300: loss 0.602332\n",
      "iteration 65 / 300: loss 0.586241\n",
      "iteration 65 / 300: loss 0.589073\n",
      "iteration 65 / 300: loss 0.568202\n",
      "iteration 65 / 300: loss 0.592973\n",
      "iteration 65 / 300: loss 0.594278\n",
      "iteration 65 / 300: loss 0.596071\n",
      "iteration 65 / 300: loss 0.609482\n",
      "iteration 65 / 300: loss 0.593428\n",
      "iteration 65 / 300: loss 0.628843\n",
      "iteration 65 / 300: loss 0.580993\n",
      "iteration 65 / 300: loss 0.608701\n",
      "iteration 65 / 300: loss 0.588106\n",
      "iteration 65 / 300: loss 0.592392\n",
      "iteration 65 / 300: loss 0.572022\n",
      "iteration 65 / 300: loss 0.583671\n",
      "iteration 65 / 300: loss 0.609019\n",
      "iteration 65 / 300: loss 0.599085\n",
      "iteration 65 / 300: loss 0.584489\n",
      "iteration 65 / 300: loss 0.615993\n",
      "iteration 65 / 300: loss 0.592371\n",
      "iteration 65 / 300: loss 0.586189\n",
      "iteration 65 / 300: loss 0.592085\n",
      "iteration 65 / 300: loss 0.605102\n",
      "iteration 65 / 300: loss 0.596556\n",
      "iteration 65 / 300: loss 0.615487\n",
      "iteration 65 / 300: loss 0.608987\n",
      "iteration 65 / 300: loss 0.598989\n",
      "iteration 65 / 300: loss 0.589600\n",
      "iteration 65 / 300: loss 0.618527\n",
      "iteration 65 / 300: loss 0.595517\n",
      "iteration 65 / 300: loss 0.602498\n",
      "iteration 65 / 300: loss 0.631896\n",
      "iteration 65 / 300: loss 0.588282\n",
      "iteration 65 / 300: loss 0.607293\n",
      "iteration 65 / 300: loss 0.588829\n",
      "iteration 65 / 300: loss 0.601767\n",
      "iteration 65 / 300: loss 0.596659\n",
      "iteration 65 / 300: loss 0.590194\n",
      "iteration 65 / 300: loss 0.600362\n",
      "iteration 65 / 300: loss 0.605570\n",
      "iteration 65 / 300: loss 0.620199\n",
      "iteration 65 / 300: loss 0.589674\n",
      "iteration 65 / 300: loss 0.594513\n",
      "iteration 65 / 300: loss 0.586478\n",
      "iteration 65 / 300: loss 0.613825\n",
      "iteration 65 / 300: loss 0.588238\n",
      "iteration 65 / 300: loss 0.579131\n",
      "iteration 65 / 300: loss 0.568136\n",
      "iteration 65 / 300: loss 0.562792\n",
      "iteration 65 / 300: loss 0.594889\n",
      "iteration 65 / 300: loss 0.579421\n",
      "iteration 65 / 300: loss 0.586986\n",
      "iteration 65 / 300: loss 0.573570\n",
      "iteration 65 / 300: loss 0.596849\n",
      "iteration 65 / 300: loss 0.608552\n",
      "iteration 65 / 300: loss 0.611346\n",
      "iteration 65 / 300: loss 0.606991\n",
      "iteration 65 / 300: loss 0.584410\n",
      "iteration 65 / 300: loss 0.590200\n",
      "iteration 65 / 300: loss 0.595893\n",
      "iteration 65 / 300: loss 0.599567\n",
      "iteration 65 / 300: loss 0.596858\n",
      "iteration 65 / 300: loss 0.590366\n",
      "iteration 65 / 300: loss 0.591774\n",
      "iteration 65 / 300: loss 0.585432\n",
      "iteration 65 / 300: loss 0.600309\n",
      "iteration 65 / 300: loss 0.599468\n",
      "iteration 65 / 300: loss 0.614790\n",
      "iteration 65 / 300: loss 0.598441\n",
      "iteration 65 / 300: loss 0.599925\n",
      "iteration 65 / 300: loss 0.604062\n",
      "iteration 65 / 300: loss 0.593589\n",
      "iteration 65 / 300: loss 0.593118\n",
      "iteration 65 / 300: loss 0.589689\n",
      "iteration 65 / 300: loss 0.597273\n",
      "iteration 65 / 300: loss 0.606437\n",
      "iteration 65 / 300: loss 0.611195\n",
      "iteration 65 / 300: loss 0.588391\n",
      "iteration 65 / 300: loss 0.599856\n",
      "iteration 65 / 300: loss 0.603414\n",
      "iteration 65 / 300: loss 0.605716\n",
      "iteration 65 / 300: loss 0.604645\n",
      "iteration 65 / 300: loss 0.624714\n",
      "iteration 65 / 300: loss 0.587746\n",
      "iteration 65 / 300: loss 0.581400\n",
      "iteration 65 / 300: loss 0.625833\n",
      "iteration 65 / 300: loss 0.604018\n",
      "iteration 65 / 300: loss 0.605003\n",
      "iteration 65 / 300: loss 0.596255\n",
      "iteration 65 / 300: loss 0.598308\n",
      "iteration 65 / 300: loss 0.593478\n",
      "iteration 65 / 300: loss 0.590179\n",
      "iteration 65 / 300: loss 0.600002\n",
      "iteration 65 / 300: loss 0.612010\n",
      "iteration 65 / 300: loss 0.593159\n",
      "iteration 65 / 300: loss 0.600138\n",
      "iteration 65 / 300: loss 0.603925\n",
      "iteration 65 / 300: loss 0.603128\n",
      "iteration 65 / 300: loss 0.580442\n",
      "iteration 65 / 300: loss 0.602265\n",
      "iteration 66 / 300: loss 0.586174\n",
      "iteration 66 / 300: loss 0.589014\n",
      "iteration 66 / 300: loss 0.568139\n",
      "iteration 66 / 300: loss 0.592920\n",
      "iteration 66 / 300: loss 0.594216\n",
      "iteration 66 / 300: loss 0.595998\n",
      "iteration 66 / 300: loss 0.609416\n",
      "iteration 66 / 300: loss 0.593364\n",
      "iteration 66 / 300: loss 0.628770\n",
      "iteration 66 / 300: loss 0.580916\n",
      "iteration 66 / 300: loss 0.608629\n",
      "iteration 66 / 300: loss 0.588042\n",
      "iteration 66 / 300: loss 0.592327\n",
      "iteration 66 / 300: loss 0.571964\n",
      "iteration 66 / 300: loss 0.583613\n",
      "iteration 66 / 300: loss 0.608964\n",
      "iteration 66 / 300: loss 0.599019\n",
      "iteration 66 / 300: loss 0.584430\n",
      "iteration 66 / 300: loss 0.615924\n",
      "iteration 66 / 300: loss 0.592304\n",
      "iteration 66 / 300: loss 0.586125\n",
      "iteration 66 / 300: loss 0.592014\n",
      "iteration 66 / 300: loss 0.605030\n",
      "iteration 66 / 300: loss 0.596486\n",
      "iteration 66 / 300: loss 0.615437\n",
      "iteration 66 / 300: loss 0.608931\n",
      "iteration 66 / 300: loss 0.598918\n",
      "iteration 66 / 300: loss 0.589536\n",
      "iteration 66 / 300: loss 0.618454\n",
      "iteration 66 / 300: loss 0.595446\n",
      "iteration 66 / 300: loss 0.602422\n",
      "iteration 66 / 300: loss 0.631816\n",
      "iteration 66 / 300: loss 0.588212\n",
      "iteration 66 / 300: loss 0.607227\n",
      "iteration 66 / 300: loss 0.588754\n",
      "iteration 66 / 300: loss 0.601683\n",
      "iteration 66 / 300: loss 0.596592\n",
      "iteration 66 / 300: loss 0.590109\n",
      "iteration 66 / 300: loss 0.600286\n",
      "iteration 66 / 300: loss 0.605505\n",
      "iteration 66 / 300: loss 0.620126\n",
      "iteration 66 / 300: loss 0.589593\n",
      "iteration 66 / 300: loss 0.594432\n",
      "iteration 66 / 300: loss 0.586395\n",
      "iteration 66 / 300: loss 0.613770\n",
      "iteration 66 / 300: loss 0.588171\n",
      "iteration 66 / 300: loss 0.579056\n",
      "iteration 66 / 300: loss 0.568069\n",
      "iteration 66 / 300: loss 0.562741\n",
      "iteration 66 / 300: loss 0.594824\n",
      "iteration 66 / 300: loss 0.579365\n",
      "iteration 66 / 300: loss 0.586928\n",
      "iteration 66 / 300: loss 0.573506\n",
      "iteration 66 / 300: loss 0.596784\n",
      "iteration 66 / 300: loss 0.608496\n",
      "iteration 66 / 300: loss 0.611299\n",
      "iteration 66 / 300: loss 0.606923\n",
      "iteration 66 / 300: loss 0.584354\n",
      "iteration 66 / 300: loss 0.590147\n",
      "iteration 66 / 300: loss 0.595827\n",
      "iteration 66 / 300: loss 0.599511\n",
      "iteration 66 / 300: loss 0.596791\n",
      "iteration 66 / 300: loss 0.590312\n",
      "iteration 66 / 300: loss 0.591715\n",
      "iteration 66 / 300: loss 0.585380\n",
      "iteration 66 / 300: loss 0.600246\n",
      "iteration 66 / 300: loss 0.599415\n",
      "iteration 66 / 300: loss 0.614744\n",
      "iteration 66 / 300: loss 0.598381\n",
      "iteration 66 / 300: loss 0.599866\n",
      "iteration 66 / 300: loss 0.603993\n",
      "iteration 66 / 300: loss 0.593520\n",
      "iteration 66 / 300: loss 0.593049\n",
      "iteration 66 / 300: loss 0.589629\n",
      "iteration 66 / 300: loss 0.597196\n",
      "iteration 66 / 300: loss 0.606369\n",
      "iteration 66 / 300: loss 0.611135\n",
      "iteration 66 / 300: loss 0.588334\n",
      "iteration 66 / 300: loss 0.599807\n",
      "iteration 66 / 300: loss 0.603357\n",
      "iteration 66 / 300: loss 0.605653\n",
      "iteration 66 / 300: loss 0.604571\n",
      "iteration 66 / 300: loss 0.624661\n",
      "iteration 66 / 300: loss 0.587697\n",
      "iteration 66 / 300: loss 0.581340\n",
      "iteration 66 / 300: loss 0.625757\n",
      "iteration 66 / 300: loss 0.603952\n",
      "iteration 66 / 300: loss 0.604943\n",
      "iteration 66 / 300: loss 0.596184\n",
      "iteration 66 / 300: loss 0.598237\n",
      "iteration 66 / 300: loss 0.593410\n",
      "iteration 66 / 300: loss 0.590115\n",
      "iteration 66 / 300: loss 0.599931\n",
      "iteration 66 / 300: loss 0.611950\n",
      "iteration 66 / 300: loss 0.593094\n",
      "iteration 66 / 300: loss 0.600073\n",
      "iteration 66 / 300: loss 0.603848\n",
      "iteration 66 / 300: loss 0.603062\n",
      "iteration 66 / 300: loss 0.580383\n",
      "iteration 66 / 300: loss 0.602203\n",
      "iteration 67 / 300: loss 0.586113\n",
      "iteration 67 / 300: loss 0.588960\n",
      "iteration 67 / 300: loss 0.568081\n",
      "iteration 67 / 300: loss 0.592871\n",
      "iteration 67 / 300: loss 0.594160\n",
      "iteration 67 / 300: loss 0.595932\n",
      "iteration 67 / 300: loss 0.609356\n",
      "iteration 67 / 300: loss 0.593306\n",
      "iteration 67 / 300: loss 0.628705\n",
      "iteration 67 / 300: loss 0.580845\n",
      "iteration 67 / 300: loss 0.608563\n",
      "iteration 67 / 300: loss 0.587983\n",
      "iteration 67 / 300: loss 0.592267\n",
      "iteration 67 / 300: loss 0.571911\n",
      "iteration 67 / 300: loss 0.583560\n",
      "iteration 67 / 300: loss 0.608914\n",
      "iteration 67 / 300: loss 0.598958\n",
      "iteration 67 / 300: loss 0.584377\n",
      "iteration 67 / 300: loss 0.615861\n",
      "iteration 67 / 300: loss 0.592244\n",
      "iteration 67 / 300: loss 0.586066\n",
      "iteration 67 / 300: loss 0.591950\n",
      "iteration 67 / 300: loss 0.604965\n",
      "iteration 67 / 300: loss 0.596421\n",
      "iteration 67 / 300: loss 0.615391\n",
      "iteration 67 / 300: loss 0.608880\n",
      "iteration 67 / 300: loss 0.598853\n",
      "iteration 67 / 300: loss 0.589479\n",
      "iteration 67 / 300: loss 0.618388\n",
      "iteration 67 / 300: loss 0.595382\n",
      "iteration 67 / 300: loss 0.602353\n",
      "iteration 67 / 300: loss 0.631744\n",
      "iteration 67 / 300: loss 0.588148\n",
      "iteration 67 / 300: loss 0.607166\n",
      "iteration 67 / 300: loss 0.588686\n",
      "iteration 67 / 300: loss 0.601608\n",
      "iteration 67 / 300: loss 0.596532\n",
      "iteration 67 / 300: loss 0.590031\n",
      "iteration 67 / 300: loss 0.600217\n",
      "iteration 67 / 300: loss 0.605445\n",
      "iteration 67 / 300: loss 0.620060\n",
      "iteration 67 / 300: loss 0.589520\n",
      "iteration 67 / 300: loss 0.594359\n",
      "iteration 67 / 300: loss 0.586320\n",
      "iteration 67 / 300: loss 0.613720\n",
      "iteration 67 / 300: loss 0.588111\n",
      "iteration 67 / 300: loss 0.578989\n",
      "iteration 67 / 300: loss 0.568009\n",
      "iteration 67 / 300: loss 0.562695\n",
      "iteration 67 / 300: loss 0.594764\n",
      "iteration 67 / 300: loss 0.579314\n",
      "iteration 67 / 300: loss 0.586874\n",
      "iteration 67 / 300: loss 0.573447\n",
      "iteration 67 / 300: loss 0.596725\n",
      "iteration 67 / 300: loss 0.608445\n",
      "iteration 67 / 300: loss 0.611257\n",
      "iteration 67 / 300: loss 0.606862\n",
      "iteration 67 / 300: loss 0.584302\n",
      "iteration 67 / 300: loss 0.590099\n",
      "iteration 67 / 300: loss 0.595767\n",
      "iteration 67 / 300: loss 0.599460\n",
      "iteration 67 / 300: loss 0.596730\n",
      "iteration 67 / 300: loss 0.590263\n",
      "iteration 67 / 300: loss 0.591661\n",
      "iteration 67 / 300: loss 0.585332\n",
      "iteration 67 / 300: loss 0.600189\n",
      "iteration 67 / 300: loss 0.599368\n",
      "iteration 67 / 300: loss 0.614702\n",
      "iteration 67 / 300: loss 0.598327\n",
      "iteration 67 / 300: loss 0.599812\n",
      "iteration 67 / 300: loss 0.603929\n",
      "iteration 67 / 300: loss 0.593458\n",
      "iteration 67 / 300: loss 0.592987\n",
      "iteration 67 / 300: loss 0.589574\n",
      "iteration 67 / 300: loss 0.597126\n",
      "iteration 67 / 300: loss 0.606307\n",
      "iteration 67 / 300: loss 0.611081\n",
      "iteration 67 / 300: loss 0.588283\n",
      "iteration 67 / 300: loss 0.599763\n",
      "iteration 67 / 300: loss 0.603305\n",
      "iteration 67 / 300: loss 0.605596\n",
      "iteration 67 / 300: loss 0.604503\n",
      "iteration 67 / 300: loss 0.624613\n",
      "iteration 67 / 300: loss 0.587652\n",
      "iteration 67 / 300: loss 0.581285\n",
      "iteration 67 / 300: loss 0.625689\n",
      "iteration 67 / 300: loss 0.603893\n",
      "iteration 67 / 300: loss 0.604887\n",
      "iteration 67 / 300: loss 0.596119\n",
      "iteration 67 / 300: loss 0.598172\n",
      "iteration 67 / 300: loss 0.593348\n",
      "iteration 67 / 300: loss 0.590056\n",
      "iteration 67 / 300: loss 0.599868\n",
      "iteration 67 / 300: loss 0.611896\n",
      "iteration 67 / 300: loss 0.593035\n",
      "iteration 67 / 300: loss 0.600013\n",
      "iteration 67 / 300: loss 0.603778\n",
      "iteration 67 / 300: loss 0.603001\n",
      "iteration 67 / 300: loss 0.580331\n",
      "iteration 67 / 300: loss 0.602147\n",
      "iteration 68 / 300: loss 0.586058\n",
      "iteration 68 / 300: loss 0.588911\n",
      "iteration 68 / 300: loss 0.568029\n",
      "iteration 68 / 300: loss 0.592827\n",
      "iteration 68 / 300: loss 0.594109\n",
      "iteration 68 / 300: loss 0.595872\n",
      "iteration 68 / 300: loss 0.609301\n",
      "iteration 68 / 300: loss 0.593253\n",
      "iteration 68 / 300: loss 0.628645\n",
      "iteration 68 / 300: loss 0.580781\n",
      "iteration 68 / 300: loss 0.608503\n",
      "iteration 68 / 300: loss 0.587930\n",
      "iteration 68 / 300: loss 0.592213\n",
      "iteration 68 / 300: loss 0.571862\n",
      "iteration 68 / 300: loss 0.583512\n",
      "iteration 68 / 300: loss 0.608869\n",
      "iteration 68 / 300: loss 0.598902\n",
      "iteration 68 / 300: loss 0.584328\n",
      "iteration 68 / 300: loss 0.615804\n",
      "iteration 68 / 300: loss 0.592189\n",
      "iteration 68 / 300: loss 0.586013\n",
      "iteration 68 / 300: loss 0.591891\n",
      "iteration 68 / 300: loss 0.604906\n",
      "iteration 68 / 300: loss 0.596362\n",
      "iteration 68 / 300: loss 0.615350\n",
      "iteration 68 / 300: loss 0.608834\n",
      "iteration 68 / 300: loss 0.598794\n",
      "iteration 68 / 300: loss 0.589427\n",
      "iteration 68 / 300: loss 0.618328\n",
      "iteration 68 / 300: loss 0.595323\n",
      "iteration 68 / 300: loss 0.602290\n",
      "iteration 68 / 300: loss 0.631678\n",
      "iteration 68 / 300: loss 0.588090\n",
      "iteration 68 / 300: loss 0.607111\n",
      "iteration 68 / 300: loss 0.588624\n",
      "iteration 68 / 300: loss 0.601540\n",
      "iteration 68 / 300: loss 0.596477\n",
      "iteration 68 / 300: loss 0.589961\n",
      "iteration 68 / 300: loss 0.600154\n",
      "iteration 68 / 300: loss 0.605391\n",
      "iteration 68 / 300: loss 0.620000\n",
      "iteration 68 / 300: loss 0.589453\n",
      "iteration 68 / 300: loss 0.594292\n",
      "iteration 68 / 300: loss 0.586252\n",
      "iteration 68 / 300: loss 0.613674\n",
      "iteration 68 / 300: loss 0.588056\n",
      "iteration 68 / 300: loss 0.578927\n",
      "iteration 68 / 300: loss 0.567955\n",
      "iteration 68 / 300: loss 0.562653\n",
      "iteration 68 / 300: loss 0.594710\n",
      "iteration 68 / 300: loss 0.579268\n",
      "iteration 68 / 300: loss 0.586826\n",
      "iteration 68 / 300: loss 0.573395\n",
      "iteration 68 / 300: loss 0.596671\n",
      "iteration 68 / 300: loss 0.608399\n",
      "iteration 68 / 300: loss 0.611218\n",
      "iteration 68 / 300: loss 0.606806\n",
      "iteration 68 / 300: loss 0.584255\n",
      "iteration 68 / 300: loss 0.590055\n",
      "iteration 68 / 300: loss 0.595712\n",
      "iteration 68 / 300: loss 0.599413\n",
      "iteration 68 / 300: loss 0.596675\n",
      "iteration 68 / 300: loss 0.590218\n",
      "iteration 68 / 300: loss 0.591612\n",
      "iteration 68 / 300: loss 0.585288\n",
      "iteration 68 / 300: loss 0.600138\n",
      "iteration 68 / 300: loss 0.599324\n",
      "iteration 68 / 300: loss 0.614664\n",
      "iteration 68 / 300: loss 0.598277\n",
      "iteration 68 / 300: loss 0.599764\n",
      "iteration 68 / 300: loss 0.603872\n",
      "iteration 68 / 300: loss 0.593401\n",
      "iteration 68 / 300: loss 0.592931\n",
      "iteration 68 / 300: loss 0.589525\n",
      "iteration 68 / 300: loss 0.597062\n",
      "iteration 68 / 300: loss 0.606250\n",
      "iteration 68 / 300: loss 0.611032\n",
      "iteration 68 / 300: loss 0.588236\n",
      "iteration 68 / 300: loss 0.599723\n",
      "iteration 68 / 300: loss 0.603258\n",
      "iteration 68 / 300: loss 0.605543\n",
      "iteration 68 / 300: loss 0.604442\n",
      "iteration 68 / 300: loss 0.624570\n",
      "iteration 68 / 300: loss 0.587611\n",
      "iteration 68 / 300: loss 0.581235\n",
      "iteration 68 / 300: loss 0.625627\n",
      "iteration 68 / 300: loss 0.603839\n",
      "iteration 68 / 300: loss 0.604836\n",
      "iteration 68 / 300: loss 0.596060\n",
      "iteration 68 / 300: loss 0.598113\n",
      "iteration 68 / 300: loss 0.593292\n",
      "iteration 68 / 300: loss 0.590004\n",
      "iteration 68 / 300: loss 0.599810\n",
      "iteration 68 / 300: loss 0.611846\n",
      "iteration 68 / 300: loss 0.592981\n",
      "iteration 68 / 300: loss 0.599959\n",
      "iteration 68 / 300: loss 0.603714\n",
      "iteration 68 / 300: loss 0.602946\n",
      "iteration 68 / 300: loss 0.580282\n",
      "iteration 68 / 300: loss 0.602096\n",
      "iteration 69 / 300: loss 0.586008\n",
      "iteration 69 / 300: loss 0.588867\n",
      "iteration 69 / 300: loss 0.567982\n",
      "iteration 69 / 300: loss 0.592786\n",
      "iteration 69 / 300: loss 0.594062\n",
      "iteration 69 / 300: loss 0.595818\n",
      "iteration 69 / 300: loss 0.609252\n",
      "iteration 69 / 300: loss 0.593205\n",
      "iteration 69 / 300: loss 0.628590\n",
      "iteration 69 / 300: loss 0.580722\n",
      "iteration 69 / 300: loss 0.608449\n",
      "iteration 69 / 300: loss 0.587881\n",
      "iteration 69 / 300: loss 0.592164\n",
      "iteration 69 / 300: loss 0.571817\n",
      "iteration 69 / 300: loss 0.583467\n",
      "iteration 69 / 300: loss 0.608829\n",
      "iteration 69 / 300: loss 0.598852\n",
      "iteration 69 / 300: loss 0.584284\n",
      "iteration 69 / 300: loss 0.615752\n",
      "iteration 69 / 300: loss 0.592139\n",
      "iteration 69 / 300: loss 0.585965\n",
      "iteration 69 / 300: loss 0.591838\n",
      "iteration 69 / 300: loss 0.604852\n",
      "iteration 69 / 300: loss 0.596309\n",
      "iteration 69 / 300: loss 0.615313\n",
      "iteration 69 / 300: loss 0.608792\n",
      "iteration 69 / 300: loss 0.598741\n",
      "iteration 69 / 300: loss 0.589381\n",
      "iteration 69 / 300: loss 0.618274\n",
      "iteration 69 / 300: loss 0.595271\n",
      "iteration 69 / 300: loss 0.602233\n",
      "iteration 69 / 300: loss 0.631617\n",
      "iteration 69 / 300: loss 0.588037\n",
      "iteration 69 / 300: loss 0.607060\n",
      "iteration 69 / 300: loss 0.588568\n",
      "iteration 69 / 300: loss 0.601478\n",
      "iteration 69 / 300: loss 0.596428\n",
      "iteration 69 / 300: loss 0.589898\n",
      "iteration 69 / 300: loss 0.600096\n",
      "iteration 69 / 300: loss 0.605342\n",
      "iteration 69 / 300: loss 0.619946\n",
      "iteration 69 / 300: loss 0.589392\n",
      "iteration 69 / 300: loss 0.594231\n",
      "iteration 69 / 300: loss 0.586190\n",
      "iteration 69 / 300: loss 0.613631\n",
      "iteration 69 / 300: loss 0.588006\n",
      "iteration 69 / 300: loss 0.578871\n",
      "iteration 69 / 300: loss 0.567905\n",
      "iteration 69 / 300: loss 0.562615\n",
      "iteration 69 / 300: loss 0.594660\n",
      "iteration 69 / 300: loss 0.579226\n",
      "iteration 69 / 300: loss 0.586782\n",
      "iteration 69 / 300: loss 0.573347\n",
      "iteration 69 / 300: loss 0.596623\n",
      "iteration 69 / 300: loss 0.608357\n",
      "iteration 69 / 300: loss 0.611183\n",
      "iteration 69 / 300: loss 0.606755\n",
      "iteration 69 / 300: loss 0.584212\n",
      "iteration 69 / 300: loss 0.590015\n",
      "iteration 69 / 300: loss 0.595663\n",
      "iteration 69 / 300: loss 0.599371\n",
      "iteration 69 / 300: loss 0.596624\n",
      "iteration 69 / 300: loss 0.590177\n",
      "iteration 69 / 300: loss 0.591568\n",
      "iteration 69 / 300: loss 0.585249\n",
      "iteration 69 / 300: loss 0.600091\n",
      "iteration 69 / 300: loss 0.599285\n",
      "iteration 69 / 300: loss 0.614629\n",
      "iteration 69 / 300: loss 0.598232\n",
      "iteration 69 / 300: loss 0.599720\n",
      "iteration 69 / 300: loss 0.603820\n",
      "iteration 69 / 300: loss 0.593350\n",
      "iteration 69 / 300: loss 0.592879\n",
      "iteration 69 / 300: loss 0.589480\n",
      "iteration 69 / 300: loss 0.597004\n",
      "iteration 69 / 300: loss 0.606199\n",
      "iteration 69 / 300: loss 0.610987\n",
      "iteration 69 / 300: loss 0.588193\n",
      "iteration 69 / 300: loss 0.599688\n",
      "iteration 69 / 300: loss 0.603215\n",
      "iteration 69 / 300: loss 0.605495\n",
      "iteration 69 / 300: loss 0.604387\n",
      "iteration 69 / 300: loss 0.624530\n",
      "iteration 69 / 300: loss 0.587574\n",
      "iteration 69 / 300: loss 0.581190\n",
      "iteration 69 / 300: loss 0.625571\n",
      "iteration 69 / 300: loss 0.603789\n",
      "iteration 69 / 300: loss 0.604790\n",
      "iteration 69 / 300: loss 0.596006\n",
      "iteration 69 / 300: loss 0.598060\n",
      "iteration 69 / 300: loss 0.593240\n",
      "iteration 69 / 300: loss 0.589956\n",
      "iteration 69 / 300: loss 0.599758\n",
      "iteration 69 / 300: loss 0.611802\n",
      "iteration 69 / 300: loss 0.592932\n",
      "iteration 69 / 300: loss 0.599909\n",
      "iteration 69 / 300: loss 0.603657\n",
      "iteration 69 / 300: loss 0.602896\n",
      "iteration 69 / 300: loss 0.580239\n",
      "iteration 69 / 300: loss 0.602049\n",
      "iteration 70 / 300: loss 0.585963\n",
      "iteration 70 / 300: loss 0.588826\n",
      "iteration 70 / 300: loss 0.567938\n",
      "iteration 70 / 300: loss 0.592749\n",
      "iteration 70 / 300: loss 0.594020\n",
      "iteration 70 / 300: loss 0.595768\n",
      "iteration 70 / 300: loss 0.609208\n",
      "iteration 70 / 300: loss 0.593161\n",
      "iteration 70 / 300: loss 0.628541\n",
      "iteration 70 / 300: loss 0.580669\n",
      "iteration 70 / 300: loss 0.608400\n",
      "iteration 70 / 300: loss 0.587837\n",
      "iteration 70 / 300: loss 0.592119\n",
      "iteration 70 / 300: loss 0.571776\n",
      "iteration 70 / 300: loss 0.583427\n",
      "iteration 70 / 300: loss 0.608792\n",
      "iteration 70 / 300: loss 0.598806\n",
      "iteration 70 / 300: loss 0.584244\n",
      "iteration 70 / 300: loss 0.615705\n",
      "iteration 70 / 300: loss 0.592093\n",
      "iteration 70 / 300: loss 0.585922\n",
      "iteration 70 / 300: loss 0.591790\n",
      "iteration 70 / 300: loss 0.604804\n",
      "iteration 70 / 300: loss 0.596260\n",
      "iteration 70 / 300: loss 0.615279\n",
      "iteration 70 / 300: loss 0.608755\n",
      "iteration 70 / 300: loss 0.598692\n",
      "iteration 70 / 300: loss 0.589338\n",
      "iteration 70 / 300: loss 0.618224\n",
      "iteration 70 / 300: loss 0.595223\n",
      "iteration 70 / 300: loss 0.602181\n",
      "iteration 70 / 300: loss 0.631563\n",
      "iteration 70 / 300: loss 0.587988\n",
      "iteration 70 / 300: loss 0.607014\n",
      "iteration 70 / 300: loss 0.588517\n",
      "iteration 70 / 300: loss 0.601422\n",
      "iteration 70 / 300: loss 0.596383\n",
      "iteration 70 / 300: loss 0.589840\n",
      "iteration 70 / 300: loss 0.600043\n",
      "iteration 70 / 300: loss 0.605297\n",
      "iteration 70 / 300: loss 0.619896\n",
      "iteration 70 / 300: loss 0.589337\n",
      "iteration 70 / 300: loss 0.594176\n",
      "iteration 70 / 300: loss 0.586134\n",
      "iteration 70 / 300: loss 0.613593\n",
      "iteration 70 / 300: loss 0.587960\n",
      "iteration 70 / 300: loss 0.578821\n",
      "iteration 70 / 300: loss 0.567861\n",
      "iteration 70 / 300: loss 0.562580\n",
      "iteration 70 / 300: loss 0.594616\n",
      "iteration 70 / 300: loss 0.579188\n",
      "iteration 70 / 300: loss 0.586743\n",
      "iteration 70 / 300: loss 0.573304\n",
      "iteration 70 / 300: loss 0.596578\n",
      "iteration 70 / 300: loss 0.608319\n",
      "iteration 70 / 300: loss 0.611151\n",
      "iteration 70 / 300: loss 0.606709\n",
      "iteration 70 / 300: loss 0.584173\n",
      "iteration 70 / 300: loss 0.589979\n",
      "iteration 70 / 300: loss 0.595618\n",
      "iteration 70 / 300: loss 0.599332\n",
      "iteration 70 / 300: loss 0.596579\n",
      "iteration 70 / 300: loss 0.590140\n",
      "iteration 70 / 300: loss 0.591527\n",
      "iteration 70 / 300: loss 0.585212\n",
      "iteration 70 / 300: loss 0.600049\n",
      "iteration 70 / 300: loss 0.599249\n",
      "iteration 70 / 300: loss 0.614597\n",
      "iteration 70 / 300: loss 0.598191\n",
      "iteration 70 / 300: loss 0.599680\n",
      "iteration 70 / 300: loss 0.603773\n",
      "iteration 70 / 300: loss 0.593304\n",
      "iteration 70 / 300: loss 0.592833\n",
      "iteration 70 / 300: loss 0.589439\n",
      "iteration 70 / 300: loss 0.596952\n",
      "iteration 70 / 300: loss 0.606153\n",
      "iteration 70 / 300: loss 0.610947\n",
      "iteration 70 / 300: loss 0.588155\n",
      "iteration 70 / 300: loss 0.599655\n",
      "iteration 70 / 300: loss 0.603175\n",
      "iteration 70 / 300: loss 0.605452\n",
      "iteration 70 / 300: loss 0.604336\n",
      "iteration 70 / 300: loss 0.624494\n",
      "iteration 70 / 300: loss 0.587541\n",
      "iteration 70 / 300: loss 0.581149\n",
      "iteration 70 / 300: loss 0.625520\n",
      "iteration 70 / 300: loss 0.603744\n",
      "iteration 70 / 300: loss 0.604747\n",
      "iteration 70 / 300: loss 0.595956\n",
      "iteration 70 / 300: loss 0.598011\n",
      "iteration 70 / 300: loss 0.593194\n",
      "iteration 70 / 300: loss 0.589913\n",
      "iteration 70 / 300: loss 0.599711\n",
      "iteration 70 / 300: loss 0.611762\n",
      "iteration 70 / 300: loss 0.592888\n",
      "iteration 70 / 300: loss 0.599864\n",
      "iteration 70 / 300: loss 0.603604\n",
      "iteration 70 / 300: loss 0.602851\n",
      "iteration 70 / 300: loss 0.580199\n",
      "iteration 70 / 300: loss 0.602007\n",
      "iteration 71 / 300: loss 0.585922\n",
      "iteration 71 / 300: loss 0.588789\n",
      "iteration 71 / 300: loss 0.567899\n",
      "iteration 71 / 300: loss 0.592715\n",
      "iteration 71 / 300: loss 0.593982\n",
      "iteration 71 / 300: loss 0.595724\n",
      "iteration 71 / 300: loss 0.609167\n",
      "iteration 71 / 300: loss 0.593122\n",
      "iteration 71 / 300: loss 0.628496\n",
      "iteration 71 / 300: loss 0.580621\n",
      "iteration 71 / 300: loss 0.608356\n",
      "iteration 71 / 300: loss 0.587796\n",
      "iteration 71 / 300: loss 0.592079\n",
      "iteration 71 / 300: loss 0.571739\n",
      "iteration 71 / 300: loss 0.583390\n",
      "iteration 71 / 300: loss 0.608759\n",
      "iteration 71 / 300: loss 0.598764\n",
      "iteration 71 / 300: loss 0.584208\n",
      "iteration 71 / 300: loss 0.615663\n",
      "iteration 71 / 300: loss 0.592052\n",
      "iteration 71 / 300: loss 0.585882\n",
      "iteration 71 / 300: loss 0.591747\n",
      "iteration 71 / 300: loss 0.604760\n",
      "iteration 71 / 300: loss 0.596216\n",
      "iteration 71 / 300: loss 0.615248\n",
      "iteration 71 / 300: loss 0.608720\n",
      "iteration 71 / 300: loss 0.598648\n",
      "iteration 71 / 300: loss 0.589300\n",
      "iteration 71 / 300: loss 0.618180\n",
      "iteration 71 / 300: loss 0.595180\n",
      "iteration 71 / 300: loss 0.602134\n",
      "iteration 71 / 300: loss 0.631513\n",
      "iteration 71 / 300: loss 0.587944\n",
      "iteration 71 / 300: loss 0.606972\n",
      "iteration 71 / 300: loss 0.588471\n",
      "iteration 71 / 300: loss 0.601372\n",
      "iteration 71 / 300: loss 0.596343\n",
      "iteration 71 / 300: loss 0.589788\n",
      "iteration 71 / 300: loss 0.599995\n",
      "iteration 71 / 300: loss 0.605256\n",
      "iteration 71 / 300: loss 0.619851\n",
      "iteration 71 / 300: loss 0.589287\n",
      "iteration 71 / 300: loss 0.594126\n",
      "iteration 71 / 300: loss 0.586083\n",
      "iteration 71 / 300: loss 0.613558\n",
      "iteration 71 / 300: loss 0.587919\n",
      "iteration 71 / 300: loss 0.578774\n",
      "iteration 71 / 300: loss 0.567820\n",
      "iteration 71 / 300: loss 0.562548\n",
      "iteration 71 / 300: loss 0.594575\n",
      "iteration 71 / 300: loss 0.579154\n",
      "iteration 71 / 300: loss 0.586707\n",
      "iteration 71 / 300: loss 0.573265\n",
      "iteration 71 / 300: loss 0.596538\n",
      "iteration 71 / 300: loss 0.608284\n",
      "iteration 71 / 300: loss 0.611121\n",
      "iteration 71 / 300: loss 0.606667\n",
      "iteration 71 / 300: loss 0.584137\n",
      "iteration 71 / 300: loss 0.589946\n",
      "iteration 71 / 300: loss 0.595577\n",
      "iteration 71 / 300: loss 0.599297\n",
      "iteration 71 / 300: loss 0.596537\n",
      "iteration 71 / 300: loss 0.590106\n",
      "iteration 71 / 300: loss 0.591490\n",
      "iteration 71 / 300: loss 0.585179\n",
      "iteration 71 / 300: loss 0.600011\n",
      "iteration 71 / 300: loss 0.599217\n",
      "iteration 71 / 300: loss 0.614568\n",
      "iteration 71 / 300: loss 0.598154\n",
      "iteration 71 / 300: loss 0.599644\n",
      "iteration 71 / 300: loss 0.603730\n",
      "iteration 71 / 300: loss 0.593262\n",
      "iteration 71 / 300: loss 0.592791\n",
      "iteration 71 / 300: loss 0.589402\n",
      "iteration 71 / 300: loss 0.596904\n",
      "iteration 71 / 300: loss 0.606111\n",
      "iteration 71 / 300: loss 0.610910\n",
      "iteration 71 / 300: loss 0.588120\n",
      "iteration 71 / 300: loss 0.599626\n",
      "iteration 71 / 300: loss 0.603140\n",
      "iteration 71 / 300: loss 0.605412\n",
      "iteration 71 / 300: loss 0.604290\n",
      "iteration 71 / 300: loss 0.624461\n",
      "iteration 71 / 300: loss 0.587511\n",
      "iteration 71 / 300: loss 0.581112\n",
      "iteration 71 / 300: loss 0.625475\n",
      "iteration 71 / 300: loss 0.603704\n",
      "iteration 71 / 300: loss 0.604708\n",
      "iteration 71 / 300: loss 0.595912\n",
      "iteration 71 / 300: loss 0.597967\n",
      "iteration 71 / 300: loss 0.593151\n",
      "iteration 71 / 300: loss 0.589873\n",
      "iteration 71 / 300: loss 0.599669\n",
      "iteration 71 / 300: loss 0.611725\n",
      "iteration 71 / 300: loss 0.592848\n",
      "iteration 71 / 300: loss 0.599823\n",
      "iteration 71 / 300: loss 0.603557\n",
      "iteration 71 / 300: loss 0.602810\n",
      "iteration 71 / 300: loss 0.580163\n",
      "iteration 71 / 300: loss 0.601968\n",
      "iteration 72 / 300: loss 0.585885\n",
      "iteration 72 / 300: loss 0.588755\n",
      "iteration 72 / 300: loss 0.567863\n",
      "iteration 72 / 300: loss 0.592685\n",
      "iteration 72 / 300: loss 0.593947\n",
      "iteration 72 / 300: loss 0.595683\n",
      "iteration 72 / 300: loss 0.609131\n",
      "iteration 72 / 300: loss 0.593085\n",
      "iteration 72 / 300: loss 0.628455\n",
      "iteration 72 / 300: loss 0.580577\n",
      "iteration 72 / 300: loss 0.608315\n",
      "iteration 72 / 300: loss 0.587759\n",
      "iteration 72 / 300: loss 0.592042\n",
      "iteration 72 / 300: loss 0.571705\n",
      "iteration 72 / 300: loss 0.583356\n",
      "iteration 72 / 300: loss 0.608728\n",
      "iteration 72 / 300: loss 0.598726\n",
      "iteration 72 / 300: loss 0.584175\n",
      "iteration 72 / 300: loss 0.615624\n",
      "iteration 72 / 300: loss 0.592014\n",
      "iteration 72 / 300: loss 0.585846\n",
      "iteration 72 / 300: loss 0.591707\n",
      "iteration 72 / 300: loss 0.604720\n",
      "iteration 72 / 300: loss 0.596176\n",
      "iteration 72 / 300: loss 0.615220\n",
      "iteration 72 / 300: loss 0.608689\n",
      "iteration 72 / 300: loss 0.598608\n",
      "iteration 72 / 300: loss 0.589265\n",
      "iteration 72 / 300: loss 0.618140\n",
      "iteration 72 / 300: loss 0.595141\n",
      "iteration 72 / 300: loss 0.602091\n",
      "iteration 72 / 300: loss 0.631468\n",
      "iteration 72 / 300: loss 0.587904\n",
      "iteration 72 / 300: loss 0.606934\n",
      "iteration 72 / 300: loss 0.588430\n",
      "iteration 72 / 300: loss 0.601326\n",
      "iteration 72 / 300: loss 0.596306\n",
      "iteration 72 / 300: loss 0.589740\n",
      "iteration 72 / 300: loss 0.599952\n",
      "iteration 72 / 300: loss 0.605219\n",
      "iteration 72 / 300: loss 0.619810\n",
      "iteration 72 / 300: loss 0.589242\n",
      "iteration 72 / 300: loss 0.594080\n",
      "iteration 72 / 300: loss 0.586037\n",
      "iteration 72 / 300: loss 0.613526\n",
      "iteration 72 / 300: loss 0.587882\n",
      "iteration 72 / 300: loss 0.578732\n",
      "iteration 72 / 300: loss 0.567784\n",
      "iteration 72 / 300: loss 0.562519\n",
      "iteration 72 / 300: loss 0.594538\n",
      "iteration 72 / 300: loss 0.579123\n",
      "iteration 72 / 300: loss 0.586674\n",
      "iteration 72 / 300: loss 0.573229\n",
      "iteration 72 / 300: loss 0.596502\n",
      "iteration 72 / 300: loss 0.608253\n",
      "iteration 72 / 300: loss 0.611095\n",
      "iteration 72 / 300: loss 0.606630\n",
      "iteration 72 / 300: loss 0.584105\n",
      "iteration 72 / 300: loss 0.589916\n",
      "iteration 72 / 300: loss 0.595540\n",
      "iteration 72 / 300: loss 0.599265\n",
      "iteration 72 / 300: loss 0.596499\n",
      "iteration 72 / 300: loss 0.590075\n",
      "iteration 72 / 300: loss 0.591457\n",
      "iteration 72 / 300: loss 0.585149\n",
      "iteration 72 / 300: loss 0.599976\n",
      "iteration 72 / 300: loss 0.599188\n",
      "iteration 72 / 300: loss 0.614541\n",
      "iteration 72 / 300: loss 0.598121\n",
      "iteration 72 / 300: loss 0.599611\n",
      "iteration 72 / 300: loss 0.603691\n",
      "iteration 72 / 300: loss 0.593224\n",
      "iteration 72 / 300: loss 0.592753\n",
      "iteration 72 / 300: loss 0.589368\n",
      "iteration 72 / 300: loss 0.596861\n",
      "iteration 72 / 300: loss 0.606073\n",
      "iteration 72 / 300: loss 0.610877\n",
      "iteration 72 / 300: loss 0.588088\n",
      "iteration 72 / 300: loss 0.599600\n",
      "iteration 72 / 300: loss 0.603107\n",
      "iteration 72 / 300: loss 0.605376\n",
      "iteration 72 / 300: loss 0.604248\n",
      "iteration 72 / 300: loss 0.624432\n",
      "iteration 72 / 300: loss 0.587483\n",
      "iteration 72 / 300: loss 0.581078\n",
      "iteration 72 / 300: loss 0.625433\n",
      "iteration 72 / 300: loss 0.603667\n",
      "iteration 72 / 300: loss 0.604673\n",
      "iteration 72 / 300: loss 0.595871\n",
      "iteration 72 / 300: loss 0.597927\n",
      "iteration 72 / 300: loss 0.593113\n",
      "iteration 72 / 300: loss 0.589838\n",
      "iteration 72 / 300: loss 0.599630\n",
      "iteration 72 / 300: loss 0.611692\n",
      "iteration 72 / 300: loss 0.592811\n",
      "iteration 72 / 300: loss 0.599786\n",
      "iteration 72 / 300: loss 0.603514\n",
      "iteration 72 / 300: loss 0.602772\n",
      "iteration 72 / 300: loss 0.580130\n",
      "iteration 72 / 300: loss 0.601933\n",
      "iteration 73 / 300: loss 0.585851\n",
      "iteration 73 / 300: loss 0.588725\n",
      "iteration 73 / 300: loss 0.567831\n",
      "iteration 73 / 300: loss 0.592656\n",
      "iteration 73 / 300: loss 0.593916\n",
      "iteration 73 / 300: loss 0.595646\n",
      "iteration 73 / 300: loss 0.609098\n",
      "iteration 73 / 300: loss 0.593052\n",
      "iteration 73 / 300: loss 0.628418\n",
      "iteration 73 / 300: loss 0.580537\n",
      "iteration 73 / 300: loss 0.608278\n",
      "iteration 73 / 300: loss 0.587725\n",
      "iteration 73 / 300: loss 0.592009\n",
      "iteration 73 / 300: loss 0.571674\n",
      "iteration 73 / 300: loss 0.583325\n",
      "iteration 73 / 300: loss 0.608701\n",
      "iteration 73 / 300: loss 0.598692\n",
      "iteration 73 / 300: loss 0.584145\n",
      "iteration 73 / 300: loss 0.615589\n",
      "iteration 73 / 300: loss 0.591980\n",
      "iteration 73 / 300: loss 0.585813\n",
      "iteration 73 / 300: loss 0.591671\n",
      "iteration 73 / 300: loss 0.604684\n",
      "iteration 73 / 300: loss 0.596140\n",
      "iteration 73 / 300: loss 0.615194\n",
      "iteration 73 / 300: loss 0.608661\n",
      "iteration 73 / 300: loss 0.598572\n",
      "iteration 73 / 300: loss 0.589234\n",
      "iteration 73 / 300: loss 0.618103\n",
      "iteration 73 / 300: loss 0.595105\n",
      "iteration 73 / 300: loss 0.602053\n",
      "iteration 73 / 300: loss 0.631427\n",
      "iteration 73 / 300: loss 0.587868\n",
      "iteration 73 / 300: loss 0.606899\n",
      "iteration 73 / 300: loss 0.588392\n",
      "iteration 73 / 300: loss 0.601284\n",
      "iteration 73 / 300: loss 0.596273\n",
      "iteration 73 / 300: loss 0.589698\n",
      "iteration 73 / 300: loss 0.599912\n",
      "iteration 73 / 300: loss 0.605185\n",
      "iteration 73 / 300: loss 0.619773\n",
      "iteration 73 / 300: loss 0.589201\n",
      "iteration 73 / 300: loss 0.594039\n",
      "iteration 73 / 300: loss 0.585995\n",
      "iteration 73 / 300: loss 0.613497\n",
      "iteration 73 / 300: loss 0.587848\n",
      "iteration 73 / 300: loss 0.578694\n",
      "iteration 73 / 300: loss 0.567751\n",
      "iteration 73 / 300: loss 0.562493\n",
      "iteration 73 / 300: loss 0.594505\n",
      "iteration 73 / 300: loss 0.579094\n",
      "iteration 73 / 300: loss 0.586644\n",
      "iteration 73 / 300: loss 0.573197\n",
      "iteration 73 / 300: loss 0.596468\n",
      "iteration 73 / 300: loss 0.608224\n",
      "iteration 73 / 300: loss 0.611071\n",
      "iteration 73 / 300: loss 0.606595\n",
      "iteration 73 / 300: loss 0.584075\n",
      "iteration 73 / 300: loss 0.589889\n",
      "iteration 73 / 300: loss 0.595507\n",
      "iteration 73 / 300: loss 0.599236\n",
      "iteration 73 / 300: loss 0.596465\n",
      "iteration 73 / 300: loss 0.590046\n",
      "iteration 73 / 300: loss 0.591427\n",
      "iteration 73 / 300: loss 0.585122\n",
      "iteration 73 / 300: loss 0.599945\n",
      "iteration 73 / 300: loss 0.599161\n",
      "iteration 73 / 300: loss 0.614517\n",
      "iteration 73 / 300: loss 0.598090\n",
      "iteration 73 / 300: loss 0.599582\n",
      "iteration 73 / 300: loss 0.603655\n",
      "iteration 73 / 300: loss 0.593190\n",
      "iteration 73 / 300: loss 0.592719\n",
      "iteration 73 / 300: loss 0.589337\n",
      "iteration 73 / 300: loss 0.596822\n",
      "iteration 73 / 300: loss 0.606039\n",
      "iteration 73 / 300: loss 0.610847\n",
      "iteration 73 / 300: loss 0.588059\n",
      "iteration 73 / 300: loss 0.599576\n",
      "iteration 73 / 300: loss 0.603078\n",
      "iteration 73 / 300: loss 0.605344\n",
      "iteration 73 / 300: loss 0.604211\n",
      "iteration 73 / 300: loss 0.624405\n",
      "iteration 73 / 300: loss 0.587458\n",
      "iteration 73 / 300: loss 0.581048\n",
      "iteration 73 / 300: loss 0.625396\n",
      "iteration 73 / 300: loss 0.603633\n",
      "iteration 73 / 300: loss 0.604640\n",
      "iteration 73 / 300: loss 0.595834\n",
      "iteration 73 / 300: loss 0.597891\n",
      "iteration 73 / 300: loss 0.593078\n",
      "iteration 73 / 300: loss 0.589805\n",
      "iteration 73 / 300: loss 0.599595\n",
      "iteration 73 / 300: loss 0.611662\n",
      "iteration 73 / 300: loss 0.592778\n",
      "iteration 73 / 300: loss 0.599752\n",
      "iteration 73 / 300: loss 0.603475\n",
      "iteration 73 / 300: loss 0.602738\n",
      "iteration 73 / 300: loss 0.580100\n",
      "iteration 73 / 300: loss 0.601901\n",
      "iteration 74 / 300: loss 0.585820\n",
      "iteration 74 / 300: loss 0.588697\n",
      "iteration 74 / 300: loss 0.567801\n",
      "iteration 74 / 300: loss 0.592631\n",
      "iteration 74 / 300: loss 0.593888\n",
      "iteration 74 / 300: loss 0.595613\n",
      "iteration 74 / 300: loss 0.609068\n",
      "iteration 74 / 300: loss 0.593022\n",
      "iteration 74 / 300: loss 0.628384\n",
      "iteration 74 / 300: loss 0.580501\n",
      "iteration 74 / 300: loss 0.608245\n",
      "iteration 74 / 300: loss 0.587694\n",
      "iteration 74 / 300: loss 0.591978\n",
      "iteration 74 / 300: loss 0.571646\n",
      "iteration 74 / 300: loss 0.583297\n",
      "iteration 74 / 300: loss 0.608676\n",
      "iteration 74 / 300: loss 0.598661\n",
      "iteration 74 / 300: loss 0.584118\n",
      "iteration 74 / 300: loss 0.615557\n",
      "iteration 74 / 300: loss 0.591949\n",
      "iteration 74 / 300: loss 0.585784\n",
      "iteration 74 / 300: loss 0.591638\n",
      "iteration 74 / 300: loss 0.604651\n",
      "iteration 74 / 300: loss 0.596106\n",
      "iteration 74 / 300: loss 0.615171\n",
      "iteration 74 / 300: loss 0.608635\n",
      "iteration 74 / 300: loss 0.598539\n",
      "iteration 74 / 300: loss 0.589206\n",
      "iteration 74 / 300: loss 0.618071\n",
      "iteration 74 / 300: loss 0.595073\n",
      "iteration 74 / 300: loss 0.602018\n",
      "iteration 74 / 300: loss 0.631389\n",
      "iteration 74 / 300: loss 0.587834\n",
      "iteration 74 / 300: loss 0.606868\n",
      "iteration 74 / 300: loss 0.588358\n",
      "iteration 74 / 300: loss 0.601247\n",
      "iteration 74 / 300: loss 0.596243\n",
      "iteration 74 / 300: loss 0.589659\n",
      "iteration 74 / 300: loss 0.599876\n",
      "iteration 74 / 300: loss 0.605154\n",
      "iteration 74 / 300: loss 0.619739\n",
      "iteration 74 / 300: loss 0.589164\n",
      "iteration 74 / 300: loss 0.594002\n",
      "iteration 74 / 300: loss 0.585957\n",
      "iteration 74 / 300: loss 0.613471\n",
      "iteration 74 / 300: loss 0.587817\n",
      "iteration 74 / 300: loss 0.578660\n",
      "iteration 74 / 300: loss 0.567721\n",
      "iteration 74 / 300: loss 0.562469\n",
      "iteration 74 / 300: loss 0.594475\n",
      "iteration 74 / 300: loss 0.579069\n",
      "iteration 74 / 300: loss 0.586618\n",
      "iteration 74 / 300: loss 0.573168\n",
      "iteration 74 / 300: loss 0.596439\n",
      "iteration 74 / 300: loss 0.608198\n",
      "iteration 74 / 300: loss 0.611049\n",
      "iteration 74 / 300: loss 0.606564\n",
      "iteration 74 / 300: loss 0.584049\n",
      "iteration 74 / 300: loss 0.589864\n",
      "iteration 74 / 300: loss 0.595476\n",
      "iteration 74 / 300: loss 0.599210\n",
      "iteration 74 / 300: loss 0.596433\n",
      "iteration 74 / 300: loss 0.590021\n",
      "iteration 74 / 300: loss 0.591399\n",
      "iteration 74 / 300: loss 0.585097\n",
      "iteration 74 / 300: loss 0.599917\n",
      "iteration 74 / 300: loss 0.599137\n",
      "iteration 74 / 300: loss 0.614496\n",
      "iteration 74 / 300: loss 0.598062\n",
      "iteration 74 / 300: loss 0.599555\n",
      "iteration 74 / 300: loss 0.603623\n",
      "iteration 74 / 300: loss 0.593159\n",
      "iteration 74 / 300: loss 0.592687\n",
      "iteration 74 / 300: loss 0.589309\n",
      "iteration 74 / 300: loss 0.596786\n",
      "iteration 74 / 300: loss 0.606007\n",
      "iteration 74 / 300: loss 0.610820\n",
      "iteration 74 / 300: loss 0.588033\n",
      "iteration 74 / 300: loss 0.599554\n",
      "iteration 74 / 300: loss 0.603051\n",
      "iteration 74 / 300: loss 0.605314\n",
      "iteration 74 / 300: loss 0.604176\n",
      "iteration 74 / 300: loss 0.624380\n",
      "iteration 74 / 300: loss 0.587436\n",
      "iteration 74 / 300: loss 0.581020\n",
      "iteration 74 / 300: loss 0.625363\n",
      "iteration 74 / 300: loss 0.603603\n",
      "iteration 74 / 300: loss 0.604611\n",
      "iteration 74 / 300: loss 0.595801\n",
      "iteration 74 / 300: loss 0.597858\n",
      "iteration 74 / 300: loss 0.593046\n",
      "iteration 74 / 300: loss 0.589776\n",
      "iteration 74 / 300: loss 0.599564\n",
      "iteration 74 / 300: loss 0.611635\n",
      "iteration 74 / 300: loss 0.592749\n",
      "iteration 74 / 300: loss 0.599721\n",
      "iteration 74 / 300: loss 0.603439\n",
      "iteration 74 / 300: loss 0.602707\n",
      "iteration 74 / 300: loss 0.580073\n",
      "iteration 74 / 300: loss 0.601872\n",
      "iteration 75 / 300: loss 0.585792\n",
      "iteration 75 / 300: loss 0.588672\n",
      "iteration 75 / 300: loss 0.567775\n",
      "iteration 75 / 300: loss 0.592607\n",
      "iteration 75 / 300: loss 0.593862\n",
      "iteration 75 / 300: loss 0.595583\n",
      "iteration 75 / 300: loss 0.609041\n",
      "iteration 75 / 300: loss 0.592995\n",
      "iteration 75 / 300: loss 0.628354\n",
      "iteration 75 / 300: loss 0.580468\n",
      "iteration 75 / 300: loss 0.608215\n",
      "iteration 75 / 300: loss 0.587666\n",
      "iteration 75 / 300: loss 0.591951\n",
      "iteration 75 / 300: loss 0.571620\n",
      "iteration 75 / 300: loss 0.583272\n",
      "iteration 75 / 300: loss 0.608654\n",
      "iteration 75 / 300: loss 0.598632\n",
      "iteration 75 / 300: loss 0.584094\n",
      "iteration 75 / 300: loss 0.615529\n",
      "iteration 75 / 300: loss 0.591921\n",
      "iteration 75 / 300: loss 0.585757\n",
      "iteration 75 / 300: loss 0.591609\n",
      "iteration 75 / 300: loss 0.604622\n",
      "iteration 75 / 300: loss 0.596076\n",
      "iteration 75 / 300: loss 0.615151\n",
      "iteration 75 / 300: loss 0.608612\n",
      "iteration 75 / 300: loss 0.598509\n",
      "iteration 75 / 300: loss 0.589180\n",
      "iteration 75 / 300: loss 0.618041\n",
      "iteration 75 / 300: loss 0.595044\n",
      "iteration 75 / 300: loss 0.601986\n",
      "iteration 75 / 300: loss 0.631355\n",
      "iteration 75 / 300: loss 0.587804\n",
      "iteration 75 / 300: loss 0.606839\n",
      "iteration 75 / 300: loss 0.588328\n",
      "iteration 75 / 300: loss 0.601213\n",
      "iteration 75 / 300: loss 0.596216\n",
      "iteration 75 / 300: loss 0.589624\n",
      "iteration 75 / 300: loss 0.599843\n",
      "iteration 75 / 300: loss 0.605126\n",
      "iteration 75 / 300: loss 0.619709\n",
      "iteration 75 / 300: loss 0.589130\n",
      "iteration 75 / 300: loss 0.593968\n",
      "iteration 75 / 300: loss 0.585923\n",
      "iteration 75 / 300: loss 0.613447\n",
      "iteration 75 / 300: loss 0.587790\n",
      "iteration 75 / 300: loss 0.578629\n",
      "iteration 75 / 300: loss 0.567694\n",
      "iteration 75 / 300: loss 0.562447\n",
      "iteration 75 / 300: loss 0.594447\n",
      "iteration 75 / 300: loss 0.579045\n",
      "iteration 75 / 300: loss 0.586593\n",
      "iteration 75 / 300: loss 0.573141\n",
      "iteration 75 / 300: loss 0.596411\n",
      "iteration 75 / 300: loss 0.608175\n",
      "iteration 75 / 300: loss 0.611030\n",
      "iteration 75 / 300: loss 0.606536\n",
      "iteration 75 / 300: loss 0.584024\n",
      "iteration 75 / 300: loss 0.589842\n",
      "iteration 75 / 300: loss 0.595449\n",
      "iteration 75 / 300: loss 0.599186\n",
      "iteration 75 / 300: loss 0.596405\n",
      "iteration 75 / 300: loss 0.589997\n",
      "iteration 75 / 300: loss 0.591375\n",
      "iteration 75 / 300: loss 0.585074\n",
      "iteration 75 / 300: loss 0.599891\n",
      "iteration 75 / 300: loss 0.599115\n",
      "iteration 75 / 300: loss 0.614476\n",
      "iteration 75 / 300: loss 0.598037\n",
      "iteration 75 / 300: loss 0.599531\n",
      "iteration 75 / 300: loss 0.603595\n",
      "iteration 75 / 300: loss 0.593131\n",
      "iteration 75 / 300: loss 0.592659\n",
      "iteration 75 / 300: loss 0.589284\n",
      "iteration 75 / 300: loss 0.596754\n",
      "iteration 75 / 300: loss 0.605979\n",
      "iteration 75 / 300: loss 0.610796\n",
      "iteration 75 / 300: loss 0.588009\n",
      "iteration 75 / 300: loss 0.599535\n",
      "iteration 75 / 300: loss 0.603027\n",
      "iteration 75 / 300: loss 0.605287\n",
      "iteration 75 / 300: loss 0.604145\n",
      "iteration 75 / 300: loss 0.624358\n",
      "iteration 75 / 300: loss 0.587415\n",
      "iteration 75 / 300: loss 0.580995\n",
      "iteration 75 / 300: loss 0.625332\n",
      "iteration 75 / 300: loss 0.603575\n",
      "iteration 75 / 300: loss 0.604584\n",
      "iteration 75 / 300: loss 0.595770\n",
      "iteration 75 / 300: loss 0.597828\n",
      "iteration 75 / 300: loss 0.593017\n",
      "iteration 75 / 300: loss 0.589749\n",
      "iteration 75 / 300: loss 0.599535\n",
      "iteration 75 / 300: loss 0.611611\n",
      "iteration 75 / 300: loss 0.592722\n",
      "iteration 75 / 300: loss 0.599694\n",
      "iteration 75 / 300: loss 0.603407\n",
      "iteration 75 / 300: loss 0.602679\n",
      "iteration 75 / 300: loss 0.580048\n",
      "iteration 75 / 300: loss 0.601846\n",
      "iteration 76 / 300: loss 0.585767\n",
      "iteration 76 / 300: loss 0.588649\n",
      "iteration 76 / 300: loss 0.567750\n",
      "iteration 76 / 300: loss 0.592586\n",
      "iteration 76 / 300: loss 0.593839\n",
      "iteration 76 / 300: loss 0.595556\n",
      "iteration 76 / 300: loss 0.609016\n",
      "iteration 76 / 300: loss 0.592971\n",
      "iteration 76 / 300: loss 0.628326\n",
      "iteration 76 / 300: loss 0.580438\n",
      "iteration 76 / 300: loss 0.608187\n",
      "iteration 76 / 300: loss 0.587641\n",
      "iteration 76 / 300: loss 0.591926\n",
      "iteration 76 / 300: loss 0.571597\n",
      "iteration 76 / 300: loss 0.583249\n",
      "iteration 76 / 300: loss 0.608634\n",
      "iteration 76 / 300: loss 0.598607\n",
      "iteration 76 / 300: loss 0.584071\n",
      "iteration 76 / 300: loss 0.615503\n",
      "iteration 76 / 300: loss 0.591896\n",
      "iteration 76 / 300: loss 0.585733\n",
      "iteration 76 / 300: loss 0.591582\n",
      "iteration 76 / 300: loss 0.604595\n",
      "iteration 76 / 300: loss 0.596049\n",
      "iteration 76 / 300: loss 0.615132\n",
      "iteration 76 / 300: loss 0.608591\n",
      "iteration 76 / 300: loss 0.598482\n",
      "iteration 76 / 300: loss 0.589157\n",
      "iteration 76 / 300: loss 0.618014\n",
      "iteration 76 / 300: loss 0.595018\n",
      "iteration 76 / 300: loss 0.601958\n",
      "iteration 76 / 300: loss 0.631325\n",
      "iteration 76 / 300: loss 0.587777\n",
      "iteration 76 / 300: loss 0.606813\n",
      "iteration 76 / 300: loss 0.588300\n",
      "iteration 76 / 300: loss 0.601182\n",
      "iteration 76 / 300: loss 0.596191\n",
      "iteration 76 / 300: loss 0.589592\n",
      "iteration 76 / 300: loss 0.599813\n",
      "iteration 76 / 300: loss 0.605101\n",
      "iteration 76 / 300: loss 0.619681\n",
      "iteration 76 / 300: loss 0.589100\n",
      "iteration 76 / 300: loss 0.593938\n",
      "iteration 76 / 300: loss 0.585892\n",
      "iteration 76 / 300: loss 0.613425\n",
      "iteration 76 / 300: loss 0.587764\n",
      "iteration 76 / 300: loss 0.578600\n",
      "iteration 76 / 300: loss 0.567669\n",
      "iteration 76 / 300: loss 0.562427\n",
      "iteration 76 / 300: loss 0.594422\n",
      "iteration 76 / 300: loss 0.579024\n",
      "iteration 76 / 300: loss 0.586571\n",
      "iteration 76 / 300: loss 0.573118\n",
      "iteration 76 / 300: loss 0.596387\n",
      "iteration 76 / 300: loss 0.608154\n",
      "iteration 76 / 300: loss 0.611012\n",
      "iteration 76 / 300: loss 0.606510\n",
      "iteration 76 / 300: loss 0.584002\n",
      "iteration 76 / 300: loss 0.589821\n",
      "iteration 76 / 300: loss 0.595424\n",
      "iteration 76 / 300: loss 0.599164\n",
      "iteration 76 / 300: loss 0.596379\n",
      "iteration 76 / 300: loss 0.589976\n",
      "iteration 76 / 300: loss 0.591352\n",
      "iteration 76 / 300: loss 0.585054\n",
      "iteration 76 / 300: loss 0.599868\n",
      "iteration 76 / 300: loss 0.599095\n",
      "iteration 76 / 300: loss 0.614458\n",
      "iteration 76 / 300: loss 0.598015\n",
      "iteration 76 / 300: loss 0.599509\n",
      "iteration 76 / 300: loss 0.603568\n",
      "iteration 76 / 300: loss 0.593106\n",
      "iteration 76 / 300: loss 0.592634\n",
      "iteration 76 / 300: loss 0.589261\n",
      "iteration 76 / 300: loss 0.596725\n",
      "iteration 76 / 300: loss 0.605953\n",
      "iteration 76 / 300: loss 0.610773\n",
      "iteration 76 / 300: loss 0.587988\n",
      "iteration 76 / 300: loss 0.599517\n",
      "iteration 76 / 300: loss 0.603004\n",
      "iteration 76 / 300: loss 0.605263\n",
      "iteration 76 / 300: loss 0.604117\n",
      "iteration 76 / 300: loss 0.624338\n",
      "iteration 76 / 300: loss 0.587397\n",
      "iteration 76 / 300: loss 0.580972\n",
      "iteration 76 / 300: loss 0.625305\n",
      "iteration 76 / 300: loss 0.603550\n",
      "iteration 76 / 300: loss 0.604560\n",
      "iteration 76 / 300: loss 0.595743\n",
      "iteration 76 / 300: loss 0.597802\n",
      "iteration 76 / 300: loss 0.592991\n",
      "iteration 76 / 300: loss 0.589725\n",
      "iteration 76 / 300: loss 0.599509\n",
      "iteration 76 / 300: loss 0.611589\n",
      "iteration 76 / 300: loss 0.592697\n",
      "iteration 76 / 300: loss 0.599668\n",
      "iteration 76 / 300: loss 0.603378\n",
      "iteration 76 / 300: loss 0.602654\n",
      "iteration 76 / 300: loss 0.580026\n",
      "iteration 76 / 300: loss 0.601822\n",
      "iteration 77 / 300: loss 0.585745\n",
      "iteration 77 / 300: loss 0.588628\n",
      "iteration 77 / 300: loss 0.567728\n",
      "iteration 77 / 300: loss 0.592567\n",
      "iteration 77 / 300: loss 0.593818\n",
      "iteration 77 / 300: loss 0.595531\n",
      "iteration 77 / 300: loss 0.608994\n",
      "iteration 77 / 300: loss 0.592948\n",
      "iteration 77 / 300: loss 0.628301\n",
      "iteration 77 / 300: loss 0.580411\n",
      "iteration 77 / 300: loss 0.608162\n",
      "iteration 77 / 300: loss 0.587618\n",
      "iteration 77 / 300: loss 0.591903\n",
      "iteration 77 / 300: loss 0.571576\n",
      "iteration 77 / 300: loss 0.583228\n",
      "iteration 77 / 300: loss 0.608616\n",
      "iteration 77 / 300: loss 0.598583\n",
      "iteration 77 / 300: loss 0.584051\n",
      "iteration 77 / 300: loss 0.615479\n",
      "iteration 77 / 300: loss 0.591872\n",
      "iteration 77 / 300: loss 0.585711\n",
      "iteration 77 / 300: loss 0.591558\n",
      "iteration 77 / 300: loss 0.604571\n",
      "iteration 77 / 300: loss 0.596024\n",
      "iteration 77 / 300: loss 0.615114\n",
      "iteration 77 / 300: loss 0.608572\n",
      "iteration 77 / 300: loss 0.598457\n",
      "iteration 77 / 300: loss 0.589136\n",
      "iteration 77 / 300: loss 0.617989\n",
      "iteration 77 / 300: loss 0.594994\n",
      "iteration 77 / 300: loss 0.601932\n",
      "iteration 77 / 300: loss 0.631297\n",
      "iteration 77 / 300: loss 0.587752\n",
      "iteration 77 / 300: loss 0.606790\n",
      "iteration 77 / 300: loss 0.588274\n",
      "iteration 77 / 300: loss 0.601154\n",
      "iteration 77 / 300: loss 0.596169\n",
      "iteration 77 / 300: loss 0.589563\n",
      "iteration 77 / 300: loss 0.599786\n",
      "iteration 77 / 300: loss 0.605078\n",
      "iteration 77 / 300: loss 0.619656\n",
      "iteration 77 / 300: loss 0.589072\n",
      "iteration 77 / 300: loss 0.593910\n",
      "iteration 77 / 300: loss 0.585864\n",
      "iteration 77 / 300: loss 0.613405\n",
      "iteration 77 / 300: loss 0.587742\n",
      "iteration 77 / 300: loss 0.578575\n",
      "iteration 77 / 300: loss 0.567647\n",
      "iteration 77 / 300: loss 0.562409\n",
      "iteration 77 / 300: loss 0.594400\n",
      "iteration 77 / 300: loss 0.579005\n",
      "iteration 77 / 300: loss 0.586551\n",
      "iteration 77 / 300: loss 0.573096\n",
      "iteration 77 / 300: loss 0.596364\n",
      "iteration 77 / 300: loss 0.608135\n",
      "iteration 77 / 300: loss 0.610995\n",
      "iteration 77 / 300: loss 0.606487\n",
      "iteration 77 / 300: loss 0.583983\n",
      "iteration 77 / 300: loss 0.589803\n",
      "iteration 77 / 300: loss 0.595401\n",
      "iteration 77 / 300: loss 0.599144\n",
      "iteration 77 / 300: loss 0.596356\n",
      "iteration 77 / 300: loss 0.589957\n",
      "iteration 77 / 300: loss 0.591332\n",
      "iteration 77 / 300: loss 0.585035\n",
      "iteration 77 / 300: loss 0.599847\n",
      "iteration 77 / 300: loss 0.599076\n",
      "iteration 77 / 300: loss 0.614441\n",
      "iteration 77 / 300: loss 0.597994\n",
      "iteration 77 / 300: loss 0.599489\n",
      "iteration 77 / 300: loss 0.603544\n",
      "iteration 77 / 300: loss 0.593083\n",
      "iteration 77 / 300: loss 0.592611\n",
      "iteration 77 / 300: loss 0.589240\n",
      "iteration 77 / 300: loss 0.596698\n",
      "iteration 77 / 300: loss 0.605930\n",
      "iteration 77 / 300: loss 0.610753\n",
      "iteration 77 / 300: loss 0.587969\n",
      "iteration 77 / 300: loss 0.599501\n",
      "iteration 77 / 300: loss 0.602984\n",
      "iteration 77 / 300: loss 0.605241\n",
      "iteration 77 / 300: loss 0.604092\n",
      "iteration 77 / 300: loss 0.624320\n",
      "iteration 77 / 300: loss 0.587380\n",
      "iteration 77 / 300: loss 0.580951\n",
      "iteration 77 / 300: loss 0.625280\n",
      "iteration 77 / 300: loss 0.603527\n",
      "iteration 77 / 300: loss 0.604537\n",
      "iteration 77 / 300: loss 0.595718\n",
      "iteration 77 / 300: loss 0.597777\n",
      "iteration 77 / 300: loss 0.592967\n",
      "iteration 77 / 300: loss 0.589703\n",
      "iteration 77 / 300: loss 0.599486\n",
      "iteration 77 / 300: loss 0.611569\n",
      "iteration 77 / 300: loss 0.592675\n",
      "iteration 77 / 300: loss 0.599645\n",
      "iteration 77 / 300: loss 0.603352\n",
      "iteration 77 / 300: loss 0.602631\n",
      "iteration 77 / 300: loss 0.580006\n",
      "iteration 77 / 300: loss 0.601801\n",
      "iteration 78 / 300: loss 0.585724\n",
      "iteration 78 / 300: loss 0.588609\n",
      "iteration 78 / 300: loss 0.567708\n",
      "iteration 78 / 300: loss 0.592549\n",
      "iteration 78 / 300: loss 0.593799\n",
      "iteration 78 / 300: loss 0.595508\n",
      "iteration 78 / 300: loss 0.608974\n",
      "iteration 78 / 300: loss 0.592928\n",
      "iteration 78 / 300: loss 0.628278\n",
      "iteration 78 / 300: loss 0.580386\n",
      "iteration 78 / 300: loss 0.608140\n",
      "iteration 78 / 300: loss 0.587597\n",
      "iteration 78 / 300: loss 0.591883\n",
      "iteration 78 / 300: loss 0.571556\n",
      "iteration 78 / 300: loss 0.583209\n",
      "iteration 78 / 300: loss 0.608599\n",
      "iteration 78 / 300: loss 0.598562\n",
      "iteration 78 / 300: loss 0.584033\n",
      "iteration 78 / 300: loss 0.615457\n",
      "iteration 78 / 300: loss 0.591851\n",
      "iteration 78 / 300: loss 0.585691\n",
      "iteration 78 / 300: loss 0.591536\n",
      "iteration 78 / 300: loss 0.604549\n",
      "iteration 78 / 300: loss 0.596002\n",
      "iteration 78 / 300: loss 0.615099\n",
      "iteration 78 / 300: loss 0.608554\n",
      "iteration 78 / 300: loss 0.598435\n",
      "iteration 78 / 300: loss 0.589117\n",
      "iteration 78 / 300: loss 0.617967\n",
      "iteration 78 / 300: loss 0.594973\n",
      "iteration 78 / 300: loss 0.601908\n",
      "iteration 78 / 300: loss 0.631272\n",
      "iteration 78 / 300: loss 0.587730\n",
      "iteration 78 / 300: loss 0.606768\n",
      "iteration 78 / 300: loss 0.588252\n",
      "iteration 78 / 300: loss 0.601129\n",
      "iteration 78 / 300: loss 0.596149\n",
      "iteration 78 / 300: loss 0.589538\n",
      "iteration 78 / 300: loss 0.599762\n",
      "iteration 78 / 300: loss 0.605057\n",
      "iteration 78 / 300: loss 0.619633\n",
      "iteration 78 / 300: loss 0.589047\n",
      "iteration 78 / 300: loss 0.593885\n",
      "iteration 78 / 300: loss 0.585838\n",
      "iteration 78 / 300: loss 0.613387\n",
      "iteration 78 / 300: loss 0.587721\n",
      "iteration 78 / 300: loss 0.578551\n",
      "iteration 78 / 300: loss 0.567627\n",
      "iteration 78 / 300: loss 0.562393\n",
      "iteration 78 / 300: loss 0.594379\n",
      "iteration 78 / 300: loss 0.578988\n",
      "iteration 78 / 300: loss 0.586533\n",
      "iteration 78 / 300: loss 0.573076\n",
      "iteration 78 / 300: loss 0.596344\n",
      "iteration 78 / 300: loss 0.608117\n",
      "iteration 78 / 300: loss 0.610981\n",
      "iteration 78 / 300: loss 0.606466\n",
      "iteration 78 / 300: loss 0.583964\n",
      "iteration 78 / 300: loss 0.589786\n",
      "iteration 78 / 300: loss 0.595381\n",
      "iteration 78 / 300: loss 0.599126\n",
      "iteration 78 / 300: loss 0.596335\n",
      "iteration 78 / 300: loss 0.589939\n",
      "iteration 78 / 300: loss 0.591313\n",
      "iteration 78 / 300: loss 0.585018\n",
      "iteration 78 / 300: loss 0.599828\n",
      "iteration 78 / 300: loss 0.599060\n",
      "iteration 78 / 300: loss 0.614426\n",
      "iteration 78 / 300: loss 0.597975\n",
      "iteration 78 / 300: loss 0.599471\n",
      "iteration 78 / 300: loss 0.603523\n",
      "iteration 78 / 300: loss 0.593062\n",
      "iteration 78 / 300: loss 0.592590\n",
      "iteration 78 / 300: loss 0.589222\n",
      "iteration 78 / 300: loss 0.596674\n",
      "iteration 78 / 300: loss 0.605909\n",
      "iteration 78 / 300: loss 0.610735\n",
      "iteration 78 / 300: loss 0.587951\n",
      "iteration 78 / 300: loss 0.599487\n",
      "iteration 78 / 300: loss 0.602966\n",
      "iteration 78 / 300: loss 0.605221\n",
      "iteration 78 / 300: loss 0.604069\n",
      "iteration 78 / 300: loss 0.624303\n",
      "iteration 78 / 300: loss 0.587365\n",
      "iteration 78 / 300: loss 0.580933\n",
      "iteration 78 / 300: loss 0.625257\n",
      "iteration 78 / 300: loss 0.603507\n",
      "iteration 78 / 300: loss 0.604517\n",
      "iteration 78 / 300: loss 0.595695\n",
      "iteration 78 / 300: loss 0.597755\n",
      "iteration 78 / 300: loss 0.592946\n",
      "iteration 78 / 300: loss 0.589683\n",
      "iteration 78 / 300: loss 0.599465\n",
      "iteration 78 / 300: loss 0.611551\n",
      "iteration 78 / 300: loss 0.592655\n",
      "iteration 78 / 300: loss 0.599624\n",
      "iteration 78 / 300: loss 0.603328\n",
      "iteration 78 / 300: loss 0.602610\n",
      "iteration 78 / 300: loss 0.579987\n",
      "iteration 78 / 300: loss 0.601781\n",
      "iteration 79 / 300: loss 0.585705\n",
      "iteration 79 / 300: loss 0.588592\n",
      "iteration 79 / 300: loss 0.567690\n",
      "iteration 79 / 300: loss 0.592533\n",
      "iteration 79 / 300: loss 0.593782\n",
      "iteration 79 / 300: loss 0.595488\n",
      "iteration 79 / 300: loss 0.608956\n",
      "iteration 79 / 300: loss 0.592909\n",
      "iteration 79 / 300: loss 0.628258\n",
      "iteration 79 / 300: loss 0.580364\n",
      "iteration 79 / 300: loss 0.608119\n",
      "iteration 79 / 300: loss 0.587578\n",
      "iteration 79 / 300: loss 0.591864\n",
      "iteration 79 / 300: loss 0.571539\n",
      "iteration 79 / 300: loss 0.583192\n",
      "iteration 79 / 300: loss 0.608584\n",
      "iteration 79 / 300: loss 0.598543\n",
      "iteration 79 / 300: loss 0.584016\n",
      "iteration 79 / 300: loss 0.615438\n",
      "iteration 79 / 300: loss 0.591832\n",
      "iteration 79 / 300: loss 0.585672\n",
      "iteration 79 / 300: loss 0.591516\n",
      "iteration 79 / 300: loss 0.604529\n",
      "iteration 79 / 300: loss 0.595982\n",
      "iteration 79 / 300: loss 0.615085\n",
      "iteration 79 / 300: loss 0.608539\n",
      "iteration 79 / 300: loss 0.598415\n",
      "iteration 79 / 300: loss 0.589099\n",
      "iteration 79 / 300: loss 0.617947\n",
      "iteration 79 / 300: loss 0.594953\n",
      "iteration 79 / 300: loss 0.601887\n",
      "iteration 79 / 300: loss 0.631249\n",
      "iteration 79 / 300: loss 0.587709\n",
      "iteration 79 / 300: loss 0.606749\n",
      "iteration 79 / 300: loss 0.588231\n",
      "iteration 79 / 300: loss 0.601106\n",
      "iteration 79 / 300: loss 0.596131\n",
      "iteration 79 / 300: loss 0.589514\n",
      "iteration 79 / 300: loss 0.599740\n",
      "iteration 79 / 300: loss 0.605038\n",
      "iteration 79 / 300: loss 0.619612\n",
      "iteration 79 / 300: loss 0.589024\n",
      "iteration 79 / 300: loss 0.593862\n",
      "iteration 79 / 300: loss 0.585815\n",
      "iteration 79 / 300: loss 0.613370\n",
      "iteration 79 / 300: loss 0.587702\n",
      "iteration 79 / 300: loss 0.578530\n",
      "iteration 79 / 300: loss 0.567609\n",
      "iteration 79 / 300: loss 0.562378\n",
      "iteration 79 / 300: loss 0.594361\n",
      "iteration 79 / 300: loss 0.578972\n",
      "iteration 79 / 300: loss 0.586517\n",
      "iteration 79 / 300: loss 0.573059\n",
      "iteration 79 / 300: loss 0.596326\n",
      "iteration 79 / 300: loss 0.608101\n",
      "iteration 79 / 300: loss 0.610967\n",
      "iteration 79 / 300: loss 0.606447\n",
      "iteration 79 / 300: loss 0.583948\n",
      "iteration 79 / 300: loss 0.589771\n",
      "iteration 79 / 300: loss 0.595362\n",
      "iteration 79 / 300: loss 0.599110\n",
      "iteration 79 / 300: loss 0.596316\n",
      "iteration 79 / 300: loss 0.589923\n",
      "iteration 79 / 300: loss 0.591296\n",
      "iteration 79 / 300: loss 0.585003\n",
      "iteration 79 / 300: loss 0.599811\n",
      "iteration 79 / 300: loss 0.599045\n",
      "iteration 79 / 300: loss 0.614413\n",
      "iteration 79 / 300: loss 0.597958\n",
      "iteration 79 / 300: loss 0.599454\n",
      "iteration 79 / 300: loss 0.603503\n",
      "iteration 79 / 300: loss 0.593043\n",
      "iteration 79 / 300: loss 0.592571\n",
      "iteration 79 / 300: loss 0.589205\n",
      "iteration 79 / 300: loss 0.596653\n",
      "iteration 79 / 300: loss 0.605890\n",
      "iteration 79 / 300: loss 0.610719\n",
      "iteration 79 / 300: loss 0.587935\n",
      "iteration 79 / 300: loss 0.599474\n",
      "iteration 79 / 300: loss 0.602950\n",
      "iteration 79 / 300: loss 0.605202\n",
      "iteration 79 / 300: loss 0.604048\n",
      "iteration 79 / 300: loss 0.624288\n",
      "iteration 79 / 300: loss 0.587351\n",
      "iteration 79 / 300: loss 0.580916\n",
      "iteration 79 / 300: loss 0.625237\n",
      "iteration 79 / 300: loss 0.603488\n",
      "iteration 79 / 300: loss 0.604499\n",
      "iteration 79 / 300: loss 0.595674\n",
      "iteration 79 / 300: loss 0.597735\n",
      "iteration 79 / 300: loss 0.592927\n",
      "iteration 79 / 300: loss 0.589665\n",
      "iteration 79 / 300: loss 0.599446\n",
      "iteration 79 / 300: loss 0.611534\n",
      "iteration 79 / 300: loss 0.592637\n",
      "iteration 79 / 300: loss 0.599606\n",
      "iteration 79 / 300: loss 0.603306\n",
      "iteration 79 / 300: loss 0.602591\n",
      "iteration 79 / 300: loss 0.579971\n",
      "iteration 79 / 300: loss 0.601763\n",
      "iteration 80 / 300: loss 0.585689\n",
      "iteration 80 / 300: loss 0.588576\n",
      "iteration 80 / 300: loss 0.567674\n",
      "iteration 80 / 300: loss 0.592519\n",
      "iteration 80 / 300: loss 0.593766\n",
      "iteration 80 / 300: loss 0.595470\n",
      "iteration 80 / 300: loss 0.608940\n",
      "iteration 80 / 300: loss 0.592893\n",
      "iteration 80 / 300: loss 0.628239\n",
      "iteration 80 / 300: loss 0.580344\n",
      "iteration 80 / 300: loss 0.608101\n",
      "iteration 80 / 300: loss 0.587561\n",
      "iteration 80 / 300: loss 0.591847\n",
      "iteration 80 / 300: loss 0.571523\n",
      "iteration 80 / 300: loss 0.583176\n",
      "iteration 80 / 300: loss 0.608570\n",
      "iteration 80 / 300: loss 0.598525\n",
      "iteration 80 / 300: loss 0.584001\n",
      "iteration 80 / 300: loss 0.615420\n",
      "iteration 80 / 300: loss 0.591815\n",
      "iteration 80 / 300: loss 0.585656\n",
      "iteration 80 / 300: loss 0.591498\n",
      "iteration 80 / 300: loss 0.604511\n",
      "iteration 80 / 300: loss 0.595963\n",
      "iteration 80 / 300: loss 0.615072\n",
      "iteration 80 / 300: loss 0.608525\n",
      "iteration 80 / 300: loss 0.598397\n",
      "iteration 80 / 300: loss 0.589084\n",
      "iteration 80 / 300: loss 0.617929\n",
      "iteration 80 / 300: loss 0.594936\n",
      "iteration 80 / 300: loss 0.601868\n",
      "iteration 80 / 300: loss 0.631228\n",
      "iteration 80 / 300: loss 0.587691\n",
      "iteration 80 / 300: loss 0.606731\n",
      "iteration 80 / 300: loss 0.588212\n",
      "iteration 80 / 300: loss 0.601085\n",
      "iteration 80 / 300: loss 0.596114\n",
      "iteration 80 / 300: loss 0.589493\n",
      "iteration 80 / 300: loss 0.599719\n",
      "iteration 80 / 300: loss 0.605021\n",
      "iteration 80 / 300: loss 0.619593\n",
      "iteration 80 / 300: loss 0.589004\n",
      "iteration 80 / 300: loss 0.593841\n",
      "iteration 80 / 300: loss 0.585794\n",
      "iteration 80 / 300: loss 0.613356\n",
      "iteration 80 / 300: loss 0.587685\n",
      "iteration 80 / 300: loss 0.578511\n",
      "iteration 80 / 300: loss 0.567592\n",
      "iteration 80 / 300: loss 0.562365\n",
      "iteration 80 / 300: loss 0.594344\n",
      "iteration 80 / 300: loss 0.578958\n",
      "iteration 80 / 300: loss 0.586502\n",
      "iteration 80 / 300: loss 0.573043\n",
      "iteration 80 / 300: loss 0.596309\n",
      "iteration 80 / 300: loss 0.608087\n",
      "iteration 80 / 300: loss 0.610955\n",
      "iteration 80 / 300: loss 0.606430\n",
      "iteration 80 / 300: loss 0.583933\n",
      "iteration 80 / 300: loss 0.589758\n",
      "iteration 80 / 300: loss 0.595345\n",
      "iteration 80 / 300: loss 0.599096\n",
      "iteration 80 / 300: loss 0.596299\n",
      "iteration 80 / 300: loss 0.589909\n",
      "iteration 80 / 300: loss 0.591281\n",
      "iteration 80 / 300: loss 0.584989\n",
      "iteration 80 / 300: loss 0.599795\n",
      "iteration 80 / 300: loss 0.599032\n",
      "iteration 80 / 300: loss 0.614401\n",
      "iteration 80 / 300: loss 0.597943\n",
      "iteration 80 / 300: loss 0.599439\n",
      "iteration 80 / 300: loss 0.603486\n",
      "iteration 80 / 300: loss 0.593026\n",
      "iteration 80 / 300: loss 0.592554\n",
      "iteration 80 / 300: loss 0.589189\n",
      "iteration 80 / 300: loss 0.596633\n",
      "iteration 80 / 300: loss 0.605873\n",
      "iteration 80 / 300: loss 0.610704\n",
      "iteration 80 / 300: loss 0.587920\n",
      "iteration 80 / 300: loss 0.599462\n",
      "iteration 80 / 300: loss 0.602935\n",
      "iteration 80 / 300: loss 0.605186\n",
      "iteration 80 / 300: loss 0.604029\n",
      "iteration 80 / 300: loss 0.624274\n",
      "iteration 80 / 300: loss 0.587339\n",
      "iteration 80 / 300: loss 0.580901\n",
      "iteration 80 / 300: loss 0.625219\n",
      "iteration 80 / 300: loss 0.603471\n",
      "iteration 80 / 300: loss 0.604482\n",
      "iteration 80 / 300: loss 0.595655\n",
      "iteration 80 / 300: loss 0.597717\n",
      "iteration 80 / 300: loss 0.592909\n",
      "iteration 80 / 300: loss 0.589649\n",
      "iteration 80 / 300: loss 0.599429\n",
      "iteration 80 / 300: loss 0.611520\n",
      "iteration 80 / 300: loss 0.592620\n",
      "iteration 80 / 300: loss 0.599588\n",
      "iteration 80 / 300: loss 0.603287\n",
      "iteration 80 / 300: loss 0.602574\n",
      "iteration 80 / 300: loss 0.579956\n",
      "iteration 80 / 300: loss 0.601747\n",
      "iteration 81 / 300: loss 0.585673\n",
      "iteration 81 / 300: loss 0.588562\n",
      "iteration 81 / 300: loss 0.567659\n",
      "iteration 81 / 300: loss 0.592506\n",
      "iteration 81 / 300: loss 0.593752\n",
      "iteration 81 / 300: loss 0.595453\n",
      "iteration 81 / 300: loss 0.608925\n",
      "iteration 81 / 300: loss 0.592878\n",
      "iteration 81 / 300: loss 0.628222\n",
      "iteration 81 / 300: loss 0.580326\n",
      "iteration 81 / 300: loss 0.608084\n",
      "iteration 81 / 300: loss 0.587545\n",
      "iteration 81 / 300: loss 0.591832\n",
      "iteration 81 / 300: loss 0.571508\n",
      "iteration 81 / 300: loss 0.583162\n",
      "iteration 81 / 300: loss 0.608558\n",
      "iteration 81 / 300: loss 0.598510\n",
      "iteration 81 / 300: loss 0.583988\n",
      "iteration 81 / 300: loss 0.615405\n",
      "iteration 81 / 300: loss 0.591799\n",
      "iteration 81 / 300: loss 0.585641\n",
      "iteration 81 / 300: loss 0.591481\n",
      "iteration 81 / 300: loss 0.604495\n",
      "iteration 81 / 300: loss 0.595946\n",
      "iteration 81 / 300: loss 0.615060\n",
      "iteration 81 / 300: loss 0.608512\n",
      "iteration 81 / 300: loss 0.598380\n",
      "iteration 81 / 300: loss 0.589070\n",
      "iteration 81 / 300: loss 0.617913\n",
      "iteration 81 / 300: loss 0.594920\n",
      "iteration 81 / 300: loss 0.601850\n",
      "iteration 81 / 300: loss 0.631210\n",
      "iteration 81 / 300: loss 0.587674\n",
      "iteration 81 / 300: loss 0.606715\n",
      "iteration 81 / 300: loss 0.588195\n",
      "iteration 81 / 300: loss 0.601067\n",
      "iteration 81 / 300: loss 0.596099\n",
      "iteration 81 / 300: loss 0.589474\n",
      "iteration 81 / 300: loss 0.599701\n",
      "iteration 81 / 300: loss 0.605005\n",
      "iteration 81 / 300: loss 0.619576\n",
      "iteration 81 / 300: loss 0.588985\n",
      "iteration 81 / 300: loss 0.593823\n",
      "iteration 81 / 300: loss 0.585775\n",
      "iteration 81 / 300: loss 0.613342\n",
      "iteration 81 / 300: loss 0.587670\n",
      "iteration 81 / 300: loss 0.578494\n",
      "iteration 81 / 300: loss 0.567577\n",
      "iteration 81 / 300: loss 0.562353\n",
      "iteration 81 / 300: loss 0.594329\n",
      "iteration 81 / 300: loss 0.578945\n",
      "iteration 81 / 300: loss 0.586489\n",
      "iteration 81 / 300: loss 0.573028\n",
      "iteration 81 / 300: loss 0.596294\n",
      "iteration 81 / 300: loss 0.608074\n",
      "iteration 81 / 300: loss 0.610944\n",
      "iteration 81 / 300: loss 0.606414\n",
      "iteration 81 / 300: loss 0.583920\n",
      "iteration 81 / 300: loss 0.589745\n",
      "iteration 81 / 300: loss 0.595330\n",
      "iteration 81 / 300: loss 0.599082\n",
      "iteration 81 / 300: loss 0.596283\n",
      "iteration 81 / 300: loss 0.589895\n",
      "iteration 81 / 300: loss 0.591267\n",
      "iteration 81 / 300: loss 0.584976\n",
      "iteration 81 / 300: loss 0.599781\n",
      "iteration 81 / 300: loss 0.599019\n",
      "iteration 81 / 300: loss 0.614390\n",
      "iteration 81 / 300: loss 0.597929\n",
      "iteration 81 / 300: loss 0.599426\n",
      "iteration 81 / 300: loss 0.603470\n",
      "iteration 81 / 300: loss 0.593011\n",
      "iteration 81 / 300: loss 0.592538\n",
      "iteration 81 / 300: loss 0.589175\n",
      "iteration 81 / 300: loss 0.596615\n",
      "iteration 81 / 300: loss 0.605857\n",
      "iteration 81 / 300: loss 0.610690\n",
      "iteration 81 / 300: loss 0.587907\n",
      "iteration 81 / 300: loss 0.599451\n",
      "iteration 81 / 300: loss 0.602921\n",
      "iteration 81 / 300: loss 0.605171\n",
      "iteration 81 / 300: loss 0.604012\n",
      "iteration 81 / 300: loss 0.624262\n",
      "iteration 81 / 300: loss 0.587327\n",
      "iteration 81 / 300: loss 0.580887\n",
      "iteration 81 / 300: loss 0.625202\n",
      "iteration 81 / 300: loss 0.603456\n",
      "iteration 81 / 300: loss 0.604467\n",
      "iteration 81 / 300: loss 0.595639\n",
      "iteration 81 / 300: loss 0.597700\n",
      "iteration 81 / 300: loss 0.592893\n",
      "iteration 81 / 300: loss 0.589634\n",
      "iteration 81 / 300: loss 0.599413\n",
      "iteration 81 / 300: loss 0.611506\n",
      "iteration 81 / 300: loss 0.592605\n",
      "iteration 81 / 300: loss 0.599573\n",
      "iteration 81 / 300: loss 0.603269\n",
      "iteration 81 / 300: loss 0.602558\n",
      "iteration 81 / 300: loss 0.579942\n",
      "iteration 81 / 300: loss 0.601732\n",
      "iteration 82 / 300: loss 0.585659\n",
      "iteration 82 / 300: loss 0.588550\n",
      "iteration 82 / 300: loss 0.567645\n",
      "iteration 82 / 300: loss 0.592494\n",
      "iteration 82 / 300: loss 0.593739\n",
      "iteration 82 / 300: loss 0.595438\n",
      "iteration 82 / 300: loss 0.608911\n",
      "iteration 82 / 300: loss 0.592864\n",
      "iteration 82 / 300: loss 0.628207\n",
      "iteration 82 / 300: loss 0.580309\n",
      "iteration 82 / 300: loss 0.608069\n",
      "iteration 82 / 300: loss 0.587531\n",
      "iteration 82 / 300: loss 0.591818\n",
      "iteration 82 / 300: loss 0.571495\n",
      "iteration 82 / 300: loss 0.583149\n",
      "iteration 82 / 300: loss 0.608547\n",
      "iteration 82 / 300: loss 0.598495\n",
      "iteration 82 / 300: loss 0.583975\n",
      "iteration 82 / 300: loss 0.615390\n",
      "iteration 82 / 300: loss 0.591785\n",
      "iteration 82 / 300: loss 0.585628\n",
      "iteration 82 / 300: loss 0.591466\n",
      "iteration 82 / 300: loss 0.604480\n",
      "iteration 82 / 300: loss 0.595931\n",
      "iteration 82 / 300: loss 0.615050\n",
      "iteration 82 / 300: loss 0.608500\n",
      "iteration 82 / 300: loss 0.598365\n",
      "iteration 82 / 300: loss 0.589057\n",
      "iteration 82 / 300: loss 0.617898\n",
      "iteration 82 / 300: loss 0.594906\n",
      "iteration 82 / 300: loss 0.601835\n",
      "iteration 82 / 300: loss 0.631193\n",
      "iteration 82 / 300: loss 0.587659\n",
      "iteration 82 / 300: loss 0.606701\n",
      "iteration 82 / 300: loss 0.588180\n",
      "iteration 82 / 300: loss 0.601050\n",
      "iteration 82 / 300: loss 0.596086\n",
      "iteration 82 / 300: loss 0.589456\n",
      "iteration 82 / 300: loss 0.599685\n",
      "iteration 82 / 300: loss 0.604991\n",
      "iteration 82 / 300: loss 0.619561\n",
      "iteration 82 / 300: loss 0.588969\n",
      "iteration 82 / 300: loss 0.593806\n",
      "iteration 82 / 300: loss 0.585758\n",
      "iteration 82 / 300: loss 0.613330\n",
      "iteration 82 / 300: loss 0.587656\n",
      "iteration 82 / 300: loss 0.578478\n",
      "iteration 82 / 300: loss 0.567564\n",
      "iteration 82 / 300: loss 0.562342\n",
      "iteration 82 / 300: loss 0.594315\n",
      "iteration 82 / 300: loss 0.578933\n",
      "iteration 82 / 300: loss 0.586476\n",
      "iteration 82 / 300: loss 0.573015\n",
      "iteration 82 / 300: loss 0.596281\n",
      "iteration 82 / 300: loss 0.608062\n",
      "iteration 82 / 300: loss 0.610934\n",
      "iteration 82 / 300: loss 0.606400\n",
      "iteration 82 / 300: loss 0.583907\n",
      "iteration 82 / 300: loss 0.589734\n",
      "iteration 82 / 300: loss 0.595316\n",
      "iteration 82 / 300: loss 0.599070\n",
      "iteration 82 / 300: loss 0.596269\n",
      "iteration 82 / 300: loss 0.589884\n",
      "iteration 82 / 300: loss 0.591255\n",
      "iteration 82 / 300: loss 0.584965\n",
      "iteration 82 / 300: loss 0.599768\n",
      "iteration 82 / 300: loss 0.599008\n",
      "iteration 82 / 300: loss 0.614379\n",
      "iteration 82 / 300: loss 0.597917\n",
      "iteration 82 / 300: loss 0.599414\n",
      "iteration 82 / 300: loss 0.603455\n",
      "iteration 82 / 300: loss 0.592997\n",
      "iteration 82 / 300: loss 0.592524\n",
      "iteration 82 / 300: loss 0.589162\n",
      "iteration 82 / 300: loss 0.596599\n",
      "iteration 82 / 300: loss 0.605843\n",
      "iteration 82 / 300: loss 0.610678\n",
      "iteration 82 / 300: loss 0.587895\n",
      "iteration 82 / 300: loss 0.599442\n",
      "iteration 82 / 300: loss 0.602909\n",
      "iteration 82 / 300: loss 0.605157\n",
      "iteration 82 / 300: loss 0.603996\n",
      "iteration 82 / 300: loss 0.624251\n",
      "iteration 82 / 300: loss 0.587317\n",
      "iteration 82 / 300: loss 0.580874\n",
      "iteration 82 / 300: loss 0.625187\n",
      "iteration 82 / 300: loss 0.603442\n",
      "iteration 82 / 300: loss 0.604453\n",
      "iteration 82 / 300: loss 0.595623\n",
      "iteration 82 / 300: loss 0.597685\n",
      "iteration 82 / 300: loss 0.592878\n",
      "iteration 82 / 300: loss 0.589621\n",
      "iteration 82 / 300: loss 0.599399\n",
      "iteration 82 / 300: loss 0.611494\n",
      "iteration 82 / 300: loss 0.592592\n",
      "iteration 82 / 300: loss 0.599559\n",
      "iteration 82 / 300: loss 0.603253\n",
      "iteration 82 / 300: loss 0.602544\n",
      "iteration 82 / 300: loss 0.579930\n",
      "iteration 82 / 300: loss 0.601719\n",
      "iteration 83 / 300: loss 0.585647\n",
      "iteration 83 / 300: loss 0.588538\n",
      "iteration 83 / 300: loss 0.567633\n",
      "iteration 83 / 300: loss 0.592483\n",
      "iteration 83 / 300: loss 0.593728\n",
      "iteration 83 / 300: loss 0.595425\n",
      "iteration 83 / 300: loss 0.608899\n",
      "iteration 83 / 300: loss 0.592851\n",
      "iteration 83 / 300: loss 0.628193\n",
      "iteration 83 / 300: loss 0.580294\n",
      "iteration 83 / 300: loss 0.608055\n",
      "iteration 83 / 300: loss 0.587518\n",
      "iteration 83 / 300: loss 0.591806\n",
      "iteration 83 / 300: loss 0.571484\n",
      "iteration 83 / 300: loss 0.583137\n",
      "iteration 83 / 300: loss 0.608537\n",
      "iteration 83 / 300: loss 0.598482\n",
      "iteration 83 / 300: loss 0.583964\n",
      "iteration 83 / 300: loss 0.615377\n",
      "iteration 83 / 300: loss 0.591772\n",
      "iteration 83 / 300: loss 0.585616\n",
      "iteration 83 / 300: loss 0.591453\n",
      "iteration 83 / 300: loss 0.604467\n",
      "iteration 83 / 300: loss 0.595918\n",
      "iteration 83 / 300: loss 0.615040\n",
      "iteration 83 / 300: loss 0.608490\n",
      "iteration 83 / 300: loss 0.598352\n",
      "iteration 83 / 300: loss 0.589046\n",
      "iteration 83 / 300: loss 0.617884\n",
      "iteration 83 / 300: loss 0.594893\n",
      "iteration 83 / 300: loss 0.601820\n",
      "iteration 83 / 300: loss 0.631177\n",
      "iteration 83 / 300: loss 0.587645\n",
      "iteration 83 / 300: loss 0.606687\n",
      "iteration 83 / 300: loss 0.588166\n",
      "iteration 83 / 300: loss 0.601035\n",
      "iteration 83 / 300: loss 0.596074\n",
      "iteration 83 / 300: loss 0.589440\n",
      "iteration 83 / 300: loss 0.599670\n",
      "iteration 83 / 300: loss 0.604978\n",
      "iteration 83 / 300: loss 0.619547\n",
      "iteration 83 / 300: loss 0.588953\n",
      "iteration 83 / 300: loss 0.593790\n",
      "iteration 83 / 300: loss 0.585743\n",
      "iteration 83 / 300: loss 0.613319\n",
      "iteration 83 / 300: loss 0.587643\n",
      "iteration 83 / 300: loss 0.578464\n",
      "iteration 83 / 300: loss 0.567551\n",
      "iteration 83 / 300: loss 0.562332\n",
      "iteration 83 / 300: loss 0.594302\n",
      "iteration 83 / 300: loss 0.578922\n",
      "iteration 83 / 300: loss 0.586465\n",
      "iteration 83 / 300: loss 0.573003\n",
      "iteration 83 / 300: loss 0.596268\n",
      "iteration 83 / 300: loss 0.608052\n",
      "iteration 83 / 300: loss 0.610925\n",
      "iteration 83 / 300: loss 0.606387\n",
      "iteration 83 / 300: loss 0.583896\n",
      "iteration 83 / 300: loss 0.589724\n",
      "iteration 83 / 300: loss 0.595303\n",
      "iteration 83 / 300: loss 0.599059\n",
      "iteration 83 / 300: loss 0.596256\n",
      "iteration 83 / 300: loss 0.589873\n",
      "iteration 83 / 300: loss 0.591244\n",
      "iteration 83 / 300: loss 0.584954\n",
      "iteration 83 / 300: loss 0.599757\n",
      "iteration 83 / 300: loss 0.598998\n",
      "iteration 83 / 300: loss 0.614370\n",
      "iteration 83 / 300: loss 0.597905\n",
      "iteration 83 / 300: loss 0.599403\n",
      "iteration 83 / 300: loss 0.603442\n",
      "iteration 83 / 300: loss 0.592985\n",
      "iteration 83 / 300: loss 0.592512\n",
      "iteration 83 / 300: loss 0.589151\n",
      "iteration 83 / 300: loss 0.596585\n",
      "iteration 83 / 300: loss 0.605831\n",
      "iteration 83 / 300: loss 0.610667\n",
      "iteration 83 / 300: loss 0.587885\n",
      "iteration 83 / 300: loss 0.599433\n",
      "iteration 83 / 300: loss 0.602898\n",
      "iteration 83 / 300: loss 0.605145\n",
      "iteration 83 / 300: loss 0.603982\n",
      "iteration 83 / 300: loss 0.624241\n",
      "iteration 83 / 300: loss 0.587308\n",
      "iteration 83 / 300: loss 0.580863\n",
      "iteration 83 / 300: loss 0.625174\n",
      "iteration 83 / 300: loss 0.603430\n",
      "iteration 83 / 300: loss 0.604441\n",
      "iteration 83 / 300: loss 0.595609\n",
      "iteration 83 / 300: loss 0.597672\n",
      "iteration 83 / 300: loss 0.592865\n",
      "iteration 83 / 300: loss 0.589609\n",
      "iteration 83 / 300: loss 0.599386\n",
      "iteration 83 / 300: loss 0.611483\n",
      "iteration 83 / 300: loss 0.592579\n",
      "iteration 83 / 300: loss 0.599546\n",
      "iteration 83 / 300: loss 0.603239\n",
      "iteration 83 / 300: loss 0.602532\n",
      "iteration 83 / 300: loss 0.579918\n",
      "iteration 83 / 300: loss 0.601707\n",
      "iteration 84 / 300: loss 0.585636\n",
      "iteration 84 / 300: loss 0.588528\n",
      "iteration 84 / 300: loss 0.567622\n",
      "iteration 84 / 300: loss 0.592473\n",
      "iteration 84 / 300: loss 0.593717\n",
      "iteration 84 / 300: loss 0.595412\n",
      "iteration 84 / 300: loss 0.608888\n",
      "iteration 84 / 300: loss 0.592840\n",
      "iteration 84 / 300: loss 0.628180\n",
      "iteration 84 / 300: loss 0.580281\n",
      "iteration 84 / 300: loss 0.608042\n",
      "iteration 84 / 300: loss 0.587506\n",
      "iteration 84 / 300: loss 0.591794\n",
      "iteration 84 / 300: loss 0.571473\n",
      "iteration 84 / 300: loss 0.583126\n",
      "iteration 84 / 300: loss 0.608528\n",
      "iteration 84 / 300: loss 0.598471\n",
      "iteration 84 / 300: loss 0.583954\n",
      "iteration 84 / 300: loss 0.615365\n",
      "iteration 84 / 300: loss 0.591761\n",
      "iteration 84 / 300: loss 0.585604\n",
      "iteration 84 / 300: loss 0.591441\n",
      "iteration 84 / 300: loss 0.604455\n",
      "iteration 84 / 300: loss 0.595905\n",
      "iteration 84 / 300: loss 0.615032\n",
      "iteration 84 / 300: loss 0.608480\n",
      "iteration 84 / 300: loss 0.598339\n",
      "iteration 84 / 300: loss 0.589035\n",
      "iteration 84 / 300: loss 0.617872\n",
      "iteration 84 / 300: loss 0.594881\n",
      "iteration 84 / 300: loss 0.601807\n",
      "iteration 84 / 300: loss 0.631164\n",
      "iteration 84 / 300: loss 0.587632\n",
      "iteration 84 / 300: loss 0.606675\n",
      "iteration 84 / 300: loss 0.588153\n",
      "iteration 84 / 300: loss 0.601021\n",
      "iteration 84 / 300: loss 0.596063\n",
      "iteration 84 / 300: loss 0.589426\n",
      "iteration 84 / 300: loss 0.599656\n",
      "iteration 84 / 300: loss 0.604967\n",
      "iteration 84 / 300: loss 0.619534\n",
      "iteration 84 / 300: loss 0.588939\n",
      "iteration 84 / 300: loss 0.593777\n",
      "iteration 84 / 300: loss 0.585729\n",
      "iteration 84 / 300: loss 0.613309\n",
      "iteration 84 / 300: loss 0.587632\n",
      "iteration 84 / 300: loss 0.578451\n",
      "iteration 84 / 300: loss 0.567540\n",
      "iteration 84 / 300: loss 0.562322\n",
      "iteration 84 / 300: loss 0.594291\n",
      "iteration 84 / 300: loss 0.578913\n",
      "iteration 84 / 300: loss 0.586455\n",
      "iteration 84 / 300: loss 0.572992\n",
      "iteration 84 / 300: loss 0.596257\n",
      "iteration 84 / 300: loss 0.608042\n",
      "iteration 84 / 300: loss 0.610917\n",
      "iteration 84 / 300: loss 0.606376\n",
      "iteration 84 / 300: loss 0.583886\n",
      "iteration 84 / 300: loss 0.589715\n",
      "iteration 84 / 300: loss 0.595292\n",
      "iteration 84 / 300: loss 0.599049\n",
      "iteration 84 / 300: loss 0.596244\n",
      "iteration 84 / 300: loss 0.589863\n",
      "iteration 84 / 300: loss 0.591233\n",
      "iteration 84 / 300: loss 0.584945\n",
      "iteration 84 / 300: loss 0.599746\n",
      "iteration 84 / 300: loss 0.598989\n",
      "iteration 84 / 300: loss 0.614362\n",
      "iteration 84 / 300: loss 0.597895\n",
      "iteration 84 / 300: loss 0.599393\n",
      "iteration 84 / 300: loss 0.603430\n",
      "iteration 84 / 300: loss 0.592973\n",
      "iteration 84 / 300: loss 0.592500\n",
      "iteration 84 / 300: loss 0.589141\n",
      "iteration 84 / 300: loss 0.596571\n",
      "iteration 84 / 300: loss 0.605819\n",
      "iteration 84 / 300: loss 0.610657\n",
      "iteration 84 / 300: loss 0.587875\n",
      "iteration 84 / 300: loss 0.599425\n",
      "iteration 84 / 300: loss 0.602888\n",
      "iteration 84 / 300: loss 0.605134\n",
      "iteration 84 / 300: loss 0.603969\n",
      "iteration 84 / 300: loss 0.624232\n",
      "iteration 84 / 300: loss 0.587299\n",
      "iteration 84 / 300: loss 0.580852\n",
      "iteration 84 / 300: loss 0.625161\n",
      "iteration 84 / 300: loss 0.603418\n",
      "iteration 84 / 300: loss 0.604430\n",
      "iteration 84 / 300: loss 0.595597\n",
      "iteration 84 / 300: loss 0.597660\n",
      "iteration 84 / 300: loss 0.592854\n",
      "iteration 84 / 300: loss 0.589598\n",
      "iteration 84 / 300: loss 0.599374\n",
      "iteration 84 / 300: loss 0.611473\n",
      "iteration 84 / 300: loss 0.592568\n",
      "iteration 84 / 300: loss 0.599535\n",
      "iteration 84 / 300: loss 0.603226\n",
      "iteration 84 / 300: loss 0.602520\n",
      "iteration 84 / 300: loss 0.579908\n",
      "iteration 84 / 300: loss 0.601696\n",
      "iteration 85 / 300: loss 0.585625\n",
      "iteration 85 / 300: loss 0.588518\n",
      "iteration 85 / 300: loss 0.567612\n",
      "iteration 85 / 300: loss 0.592465\n",
      "iteration 85 / 300: loss 0.593708\n",
      "iteration 85 / 300: loss 0.595401\n",
      "iteration 85 / 300: loss 0.608878\n",
      "iteration 85 / 300: loss 0.592830\n",
      "iteration 85 / 300: loss 0.628169\n",
      "iteration 85 / 300: loss 0.580269\n",
      "iteration 85 / 300: loss 0.608031\n",
      "iteration 85 / 300: loss 0.587496\n",
      "iteration 85 / 300: loss 0.591784\n",
      "iteration 85 / 300: loss 0.571463\n",
      "iteration 85 / 300: loss 0.583117\n",
      "iteration 85 / 300: loss 0.608520\n",
      "iteration 85 / 300: loss 0.598460\n",
      "iteration 85 / 300: loss 0.583945\n",
      "iteration 85 / 300: loss 0.615355\n",
      "iteration 85 / 300: loss 0.591750\n",
      "iteration 85 / 300: loss 0.585595\n",
      "iteration 85 / 300: loss 0.591430\n",
      "iteration 85 / 300: loss 0.604444\n",
      "iteration 85 / 300: loss 0.595894\n",
      "iteration 85 / 300: loss 0.615024\n",
      "iteration 85 / 300: loss 0.608471\n",
      "iteration 85 / 300: loss 0.598328\n",
      "iteration 85 / 300: loss 0.589026\n",
      "iteration 85 / 300: loss 0.617861\n",
      "iteration 85 / 300: loss 0.594870\n",
      "iteration 85 / 300: loss 0.601796\n",
      "iteration 85 / 300: loss 0.631151\n",
      "iteration 85 / 300: loss 0.587621\n",
      "iteration 85 / 300: loss 0.606665\n",
      "iteration 85 / 300: loss 0.588142\n",
      "iteration 85 / 300: loss 0.601008\n",
      "iteration 85 / 300: loss 0.596053\n",
      "iteration 85 / 300: loss 0.589413\n",
      "iteration 85 / 300: loss 0.599644\n",
      "iteration 85 / 300: loss 0.604956\n",
      "iteration 85 / 300: loss 0.619523\n",
      "iteration 85 / 300: loss 0.588927\n",
      "iteration 85 / 300: loss 0.593764\n",
      "iteration 85 / 300: loss 0.585716\n",
      "iteration 85 / 300: loss 0.613300\n",
      "iteration 85 / 300: loss 0.587622\n",
      "iteration 85 / 300: loss 0.578439\n",
      "iteration 85 / 300: loss 0.567530\n",
      "iteration 85 / 300: loss 0.562314\n",
      "iteration 85 / 300: loss 0.594281\n",
      "iteration 85 / 300: loss 0.578904\n",
      "iteration 85 / 300: loss 0.586446\n",
      "iteration 85 / 300: loss 0.572983\n",
      "iteration 85 / 300: loss 0.596247\n",
      "iteration 85 / 300: loss 0.608033\n",
      "iteration 85 / 300: loss 0.610910\n",
      "iteration 85 / 300: loss 0.606365\n",
      "iteration 85 / 300: loss 0.583877\n",
      "iteration 85 / 300: loss 0.589706\n",
      "iteration 85 / 300: loss 0.595282\n",
      "iteration 85 / 300: loss 0.599040\n",
      "iteration 85 / 300: loss 0.596234\n",
      "iteration 85 / 300: loss 0.589854\n",
      "iteration 85 / 300: loss 0.591224\n",
      "iteration 85 / 300: loss 0.584936\n",
      "iteration 85 / 300: loss 0.599737\n",
      "iteration 85 / 300: loss 0.598981\n",
      "iteration 85 / 300: loss 0.614355\n",
      "iteration 85 / 300: loss 0.597885\n",
      "iteration 85 / 300: loss 0.599384\n",
      "iteration 85 / 300: loss 0.603420\n",
      "iteration 85 / 300: loss 0.592963\n",
      "iteration 85 / 300: loss 0.592490\n",
      "iteration 85 / 300: loss 0.589131\n",
      "iteration 85 / 300: loss 0.596559\n",
      "iteration 85 / 300: loss 0.605809\n",
      "iteration 85 / 300: loss 0.610648\n",
      "iteration 85 / 300: loss 0.587866\n",
      "iteration 85 / 300: loss 0.599418\n",
      "iteration 85 / 300: loss 0.602879\n",
      "iteration 85 / 300: loss 0.605124\n",
      "iteration 85 / 300: loss 0.603958\n",
      "iteration 85 / 300: loss 0.624223\n",
      "iteration 85 / 300: loss 0.587292\n",
      "iteration 85 / 300: loss 0.580843\n",
      "iteration 85 / 300: loss 0.625150\n",
      "iteration 85 / 300: loss 0.603408\n",
      "iteration 85 / 300: loss 0.604420\n",
      "iteration 85 / 300: loss 0.595585\n",
      "iteration 85 / 300: loss 0.597648\n",
      "iteration 85 / 300: loss 0.592843\n",
      "iteration 85 / 300: loss 0.589588\n",
      "iteration 85 / 300: loss 0.599364\n",
      "iteration 85 / 300: loss 0.611464\n",
      "iteration 85 / 300: loss 0.592558\n",
      "iteration 85 / 300: loss 0.599524\n",
      "iteration 85 / 300: loss 0.603214\n",
      "iteration 85 / 300: loss 0.602510\n",
      "iteration 85 / 300: loss 0.579899\n",
      "iteration 85 / 300: loss 0.601686\n",
      "iteration 86 / 300: loss 0.585616\n",
      "iteration 86 / 300: loss 0.588510\n",
      "iteration 86 / 300: loss 0.567603\n",
      "iteration 86 / 300: loss 0.592457\n",
      "iteration 86 / 300: loss 0.593699\n",
      "iteration 86 / 300: loss 0.595391\n",
      "iteration 86 / 300: loss 0.608869\n",
      "iteration 86 / 300: loss 0.592821\n",
      "iteration 86 / 300: loss 0.628159\n",
      "iteration 86 / 300: loss 0.580258\n",
      "iteration 86 / 300: loss 0.608021\n",
      "iteration 86 / 300: loss 0.587486\n",
      "iteration 86 / 300: loss 0.591775\n",
      "iteration 86 / 300: loss 0.571454\n",
      "iteration 86 / 300: loss 0.583108\n",
      "iteration 86 / 300: loss 0.608512\n",
      "iteration 86 / 300: loss 0.598451\n",
      "iteration 86 / 300: loss 0.583937\n",
      "iteration 86 / 300: loss 0.615345\n",
      "iteration 86 / 300: loss 0.591741\n",
      "iteration 86 / 300: loss 0.585585\n",
      "iteration 86 / 300: loss 0.591420\n",
      "iteration 86 / 300: loss 0.604434\n",
      "iteration 86 / 300: loss 0.595884\n",
      "iteration 86 / 300: loss 0.615017\n",
      "iteration 86 / 300: loss 0.608464\n",
      "iteration 86 / 300: loss 0.598318\n",
      "iteration 86 / 300: loss 0.589017\n",
      "iteration 86 / 300: loss 0.617851\n",
      "iteration 86 / 300: loss 0.594861\n",
      "iteration 86 / 300: loss 0.601785\n",
      "iteration 86 / 300: loss 0.631140\n",
      "iteration 86 / 300: loss 0.587611\n",
      "iteration 86 / 300: loss 0.606655\n",
      "iteration 86 / 300: loss 0.588132\n",
      "iteration 86 / 300: loss 0.600997\n",
      "iteration 86 / 300: loss 0.596044\n",
      "iteration 86 / 300: loss 0.589402\n",
      "iteration 86 / 300: loss 0.599632\n",
      "iteration 86 / 300: loss 0.604946\n",
      "iteration 86 / 300: loss 0.619513\n",
      "iteration 86 / 300: loss 0.588916\n",
      "iteration 86 / 300: loss 0.593753\n",
      "iteration 86 / 300: loss 0.585704\n",
      "iteration 86 / 300: loss 0.613291\n",
      "iteration 86 / 300: loss 0.587612\n",
      "iteration 86 / 300: loss 0.578429\n",
      "iteration 86 / 300: loss 0.567521\n",
      "iteration 86 / 300: loss 0.562307\n",
      "iteration 86 / 300: loss 0.594272\n",
      "iteration 86 / 300: loss 0.578896\n",
      "iteration 86 / 300: loss 0.586438\n",
      "iteration 86 / 300: loss 0.572974\n",
      "iteration 86 / 300: loss 0.596238\n",
      "iteration 86 / 300: loss 0.608026\n",
      "iteration 86 / 300: loss 0.610903\n",
      "iteration 86 / 300: loss 0.606356\n",
      "iteration 86 / 300: loss 0.583869\n",
      "iteration 86 / 300: loss 0.589699\n",
      "iteration 86 / 300: loss 0.595272\n",
      "iteration 86 / 300: loss 0.599032\n",
      "iteration 86 / 300: loss 0.596224\n",
      "iteration 86 / 300: loss 0.589846\n",
      "iteration 86 / 300: loss 0.591216\n",
      "iteration 86 / 300: loss 0.584928\n",
      "iteration 86 / 300: loss 0.599728\n",
      "iteration 86 / 300: loss 0.598973\n",
      "iteration 86 / 300: loss 0.614348\n",
      "iteration 86 / 300: loss 0.597877\n",
      "iteration 86 / 300: loss 0.599376\n",
      "iteration 86 / 300: loss 0.603410\n",
      "iteration 86 / 300: loss 0.592954\n",
      "iteration 86 / 300: loss 0.592480\n",
      "iteration 86 / 300: loss 0.589123\n",
      "iteration 86 / 300: loss 0.596549\n",
      "iteration 86 / 300: loss 0.605799\n",
      "iteration 86 / 300: loss 0.610640\n",
      "iteration 86 / 300: loss 0.587858\n",
      "iteration 86 / 300: loss 0.599412\n",
      "iteration 86 / 300: loss 0.602871\n",
      "iteration 86 / 300: loss 0.605115\n",
      "iteration 86 / 300: loss 0.603947\n",
      "iteration 86 / 300: loss 0.624216\n",
      "iteration 86 / 300: loss 0.587285\n",
      "iteration 86 / 300: loss 0.580835\n",
      "iteration 86 / 300: loss 0.625140\n",
      "iteration 86 / 300: loss 0.603399\n",
      "iteration 86 / 300: loss 0.604410\n",
      "iteration 86 / 300: loss 0.595575\n",
      "iteration 86 / 300: loss 0.597638\n",
      "iteration 86 / 300: loss 0.592833\n",
      "iteration 86 / 300: loss 0.589579\n",
      "iteration 86 / 300: loss 0.599354\n",
      "iteration 86 / 300: loss 0.611456\n",
      "iteration 86 / 300: loss 0.592549\n",
      "iteration 86 / 300: loss 0.599515\n",
      "iteration 86 / 300: loss 0.603203\n",
      "iteration 86 / 300: loss 0.602500\n",
      "iteration 86 / 300: loss 0.579891\n",
      "iteration 86 / 300: loss 0.601677\n",
      "iteration 87 / 300: loss 0.585608\n",
      "iteration 87 / 300: loss 0.588502\n",
      "iteration 87 / 300: loss 0.567595\n",
      "iteration 87 / 300: loss 0.592449\n",
      "iteration 87 / 300: loss 0.593692\n",
      "iteration 87 / 300: loss 0.595382\n",
      "iteration 87 / 300: loss 0.608861\n",
      "iteration 87 / 300: loss 0.592812\n",
      "iteration 87 / 300: loss 0.628149\n",
      "iteration 87 / 300: loss 0.580247\n",
      "iteration 87 / 300: loss 0.608012\n",
      "iteration 87 / 300: loss 0.587477\n",
      "iteration 87 / 300: loss 0.591766\n",
      "iteration 87 / 300: loss 0.571446\n",
      "iteration 87 / 300: loss 0.583100\n",
      "iteration 87 / 300: loss 0.608505\n",
      "iteration 87 / 300: loss 0.598442\n",
      "iteration 87 / 300: loss 0.583929\n",
      "iteration 87 / 300: loss 0.615336\n",
      "iteration 87 / 300: loss 0.591732\n",
      "iteration 87 / 300: loss 0.585577\n",
      "iteration 87 / 300: loss 0.591411\n",
      "iteration 87 / 300: loss 0.604425\n",
      "iteration 87 / 300: loss 0.595874\n",
      "iteration 87 / 300: loss 0.615010\n",
      "iteration 87 / 300: loss 0.608456\n",
      "iteration 87 / 300: loss 0.598309\n",
      "iteration 87 / 300: loss 0.589009\n",
      "iteration 87 / 300: loss 0.617842\n",
      "iteration 87 / 300: loss 0.594852\n",
      "iteration 87 / 300: loss 0.601775\n",
      "iteration 87 / 300: loss 0.631129\n",
      "iteration 87 / 300: loss 0.587601\n",
      "iteration 87 / 300: loss 0.606646\n",
      "iteration 87 / 300: loss 0.588122\n",
      "iteration 87 / 300: loss 0.600987\n",
      "iteration 87 / 300: loss 0.596035\n",
      "iteration 87 / 300: loss 0.589391\n",
      "iteration 87 / 300: loss 0.599622\n",
      "iteration 87 / 300: loss 0.604938\n",
      "iteration 87 / 300: loss 0.619503\n",
      "iteration 87 / 300: loss 0.588905\n",
      "iteration 87 / 300: loss 0.593742\n",
      "iteration 87 / 300: loss 0.585694\n",
      "iteration 87 / 300: loss 0.613284\n",
      "iteration 87 / 300: loss 0.587604\n",
      "iteration 87 / 300: loss 0.578419\n",
      "iteration 87 / 300: loss 0.567513\n",
      "iteration 87 / 300: loss 0.562300\n",
      "iteration 87 / 300: loss 0.594263\n",
      "iteration 87 / 300: loss 0.578889\n",
      "iteration 87 / 300: loss 0.586431\n",
      "iteration 87 / 300: loss 0.572966\n",
      "iteration 87 / 300: loss 0.596230\n",
      "iteration 87 / 300: loss 0.608018\n",
      "iteration 87 / 300: loss 0.610897\n",
      "iteration 87 / 300: loss 0.606347\n",
      "iteration 87 / 300: loss 0.583861\n",
      "iteration 87 / 300: loss 0.589692\n",
      "iteration 87 / 300: loss 0.595264\n",
      "iteration 87 / 300: loss 0.599025\n",
      "iteration 87 / 300: loss 0.596215\n",
      "iteration 87 / 300: loss 0.589839\n",
      "iteration 87 / 300: loss 0.591208\n",
      "iteration 87 / 300: loss 0.584921\n",
      "iteration 87 / 300: loss 0.599720\n",
      "iteration 87 / 300: loss 0.598967\n",
      "iteration 87 / 300: loss 0.614342\n",
      "iteration 87 / 300: loss 0.597869\n",
      "iteration 87 / 300: loss 0.599368\n",
      "iteration 87 / 300: loss 0.603401\n",
      "iteration 87 / 300: loss 0.592945\n",
      "iteration 87 / 300: loss 0.592472\n",
      "iteration 87 / 300: loss 0.589115\n",
      "iteration 87 / 300: loss 0.596539\n",
      "iteration 87 / 300: loss 0.605791\n",
      "iteration 87 / 300: loss 0.610632\n",
      "iteration 87 / 300: loss 0.587851\n",
      "iteration 87 / 300: loss 0.599406\n",
      "iteration 87 / 300: loss 0.602863\n",
      "iteration 87 / 300: loss 0.605107\n",
      "iteration 87 / 300: loss 0.603938\n",
      "iteration 87 / 300: loss 0.624209\n",
      "iteration 87 / 300: loss 0.587279\n",
      "iteration 87 / 300: loss 0.580827\n",
      "iteration 87 / 300: loss 0.625131\n",
      "iteration 87 / 300: loss 0.603390\n",
      "iteration 87 / 300: loss 0.604402\n",
      "iteration 87 / 300: loss 0.595565\n",
      "iteration 87 / 300: loss 0.597629\n",
      "iteration 87 / 300: loss 0.592824\n",
      "iteration 87 / 300: loss 0.589571\n",
      "iteration 87 / 300: loss 0.599346\n",
      "iteration 87 / 300: loss 0.611449\n",
      "iteration 87 / 300: loss 0.592541\n",
      "iteration 87 / 300: loss 0.599506\n",
      "iteration 87 / 300: loss 0.603193\n",
      "iteration 87 / 300: loss 0.602492\n",
      "iteration 87 / 300: loss 0.579883\n",
      "iteration 87 / 300: loss 0.601669\n",
      "iteration 88 / 300: loss 0.585600\n",
      "iteration 88 / 300: loss 0.588495\n",
      "iteration 88 / 300: loss 0.567587\n",
      "iteration 88 / 300: loss 0.592443\n",
      "iteration 88 / 300: loss 0.593685\n",
      "iteration 88 / 300: loss 0.595374\n",
      "iteration 88 / 300: loss 0.608854\n",
      "iteration 88 / 300: loss 0.592805\n",
      "iteration 88 / 300: loss 0.628141\n",
      "iteration 88 / 300: loss 0.580238\n",
      "iteration 88 / 300: loss 0.608003\n",
      "iteration 88 / 300: loss 0.587470\n",
      "iteration 88 / 300: loss 0.591759\n",
      "iteration 88 / 300: loss 0.571439\n",
      "iteration 88 / 300: loss 0.583093\n",
      "iteration 88 / 300: loss 0.608499\n",
      "iteration 88 / 300: loss 0.598434\n",
      "iteration 88 / 300: loss 0.583922\n",
      "iteration 88 / 300: loss 0.615328\n",
      "iteration 88 / 300: loss 0.591724\n",
      "iteration 88 / 300: loss 0.585570\n",
      "iteration 88 / 300: loss 0.591403\n",
      "iteration 88 / 300: loss 0.604417\n",
      "iteration 88 / 300: loss 0.595866\n",
      "iteration 88 / 300: loss 0.615005\n",
      "iteration 88 / 300: loss 0.608450\n",
      "iteration 88 / 300: loss 0.598301\n",
      "iteration 88 / 300: loss 0.589002\n",
      "iteration 88 / 300: loss 0.617834\n",
      "iteration 88 / 300: loss 0.594844\n",
      "iteration 88 / 300: loss 0.601767\n",
      "iteration 88 / 300: loss 0.631120\n",
      "iteration 88 / 300: loss 0.587593\n",
      "iteration 88 / 300: loss 0.606638\n",
      "iteration 88 / 300: loss 0.588114\n",
      "iteration 88 / 300: loss 0.600978\n",
      "iteration 88 / 300: loss 0.596028\n",
      "iteration 88 / 300: loss 0.589382\n",
      "iteration 88 / 300: loss 0.599613\n",
      "iteration 88 / 300: loss 0.604930\n",
      "iteration 88 / 300: loss 0.619495\n",
      "iteration 88 / 300: loss 0.588896\n",
      "iteration 88 / 300: loss 0.593733\n",
      "iteration 88 / 300: loss 0.585685\n",
      "iteration 88 / 300: loss 0.613277\n",
      "iteration 88 / 300: loss 0.587596\n",
      "iteration 88 / 300: loss 0.578411\n",
      "iteration 88 / 300: loss 0.567505\n",
      "iteration 88 / 300: loss 0.562294\n",
      "iteration 88 / 300: loss 0.594256\n",
      "iteration 88 / 300: loss 0.578883\n",
      "iteration 88 / 300: loss 0.586424\n",
      "iteration 88 / 300: loss 0.572959\n",
      "iteration 88 / 300: loss 0.596222\n",
      "iteration 88 / 300: loss 0.608012\n",
      "iteration 88 / 300: loss 0.610891\n",
      "iteration 88 / 300: loss 0.606340\n",
      "iteration 88 / 300: loss 0.583855\n",
      "iteration 88 / 300: loss 0.589686\n",
      "iteration 88 / 300: loss 0.595256\n",
      "iteration 88 / 300: loss 0.599018\n",
      "iteration 88 / 300: loss 0.596208\n",
      "iteration 88 / 300: loss 0.589832\n",
      "iteration 88 / 300: loss 0.591201\n",
      "iteration 88 / 300: loss 0.584915\n",
      "iteration 88 / 300: loss 0.599713\n",
      "iteration 88 / 300: loss 0.598960\n",
      "iteration 88 / 300: loss 0.614336\n",
      "iteration 88 / 300: loss 0.597862\n",
      "iteration 88 / 300: loss 0.599362\n",
      "iteration 88 / 300: loss 0.603393\n",
      "iteration 88 / 300: loss 0.592938\n",
      "iteration 88 / 300: loss 0.592464\n",
      "iteration 88 / 300: loss 0.589108\n",
      "iteration 88 / 300: loss 0.596530\n",
      "iteration 88 / 300: loss 0.605783\n",
      "iteration 88 / 300: loss 0.610626\n",
      "iteration 88 / 300: loss 0.587844\n",
      "iteration 88 / 300: loss 0.599401\n",
      "iteration 88 / 300: loss 0.602856\n",
      "iteration 88 / 300: loss 0.605099\n",
      "iteration 88 / 300: loss 0.603929\n",
      "iteration 88 / 300: loss 0.624203\n",
      "iteration 88 / 300: loss 0.587273\n",
      "iteration 88 / 300: loss 0.580820\n",
      "iteration 88 / 300: loss 0.625123\n",
      "iteration 88 / 300: loss 0.603383\n",
      "iteration 88 / 300: loss 0.604394\n",
      "iteration 88 / 300: loss 0.595557\n",
      "iteration 88 / 300: loss 0.597621\n",
      "iteration 88 / 300: loss 0.592816\n",
      "iteration 88 / 300: loss 0.589564\n",
      "iteration 88 / 300: loss 0.599338\n",
      "iteration 88 / 300: loss 0.611442\n",
      "iteration 88 / 300: loss 0.592534\n",
      "iteration 88 / 300: loss 0.599498\n",
      "iteration 88 / 300: loss 0.603184\n",
      "iteration 88 / 300: loss 0.602484\n",
      "iteration 88 / 300: loss 0.579876\n",
      "iteration 88 / 300: loss 0.601662\n",
      "iteration 89 / 300: loss 0.585593\n",
      "iteration 89 / 300: loss 0.588488\n",
      "iteration 89 / 300: loss 0.567581\n",
      "iteration 89 / 300: loss 0.592437\n",
      "iteration 89 / 300: loss 0.593678\n",
      "iteration 89 / 300: loss 0.595366\n",
      "iteration 89 / 300: loss 0.608847\n",
      "iteration 89 / 300: loss 0.592798\n",
      "iteration 89 / 300: loss 0.628133\n",
      "iteration 89 / 300: loss 0.580230\n",
      "iteration 89 / 300: loss 0.607996\n",
      "iteration 89 / 300: loss 0.587463\n",
      "iteration 89 / 300: loss 0.591752\n",
      "iteration 89 / 300: loss 0.571432\n",
      "iteration 89 / 300: loss 0.583087\n",
      "iteration 89 / 300: loss 0.608494\n",
      "iteration 89 / 300: loss 0.598427\n",
      "iteration 89 / 300: loss 0.583916\n",
      "iteration 89 / 300: loss 0.615321\n",
      "iteration 89 / 300: loss 0.591717\n",
      "iteration 89 / 300: loss 0.585563\n",
      "iteration 89 / 300: loss 0.591395\n",
      "iteration 89 / 300: loss 0.604410\n",
      "iteration 89 / 300: loss 0.595859\n",
      "iteration 89 / 300: loss 0.614999\n",
      "iteration 89 / 300: loss 0.608444\n",
      "iteration 89 / 300: loss 0.598293\n",
      "iteration 89 / 300: loss 0.588996\n",
      "iteration 89 / 300: loss 0.617827\n",
      "iteration 89 / 300: loss 0.594837\n",
      "iteration 89 / 300: loss 0.601759\n",
      "iteration 89 / 300: loss 0.631111\n",
      "iteration 89 / 300: loss 0.587585\n",
      "iteration 89 / 300: loss 0.606631\n",
      "iteration 89 / 300: loss 0.588106\n",
      "iteration 89 / 300: loss 0.600969\n",
      "iteration 89 / 300: loss 0.596021\n",
      "iteration 89 / 300: loss 0.589373\n",
      "iteration 89 / 300: loss 0.599605\n",
      "iteration 89 / 300: loss 0.604923\n",
      "iteration 89 / 300: loss 0.619487\n",
      "iteration 89 / 300: loss 0.588888\n",
      "iteration 89 / 300: loss 0.593725\n",
      "iteration 89 / 300: loss 0.585676\n",
      "iteration 89 / 300: loss 0.613271\n",
      "iteration 89 / 300: loss 0.587589\n",
      "iteration 89 / 300: loss 0.578403\n",
      "iteration 89 / 300: loss 0.567499\n",
      "iteration 89 / 300: loss 0.562288\n",
      "iteration 89 / 300: loss 0.594249\n",
      "iteration 89 / 300: loss 0.578877\n",
      "iteration 89 / 300: loss 0.586418\n",
      "iteration 89 / 300: loss 0.572952\n",
      "iteration 89 / 300: loss 0.596216\n",
      "iteration 89 / 300: loss 0.608006\n",
      "iteration 89 / 300: loss 0.610886\n",
      "iteration 89 / 300: loss 0.606332\n",
      "iteration 89 / 300: loss 0.583849\n",
      "iteration 89 / 300: loss 0.589680\n",
      "iteration 89 / 300: loss 0.595249\n",
      "iteration 89 / 300: loss 0.599012\n",
      "iteration 89 / 300: loss 0.596200\n",
      "iteration 89 / 300: loss 0.589826\n",
      "iteration 89 / 300: loss 0.591195\n",
      "iteration 89 / 300: loss 0.584909\n",
      "iteration 89 / 300: loss 0.599707\n",
      "iteration 89 / 300: loss 0.598955\n",
      "iteration 89 / 300: loss 0.614331\n",
      "iteration 89 / 300: loss 0.597856\n",
      "iteration 89 / 300: loss 0.599356\n",
      "iteration 89 / 300: loss 0.603386\n",
      "iteration 89 / 300: loss 0.592931\n",
      "iteration 89 / 300: loss 0.592457\n",
      "iteration 89 / 300: loss 0.589102\n",
      "iteration 89 / 300: loss 0.596522\n",
      "iteration 89 / 300: loss 0.605776\n",
      "iteration 89 / 300: loss 0.610620\n",
      "iteration 89 / 300: loss 0.587838\n",
      "iteration 89 / 300: loss 0.599396\n",
      "iteration 89 / 300: loss 0.602850\n",
      "iteration 89 / 300: loss 0.605093\n",
      "iteration 89 / 300: loss 0.603921\n",
      "iteration 89 / 300: loss 0.624197\n",
      "iteration 89 / 300: loss 0.587268\n",
      "iteration 89 / 300: loss 0.580814\n",
      "iteration 89 / 300: loss 0.625116\n",
      "iteration 89 / 300: loss 0.603376\n",
      "iteration 89 / 300: loss 0.604387\n",
      "iteration 89 / 300: loss 0.595549\n",
      "iteration 89 / 300: loss 0.597614\n",
      "iteration 89 / 300: loss 0.592809\n",
      "iteration 89 / 300: loss 0.589557\n",
      "iteration 89 / 300: loss 0.599331\n",
      "iteration 89 / 300: loss 0.611436\n",
      "iteration 89 / 300: loss 0.592527\n",
      "iteration 89 / 300: loss 0.599491\n",
      "iteration 89 / 300: loss 0.603176\n",
      "iteration 89 / 300: loss 0.602477\n",
      "iteration 89 / 300: loss 0.579870\n",
      "iteration 89 / 300: loss 0.601655\n",
      "iteration 90 / 300: loss 0.585587\n",
      "iteration 90 / 300: loss 0.588483\n",
      "iteration 90 / 300: loss 0.567575\n",
      "iteration 90 / 300: loss 0.592431\n",
      "iteration 90 / 300: loss 0.593673\n",
      "iteration 90 / 300: loss 0.595359\n",
      "iteration 90 / 300: loss 0.608841\n",
      "iteration 90 / 300: loss 0.592791\n",
      "iteration 90 / 300: loss 0.628126\n",
      "iteration 90 / 300: loss 0.580223\n",
      "iteration 90 / 300: loss 0.607989\n",
      "iteration 90 / 300: loss 0.587456\n",
      "iteration 90 / 300: loss 0.591746\n",
      "iteration 90 / 300: loss 0.571427\n",
      "iteration 90 / 300: loss 0.583081\n",
      "iteration 90 / 300: loss 0.608489\n",
      "iteration 90 / 300: loss 0.598420\n",
      "iteration 90 / 300: loss 0.583911\n",
      "iteration 90 / 300: loss 0.615315\n",
      "iteration 90 / 300: loss 0.591711\n",
      "iteration 90 / 300: loss 0.585557\n",
      "iteration 90 / 300: loss 0.591388\n",
      "iteration 90 / 300: loss 0.604403\n",
      "iteration 90 / 300: loss 0.595852\n",
      "iteration 90 / 300: loss 0.614995\n",
      "iteration 90 / 300: loss 0.608439\n",
      "iteration 90 / 300: loss 0.598287\n",
      "iteration 90 / 300: loss 0.588990\n",
      "iteration 90 / 300: loss 0.617820\n",
      "iteration 90 / 300: loss 0.594831\n",
      "iteration 90 / 300: loss 0.601752\n",
      "iteration 90 / 300: loss 0.631104\n",
      "iteration 90 / 300: loss 0.587578\n",
      "iteration 90 / 300: loss 0.606624\n",
      "iteration 90 / 300: loss 0.588099\n",
      "iteration 90 / 300: loss 0.600962\n",
      "iteration 90 / 300: loss 0.596015\n",
      "iteration 90 / 300: loss 0.589365\n",
      "iteration 90 / 300: loss 0.599597\n",
      "iteration 90 / 300: loss 0.604917\n",
      "iteration 90 / 300: loss 0.619480\n",
      "iteration 90 / 300: loss 0.588880\n",
      "iteration 90 / 300: loss 0.593717\n",
      "iteration 90 / 300: loss 0.585668\n",
      "iteration 90 / 300: loss 0.613266\n",
      "iteration 90 / 300: loss 0.587583\n",
      "iteration 90 / 300: loss 0.578396\n",
      "iteration 90 / 300: loss 0.567493\n",
      "iteration 90 / 300: loss 0.562283\n",
      "iteration 90 / 300: loss 0.594243\n",
      "iteration 90 / 300: loss 0.578872\n",
      "iteration 90 / 300: loss 0.586413\n",
      "iteration 90 / 300: loss 0.572946\n",
      "iteration 90 / 300: loss 0.596209\n",
      "iteration 90 / 300: loss 0.608001\n",
      "iteration 90 / 300: loss 0.610882\n",
      "iteration 90 / 300: loss 0.606326\n",
      "iteration 90 / 300: loss 0.583843\n",
      "iteration 90 / 300: loss 0.589675\n",
      "iteration 90 / 300: loss 0.595243\n",
      "iteration 90 / 300: loss 0.599007\n",
      "iteration 90 / 300: loss 0.596194\n",
      "iteration 90 / 300: loss 0.589821\n",
      "iteration 90 / 300: loss 0.591189\n",
      "iteration 90 / 300: loss 0.584904\n",
      "iteration 90 / 300: loss 0.599701\n",
      "iteration 90 / 300: loss 0.598950\n",
      "iteration 90 / 300: loss 0.614326\n",
      "iteration 90 / 300: loss 0.597850\n",
      "iteration 90 / 300: loss 0.599350\n",
      "iteration 90 / 300: loss 0.603379\n",
      "iteration 90 / 300: loss 0.592925\n",
      "iteration 90 / 300: loss 0.592451\n",
      "iteration 90 / 300: loss 0.589096\n",
      "iteration 90 / 300: loss 0.596515\n",
      "iteration 90 / 300: loss 0.605769\n",
      "iteration 90 / 300: loss 0.610614\n",
      "iteration 90 / 300: loss 0.587833\n",
      "iteration 90 / 300: loss 0.599392\n",
      "iteration 90 / 300: loss 0.602845\n",
      "iteration 90 / 300: loss 0.605086\n",
      "iteration 90 / 300: loss 0.603914\n",
      "iteration 90 / 300: loss 0.624192\n",
      "iteration 90 / 300: loss 0.587263\n",
      "iteration 90 / 300: loss 0.580808\n",
      "iteration 90 / 300: loss 0.625109\n",
      "iteration 90 / 300: loss 0.603369\n",
      "iteration 90 / 300: loss 0.604381\n",
      "iteration 90 / 300: loss 0.595542\n",
      "iteration 90 / 300: loss 0.597607\n",
      "iteration 90 / 300: loss 0.592802\n",
      "iteration 90 / 300: loss 0.589551\n",
      "iteration 90 / 300: loss 0.599325\n",
      "iteration 90 / 300: loss 0.611431\n",
      "iteration 90 / 300: loss 0.592521\n",
      "iteration 90 / 300: loss 0.599485\n",
      "iteration 90 / 300: loss 0.603169\n",
      "iteration 90 / 300: loss 0.602471\n",
      "iteration 90 / 300: loss 0.579865\n",
      "iteration 90 / 300: loss 0.601649\n",
      "iteration 91 / 300: loss 0.585581\n",
      "iteration 91 / 300: loss 0.588477\n",
      "iteration 91 / 300: loss 0.567569\n",
      "iteration 91 / 300: loss 0.592426\n",
      "iteration 91 / 300: loss 0.593667\n",
      "iteration 91 / 300: loss 0.595353\n",
      "iteration 91 / 300: loss 0.608836\n",
      "iteration 91 / 300: loss 0.592786\n",
      "iteration 91 / 300: loss 0.628120\n",
      "iteration 91 / 300: loss 0.580216\n",
      "iteration 91 / 300: loss 0.607982\n",
      "iteration 91 / 300: loss 0.587450\n",
      "iteration 91 / 300: loss 0.591740\n",
      "iteration 91 / 300: loss 0.571421\n",
      "iteration 91 / 300: loss 0.583075\n",
      "iteration 91 / 300: loss 0.608484\n",
      "iteration 91 / 300: loss 0.598415\n",
      "iteration 91 / 300: loss 0.583906\n",
      "iteration 91 / 300: loss 0.615309\n",
      "iteration 91 / 300: loss 0.591705\n",
      "iteration 91 / 300: loss 0.585552\n",
      "iteration 91 / 300: loss 0.591382\n",
      "iteration 91 / 300: loss 0.604397\n",
      "iteration 91 / 300: loss 0.595845\n",
      "iteration 91 / 300: loss 0.614990\n",
      "iteration 91 / 300: loss 0.608434\n",
      "iteration 91 / 300: loss 0.598281\n",
      "iteration 91 / 300: loss 0.588985\n",
      "iteration 91 / 300: loss 0.617814\n",
      "iteration 91 / 300: loss 0.594825\n",
      "iteration 91 / 300: loss 0.601745\n",
      "iteration 91 / 300: loss 0.631097\n",
      "iteration 91 / 300: loss 0.587572\n",
      "iteration 91 / 300: loss 0.606618\n",
      "iteration 91 / 300: loss 0.588093\n",
      "iteration 91 / 300: loss 0.600955\n",
      "iteration 91 / 300: loss 0.596010\n",
      "iteration 91 / 300: loss 0.589358\n",
      "iteration 91 / 300: loss 0.599591\n",
      "iteration 91 / 300: loss 0.604911\n",
      "iteration 91 / 300: loss 0.619474\n",
      "iteration 91 / 300: loss 0.588873\n",
      "iteration 91 / 300: loss 0.593710\n",
      "iteration 91 / 300: loss 0.585661\n",
      "iteration 91 / 300: loss 0.613261\n",
      "iteration 91 / 300: loss 0.587577\n",
      "iteration 91 / 300: loss 0.578389\n",
      "iteration 91 / 300: loss 0.567487\n",
      "iteration 91 / 300: loss 0.562279\n",
      "iteration 91 / 300: loss 0.594237\n",
      "iteration 91 / 300: loss 0.578867\n",
      "iteration 91 / 300: loss 0.586408\n",
      "iteration 91 / 300: loss 0.572941\n",
      "iteration 91 / 300: loss 0.596204\n",
      "iteration 91 / 300: loss 0.607996\n",
      "iteration 91 / 300: loss 0.610878\n",
      "iteration 91 / 300: loss 0.606320\n",
      "iteration 91 / 300: loss 0.583838\n",
      "iteration 91 / 300: loss 0.589670\n",
      "iteration 91 / 300: loss 0.595238\n",
      "iteration 91 / 300: loss 0.599002\n",
      "iteration 91 / 300: loss 0.596188\n",
      "iteration 91 / 300: loss 0.589816\n",
      "iteration 91 / 300: loss 0.591184\n",
      "iteration 91 / 300: loss 0.584899\n",
      "iteration 91 / 300: loss 0.599696\n",
      "iteration 91 / 300: loss 0.598945\n",
      "iteration 91 / 300: loss 0.614322\n",
      "iteration 91 / 300: loss 0.597845\n",
      "iteration 91 / 300: loss 0.599345\n",
      "iteration 91 / 300: loss 0.603373\n",
      "iteration 91 / 300: loss 0.592919\n",
      "iteration 91 / 300: loss 0.592445\n",
      "iteration 91 / 300: loss 0.589091\n",
      "iteration 91 / 300: loss 0.596508\n",
      "iteration 91 / 300: loss 0.605764\n",
      "iteration 91 / 300: loss 0.610609\n",
      "iteration 91 / 300: loss 0.587828\n",
      "iteration 91 / 300: loss 0.599388\n",
      "iteration 91 / 300: loss 0.602840\n",
      "iteration 91 / 300: loss 0.605081\n",
      "iteration 91 / 300: loss 0.603908\n",
      "iteration 91 / 300: loss 0.624187\n",
      "iteration 91 / 300: loss 0.587259\n",
      "iteration 91 / 300: loss 0.580803\n",
      "iteration 91 / 300: loss 0.625103\n",
      "iteration 91 / 300: loss 0.603364\n",
      "iteration 91 / 300: loss 0.604375\n",
      "iteration 91 / 300: loss 0.595536\n",
      "iteration 91 / 300: loss 0.597601\n",
      "iteration 91 / 300: loss 0.592797\n",
      "iteration 91 / 300: loss 0.589546\n",
      "iteration 91 / 300: loss 0.599319\n",
      "iteration 91 / 300: loss 0.611426\n",
      "iteration 91 / 300: loss 0.592515\n",
      "iteration 91 / 300: loss 0.599479\n",
      "iteration 91 / 300: loss 0.603163\n",
      "iteration 91 / 300: loss 0.602465\n",
      "iteration 91 / 300: loss 0.579860\n",
      "iteration 91 / 300: loss 0.601644\n",
      "iteration 92 / 300: loss 0.585576\n",
      "iteration 92 / 300: loss 0.588473\n",
      "iteration 92 / 300: loss 0.567564\n",
      "iteration 92 / 300: loss 0.592422\n",
      "iteration 92 / 300: loss 0.593663\n",
      "iteration 92 / 300: loss 0.595348\n",
      "iteration 92 / 300: loss 0.608831\n",
      "iteration 92 / 300: loss 0.592781\n",
      "iteration 92 / 300: loss 0.628114\n",
      "iteration 92 / 300: loss 0.580210\n",
      "iteration 92 / 300: loss 0.607977\n",
      "iteration 92 / 300: loss 0.587445\n",
      "iteration 92 / 300: loss 0.591735\n",
      "iteration 92 / 300: loss 0.571416\n",
      "iteration 92 / 300: loss 0.583071\n",
      "iteration 92 / 300: loss 0.608480\n",
      "iteration 92 / 300: loss 0.598409\n",
      "iteration 92 / 300: loss 0.583901\n",
      "iteration 92 / 300: loss 0.615303\n",
      "iteration 92 / 300: loss 0.591700\n",
      "iteration 92 / 300: loss 0.585547\n",
      "iteration 92 / 300: loss 0.591377\n",
      "iteration 92 / 300: loss 0.604392\n",
      "iteration 92 / 300: loss 0.595840\n",
      "iteration 92 / 300: loss 0.614986\n",
      "iteration 92 / 300: loss 0.608430\n",
      "iteration 92 / 300: loss 0.598275\n",
      "iteration 92 / 300: loss 0.588980\n",
      "iteration 92 / 300: loss 0.617809\n",
      "iteration 92 / 300: loss 0.594820\n",
      "iteration 92 / 300: loss 0.601740\n",
      "iteration 92 / 300: loss 0.631091\n",
      "iteration 92 / 300: loss 0.587566\n",
      "iteration 92 / 300: loss 0.606613\n",
      "iteration 92 / 300: loss 0.588088\n",
      "iteration 92 / 300: loss 0.600949\n",
      "iteration 92 / 300: loss 0.596005\n",
      "iteration 92 / 300: loss 0.589352\n",
      "iteration 92 / 300: loss 0.599584\n",
      "iteration 92 / 300: loss 0.604905\n",
      "iteration 92 / 300: loss 0.619468\n",
      "iteration 92 / 300: loss 0.588867\n",
      "iteration 92 / 300: loss 0.593704\n",
      "iteration 92 / 300: loss 0.585655\n",
      "iteration 92 / 300: loss 0.613256\n",
      "iteration 92 / 300: loss 0.587572\n",
      "iteration 92 / 300: loss 0.578383\n",
      "iteration 92 / 300: loss 0.567482\n",
      "iteration 92 / 300: loss 0.562275\n",
      "iteration 92 / 300: loss 0.594232\n",
      "iteration 92 / 300: loss 0.578862\n",
      "iteration 92 / 300: loss 0.586403\n",
      "iteration 92 / 300: loss 0.572936\n",
      "iteration 92 / 300: loss 0.596199\n",
      "iteration 92 / 300: loss 0.607992\n",
      "iteration 92 / 300: loss 0.610874\n",
      "iteration 92 / 300: loss 0.606315\n",
      "iteration 92 / 300: loss 0.583833\n",
      "iteration 92 / 300: loss 0.589666\n",
      "iteration 92 / 300: loss 0.595232\n",
      "iteration 92 / 300: loss 0.598997\n",
      "iteration 92 / 300: loss 0.596183\n",
      "iteration 92 / 300: loss 0.589812\n",
      "iteration 92 / 300: loss 0.591180\n",
      "iteration 92 / 300: loss 0.584895\n",
      "iteration 92 / 300: loss 0.599691\n",
      "iteration 92 / 300: loss 0.598941\n",
      "iteration 92 / 300: loss 0.614318\n",
      "iteration 92 / 300: loss 0.597841\n",
      "iteration 92 / 300: loss 0.599341\n",
      "iteration 92 / 300: loss 0.603368\n",
      "iteration 92 / 300: loss 0.592914\n",
      "iteration 92 / 300: loss 0.592440\n",
      "iteration 92 / 300: loss 0.589086\n",
      "iteration 92 / 300: loss 0.596502\n",
      "iteration 92 / 300: loss 0.605758\n",
      "iteration 92 / 300: loss 0.610605\n",
      "iteration 92 / 300: loss 0.587824\n",
      "iteration 92 / 300: loss 0.599384\n",
      "iteration 92 / 300: loss 0.602835\n",
      "iteration 92 / 300: loss 0.605076\n",
      "iteration 92 / 300: loss 0.603902\n",
      "iteration 92 / 300: loss 0.624183\n",
      "iteration 92 / 300: loss 0.587255\n",
      "iteration 92 / 300: loss 0.580799\n",
      "iteration 92 / 300: loss 0.625097\n",
      "iteration 92 / 300: loss 0.603359\n",
      "iteration 92 / 300: loss 0.604370\n",
      "iteration 92 / 300: loss 0.595530\n",
      "iteration 92 / 300: loss 0.597595\n",
      "iteration 92 / 300: loss 0.592791\n",
      "iteration 92 / 300: loss 0.589541\n",
      "iteration 92 / 300: loss 0.599314\n",
      "iteration 92 / 300: loss 0.611422\n",
      "iteration 92 / 300: loss 0.592510\n",
      "iteration 92 / 300: loss 0.599474\n",
      "iteration 92 / 300: loss 0.603157\n",
      "iteration 92 / 300: loss 0.602460\n",
      "iteration 92 / 300: loss 0.579855\n",
      "iteration 92 / 300: loss 0.601639\n",
      "iteration 93 / 300: loss 0.585572\n",
      "iteration 93 / 300: loss 0.588468\n",
      "iteration 93 / 300: loss 0.567559\n",
      "iteration 93 / 300: loss 0.592418\n",
      "iteration 93 / 300: loss 0.593659\n",
      "iteration 93 / 300: loss 0.595343\n",
      "iteration 93 / 300: loss 0.608826\n",
      "iteration 93 / 300: loss 0.592776\n",
      "iteration 93 / 300: loss 0.628109\n",
      "iteration 93 / 300: loss 0.580204\n",
      "iteration 93 / 300: loss 0.607972\n",
      "iteration 93 / 300: loss 0.587440\n",
      "iteration 93 / 300: loss 0.591730\n",
      "iteration 93 / 300: loss 0.571412\n",
      "iteration 93 / 300: loss 0.583066\n",
      "iteration 93 / 300: loss 0.608476\n",
      "iteration 93 / 300: loss 0.598404\n",
      "iteration 93 / 300: loss 0.583897\n",
      "iteration 93 / 300: loss 0.615298\n",
      "iteration 93 / 300: loss 0.591695\n",
      "iteration 93 / 300: loss 0.585542\n",
      "iteration 93 / 300: loss 0.591372\n",
      "iteration 93 / 300: loss 0.604387\n",
      "iteration 93 / 300: loss 0.595835\n",
      "iteration 93 / 300: loss 0.614983\n",
      "iteration 93 / 300: loss 0.608426\n",
      "iteration 93 / 300: loss 0.598270\n",
      "iteration 93 / 300: loss 0.588976\n",
      "iteration 93 / 300: loss 0.617804\n",
      "iteration 93 / 300: loss 0.594815\n",
      "iteration 93 / 300: loss 0.601734\n",
      "iteration 93 / 300: loss 0.631085\n",
      "iteration 93 / 300: loss 0.587561\n",
      "iteration 93 / 300: loss 0.606608\n",
      "iteration 93 / 300: loss 0.588082\n",
      "iteration 93 / 300: loss 0.600943\n",
      "iteration 93 / 300: loss 0.596000\n",
      "iteration 93 / 300: loss 0.589346\n",
      "iteration 93 / 300: loss 0.599579\n",
      "iteration 93 / 300: loss 0.604901\n",
      "iteration 93 / 300: loss 0.619463\n",
      "iteration 93 / 300: loss 0.588861\n",
      "iteration 93 / 300: loss 0.593698\n",
      "iteration 93 / 300: loss 0.585649\n",
      "iteration 93 / 300: loss 0.613252\n",
      "iteration 93 / 300: loss 0.587567\n",
      "iteration 93 / 300: loss 0.578378\n",
      "iteration 93 / 300: loss 0.567478\n",
      "iteration 93 / 300: loss 0.562271\n",
      "iteration 93 / 300: loss 0.594227\n",
      "iteration 93 / 300: loss 0.578859\n",
      "iteration 93 / 300: loss 0.586399\n",
      "iteration 93 / 300: loss 0.572932\n",
      "iteration 93 / 300: loss 0.596194\n",
      "iteration 93 / 300: loss 0.607988\n",
      "iteration 93 / 300: loss 0.610871\n",
      "iteration 93 / 300: loss 0.606310\n",
      "iteration 93 / 300: loss 0.583829\n",
      "iteration 93 / 300: loss 0.589662\n",
      "iteration 93 / 300: loss 0.595228\n",
      "iteration 93 / 300: loss 0.598993\n",
      "iteration 93 / 300: loss 0.596178\n",
      "iteration 93 / 300: loss 0.589808\n",
      "iteration 93 / 300: loss 0.591175\n",
      "iteration 93 / 300: loss 0.584891\n",
      "iteration 93 / 300: loss 0.599687\n",
      "iteration 93 / 300: loss 0.598937\n",
      "iteration 93 / 300: loss 0.614315\n",
      "iteration 93 / 300: loss 0.597836\n",
      "iteration 93 / 300: loss 0.599337\n",
      "iteration 93 / 300: loss 0.603363\n",
      "iteration 93 / 300: loss 0.592909\n",
      "iteration 93 / 300: loss 0.592435\n",
      "iteration 93 / 300: loss 0.589082\n",
      "iteration 93 / 300: loss 0.596497\n",
      "iteration 93 / 300: loss 0.605754\n",
      "iteration 93 / 300: loss 0.610600\n",
      "iteration 93 / 300: loss 0.587820\n",
      "iteration 93 / 300: loss 0.599381\n",
      "iteration 93 / 300: loss 0.602831\n",
      "iteration 93 / 300: loss 0.605071\n",
      "iteration 93 / 300: loss 0.603897\n",
      "iteration 93 / 300: loss 0.624180\n",
      "iteration 93 / 300: loss 0.587252\n",
      "iteration 93 / 300: loss 0.580794\n",
      "iteration 93 / 300: loss 0.625092\n",
      "iteration 93 / 300: loss 0.603354\n",
      "iteration 93 / 300: loss 0.604366\n",
      "iteration 93 / 300: loss 0.595525\n",
      "iteration 93 / 300: loss 0.597590\n",
      "iteration 93 / 300: loss 0.592786\n",
      "iteration 93 / 300: loss 0.589536\n",
      "iteration 93 / 300: loss 0.599309\n",
      "iteration 93 / 300: loss 0.611418\n",
      "iteration 93 / 300: loss 0.592506\n",
      "iteration 93 / 300: loss 0.599469\n",
      "iteration 93 / 300: loss 0.603151\n",
      "iteration 93 / 300: loss 0.602455\n",
      "iteration 93 / 300: loss 0.579851\n",
      "iteration 93 / 300: loss 0.601634\n",
      "iteration 94 / 300: loss 0.585567\n",
      "iteration 94 / 300: loss 0.588465\n",
      "iteration 94 / 300: loss 0.567555\n",
      "iteration 94 / 300: loss 0.592414\n",
      "iteration 94 / 300: loss 0.593655\n",
      "iteration 94 / 300: loss 0.595338\n",
      "iteration 94 / 300: loss 0.608822\n",
      "iteration 94 / 300: loss 0.592772\n",
      "iteration 94 / 300: loss 0.628105\n",
      "iteration 94 / 300: loss 0.580199\n",
      "iteration 94 / 300: loss 0.607967\n",
      "iteration 94 / 300: loss 0.587436\n",
      "iteration 94 / 300: loss 0.591726\n",
      "iteration 94 / 300: loss 0.571408\n",
      "iteration 94 / 300: loss 0.583062\n",
      "iteration 94 / 300: loss 0.608473\n",
      "iteration 94 / 300: loss 0.598400\n",
      "iteration 94 / 300: loss 0.583893\n",
      "iteration 94 / 300: loss 0.615294\n",
      "iteration 94 / 300: loss 0.591690\n",
      "iteration 94 / 300: loss 0.585538\n",
      "iteration 94 / 300: loss 0.591367\n",
      "iteration 94 / 300: loss 0.604383\n",
      "iteration 94 / 300: loss 0.595830\n",
      "iteration 94 / 300: loss 0.614980\n",
      "iteration 94 / 300: loss 0.608422\n",
      "iteration 94 / 300: loss 0.598265\n",
      "iteration 94 / 300: loss 0.588972\n",
      "iteration 94 / 300: loss 0.617799\n",
      "iteration 94 / 300: loss 0.594811\n",
      "iteration 94 / 300: loss 0.601730\n",
      "iteration 94 / 300: loss 0.631080\n",
      "iteration 94 / 300: loss 0.587557\n",
      "iteration 94 / 300: loss 0.606604\n",
      "iteration 94 / 300: loss 0.588078\n",
      "iteration 94 / 300: loss 0.600938\n",
      "iteration 94 / 300: loss 0.595996\n",
      "iteration 94 / 300: loss 0.589341\n",
      "iteration 94 / 300: loss 0.599574\n",
      "iteration 94 / 300: loss 0.604896\n",
      "iteration 94 / 300: loss 0.619458\n",
      "iteration 94 / 300: loss 0.588856\n",
      "iteration 94 / 300: loss 0.593693\n",
      "iteration 94 / 300: loss 0.585644\n",
      "iteration 94 / 300: loss 0.613248\n",
      "iteration 94 / 300: loss 0.587563\n",
      "iteration 94 / 300: loss 0.578373\n",
      "iteration 94 / 300: loss 0.567473\n",
      "iteration 94 / 300: loss 0.562267\n",
      "iteration 94 / 300: loss 0.594223\n",
      "iteration 94 / 300: loss 0.578855\n",
      "iteration 94 / 300: loss 0.586395\n",
      "iteration 94 / 300: loss 0.572928\n",
      "iteration 94 / 300: loss 0.596190\n",
      "iteration 94 / 300: loss 0.607984\n",
      "iteration 94 / 300: loss 0.610868\n",
      "iteration 94 / 300: loss 0.606306\n",
      "iteration 94 / 300: loss 0.583826\n",
      "iteration 94 / 300: loss 0.589659\n",
      "iteration 94 / 300: loss 0.595224\n",
      "iteration 94 / 300: loss 0.598990\n",
      "iteration 94 / 300: loss 0.596174\n",
      "iteration 94 / 300: loss 0.589804\n",
      "iteration 94 / 300: loss 0.591172\n",
      "iteration 94 / 300: loss 0.584888\n",
      "iteration 94 / 300: loss 0.599683\n",
      "iteration 94 / 300: loss 0.598934\n",
      "iteration 94 / 300: loss 0.614312\n",
      "iteration 94 / 300: loss 0.597833\n",
      "iteration 94 / 300: loss 0.599333\n",
      "iteration 94 / 300: loss 0.603359\n",
      "iteration 94 / 300: loss 0.592905\n",
      "iteration 94 / 300: loss 0.592431\n",
      "iteration 94 / 300: loss 0.589078\n",
      "iteration 94 / 300: loss 0.596492\n",
      "iteration 94 / 300: loss 0.605749\n",
      "iteration 94 / 300: loss 0.610597\n",
      "iteration 94 / 300: loss 0.587816\n",
      "iteration 94 / 300: loss 0.599378\n",
      "iteration 94 / 300: loss 0.602827\n",
      "iteration 94 / 300: loss 0.605067\n",
      "iteration 94 / 300: loss 0.603892\n",
      "iteration 94 / 300: loss 0.624176\n",
      "iteration 94 / 300: loss 0.587249\n",
      "iteration 94 / 300: loss 0.580791\n",
      "iteration 94 / 300: loss 0.625088\n",
      "iteration 94 / 300: loss 0.603350\n",
      "iteration 94 / 300: loss 0.604362\n",
      "iteration 94 / 300: loss 0.595520\n",
      "iteration 94 / 300: loss 0.597586\n",
      "iteration 94 / 300: loss 0.592782\n",
      "iteration 94 / 300: loss 0.589532\n",
      "iteration 94 / 300: loss 0.599305\n",
      "iteration 94 / 300: loss 0.611414\n",
      "iteration 94 / 300: loss 0.592502\n",
      "iteration 94 / 300: loss 0.599465\n",
      "iteration 94 / 300: loss 0.603146\n",
      "iteration 94 / 300: loss 0.602451\n",
      "iteration 94 / 300: loss 0.579847\n",
      "iteration 94 / 300: loss 0.601630\n",
      "iteration 95 / 300: loss 0.585564\n",
      "iteration 95 / 300: loss 0.588461\n",
      "iteration 95 / 300: loss 0.567552\n",
      "iteration 95 / 300: loss 0.592411\n",
      "iteration 95 / 300: loss 0.593651\n",
      "iteration 95 / 300: loss 0.595334\n",
      "iteration 95 / 300: loss 0.608818\n",
      "iteration 95 / 300: loss 0.592768\n",
      "iteration 95 / 300: loss 0.628100\n",
      "iteration 95 / 300: loss 0.580195\n",
      "iteration 95 / 300: loss 0.607963\n",
      "iteration 95 / 300: loss 0.587432\n",
      "iteration 95 / 300: loss 0.591722\n",
      "iteration 95 / 300: loss 0.571404\n",
      "iteration 95 / 300: loss 0.583059\n",
      "iteration 95 / 300: loss 0.608470\n",
      "iteration 95 / 300: loss 0.598396\n",
      "iteration 95 / 300: loss 0.583890\n",
      "iteration 95 / 300: loss 0.615290\n",
      "iteration 95 / 300: loss 0.591687\n",
      "iteration 95 / 300: loss 0.585534\n",
      "iteration 95 / 300: loss 0.591363\n",
      "iteration 95 / 300: loss 0.604379\n",
      "iteration 95 / 300: loss 0.595826\n",
      "iteration 95 / 300: loss 0.614977\n",
      "iteration 95 / 300: loss 0.608419\n",
      "iteration 95 / 300: loss 0.598261\n",
      "iteration 95 / 300: loss 0.588969\n",
      "iteration 95 / 300: loss 0.617795\n",
      "iteration 95 / 300: loss 0.594807\n",
      "iteration 95 / 300: loss 0.601725\n",
      "iteration 95 / 300: loss 0.631075\n",
      "iteration 95 / 300: loss 0.587553\n",
      "iteration 95 / 300: loss 0.606600\n",
      "iteration 95 / 300: loss 0.588074\n",
      "iteration 95 / 300: loss 0.600933\n",
      "iteration 95 / 300: loss 0.595993\n",
      "iteration 95 / 300: loss 0.589336\n",
      "iteration 95 / 300: loss 0.599569\n",
      "iteration 95 / 300: loss 0.604892\n",
      "iteration 95 / 300: loss 0.619454\n",
      "iteration 95 / 300: loss 0.588852\n",
      "iteration 95 / 300: loss 0.593689\n",
      "iteration 95 / 300: loss 0.585640\n",
      "iteration 95 / 300: loss 0.613245\n",
      "iteration 95 / 300: loss 0.587559\n",
      "iteration 95 / 300: loss 0.578369\n",
      "iteration 95 / 300: loss 0.567470\n",
      "iteration 95 / 300: loss 0.562264\n",
      "iteration 95 / 300: loss 0.594219\n",
      "iteration 95 / 300: loss 0.578852\n",
      "iteration 95 / 300: loss 0.586392\n",
      "iteration 95 / 300: loss 0.572924\n",
      "iteration 95 / 300: loss 0.596186\n",
      "iteration 95 / 300: loss 0.607981\n",
      "iteration 95 / 300: loss 0.610865\n",
      "iteration 95 / 300: loss 0.606302\n",
      "iteration 95 / 300: loss 0.583822\n",
      "iteration 95 / 300: loss 0.589656\n",
      "iteration 95 / 300: loss 0.595220\n",
      "iteration 95 / 300: loss 0.598986\n",
      "iteration 95 / 300: loss 0.596170\n",
      "iteration 95 / 300: loss 0.589801\n",
      "iteration 95 / 300: loss 0.591168\n",
      "iteration 95 / 300: loss 0.584884\n",
      "iteration 95 / 300: loss 0.599680\n",
      "iteration 95 / 300: loss 0.598931\n",
      "iteration 95 / 300: loss 0.614309\n",
      "iteration 95 / 300: loss 0.597829\n",
      "iteration 95 / 300: loss 0.599330\n",
      "iteration 95 / 300: loss 0.603355\n",
      "iteration 95 / 300: loss 0.592901\n",
      "iteration 95 / 300: loss 0.592427\n",
      "iteration 95 / 300: loss 0.589074\n",
      "iteration 95 / 300: loss 0.596487\n",
      "iteration 95 / 300: loss 0.605746\n",
      "iteration 95 / 300: loss 0.610593\n",
      "iteration 95 / 300: loss 0.587813\n",
      "iteration 95 / 300: loss 0.599376\n",
      "iteration 95 / 300: loss 0.602824\n",
      "iteration 95 / 300: loss 0.605064\n",
      "iteration 95 / 300: loss 0.603888\n",
      "iteration 95 / 300: loss 0.624173\n",
      "iteration 95 / 300: loss 0.587246\n",
      "iteration 95 / 300: loss 0.580787\n",
      "iteration 95 / 300: loss 0.625084\n",
      "iteration 95 / 300: loss 0.603346\n",
      "iteration 95 / 300: loss 0.604358\n",
      "iteration 95 / 300: loss 0.595516\n",
      "iteration 95 / 300: loss 0.597582\n",
      "iteration 95 / 300: loss 0.592778\n",
      "iteration 95 / 300: loss 0.589529\n",
      "iteration 95 / 300: loss 0.599301\n",
      "iteration 95 / 300: loss 0.611411\n",
      "iteration 95 / 300: loss 0.592498\n",
      "iteration 95 / 300: loss 0.599461\n",
      "iteration 95 / 300: loss 0.603142\n",
      "iteration 95 / 300: loss 0.602447\n",
      "iteration 95 / 300: loss 0.579844\n",
      "iteration 95 / 300: loss 0.601627\n",
      "iteration 96 / 300: loss 0.585560\n",
      "iteration 96 / 300: loss 0.588458\n",
      "iteration 96 / 300: loss 0.567548\n",
      "iteration 96 / 300: loss 0.592408\n",
      "iteration 96 / 300: loss 0.593648\n",
      "iteration 96 / 300: loss 0.595330\n",
      "iteration 96 / 300: loss 0.608815\n",
      "iteration 96 / 300: loss 0.592765\n",
      "iteration 96 / 300: loss 0.628097\n",
      "iteration 96 / 300: loss 0.580191\n",
      "iteration 96 / 300: loss 0.607959\n",
      "iteration 96 / 300: loss 0.587428\n",
      "iteration 96 / 300: loss 0.591719\n",
      "iteration 96 / 300: loss 0.571401\n",
      "iteration 96 / 300: loss 0.583056\n",
      "iteration 96 / 300: loss 0.608467\n",
      "iteration 96 / 300: loss 0.598393\n",
      "iteration 96 / 300: loss 0.583887\n",
      "iteration 96 / 300: loss 0.615287\n",
      "iteration 96 / 300: loss 0.591683\n",
      "iteration 96 / 300: loss 0.585531\n",
      "iteration 96 / 300: loss 0.591360\n",
      "iteration 96 / 300: loss 0.604375\n",
      "iteration 96 / 300: loss 0.595822\n",
      "iteration 96 / 300: loss 0.614974\n",
      "iteration 96 / 300: loss 0.608416\n",
      "iteration 96 / 300: loss 0.598258\n",
      "iteration 96 / 300: loss 0.588966\n",
      "iteration 96 / 300: loss 0.617791\n",
      "iteration 96 / 300: loss 0.594803\n",
      "iteration 96 / 300: loss 0.601721\n",
      "iteration 96 / 300: loss 0.631071\n",
      "iteration 96 / 300: loss 0.587549\n",
      "iteration 96 / 300: loss 0.606596\n",
      "iteration 96 / 300: loss 0.588070\n",
      "iteration 96 / 300: loss 0.600929\n",
      "iteration 96 / 300: loss 0.595989\n",
      "iteration 96 / 300: loss 0.589332\n",
      "iteration 96 / 300: loss 0.599565\n",
      "iteration 96 / 300: loss 0.604889\n",
      "iteration 96 / 300: loss 0.619450\n",
      "iteration 96 / 300: loss 0.588848\n",
      "iteration 96 / 300: loss 0.593684\n",
      "iteration 96 / 300: loss 0.585635\n",
      "iteration 96 / 300: loss 0.613242\n",
      "iteration 96 / 300: loss 0.587556\n",
      "iteration 96 / 300: loss 0.578365\n",
      "iteration 96 / 300: loss 0.567466\n",
      "iteration 96 / 300: loss 0.562262\n",
      "iteration 96 / 300: loss 0.594216\n",
      "iteration 96 / 300: loss 0.578849\n",
      "iteration 96 / 300: loss 0.586389\n",
      "iteration 96 / 300: loss 0.572921\n",
      "iteration 96 / 300: loss 0.596183\n",
      "iteration 96 / 300: loss 0.607978\n",
      "iteration 96 / 300: loss 0.610863\n",
      "iteration 96 / 300: loss 0.606299\n",
      "iteration 96 / 300: loss 0.583819\n",
      "iteration 96 / 300: loss 0.589653\n",
      "iteration 96 / 300: loss 0.595216\n",
      "iteration 96 / 300: loss 0.598983\n",
      "iteration 96 / 300: loss 0.596167\n",
      "iteration 96 / 300: loss 0.589798\n",
      "iteration 96 / 300: loss 0.591165\n",
      "iteration 96 / 300: loss 0.584882\n",
      "iteration 96 / 300: loss 0.599676\n",
      "iteration 96 / 300: loss 0.598928\n",
      "iteration 96 / 300: loss 0.614307\n",
      "iteration 96 / 300: loss 0.597826\n",
      "iteration 96 / 300: loss 0.599327\n",
      "iteration 96 / 300: loss 0.603351\n",
      "iteration 96 / 300: loss 0.592898\n",
      "iteration 96 / 300: loss 0.592424\n",
      "iteration 96 / 300: loss 0.589071\n",
      "iteration 96 / 300: loss 0.596483\n",
      "iteration 96 / 300: loss 0.605742\n",
      "iteration 96 / 300: loss 0.610590\n",
      "iteration 96 / 300: loss 0.587810\n",
      "iteration 96 / 300: loss 0.599373\n",
      "iteration 96 / 300: loss 0.602821\n",
      "iteration 96 / 300: loss 0.605060\n",
      "iteration 96 / 300: loss 0.603884\n",
      "iteration 96 / 300: loss 0.624170\n",
      "iteration 96 / 300: loss 0.587243\n",
      "iteration 96 / 300: loss 0.580784\n",
      "iteration 96 / 300: loss 0.625080\n",
      "iteration 96 / 300: loss 0.603343\n",
      "iteration 96 / 300: loss 0.604354\n",
      "iteration 96 / 300: loss 0.595512\n",
      "iteration 96 / 300: loss 0.597578\n",
      "iteration 96 / 300: loss 0.592774\n",
      "iteration 96 / 300: loss 0.589525\n",
      "iteration 96 / 300: loss 0.599297\n",
      "iteration 96 / 300: loss 0.611408\n",
      "iteration 96 / 300: loss 0.592495\n",
      "iteration 96 / 300: loss 0.599458\n",
      "iteration 96 / 300: loss 0.603138\n",
      "iteration 96 / 300: loss 0.602443\n",
      "iteration 96 / 300: loss 0.579841\n",
      "iteration 96 / 300: loss 0.601623\n",
      "iteration 97 / 300: loss 0.585557\n",
      "iteration 97 / 300: loss 0.588455\n",
      "iteration 97 / 300: loss 0.567545\n",
      "iteration 97 / 300: loss 0.592405\n",
      "iteration 97 / 300: loss 0.593645\n",
      "iteration 97 / 300: loss 0.595327\n",
      "iteration 97 / 300: loss 0.608812\n",
      "iteration 97 / 300: loss 0.592762\n",
      "iteration 97 / 300: loss 0.628093\n",
      "iteration 97 / 300: loss 0.580187\n",
      "iteration 97 / 300: loss 0.607956\n",
      "iteration 97 / 300: loss 0.587425\n",
      "iteration 97 / 300: loss 0.591716\n",
      "iteration 97 / 300: loss 0.571398\n",
      "iteration 97 / 300: loss 0.583053\n",
      "iteration 97 / 300: loss 0.608465\n",
      "iteration 97 / 300: loss 0.598389\n",
      "iteration 97 / 300: loss 0.583884\n",
      "iteration 97 / 300: loss 0.615283\n",
      "iteration 97 / 300: loss 0.591680\n",
      "iteration 97 / 300: loss 0.585528\n",
      "iteration 97 / 300: loss 0.591356\n",
      "iteration 97 / 300: loss 0.604372\n",
      "iteration 97 / 300: loss 0.595819\n",
      "iteration 97 / 300: loss 0.614972\n",
      "iteration 97 / 300: loss 0.608414\n",
      "iteration 97 / 300: loss 0.598254\n",
      "iteration 97 / 300: loss 0.588963\n",
      "iteration 97 / 300: loss 0.617788\n",
      "iteration 97 / 300: loss 0.594800\n",
      "iteration 97 / 300: loss 0.601718\n",
      "iteration 97 / 300: loss 0.631067\n",
      "iteration 97 / 300: loss 0.587545\n",
      "iteration 97 / 300: loss 0.606593\n",
      "iteration 97 / 300: loss 0.588066\n",
      "iteration 97 / 300: loss 0.600925\n",
      "iteration 97 / 300: loss 0.595986\n",
      "iteration 97 / 300: loss 0.589328\n",
      "iteration 97 / 300: loss 0.599561\n",
      "iteration 97 / 300: loss 0.604886\n",
      "iteration 97 / 300: loss 0.619447\n",
      "iteration 97 / 300: loss 0.588844\n",
      "iteration 97 / 300: loss 0.593681\n",
      "iteration 97 / 300: loss 0.585631\n",
      "iteration 97 / 300: loss 0.613239\n",
      "iteration 97 / 300: loss 0.587553\n",
      "iteration 97 / 300: loss 0.578362\n",
      "iteration 97 / 300: loss 0.567463\n",
      "iteration 97 / 300: loss 0.562259\n",
      "iteration 97 / 300: loss 0.594213\n",
      "iteration 97 / 300: loss 0.578846\n",
      "iteration 97 / 300: loss 0.586386\n",
      "iteration 97 / 300: loss 0.572918\n",
      "iteration 97 / 300: loss 0.596180\n",
      "iteration 97 / 300: loss 0.607976\n",
      "iteration 97 / 300: loss 0.610860\n",
      "iteration 97 / 300: loss 0.606296\n",
      "iteration 97 / 300: loss 0.583816\n",
      "iteration 97 / 300: loss 0.589651\n",
      "iteration 97 / 300: loss 0.595213\n",
      "iteration 97 / 300: loss 0.598980\n",
      "iteration 97 / 300: loss 0.596163\n",
      "iteration 97 / 300: loss 0.589795\n",
      "iteration 97 / 300: loss 0.591162\n",
      "iteration 97 / 300: loss 0.584879\n",
      "iteration 97 / 300: loss 0.599674\n",
      "iteration 97 / 300: loss 0.598926\n",
      "iteration 97 / 300: loss 0.614304\n",
      "iteration 97 / 300: loss 0.597823\n",
      "iteration 97 / 300: loss 0.599324\n",
      "iteration 97 / 300: loss 0.603348\n",
      "iteration 97 / 300: loss 0.592895\n",
      "iteration 97 / 300: loss 0.592421\n",
      "iteration 97 / 300: loss 0.589068\n",
      "iteration 97 / 300: loss 0.596480\n",
      "iteration 97 / 300: loss 0.605739\n",
      "iteration 97 / 300: loss 0.610588\n",
      "iteration 97 / 300: loss 0.587807\n",
      "iteration 97 / 300: loss 0.599371\n",
      "iteration 97 / 300: loss 0.602818\n",
      "iteration 97 / 300: loss 0.605057\n",
      "iteration 97 / 300: loss 0.603881\n",
      "iteration 97 / 300: loss 0.624168\n",
      "iteration 97 / 300: loss 0.587241\n",
      "iteration 97 / 300: loss 0.580781\n",
      "iteration 97 / 300: loss 0.625077\n",
      "iteration 97 / 300: loss 0.603339\n",
      "iteration 97 / 300: loss 0.604351\n",
      "iteration 97 / 300: loss 0.595509\n",
      "iteration 97 / 300: loss 0.597575\n",
      "iteration 97 / 300: loss 0.592771\n",
      "iteration 97 / 300: loss 0.589522\n",
      "iteration 97 / 300: loss 0.599294\n",
      "iteration 97 / 300: loss 0.611405\n",
      "iteration 97 / 300: loss 0.592492\n",
      "iteration 97 / 300: loss 0.599455\n",
      "iteration 97 / 300: loss 0.603135\n",
      "iteration 97 / 300: loss 0.602440\n",
      "iteration 97 / 300: loss 0.579838\n",
      "iteration 97 / 300: loss 0.601620\n",
      "iteration 98 / 300: loss 0.585554\n",
      "iteration 98 / 300: loss 0.588452\n",
      "iteration 98 / 300: loss 0.567542\n",
      "iteration 98 / 300: loss 0.592403\n",
      "iteration 98 / 300: loss 0.593643\n",
      "iteration 98 / 300: loss 0.595324\n",
      "iteration 98 / 300: loss 0.608809\n",
      "iteration 98 / 300: loss 0.592759\n",
      "iteration 98 / 300: loss 0.628090\n",
      "iteration 98 / 300: loss 0.580184\n",
      "iteration 98 / 300: loss 0.607952\n",
      "iteration 98 / 300: loss 0.587422\n",
      "iteration 98 / 300: loss 0.591713\n",
      "iteration 98 / 300: loss 0.571395\n",
      "iteration 98 / 300: loss 0.583050\n",
      "iteration 98 / 300: loss 0.608462\n",
      "iteration 98 / 300: loss 0.598386\n",
      "iteration 98 / 300: loss 0.583881\n",
      "iteration 98 / 300: loss 0.615280\n",
      "iteration 98 / 300: loss 0.591677\n",
      "iteration 98 / 300: loss 0.585525\n",
      "iteration 98 / 300: loss 0.591353\n",
      "iteration 98 / 300: loss 0.604369\n",
      "iteration 98 / 300: loss 0.595816\n",
      "iteration 98 / 300: loss 0.614970\n",
      "iteration 98 / 300: loss 0.608411\n",
      "iteration 98 / 300: loss 0.598251\n",
      "iteration 98 / 300: loss 0.588960\n",
      "iteration 98 / 300: loss 0.617785\n",
      "iteration 98 / 300: loss 0.594797\n",
      "iteration 98 / 300: loss 0.601715\n",
      "iteration 98 / 300: loss 0.631064\n",
      "iteration 98 / 300: loss 0.587542\n",
      "iteration 98 / 300: loss 0.606590\n",
      "iteration 98 / 300: loss 0.588063\n",
      "iteration 98 / 300: loss 0.600922\n",
      "iteration 98 / 300: loss 0.595984\n",
      "iteration 98 / 300: loss 0.589324\n",
      "iteration 98 / 300: loss 0.599558\n",
      "iteration 98 / 300: loss 0.604883\n",
      "iteration 98 / 300: loss 0.619443\n",
      "iteration 98 / 300: loss 0.588840\n",
      "iteration 98 / 300: loss 0.593677\n",
      "iteration 98 / 300: loss 0.585628\n",
      "iteration 98 / 300: loss 0.613236\n",
      "iteration 98 / 300: loss 0.587550\n",
      "iteration 98 / 300: loss 0.578358\n",
      "iteration 98 / 300: loss 0.567461\n",
      "iteration 98 / 300: loss 0.562257\n",
      "iteration 98 / 300: loss 0.594210\n",
      "iteration 98 / 300: loss 0.578844\n",
      "iteration 98 / 300: loss 0.586384\n",
      "iteration 98 / 300: loss 0.572915\n",
      "iteration 98 / 300: loss 0.596177\n",
      "iteration 98 / 300: loss 0.607973\n",
      "iteration 98 / 300: loss 0.610858\n",
      "iteration 98 / 300: loss 0.606293\n",
      "iteration 98 / 300: loss 0.583814\n",
      "iteration 98 / 300: loss 0.589648\n",
      "iteration 98 / 300: loss 0.595210\n",
      "iteration 98 / 300: loss 0.598978\n",
      "iteration 98 / 300: loss 0.596160\n",
      "iteration 98 / 300: loss 0.589793\n",
      "iteration 98 / 300: loss 0.591160\n",
      "iteration 98 / 300: loss 0.584877\n",
      "iteration 98 / 300: loss 0.599671\n",
      "iteration 98 / 300: loss 0.598924\n",
      "iteration 98 / 300: loss 0.614302\n",
      "iteration 98 / 300: loss 0.597821\n",
      "iteration 98 / 300: loss 0.599322\n",
      "iteration 98 / 300: loss 0.603345\n",
      "iteration 98 / 300: loss 0.592892\n",
      "iteration 98 / 300: loss 0.592418\n",
      "iteration 98 / 300: loss 0.589066\n",
      "iteration 98 / 300: loss 0.596477\n",
      "iteration 98 / 300: loss 0.605736\n",
      "iteration 98 / 300: loss 0.610585\n",
      "iteration 98 / 300: loss 0.587805\n",
      "iteration 98 / 300: loss 0.599369\n",
      "iteration 98 / 300: loss 0.602815\n",
      "iteration 98 / 300: loss 0.605054\n",
      "iteration 98 / 300: loss 0.603878\n",
      "iteration 98 / 300: loss 0.624165\n",
      "iteration 98 / 300: loss 0.587239\n",
      "iteration 98 / 300: loss 0.580779\n",
      "iteration 98 / 300: loss 0.625074\n",
      "iteration 98 / 300: loss 0.603337\n",
      "iteration 98 / 300: loss 0.604348\n",
      "iteration 98 / 300: loss 0.595506\n",
      "iteration 98 / 300: loss 0.597572\n",
      "iteration 98 / 300: loss 0.592768\n",
      "iteration 98 / 300: loss 0.589520\n",
      "iteration 98 / 300: loss 0.599291\n",
      "iteration 98 / 300: loss 0.611403\n",
      "iteration 98 / 300: loss 0.592489\n",
      "iteration 98 / 300: loss 0.599452\n",
      "iteration 98 / 300: loss 0.603131\n",
      "iteration 98 / 300: loss 0.602437\n",
      "iteration 98 / 300: loss 0.579835\n",
      "iteration 98 / 300: loss 0.601618\n",
      "iteration 99 / 300: loss 0.585552\n",
      "iteration 99 / 300: loss 0.588450\n",
      "iteration 99 / 300: loss 0.567540\n",
      "iteration 99 / 300: loss 0.592401\n",
      "iteration 99 / 300: loss 0.593640\n",
      "iteration 99 / 300: loss 0.595321\n",
      "iteration 99 / 300: loss 0.608807\n",
      "iteration 99 / 300: loss 0.592756\n",
      "iteration 99 / 300: loss 0.628087\n",
      "iteration 99 / 300: loss 0.580181\n",
      "iteration 99 / 300: loss 0.607950\n",
      "iteration 99 / 300: loss 0.587420\n",
      "iteration 99 / 300: loss 0.591710\n",
      "iteration 99 / 300: loss 0.571393\n",
      "iteration 99 / 300: loss 0.583048\n",
      "iteration 99 / 300: loss 0.608460\n",
      "iteration 99 / 300: loss 0.598384\n",
      "iteration 99 / 300: loss 0.583879\n",
      "iteration 99 / 300: loss 0.615278\n",
      "iteration 99 / 300: loss 0.591674\n",
      "iteration 99 / 300: loss 0.585523\n",
      "iteration 99 / 300: loss 0.591351\n",
      "iteration 99 / 300: loss 0.604366\n",
      "iteration 99 / 300: loss 0.595813\n",
      "iteration 99 / 300: loss 0.614968\n",
      "iteration 99 / 300: loss 0.608409\n",
      "iteration 99 / 300: loss 0.598248\n",
      "iteration 99 / 300: loss 0.588958\n",
      "iteration 99 / 300: loss 0.617782\n",
      "iteration 99 / 300: loss 0.594794\n",
      "iteration 99 / 300: loss 0.601712\n",
      "iteration 99 / 300: loss 0.631061\n",
      "iteration 99 / 300: loss 0.587539\n",
      "iteration 99 / 300: loss 0.606587\n",
      "iteration 99 / 300: loss 0.588060\n",
      "iteration 99 / 300: loss 0.600919\n",
      "iteration 99 / 300: loss 0.595981\n",
      "iteration 99 / 300: loss 0.589321\n",
      "iteration 99 / 300: loss 0.599555\n",
      "iteration 99 / 300: loss 0.604880\n",
      "iteration 99 / 300: loss 0.619441\n",
      "iteration 99 / 300: loss 0.588837\n",
      "iteration 99 / 300: loss 0.593674\n",
      "iteration 99 / 300: loss 0.585625\n",
      "iteration 99 / 300: loss 0.613234\n",
      "iteration 99 / 300: loss 0.587548\n",
      "iteration 99 / 300: loss 0.578356\n",
      "iteration 99 / 300: loss 0.567458\n",
      "iteration 99 / 300: loss 0.562255\n",
      "iteration 99 / 300: loss 0.594207\n",
      "iteration 99 / 300: loss 0.578842\n",
      "iteration 99 / 300: loss 0.586381\n",
      "iteration 99 / 300: loss 0.572913\n",
      "iteration 99 / 300: loss 0.596175\n",
      "iteration 99 / 300: loss 0.607971\n",
      "iteration 99 / 300: loss 0.610856\n",
      "iteration 99 / 300: loss 0.606290\n",
      "iteration 99 / 300: loss 0.583812\n",
      "iteration 99 / 300: loss 0.589646\n",
      "iteration 99 / 300: loss 0.595208\n",
      "iteration 99 / 300: loss 0.598976\n",
      "iteration 99 / 300: loss 0.596158\n",
      "iteration 99 / 300: loss 0.589790\n",
      "iteration 99 / 300: loss 0.591158\n",
      "iteration 99 / 300: loss 0.584874\n",
      "iteration 99 / 300: loss 0.599669\n",
      "iteration 99 / 300: loss 0.598921\n",
      "iteration 99 / 300: loss 0.614300\n",
      "iteration 99 / 300: loss 0.597818\n",
      "iteration 99 / 300: loss 0.599319\n",
      "iteration 99 / 300: loss 0.603342\n",
      "iteration 99 / 300: loss 0.592890\n",
      "iteration 99 / 300: loss 0.592415\n",
      "iteration 99 / 300: loss 0.589063\n",
      "iteration 99 / 300: loss 0.596474\n",
      "iteration 99 / 300: loss 0.605734\n",
      "iteration 99 / 300: loss 0.610583\n",
      "iteration 99 / 300: loss 0.587803\n",
      "iteration 99 / 300: loss 0.599368\n",
      "iteration 99 / 300: loss 0.602813\n",
      "iteration 99 / 300: loss 0.605052\n",
      "iteration 99 / 300: loss 0.603875\n",
      "iteration 99 / 300: loss 0.624163\n",
      "iteration 99 / 300: loss 0.587237\n",
      "iteration 99 / 300: loss 0.580776\n",
      "iteration 99 / 300: loss 0.625071\n",
      "iteration 99 / 300: loss 0.603334\n",
      "iteration 99 / 300: loss 0.604346\n",
      "iteration 99 / 300: loss 0.595503\n",
      "iteration 99 / 300: loss 0.597569\n",
      "iteration 99 / 300: loss 0.592765\n",
      "iteration 99 / 300: loss 0.589517\n",
      "iteration 99 / 300: loss 0.599289\n",
      "iteration 99 / 300: loss 0.611400\n",
      "iteration 99 / 300: loss 0.592486\n",
      "iteration 99 / 300: loss 0.599449\n",
      "iteration 99 / 300: loss 0.603128\n",
      "iteration 99 / 300: loss 0.602435\n",
      "iteration 99 / 300: loss 0.579833\n",
      "iteration 99 / 300: loss 0.601615\n",
      "iteration 100 / 300: loss 0.585549\n",
      "iteration 100 / 300: loss 0.588448\n",
      "iteration 100 / 300: loss 0.567538\n",
      "iteration 100 / 300: loss 0.592399\n",
      "iteration 100 / 300: loss 0.593638\n",
      "iteration 100 / 300: loss 0.595319\n",
      "iteration 100 / 300: loss 0.608805\n",
      "iteration 100 / 300: loss 0.592754\n",
      "iteration 100 / 300: loss 0.628085\n",
      "iteration 100 / 300: loss 0.580178\n",
      "iteration 100 / 300: loss 0.607947\n",
      "iteration 100 / 300: loss 0.587417\n",
      "iteration 100 / 300: loss 0.591708\n",
      "iteration 100 / 300: loss 0.571391\n",
      "iteration 100 / 300: loss 0.583045\n",
      "iteration 100 / 300: loss 0.608459\n",
      "iteration 100 / 300: loss 0.598381\n",
      "iteration 100 / 300: loss 0.583877\n",
      "iteration 100 / 300: loss 0.615275\n",
      "iteration 100 / 300: loss 0.591672\n",
      "iteration 100 / 300: loss 0.585520\n",
      "iteration 100 / 300: loss 0.591348\n",
      "iteration 100 / 300: loss 0.604364\n",
      "iteration 100 / 300: loss 0.595810\n",
      "iteration 100 / 300: loss 0.614966\n",
      "iteration 100 / 300: loss 0.608407\n",
      "iteration 100 / 300: loss 0.598246\n",
      "iteration 100 / 300: loss 0.588956\n",
      "iteration 100 / 300: loss 0.617780\n",
      "iteration 100 / 300: loss 0.594792\n",
      "iteration 100 / 300: loss 0.601709\n",
      "iteration 100 / 300: loss 0.631058\n",
      "iteration 100 / 300: loss 0.587537\n",
      "iteration 100 / 300: loss 0.606585\n",
      "iteration 100 / 300: loss 0.588058\n",
      "iteration 100 / 300: loss 0.600916\n",
      "iteration 100 / 300: loss 0.595979\n",
      "iteration 100 / 300: loss 0.589318\n",
      "iteration 100 / 300: loss 0.599552\n",
      "iteration 100 / 300: loss 0.604878\n",
      "iteration 100 / 300: loss 0.619438\n",
      "iteration 100 / 300: loss 0.588835\n",
      "iteration 100 / 300: loss 0.593671\n",
      "iteration 100 / 300: loss 0.585622\n",
      "iteration 100 / 300: loss 0.613232\n",
      "iteration 100 / 300: loss 0.587545\n",
      "iteration 100 / 300: loss 0.578353\n",
      "iteration 100 / 300: loss 0.567456\n",
      "iteration 100 / 300: loss 0.562253\n",
      "iteration 100 / 300: loss 0.594205\n",
      "iteration 100 / 300: loss 0.578840\n",
      "iteration 100 / 300: loss 0.586379\n",
      "iteration 100 / 300: loss 0.572911\n",
      "iteration 100 / 300: loss 0.596173\n",
      "iteration 100 / 300: loss 0.607969\n",
      "iteration 100 / 300: loss 0.610855\n",
      "iteration 100 / 300: loss 0.606288\n",
      "iteration 100 / 300: loss 0.583810\n",
      "iteration 100 / 300: loss 0.589644\n",
      "iteration 100 / 300: loss 0.595206\n",
      "iteration 100 / 300: loss 0.598974\n",
      "iteration 100 / 300: loss 0.596155\n",
      "iteration 100 / 300: loss 0.589788\n",
      "iteration 100 / 300: loss 0.591155\n",
      "iteration 100 / 300: loss 0.584872\n",
      "iteration 100 / 300: loss 0.599667\n",
      "iteration 100 / 300: loss 0.598920\n",
      "iteration 100 / 300: loss 0.614299\n",
      "iteration 100 / 300: loss 0.597816\n",
      "iteration 100 / 300: loss 0.599317\n",
      "iteration 100 / 300: loss 0.603340\n",
      "iteration 100 / 300: loss 0.592887\n",
      "iteration 100 / 300: loss 0.592413\n",
      "iteration 100 / 300: loss 0.589061\n",
      "iteration 100 / 300: loss 0.596471\n",
      "iteration 100 / 300: loss 0.605731\n",
      "iteration 100 / 300: loss 0.610581\n",
      "iteration 100 / 300: loss 0.587801\n",
      "iteration 100 / 300: loss 0.599366\n",
      "iteration 100 / 300: loss 0.602811\n",
      "iteration 100 / 300: loss 0.605050\n",
      "iteration 100 / 300: loss 0.603872\n",
      "iteration 100 / 300: loss 0.624162\n",
      "iteration 100 / 300: loss 0.587235\n",
      "iteration 100 / 300: loss 0.580774\n",
      "iteration 100 / 300: loss 0.625069\n",
      "iteration 100 / 300: loss 0.603332\n",
      "iteration 100 / 300: loss 0.604343\n",
      "iteration 100 / 300: loss 0.595500\n",
      "iteration 100 / 300: loss 0.597566\n",
      "iteration 100 / 300: loss 0.592763\n",
      "iteration 100 / 300: loss 0.589515\n",
      "iteration 100 / 300: loss 0.599286\n",
      "iteration 100 / 300: loss 0.611398\n",
      "iteration 100 / 300: loss 0.592484\n",
      "iteration 100 / 300: loss 0.599447\n",
      "iteration 100 / 300: loss 0.603126\n",
      "iteration 100 / 300: loss 0.602432\n",
      "iteration 100 / 300: loss 0.579831\n",
      "iteration 100 / 300: loss 0.601613\n",
      "iteration 101 / 300: loss 0.585547\n",
      "iteration 101 / 300: loss 0.588446\n",
      "iteration 101 / 300: loss 0.567536\n",
      "iteration 101 / 300: loss 0.592397\n",
      "iteration 101 / 300: loss 0.593636\n",
      "iteration 101 / 300: loss 0.595317\n",
      "iteration 101 / 300: loss 0.608803\n",
      "iteration 101 / 300: loss 0.592752\n",
      "iteration 101 / 300: loss 0.628082\n",
      "iteration 101 / 300: loss 0.580175\n",
      "iteration 101 / 300: loss 0.607945\n",
      "iteration 101 / 300: loss 0.587415\n",
      "iteration 101 / 300: loss 0.591706\n",
      "iteration 101 / 300: loss 0.571389\n",
      "iteration 101 / 300: loss 0.583043\n",
      "iteration 101 / 300: loss 0.608457\n",
      "iteration 101 / 300: loss 0.598379\n",
      "iteration 101 / 300: loss 0.583875\n",
      "iteration 101 / 300: loss 0.615273\n",
      "iteration 101 / 300: loss 0.591670\n",
      "iteration 101 / 300: loss 0.585518\n",
      "iteration 101 / 300: loss 0.591346\n",
      "iteration 101 / 300: loss 0.604362\n",
      "iteration 101 / 300: loss 0.595808\n",
      "iteration 101 / 300: loss 0.614964\n",
      "iteration 101 / 300: loss 0.608405\n",
      "iteration 101 / 300: loss 0.598244\n",
      "iteration 101 / 300: loss 0.588954\n",
      "iteration 101 / 300: loss 0.617778\n",
      "iteration 101 / 300: loss 0.594790\n",
      "iteration 101 / 300: loss 0.601707\n",
      "iteration 101 / 300: loss 0.631055\n",
      "iteration 101 / 300: loss 0.587534\n",
      "iteration 101 / 300: loss 0.606582\n",
      "iteration 101 / 300: loss 0.588056\n",
      "iteration 101 / 300: loss 0.600914\n",
      "iteration 101 / 300: loss 0.595977\n",
      "iteration 101 / 300: loss 0.589316\n",
      "iteration 101 / 300: loss 0.599550\n",
      "iteration 101 / 300: loss 0.604876\n",
      "iteration 101 / 300: loss 0.619436\n",
      "iteration 101 / 300: loss 0.588832\n",
      "iteration 101 / 300: loss 0.593669\n",
      "iteration 101 / 300: loss 0.585619\n",
      "iteration 101 / 300: loss 0.613230\n",
      "iteration 101 / 300: loss 0.587543\n",
      "iteration 101 / 300: loss 0.578351\n",
      "iteration 101 / 300: loss 0.567454\n",
      "iteration 101 / 300: loss 0.562251\n",
      "iteration 101 / 300: loss 0.594203\n",
      "iteration 101 / 300: loss 0.578838\n",
      "iteration 101 / 300: loss 0.586378\n",
      "iteration 101 / 300: loss 0.572909\n",
      "iteration 101 / 300: loss 0.596171\n",
      "iteration 101 / 300: loss 0.607967\n",
      "iteration 101 / 300: loss 0.610853\n",
      "iteration 101 / 300: loss 0.606286\n",
      "iteration 101 / 300: loss 0.583808\n",
      "iteration 101 / 300: loss 0.589643\n",
      "iteration 101 / 300: loss 0.595203\n",
      "iteration 101 / 300: loss 0.598972\n",
      "iteration 101 / 300: loss 0.596153\n",
      "iteration 101 / 300: loss 0.589787\n",
      "iteration 101 / 300: loss 0.591154\n",
      "iteration 101 / 300: loss 0.584871\n",
      "iteration 101 / 300: loss 0.599665\n",
      "iteration 101 / 300: loss 0.598918\n",
      "iteration 101 / 300: loss 0.614297\n",
      "iteration 101 / 300: loss 0.597814\n",
      "iteration 101 / 300: loss 0.599316\n",
      "iteration 101 / 300: loss 0.603338\n",
      "iteration 101 / 300: loss 0.592885\n",
      "iteration 101 / 300: loss 0.592411\n",
      "iteration 101 / 300: loss 0.589059\n",
      "iteration 101 / 300: loss 0.596469\n",
      "iteration 101 / 300: loss 0.605729\n",
      "iteration 101 / 300: loss 0.610579\n",
      "iteration 101 / 300: loss 0.587799\n",
      "iteration 101 / 300: loss 0.599365\n",
      "iteration 101 / 300: loss 0.602809\n",
      "iteration 101 / 300: loss 0.605048\n",
      "iteration 101 / 300: loss 0.603870\n",
      "iteration 101 / 300: loss 0.624160\n",
      "iteration 101 / 300: loss 0.587234\n",
      "iteration 101 / 300: loss 0.580772\n",
      "iteration 101 / 300: loss 0.625066\n",
      "iteration 101 / 300: loss 0.603330\n",
      "iteration 101 / 300: loss 0.604341\n",
      "iteration 101 / 300: loss 0.595498\n",
      "iteration 101 / 300: loss 0.597564\n",
      "iteration 101 / 300: loss 0.592761\n",
      "iteration 101 / 300: loss 0.589513\n",
      "iteration 101 / 300: loss 0.599284\n",
      "iteration 101 / 300: loss 0.611397\n",
      "iteration 101 / 300: loss 0.592482\n",
      "iteration 101 / 300: loss 0.599445\n",
      "iteration 101 / 300: loss 0.603123\n",
      "iteration 101 / 300: loss 0.602430\n",
      "iteration 101 / 300: loss 0.579829\n",
      "iteration 101 / 300: loss 0.601611\n",
      "iteration 102 / 300: loss 0.585546\n",
      "iteration 102 / 300: loss 0.588444\n",
      "iteration 102 / 300: loss 0.567534\n",
      "iteration 102 / 300: loss 0.592395\n",
      "iteration 102 / 300: loss 0.593635\n",
      "iteration 102 / 300: loss 0.595314\n",
      "iteration 102 / 300: loss 0.608801\n",
      "iteration 102 / 300: loss 0.592750\n",
      "iteration 102 / 300: loss 0.628080\n",
      "iteration 102 / 300: loss 0.580173\n",
      "iteration 102 / 300: loss 0.607943\n",
      "iteration 102 / 300: loss 0.587413\n",
      "iteration 102 / 300: loss 0.591704\n",
      "iteration 102 / 300: loss 0.571387\n",
      "iteration 102 / 300: loss 0.583042\n",
      "iteration 102 / 300: loss 0.608455\n",
      "iteration 102 / 300: loss 0.598377\n",
      "iteration 102 / 300: loss 0.583874\n",
      "iteration 102 / 300: loss 0.615271\n",
      "iteration 102 / 300: loss 0.591668\n",
      "iteration 102 / 300: loss 0.585517\n",
      "iteration 102 / 300: loss 0.591344\n",
      "iteration 102 / 300: loss 0.604360\n",
      "iteration 102 / 300: loss 0.595806\n",
      "iteration 102 / 300: loss 0.614963\n",
      "iteration 102 / 300: loss 0.608404\n",
      "iteration 102 / 300: loss 0.598242\n",
      "iteration 102 / 300: loss 0.588952\n",
      "iteration 102 / 300: loss 0.617776\n",
      "iteration 102 / 300: loss 0.594788\n",
      "iteration 102 / 300: loss 0.601705\n",
      "iteration 102 / 300: loss 0.631053\n",
      "iteration 102 / 300: loss 0.587532\n",
      "iteration 102 / 300: loss 0.606580\n",
      "iteration 102 / 300: loss 0.588054\n",
      "iteration 102 / 300: loss 0.600911\n",
      "iteration 102 / 300: loss 0.595975\n",
      "iteration 102 / 300: loss 0.589313\n",
      "iteration 102 / 300: loss 0.599547\n",
      "iteration 102 / 300: loss 0.604874\n",
      "iteration 102 / 300: loss 0.619434\n",
      "iteration 102 / 300: loss 0.588830\n",
      "iteration 102 / 300: loss 0.593666\n",
      "iteration 102 / 300: loss 0.585617\n",
      "iteration 102 / 300: loss 0.613229\n",
      "iteration 102 / 300: loss 0.587541\n",
      "iteration 102 / 300: loss 0.578348\n",
      "iteration 102 / 300: loss 0.567452\n",
      "iteration 102 / 300: loss 0.562250\n",
      "iteration 102 / 300: loss 0.594201\n",
      "iteration 102 / 300: loss 0.578836\n",
      "iteration 102 / 300: loss 0.586376\n",
      "iteration 102 / 300: loss 0.572907\n",
      "iteration 102 / 300: loss 0.596169\n",
      "iteration 102 / 300: loss 0.607966\n",
      "iteration 102 / 300: loss 0.610852\n",
      "iteration 102 / 300: loss 0.606284\n",
      "iteration 102 / 300: loss 0.583806\n",
      "iteration 102 / 300: loss 0.589641\n",
      "iteration 102 / 300: loss 0.595202\n",
      "iteration 102 / 300: loss 0.598970\n",
      "iteration 102 / 300: loss 0.596151\n",
      "iteration 102 / 300: loss 0.589785\n",
      "iteration 102 / 300: loss 0.591152\n",
      "iteration 102 / 300: loss 0.584869\n",
      "iteration 102 / 300: loss 0.599663\n",
      "iteration 102 / 300: loss 0.598916\n",
      "iteration 102 / 300: loss 0.614296\n",
      "iteration 102 / 300: loss 0.597813\n",
      "iteration 102 / 300: loss 0.599314\n",
      "iteration 102 / 300: loss 0.603336\n",
      "iteration 102 / 300: loss 0.592883\n",
      "iteration 102 / 300: loss 0.592409\n",
      "iteration 102 / 300: loss 0.589058\n",
      "iteration 102 / 300: loss 0.596466\n",
      "iteration 102 / 300: loss 0.605727\n",
      "iteration 102 / 300: loss 0.610578\n",
      "iteration 102 / 300: loss 0.587797\n",
      "iteration 102 / 300: loss 0.599363\n",
      "iteration 102 / 300: loss 0.602808\n",
      "iteration 102 / 300: loss 0.605046\n",
      "iteration 102 / 300: loss 0.603868\n",
      "iteration 102 / 300: loss 0.624158\n",
      "iteration 102 / 300: loss 0.587232\n",
      "iteration 102 / 300: loss 0.580771\n",
      "iteration 102 / 300: loss 0.625064\n",
      "iteration 102 / 300: loss 0.603328\n",
      "iteration 102 / 300: loss 0.604339\n",
      "iteration 102 / 300: loss 0.595496\n",
      "iteration 102 / 300: loss 0.597562\n",
      "iteration 102 / 300: loss 0.592759\n",
      "iteration 102 / 300: loss 0.589511\n",
      "iteration 102 / 300: loss 0.599282\n",
      "iteration 102 / 300: loss 0.611395\n",
      "iteration 102 / 300: loss 0.592480\n",
      "iteration 102 / 300: loss 0.599443\n",
      "iteration 102 / 300: loss 0.603121\n",
      "iteration 102 / 300: loss 0.602428\n",
      "iteration 102 / 300: loss 0.579828\n",
      "iteration 102 / 300: loss 0.601609\n",
      "iteration 103 / 300: loss 0.585544\n",
      "iteration 103 / 300: loss 0.588443\n",
      "iteration 103 / 300: loss 0.567532\n",
      "iteration 103 / 300: loss 0.592394\n",
      "iteration 103 / 300: loss 0.593633\n",
      "iteration 103 / 300: loss 0.595313\n",
      "iteration 103 / 300: loss 0.608799\n",
      "iteration 103 / 300: loss 0.592748\n",
      "iteration 103 / 300: loss 0.628078\n",
      "iteration 103 / 300: loss 0.580171\n",
      "iteration 103 / 300: loss 0.607941\n",
      "iteration 103 / 300: loss 0.587411\n",
      "iteration 103 / 300: loss 0.591702\n",
      "iteration 103 / 300: loss 0.571385\n",
      "iteration 103 / 300: loss 0.583040\n",
      "iteration 103 / 300: loss 0.608454\n",
      "iteration 103 / 300: loss 0.598376\n",
      "iteration 103 / 300: loss 0.583872\n",
      "iteration 103 / 300: loss 0.615269\n",
      "iteration 103 / 300: loss 0.591666\n",
      "iteration 103 / 300: loss 0.585515\n",
      "iteration 103 / 300: loss 0.591342\n",
      "iteration 103 / 300: loss 0.604358\n",
      "iteration 103 / 300: loss 0.595804\n",
      "iteration 103 / 300: loss 0.614962\n",
      "iteration 103 / 300: loss 0.608402\n",
      "iteration 103 / 300: loss 0.598240\n",
      "iteration 103 / 300: loss 0.588951\n",
      "iteration 103 / 300: loss 0.617774\n",
      "iteration 103 / 300: loss 0.594786\n",
      "iteration 103 / 300: loss 0.601703\n",
      "iteration 103 / 300: loss 0.631051\n",
      "iteration 103 / 300: loss 0.587531\n",
      "iteration 103 / 300: loss 0.606579\n",
      "iteration 103 / 300: loss 0.588052\n",
      "iteration 103 / 300: loss 0.600909\n",
      "iteration 103 / 300: loss 0.595973\n",
      "iteration 103 / 300: loss 0.589311\n",
      "iteration 103 / 300: loss 0.599545\n",
      "iteration 103 / 300: loss 0.604872\n",
      "iteration 103 / 300: loss 0.619432\n",
      "iteration 103 / 300: loss 0.588828\n",
      "iteration 103 / 300: loss 0.593664\n",
      "iteration 103 / 300: loss 0.585615\n",
      "iteration 103 / 300: loss 0.613227\n",
      "iteration 103 / 300: loss 0.587539\n",
      "iteration 103 / 300: loss 0.578347\n",
      "iteration 103 / 300: loss 0.567450\n",
      "iteration 103 / 300: loss 0.562248\n",
      "iteration 103 / 300: loss 0.594199\n",
      "iteration 103 / 300: loss 0.578835\n",
      "iteration 103 / 300: loss 0.586374\n",
      "iteration 103 / 300: loss 0.572905\n",
      "iteration 103 / 300: loss 0.596167\n",
      "iteration 103 / 300: loss 0.607964\n",
      "iteration 103 / 300: loss 0.610851\n",
      "iteration 103 / 300: loss 0.606282\n",
      "iteration 103 / 300: loss 0.583805\n",
      "iteration 103 / 300: loss 0.589640\n",
      "iteration 103 / 300: loss 0.595200\n",
      "iteration 103 / 300: loss 0.598969\n",
      "iteration 103 / 300: loss 0.596150\n",
      "iteration 103 / 300: loss 0.589783\n",
      "iteration 103 / 300: loss 0.591150\n",
      "iteration 103 / 300: loss 0.584868\n",
      "iteration 103 / 300: loss 0.599661\n",
      "iteration 103 / 300: loss 0.598915\n",
      "iteration 103 / 300: loss 0.614294\n",
      "iteration 103 / 300: loss 0.597811\n",
      "iteration 103 / 300: loss 0.599312\n",
      "iteration 103 / 300: loss 0.603334\n",
      "iteration 103 / 300: loss 0.592882\n",
      "iteration 103 / 300: loss 0.592407\n",
      "iteration 103 / 300: loss 0.589056\n",
      "iteration 103 / 300: loss 0.596464\n",
      "iteration 103 / 300: loss 0.605725\n",
      "iteration 103 / 300: loss 0.610576\n",
      "iteration 103 / 300: loss 0.587796\n",
      "iteration 103 / 300: loss 0.599362\n",
      "iteration 103 / 300: loss 0.602806\n",
      "iteration 103 / 300: loss 0.605044\n",
      "iteration 103 / 300: loss 0.603866\n",
      "iteration 103 / 300: loss 0.624157\n",
      "iteration 103 / 300: loss 0.587231\n",
      "iteration 103 / 300: loss 0.580769\n",
      "iteration 103 / 300: loss 0.625063\n",
      "iteration 103 / 300: loss 0.603326\n",
      "iteration 103 / 300: loss 0.604338\n",
      "iteration 103 / 300: loss 0.595494\n",
      "iteration 103 / 300: loss 0.597560\n",
      "iteration 103 / 300: loss 0.592757\n",
      "iteration 103 / 300: loss 0.589509\n",
      "iteration 103 / 300: loss 0.599281\n",
      "iteration 103 / 300: loss 0.611394\n",
      "iteration 103 / 300: loss 0.592479\n",
      "iteration 103 / 300: loss 0.599441\n",
      "iteration 103 / 300: loss 0.603119\n",
      "iteration 103 / 300: loss 0.602427\n",
      "iteration 103 / 300: loss 0.579826\n",
      "iteration 103 / 300: loss 0.601608\n",
      "iteration 104 / 300: loss 0.585542\n",
      "iteration 104 / 300: loss 0.588441\n",
      "iteration 104 / 300: loss 0.567531\n",
      "iteration 104 / 300: loss 0.592392\n",
      "iteration 104 / 300: loss 0.593632\n",
      "iteration 104 / 300: loss 0.595311\n",
      "iteration 104 / 300: loss 0.608798\n",
      "iteration 104 / 300: loss 0.592747\n",
      "iteration 104 / 300: loss 0.628077\n",
      "iteration 104 / 300: loss 0.580169\n",
      "iteration 104 / 300: loss 0.607939\n",
      "iteration 104 / 300: loss 0.587410\n",
      "iteration 104 / 300: loss 0.591701\n",
      "iteration 104 / 300: loss 0.571384\n",
      "iteration 104 / 300: loss 0.583039\n",
      "iteration 104 / 300: loss 0.608453\n",
      "iteration 104 / 300: loss 0.598374\n",
      "iteration 104 / 300: loss 0.583871\n",
      "iteration 104 / 300: loss 0.615268\n",
      "iteration 104 / 300: loss 0.591664\n",
      "iteration 104 / 300: loss 0.585513\n",
      "iteration 104 / 300: loss 0.591340\n",
      "iteration 104 / 300: loss 0.604356\n",
      "iteration 104 / 300: loss 0.595802\n",
      "iteration 104 / 300: loss 0.614961\n",
      "iteration 104 / 300: loss 0.608401\n",
      "iteration 104 / 300: loss 0.598238\n",
      "iteration 104 / 300: loss 0.588949\n",
      "iteration 104 / 300: loss 0.617772\n",
      "iteration 104 / 300: loss 0.594785\n",
      "iteration 104 / 300: loss 0.601701\n",
      "iteration 104 / 300: loss 0.631049\n",
      "iteration 104 / 300: loss 0.587529\n",
      "iteration 104 / 300: loss 0.606577\n",
      "iteration 104 / 300: loss 0.588050\n",
      "iteration 104 / 300: loss 0.600907\n",
      "iteration 104 / 300: loss 0.595972\n",
      "iteration 104 / 300: loss 0.589309\n",
      "iteration 104 / 300: loss 0.599543\n",
      "iteration 104 / 300: loss 0.604870\n",
      "iteration 104 / 300: loss 0.619430\n",
      "iteration 104 / 300: loss 0.588826\n",
      "iteration 104 / 300: loss 0.593662\n",
      "iteration 104 / 300: loss 0.585613\n",
      "iteration 104 / 300: loss 0.613226\n",
      "iteration 104 / 300: loss 0.587538\n",
      "iteration 104 / 300: loss 0.578345\n",
      "iteration 104 / 300: loss 0.567449\n",
      "iteration 104 / 300: loss 0.562247\n",
      "iteration 104 / 300: loss 0.594198\n",
      "iteration 104 / 300: loss 0.578834\n",
      "iteration 104 / 300: loss 0.586373\n",
      "iteration 104 / 300: loss 0.572904\n",
      "iteration 104 / 300: loss 0.596166\n",
      "iteration 104 / 300: loss 0.607963\n",
      "iteration 104 / 300: loss 0.610850\n",
      "iteration 104 / 300: loss 0.606280\n",
      "iteration 104 / 300: loss 0.583803\n",
      "iteration 104 / 300: loss 0.589638\n",
      "iteration 104 / 300: loss 0.595198\n",
      "iteration 104 / 300: loss 0.598967\n",
      "iteration 104 / 300: loss 0.596148\n",
      "iteration 104 / 300: loss 0.589782\n",
      "iteration 104 / 300: loss 0.591149\n",
      "iteration 104 / 300: loss 0.584866\n",
      "iteration 104 / 300: loss 0.599660\n",
      "iteration 104 / 300: loss 0.598914\n",
      "iteration 104 / 300: loss 0.614293\n",
      "iteration 104 / 300: loss 0.597810\n",
      "iteration 104 / 300: loss 0.599311\n",
      "iteration 104 / 300: loss 0.603333\n",
      "iteration 104 / 300: loss 0.592880\n",
      "iteration 104 / 300: loss 0.592406\n",
      "iteration 104 / 300: loss 0.589055\n",
      "iteration 104 / 300: loss 0.596463\n",
      "iteration 104 / 300: loss 0.605724\n",
      "iteration 104 / 300: loss 0.610575\n",
      "iteration 104 / 300: loss 0.587795\n",
      "iteration 104 / 300: loss 0.599361\n",
      "iteration 104 / 300: loss 0.602805\n",
      "iteration 104 / 300: loss 0.605043\n",
      "iteration 104 / 300: loss 0.603864\n",
      "iteration 104 / 300: loss 0.624156\n",
      "iteration 104 / 300: loss 0.587230\n",
      "iteration 104 / 300: loss 0.580768\n",
      "iteration 104 / 300: loss 0.625061\n",
      "iteration 104 / 300: loss 0.603325\n",
      "iteration 104 / 300: loss 0.604336\n",
      "iteration 104 / 300: loss 0.595492\n",
      "iteration 104 / 300: loss 0.597559\n",
      "iteration 104 / 300: loss 0.592755\n",
      "iteration 104 / 300: loss 0.589508\n",
      "iteration 104 / 300: loss 0.599279\n",
      "iteration 104 / 300: loss 0.611392\n",
      "iteration 104 / 300: loss 0.592477\n",
      "iteration 104 / 300: loss 0.599439\n",
      "iteration 104 / 300: loss 0.603117\n",
      "iteration 104 / 300: loss 0.602425\n",
      "iteration 104 / 300: loss 0.579825\n",
      "iteration 104 / 300: loss 0.601606\n",
      "iteration 105 / 300: loss 0.585541\n",
      "iteration 105 / 300: loss 0.588440\n",
      "iteration 105 / 300: loss 0.567529\n",
      "iteration 105 / 300: loss 0.592391\n",
      "iteration 105 / 300: loss 0.593630\n",
      "iteration 105 / 300: loss 0.595309\n",
      "iteration 105 / 300: loss 0.608796\n",
      "iteration 105 / 300: loss 0.592745\n",
      "iteration 105 / 300: loss 0.628075\n",
      "iteration 105 / 300: loss 0.580168\n",
      "iteration 105 / 300: loss 0.607938\n",
      "iteration 105 / 300: loss 0.587408\n",
      "iteration 105 / 300: loss 0.591699\n",
      "iteration 105 / 300: loss 0.571382\n",
      "iteration 105 / 300: loss 0.583037\n",
      "iteration 105 / 300: loss 0.608452\n",
      "iteration 105 / 300: loss 0.598373\n",
      "iteration 105 / 300: loss 0.583869\n",
      "iteration 105 / 300: loss 0.615266\n",
      "iteration 105 / 300: loss 0.591663\n",
      "iteration 105 / 300: loss 0.585512\n",
      "iteration 105 / 300: loss 0.591339\n",
      "iteration 105 / 300: loss 0.604355\n",
      "iteration 105 / 300: loss 0.595801\n",
      "iteration 105 / 300: loss 0.614959\n",
      "iteration 105 / 300: loss 0.608400\n",
      "iteration 105 / 300: loss 0.598237\n",
      "iteration 105 / 300: loss 0.588948\n",
      "iteration 105 / 300: loss 0.617771\n",
      "iteration 105 / 300: loss 0.594783\n",
      "iteration 105 / 300: loss 0.601699\n",
      "iteration 105 / 300: loss 0.631047\n",
      "iteration 105 / 300: loss 0.587527\n",
      "iteration 105 / 300: loss 0.606575\n",
      "iteration 105 / 300: loss 0.588048\n",
      "iteration 105 / 300: loss 0.600906\n",
      "iteration 105 / 300: loss 0.595971\n",
      "iteration 105 / 300: loss 0.589307\n",
      "iteration 105 / 300: loss 0.599542\n",
      "iteration 105 / 300: loss 0.604869\n",
      "iteration 105 / 300: loss 0.619428\n",
      "iteration 105 / 300: loss 0.588824\n",
      "iteration 105 / 300: loss 0.593661\n",
      "iteration 105 / 300: loss 0.585611\n",
      "iteration 105 / 300: loss 0.613224\n",
      "iteration 105 / 300: loss 0.587537\n",
      "iteration 105 / 300: loss 0.578343\n",
      "iteration 105 / 300: loss 0.567448\n",
      "iteration 105 / 300: loss 0.562246\n",
      "iteration 105 / 300: loss 0.594197\n",
      "iteration 105 / 300: loss 0.578832\n",
      "iteration 105 / 300: loss 0.586372\n",
      "iteration 105 / 300: loss 0.572902\n",
      "iteration 105 / 300: loss 0.596164\n",
      "iteration 105 / 300: loss 0.607962\n",
      "iteration 105 / 300: loss 0.610849\n",
      "iteration 105 / 300: loss 0.606279\n",
      "iteration 105 / 300: loss 0.583802\n",
      "iteration 105 / 300: loss 0.589637\n",
      "iteration 105 / 300: loss 0.595197\n",
      "iteration 105 / 300: loss 0.598966\n",
      "iteration 105 / 300: loss 0.596147\n",
      "iteration 105 / 300: loss 0.589781\n",
      "iteration 105 / 300: loss 0.591148\n",
      "iteration 105 / 300: loss 0.584865\n",
      "iteration 105 / 300: loss 0.599659\n",
      "iteration 105 / 300: loss 0.598913\n",
      "iteration 105 / 300: loss 0.614292\n",
      "iteration 105 / 300: loss 0.597808\n",
      "iteration 105 / 300: loss 0.599310\n",
      "iteration 105 / 300: loss 0.603331\n",
      "iteration 105 / 300: loss 0.592879\n",
      "iteration 105 / 300: loss 0.592404\n",
      "iteration 105 / 300: loss 0.589053\n",
      "iteration 105 / 300: loss 0.596461\n",
      "iteration 105 / 300: loss 0.605722\n",
      "iteration 105 / 300: loss 0.610573\n",
      "iteration 105 / 300: loss 0.587793\n",
      "iteration 105 / 300: loss 0.599360\n",
      "iteration 105 / 300: loss 0.602804\n",
      "iteration 105 / 300: loss 0.605041\n",
      "iteration 105 / 300: loss 0.603862\n",
      "iteration 105 / 300: loss 0.624155\n",
      "iteration 105 / 300: loss 0.587229\n",
      "iteration 105 / 300: loss 0.580766\n",
      "iteration 105 / 300: loss 0.625060\n",
      "iteration 105 / 300: loss 0.603323\n",
      "iteration 105 / 300: loss 0.604335\n",
      "iteration 105 / 300: loss 0.595491\n",
      "iteration 105 / 300: loss 0.597557\n",
      "iteration 105 / 300: loss 0.592754\n",
      "iteration 105 / 300: loss 0.589507\n",
      "iteration 105 / 300: loss 0.599278\n",
      "iteration 105 / 300: loss 0.611391\n",
      "iteration 105 / 300: loss 0.592476\n",
      "iteration 105 / 300: loss 0.599438\n",
      "iteration 105 / 300: loss 0.603116\n",
      "iteration 105 / 300: loss 0.602424\n",
      "iteration 105 / 300: loss 0.579823\n",
      "iteration 105 / 300: loss 0.601605\n",
      "iteration 106 / 300: loss 0.585540\n",
      "iteration 106 / 300: loss 0.588439\n",
      "iteration 106 / 300: loss 0.567528\n",
      "iteration 106 / 300: loss 0.592390\n",
      "iteration 106 / 300: loss 0.593629\n",
      "iteration 106 / 300: loss 0.595308\n",
      "iteration 106 / 300: loss 0.608795\n",
      "iteration 106 / 300: loss 0.592744\n",
      "iteration 106 / 300: loss 0.628074\n",
      "iteration 106 / 300: loss 0.580166\n",
      "iteration 106 / 300: loss 0.607936\n",
      "iteration 106 / 300: loss 0.587407\n",
      "iteration 106 / 300: loss 0.591698\n",
      "iteration 106 / 300: loss 0.571381\n",
      "iteration 106 / 300: loss 0.583036\n",
      "iteration 106 / 300: loss 0.608451\n",
      "iteration 106 / 300: loss 0.598371\n",
      "iteration 106 / 300: loss 0.583868\n",
      "iteration 106 / 300: loss 0.615265\n",
      "iteration 106 / 300: loss 0.591662\n",
      "iteration 106 / 300: loss 0.585511\n",
      "iteration 106 / 300: loss 0.591338\n",
      "iteration 106 / 300: loss 0.604353\n",
      "iteration 106 / 300: loss 0.595799\n",
      "iteration 106 / 300: loss 0.614958\n",
      "iteration 106 / 300: loss 0.608399\n",
      "iteration 106 / 300: loss 0.598235\n",
      "iteration 106 / 300: loss 0.588947\n",
      "iteration 106 / 300: loss 0.617769\n",
      "iteration 106 / 300: loss 0.594782\n",
      "iteration 106 / 300: loss 0.601698\n",
      "iteration 106 / 300: loss 0.631046\n",
      "iteration 106 / 300: loss 0.587526\n",
      "iteration 106 / 300: loss 0.606574\n",
      "iteration 106 / 300: loss 0.588047\n",
      "iteration 106 / 300: loss 0.600904\n",
      "iteration 106 / 300: loss 0.595969\n",
      "iteration 106 / 300: loss 0.589306\n",
      "iteration 106 / 300: loss 0.599540\n",
      "iteration 106 / 300: loss 0.604868\n",
      "iteration 106 / 300: loss 0.619427\n",
      "iteration 106 / 300: loss 0.588823\n",
      "iteration 106 / 300: loss 0.593659\n",
      "iteration 106 / 300: loss 0.585610\n",
      "iteration 106 / 300: loss 0.613223\n",
      "iteration 106 / 300: loss 0.587535\n",
      "iteration 106 / 300: loss 0.578342\n",
      "iteration 106 / 300: loss 0.567446\n",
      "iteration 106 / 300: loss 0.562245\n",
      "iteration 106 / 300: loss 0.594195\n",
      "iteration 106 / 300: loss 0.578831\n",
      "iteration 106 / 300: loss 0.586371\n",
      "iteration 106 / 300: loss 0.572901\n",
      "iteration 106 / 300: loss 0.596163\n",
      "iteration 106 / 300: loss 0.607961\n",
      "iteration 106 / 300: loss 0.610848\n",
      "iteration 106 / 300: loss 0.606278\n",
      "iteration 106 / 300: loss 0.583801\n",
      "iteration 106 / 300: loss 0.589636\n",
      "iteration 106 / 300: loss 0.595196\n",
      "iteration 106 / 300: loss 0.598965\n",
      "iteration 106 / 300: loss 0.596145\n",
      "iteration 106 / 300: loss 0.589780\n",
      "iteration 106 / 300: loss 0.591147\n",
      "iteration 106 / 300: loss 0.584864\n",
      "iteration 106 / 300: loss 0.599657\n",
      "iteration 106 / 300: loss 0.598912\n",
      "iteration 106 / 300: loss 0.614291\n",
      "iteration 106 / 300: loss 0.597807\n",
      "iteration 106 / 300: loss 0.599309\n",
      "iteration 106 / 300: loss 0.603330\n",
      "iteration 106 / 300: loss 0.592877\n",
      "iteration 106 / 300: loss 0.592403\n",
      "iteration 106 / 300: loss 0.589052\n",
      "iteration 106 / 300: loss 0.596460\n",
      "iteration 106 / 300: loss 0.605721\n",
      "iteration 106 / 300: loss 0.610572\n",
      "iteration 106 / 300: loss 0.587792\n",
      "iteration 106 / 300: loss 0.599359\n",
      "iteration 106 / 300: loss 0.602802\n",
      "iteration 106 / 300: loss 0.605040\n",
      "iteration 106 / 300: loss 0.603861\n",
      "iteration 106 / 300: loss 0.624154\n",
      "iteration 106 / 300: loss 0.587228\n",
      "iteration 106 / 300: loss 0.580765\n",
      "iteration 106 / 300: loss 0.625058\n",
      "iteration 106 / 300: loss 0.603322\n",
      "iteration 106 / 300: loss 0.604334\n",
      "iteration 106 / 300: loss 0.595489\n",
      "iteration 106 / 300: loss 0.597556\n",
      "iteration 106 / 300: loss 0.592753\n",
      "iteration 106 / 300: loss 0.589505\n",
      "iteration 106 / 300: loss 0.599276\n",
      "iteration 106 / 300: loss 0.611390\n",
      "iteration 106 / 300: loss 0.592475\n",
      "iteration 106 / 300: loss 0.599437\n",
      "iteration 106 / 300: loss 0.603114\n",
      "iteration 106 / 300: loss 0.602422\n",
      "iteration 106 / 300: loss 0.579822\n",
      "iteration 106 / 300: loss 0.601604\n",
      "iteration 107 / 300: loss 0.585538\n",
      "iteration 107 / 300: loss 0.588438\n",
      "iteration 107 / 300: loss 0.567527\n",
      "iteration 107 / 300: loss 0.592389\n",
      "iteration 107 / 300: loss 0.593628\n",
      "iteration 107 / 300: loss 0.595307\n",
      "iteration 107 / 300: loss 0.608794\n",
      "iteration 107 / 300: loss 0.592743\n",
      "iteration 107 / 300: loss 0.628072\n",
      "iteration 107 / 300: loss 0.580165\n",
      "iteration 107 / 300: loss 0.607935\n",
      "iteration 107 / 300: loss 0.587406\n",
      "iteration 107 / 300: loss 0.591697\n",
      "iteration 107 / 300: loss 0.571380\n",
      "iteration 107 / 300: loss 0.583035\n",
      "iteration 107 / 300: loss 0.608450\n",
      "iteration 107 / 300: loss 0.598370\n",
      "iteration 107 / 300: loss 0.583867\n",
      "iteration 107 / 300: loss 0.615264\n",
      "iteration 107 / 300: loss 0.591661\n",
      "iteration 107 / 300: loss 0.585510\n",
      "iteration 107 / 300: loss 0.591336\n",
      "iteration 107 / 300: loss 0.604352\n",
      "iteration 107 / 300: loss 0.595798\n",
      "iteration 107 / 300: loss 0.614958\n",
      "iteration 107 / 300: loss 0.608398\n",
      "iteration 107 / 300: loss 0.598234\n",
      "iteration 107 / 300: loss 0.588946\n",
      "iteration 107 / 300: loss 0.617768\n",
      "iteration 107 / 300: loss 0.594781\n",
      "iteration 107 / 300: loss 0.601697\n",
      "iteration 107 / 300: loss 0.631044\n",
      "iteration 107 / 300: loss 0.587525\n",
      "iteration 107 / 300: loss 0.606573\n",
      "iteration 107 / 300: loss 0.588046\n",
      "iteration 107 / 300: loss 0.600903\n",
      "iteration 107 / 300: loss 0.595968\n",
      "iteration 107 / 300: loss 0.589304\n",
      "iteration 107 / 300: loss 0.599539\n",
      "iteration 107 / 300: loss 0.604867\n",
      "iteration 107 / 300: loss 0.619426\n",
      "iteration 107 / 300: loss 0.588821\n",
      "iteration 107 / 300: loss 0.593658\n",
      "iteration 107 / 300: loss 0.585608\n",
      "iteration 107 / 300: loss 0.613222\n",
      "iteration 107 / 300: loss 0.587534\n",
      "iteration 107 / 300: loss 0.578340\n",
      "iteration 107 / 300: loss 0.567445\n",
      "iteration 107 / 300: loss 0.562244\n",
      "iteration 107 / 300: loss 0.594194\n",
      "iteration 107 / 300: loss 0.578830\n",
      "iteration 107 / 300: loss 0.586370\n",
      "iteration 107 / 300: loss 0.572900\n",
      "iteration 107 / 300: loss 0.596162\n",
      "iteration 107 / 300: loss 0.607960\n",
      "iteration 107 / 300: loss 0.610847\n",
      "iteration 107 / 300: loss 0.606277\n",
      "iteration 107 / 300: loss 0.583800\n",
      "iteration 107 / 300: loss 0.589635\n",
      "iteration 107 / 300: loss 0.595195\n",
      "iteration 107 / 300: loss 0.598964\n",
      "iteration 107 / 300: loss 0.596144\n",
      "iteration 107 / 300: loss 0.589779\n",
      "iteration 107 / 300: loss 0.591145\n",
      "iteration 107 / 300: loss 0.584863\n",
      "iteration 107 / 300: loss 0.599656\n",
      "iteration 107 / 300: loss 0.598911\n",
      "iteration 107 / 300: loss 0.614290\n",
      "iteration 107 / 300: loss 0.597806\n",
      "iteration 107 / 300: loss 0.599308\n",
      "iteration 107 / 300: loss 0.603329\n",
      "iteration 107 / 300: loss 0.592876\n",
      "iteration 107 / 300: loss 0.592402\n",
      "iteration 107 / 300: loss 0.589051\n",
      "iteration 107 / 300: loss 0.596458\n",
      "iteration 107 / 300: loss 0.605720\n",
      "iteration 107 / 300: loss 0.610571\n",
      "iteration 107 / 300: loss 0.587791\n",
      "iteration 107 / 300: loss 0.599358\n",
      "iteration 107 / 300: loss 0.602801\n",
      "iteration 107 / 300: loss 0.605039\n",
      "iteration 107 / 300: loss 0.603860\n",
      "iteration 107 / 300: loss 0.624153\n",
      "iteration 107 / 300: loss 0.587227\n",
      "iteration 107 / 300: loss 0.580764\n",
      "iteration 107 / 300: loss 0.625057\n",
      "iteration 107 / 300: loss 0.603321\n",
      "iteration 107 / 300: loss 0.604332\n",
      "iteration 107 / 300: loss 0.595488\n",
      "iteration 107 / 300: loss 0.597555\n",
      "iteration 107 / 300: loss 0.592752\n",
      "iteration 107 / 300: loss 0.589504\n",
      "iteration 107 / 300: loss 0.599275\n",
      "iteration 107 / 300: loss 0.611389\n",
      "iteration 107 / 300: loss 0.592473\n",
      "iteration 107 / 300: loss 0.599436\n",
      "iteration 107 / 300: loss 0.603113\n",
      "iteration 107 / 300: loss 0.602421\n",
      "iteration 107 / 300: loss 0.579821\n",
      "iteration 107 / 300: loss 0.601602\n",
      "iteration 108 / 300: loss 0.585537\n",
      "iteration 108 / 300: loss 0.588437\n",
      "iteration 108 / 300: loss 0.567526\n",
      "iteration 108 / 300: loss 0.592388\n",
      "iteration 108 / 300: loss 0.593627\n",
      "iteration 108 / 300: loss 0.595306\n",
      "iteration 108 / 300: loss 0.608793\n",
      "iteration 108 / 300: loss 0.592742\n",
      "iteration 108 / 300: loss 0.628071\n",
      "iteration 108 / 300: loss 0.580163\n",
      "iteration 108 / 300: loss 0.607934\n",
      "iteration 108 / 300: loss 0.587405\n",
      "iteration 108 / 300: loss 0.591696\n",
      "iteration 108 / 300: loss 0.571379\n",
      "iteration 108 / 300: loss 0.583034\n",
      "iteration 108 / 300: loss 0.608449\n",
      "iteration 108 / 300: loss 0.598369\n",
      "iteration 108 / 300: loss 0.583866\n",
      "iteration 108 / 300: loss 0.615263\n",
      "iteration 108 / 300: loss 0.591659\n",
      "iteration 108 / 300: loss 0.585509\n",
      "iteration 108 / 300: loss 0.591335\n",
      "iteration 108 / 300: loss 0.604351\n",
      "iteration 108 / 300: loss 0.595797\n",
      "iteration 108 / 300: loss 0.614957\n",
      "iteration 108 / 300: loss 0.608397\n",
      "iteration 108 / 300: loss 0.598233\n",
      "iteration 108 / 300: loss 0.588945\n",
      "iteration 108 / 300: loss 0.617767\n",
      "iteration 108 / 300: loss 0.594780\n",
      "iteration 108 / 300: loss 0.601695\n",
      "iteration 108 / 300: loss 0.631043\n",
      "iteration 108 / 300: loss 0.587523\n",
      "iteration 108 / 300: loss 0.606572\n",
      "iteration 108 / 300: loss 0.588045\n",
      "iteration 108 / 300: loss 0.600901\n",
      "iteration 108 / 300: loss 0.595967\n",
      "iteration 108 / 300: loss 0.589303\n",
      "iteration 108 / 300: loss 0.599538\n",
      "iteration 108 / 300: loss 0.604865\n",
      "iteration 108 / 300: loss 0.619425\n",
      "iteration 108 / 300: loss 0.588820\n",
      "iteration 108 / 300: loss 0.593657\n",
      "iteration 108 / 300: loss 0.585607\n",
      "iteration 108 / 300: loss 0.613221\n",
      "iteration 108 / 300: loss 0.587533\n",
      "iteration 108 / 300: loss 0.578339\n",
      "iteration 108 / 300: loss 0.567444\n",
      "iteration 108 / 300: loss 0.562243\n",
      "iteration 108 / 300: loss 0.594193\n",
      "iteration 108 / 300: loss 0.578829\n",
      "iteration 108 / 300: loss 0.586369\n",
      "iteration 108 / 300: loss 0.572899\n",
      "iteration 108 / 300: loss 0.596161\n",
      "iteration 108 / 300: loss 0.607959\n",
      "iteration 108 / 300: loss 0.610846\n",
      "iteration 108 / 300: loss 0.606276\n",
      "iteration 108 / 300: loss 0.583799\n",
      "iteration 108 / 300: loss 0.589635\n",
      "iteration 108 / 300: loss 0.595193\n",
      "iteration 108 / 300: loss 0.598963\n",
      "iteration 108 / 300: loss 0.596143\n",
      "iteration 108 / 300: loss 0.589778\n",
      "iteration 108 / 300: loss 0.591145\n",
      "iteration 108 / 300: loss 0.584862\n",
      "iteration 108 / 300: loss 0.599655\n",
      "iteration 108 / 300: loss 0.598910\n",
      "iteration 108 / 300: loss 0.614290\n",
      "iteration 108 / 300: loss 0.597805\n",
      "iteration 108 / 300: loss 0.599307\n",
      "iteration 108 / 300: loss 0.603327\n",
      "iteration 108 / 300: loss 0.592875\n",
      "iteration 108 / 300: loss 0.592401\n",
      "iteration 108 / 300: loss 0.589050\n",
      "iteration 108 / 300: loss 0.596457\n",
      "iteration 108 / 300: loss 0.605719\n",
      "iteration 108 / 300: loss 0.610570\n",
      "iteration 108 / 300: loss 0.587790\n",
      "iteration 108 / 300: loss 0.599358\n",
      "iteration 108 / 300: loss 0.602800\n",
      "iteration 108 / 300: loss 0.605038\n",
      "iteration 108 / 300: loss 0.603859\n",
      "iteration 108 / 300: loss 0.624152\n",
      "iteration 108 / 300: loss 0.587226\n",
      "iteration 108 / 300: loss 0.580763\n",
      "iteration 108 / 300: loss 0.625056\n",
      "iteration 108 / 300: loss 0.603320\n",
      "iteration 108 / 300: loss 0.604331\n",
      "iteration 108 / 300: loss 0.595487\n",
      "iteration 108 / 300: loss 0.597553\n",
      "iteration 108 / 300: loss 0.592750\n",
      "iteration 108 / 300: loss 0.589503\n",
      "iteration 108 / 300: loss 0.599274\n",
      "iteration 108 / 300: loss 0.611388\n",
      "iteration 108 / 300: loss 0.592472\n",
      "iteration 108 / 300: loss 0.599434\n",
      "iteration 108 / 300: loss 0.603112\n",
      "iteration 108 / 300: loss 0.602420\n",
      "iteration 108 / 300: loss 0.579820\n",
      "iteration 108 / 300: loss 0.601601\n",
      "iteration 109 / 300: loss 0.585537\n",
      "iteration 109 / 300: loss 0.588436\n",
      "iteration 109 / 300: loss 0.567525\n",
      "iteration 109 / 300: loss 0.592387\n",
      "iteration 109 / 300: loss 0.593626\n",
      "iteration 109 / 300: loss 0.595305\n",
      "iteration 109 / 300: loss 0.608792\n",
      "iteration 109 / 300: loss 0.592741\n",
      "iteration 109 / 300: loss 0.628070\n",
      "iteration 109 / 300: loss 0.580162\n",
      "iteration 109 / 300: loss 0.607933\n",
      "iteration 109 / 300: loss 0.587404\n",
      "iteration 109 / 300: loss 0.591695\n",
      "iteration 109 / 300: loss 0.571378\n",
      "iteration 109 / 300: loss 0.583033\n",
      "iteration 109 / 300: loss 0.608448\n",
      "iteration 109 / 300: loss 0.598368\n",
      "iteration 109 / 300: loss 0.583865\n",
      "iteration 109 / 300: loss 0.615262\n",
      "iteration 109 / 300: loss 0.591659\n",
      "iteration 109 / 300: loss 0.585508\n",
      "iteration 109 / 300: loss 0.591334\n",
      "iteration 109 / 300: loss 0.604350\n",
      "iteration 109 / 300: loss 0.595796\n",
      "iteration 109 / 300: loss 0.614956\n",
      "iteration 109 / 300: loss 0.608396\n",
      "iteration 109 / 300: loss 0.598232\n",
      "iteration 109 / 300: loss 0.588944\n",
      "iteration 109 / 300: loss 0.617766\n",
      "iteration 109 / 300: loss 0.594779\n",
      "iteration 109 / 300: loss 0.601694\n",
      "iteration 109 / 300: loss 0.631042\n",
      "iteration 109 / 300: loss 0.587522\n",
      "iteration 109 / 300: loss 0.606571\n",
      "iteration 109 / 300: loss 0.588044\n",
      "iteration 109 / 300: loss 0.600900\n",
      "iteration 109 / 300: loss 0.595966\n",
      "iteration 109 / 300: loss 0.589302\n",
      "iteration 109 / 300: loss 0.599536\n",
      "iteration 109 / 300: loss 0.604864\n",
      "iteration 109 / 300: loss 0.619424\n",
      "iteration 109 / 300: loss 0.588819\n",
      "iteration 109 / 300: loss 0.593655\n",
      "iteration 109 / 300: loss 0.585606\n",
      "iteration 109 / 300: loss 0.613220\n",
      "iteration 109 / 300: loss 0.587532\n",
      "iteration 109 / 300: loss 0.578338\n",
      "iteration 109 / 300: loss 0.567443\n",
      "iteration 109 / 300: loss 0.562242\n",
      "iteration 109 / 300: loss 0.594192\n",
      "iteration 109 / 300: loss 0.578829\n",
      "iteration 109 / 300: loss 0.586368\n",
      "iteration 109 / 300: loss 0.572898\n",
      "iteration 109 / 300: loss 0.596160\n",
      "iteration 109 / 300: loss 0.607958\n",
      "iteration 109 / 300: loss 0.610845\n",
      "iteration 109 / 300: loss 0.606275\n",
      "iteration 109 / 300: loss 0.583798\n",
      "iteration 109 / 300: loss 0.589634\n",
      "iteration 109 / 300: loss 0.595193\n",
      "iteration 109 / 300: loss 0.598962\n",
      "iteration 109 / 300: loss 0.596142\n",
      "iteration 109 / 300: loss 0.589777\n",
      "iteration 109 / 300: loss 0.591144\n",
      "iteration 109 / 300: loss 0.584862\n",
      "iteration 109 / 300: loss 0.599655\n",
      "iteration 109 / 300: loss 0.598909\n",
      "iteration 109 / 300: loss 0.614289\n",
      "iteration 109 / 300: loss 0.597804\n",
      "iteration 109 / 300: loss 0.599306\n",
      "iteration 109 / 300: loss 0.603326\n",
      "iteration 109 / 300: loss 0.592874\n",
      "iteration 109 / 300: loss 0.592400\n",
      "iteration 109 / 300: loss 0.589049\n",
      "iteration 109 / 300: loss 0.596456\n",
      "iteration 109 / 300: loss 0.605718\n",
      "iteration 109 / 300: loss 0.610570\n",
      "iteration 109 / 300: loss 0.587790\n",
      "iteration 109 / 300: loss 0.599357\n",
      "iteration 109 / 300: loss 0.602800\n",
      "iteration 109 / 300: loss 0.605037\n",
      "iteration 109 / 300: loss 0.603858\n",
      "iteration 109 / 300: loss 0.624151\n",
      "iteration 109 / 300: loss 0.587226\n",
      "iteration 109 / 300: loss 0.580762\n",
      "iteration 109 / 300: loss 0.625055\n",
      "iteration 109 / 300: loss 0.603319\n",
      "iteration 109 / 300: loss 0.604330\n",
      "iteration 109 / 300: loss 0.595486\n",
      "iteration 109 / 300: loss 0.597552\n",
      "iteration 109 / 300: loss 0.592749\n",
      "iteration 109 / 300: loss 0.589502\n",
      "iteration 109 / 300: loss 0.599273\n",
      "iteration 109 / 300: loss 0.611387\n",
      "iteration 109 / 300: loss 0.592472\n",
      "iteration 109 / 300: loss 0.599434\n",
      "iteration 109 / 300: loss 0.603111\n",
      "iteration 109 / 300: loss 0.602419\n",
      "iteration 109 / 300: loss 0.579819\n",
      "iteration 109 / 300: loss 0.601601\n",
      "iteration 110 / 300: loss 0.585536\n",
      "iteration 110 / 300: loss 0.588435\n",
      "iteration 110 / 300: loss 0.567524\n",
      "iteration 110 / 300: loss 0.592387\n",
      "iteration 110 / 300: loss 0.593626\n",
      "iteration 110 / 300: loss 0.595304\n",
      "iteration 110 / 300: loss 0.608791\n",
      "iteration 110 / 300: loss 0.592740\n",
      "iteration 110 / 300: loss 0.628069\n",
      "iteration 110 / 300: loss 0.580161\n",
      "iteration 110 / 300: loss 0.607932\n",
      "iteration 110 / 300: loss 0.587403\n",
      "iteration 110 / 300: loss 0.591694\n",
      "iteration 110 / 300: loss 0.571377\n",
      "iteration 110 / 300: loss 0.583032\n",
      "iteration 110 / 300: loss 0.608447\n",
      "iteration 110 / 300: loss 0.598367\n",
      "iteration 110 / 300: loss 0.583865\n",
      "iteration 110 / 300: loss 0.615261\n",
      "iteration 110 / 300: loss 0.591658\n",
      "iteration 110 / 300: loss 0.585507\n",
      "iteration 110 / 300: loss 0.591333\n",
      "iteration 110 / 300: loss 0.604349\n",
      "iteration 110 / 300: loss 0.595795\n",
      "iteration 110 / 300: loss 0.614955\n",
      "iteration 110 / 300: loss 0.608396\n",
      "iteration 110 / 300: loss 0.598231\n",
      "iteration 110 / 300: loss 0.588943\n",
      "iteration 110 / 300: loss 0.617765\n",
      "iteration 110 / 300: loss 0.594778\n",
      "iteration 110 / 300: loss 0.601693\n",
      "iteration 110 / 300: loss 0.631041\n",
      "iteration 110 / 300: loss 0.587521\n",
      "iteration 110 / 300: loss 0.606570\n",
      "iteration 110 / 300: loss 0.588043\n",
      "iteration 110 / 300: loss 0.600899\n",
      "iteration 110 / 300: loss 0.595966\n",
      "iteration 110 / 300: loss 0.589301\n",
      "iteration 110 / 300: loss 0.599535\n",
      "iteration 110 / 300: loss 0.604864\n",
      "iteration 110 / 300: loss 0.619423\n",
      "iteration 110 / 300: loss 0.588818\n",
      "iteration 110 / 300: loss 0.593654\n",
      "iteration 110 / 300: loss 0.585605\n",
      "iteration 110 / 300: loss 0.613220\n",
      "iteration 110 / 300: loss 0.587531\n",
      "iteration 110 / 300: loss 0.578337\n",
      "iteration 110 / 300: loss 0.567442\n",
      "iteration 110 / 300: loss 0.562242\n",
      "iteration 110 / 300: loss 0.594191\n",
      "iteration 110 / 300: loss 0.578828\n",
      "iteration 110 / 300: loss 0.586367\n",
      "iteration 110 / 300: loss 0.572898\n",
      "iteration 110 / 300: loss 0.596159\n",
      "iteration 110 / 300: loss 0.607957\n",
      "iteration 110 / 300: loss 0.610845\n",
      "iteration 110 / 300: loss 0.606274\n",
      "iteration 110 / 300: loss 0.583797\n",
      "iteration 110 / 300: loss 0.589633\n",
      "iteration 110 / 300: loss 0.595192\n",
      "iteration 110 / 300: loss 0.598962\n",
      "iteration 110 / 300: loss 0.596141\n",
      "iteration 110 / 300: loss 0.589776\n",
      "iteration 110 / 300: loss 0.591143\n",
      "iteration 110 / 300: loss 0.584861\n",
      "iteration 110 / 300: loss 0.599654\n",
      "iteration 110 / 300: loss 0.598908\n",
      "iteration 110 / 300: loss 0.614288\n",
      "iteration 110 / 300: loss 0.597804\n",
      "iteration 110 / 300: loss 0.599305\n",
      "iteration 110 / 300: loss 0.603326\n",
      "iteration 110 / 300: loss 0.592873\n",
      "iteration 110 / 300: loss 0.592399\n",
      "iteration 110 / 300: loss 0.589048\n",
      "iteration 110 / 300: loss 0.596455\n",
      "iteration 110 / 300: loss 0.605717\n",
      "iteration 110 / 300: loss 0.610569\n",
      "iteration 110 / 300: loss 0.587789\n",
      "iteration 110 / 300: loss 0.599357\n",
      "iteration 110 / 300: loss 0.602799\n",
      "iteration 110 / 300: loss 0.605036\n",
      "iteration 110 / 300: loss 0.603857\n",
      "iteration 110 / 300: loss 0.624150\n",
      "iteration 110 / 300: loss 0.587225\n",
      "iteration 110 / 300: loss 0.580762\n",
      "iteration 110 / 300: loss 0.625054\n",
      "iteration 110 / 300: loss 0.603318\n",
      "iteration 110 / 300: loss 0.604330\n",
      "iteration 110 / 300: loss 0.595485\n",
      "iteration 110 / 300: loss 0.597552\n",
      "iteration 110 / 300: loss 0.592749\n",
      "iteration 110 / 300: loss 0.589502\n",
      "iteration 110 / 300: loss 0.599272\n",
      "iteration 110 / 300: loss 0.611386\n",
      "iteration 110 / 300: loss 0.592471\n",
      "iteration 110 / 300: loss 0.599433\n",
      "iteration 110 / 300: loss 0.603110\n",
      "iteration 110 / 300: loss 0.602418\n",
      "iteration 110 / 300: loss 0.579819\n",
      "iteration 110 / 300: loss 0.601600\n",
      "iteration 111 / 300: loss 0.585535\n",
      "iteration 111 / 300: loss 0.588434\n",
      "iteration 111 / 300: loss 0.567523\n",
      "iteration 111 / 300: loss 0.592386\n",
      "iteration 111 / 300: loss 0.593625\n",
      "iteration 111 / 300: loss 0.595303\n",
      "iteration 111 / 300: loss 0.608791\n",
      "iteration 111 / 300: loss 0.592739\n",
      "iteration 111 / 300: loss 0.628068\n",
      "iteration 111 / 300: loss 0.580160\n",
      "iteration 111 / 300: loss 0.607931\n",
      "iteration 111 / 300: loss 0.587402\n",
      "iteration 111 / 300: loss 0.591693\n",
      "iteration 111 / 300: loss 0.571377\n",
      "iteration 111 / 300: loss 0.583032\n",
      "iteration 111 / 300: loss 0.608447\n",
      "iteration 111 / 300: loss 0.598366\n",
      "iteration 111 / 300: loss 0.583864\n",
      "iteration 111 / 300: loss 0.615260\n",
      "iteration 111 / 300: loss 0.591657\n",
      "iteration 111 / 300: loss 0.585506\n",
      "iteration 111 / 300: loss 0.591333\n",
      "iteration 111 / 300: loss 0.604348\n",
      "iteration 111 / 300: loss 0.595794\n",
      "iteration 111 / 300: loss 0.614955\n",
      "iteration 111 / 300: loss 0.608395\n",
      "iteration 111 / 300: loss 0.598230\n",
      "iteration 111 / 300: loss 0.588942\n",
      "iteration 111 / 300: loss 0.617764\n",
      "iteration 111 / 300: loss 0.594777\n",
      "iteration 111 / 300: loss 0.601693\n",
      "iteration 111 / 300: loss 0.631040\n",
      "iteration 111 / 300: loss 0.587521\n",
      "iteration 111 / 300: loss 0.606569\n",
      "iteration 111 / 300: loss 0.588042\n",
      "iteration 111 / 300: loss 0.600898\n",
      "iteration 111 / 300: loss 0.595965\n",
      "iteration 111 / 300: loss 0.589300\n",
      "iteration 111 / 300: loss 0.599534\n",
      "iteration 111 / 300: loss 0.604863\n",
      "iteration 111 / 300: loss 0.619422\n",
      "iteration 111 / 300: loss 0.588817\n",
      "iteration 111 / 300: loss 0.593653\n",
      "iteration 111 / 300: loss 0.585604\n",
      "iteration 111 / 300: loss 0.613219\n",
      "iteration 111 / 300: loss 0.587531\n",
      "iteration 111 / 300: loss 0.578336\n",
      "iteration 111 / 300: loss 0.567442\n",
      "iteration 111 / 300: loss 0.562241\n",
      "iteration 111 / 300: loss 0.594191\n",
      "iteration 111 / 300: loss 0.578827\n",
      "iteration 111 / 300: loss 0.586367\n",
      "iteration 111 / 300: loss 0.572897\n",
      "iteration 111 / 300: loss 0.596158\n",
      "iteration 111 / 300: loss 0.607957\n",
      "iteration 111 / 300: loss 0.610844\n",
      "iteration 111 / 300: loss 0.606273\n",
      "iteration 111 / 300: loss 0.583797\n",
      "iteration 111 / 300: loss 0.589632\n",
      "iteration 111 / 300: loss 0.595191\n",
      "iteration 111 / 300: loss 0.598961\n",
      "iteration 111 / 300: loss 0.596140\n",
      "iteration 111 / 300: loss 0.589776\n",
      "iteration 111 / 300: loss 0.591142\n",
      "iteration 111 / 300: loss 0.584860\n",
      "iteration 111 / 300: loss 0.599653\n",
      "iteration 111 / 300: loss 0.598908\n",
      "iteration 111 / 300: loss 0.614288\n",
      "iteration 111 / 300: loss 0.597803\n",
      "iteration 111 / 300: loss 0.599305\n",
      "iteration 111 / 300: loss 0.603325\n",
      "iteration 111 / 300: loss 0.592873\n",
      "iteration 111 / 300: loss 0.592398\n",
      "iteration 111 / 300: loss 0.589048\n",
      "iteration 111 / 300: loss 0.596454\n",
      "iteration 111 / 300: loss 0.605716\n",
      "iteration 111 / 300: loss 0.610568\n",
      "iteration 111 / 300: loss 0.587788\n",
      "iteration 111 / 300: loss 0.599356\n",
      "iteration 111 / 300: loss 0.602798\n",
      "iteration 111 / 300: loss 0.605035\n",
      "iteration 111 / 300: loss 0.603856\n",
      "iteration 111 / 300: loss 0.624150\n",
      "iteration 111 / 300: loss 0.587225\n",
      "iteration 111 / 300: loss 0.580761\n",
      "iteration 111 / 300: loss 0.625053\n",
      "iteration 111 / 300: loss 0.603317\n",
      "iteration 111 / 300: loss 0.604329\n",
      "iteration 111 / 300: loss 0.595484\n",
      "iteration 111 / 300: loss 0.597551\n",
      "iteration 111 / 300: loss 0.592748\n",
      "iteration 111 / 300: loss 0.589501\n",
      "iteration 111 / 300: loss 0.599271\n",
      "iteration 111 / 300: loss 0.611386\n",
      "iteration 111 / 300: loss 0.592470\n",
      "iteration 111 / 300: loss 0.599432\n",
      "iteration 111 / 300: loss 0.603109\n",
      "iteration 111 / 300: loss 0.602418\n",
      "iteration 111 / 300: loss 0.579818\n",
      "iteration 111 / 300: loss 0.601599\n",
      "iteration 112 / 300: loss 0.585534\n",
      "iteration 112 / 300: loss 0.588434\n",
      "iteration 112 / 300: loss 0.567523\n",
      "iteration 112 / 300: loss 0.592385\n",
      "iteration 112 / 300: loss 0.593624\n",
      "iteration 112 / 300: loss 0.595302\n",
      "iteration 112 / 300: loss 0.608790\n",
      "iteration 112 / 300: loss 0.592739\n",
      "iteration 112 / 300: loss 0.628068\n",
      "iteration 112 / 300: loss 0.580160\n",
      "iteration 112 / 300: loss 0.607930\n",
      "iteration 112 / 300: loss 0.587401\n",
      "iteration 112 / 300: loss 0.591693\n",
      "iteration 112 / 300: loss 0.571376\n",
      "iteration 112 / 300: loss 0.583031\n",
      "iteration 112 / 300: loss 0.608446\n",
      "iteration 112 / 300: loss 0.598366\n",
      "iteration 112 / 300: loss 0.583863\n",
      "iteration 112 / 300: loss 0.615259\n",
      "iteration 112 / 300: loss 0.591656\n",
      "iteration 112 / 300: loss 0.585505\n",
      "iteration 112 / 300: loss 0.591332\n",
      "iteration 112 / 300: loss 0.604348\n",
      "iteration 112 / 300: loss 0.595794\n",
      "iteration 112 / 300: loss 0.614954\n",
      "iteration 112 / 300: loss 0.608394\n",
      "iteration 112 / 300: loss 0.598229\n",
      "iteration 112 / 300: loss 0.588942\n",
      "iteration 112 / 300: loss 0.617764\n",
      "iteration 112 / 300: loss 0.594776\n",
      "iteration 112 / 300: loss 0.601692\n",
      "iteration 112 / 300: loss 0.631039\n",
      "iteration 112 / 300: loss 0.587520\n",
      "iteration 112 / 300: loss 0.606568\n",
      "iteration 112 / 300: loss 0.588041\n",
      "iteration 112 / 300: loss 0.600898\n",
      "iteration 112 / 300: loss 0.595964\n",
      "iteration 112 / 300: loss 0.589299\n",
      "iteration 112 / 300: loss 0.599534\n",
      "iteration 112 / 300: loss 0.604862\n",
      "iteration 112 / 300: loss 0.619421\n",
      "iteration 112 / 300: loss 0.588816\n",
      "iteration 112 / 300: loss 0.593653\n",
      "iteration 112 / 300: loss 0.585603\n",
      "iteration 112 / 300: loss 0.613218\n",
      "iteration 112 / 300: loss 0.587530\n",
      "iteration 112 / 300: loss 0.578336\n",
      "iteration 112 / 300: loss 0.567441\n",
      "iteration 112 / 300: loss 0.562240\n",
      "iteration 112 / 300: loss 0.594190\n",
      "iteration 112 / 300: loss 0.578827\n",
      "iteration 112 / 300: loss 0.586366\n",
      "iteration 112 / 300: loss 0.572896\n",
      "iteration 112 / 300: loss 0.596158\n",
      "iteration 112 / 300: loss 0.607956\n",
      "iteration 112 / 300: loss 0.610844\n",
      "iteration 112 / 300: loss 0.606272\n",
      "iteration 112 / 300: loss 0.583796\n",
      "iteration 112 / 300: loss 0.589632\n",
      "iteration 112 / 300: loss 0.595190\n",
      "iteration 112 / 300: loss 0.598960\n",
      "iteration 112 / 300: loss 0.596140\n",
      "iteration 112 / 300: loss 0.589775\n",
      "iteration 112 / 300: loss 0.591142\n",
      "iteration 112 / 300: loss 0.584860\n",
      "iteration 112 / 300: loss 0.599653\n",
      "iteration 112 / 300: loss 0.598907\n",
      "iteration 112 / 300: loss 0.614287\n",
      "iteration 112 / 300: loss 0.597802\n",
      "iteration 112 / 300: loss 0.599304\n",
      "iteration 112 / 300: loss 0.603324\n",
      "iteration 112 / 300: loss 0.592872\n",
      "iteration 112 / 300: loss 0.592398\n",
      "iteration 112 / 300: loss 0.589047\n",
      "iteration 112 / 300: loss 0.596453\n",
      "iteration 112 / 300: loss 0.605716\n",
      "iteration 112 / 300: loss 0.610568\n",
      "iteration 112 / 300: loss 0.587788\n",
      "iteration 112 / 300: loss 0.599356\n",
      "iteration 112 / 300: loss 0.602798\n",
      "iteration 112 / 300: loss 0.605035\n",
      "iteration 112 / 300: loss 0.603855\n",
      "iteration 112 / 300: loss 0.624149\n",
      "iteration 112 / 300: loss 0.587224\n",
      "iteration 112 / 300: loss 0.580760\n",
      "iteration 112 / 300: loss 0.625052\n",
      "iteration 112 / 300: loss 0.603316\n",
      "iteration 112 / 300: loss 0.604328\n",
      "iteration 112 / 300: loss 0.595483\n",
      "iteration 112 / 300: loss 0.597550\n",
      "iteration 112 / 300: loss 0.592747\n",
      "iteration 112 / 300: loss 0.589500\n",
      "iteration 112 / 300: loss 0.599271\n",
      "iteration 112 / 300: loss 0.611385\n",
      "iteration 112 / 300: loss 0.592469\n",
      "iteration 112 / 300: loss 0.599431\n",
      "iteration 112 / 300: loss 0.603108\n",
      "iteration 112 / 300: loss 0.602417\n",
      "iteration 112 / 300: loss 0.579817\n",
      "iteration 112 / 300: loss 0.601598\n",
      "iteration 113 / 300: loss 0.585534\n",
      "iteration 113 / 300: loss 0.588433\n",
      "iteration 113 / 300: loss 0.567522\n",
      "iteration 113 / 300: loss 0.592385\n",
      "iteration 113 / 300: loss 0.593624\n",
      "iteration 113 / 300: loss 0.595302\n",
      "iteration 113 / 300: loss 0.608789\n",
      "iteration 113 / 300: loss 0.592738\n",
      "iteration 113 / 300: loss 0.628067\n",
      "iteration 113 / 300: loss 0.580159\n",
      "iteration 113 / 300: loss 0.607930\n",
      "iteration 113 / 300: loss 0.587401\n",
      "iteration 113 / 300: loss 0.591692\n",
      "iteration 113 / 300: loss 0.571375\n",
      "iteration 113 / 300: loss 0.583030\n",
      "iteration 113 / 300: loss 0.608446\n",
      "iteration 113 / 300: loss 0.598365\n",
      "iteration 113 / 300: loss 0.583863\n",
      "iteration 113 / 300: loss 0.615259\n",
      "iteration 113 / 300: loss 0.591656\n",
      "iteration 113 / 300: loss 0.585505\n",
      "iteration 113 / 300: loss 0.591331\n",
      "iteration 113 / 300: loss 0.604347\n",
      "iteration 113 / 300: loss 0.595793\n",
      "iteration 113 / 300: loss 0.614954\n",
      "iteration 113 / 300: loss 0.608394\n",
      "iteration 113 / 300: loss 0.598229\n",
      "iteration 113 / 300: loss 0.588941\n",
      "iteration 113 / 300: loss 0.617763\n",
      "iteration 113 / 300: loss 0.594776\n",
      "iteration 113 / 300: loss 0.601691\n",
      "iteration 113 / 300: loss 0.631038\n",
      "iteration 113 / 300: loss 0.587519\n",
      "iteration 113 / 300: loss 0.606568\n",
      "iteration 113 / 300: loss 0.588040\n",
      "iteration 113 / 300: loss 0.600897\n",
      "iteration 113 / 300: loss 0.595964\n",
      "iteration 113 / 300: loss 0.589298\n",
      "iteration 113 / 300: loss 0.599533\n",
      "iteration 113 / 300: loss 0.604861\n",
      "iteration 113 / 300: loss 0.619420\n",
      "iteration 113 / 300: loss 0.588815\n",
      "iteration 113 / 300: loss 0.593652\n",
      "iteration 113 / 300: loss 0.585602\n",
      "iteration 113 / 300: loss 0.613218\n",
      "iteration 113 / 300: loss 0.587529\n",
      "iteration 113 / 300: loss 0.578335\n",
      "iteration 113 / 300: loss 0.567440\n",
      "iteration 113 / 300: loss 0.562240\n",
      "iteration 113 / 300: loss 0.594189\n",
      "iteration 113 / 300: loss 0.578826\n",
      "iteration 113 / 300: loss 0.586365\n",
      "iteration 113 / 300: loss 0.572896\n",
      "iteration 113 / 300: loss 0.596157\n",
      "iteration 113 / 300: loss 0.607956\n",
      "iteration 113 / 300: loss 0.610843\n",
      "iteration 113 / 300: loss 0.606272\n",
      "iteration 113 / 300: loss 0.583795\n",
      "iteration 113 / 300: loss 0.589631\n",
      "iteration 113 / 300: loss 0.595190\n",
      "iteration 113 / 300: loss 0.598960\n",
      "iteration 113 / 300: loss 0.596139\n",
      "iteration 113 / 300: loss 0.589775\n",
      "iteration 113 / 300: loss 0.591141\n",
      "iteration 113 / 300: loss 0.584859\n",
      "iteration 113 / 300: loss 0.599652\n",
      "iteration 113 / 300: loss 0.598907\n",
      "iteration 113 / 300: loss 0.614287\n",
      "iteration 113 / 300: loss 0.597802\n",
      "iteration 113 / 300: loss 0.599303\n",
      "iteration 113 / 300: loss 0.603323\n",
      "iteration 113 / 300: loss 0.592871\n",
      "iteration 113 / 300: loss 0.592397\n",
      "iteration 113 / 300: loss 0.589047\n",
      "iteration 113 / 300: loss 0.596452\n",
      "iteration 113 / 300: loss 0.605715\n",
      "iteration 113 / 300: loss 0.610567\n",
      "iteration 113 / 300: loss 0.587787\n",
      "iteration 113 / 300: loss 0.599355\n",
      "iteration 113 / 300: loss 0.602797\n",
      "iteration 113 / 300: loss 0.605034\n",
      "iteration 113 / 300: loss 0.603854\n",
      "iteration 113 / 300: loss 0.624149\n",
      "iteration 113 / 300: loss 0.587224\n",
      "iteration 113 / 300: loss 0.580760\n",
      "iteration 113 / 300: loss 0.625052\n",
      "iteration 113 / 300: loss 0.603316\n",
      "iteration 113 / 300: loss 0.604327\n",
      "iteration 113 / 300: loss 0.595483\n",
      "iteration 113 / 300: loss 0.597549\n",
      "iteration 113 / 300: loss 0.592746\n",
      "iteration 113 / 300: loss 0.589500\n",
      "iteration 113 / 300: loss 0.599270\n",
      "iteration 113 / 300: loss 0.611385\n",
      "iteration 113 / 300: loss 0.592469\n",
      "iteration 113 / 300: loss 0.599431\n",
      "iteration 113 / 300: loss 0.603107\n",
      "iteration 113 / 300: loss 0.602416\n",
      "iteration 113 / 300: loss 0.579817\n",
      "iteration 113 / 300: loss 0.601598\n",
      "iteration 114 / 300: loss 0.585533\n",
      "iteration 114 / 300: loss 0.588433\n",
      "iteration 114 / 300: loss 0.567522\n",
      "iteration 114 / 300: loss 0.592384\n",
      "iteration 114 / 300: loss 0.593623\n",
      "iteration 114 / 300: loss 0.595301\n",
      "iteration 114 / 300: loss 0.608789\n",
      "iteration 114 / 300: loss 0.592737\n",
      "iteration 114 / 300: loss 0.628066\n",
      "iteration 114 / 300: loss 0.580158\n",
      "iteration 114 / 300: loss 0.607929\n",
      "iteration 114 / 300: loss 0.587400\n",
      "iteration 114 / 300: loss 0.591692\n",
      "iteration 114 / 300: loss 0.571375\n",
      "iteration 114 / 300: loss 0.583030\n",
      "iteration 114 / 300: loss 0.608445\n",
      "iteration 114 / 300: loss 0.598364\n",
      "iteration 114 / 300: loss 0.583862\n",
      "iteration 114 / 300: loss 0.615258\n",
      "iteration 114 / 300: loss 0.591655\n",
      "iteration 114 / 300: loss 0.585504\n",
      "iteration 114 / 300: loss 0.591331\n",
      "iteration 114 / 300: loss 0.604346\n",
      "iteration 114 / 300: loss 0.595792\n",
      "iteration 114 / 300: loss 0.614953\n",
      "iteration 114 / 300: loss 0.608393\n",
      "iteration 114 / 300: loss 0.598228\n",
      "iteration 114 / 300: loss 0.588941\n",
      "iteration 114 / 300: loss 0.617762\n",
      "iteration 114 / 300: loss 0.594775\n",
      "iteration 114 / 300: loss 0.601690\n",
      "iteration 114 / 300: loss 0.631038\n",
      "iteration 114 / 300: loss 0.587519\n",
      "iteration 114 / 300: loss 0.606567\n",
      "iteration 114 / 300: loss 0.588040\n",
      "iteration 114 / 300: loss 0.600896\n",
      "iteration 114 / 300: loss 0.595963\n",
      "iteration 114 / 300: loss 0.589298\n",
      "iteration 114 / 300: loss 0.599532\n",
      "iteration 114 / 300: loss 0.604861\n",
      "iteration 114 / 300: loss 0.619420\n",
      "iteration 114 / 300: loss 0.588814\n",
      "iteration 114 / 300: loss 0.593651\n",
      "iteration 114 / 300: loss 0.585602\n",
      "iteration 114 / 300: loss 0.613217\n",
      "iteration 114 / 300: loss 0.587529\n",
      "iteration 114 / 300: loss 0.578334\n",
      "iteration 114 / 300: loss 0.567440\n",
      "iteration 114 / 300: loss 0.562239\n",
      "iteration 114 / 300: loss 0.594189\n",
      "iteration 114 / 300: loss 0.578826\n",
      "iteration 114 / 300: loss 0.586365\n",
      "iteration 114 / 300: loss 0.572895\n",
      "iteration 114 / 300: loss 0.596156\n",
      "iteration 114 / 300: loss 0.607955\n",
      "iteration 114 / 300: loss 0.610843\n",
      "iteration 114 / 300: loss 0.606271\n",
      "iteration 114 / 300: loss 0.583795\n",
      "iteration 114 / 300: loss 0.589631\n",
      "iteration 114 / 300: loss 0.595189\n",
      "iteration 114 / 300: loss 0.598959\n",
      "iteration 114 / 300: loss 0.596139\n",
      "iteration 114 / 300: loss 0.589774\n",
      "iteration 114 / 300: loss 0.591141\n",
      "iteration 114 / 300: loss 0.584859\n",
      "iteration 114 / 300: loss 0.599651\n",
      "iteration 114 / 300: loss 0.598906\n",
      "iteration 114 / 300: loss 0.614286\n",
      "iteration 114 / 300: loss 0.597801\n",
      "iteration 114 / 300: loss 0.599303\n",
      "iteration 114 / 300: loss 0.603323\n",
      "iteration 114 / 300: loss 0.592871\n",
      "iteration 114 / 300: loss 0.592396\n",
      "iteration 114 / 300: loss 0.589046\n",
      "iteration 114 / 300: loss 0.596452\n",
      "iteration 114 / 300: loss 0.605714\n",
      "iteration 114 / 300: loss 0.610567\n",
      "iteration 114 / 300: loss 0.587787\n",
      "iteration 114 / 300: loss 0.599355\n",
      "iteration 114 / 300: loss 0.602796\n",
      "iteration 114 / 300: loss 0.605033\n",
      "iteration 114 / 300: loss 0.603854\n",
      "iteration 114 / 300: loss 0.624148\n",
      "iteration 114 / 300: loss 0.587223\n",
      "iteration 114 / 300: loss 0.580759\n",
      "iteration 114 / 300: loss 0.625051\n",
      "iteration 114 / 300: loss 0.603315\n",
      "iteration 114 / 300: loss 0.604327\n",
      "iteration 114 / 300: loss 0.595482\n",
      "iteration 114 / 300: loss 0.597549\n",
      "iteration 114 / 300: loss 0.592746\n",
      "iteration 114 / 300: loss 0.589499\n",
      "iteration 114 / 300: loss 0.599270\n",
      "iteration 114 / 300: loss 0.611384\n",
      "iteration 114 / 300: loss 0.592468\n",
      "iteration 114 / 300: loss 0.599430\n",
      "iteration 114 / 300: loss 0.603107\n",
      "iteration 114 / 300: loss 0.602416\n",
      "iteration 114 / 300: loss 0.579816\n",
      "iteration 114 / 300: loss 0.601597\n",
      "iteration 115 / 300: loss 0.585533\n",
      "iteration 115 / 300: loss 0.588432\n",
      "iteration 115 / 300: loss 0.567521\n",
      "iteration 115 / 300: loss 0.592384\n",
      "iteration 115 / 300: loss 0.593623\n",
      "iteration 115 / 300: loss 0.595300\n",
      "iteration 115 / 300: loss 0.608788\n",
      "iteration 115 / 300: loss 0.592737\n",
      "iteration 115 / 300: loss 0.628066\n",
      "iteration 115 / 300: loss 0.580158\n",
      "iteration 115 / 300: loss 0.607928\n",
      "iteration 115 / 300: loss 0.587399\n",
      "iteration 115 / 300: loss 0.591691\n",
      "iteration 115 / 300: loss 0.571374\n",
      "iteration 115 / 300: loss 0.583029\n",
      "iteration 115 / 300: loss 0.608445\n",
      "iteration 115 / 300: loss 0.598364\n",
      "iteration 115 / 300: loss 0.583862\n",
      "iteration 115 / 300: loss 0.615258\n",
      "iteration 115 / 300: loss 0.591654\n",
      "iteration 115 / 300: loss 0.585504\n",
      "iteration 115 / 300: loss 0.591330\n",
      "iteration 115 / 300: loss 0.604346\n",
      "iteration 115 / 300: loss 0.595792\n",
      "iteration 115 / 300: loss 0.614953\n",
      "iteration 115 / 300: loss 0.608393\n",
      "iteration 115 / 300: loss 0.598228\n",
      "iteration 115 / 300: loss 0.588940\n",
      "iteration 115 / 300: loss 0.617762\n",
      "iteration 115 / 300: loss 0.594775\n",
      "iteration 115 / 300: loss 0.601690\n",
      "iteration 115 / 300: loss 0.631037\n",
      "iteration 115 / 300: loss 0.587518\n",
      "iteration 115 / 300: loss 0.606567\n",
      "iteration 115 / 300: loss 0.588039\n",
      "iteration 115 / 300: loss 0.600895\n",
      "iteration 115 / 300: loss 0.595963\n",
      "iteration 115 / 300: loss 0.589297\n",
      "iteration 115 / 300: loss 0.599532\n",
      "iteration 115 / 300: loss 0.604860\n",
      "iteration 115 / 300: loss 0.619419\n",
      "iteration 115 / 300: loss 0.588814\n",
      "iteration 115 / 300: loss 0.593651\n",
      "iteration 115 / 300: loss 0.585601\n",
      "iteration 115 / 300: loss 0.613217\n",
      "iteration 115 / 300: loss 0.587528\n",
      "iteration 115 / 300: loss 0.578334\n",
      "iteration 115 / 300: loss 0.567439\n",
      "iteration 115 / 300: loss 0.562239\n",
      "iteration 115 / 300: loss 0.594188\n",
      "iteration 115 / 300: loss 0.578825\n",
      "iteration 115 / 300: loss 0.586364\n",
      "iteration 115 / 300: loss 0.572895\n",
      "iteration 115 / 300: loss 0.596156\n",
      "iteration 115 / 300: loss 0.607955\n",
      "iteration 115 / 300: loss 0.610842\n",
      "iteration 115 / 300: loss 0.606270\n",
      "iteration 115 / 300: loss 0.583794\n",
      "iteration 115 / 300: loss 0.589630\n",
      "iteration 115 / 300: loss 0.595189\n",
      "iteration 115 / 300: loss 0.598959\n",
      "iteration 115 / 300: loss 0.596138\n",
      "iteration 115 / 300: loss 0.589774\n",
      "iteration 115 / 300: loss 0.591140\n",
      "iteration 115 / 300: loss 0.584858\n",
      "iteration 115 / 300: loss 0.599651\n",
      "iteration 115 / 300: loss 0.598906\n",
      "iteration 115 / 300: loss 0.614286\n",
      "iteration 115 / 300: loss 0.597801\n",
      "iteration 115 / 300: loss 0.599302\n",
      "iteration 115 / 300: loss 0.603322\n",
      "iteration 115 / 300: loss 0.592870\n",
      "iteration 115 / 300: loss 0.592396\n",
      "iteration 115 / 300: loss 0.589046\n",
      "iteration 115 / 300: loss 0.596451\n",
      "iteration 115 / 300: loss 0.605714\n",
      "iteration 115 / 300: loss 0.610566\n",
      "iteration 115 / 300: loss 0.587786\n",
      "iteration 115 / 300: loss 0.599354\n",
      "iteration 115 / 300: loss 0.602796\n",
      "iteration 115 / 300: loss 0.605033\n",
      "iteration 115 / 300: loss 0.603853\n",
      "iteration 115 / 300: loss 0.624148\n",
      "iteration 115 / 300: loss 0.587223\n",
      "iteration 115 / 300: loss 0.580759\n",
      "iteration 115 / 300: loss 0.625051\n",
      "iteration 115 / 300: loss 0.603315\n",
      "iteration 115 / 300: loss 0.604326\n",
      "iteration 115 / 300: loss 0.595481\n",
      "iteration 115 / 300: loss 0.597548\n",
      "iteration 115 / 300: loss 0.592745\n",
      "iteration 115 / 300: loss 0.589498\n",
      "iteration 115 / 300: loss 0.599269\n",
      "iteration 115 / 300: loss 0.611384\n",
      "iteration 115 / 300: loss 0.592468\n",
      "iteration 115 / 300: loss 0.599429\n",
      "iteration 115 / 300: loss 0.603106\n",
      "iteration 115 / 300: loss 0.602415\n",
      "iteration 115 / 300: loss 0.579816\n",
      "iteration 115 / 300: loss 0.601597\n",
      "iteration 116 / 300: loss 0.585532\n",
      "iteration 116 / 300: loss 0.588432\n",
      "iteration 116 / 300: loss 0.567521\n",
      "iteration 116 / 300: loss 0.592383\n",
      "iteration 116 / 300: loss 0.593622\n",
      "iteration 116 / 300: loss 0.595300\n",
      "iteration 116 / 300: loss 0.608788\n",
      "iteration 116 / 300: loss 0.592736\n",
      "iteration 116 / 300: loss 0.628065\n",
      "iteration 116 / 300: loss 0.580157\n",
      "iteration 116 / 300: loss 0.607928\n",
      "iteration 116 / 300: loss 0.587399\n",
      "iteration 116 / 300: loss 0.591691\n",
      "iteration 116 / 300: loss 0.571374\n",
      "iteration 116 / 300: loss 0.583029\n",
      "iteration 116 / 300: loss 0.608445\n",
      "iteration 116 / 300: loss 0.598363\n",
      "iteration 116 / 300: loss 0.583861\n",
      "iteration 116 / 300: loss 0.615257\n",
      "iteration 116 / 300: loss 0.591654\n",
      "iteration 116 / 300: loss 0.585503\n",
      "iteration 116 / 300: loss 0.591329\n",
      "iteration 116 / 300: loss 0.604345\n",
      "iteration 116 / 300: loss 0.595791\n",
      "iteration 116 / 300: loss 0.614953\n",
      "iteration 116 / 300: loss 0.608392\n",
      "iteration 116 / 300: loss 0.598227\n",
      "iteration 116 / 300: loss 0.588940\n",
      "iteration 116 / 300: loss 0.617761\n",
      "iteration 116 / 300: loss 0.594774\n",
      "iteration 116 / 300: loss 0.601689\n",
      "iteration 116 / 300: loss 0.631036\n",
      "iteration 116 / 300: loss 0.587517\n",
      "iteration 116 / 300: loss 0.606566\n",
      "iteration 116 / 300: loss 0.588039\n",
      "iteration 116 / 300: loss 0.600895\n",
      "iteration 116 / 300: loss 0.595962\n",
      "iteration 116 / 300: loss 0.589296\n",
      "iteration 116 / 300: loss 0.599531\n",
      "iteration 116 / 300: loss 0.604860\n",
      "iteration 116 / 300: loss 0.619418\n",
      "iteration 116 / 300: loss 0.588813\n",
      "iteration 116 / 300: loss 0.593650\n",
      "iteration 116 / 300: loss 0.585600\n",
      "iteration 116 / 300: loss 0.613216\n",
      "iteration 116 / 300: loss 0.587528\n",
      "iteration 116 / 300: loss 0.578333\n",
      "iteration 116 / 300: loss 0.567439\n",
      "iteration 116 / 300: loss 0.562239\n",
      "iteration 116 / 300: loss 0.594188\n",
      "iteration 116 / 300: loss 0.578825\n",
      "iteration 116 / 300: loss 0.586364\n",
      "iteration 116 / 300: loss 0.572894\n",
      "iteration 116 / 300: loss 0.596155\n",
      "iteration 116 / 300: loss 0.607954\n",
      "iteration 116 / 300: loss 0.610842\n",
      "iteration 116 / 300: loss 0.606270\n",
      "iteration 116 / 300: loss 0.583794\n",
      "iteration 116 / 300: loss 0.589630\n",
      "iteration 116 / 300: loss 0.595188\n",
      "iteration 116 / 300: loss 0.598958\n",
      "iteration 116 / 300: loss 0.596138\n",
      "iteration 116 / 300: loss 0.589773\n",
      "iteration 116 / 300: loss 0.591140\n",
      "iteration 116 / 300: loss 0.584858\n",
      "iteration 116 / 300: loss 0.599651\n",
      "iteration 116 / 300: loss 0.598905\n",
      "iteration 116 / 300: loss 0.614286\n",
      "iteration 116 / 300: loss 0.597800\n",
      "iteration 116 / 300: loss 0.599302\n",
      "iteration 116 / 300: loss 0.603322\n",
      "iteration 116 / 300: loss 0.592870\n",
      "iteration 116 / 300: loss 0.592395\n",
      "iteration 116 / 300: loss 0.589045\n",
      "iteration 116 / 300: loss 0.596451\n",
      "iteration 116 / 300: loss 0.605713\n",
      "iteration 116 / 300: loss 0.610566\n",
      "iteration 116 / 300: loss 0.587786\n",
      "iteration 116 / 300: loss 0.599354\n",
      "iteration 116 / 300: loss 0.602796\n",
      "iteration 116 / 300: loss 0.605032\n",
      "iteration 116 / 300: loss 0.603853\n",
      "iteration 116 / 300: loss 0.624147\n",
      "iteration 116 / 300: loss 0.587222\n",
      "iteration 116 / 300: loss 0.580758\n",
      "iteration 116 / 300: loss 0.625050\n",
      "iteration 116 / 300: loss 0.603314\n",
      "iteration 116 / 300: loss 0.604326\n",
      "iteration 116 / 300: loss 0.595481\n",
      "iteration 116 / 300: loss 0.597548\n",
      "iteration 116 / 300: loss 0.592745\n",
      "iteration 116 / 300: loss 0.589498\n",
      "iteration 116 / 300: loss 0.599269\n",
      "iteration 116 / 300: loss 0.611383\n",
      "iteration 116 / 300: loss 0.592467\n",
      "iteration 116 / 300: loss 0.599429\n",
      "iteration 116 / 300: loss 0.603105\n",
      "iteration 116 / 300: loss 0.602415\n",
      "iteration 116 / 300: loss 0.579815\n",
      "iteration 116 / 300: loss 0.601596\n",
      "iteration 117 / 300: loss 0.585532\n",
      "iteration 117 / 300: loss 0.588431\n",
      "iteration 117 / 300: loss 0.567520\n",
      "iteration 117 / 300: loss 0.592383\n",
      "iteration 117 / 300: loss 0.593622\n",
      "iteration 117 / 300: loss 0.595299\n",
      "iteration 117 / 300: loss 0.608788\n",
      "iteration 117 / 300: loss 0.592736\n",
      "iteration 117 / 300: loss 0.628065\n",
      "iteration 117 / 300: loss 0.580157\n",
      "iteration 117 / 300: loss 0.607927\n",
      "iteration 117 / 300: loss 0.587399\n",
      "iteration 117 / 300: loss 0.591690\n",
      "iteration 117 / 300: loss 0.571374\n",
      "iteration 117 / 300: loss 0.583028\n",
      "iteration 117 / 300: loss 0.608444\n",
      "iteration 117 / 300: loss 0.598363\n",
      "iteration 117 / 300: loss 0.583861\n",
      "iteration 117 / 300: loss 0.615257\n",
      "iteration 117 / 300: loss 0.591653\n",
      "iteration 117 / 300: loss 0.585503\n",
      "iteration 117 / 300: loss 0.591329\n",
      "iteration 117 / 300: loss 0.604345\n",
      "iteration 117 / 300: loss 0.595791\n",
      "iteration 117 / 300: loss 0.614952\n",
      "iteration 117 / 300: loss 0.608392\n",
      "iteration 117 / 300: loss 0.598227\n",
      "iteration 117 / 300: loss 0.588939\n",
      "iteration 117 / 300: loss 0.617761\n",
      "iteration 117 / 300: loss 0.594774\n",
      "iteration 117 / 300: loss 0.601689\n",
      "iteration 117 / 300: loss 0.631036\n",
      "iteration 117 / 300: loss 0.587517\n",
      "iteration 117 / 300: loss 0.606566\n",
      "iteration 117 / 300: loss 0.588038\n",
      "iteration 117 / 300: loss 0.600894\n",
      "iteration 117 / 300: loss 0.595962\n",
      "iteration 117 / 300: loss 0.589296\n",
      "iteration 117 / 300: loss 0.599530\n",
      "iteration 117 / 300: loss 0.604859\n",
      "iteration 117 / 300: loss 0.619418\n",
      "iteration 117 / 300: loss 0.588813\n",
      "iteration 117 / 300: loss 0.593649\n",
      "iteration 117 / 300: loss 0.585600\n",
      "iteration 117 / 300: loss 0.613216\n",
      "iteration 117 / 300: loss 0.587527\n",
      "iteration 117 / 300: loss 0.578333\n",
      "iteration 117 / 300: loss 0.567438\n",
      "iteration 117 / 300: loss 0.562238\n",
      "iteration 117 / 300: loss 0.594187\n",
      "iteration 117 / 300: loss 0.578824\n",
      "iteration 117 / 300: loss 0.586364\n",
      "iteration 117 / 300: loss 0.572894\n",
      "iteration 117 / 300: loss 0.596155\n",
      "iteration 117 / 300: loss 0.607954\n",
      "iteration 117 / 300: loss 0.610842\n",
      "iteration 117 / 300: loss 0.606270\n",
      "iteration 117 / 300: loss 0.583794\n",
      "iteration 117 / 300: loss 0.589630\n",
      "iteration 117 / 300: loss 0.595188\n",
      "iteration 117 / 300: loss 0.598958\n",
      "iteration 117 / 300: loss 0.596137\n",
      "iteration 117 / 300: loss 0.589773\n",
      "iteration 117 / 300: loss 0.591139\n",
      "iteration 117 / 300: loss 0.584857\n",
      "iteration 117 / 300: loss 0.599650\n",
      "iteration 117 / 300: loss 0.598905\n",
      "iteration 117 / 300: loss 0.614285\n",
      "iteration 117 / 300: loss 0.597800\n",
      "iteration 117 / 300: loss 0.599302\n",
      "iteration 117 / 300: loss 0.603321\n",
      "iteration 117 / 300: loss 0.592869\n",
      "iteration 117 / 300: loss 0.592395\n",
      "iteration 117 / 300: loss 0.589045\n",
      "iteration 117 / 300: loss 0.596450\n",
      "iteration 117 / 300: loss 0.605713\n",
      "iteration 117 / 300: loss 0.610565\n",
      "iteration 117 / 300: loss 0.587785\n",
      "iteration 117 / 300: loss 0.599354\n",
      "iteration 117 / 300: loss 0.602795\n",
      "iteration 117 / 300: loss 0.605032\n",
      "iteration 117 / 300: loss 0.603852\n",
      "iteration 117 / 300: loss 0.624147\n",
      "iteration 117 / 300: loss 0.587222\n",
      "iteration 117 / 300: loss 0.580758\n",
      "iteration 117 / 300: loss 0.625050\n",
      "iteration 117 / 300: loss 0.603314\n",
      "iteration 117 / 300: loss 0.604325\n",
      "iteration 117 / 300: loss 0.595480\n",
      "iteration 117 / 300: loss 0.597547\n",
      "iteration 117 / 300: loss 0.592744\n",
      "iteration 117 / 300: loss 0.589498\n",
      "iteration 117 / 300: loss 0.599268\n",
      "iteration 117 / 300: loss 0.611383\n",
      "iteration 117 / 300: loss 0.592467\n",
      "iteration 117 / 300: loss 0.599429\n",
      "iteration 117 / 300: loss 0.603105\n",
      "iteration 117 / 300: loss 0.602414\n",
      "iteration 117 / 300: loss 0.579815\n",
      "iteration 117 / 300: loss 0.601596\n",
      "iteration 118 / 300: loss 0.585531\n",
      "iteration 118 / 300: loss 0.588431\n",
      "iteration 118 / 300: loss 0.567520\n",
      "iteration 118 / 300: loss 0.592383\n",
      "iteration 118 / 300: loss 0.593621\n",
      "iteration 118 / 300: loss 0.595299\n",
      "iteration 118 / 300: loss 0.608787\n",
      "iteration 118 / 300: loss 0.592736\n",
      "iteration 118 / 300: loss 0.628064\n",
      "iteration 118 / 300: loss 0.580156\n",
      "iteration 118 / 300: loss 0.607927\n",
      "iteration 118 / 300: loss 0.587398\n",
      "iteration 118 / 300: loss 0.591690\n",
      "iteration 118 / 300: loss 0.571373\n",
      "iteration 118 / 300: loss 0.583028\n",
      "iteration 118 / 300: loss 0.608444\n",
      "iteration 118 / 300: loss 0.598363\n",
      "iteration 118 / 300: loss 0.583861\n",
      "iteration 118 / 300: loss 0.615256\n",
      "iteration 118 / 300: loss 0.591653\n",
      "iteration 118 / 300: loss 0.585503\n",
      "iteration 118 / 300: loss 0.591329\n",
      "iteration 118 / 300: loss 0.604344\n",
      "iteration 118 / 300: loss 0.595790\n",
      "iteration 118 / 300: loss 0.614952\n",
      "iteration 118 / 300: loss 0.608392\n",
      "iteration 118 / 300: loss 0.598226\n",
      "iteration 118 / 300: loss 0.588939\n",
      "iteration 118 / 300: loss 0.617760\n",
      "iteration 118 / 300: loss 0.594773\n",
      "iteration 118 / 300: loss 0.601688\n",
      "iteration 118 / 300: loss 0.631035\n",
      "iteration 118 / 300: loss 0.587517\n",
      "iteration 118 / 300: loss 0.606565\n",
      "iteration 118 / 300: loss 0.588038\n",
      "iteration 118 / 300: loss 0.600894\n",
      "iteration 118 / 300: loss 0.595961\n",
      "iteration 118 / 300: loss 0.589295\n",
      "iteration 118 / 300: loss 0.599530\n",
      "iteration 118 / 300: loss 0.604859\n",
      "iteration 118 / 300: loss 0.619418\n",
      "iteration 118 / 300: loss 0.588812\n",
      "iteration 118 / 300: loss 0.593649\n",
      "iteration 118 / 300: loss 0.585599\n",
      "iteration 118 / 300: loss 0.613216\n",
      "iteration 118 / 300: loss 0.587527\n",
      "iteration 118 / 300: loss 0.578332\n",
      "iteration 118 / 300: loss 0.567438\n",
      "iteration 118 / 300: loss 0.562238\n",
      "iteration 118 / 300: loss 0.594187\n",
      "iteration 118 / 300: loss 0.578824\n",
      "iteration 118 / 300: loss 0.586363\n",
      "iteration 118 / 300: loss 0.572893\n",
      "iteration 118 / 300: loss 0.596155\n",
      "iteration 118 / 300: loss 0.607954\n",
      "iteration 118 / 300: loss 0.610842\n",
      "iteration 118 / 300: loss 0.606269\n",
      "iteration 118 / 300: loss 0.583793\n",
      "iteration 118 / 300: loss 0.589629\n",
      "iteration 118 / 300: loss 0.595187\n",
      "iteration 118 / 300: loss 0.598958\n",
      "iteration 118 / 300: loss 0.596137\n",
      "iteration 118 / 300: loss 0.589772\n",
      "iteration 118 / 300: loss 0.591139\n",
      "iteration 118 / 300: loss 0.584857\n",
      "iteration 118 / 300: loss 0.599650\n",
      "iteration 118 / 300: loss 0.598905\n",
      "iteration 118 / 300: loss 0.614285\n",
      "iteration 118 / 300: loss 0.597800\n",
      "iteration 118 / 300: loss 0.599301\n",
      "iteration 118 / 300: loss 0.603321\n",
      "iteration 118 / 300: loss 0.592869\n",
      "iteration 118 / 300: loss 0.592395\n",
      "iteration 118 / 300: loss 0.589044\n",
      "iteration 118 / 300: loss 0.596450\n",
      "iteration 118 / 300: loss 0.605713\n",
      "iteration 118 / 300: loss 0.610565\n",
      "iteration 118 / 300: loss 0.587785\n",
      "iteration 118 / 300: loss 0.599354\n",
      "iteration 118 / 300: loss 0.602795\n",
      "iteration 118 / 300: loss 0.605032\n",
      "iteration 118 / 300: loss 0.603852\n",
      "iteration 118 / 300: loss 0.624147\n",
      "iteration 118 / 300: loss 0.587222\n",
      "iteration 118 / 300: loss 0.580758\n",
      "iteration 118 / 300: loss 0.625049\n",
      "iteration 118 / 300: loss 0.603313\n",
      "iteration 118 / 300: loss 0.604325\n",
      "iteration 118 / 300: loss 0.595480\n",
      "iteration 118 / 300: loss 0.597547\n",
      "iteration 118 / 300: loss 0.592744\n",
      "iteration 118 / 300: loss 0.589497\n",
      "iteration 118 / 300: loss 0.599268\n",
      "iteration 118 / 300: loss 0.611383\n",
      "iteration 118 / 300: loss 0.592466\n",
      "iteration 118 / 300: loss 0.599428\n",
      "iteration 118 / 300: loss 0.603105\n",
      "iteration 118 / 300: loss 0.602414\n",
      "iteration 118 / 300: loss 0.579815\n",
      "iteration 118 / 300: loss 0.601595\n",
      "iteration 119 / 300: loss 0.585531\n",
      "iteration 119 / 300: loss 0.588431\n",
      "iteration 119 / 300: loss 0.567519\n",
      "iteration 119 / 300: loss 0.592382\n",
      "iteration 119 / 300: loss 0.593621\n",
      "iteration 119 / 300: loss 0.595299\n",
      "iteration 119 / 300: loss 0.608787\n",
      "iteration 119 / 300: loss 0.592735\n",
      "iteration 119 / 300: loss 0.628064\n",
      "iteration 119 / 300: loss 0.580156\n",
      "iteration 119 / 300: loss 0.607927\n",
      "iteration 119 / 300: loss 0.587398\n",
      "iteration 119 / 300: loss 0.591689\n",
      "iteration 119 / 300: loss 0.571373\n",
      "iteration 119 / 300: loss 0.583028\n",
      "iteration 119 / 300: loss 0.608444\n",
      "iteration 119 / 300: loss 0.598362\n",
      "iteration 119 / 300: loss 0.583860\n",
      "iteration 119 / 300: loss 0.615256\n",
      "iteration 119 / 300: loss 0.591653\n",
      "iteration 119 / 300: loss 0.585502\n",
      "iteration 119 / 300: loss 0.591328\n",
      "iteration 119 / 300: loss 0.604344\n",
      "iteration 119 / 300: loss 0.595790\n",
      "iteration 119 / 300: loss 0.614952\n",
      "iteration 119 / 300: loss 0.608392\n",
      "iteration 119 / 300: loss 0.598226\n",
      "iteration 119 / 300: loss 0.588939\n",
      "iteration 119 / 300: loss 0.617760\n",
      "iteration 119 / 300: loss 0.594773\n",
      "iteration 119 / 300: loss 0.601688\n",
      "iteration 119 / 300: loss 0.631035\n",
      "iteration 119 / 300: loss 0.587516\n",
      "iteration 119 / 300: loss 0.606565\n",
      "iteration 119 / 300: loss 0.588037\n",
      "iteration 119 / 300: loss 0.600894\n",
      "iteration 119 / 300: loss 0.595961\n",
      "iteration 119 / 300: loss 0.589295\n",
      "iteration 119 / 300: loss 0.599530\n",
      "iteration 119 / 300: loss 0.604859\n",
      "iteration 119 / 300: loss 0.619417\n",
      "iteration 119 / 300: loss 0.588812\n",
      "iteration 119 / 300: loss 0.593649\n",
      "iteration 119 / 300: loss 0.585599\n",
      "iteration 119 / 300: loss 0.613215\n",
      "iteration 119 / 300: loss 0.587527\n",
      "iteration 119 / 300: loss 0.578332\n",
      "iteration 119 / 300: loss 0.567438\n",
      "iteration 119 / 300: loss 0.562238\n",
      "iteration 119 / 300: loss 0.594187\n",
      "iteration 119 / 300: loss 0.578824\n",
      "iteration 119 / 300: loss 0.586363\n",
      "iteration 119 / 300: loss 0.572893\n",
      "iteration 119 / 300: loss 0.596154\n",
      "iteration 119 / 300: loss 0.607953\n",
      "iteration 119 / 300: loss 0.610841\n",
      "iteration 119 / 300: loss 0.606269\n",
      "iteration 119 / 300: loss 0.583793\n",
      "iteration 119 / 300: loss 0.589629\n",
      "iteration 119 / 300: loss 0.595187\n",
      "iteration 119 / 300: loss 0.598957\n",
      "iteration 119 / 300: loss 0.596136\n",
      "iteration 119 / 300: loss 0.589772\n",
      "iteration 119 / 300: loss 0.591139\n",
      "iteration 119 / 300: loss 0.584857\n",
      "iteration 119 / 300: loss 0.599649\n",
      "iteration 119 / 300: loss 0.598905\n",
      "iteration 119 / 300: loss 0.614285\n",
      "iteration 119 / 300: loss 0.597799\n",
      "iteration 119 / 300: loss 0.599301\n",
      "iteration 119 / 300: loss 0.603321\n",
      "iteration 119 / 300: loss 0.592869\n",
      "iteration 119 / 300: loss 0.592394\n",
      "iteration 119 / 300: loss 0.589044\n",
      "iteration 119 / 300: loss 0.596449\n",
      "iteration 119 / 300: loss 0.605712\n",
      "iteration 119 / 300: loss 0.610565\n",
      "iteration 119 / 300: loss 0.587785\n",
      "iteration 119 / 300: loss 0.599353\n",
      "iteration 119 / 300: loss 0.602795\n",
      "iteration 119 / 300: loss 0.605031\n",
      "iteration 119 / 300: loss 0.603851\n",
      "iteration 119 / 300: loss 0.624146\n",
      "iteration 119 / 300: loss 0.587222\n",
      "iteration 119 / 300: loss 0.580757\n",
      "iteration 119 / 300: loss 0.625049\n",
      "iteration 119 / 300: loss 0.603313\n",
      "iteration 119 / 300: loss 0.604325\n",
      "iteration 119 / 300: loss 0.595480\n",
      "iteration 119 / 300: loss 0.597546\n",
      "iteration 119 / 300: loss 0.592744\n",
      "iteration 119 / 300: loss 0.589497\n",
      "iteration 119 / 300: loss 0.599267\n",
      "iteration 119 / 300: loss 0.611382\n",
      "iteration 119 / 300: loss 0.592466\n",
      "iteration 119 / 300: loss 0.599428\n",
      "iteration 119 / 300: loss 0.603104\n",
      "iteration 119 / 300: loss 0.602413\n",
      "iteration 119 / 300: loss 0.579814\n",
      "iteration 119 / 300: loss 0.601595\n",
      "iteration 120 / 300: loss 0.585531\n",
      "iteration 120 / 300: loss 0.588430\n",
      "iteration 120 / 300: loss 0.567519\n",
      "iteration 120 / 300: loss 0.592382\n",
      "iteration 120 / 300: loss 0.593621\n",
      "iteration 120 / 300: loss 0.595298\n",
      "iteration 120 / 300: loss 0.608787\n",
      "iteration 120 / 300: loss 0.592735\n",
      "iteration 120 / 300: loss 0.628064\n",
      "iteration 120 / 300: loss 0.580155\n",
      "iteration 120 / 300: loss 0.607926\n",
      "iteration 120 / 300: loss 0.587397\n",
      "iteration 120 / 300: loss 0.591689\n",
      "iteration 120 / 300: loss 0.571373\n",
      "iteration 120 / 300: loss 0.583028\n",
      "iteration 120 / 300: loss 0.608443\n",
      "iteration 120 / 300: loss 0.598362\n",
      "iteration 120 / 300: loss 0.583860\n",
      "iteration 120 / 300: loss 0.615256\n",
      "iteration 120 / 300: loss 0.591652\n",
      "iteration 120 / 300: loss 0.585502\n",
      "iteration 120 / 300: loss 0.591328\n",
      "iteration 120 / 300: loss 0.604344\n",
      "iteration 120 / 300: loss 0.595790\n",
      "iteration 120 / 300: loss 0.614952\n",
      "iteration 120 / 300: loss 0.608391\n",
      "iteration 120 / 300: loss 0.598225\n",
      "iteration 120 / 300: loss 0.588938\n",
      "iteration 120 / 300: loss 0.617760\n",
      "iteration 120 / 300: loss 0.594773\n",
      "iteration 120 / 300: loss 0.601688\n",
      "iteration 120 / 300: loss 0.631035\n",
      "iteration 120 / 300: loss 0.587516\n",
      "iteration 120 / 300: loss 0.606565\n",
      "iteration 120 / 300: loss 0.588037\n",
      "iteration 120 / 300: loss 0.600893\n",
      "iteration 120 / 300: loss 0.595961\n",
      "iteration 120 / 300: loss 0.589295\n",
      "iteration 120 / 300: loss 0.599529\n",
      "iteration 120 / 300: loss 0.604858\n",
      "iteration 120 / 300: loss 0.619417\n",
      "iteration 120 / 300: loss 0.588812\n",
      "iteration 120 / 300: loss 0.593648\n",
      "iteration 120 / 300: loss 0.585599\n",
      "iteration 120 / 300: loss 0.613215\n",
      "iteration 120 / 300: loss 0.587526\n",
      "iteration 120 / 300: loss 0.578331\n",
      "iteration 120 / 300: loss 0.567437\n",
      "iteration 120 / 300: loss 0.562238\n",
      "iteration 120 / 300: loss 0.594186\n",
      "iteration 120 / 300: loss 0.578824\n",
      "iteration 120 / 300: loss 0.586363\n",
      "iteration 120 / 300: loss 0.572893\n",
      "iteration 120 / 300: loss 0.596154\n",
      "iteration 120 / 300: loss 0.607953\n",
      "iteration 120 / 300: loss 0.610841\n",
      "iteration 120 / 300: loss 0.606268\n",
      "iteration 120 / 300: loss 0.583793\n",
      "iteration 120 / 300: loss 0.589629\n",
      "iteration 120 / 300: loss 0.595187\n",
      "iteration 120 / 300: loss 0.598957\n",
      "iteration 120 / 300: loss 0.596136\n",
      "iteration 120 / 300: loss 0.589772\n",
      "iteration 120 / 300: loss 0.591138\n",
      "iteration 120 / 300: loss 0.584857\n",
      "iteration 120 / 300: loss 0.599649\n",
      "iteration 120 / 300: loss 0.598904\n",
      "iteration 120 / 300: loss 0.614285\n",
      "iteration 120 / 300: loss 0.597799\n",
      "iteration 120 / 300: loss 0.599301\n",
      "iteration 120 / 300: loss 0.603320\n",
      "iteration 120 / 300: loss 0.592868\n",
      "iteration 120 / 300: loss 0.592394\n",
      "iteration 120 / 300: loss 0.589044\n",
      "iteration 120 / 300: loss 0.596449\n",
      "iteration 120 / 300: loss 0.605712\n",
      "iteration 120 / 300: loss 0.610564\n",
      "iteration 120 / 300: loss 0.587784\n",
      "iteration 120 / 300: loss 0.599353\n",
      "iteration 120 / 300: loss 0.602794\n",
      "iteration 120 / 300: loss 0.605031\n",
      "iteration 120 / 300: loss 0.603851\n",
      "iteration 120 / 300: loss 0.624146\n",
      "iteration 120 / 300: loss 0.587221\n",
      "iteration 120 / 300: loss 0.580757\n",
      "iteration 120 / 300: loss 0.625049\n",
      "iteration 120 / 300: loss 0.603313\n",
      "iteration 120 / 300: loss 0.604324\n",
      "iteration 120 / 300: loss 0.595479\n",
      "iteration 120 / 300: loss 0.597546\n",
      "iteration 120 / 300: loss 0.592743\n",
      "iteration 120 / 300: loss 0.589497\n",
      "iteration 120 / 300: loss 0.599267\n",
      "iteration 120 / 300: loss 0.611382\n",
      "iteration 120 / 300: loss 0.592466\n",
      "iteration 120 / 300: loss 0.599427\n",
      "iteration 120 / 300: loss 0.603104\n",
      "iteration 120 / 300: loss 0.602413\n",
      "iteration 120 / 300: loss 0.579814\n",
      "iteration 120 / 300: loss 0.601595\n",
      "iteration 121 / 300: loss 0.585530\n",
      "iteration 121 / 300: loss 0.588430\n",
      "iteration 121 / 300: loss 0.567519\n",
      "iteration 121 / 300: loss 0.592382\n",
      "iteration 121 / 300: loss 0.593621\n",
      "iteration 121 / 300: loss 0.595298\n",
      "iteration 121 / 300: loss 0.608786\n",
      "iteration 121 / 300: loss 0.592735\n",
      "iteration 121 / 300: loss 0.628063\n",
      "iteration 121 / 300: loss 0.580155\n",
      "iteration 121 / 300: loss 0.607926\n",
      "iteration 121 / 300: loss 0.587397\n",
      "iteration 121 / 300: loss 0.591689\n",
      "iteration 121 / 300: loss 0.571372\n",
      "iteration 121 / 300: loss 0.583027\n",
      "iteration 121 / 300: loss 0.608443\n",
      "iteration 121 / 300: loss 0.598362\n",
      "iteration 121 / 300: loss 0.583860\n",
      "iteration 121 / 300: loss 0.615255\n",
      "iteration 121 / 300: loss 0.591652\n",
      "iteration 121 / 300: loss 0.585502\n",
      "iteration 121 / 300: loss 0.591328\n",
      "iteration 121 / 300: loss 0.604343\n",
      "iteration 121 / 300: loss 0.595789\n",
      "iteration 121 / 300: loss 0.614951\n",
      "iteration 121 / 300: loss 0.608391\n",
      "iteration 121 / 300: loss 0.598225\n",
      "iteration 121 / 300: loss 0.588938\n",
      "iteration 121 / 300: loss 0.617759\n",
      "iteration 121 / 300: loss 0.594772\n",
      "iteration 121 / 300: loss 0.601687\n",
      "iteration 121 / 300: loss 0.631034\n",
      "iteration 121 / 300: loss 0.587516\n",
      "iteration 121 / 300: loss 0.606564\n",
      "iteration 121 / 300: loss 0.588037\n",
      "iteration 121 / 300: loss 0.600893\n",
      "iteration 121 / 300: loss 0.595960\n",
      "iteration 121 / 300: loss 0.589294\n",
      "iteration 121 / 300: loss 0.599529\n",
      "iteration 121 / 300: loss 0.604858\n",
      "iteration 121 / 300: loss 0.619417\n",
      "iteration 121 / 300: loss 0.588811\n",
      "iteration 121 / 300: loss 0.593648\n",
      "iteration 121 / 300: loss 0.585598\n",
      "iteration 121 / 300: loss 0.613215\n",
      "iteration 121 / 300: loss 0.587526\n",
      "iteration 121 / 300: loss 0.578331\n",
      "iteration 121 / 300: loss 0.567437\n",
      "iteration 121 / 300: loss 0.562237\n",
      "iteration 121 / 300: loss 0.594186\n",
      "iteration 121 / 300: loss 0.578823\n",
      "iteration 121 / 300: loss 0.586363\n",
      "iteration 121 / 300: loss 0.572892\n",
      "iteration 121 / 300: loss 0.596154\n",
      "iteration 121 / 300: loss 0.607953\n",
      "iteration 121 / 300: loss 0.610841\n",
      "iteration 121 / 300: loss 0.606268\n",
      "iteration 121 / 300: loss 0.583793\n",
      "iteration 121 / 300: loss 0.589629\n",
      "iteration 121 / 300: loss 0.595186\n",
      "iteration 121 / 300: loss 0.598957\n",
      "iteration 121 / 300: loss 0.596136\n",
      "iteration 121 / 300: loss 0.589772\n",
      "iteration 121 / 300: loss 0.591138\n",
      "iteration 121 / 300: loss 0.584856\n",
      "iteration 121 / 300: loss 0.599649\n",
      "iteration 121 / 300: loss 0.598904\n",
      "iteration 121 / 300: loss 0.614284\n",
      "iteration 121 / 300: loss 0.597799\n",
      "iteration 121 / 300: loss 0.599301\n",
      "iteration 121 / 300: loss 0.603320\n",
      "iteration 121 / 300: loss 0.592868\n",
      "iteration 121 / 300: loss 0.592394\n",
      "iteration 121 / 300: loss 0.589044\n",
      "iteration 121 / 300: loss 0.596449\n",
      "iteration 121 / 300: loss 0.605712\n",
      "iteration 121 / 300: loss 0.610564\n",
      "iteration 121 / 300: loss 0.587784\n",
      "iteration 121 / 300: loss 0.599353\n",
      "iteration 121 / 300: loss 0.602794\n",
      "iteration 121 / 300: loss 0.605031\n",
      "iteration 121 / 300: loss 0.603851\n",
      "iteration 121 / 300: loss 0.624146\n",
      "iteration 121 / 300: loss 0.587221\n",
      "iteration 121 / 300: loss 0.580757\n",
      "iteration 121 / 300: loss 0.625048\n",
      "iteration 121 / 300: loss 0.603312\n",
      "iteration 121 / 300: loss 0.604324\n",
      "iteration 121 / 300: loss 0.595479\n",
      "iteration 121 / 300: loss 0.597546\n",
      "iteration 121 / 300: loss 0.592743\n",
      "iteration 121 / 300: loss 0.589496\n",
      "iteration 121 / 300: loss 0.599267\n",
      "iteration 121 / 300: loss 0.611382\n",
      "iteration 121 / 300: loss 0.592466\n",
      "iteration 121 / 300: loss 0.599427\n",
      "iteration 121 / 300: loss 0.603103\n",
      "iteration 121 / 300: loss 0.602413\n",
      "iteration 121 / 300: loss 0.579814\n",
      "iteration 121 / 300: loss 0.601595\n",
      "iteration 122 / 300: loss 0.585530\n",
      "iteration 122 / 300: loss 0.588430\n",
      "iteration 122 / 300: loss 0.567519\n",
      "iteration 122 / 300: loss 0.592382\n",
      "iteration 122 / 300: loss 0.593620\n",
      "iteration 122 / 300: loss 0.595298\n",
      "iteration 122 / 300: loss 0.608786\n",
      "iteration 122 / 300: loss 0.592734\n",
      "iteration 122 / 300: loss 0.628063\n",
      "iteration 122 / 300: loss 0.580155\n",
      "iteration 122 / 300: loss 0.607926\n",
      "iteration 122 / 300: loss 0.587397\n",
      "iteration 122 / 300: loss 0.591689\n",
      "iteration 122 / 300: loss 0.571372\n",
      "iteration 122 / 300: loss 0.583027\n",
      "iteration 122 / 300: loss 0.608443\n",
      "iteration 122 / 300: loss 0.598361\n",
      "iteration 122 / 300: loss 0.583860\n",
      "iteration 122 / 300: loss 0.615255\n",
      "iteration 122 / 300: loss 0.591652\n",
      "iteration 122 / 300: loss 0.585501\n",
      "iteration 122 / 300: loss 0.591327\n",
      "iteration 122 / 300: loss 0.604343\n",
      "iteration 122 / 300: loss 0.595789\n",
      "iteration 122 / 300: loss 0.614951\n",
      "iteration 122 / 300: loss 0.608391\n",
      "iteration 122 / 300: loss 0.598225\n",
      "iteration 122 / 300: loss 0.588938\n",
      "iteration 122 / 300: loss 0.617759\n",
      "iteration 122 / 300: loss 0.594772\n",
      "iteration 122 / 300: loss 0.601687\n",
      "iteration 122 / 300: loss 0.631034\n",
      "iteration 122 / 300: loss 0.587515\n",
      "iteration 122 / 300: loss 0.606564\n",
      "iteration 122 / 300: loss 0.588036\n",
      "iteration 122 / 300: loss 0.600893\n",
      "iteration 122 / 300: loss 0.595960\n",
      "iteration 122 / 300: loss 0.589294\n",
      "iteration 122 / 300: loss 0.599529\n",
      "iteration 122 / 300: loss 0.604858\n",
      "iteration 122 / 300: loss 0.619416\n",
      "iteration 122 / 300: loss 0.588811\n",
      "iteration 122 / 300: loss 0.593648\n",
      "iteration 122 / 300: loss 0.585598\n",
      "iteration 122 / 300: loss 0.613215\n",
      "iteration 122 / 300: loss 0.587526\n",
      "iteration 122 / 300: loss 0.578331\n",
      "iteration 122 / 300: loss 0.567437\n",
      "iteration 122 / 300: loss 0.562237\n",
      "iteration 122 / 300: loss 0.594186\n",
      "iteration 122 / 300: loss 0.578823\n",
      "iteration 122 / 300: loss 0.586362\n",
      "iteration 122 / 300: loss 0.572892\n",
      "iteration 122 / 300: loss 0.596154\n",
      "iteration 122 / 300: loss 0.607953\n",
      "iteration 122 / 300: loss 0.610841\n",
      "iteration 122 / 300: loss 0.606268\n",
      "iteration 122 / 300: loss 0.583792\n",
      "iteration 122 / 300: loss 0.589628\n",
      "iteration 122 / 300: loss 0.595186\n",
      "iteration 122 / 300: loss 0.598957\n",
      "iteration 122 / 300: loss 0.596135\n",
      "iteration 122 / 300: loss 0.589771\n",
      "iteration 122 / 300: loss 0.591138\n",
      "iteration 122 / 300: loss 0.584856\n",
      "iteration 122 / 300: loss 0.599649\n",
      "iteration 122 / 300: loss 0.598904\n",
      "iteration 122 / 300: loss 0.614284\n",
      "iteration 122 / 300: loss 0.597799\n",
      "iteration 122 / 300: loss 0.599300\n",
      "iteration 122 / 300: loss 0.603320\n",
      "iteration 122 / 300: loss 0.592868\n",
      "iteration 122 / 300: loss 0.592393\n",
      "iteration 122 / 300: loss 0.589043\n",
      "iteration 122 / 300: loss 0.596448\n",
      "iteration 122 / 300: loss 0.605711\n",
      "iteration 122 / 300: loss 0.610564\n",
      "iteration 122 / 300: loss 0.587784\n",
      "iteration 122 / 300: loss 0.599353\n",
      "iteration 122 / 300: loss 0.602794\n",
      "iteration 122 / 300: loss 0.605031\n",
      "iteration 122 / 300: loss 0.603850\n",
      "iteration 122 / 300: loss 0.624146\n",
      "iteration 122 / 300: loss 0.587221\n",
      "iteration 122 / 300: loss 0.580757\n",
      "iteration 122 / 300: loss 0.625048\n",
      "iteration 122 / 300: loss 0.603312\n",
      "iteration 122 / 300: loss 0.604324\n",
      "iteration 122 / 300: loss 0.595479\n",
      "iteration 122 / 300: loss 0.597545\n",
      "iteration 122 / 300: loss 0.592743\n",
      "iteration 122 / 300: loss 0.589496\n",
      "iteration 122 / 300: loss 0.599267\n",
      "iteration 122 / 300: loss 0.611382\n",
      "iteration 122 / 300: loss 0.592465\n",
      "iteration 122 / 300: loss 0.599427\n",
      "iteration 122 / 300: loss 0.603103\n",
      "iteration 122 / 300: loss 0.602413\n",
      "iteration 122 / 300: loss 0.579814\n",
      "iteration 122 / 300: loss 0.601594\n",
      "iteration 123 / 300: loss 0.585530\n",
      "iteration 123 / 300: loss 0.588430\n",
      "iteration 123 / 300: loss 0.567518\n",
      "iteration 123 / 300: loss 0.592382\n",
      "iteration 123 / 300: loss 0.593620\n",
      "iteration 123 / 300: loss 0.595297\n",
      "iteration 123 / 300: loss 0.608786\n",
      "iteration 123 / 300: loss 0.592734\n",
      "iteration 123 / 300: loss 0.628063\n",
      "iteration 123 / 300: loss 0.580154\n",
      "iteration 123 / 300: loss 0.607925\n",
      "iteration 123 / 300: loss 0.587397\n",
      "iteration 123 / 300: loss 0.591688\n",
      "iteration 123 / 300: loss 0.571372\n",
      "iteration 123 / 300: loss 0.583027\n",
      "iteration 123 / 300: loss 0.608443\n",
      "iteration 123 / 300: loss 0.598361\n",
      "iteration 123 / 300: loss 0.583859\n",
      "iteration 123 / 300: loss 0.615255\n",
      "iteration 123 / 300: loss 0.591652\n",
      "iteration 123 / 300: loss 0.585501\n",
      "iteration 123 / 300: loss 0.591327\n",
      "iteration 123 / 300: loss 0.604343\n",
      "iteration 123 / 300: loss 0.595789\n",
      "iteration 123 / 300: loss 0.614951\n",
      "iteration 123 / 300: loss 0.608391\n",
      "iteration 123 / 300: loss 0.598225\n",
      "iteration 123 / 300: loss 0.588938\n",
      "iteration 123 / 300: loss 0.617759\n",
      "iteration 123 / 300: loss 0.594772\n",
      "iteration 123 / 300: loss 0.601687\n",
      "iteration 123 / 300: loss 0.631034\n",
      "iteration 123 / 300: loss 0.587515\n",
      "iteration 123 / 300: loss 0.606564\n",
      "iteration 123 / 300: loss 0.588036\n",
      "iteration 123 / 300: loss 0.600892\n",
      "iteration 123 / 300: loss 0.595960\n",
      "iteration 123 / 300: loss 0.589294\n",
      "iteration 123 / 300: loss 0.599528\n",
      "iteration 123 / 300: loss 0.604858\n",
      "iteration 123 / 300: loss 0.619416\n",
      "iteration 123 / 300: loss 0.588811\n",
      "iteration 123 / 300: loss 0.593647\n",
      "iteration 123 / 300: loss 0.585598\n",
      "iteration 123 / 300: loss 0.613214\n",
      "iteration 123 / 300: loss 0.587525\n",
      "iteration 123 / 300: loss 0.578331\n",
      "iteration 123 / 300: loss 0.567437\n",
      "iteration 123 / 300: loss 0.562237\n",
      "iteration 123 / 300: loss 0.594185\n",
      "iteration 123 / 300: loss 0.578823\n",
      "iteration 123 / 300: loss 0.586362\n",
      "iteration 123 / 300: loss 0.572892\n",
      "iteration 123 / 300: loss 0.596153\n",
      "iteration 123 / 300: loss 0.607952\n",
      "iteration 123 / 300: loss 0.610840\n",
      "iteration 123 / 300: loss 0.606268\n",
      "iteration 123 / 300: loss 0.583792\n",
      "iteration 123 / 300: loss 0.589628\n",
      "iteration 123 / 300: loss 0.595186\n",
      "iteration 123 / 300: loss 0.598956\n",
      "iteration 123 / 300: loss 0.596135\n",
      "iteration 123 / 300: loss 0.589771\n",
      "iteration 123 / 300: loss 0.591138\n",
      "iteration 123 / 300: loss 0.584856\n",
      "iteration 123 / 300: loss 0.599648\n",
      "iteration 123 / 300: loss 0.598904\n",
      "iteration 123 / 300: loss 0.614284\n",
      "iteration 123 / 300: loss 0.597798\n",
      "iteration 123 / 300: loss 0.599300\n",
      "iteration 123 / 300: loss 0.603319\n",
      "iteration 123 / 300: loss 0.592868\n",
      "iteration 123 / 300: loss 0.592393\n",
      "iteration 123 / 300: loss 0.589043\n",
      "iteration 123 / 300: loss 0.596448\n",
      "iteration 123 / 300: loss 0.605711\n",
      "iteration 123 / 300: loss 0.610564\n",
      "iteration 123 / 300: loss 0.587784\n",
      "iteration 123 / 300: loss 0.599353\n",
      "iteration 123 / 300: loss 0.602794\n",
      "iteration 123 / 300: loss 0.605030\n",
      "iteration 123 / 300: loss 0.603850\n",
      "iteration 123 / 300: loss 0.624146\n",
      "iteration 123 / 300: loss 0.587221\n",
      "iteration 123 / 300: loss 0.580756\n",
      "iteration 123 / 300: loss 0.625048\n",
      "iteration 123 / 300: loss 0.603312\n",
      "iteration 123 / 300: loss 0.604324\n",
      "iteration 123 / 300: loss 0.595478\n",
      "iteration 123 / 300: loss 0.597545\n",
      "iteration 123 / 300: loss 0.592742\n",
      "iteration 123 / 300: loss 0.589496\n",
      "iteration 123 / 300: loss 0.599266\n",
      "iteration 123 / 300: loss 0.611381\n",
      "iteration 123 / 300: loss 0.592465\n",
      "iteration 123 / 300: loss 0.599427\n",
      "iteration 123 / 300: loss 0.603103\n",
      "iteration 123 / 300: loss 0.602412\n",
      "iteration 123 / 300: loss 0.579813\n",
      "iteration 123 / 300: loss 0.601594\n",
      "iteration 124 / 300: loss 0.585530\n",
      "iteration 124 / 300: loss 0.588430\n",
      "iteration 124 / 300: loss 0.567518\n",
      "iteration 124 / 300: loss 0.592381\n",
      "iteration 124 / 300: loss 0.593620\n",
      "iteration 124 / 300: loss 0.595297\n",
      "iteration 124 / 300: loss 0.608786\n",
      "iteration 124 / 300: loss 0.592734\n",
      "iteration 124 / 300: loss 0.628062\n",
      "iteration 124 / 300: loss 0.580154\n",
      "iteration 124 / 300: loss 0.607925\n",
      "iteration 124 / 300: loss 0.587396\n",
      "iteration 124 / 300: loss 0.591688\n",
      "iteration 124 / 300: loss 0.571372\n",
      "iteration 124 / 300: loss 0.583027\n",
      "iteration 124 / 300: loss 0.608443\n",
      "iteration 124 / 300: loss 0.598361\n",
      "iteration 124 / 300: loss 0.583859\n",
      "iteration 124 / 300: loss 0.615255\n",
      "iteration 124 / 300: loss 0.591651\n",
      "iteration 124 / 300: loss 0.585501\n",
      "iteration 124 / 300: loss 0.591327\n",
      "iteration 124 / 300: loss 0.604343\n",
      "iteration 124 / 300: loss 0.595788\n",
      "iteration 124 / 300: loss 0.614951\n",
      "iteration 124 / 300: loss 0.608390\n",
      "iteration 124 / 300: loss 0.598224\n",
      "iteration 124 / 300: loss 0.588938\n",
      "iteration 124 / 300: loss 0.617759\n",
      "iteration 124 / 300: loss 0.594772\n",
      "iteration 124 / 300: loss 0.601687\n",
      "iteration 124 / 300: loss 0.631033\n",
      "iteration 124 / 300: loss 0.587515\n",
      "iteration 124 / 300: loss 0.606564\n",
      "iteration 124 / 300: loss 0.588036\n",
      "iteration 124 / 300: loss 0.600892\n",
      "iteration 124 / 300: loss 0.595960\n",
      "iteration 124 / 300: loss 0.589293\n",
      "iteration 124 / 300: loss 0.599528\n",
      "iteration 124 / 300: loss 0.604857\n",
      "iteration 124 / 300: loss 0.619416\n",
      "iteration 124 / 300: loss 0.588810\n",
      "iteration 124 / 300: loss 0.593647\n",
      "iteration 124 / 300: loss 0.585597\n",
      "iteration 124 / 300: loss 0.613214\n",
      "iteration 124 / 300: loss 0.587525\n",
      "iteration 124 / 300: loss 0.578330\n",
      "iteration 124 / 300: loss 0.567437\n",
      "iteration 124 / 300: loss 0.562237\n",
      "iteration 124 / 300: loss 0.594185\n",
      "iteration 124 / 300: loss 0.578823\n",
      "iteration 124 / 300: loss 0.586362\n",
      "iteration 124 / 300: loss 0.572892\n",
      "iteration 124 / 300: loss 0.596153\n",
      "iteration 124 / 300: loss 0.607952\n",
      "iteration 124 / 300: loss 0.610840\n",
      "iteration 124 / 300: loss 0.606268\n",
      "iteration 124 / 300: loss 0.583792\n",
      "iteration 124 / 300: loss 0.589628\n",
      "iteration 124 / 300: loss 0.595186\n",
      "iteration 124 / 300: loss 0.598956\n",
      "iteration 124 / 300: loss 0.596135\n",
      "iteration 124 / 300: loss 0.589771\n",
      "iteration 124 / 300: loss 0.591137\n",
      "iteration 124 / 300: loss 0.584856\n",
      "iteration 124 / 300: loss 0.599648\n",
      "iteration 124 / 300: loss 0.598904\n",
      "iteration 124 / 300: loss 0.614284\n",
      "iteration 124 / 300: loss 0.597798\n",
      "iteration 124 / 300: loss 0.599300\n",
      "iteration 124 / 300: loss 0.603319\n",
      "iteration 124 / 300: loss 0.592867\n",
      "iteration 124 / 300: loss 0.592393\n",
      "iteration 124 / 300: loss 0.589043\n",
      "iteration 124 / 300: loss 0.596448\n",
      "iteration 124 / 300: loss 0.605711\n",
      "iteration 124 / 300: loss 0.610564\n",
      "iteration 124 / 300: loss 0.587784\n",
      "iteration 124 / 300: loss 0.599352\n",
      "iteration 124 / 300: loss 0.602793\n",
      "iteration 124 / 300: loss 0.605030\n",
      "iteration 124 / 300: loss 0.603850\n",
      "iteration 124 / 300: loss 0.624145\n",
      "iteration 124 / 300: loss 0.587221\n",
      "iteration 124 / 300: loss 0.580756\n",
      "iteration 124 / 300: loss 0.625047\n",
      "iteration 124 / 300: loss 0.603312\n",
      "iteration 124 / 300: loss 0.604323\n",
      "iteration 124 / 300: loss 0.595478\n",
      "iteration 124 / 300: loss 0.597545\n",
      "iteration 124 / 300: loss 0.592742\n",
      "iteration 124 / 300: loss 0.589496\n",
      "iteration 124 / 300: loss 0.599266\n",
      "iteration 124 / 300: loss 0.611381\n",
      "iteration 124 / 300: loss 0.592465\n",
      "iteration 124 / 300: loss 0.599426\n",
      "iteration 124 / 300: loss 0.603103\n",
      "iteration 124 / 300: loss 0.602412\n",
      "iteration 124 / 300: loss 0.579813\n",
      "iteration 124 / 300: loss 0.601594\n",
      "iteration 125 / 300: loss 0.585529\n",
      "iteration 125 / 300: loss 0.588429\n",
      "iteration 125 / 300: loss 0.567518\n",
      "iteration 125 / 300: loss 0.592381\n",
      "iteration 125 / 300: loss 0.593620\n",
      "iteration 125 / 300: loss 0.595297\n",
      "iteration 125 / 300: loss 0.608785\n",
      "iteration 125 / 300: loss 0.592734\n",
      "iteration 125 / 300: loss 0.628062\n",
      "iteration 125 / 300: loss 0.580154\n",
      "iteration 125 / 300: loss 0.607925\n",
      "iteration 125 / 300: loss 0.587396\n",
      "iteration 125 / 300: loss 0.591688\n",
      "iteration 125 / 300: loss 0.571371\n",
      "iteration 125 / 300: loss 0.583026\n",
      "iteration 125 / 300: loss 0.608442\n",
      "iteration 125 / 300: loss 0.598361\n",
      "iteration 125 / 300: loss 0.583859\n",
      "iteration 125 / 300: loss 0.615254\n",
      "iteration 125 / 300: loss 0.591651\n",
      "iteration 125 / 300: loss 0.585501\n",
      "iteration 125 / 300: loss 0.591327\n",
      "iteration 125 / 300: loss 0.604343\n",
      "iteration 125 / 300: loss 0.595788\n",
      "iteration 125 / 300: loss 0.614951\n",
      "iteration 125 / 300: loss 0.608390\n",
      "iteration 125 / 300: loss 0.598224\n",
      "iteration 125 / 300: loss 0.588937\n",
      "iteration 125 / 300: loss 0.617759\n",
      "iteration 125 / 300: loss 0.594771\n",
      "iteration 125 / 300: loss 0.601686\n",
      "iteration 125 / 300: loss 0.631033\n",
      "iteration 125 / 300: loss 0.587515\n",
      "iteration 125 / 300: loss 0.606563\n",
      "iteration 125 / 300: loss 0.588036\n",
      "iteration 125 / 300: loss 0.600892\n",
      "iteration 125 / 300: loss 0.595960\n",
      "iteration 125 / 300: loss 0.589293\n",
      "iteration 125 / 300: loss 0.599528\n",
      "iteration 125 / 300: loss 0.604857\n",
      "iteration 125 / 300: loss 0.619416\n",
      "iteration 125 / 300: loss 0.588810\n",
      "iteration 125 / 300: loss 0.593647\n",
      "iteration 125 / 300: loss 0.585597\n",
      "iteration 125 / 300: loss 0.613214\n",
      "iteration 125 / 300: loss 0.587525\n",
      "iteration 125 / 300: loss 0.578330\n",
      "iteration 125 / 300: loss 0.567436\n",
      "iteration 125 / 300: loss 0.562237\n",
      "iteration 125 / 300: loss 0.594185\n",
      "iteration 125 / 300: loss 0.578823\n",
      "iteration 125 / 300: loss 0.586362\n",
      "iteration 125 / 300: loss 0.572892\n",
      "iteration 125 / 300: loss 0.596153\n",
      "iteration 125 / 300: loss 0.607952\n",
      "iteration 125 / 300: loss 0.610840\n",
      "iteration 125 / 300: loss 0.606267\n",
      "iteration 125 / 300: loss 0.583792\n",
      "iteration 125 / 300: loss 0.589628\n",
      "iteration 125 / 300: loss 0.595185\n",
      "iteration 125 / 300: loss 0.598956\n",
      "iteration 125 / 300: loss 0.596135\n",
      "iteration 125 / 300: loss 0.589771\n",
      "iteration 125 / 300: loss 0.591137\n",
      "iteration 125 / 300: loss 0.584856\n",
      "iteration 125 / 300: loss 0.599648\n",
      "iteration 125 / 300: loss 0.598903\n",
      "iteration 125 / 300: loss 0.614284\n",
      "iteration 125 / 300: loss 0.597798\n",
      "iteration 125 / 300: loss 0.599300\n",
      "iteration 125 / 300: loss 0.603319\n",
      "iteration 125 / 300: loss 0.592867\n",
      "iteration 125 / 300: loss 0.592393\n",
      "iteration 125 / 300: loss 0.589043\n",
      "iteration 125 / 300: loss 0.596448\n",
      "iteration 125 / 300: loss 0.605711\n",
      "iteration 125 / 300: loss 0.610563\n",
      "iteration 125 / 300: loss 0.587783\n",
      "iteration 125 / 300: loss 0.599352\n",
      "iteration 125 / 300: loss 0.602793\n",
      "iteration 125 / 300: loss 0.605030\n",
      "iteration 125 / 300: loss 0.603850\n",
      "iteration 125 / 300: loss 0.624145\n",
      "iteration 125 / 300: loss 0.587220\n",
      "iteration 125 / 300: loss 0.580756\n",
      "iteration 125 / 300: loss 0.625047\n",
      "iteration 125 / 300: loss 0.603312\n",
      "iteration 125 / 300: loss 0.604323\n",
      "iteration 125 / 300: loss 0.595478\n",
      "iteration 125 / 300: loss 0.597545\n",
      "iteration 125 / 300: loss 0.592742\n",
      "iteration 125 / 300: loss 0.589496\n",
      "iteration 125 / 300: loss 0.599266\n",
      "iteration 125 / 300: loss 0.611381\n",
      "iteration 125 / 300: loss 0.592465\n",
      "iteration 125 / 300: loss 0.599426\n",
      "iteration 125 / 300: loss 0.603102\n",
      "iteration 125 / 300: loss 0.602412\n",
      "iteration 125 / 300: loss 0.579813\n",
      "iteration 125 / 300: loss 0.601594\n",
      "iteration 126 / 300: loss 0.585529\n",
      "iteration 126 / 300: loss 0.588429\n",
      "iteration 126 / 300: loss 0.567518\n",
      "iteration 126 / 300: loss 0.592381\n",
      "iteration 126 / 300: loss 0.593620\n",
      "iteration 126 / 300: loss 0.595297\n",
      "iteration 126 / 300: loss 0.608785\n",
      "iteration 126 / 300: loss 0.592734\n",
      "iteration 126 / 300: loss 0.628062\n",
      "iteration 126 / 300: loss 0.580154\n",
      "iteration 126 / 300: loss 0.607925\n",
      "iteration 126 / 300: loss 0.587396\n",
      "iteration 126 / 300: loss 0.591688\n",
      "iteration 126 / 300: loss 0.571371\n",
      "iteration 126 / 300: loss 0.583026\n",
      "iteration 126 / 300: loss 0.608442\n",
      "iteration 126 / 300: loss 0.598360\n",
      "iteration 126 / 300: loss 0.583859\n",
      "iteration 126 / 300: loss 0.615254\n",
      "iteration 126 / 300: loss 0.591651\n",
      "iteration 126 / 300: loss 0.585501\n",
      "iteration 126 / 300: loss 0.591326\n",
      "iteration 126 / 300: loss 0.604342\n",
      "iteration 126 / 300: loss 0.595788\n",
      "iteration 126 / 300: loss 0.614951\n",
      "iteration 126 / 300: loss 0.608390\n",
      "iteration 126 / 300: loss 0.598224\n",
      "iteration 126 / 300: loss 0.588937\n",
      "iteration 126 / 300: loss 0.617758\n",
      "iteration 126 / 300: loss 0.594771\n",
      "iteration 126 / 300: loss 0.601686\n",
      "iteration 126 / 300: loss 0.631033\n",
      "iteration 126 / 300: loss 0.587514\n",
      "iteration 126 / 300: loss 0.606563\n",
      "iteration 126 / 300: loss 0.588036\n",
      "iteration 126 / 300: loss 0.600892\n",
      "iteration 126 / 300: loss 0.595959\n",
      "iteration 126 / 300: loss 0.589293\n",
      "iteration 126 / 300: loss 0.599528\n",
      "iteration 126 / 300: loss 0.604857\n",
      "iteration 126 / 300: loss 0.619415\n",
      "iteration 126 / 300: loss 0.588810\n",
      "iteration 126 / 300: loss 0.593647\n",
      "iteration 126 / 300: loss 0.585597\n",
      "iteration 126 / 300: loss 0.613214\n",
      "iteration 126 / 300: loss 0.587525\n",
      "iteration 126 / 300: loss 0.578330\n",
      "iteration 126 / 300: loss 0.567436\n",
      "iteration 126 / 300: loss 0.562236\n",
      "iteration 126 / 300: loss 0.594185\n",
      "iteration 126 / 300: loss 0.578822\n",
      "iteration 126 / 300: loss 0.586362\n",
      "iteration 126 / 300: loss 0.572891\n",
      "iteration 126 / 300: loss 0.596153\n",
      "iteration 126 / 300: loss 0.607952\n",
      "iteration 126 / 300: loss 0.610840\n",
      "iteration 126 / 300: loss 0.606267\n",
      "iteration 126 / 300: loss 0.583792\n",
      "iteration 126 / 300: loss 0.589628\n",
      "iteration 126 / 300: loss 0.595185\n",
      "iteration 126 / 300: loss 0.598956\n",
      "iteration 126 / 300: loss 0.596135\n",
      "iteration 126 / 300: loss 0.589771\n",
      "iteration 126 / 300: loss 0.591137\n",
      "iteration 126 / 300: loss 0.584855\n",
      "iteration 126 / 300: loss 0.599648\n",
      "iteration 126 / 300: loss 0.598903\n",
      "iteration 126 / 300: loss 0.614284\n",
      "iteration 126 / 300: loss 0.597798\n",
      "iteration 126 / 300: loss 0.599300\n",
      "iteration 126 / 300: loss 0.603319\n",
      "iteration 126 / 300: loss 0.592867\n",
      "iteration 126 / 300: loss 0.592393\n",
      "iteration 126 / 300: loss 0.589043\n",
      "iteration 126 / 300: loss 0.596447\n",
      "iteration 126 / 300: loss 0.605711\n",
      "iteration 126 / 300: loss 0.610563\n",
      "iteration 126 / 300: loss 0.587783\n",
      "iteration 126 / 300: loss 0.599352\n",
      "iteration 126 / 300: loss 0.602793\n",
      "iteration 126 / 300: loss 0.605030\n",
      "iteration 126 / 300: loss 0.603849\n",
      "iteration 126 / 300: loss 0.624145\n",
      "iteration 126 / 300: loss 0.587220\n",
      "iteration 126 / 300: loss 0.580756\n",
      "iteration 126 / 300: loss 0.625047\n",
      "iteration 126 / 300: loss 0.603311\n",
      "iteration 126 / 300: loss 0.604323\n",
      "iteration 126 / 300: loss 0.595478\n",
      "iteration 126 / 300: loss 0.597545\n",
      "iteration 126 / 300: loss 0.592742\n",
      "iteration 126 / 300: loss 0.589495\n",
      "iteration 126 / 300: loss 0.599266\n",
      "iteration 126 / 300: loss 0.611381\n",
      "iteration 126 / 300: loss 0.592464\n",
      "iteration 126 / 300: loss 0.599426\n",
      "iteration 126 / 300: loss 0.603102\n",
      "iteration 126 / 300: loss 0.602412\n",
      "iteration 126 / 300: loss 0.579813\n",
      "iteration 126 / 300: loss 0.601594\n",
      "iteration 127 / 300: loss 0.585529\n",
      "iteration 127 / 300: loss 0.588429\n",
      "iteration 127 / 300: loss 0.567518\n",
      "iteration 127 / 300: loss 0.592381\n",
      "iteration 127 / 300: loss 0.593619\n",
      "iteration 127 / 300: loss 0.595297\n",
      "iteration 127 / 300: loss 0.608785\n",
      "iteration 127 / 300: loss 0.592733\n",
      "iteration 127 / 300: loss 0.628062\n",
      "iteration 127 / 300: loss 0.580153\n",
      "iteration 127 / 300: loss 0.607925\n",
      "iteration 127 / 300: loss 0.587396\n",
      "iteration 127 / 300: loss 0.591688\n",
      "iteration 127 / 300: loss 0.571371\n",
      "iteration 127 / 300: loss 0.583026\n",
      "iteration 127 / 300: loss 0.608442\n",
      "iteration 127 / 300: loss 0.598360\n",
      "iteration 127 / 300: loss 0.583859\n",
      "iteration 127 / 300: loss 0.615254\n",
      "iteration 127 / 300: loss 0.591651\n",
      "iteration 127 / 300: loss 0.585501\n",
      "iteration 127 / 300: loss 0.591326\n",
      "iteration 127 / 300: loss 0.604342\n",
      "iteration 127 / 300: loss 0.595788\n",
      "iteration 127 / 300: loss 0.614950\n",
      "iteration 127 / 300: loss 0.608390\n",
      "iteration 127 / 300: loss 0.598224\n",
      "iteration 127 / 300: loss 0.588937\n",
      "iteration 127 / 300: loss 0.617758\n",
      "iteration 127 / 300: loss 0.594771\n",
      "iteration 127 / 300: loss 0.601686\n",
      "iteration 127 / 300: loss 0.631033\n",
      "iteration 127 / 300: loss 0.587514\n",
      "iteration 127 / 300: loss 0.606563\n",
      "iteration 127 / 300: loss 0.588035\n",
      "iteration 127 / 300: loss 0.600891\n",
      "iteration 127 / 300: loss 0.595959\n",
      "iteration 127 / 300: loss 0.589293\n",
      "iteration 127 / 300: loss 0.599527\n",
      "iteration 127 / 300: loss 0.604857\n",
      "iteration 127 / 300: loss 0.619415\n",
      "iteration 127 / 300: loss 0.588810\n",
      "iteration 127 / 300: loss 0.593646\n",
      "iteration 127 / 300: loss 0.585597\n",
      "iteration 127 / 300: loss 0.613214\n",
      "iteration 127 / 300: loss 0.587525\n",
      "iteration 127 / 300: loss 0.578330\n",
      "iteration 127 / 300: loss 0.567436\n",
      "iteration 127 / 300: loss 0.562236\n",
      "iteration 127 / 300: loss 0.594185\n",
      "iteration 127 / 300: loss 0.578822\n",
      "iteration 127 / 300: loss 0.586361\n",
      "iteration 127 / 300: loss 0.572891\n",
      "iteration 127 / 300: loss 0.596153\n",
      "iteration 127 / 300: loss 0.607952\n",
      "iteration 127 / 300: loss 0.610840\n",
      "iteration 127 / 300: loss 0.606267\n",
      "iteration 127 / 300: loss 0.583791\n",
      "iteration 127 / 300: loss 0.589628\n",
      "iteration 127 / 300: loss 0.595185\n",
      "iteration 127 / 300: loss 0.598956\n",
      "iteration 127 / 300: loss 0.596134\n",
      "iteration 127 / 300: loss 0.589771\n",
      "iteration 127 / 300: loss 0.591137\n",
      "iteration 127 / 300: loss 0.584855\n",
      "iteration 127 / 300: loss 0.599648\n",
      "iteration 127 / 300: loss 0.598903\n",
      "iteration 127 / 300: loss 0.614284\n",
      "iteration 127 / 300: loss 0.597798\n",
      "iteration 127 / 300: loss 0.599300\n",
      "iteration 127 / 300: loss 0.603319\n",
      "iteration 127 / 300: loss 0.592867\n",
      "iteration 127 / 300: loss 0.592392\n",
      "iteration 127 / 300: loss 0.589042\n",
      "iteration 127 / 300: loss 0.596447\n",
      "iteration 127 / 300: loss 0.605710\n",
      "iteration 127 / 300: loss 0.610563\n",
      "iteration 127 / 300: loss 0.587783\n",
      "iteration 127 / 300: loss 0.599352\n",
      "iteration 127 / 300: loss 0.602793\n",
      "iteration 127 / 300: loss 0.605030\n",
      "iteration 127 / 300: loss 0.603849\n",
      "iteration 127 / 300: loss 0.624145\n",
      "iteration 127 / 300: loss 0.587220\n",
      "iteration 127 / 300: loss 0.580756\n",
      "iteration 127 / 300: loss 0.625047\n",
      "iteration 127 / 300: loss 0.603311\n",
      "iteration 127 / 300: loss 0.604323\n",
      "iteration 127 / 300: loss 0.595478\n",
      "iteration 127 / 300: loss 0.597544\n",
      "iteration 127 / 300: loss 0.592742\n",
      "iteration 127 / 300: loss 0.589495\n",
      "iteration 127 / 300: loss 0.599266\n",
      "iteration 127 / 300: loss 0.611381\n",
      "iteration 127 / 300: loss 0.592464\n",
      "iteration 127 / 300: loss 0.599426\n",
      "iteration 127 / 300: loss 0.603102\n",
      "iteration 127 / 300: loss 0.602412\n",
      "iteration 127 / 300: loss 0.579813\n",
      "iteration 127 / 300: loss 0.601593\n",
      "iteration 128 / 300: loss 0.585529\n",
      "iteration 128 / 300: loss 0.588429\n",
      "iteration 128 / 300: loss 0.567518\n",
      "iteration 128 / 300: loss 0.592381\n",
      "iteration 128 / 300: loss 0.593619\n",
      "iteration 128 / 300: loss 0.595297\n",
      "iteration 128 / 300: loss 0.608785\n",
      "iteration 128 / 300: loss 0.592733\n",
      "iteration 128 / 300: loss 0.628062\n",
      "iteration 128 / 300: loss 0.580153\n",
      "iteration 128 / 300: loss 0.607924\n",
      "iteration 128 / 300: loss 0.587396\n",
      "iteration 128 / 300: loss 0.591687\n",
      "iteration 128 / 300: loss 0.571371\n",
      "iteration 128 / 300: loss 0.583026\n",
      "iteration 128 / 300: loss 0.608442\n",
      "iteration 128 / 300: loss 0.598360\n",
      "iteration 128 / 300: loss 0.583859\n",
      "iteration 128 / 300: loss 0.615254\n",
      "iteration 128 / 300: loss 0.591651\n",
      "iteration 128 / 300: loss 0.585500\n",
      "iteration 128 / 300: loss 0.591326\n",
      "iteration 128 / 300: loss 0.604342\n",
      "iteration 128 / 300: loss 0.595788\n",
      "iteration 128 / 300: loss 0.614950\n",
      "iteration 128 / 300: loss 0.608390\n",
      "iteration 128 / 300: loss 0.598224\n",
      "iteration 128 / 300: loss 0.588937\n",
      "iteration 128 / 300: loss 0.617758\n",
      "iteration 128 / 300: loss 0.594771\n",
      "iteration 128 / 300: loss 0.601686\n",
      "iteration 128 / 300: loss 0.631033\n",
      "iteration 128 / 300: loss 0.587514\n",
      "iteration 128 / 300: loss 0.606563\n",
      "iteration 128 / 300: loss 0.588035\n",
      "iteration 128 / 300: loss 0.600891\n",
      "iteration 128 / 300: loss 0.595959\n",
      "iteration 128 / 300: loss 0.589292\n",
      "iteration 128 / 300: loss 0.599527\n",
      "iteration 128 / 300: loss 0.604857\n",
      "iteration 128 / 300: loss 0.619415\n",
      "iteration 128 / 300: loss 0.588810\n",
      "iteration 128 / 300: loss 0.593646\n",
      "iteration 128 / 300: loss 0.585597\n",
      "iteration 128 / 300: loss 0.613214\n",
      "iteration 128 / 300: loss 0.587525\n",
      "iteration 128 / 300: loss 0.578330\n",
      "iteration 128 / 300: loss 0.567436\n",
      "iteration 128 / 300: loss 0.562236\n",
      "iteration 128 / 300: loss 0.594185\n",
      "iteration 128 / 300: loss 0.578822\n",
      "iteration 128 / 300: loss 0.586361\n",
      "iteration 128 / 300: loss 0.572891\n",
      "iteration 128 / 300: loss 0.596152\n",
      "iteration 128 / 300: loss 0.607952\n",
      "iteration 128 / 300: loss 0.610840\n",
      "iteration 128 / 300: loss 0.606267\n",
      "iteration 128 / 300: loss 0.583791\n",
      "iteration 128 / 300: loss 0.589628\n",
      "iteration 128 / 300: loss 0.595185\n",
      "iteration 128 / 300: loss 0.598956\n",
      "iteration 128 / 300: loss 0.596134\n",
      "iteration 128 / 300: loss 0.589770\n",
      "iteration 128 / 300: loss 0.591137\n",
      "iteration 128 / 300: loss 0.584855\n",
      "iteration 128 / 300: loss 0.599648\n",
      "iteration 128 / 300: loss 0.598903\n",
      "iteration 128 / 300: loss 0.614283\n",
      "iteration 128 / 300: loss 0.597798\n",
      "iteration 128 / 300: loss 0.599299\n",
      "iteration 128 / 300: loss 0.603319\n",
      "iteration 128 / 300: loss 0.592867\n",
      "iteration 128 / 300: loss 0.592392\n",
      "iteration 128 / 300: loss 0.589042\n",
      "iteration 128 / 300: loss 0.596447\n",
      "iteration 128 / 300: loss 0.605710\n",
      "iteration 128 / 300: loss 0.610563\n",
      "iteration 128 / 300: loss 0.587783\n",
      "iteration 128 / 300: loss 0.599352\n",
      "iteration 128 / 300: loss 0.602793\n",
      "iteration 128 / 300: loss 0.605029\n",
      "iteration 128 / 300: loss 0.603849\n",
      "iteration 128 / 300: loss 0.624145\n",
      "iteration 128 / 300: loss 0.587220\n",
      "iteration 128 / 300: loss 0.580756\n",
      "iteration 128 / 300: loss 0.625047\n",
      "iteration 128 / 300: loss 0.603311\n",
      "iteration 128 / 300: loss 0.604323\n",
      "iteration 128 / 300: loss 0.595477\n",
      "iteration 128 / 300: loss 0.597544\n",
      "iteration 128 / 300: loss 0.592741\n",
      "iteration 128 / 300: loss 0.589495\n",
      "iteration 128 / 300: loss 0.599265\n",
      "iteration 128 / 300: loss 0.611381\n",
      "iteration 128 / 300: loss 0.592464\n",
      "iteration 128 / 300: loss 0.599426\n",
      "iteration 128 / 300: loss 0.603102\n",
      "iteration 128 / 300: loss 0.602412\n",
      "iteration 128 / 300: loss 0.579813\n",
      "iteration 128 / 300: loss 0.601593\n",
      "iteration 129 / 300: loss 0.585529\n",
      "iteration 129 / 300: loss 0.588429\n",
      "iteration 129 / 300: loss 0.567517\n",
      "iteration 129 / 300: loss 0.592381\n",
      "iteration 129 / 300: loss 0.593619\n",
      "iteration 129 / 300: loss 0.595296\n",
      "iteration 129 / 300: loss 0.608785\n",
      "iteration 129 / 300: loss 0.592733\n",
      "iteration 129 / 300: loss 0.628062\n",
      "iteration 129 / 300: loss 0.580153\n",
      "iteration 129 / 300: loss 0.607924\n",
      "iteration 129 / 300: loss 0.587396\n",
      "iteration 129 / 300: loss 0.591687\n",
      "iteration 129 / 300: loss 0.571371\n",
      "iteration 129 / 300: loss 0.583026\n",
      "iteration 129 / 300: loss 0.608442\n",
      "iteration 129 / 300: loss 0.598360\n",
      "iteration 129 / 300: loss 0.583859\n",
      "iteration 129 / 300: loss 0.615254\n",
      "iteration 129 / 300: loss 0.591651\n",
      "iteration 129 / 300: loss 0.585500\n",
      "iteration 129 / 300: loss 0.591326\n",
      "iteration 129 / 300: loss 0.604342\n",
      "iteration 129 / 300: loss 0.595788\n",
      "iteration 129 / 300: loss 0.614950\n",
      "iteration 129 / 300: loss 0.608390\n",
      "iteration 129 / 300: loss 0.598224\n",
      "iteration 129 / 300: loss 0.588937\n",
      "iteration 129 / 300: loss 0.617758\n",
      "iteration 129 / 300: loss 0.594771\n",
      "iteration 129 / 300: loss 0.601686\n",
      "iteration 129 / 300: loss 0.631032\n",
      "iteration 129 / 300: loss 0.587514\n",
      "iteration 129 / 300: loss 0.606563\n",
      "iteration 129 / 300: loss 0.588035\n",
      "iteration 129 / 300: loss 0.600891\n",
      "iteration 129 / 300: loss 0.595959\n",
      "iteration 129 / 300: loss 0.589292\n",
      "iteration 129 / 300: loss 0.599527\n",
      "iteration 129 / 300: loss 0.604857\n",
      "iteration 129 / 300: loss 0.619415\n",
      "iteration 129 / 300: loss 0.588809\n",
      "iteration 129 / 300: loss 0.593646\n",
      "iteration 129 / 300: loss 0.585596\n",
      "iteration 129 / 300: loss 0.613214\n",
      "iteration 129 / 300: loss 0.587524\n",
      "iteration 129 / 300: loss 0.578329\n",
      "iteration 129 / 300: loss 0.567436\n",
      "iteration 129 / 300: loss 0.562236\n",
      "iteration 129 / 300: loss 0.594184\n",
      "iteration 129 / 300: loss 0.578822\n",
      "iteration 129 / 300: loss 0.586361\n",
      "iteration 129 / 300: loss 0.572891\n",
      "iteration 129 / 300: loss 0.596152\n",
      "iteration 129 / 300: loss 0.607952\n",
      "iteration 129 / 300: loss 0.610840\n",
      "iteration 129 / 300: loss 0.606267\n",
      "iteration 129 / 300: loss 0.583791\n",
      "iteration 129 / 300: loss 0.589627\n",
      "iteration 129 / 300: loss 0.595185\n",
      "iteration 129 / 300: loss 0.598956\n",
      "iteration 129 / 300: loss 0.596134\n",
      "iteration 129 / 300: loss 0.589770\n",
      "iteration 129 / 300: loss 0.591137\n",
      "iteration 129 / 300: loss 0.584855\n",
      "iteration 129 / 300: loss 0.599648\n",
      "iteration 129 / 300: loss 0.598903\n",
      "iteration 129 / 300: loss 0.614283\n",
      "iteration 129 / 300: loss 0.597797\n",
      "iteration 129 / 300: loss 0.599299\n",
      "iteration 129 / 300: loss 0.603318\n",
      "iteration 129 / 300: loss 0.592867\n",
      "iteration 129 / 300: loss 0.592392\n",
      "iteration 129 / 300: loss 0.589042\n",
      "iteration 129 / 300: loss 0.596447\n",
      "iteration 129 / 300: loss 0.605710\n",
      "iteration 129 / 300: loss 0.610563\n",
      "iteration 129 / 300: loss 0.587783\n",
      "iteration 129 / 300: loss 0.599352\n",
      "iteration 129 / 300: loss 0.602793\n",
      "iteration 129 / 300: loss 0.605029\n",
      "iteration 129 / 300: loss 0.603849\n",
      "iteration 129 / 300: loss 0.624145\n",
      "iteration 129 / 300: loss 0.587220\n",
      "iteration 129 / 300: loss 0.580755\n",
      "iteration 129 / 300: loss 0.625047\n",
      "iteration 129 / 300: loss 0.603311\n",
      "iteration 129 / 300: loss 0.604323\n",
      "iteration 129 / 300: loss 0.595477\n",
      "iteration 129 / 300: loss 0.597544\n",
      "iteration 129 / 300: loss 0.592741\n",
      "iteration 129 / 300: loss 0.589495\n",
      "iteration 129 / 300: loss 0.599265\n",
      "iteration 129 / 300: loss 0.611381\n",
      "iteration 129 / 300: loss 0.592464\n",
      "iteration 129 / 300: loss 0.599426\n",
      "iteration 129 / 300: loss 0.603102\n",
      "iteration 129 / 300: loss 0.602411\n",
      "iteration 129 / 300: loss 0.579813\n",
      "iteration 129 / 300: loss 0.601593\n",
      "iteration 130 / 300: loss 0.585529\n",
      "iteration 130 / 300: loss 0.588429\n",
      "iteration 130 / 300: loss 0.567517\n",
      "iteration 130 / 300: loss 0.592381\n",
      "iteration 130 / 300: loss 0.593619\n",
      "iteration 130 / 300: loss 0.595296\n",
      "iteration 130 / 300: loss 0.608785\n",
      "iteration 130 / 300: loss 0.592733\n",
      "iteration 130 / 300: loss 0.628061\n",
      "iteration 130 / 300: loss 0.580153\n",
      "iteration 130 / 300: loss 0.607924\n",
      "iteration 130 / 300: loss 0.587396\n",
      "iteration 130 / 300: loss 0.591687\n",
      "iteration 130 / 300: loss 0.571371\n",
      "iteration 130 / 300: loss 0.583026\n",
      "iteration 130 / 300: loss 0.608442\n",
      "iteration 130 / 300: loss 0.598360\n",
      "iteration 130 / 300: loss 0.583859\n",
      "iteration 130 / 300: loss 0.615254\n",
      "iteration 130 / 300: loss 0.591650\n",
      "iteration 130 / 300: loss 0.585500\n",
      "iteration 130 / 300: loss 0.591326\n",
      "iteration 130 / 300: loss 0.604342\n",
      "iteration 130 / 300: loss 0.595787\n",
      "iteration 130 / 300: loss 0.614950\n",
      "iteration 130 / 300: loss 0.608390\n",
      "iteration 130 / 300: loss 0.598223\n",
      "iteration 130 / 300: loss 0.588937\n",
      "iteration 130 / 300: loss 0.617758\n",
      "iteration 130 / 300: loss 0.594771\n",
      "iteration 130 / 300: loss 0.601686\n",
      "iteration 130 / 300: loss 0.631032\n",
      "iteration 130 / 300: loss 0.587514\n",
      "iteration 130 / 300: loss 0.606563\n",
      "iteration 130 / 300: loss 0.588035\n",
      "iteration 130 / 300: loss 0.600891\n",
      "iteration 130 / 300: loss 0.595959\n",
      "iteration 130 / 300: loss 0.589292\n",
      "iteration 130 / 300: loss 0.599527\n",
      "iteration 130 / 300: loss 0.604856\n",
      "iteration 130 / 300: loss 0.619415\n",
      "iteration 130 / 300: loss 0.588809\n",
      "iteration 130 / 300: loss 0.593646\n",
      "iteration 130 / 300: loss 0.585596\n",
      "iteration 130 / 300: loss 0.613213\n",
      "iteration 130 / 300: loss 0.587524\n",
      "iteration 130 / 300: loss 0.578329\n",
      "iteration 130 / 300: loss 0.567436\n",
      "iteration 130 / 300: loss 0.562236\n",
      "iteration 130 / 300: loss 0.594184\n",
      "iteration 130 / 300: loss 0.578822\n",
      "iteration 130 / 300: loss 0.586361\n",
      "iteration 130 / 300: loss 0.572891\n",
      "iteration 130 / 300: loss 0.596152\n",
      "iteration 130 / 300: loss 0.607952\n",
      "iteration 130 / 300: loss 0.610840\n",
      "iteration 130 / 300: loss 0.606267\n",
      "iteration 130 / 300: loss 0.583791\n",
      "iteration 130 / 300: loss 0.589627\n",
      "iteration 130 / 300: loss 0.595185\n",
      "iteration 130 / 300: loss 0.598956\n",
      "iteration 130 / 300: loss 0.596134\n",
      "iteration 130 / 300: loss 0.589770\n",
      "iteration 130 / 300: loss 0.591137\n",
      "iteration 130 / 300: loss 0.584855\n",
      "iteration 130 / 300: loss 0.599647\n",
      "iteration 130 / 300: loss 0.598903\n",
      "iteration 130 / 300: loss 0.614283\n",
      "iteration 130 / 300: loss 0.597797\n",
      "iteration 130 / 300: loss 0.599299\n",
      "iteration 130 / 300: loss 0.603318\n",
      "iteration 130 / 300: loss 0.592867\n",
      "iteration 130 / 300: loss 0.592392\n",
      "iteration 130 / 300: loss 0.589042\n",
      "iteration 130 / 300: loss 0.596447\n",
      "iteration 130 / 300: loss 0.605710\n",
      "iteration 130 / 300: loss 0.610563\n",
      "iteration 130 / 300: loss 0.587783\n",
      "iteration 130 / 300: loss 0.599352\n",
      "iteration 130 / 300: loss 0.602793\n",
      "iteration 130 / 300: loss 0.605029\n",
      "iteration 130 / 300: loss 0.603849\n",
      "iteration 130 / 300: loss 0.624145\n",
      "iteration 130 / 300: loss 0.587220\n",
      "iteration 130 / 300: loss 0.580755\n",
      "iteration 130 / 300: loss 0.625047\n",
      "iteration 130 / 300: loss 0.603311\n",
      "iteration 130 / 300: loss 0.604323\n",
      "iteration 130 / 300: loss 0.595477\n",
      "iteration 130 / 300: loss 0.597544\n",
      "iteration 130 / 300: loss 0.592741\n",
      "iteration 130 / 300: loss 0.589495\n",
      "iteration 130 / 300: loss 0.599265\n",
      "iteration 130 / 300: loss 0.611380\n",
      "iteration 130 / 300: loss 0.592464\n",
      "iteration 130 / 300: loss 0.599426\n",
      "iteration 130 / 300: loss 0.603102\n",
      "iteration 130 / 300: loss 0.602411\n",
      "iteration 130 / 300: loss 0.579812\n",
      "iteration 130 / 300: loss 0.601593\n",
      "iteration 131 / 300: loss 0.585529\n",
      "iteration 131 / 300: loss 0.588429\n",
      "iteration 131 / 300: loss 0.567517\n",
      "iteration 131 / 300: loss 0.592380\n",
      "iteration 131 / 300: loss 0.593619\n",
      "iteration 131 / 300: loss 0.595296\n",
      "iteration 131 / 300: loss 0.608785\n",
      "iteration 131 / 300: loss 0.592733\n",
      "iteration 131 / 300: loss 0.628061\n",
      "iteration 131 / 300: loss 0.580153\n",
      "iteration 131 / 300: loss 0.607924\n",
      "iteration 131 / 300: loss 0.587395\n",
      "iteration 131 / 300: loss 0.591687\n",
      "iteration 131 / 300: loss 0.571371\n",
      "iteration 131 / 300: loss 0.583026\n",
      "iteration 131 / 300: loss 0.608442\n",
      "iteration 131 / 300: loss 0.598360\n",
      "iteration 131 / 300: loss 0.583858\n",
      "iteration 131 / 300: loss 0.615254\n",
      "iteration 131 / 300: loss 0.591650\n",
      "iteration 131 / 300: loss 0.585500\n",
      "iteration 131 / 300: loss 0.591326\n",
      "iteration 131 / 300: loss 0.604342\n",
      "iteration 131 / 300: loss 0.595787\n",
      "iteration 131 / 300: loss 0.614950\n",
      "iteration 131 / 300: loss 0.608390\n",
      "iteration 131 / 300: loss 0.598223\n",
      "iteration 131 / 300: loss 0.588937\n",
      "iteration 131 / 300: loss 0.617758\n",
      "iteration 131 / 300: loss 0.594771\n",
      "iteration 131 / 300: loss 0.601685\n",
      "iteration 131 / 300: loss 0.631032\n",
      "iteration 131 / 300: loss 0.587514\n",
      "iteration 131 / 300: loss 0.606562\n",
      "iteration 131 / 300: loss 0.588035\n",
      "iteration 131 / 300: loss 0.600891\n",
      "iteration 131 / 300: loss 0.595959\n",
      "iteration 131 / 300: loss 0.589292\n",
      "iteration 131 / 300: loss 0.599527\n",
      "iteration 131 / 300: loss 0.604856\n",
      "iteration 131 / 300: loss 0.619415\n",
      "iteration 131 / 300: loss 0.588809\n",
      "iteration 131 / 300: loss 0.593646\n",
      "iteration 131 / 300: loss 0.585596\n",
      "iteration 131 / 300: loss 0.613213\n",
      "iteration 131 / 300: loss 0.587524\n",
      "iteration 131 / 300: loss 0.578329\n",
      "iteration 131 / 300: loss 0.567436\n",
      "iteration 131 / 300: loss 0.562236\n",
      "iteration 131 / 300: loss 0.594184\n",
      "iteration 131 / 300: loss 0.578822\n",
      "iteration 131 / 300: loss 0.586361\n",
      "iteration 131 / 300: loss 0.572891\n",
      "iteration 131 / 300: loss 0.596152\n",
      "iteration 131 / 300: loss 0.607951\n",
      "iteration 131 / 300: loss 0.610840\n",
      "iteration 131 / 300: loss 0.606266\n",
      "iteration 131 / 300: loss 0.583791\n",
      "iteration 131 / 300: loss 0.589627\n",
      "iteration 131 / 300: loss 0.595185\n",
      "iteration 131 / 300: loss 0.598955\n",
      "iteration 131 / 300: loss 0.596134\n",
      "iteration 131 / 300: loss 0.589770\n",
      "iteration 131 / 300: loss 0.591137\n",
      "iteration 131 / 300: loss 0.584855\n",
      "iteration 131 / 300: loss 0.599647\n",
      "iteration 131 / 300: loss 0.598903\n",
      "iteration 131 / 300: loss 0.614283\n",
      "iteration 131 / 300: loss 0.597797\n",
      "iteration 131 / 300: loss 0.599299\n",
      "iteration 131 / 300: loss 0.603318\n",
      "iteration 131 / 300: loss 0.592866\n",
      "iteration 131 / 300: loss 0.592392\n",
      "iteration 131 / 300: loss 0.589042\n",
      "iteration 131 / 300: loss 0.596447\n",
      "iteration 131 / 300: loss 0.605710\n",
      "iteration 131 / 300: loss 0.610563\n",
      "iteration 131 / 300: loss 0.587783\n",
      "iteration 131 / 300: loss 0.599352\n",
      "iteration 131 / 300: loss 0.602793\n",
      "iteration 131 / 300: loss 0.605029\n",
      "iteration 131 / 300: loss 0.603849\n",
      "iteration 131 / 300: loss 0.624145\n",
      "iteration 131 / 300: loss 0.587220\n",
      "iteration 131 / 300: loss 0.580755\n",
      "iteration 131 / 300: loss 0.625046\n",
      "iteration 131 / 300: loss 0.603311\n",
      "iteration 131 / 300: loss 0.604322\n",
      "iteration 131 / 300: loss 0.595477\n",
      "iteration 131 / 300: loss 0.597544\n",
      "iteration 131 / 300: loss 0.592741\n",
      "iteration 131 / 300: loss 0.589495\n",
      "iteration 131 / 300: loss 0.599265\n",
      "iteration 131 / 300: loss 0.611380\n",
      "iteration 131 / 300: loss 0.592464\n",
      "iteration 131 / 300: loss 0.599425\n",
      "iteration 131 / 300: loss 0.603102\n",
      "iteration 131 / 300: loss 0.602411\n",
      "iteration 131 / 300: loss 0.579812\n",
      "iteration 131 / 300: loss 0.601593\n",
      "iteration 132 / 300: loss 0.585529\n",
      "iteration 132 / 300: loss 0.588429\n",
      "iteration 132 / 300: loss 0.567517\n",
      "iteration 132 / 300: loss 0.592380\n",
      "iteration 132 / 300: loss 0.593619\n",
      "iteration 132 / 300: loss 0.595296\n",
      "iteration 132 / 300: loss 0.608785\n",
      "iteration 132 / 300: loss 0.592733\n",
      "iteration 132 / 300: loss 0.628061\n",
      "iteration 132 / 300: loss 0.580153\n",
      "iteration 132 / 300: loss 0.607924\n",
      "iteration 132 / 300: loss 0.587395\n",
      "iteration 132 / 300: loss 0.591687\n",
      "iteration 132 / 300: loss 0.571371\n",
      "iteration 132 / 300: loss 0.583026\n",
      "iteration 132 / 300: loss 0.608442\n",
      "iteration 132 / 300: loss 0.598360\n",
      "iteration 132 / 300: loss 0.583858\n",
      "iteration 132 / 300: loss 0.615254\n",
      "iteration 132 / 300: loss 0.591650\n",
      "iteration 132 / 300: loss 0.585500\n",
      "iteration 132 / 300: loss 0.591326\n",
      "iteration 132 / 300: loss 0.604342\n",
      "iteration 132 / 300: loss 0.595787\n",
      "iteration 132 / 300: loss 0.614950\n",
      "iteration 132 / 300: loss 0.608389\n",
      "iteration 132 / 300: loss 0.598223\n",
      "iteration 132 / 300: loss 0.588937\n",
      "iteration 132 / 300: loss 0.617758\n",
      "iteration 132 / 300: loss 0.594770\n",
      "iteration 132 / 300: loss 0.601685\n",
      "iteration 132 / 300: loss 0.631032\n",
      "iteration 132 / 300: loss 0.587514\n",
      "iteration 132 / 300: loss 0.606562\n",
      "iteration 132 / 300: loss 0.588035\n",
      "iteration 132 / 300: loss 0.600891\n",
      "iteration 132 / 300: loss 0.595959\n",
      "iteration 132 / 300: loss 0.589292\n",
      "iteration 132 / 300: loss 0.599527\n",
      "iteration 132 / 300: loss 0.604856\n",
      "iteration 132 / 300: loss 0.619415\n",
      "iteration 132 / 300: loss 0.588809\n",
      "iteration 132 / 300: loss 0.593646\n",
      "iteration 132 / 300: loss 0.585596\n",
      "iteration 132 / 300: loss 0.613213\n",
      "iteration 132 / 300: loss 0.587524\n",
      "iteration 132 / 300: loss 0.578329\n",
      "iteration 132 / 300: loss 0.567435\n",
      "iteration 132 / 300: loss 0.562236\n",
      "iteration 132 / 300: loss 0.594184\n",
      "iteration 132 / 300: loss 0.578822\n",
      "iteration 132 / 300: loss 0.586361\n",
      "iteration 132 / 300: loss 0.572891\n",
      "iteration 132 / 300: loss 0.596152\n",
      "iteration 132 / 300: loss 0.607951\n",
      "iteration 132 / 300: loss 0.610840\n",
      "iteration 132 / 300: loss 0.606266\n",
      "iteration 132 / 300: loss 0.583791\n",
      "iteration 132 / 300: loss 0.589627\n",
      "iteration 132 / 300: loss 0.595185\n",
      "iteration 132 / 300: loss 0.598955\n",
      "iteration 132 / 300: loss 0.596134\n",
      "iteration 132 / 300: loss 0.589770\n",
      "iteration 132 / 300: loss 0.591136\n",
      "iteration 132 / 300: loss 0.584855\n",
      "iteration 132 / 300: loss 0.599647\n",
      "iteration 132 / 300: loss 0.598903\n",
      "iteration 132 / 300: loss 0.614283\n",
      "iteration 132 / 300: loss 0.597797\n",
      "iteration 132 / 300: loss 0.599299\n",
      "iteration 132 / 300: loss 0.603318\n",
      "iteration 132 / 300: loss 0.592866\n",
      "iteration 132 / 300: loss 0.592392\n",
      "iteration 132 / 300: loss 0.589042\n",
      "iteration 132 / 300: loss 0.596447\n",
      "iteration 132 / 300: loss 0.605710\n",
      "iteration 132 / 300: loss 0.610563\n",
      "iteration 132 / 300: loss 0.587783\n",
      "iteration 132 / 300: loss 0.599352\n",
      "iteration 132 / 300: loss 0.602792\n",
      "iteration 132 / 300: loss 0.605029\n",
      "iteration 132 / 300: loss 0.603849\n",
      "iteration 132 / 300: loss 0.624144\n",
      "iteration 132 / 300: loss 0.587220\n",
      "iteration 132 / 300: loss 0.580755\n",
      "iteration 132 / 300: loss 0.625046\n",
      "iteration 132 / 300: loss 0.603311\n",
      "iteration 132 / 300: loss 0.604322\n",
      "iteration 132 / 300: loss 0.595477\n",
      "iteration 132 / 300: loss 0.597544\n",
      "iteration 132 / 300: loss 0.592741\n",
      "iteration 132 / 300: loss 0.589495\n",
      "iteration 132 / 300: loss 0.599265\n",
      "iteration 132 / 300: loss 0.611380\n",
      "iteration 132 / 300: loss 0.592464\n",
      "iteration 132 / 300: loss 0.599425\n",
      "iteration 132 / 300: loss 0.603101\n",
      "iteration 132 / 300: loss 0.602411\n",
      "iteration 132 / 300: loss 0.579812\n",
      "iteration 132 / 300: loss 0.601593\n",
      "iteration 133 / 300: loss 0.585528\n",
      "iteration 133 / 300: loss 0.588428\n",
      "iteration 133 / 300: loss 0.567517\n",
      "iteration 133 / 300: loss 0.592380\n",
      "iteration 133 / 300: loss 0.593619\n",
      "iteration 133 / 300: loss 0.595296\n",
      "iteration 133 / 300: loss 0.608784\n",
      "iteration 133 / 300: loss 0.592733\n",
      "iteration 133 / 300: loss 0.628061\n",
      "iteration 133 / 300: loss 0.580153\n",
      "iteration 133 / 300: loss 0.607924\n",
      "iteration 133 / 300: loss 0.587395\n",
      "iteration 133 / 300: loss 0.591687\n",
      "iteration 133 / 300: loss 0.571371\n",
      "iteration 133 / 300: loss 0.583025\n",
      "iteration 133 / 300: loss 0.608442\n",
      "iteration 133 / 300: loss 0.598360\n",
      "iteration 133 / 300: loss 0.583858\n",
      "iteration 133 / 300: loss 0.615253\n",
      "iteration 133 / 300: loss 0.591650\n",
      "iteration 133 / 300: loss 0.585500\n",
      "iteration 133 / 300: loss 0.591326\n",
      "iteration 133 / 300: loss 0.604342\n",
      "iteration 133 / 300: loss 0.595787\n",
      "iteration 133 / 300: loss 0.614950\n",
      "iteration 133 / 300: loss 0.608389\n",
      "iteration 133 / 300: loss 0.598223\n",
      "iteration 133 / 300: loss 0.588936\n",
      "iteration 133 / 300: loss 0.617757\n",
      "iteration 133 / 300: loss 0.594770\n",
      "iteration 133 / 300: loss 0.601685\n",
      "iteration 133 / 300: loss 0.631032\n",
      "iteration 133 / 300: loss 0.587513\n",
      "iteration 133 / 300: loss 0.606562\n",
      "iteration 133 / 300: loss 0.588035\n",
      "iteration 133 / 300: loss 0.600891\n",
      "iteration 133 / 300: loss 0.595959\n",
      "iteration 133 / 300: loss 0.589292\n",
      "iteration 133 / 300: loss 0.599527\n",
      "iteration 133 / 300: loss 0.604856\n",
      "iteration 133 / 300: loss 0.619414\n",
      "iteration 133 / 300: loss 0.588809\n",
      "iteration 133 / 300: loss 0.593646\n",
      "iteration 133 / 300: loss 0.585596\n",
      "iteration 133 / 300: loss 0.613213\n",
      "iteration 133 / 300: loss 0.587524\n",
      "iteration 133 / 300: loss 0.578329\n",
      "iteration 133 / 300: loss 0.567435\n",
      "iteration 133 / 300: loss 0.562236\n",
      "iteration 133 / 300: loss 0.594184\n",
      "iteration 133 / 300: loss 0.578822\n",
      "iteration 133 / 300: loss 0.586361\n",
      "iteration 133 / 300: loss 0.572891\n",
      "iteration 133 / 300: loss 0.596152\n",
      "iteration 133 / 300: loss 0.607951\n",
      "iteration 133 / 300: loss 0.610839\n",
      "iteration 133 / 300: loss 0.606266\n",
      "iteration 133 / 300: loss 0.583791\n",
      "iteration 133 / 300: loss 0.589627\n",
      "iteration 133 / 300: loss 0.595184\n",
      "iteration 133 / 300: loss 0.598955\n",
      "iteration 133 / 300: loss 0.596134\n",
      "iteration 133 / 300: loss 0.589770\n",
      "iteration 133 / 300: loss 0.591136\n",
      "iteration 133 / 300: loss 0.584855\n",
      "iteration 133 / 300: loss 0.599647\n",
      "iteration 133 / 300: loss 0.598903\n",
      "iteration 133 / 300: loss 0.614283\n",
      "iteration 133 / 300: loss 0.597797\n",
      "iteration 133 / 300: loss 0.599299\n",
      "iteration 133 / 300: loss 0.603318\n",
      "iteration 133 / 300: loss 0.592866\n",
      "iteration 133 / 300: loss 0.592392\n",
      "iteration 133 / 300: loss 0.589042\n",
      "iteration 133 / 300: loss 0.596446\n",
      "iteration 133 / 300: loss 0.605710\n",
      "iteration 133 / 300: loss 0.610563\n",
      "iteration 133 / 300: loss 0.587783\n",
      "iteration 133 / 300: loss 0.599352\n",
      "iteration 133 / 300: loss 0.602792\n",
      "iteration 133 / 300: loss 0.605029\n",
      "iteration 133 / 300: loss 0.603848\n",
      "iteration 133 / 300: loss 0.624144\n",
      "iteration 133 / 300: loss 0.587220\n",
      "iteration 133 / 300: loss 0.580755\n",
      "iteration 133 / 300: loss 0.625046\n",
      "iteration 133 / 300: loss 0.603311\n",
      "iteration 133 / 300: loss 0.604322\n",
      "iteration 133 / 300: loss 0.595477\n",
      "iteration 133 / 300: loss 0.597544\n",
      "iteration 133 / 300: loss 0.592741\n",
      "iteration 133 / 300: loss 0.589495\n",
      "iteration 133 / 300: loss 0.599265\n",
      "iteration 133 / 300: loss 0.611380\n",
      "iteration 133 / 300: loss 0.592464\n",
      "iteration 133 / 300: loss 0.599425\n",
      "iteration 133 / 300: loss 0.603101\n",
      "iteration 133 / 300: loss 0.602411\n",
      "iteration 133 / 300: loss 0.579812\n",
      "iteration 133 / 300: loss 0.601593\n",
      "iteration 134 / 300: loss 0.585528\n",
      "iteration 134 / 300: loss 0.588428\n",
      "iteration 134 / 300: loss 0.567517\n",
      "iteration 134 / 300: loss 0.592380\n",
      "iteration 134 / 300: loss 0.593619\n",
      "iteration 134 / 300: loss 0.595296\n",
      "iteration 134 / 300: loss 0.608784\n",
      "iteration 134 / 300: loss 0.592733\n",
      "iteration 134 / 300: loss 0.628061\n",
      "iteration 134 / 300: loss 0.580153\n",
      "iteration 134 / 300: loss 0.607924\n",
      "iteration 134 / 300: loss 0.587395\n",
      "iteration 134 / 300: loss 0.591687\n",
      "iteration 134 / 300: loss 0.571370\n",
      "iteration 134 / 300: loss 0.583025\n",
      "iteration 134 / 300: loss 0.608442\n",
      "iteration 134 / 300: loss 0.598360\n",
      "iteration 134 / 300: loss 0.583858\n",
      "iteration 134 / 300: loss 0.615253\n",
      "iteration 134 / 300: loss 0.591650\n",
      "iteration 134 / 300: loss 0.585500\n",
      "iteration 134 / 300: loss 0.591326\n",
      "iteration 134 / 300: loss 0.604341\n",
      "iteration 134 / 300: loss 0.595787\n",
      "iteration 134 / 300: loss 0.614950\n",
      "iteration 134 / 300: loss 0.608389\n",
      "iteration 134 / 300: loss 0.598223\n",
      "iteration 134 / 300: loss 0.588936\n",
      "iteration 134 / 300: loss 0.617757\n",
      "iteration 134 / 300: loss 0.594770\n",
      "iteration 134 / 300: loss 0.601685\n",
      "iteration 134 / 300: loss 0.631032\n",
      "iteration 134 / 300: loss 0.587513\n",
      "iteration 134 / 300: loss 0.606562\n",
      "iteration 134 / 300: loss 0.588035\n",
      "iteration 134 / 300: loss 0.600890\n",
      "iteration 134 / 300: loss 0.595959\n",
      "iteration 134 / 300: loss 0.589292\n",
      "iteration 134 / 300: loss 0.599527\n",
      "iteration 134 / 300: loss 0.604856\n",
      "iteration 134 / 300: loss 0.619414\n",
      "iteration 134 / 300: loss 0.588809\n",
      "iteration 134 / 300: loss 0.593645\n",
      "iteration 134 / 300: loss 0.585596\n",
      "iteration 134 / 300: loss 0.613213\n",
      "iteration 134 / 300: loss 0.587524\n",
      "iteration 134 / 300: loss 0.578329\n",
      "iteration 134 / 300: loss 0.567435\n",
      "iteration 134 / 300: loss 0.562236\n",
      "iteration 134 / 300: loss 0.594184\n",
      "iteration 134 / 300: loss 0.578822\n",
      "iteration 134 / 300: loss 0.586361\n",
      "iteration 134 / 300: loss 0.572891\n",
      "iteration 134 / 300: loss 0.596152\n",
      "iteration 134 / 300: loss 0.607951\n",
      "iteration 134 / 300: loss 0.610839\n",
      "iteration 134 / 300: loss 0.606266\n",
      "iteration 134 / 300: loss 0.583791\n",
      "iteration 134 / 300: loss 0.589627\n",
      "iteration 134 / 300: loss 0.595184\n",
      "iteration 134 / 300: loss 0.598955\n",
      "iteration 134 / 300: loss 0.596134\n",
      "iteration 134 / 300: loss 0.589770\n",
      "iteration 134 / 300: loss 0.591136\n",
      "iteration 134 / 300: loss 0.584855\n",
      "iteration 134 / 300: loss 0.599647\n",
      "iteration 134 / 300: loss 0.598903\n",
      "iteration 134 / 300: loss 0.614283\n",
      "iteration 134 / 300: loss 0.597797\n",
      "iteration 134 / 300: loss 0.599299\n",
      "iteration 134 / 300: loss 0.603318\n",
      "iteration 134 / 300: loss 0.592866\n",
      "iteration 134 / 300: loss 0.592392\n",
      "iteration 134 / 300: loss 0.589042\n",
      "iteration 134 / 300: loss 0.596446\n",
      "iteration 134 / 300: loss 0.605710\n",
      "iteration 134 / 300: loss 0.610562\n",
      "iteration 134 / 300: loss 0.587783\n",
      "iteration 134 / 300: loss 0.599352\n",
      "iteration 134 / 300: loss 0.602792\n",
      "iteration 134 / 300: loss 0.605029\n",
      "iteration 134 / 300: loss 0.603848\n",
      "iteration 134 / 300: loss 0.624144\n",
      "iteration 134 / 300: loss 0.587220\n",
      "iteration 134 / 300: loss 0.580755\n",
      "iteration 134 / 300: loss 0.625046\n",
      "iteration 134 / 300: loss 0.603311\n",
      "iteration 134 / 300: loss 0.604322\n",
      "iteration 134 / 300: loss 0.595477\n",
      "iteration 134 / 300: loss 0.597544\n",
      "iteration 134 / 300: loss 0.592741\n",
      "iteration 134 / 300: loss 0.589494\n",
      "iteration 134 / 300: loss 0.599265\n",
      "iteration 134 / 300: loss 0.611380\n",
      "iteration 134 / 300: loss 0.592464\n",
      "iteration 134 / 300: loss 0.599425\n",
      "iteration 134 / 300: loss 0.603101\n",
      "iteration 134 / 300: loss 0.602411\n",
      "iteration 134 / 300: loss 0.579812\n",
      "iteration 134 / 300: loss 0.601593\n",
      "iteration 135 / 300: loss 0.585528\n",
      "iteration 135 / 300: loss 0.588428\n",
      "iteration 135 / 300: loss 0.567517\n",
      "iteration 135 / 300: loss 0.592380\n",
      "iteration 135 / 300: loss 0.593619\n",
      "iteration 135 / 300: loss 0.595296\n",
      "iteration 135 / 300: loss 0.608784\n",
      "iteration 135 / 300: loss 0.592733\n",
      "iteration 135 / 300: loss 0.628061\n",
      "iteration 135 / 300: loss 0.580153\n",
      "iteration 135 / 300: loss 0.607924\n",
      "iteration 135 / 300: loss 0.587395\n",
      "iteration 135 / 300: loss 0.591687\n",
      "iteration 135 / 300: loss 0.571370\n",
      "iteration 135 / 300: loss 0.583025\n",
      "iteration 135 / 300: loss 0.608442\n",
      "iteration 135 / 300: loss 0.598359\n",
      "iteration 135 / 300: loss 0.583858\n",
      "iteration 135 / 300: loss 0.615253\n",
      "iteration 135 / 300: loss 0.591650\n",
      "iteration 135 / 300: loss 0.585500\n",
      "iteration 135 / 300: loss 0.591325\n",
      "iteration 135 / 300: loss 0.604341\n",
      "iteration 135 / 300: loss 0.595787\n",
      "iteration 135 / 300: loss 0.614950\n",
      "iteration 135 / 300: loss 0.608389\n",
      "iteration 135 / 300: loss 0.598223\n",
      "iteration 135 / 300: loss 0.588936\n",
      "iteration 135 / 300: loss 0.617757\n",
      "iteration 135 / 300: loss 0.594770\n",
      "iteration 135 / 300: loss 0.601685\n",
      "iteration 135 / 300: loss 0.631032\n",
      "iteration 135 / 300: loss 0.587513\n",
      "iteration 135 / 300: loss 0.606562\n",
      "iteration 135 / 300: loss 0.588034\n",
      "iteration 135 / 300: loss 0.600890\n",
      "iteration 135 / 300: loss 0.595958\n",
      "iteration 135 / 300: loss 0.589292\n",
      "iteration 135 / 300: loss 0.599526\n",
      "iteration 135 / 300: loss 0.604856\n",
      "iteration 135 / 300: loss 0.619414\n",
      "iteration 135 / 300: loss 0.588809\n",
      "iteration 135 / 300: loss 0.593645\n",
      "iteration 135 / 300: loss 0.585596\n",
      "iteration 135 / 300: loss 0.613213\n",
      "iteration 135 / 300: loss 0.587524\n",
      "iteration 135 / 300: loss 0.578329\n",
      "iteration 135 / 300: loss 0.567435\n",
      "iteration 135 / 300: loss 0.562236\n",
      "iteration 135 / 300: loss 0.594184\n",
      "iteration 135 / 300: loss 0.578822\n",
      "iteration 135 / 300: loss 0.586361\n",
      "iteration 135 / 300: loss 0.572891\n",
      "iteration 135 / 300: loss 0.596152\n",
      "iteration 135 / 300: loss 0.607951\n",
      "iteration 135 / 300: loss 0.610839\n",
      "iteration 135 / 300: loss 0.606266\n",
      "iteration 135 / 300: loss 0.583791\n",
      "iteration 135 / 300: loss 0.589627\n",
      "iteration 135 / 300: loss 0.595184\n",
      "iteration 135 / 300: loss 0.598955\n",
      "iteration 135 / 300: loss 0.596134\n",
      "iteration 135 / 300: loss 0.589770\n",
      "iteration 135 / 300: loss 0.591136\n",
      "iteration 135 / 300: loss 0.584855\n",
      "iteration 135 / 300: loss 0.599647\n",
      "iteration 135 / 300: loss 0.598902\n",
      "iteration 135 / 300: loss 0.614283\n",
      "iteration 135 / 300: loss 0.597797\n",
      "iteration 135 / 300: loss 0.599299\n",
      "iteration 135 / 300: loss 0.603318\n",
      "iteration 135 / 300: loss 0.592866\n",
      "iteration 135 / 300: loss 0.592392\n",
      "iteration 135 / 300: loss 0.589042\n",
      "iteration 135 / 300: loss 0.596446\n",
      "iteration 135 / 300: loss 0.605710\n",
      "iteration 135 / 300: loss 0.610562\n",
      "iteration 135 / 300: loss 0.587782\n",
      "iteration 135 / 300: loss 0.599352\n",
      "iteration 135 / 300: loss 0.602792\n",
      "iteration 135 / 300: loss 0.605029\n",
      "iteration 135 / 300: loss 0.603848\n",
      "iteration 135 / 300: loss 0.624144\n",
      "iteration 135 / 300: loss 0.587220\n",
      "iteration 135 / 300: loss 0.580755\n",
      "iteration 135 / 300: loss 0.625046\n",
      "iteration 135 / 300: loss 0.603310\n",
      "iteration 135 / 300: loss 0.604322\n",
      "iteration 135 / 300: loss 0.595477\n",
      "iteration 135 / 300: loss 0.597544\n",
      "iteration 135 / 300: loss 0.592741\n",
      "iteration 135 / 300: loss 0.589494\n",
      "iteration 135 / 300: loss 0.599265\n",
      "iteration 135 / 300: loss 0.611380\n",
      "iteration 135 / 300: loss 0.592464\n",
      "iteration 135 / 300: loss 0.599425\n",
      "iteration 135 / 300: loss 0.603101\n",
      "iteration 135 / 300: loss 0.602411\n",
      "iteration 135 / 300: loss 0.579812\n",
      "iteration 135 / 300: loss 0.601593\n",
      "iteration 136 / 300: loss 0.585528\n",
      "iteration 136 / 300: loss 0.588428\n",
      "iteration 136 / 300: loss 0.567517\n",
      "iteration 136 / 300: loss 0.592380\n",
      "iteration 136 / 300: loss 0.593619\n",
      "iteration 136 / 300: loss 0.595296\n",
      "iteration 136 / 300: loss 0.608784\n",
      "iteration 136 / 300: loss 0.592733\n",
      "iteration 136 / 300: loss 0.628061\n",
      "iteration 136 / 300: loss 0.580152\n",
      "iteration 136 / 300: loss 0.607924\n",
      "iteration 136 / 300: loss 0.587395\n",
      "iteration 136 / 300: loss 0.591687\n",
      "iteration 136 / 300: loss 0.571370\n",
      "iteration 136 / 300: loss 0.583025\n",
      "iteration 136 / 300: loss 0.608441\n",
      "iteration 136 / 300: loss 0.598359\n",
      "iteration 136 / 300: loss 0.583858\n",
      "iteration 136 / 300: loss 0.615253\n",
      "iteration 136 / 300: loss 0.591650\n",
      "iteration 136 / 300: loss 0.585500\n",
      "iteration 136 / 300: loss 0.591325\n",
      "iteration 136 / 300: loss 0.604341\n",
      "iteration 136 / 300: loss 0.595787\n",
      "iteration 136 / 300: loss 0.614950\n",
      "iteration 136 / 300: loss 0.608389\n",
      "iteration 136 / 300: loss 0.598223\n",
      "iteration 136 / 300: loss 0.588936\n",
      "iteration 136 / 300: loss 0.617757\n",
      "iteration 136 / 300: loss 0.594770\n",
      "iteration 136 / 300: loss 0.601685\n",
      "iteration 136 / 300: loss 0.631032\n",
      "iteration 136 / 300: loss 0.587513\n",
      "iteration 136 / 300: loss 0.606562\n",
      "iteration 136 / 300: loss 0.588034\n",
      "iteration 136 / 300: loss 0.600890\n",
      "iteration 136 / 300: loss 0.595958\n",
      "iteration 136 / 300: loss 0.589292\n",
      "iteration 136 / 300: loss 0.599526\n",
      "iteration 136 / 300: loss 0.604856\n",
      "iteration 136 / 300: loss 0.619414\n",
      "iteration 136 / 300: loss 0.588809\n",
      "iteration 136 / 300: loss 0.593645\n",
      "iteration 136 / 300: loss 0.585596\n",
      "iteration 136 / 300: loss 0.613213\n",
      "iteration 136 / 300: loss 0.587524\n",
      "iteration 136 / 300: loss 0.578329\n",
      "iteration 136 / 300: loss 0.567435\n",
      "iteration 136 / 300: loss 0.562236\n",
      "iteration 136 / 300: loss 0.594184\n",
      "iteration 136 / 300: loss 0.578822\n",
      "iteration 136 / 300: loss 0.586361\n",
      "iteration 136 / 300: loss 0.572890\n",
      "iteration 136 / 300: loss 0.596152\n",
      "iteration 136 / 300: loss 0.607951\n",
      "iteration 136 / 300: loss 0.610839\n",
      "iteration 136 / 300: loss 0.606266\n",
      "iteration 136 / 300: loss 0.583791\n",
      "iteration 136 / 300: loss 0.589627\n",
      "iteration 136 / 300: loss 0.595184\n",
      "iteration 136 / 300: loss 0.598955\n",
      "iteration 136 / 300: loss 0.596134\n",
      "iteration 136 / 300: loss 0.589770\n",
      "iteration 136 / 300: loss 0.591136\n",
      "iteration 136 / 300: loss 0.584855\n",
      "iteration 136 / 300: loss 0.599647\n",
      "iteration 136 / 300: loss 0.598902\n",
      "iteration 136 / 300: loss 0.614283\n",
      "iteration 136 / 300: loss 0.597797\n",
      "iteration 136 / 300: loss 0.599299\n",
      "iteration 136 / 300: loss 0.603318\n",
      "iteration 136 / 300: loss 0.592866\n",
      "iteration 136 / 300: loss 0.592392\n",
      "iteration 136 / 300: loss 0.589042\n",
      "iteration 136 / 300: loss 0.596446\n",
      "iteration 136 / 300: loss 0.605710\n",
      "iteration 136 / 300: loss 0.610562\n",
      "iteration 136 / 300: loss 0.587782\n",
      "iteration 136 / 300: loss 0.599351\n",
      "iteration 136 / 300: loss 0.602792\n",
      "iteration 136 / 300: loss 0.605029\n",
      "iteration 136 / 300: loss 0.603848\n",
      "iteration 136 / 300: loss 0.624144\n",
      "iteration 136 / 300: loss 0.587220\n",
      "iteration 136 / 300: loss 0.580755\n",
      "iteration 136 / 300: loss 0.625046\n",
      "iteration 136 / 300: loss 0.603310\n",
      "iteration 136 / 300: loss 0.604322\n",
      "iteration 136 / 300: loss 0.595477\n",
      "iteration 136 / 300: loss 0.597543\n",
      "iteration 136 / 300: loss 0.592741\n",
      "iteration 136 / 300: loss 0.589494\n",
      "iteration 136 / 300: loss 0.599265\n",
      "iteration 136 / 300: loss 0.611380\n",
      "iteration 136 / 300: loss 0.592463\n",
      "iteration 136 / 300: loss 0.599425\n",
      "iteration 136 / 300: loss 0.603101\n",
      "iteration 136 / 300: loss 0.602411\n",
      "iteration 136 / 300: loss 0.579812\n",
      "iteration 136 / 300: loss 0.601593\n",
      "iteration 137 / 300: loss 0.585528\n",
      "iteration 137 / 300: loss 0.588428\n",
      "iteration 137 / 300: loss 0.567517\n",
      "iteration 137 / 300: loss 0.592380\n",
      "iteration 137 / 300: loss 0.593619\n",
      "iteration 137 / 300: loss 0.595296\n",
      "iteration 137 / 300: loss 0.608784\n",
      "iteration 137 / 300: loss 0.592732\n",
      "iteration 137 / 300: loss 0.628061\n",
      "iteration 137 / 300: loss 0.580152\n",
      "iteration 137 / 300: loss 0.607924\n",
      "iteration 137 / 300: loss 0.587395\n",
      "iteration 137 / 300: loss 0.591687\n",
      "iteration 137 / 300: loss 0.571370\n",
      "iteration 137 / 300: loss 0.583025\n",
      "iteration 137 / 300: loss 0.608441\n",
      "iteration 137 / 300: loss 0.598359\n",
      "iteration 137 / 300: loss 0.583858\n",
      "iteration 137 / 300: loss 0.615253\n",
      "iteration 137 / 300: loss 0.591650\n",
      "iteration 137 / 300: loss 0.585500\n",
      "iteration 137 / 300: loss 0.591325\n",
      "iteration 137 / 300: loss 0.604341\n",
      "iteration 137 / 300: loss 0.595787\n",
      "iteration 137 / 300: loss 0.614950\n",
      "iteration 137 / 300: loss 0.608389\n",
      "iteration 137 / 300: loss 0.598223\n",
      "iteration 137 / 300: loss 0.588936\n",
      "iteration 137 / 300: loss 0.617757\n",
      "iteration 137 / 300: loss 0.594770\n",
      "iteration 137 / 300: loss 0.601685\n",
      "iteration 137 / 300: loss 0.631032\n",
      "iteration 137 / 300: loss 0.587513\n",
      "iteration 137 / 300: loss 0.606562\n",
      "iteration 137 / 300: loss 0.588034\n",
      "iteration 137 / 300: loss 0.600890\n",
      "iteration 137 / 300: loss 0.595958\n",
      "iteration 137 / 300: loss 0.589292\n",
      "iteration 137 / 300: loss 0.599526\n",
      "iteration 137 / 300: loss 0.604856\n",
      "iteration 137 / 300: loss 0.619414\n",
      "iteration 137 / 300: loss 0.588809\n",
      "iteration 137 / 300: loss 0.593645\n",
      "iteration 137 / 300: loss 0.585596\n",
      "iteration 137 / 300: loss 0.613213\n",
      "iteration 137 / 300: loss 0.587524\n",
      "iteration 137 / 300: loss 0.578329\n",
      "iteration 137 / 300: loss 0.567435\n",
      "iteration 137 / 300: loss 0.562236\n",
      "iteration 137 / 300: loss 0.594184\n",
      "iteration 137 / 300: loss 0.578822\n",
      "iteration 137 / 300: loss 0.586361\n",
      "iteration 137 / 300: loss 0.572890\n",
      "iteration 137 / 300: loss 0.596152\n",
      "iteration 137 / 300: loss 0.607951\n",
      "iteration 137 / 300: loss 0.610839\n",
      "iteration 137 / 300: loss 0.606266\n",
      "iteration 137 / 300: loss 0.583791\n",
      "iteration 137 / 300: loss 0.589627\n",
      "iteration 137 / 300: loss 0.595184\n",
      "iteration 137 / 300: loss 0.598955\n",
      "iteration 137 / 300: loss 0.596134\n",
      "iteration 137 / 300: loss 0.589770\n",
      "iteration 137 / 300: loss 0.591136\n",
      "iteration 137 / 300: loss 0.584855\n",
      "iteration 137 / 300: loss 0.599647\n",
      "iteration 137 / 300: loss 0.598902\n",
      "iteration 137 / 300: loss 0.614283\n",
      "iteration 137 / 300: loss 0.597797\n",
      "iteration 137 / 300: loss 0.599299\n",
      "iteration 137 / 300: loss 0.603318\n",
      "iteration 137 / 300: loss 0.592866\n",
      "iteration 137 / 300: loss 0.592391\n",
      "iteration 137 / 300: loss 0.589042\n",
      "iteration 137 / 300: loss 0.596446\n",
      "iteration 137 / 300: loss 0.605709\n",
      "iteration 137 / 300: loss 0.610562\n",
      "iteration 137 / 300: loss 0.587782\n",
      "iteration 137 / 300: loss 0.599351\n",
      "iteration 137 / 300: loss 0.602792\n",
      "iteration 137 / 300: loss 0.605029\n",
      "iteration 137 / 300: loss 0.603848\n",
      "iteration 137 / 300: loss 0.624144\n",
      "iteration 137 / 300: loss 0.587220\n",
      "iteration 137 / 300: loss 0.580755\n",
      "iteration 137 / 300: loss 0.625046\n",
      "iteration 137 / 300: loss 0.603310\n",
      "iteration 137 / 300: loss 0.604322\n",
      "iteration 137 / 300: loss 0.595476\n",
      "iteration 137 / 300: loss 0.597543\n",
      "iteration 137 / 300: loss 0.592741\n",
      "iteration 137 / 300: loss 0.589494\n",
      "iteration 137 / 300: loss 0.599265\n",
      "iteration 137 / 300: loss 0.611380\n",
      "iteration 137 / 300: loss 0.592463\n",
      "iteration 137 / 300: loss 0.599425\n",
      "iteration 137 / 300: loss 0.603101\n",
      "iteration 137 / 300: loss 0.602411\n",
      "iteration 137 / 300: loss 0.579812\n",
      "iteration 137 / 300: loss 0.601592\n",
      "iteration 138 / 300: loss 0.585528\n",
      "iteration 138 / 300: loss 0.588428\n",
      "iteration 138 / 300: loss 0.567517\n",
      "iteration 138 / 300: loss 0.592380\n",
      "iteration 138 / 300: loss 0.593619\n",
      "iteration 138 / 300: loss 0.595296\n",
      "iteration 138 / 300: loss 0.608784\n",
      "iteration 138 / 300: loss 0.592732\n",
      "iteration 138 / 300: loss 0.628061\n",
      "iteration 138 / 300: loss 0.580152\n",
      "iteration 138 / 300: loss 0.607923\n",
      "iteration 138 / 300: loss 0.587395\n",
      "iteration 138 / 300: loss 0.591687\n",
      "iteration 138 / 300: loss 0.571370\n",
      "iteration 138 / 300: loss 0.583025\n",
      "iteration 138 / 300: loss 0.608441\n",
      "iteration 138 / 300: loss 0.598359\n",
      "iteration 138 / 300: loss 0.583858\n",
      "iteration 138 / 300: loss 0.615253\n",
      "iteration 138 / 300: loss 0.591650\n",
      "iteration 138 / 300: loss 0.585500\n",
      "iteration 138 / 300: loss 0.591325\n",
      "iteration 138 / 300: loss 0.604341\n",
      "iteration 138 / 300: loss 0.595787\n",
      "iteration 138 / 300: loss 0.614950\n",
      "iteration 138 / 300: loss 0.608389\n",
      "iteration 138 / 300: loss 0.598223\n",
      "iteration 138 / 300: loss 0.588936\n",
      "iteration 138 / 300: loss 0.617757\n",
      "iteration 138 / 300: loss 0.594770\n",
      "iteration 138 / 300: loss 0.601685\n",
      "iteration 138 / 300: loss 0.631032\n",
      "iteration 138 / 300: loss 0.587513\n",
      "iteration 138 / 300: loss 0.606562\n",
      "iteration 138 / 300: loss 0.588034\n",
      "iteration 138 / 300: loss 0.600890\n",
      "iteration 138 / 300: loss 0.595958\n",
      "iteration 138 / 300: loss 0.589291\n",
      "iteration 138 / 300: loss 0.599526\n",
      "iteration 138 / 300: loss 0.604856\n",
      "iteration 138 / 300: loss 0.619414\n",
      "iteration 138 / 300: loss 0.588809\n",
      "iteration 138 / 300: loss 0.593645\n",
      "iteration 138 / 300: loss 0.585596\n",
      "iteration 138 / 300: loss 0.613213\n",
      "iteration 138 / 300: loss 0.587524\n",
      "iteration 138 / 300: loss 0.578329\n",
      "iteration 138 / 300: loss 0.567435\n",
      "iteration 138 / 300: loss 0.562236\n",
      "iteration 138 / 300: loss 0.594184\n",
      "iteration 138 / 300: loss 0.578822\n",
      "iteration 138 / 300: loss 0.586361\n",
      "iteration 138 / 300: loss 0.572890\n",
      "iteration 138 / 300: loss 0.596152\n",
      "iteration 138 / 300: loss 0.607951\n",
      "iteration 138 / 300: loss 0.610839\n",
      "iteration 138 / 300: loss 0.606266\n",
      "iteration 138 / 300: loss 0.583791\n",
      "iteration 138 / 300: loss 0.589627\n",
      "iteration 138 / 300: loss 0.595184\n",
      "iteration 138 / 300: loss 0.598955\n",
      "iteration 138 / 300: loss 0.596133\n",
      "iteration 138 / 300: loss 0.589770\n",
      "iteration 138 / 300: loss 0.591136\n",
      "iteration 138 / 300: loss 0.584854\n",
      "iteration 138 / 300: loss 0.599647\n",
      "iteration 138 / 300: loss 0.598902\n",
      "iteration 138 / 300: loss 0.614283\n",
      "iteration 138 / 300: loss 0.597797\n",
      "iteration 138 / 300: loss 0.599299\n",
      "iteration 138 / 300: loss 0.603318\n",
      "iteration 138 / 300: loss 0.592866\n",
      "iteration 138 / 300: loss 0.592391\n",
      "iteration 138 / 300: loss 0.589042\n",
      "iteration 138 / 300: loss 0.596446\n",
      "iteration 138 / 300: loss 0.605709\n",
      "iteration 138 / 300: loss 0.610562\n",
      "iteration 138 / 300: loss 0.587782\n",
      "iteration 138 / 300: loss 0.599351\n",
      "iteration 138 / 300: loss 0.602792\n",
      "iteration 138 / 300: loss 0.605029\n",
      "iteration 138 / 300: loss 0.603848\n",
      "iteration 138 / 300: loss 0.624144\n",
      "iteration 138 / 300: loss 0.587219\n",
      "iteration 138 / 300: loss 0.580755\n",
      "iteration 138 / 300: loss 0.625046\n",
      "iteration 138 / 300: loss 0.603310\n",
      "iteration 138 / 300: loss 0.604322\n",
      "iteration 138 / 300: loss 0.595476\n",
      "iteration 138 / 300: loss 0.597543\n",
      "iteration 138 / 300: loss 0.592741\n",
      "iteration 138 / 300: loss 0.589494\n",
      "iteration 138 / 300: loss 0.599265\n",
      "iteration 138 / 300: loss 0.611380\n",
      "iteration 138 / 300: loss 0.592463\n",
      "iteration 138 / 300: loss 0.599425\n",
      "iteration 138 / 300: loss 0.603101\n",
      "iteration 138 / 300: loss 0.602411\n",
      "iteration 138 / 300: loss 0.579812\n",
      "iteration 138 / 300: loss 0.601592\n",
      "iteration 139 / 300: loss 0.585528\n",
      "iteration 139 / 300: loss 0.588428\n",
      "iteration 139 / 300: loss 0.567517\n",
      "iteration 139 / 300: loss 0.592380\n",
      "iteration 139 / 300: loss 0.593619\n",
      "iteration 139 / 300: loss 0.595296\n",
      "iteration 139 / 300: loss 0.608784\n",
      "iteration 139 / 300: loss 0.592732\n",
      "iteration 139 / 300: loss 0.628061\n",
      "iteration 139 / 300: loss 0.580152\n",
      "iteration 139 / 300: loss 0.607923\n",
      "iteration 139 / 300: loss 0.587395\n",
      "iteration 139 / 300: loss 0.591687\n",
      "iteration 139 / 300: loss 0.571370\n",
      "iteration 139 / 300: loss 0.583025\n",
      "iteration 139 / 300: loss 0.608441\n",
      "iteration 139 / 300: loss 0.598359\n",
      "iteration 139 / 300: loss 0.583858\n",
      "iteration 139 / 300: loss 0.615253\n",
      "iteration 139 / 300: loss 0.591650\n",
      "iteration 139 / 300: loss 0.585499\n",
      "iteration 139 / 300: loss 0.591325\n",
      "iteration 139 / 300: loss 0.604341\n",
      "iteration 139 / 300: loss 0.595787\n",
      "iteration 139 / 300: loss 0.614950\n",
      "iteration 139 / 300: loss 0.608389\n",
      "iteration 139 / 300: loss 0.598223\n",
      "iteration 139 / 300: loss 0.588936\n",
      "iteration 139 / 300: loss 0.617757\n",
      "iteration 139 / 300: loss 0.594770\n",
      "iteration 139 / 300: loss 0.601685\n",
      "iteration 139 / 300: loss 0.631032\n",
      "iteration 139 / 300: loss 0.587513\n",
      "iteration 139 / 300: loss 0.606562\n",
      "iteration 139 / 300: loss 0.588034\n",
      "iteration 139 / 300: loss 0.600890\n",
      "iteration 139 / 300: loss 0.595958\n",
      "iteration 139 / 300: loss 0.589291\n",
      "iteration 139 / 300: loss 0.599526\n",
      "iteration 139 / 300: loss 0.604856\n",
      "iteration 139 / 300: loss 0.619414\n",
      "iteration 139 / 300: loss 0.588808\n",
      "iteration 139 / 300: loss 0.593645\n",
      "iteration 139 / 300: loss 0.585596\n",
      "iteration 139 / 300: loss 0.613213\n",
      "iteration 139 / 300: loss 0.587524\n",
      "iteration 139 / 300: loss 0.578329\n",
      "iteration 139 / 300: loss 0.567435\n",
      "iteration 139 / 300: loss 0.562235\n",
      "iteration 139 / 300: loss 0.594184\n",
      "iteration 139 / 300: loss 0.578821\n",
      "iteration 139 / 300: loss 0.586361\n",
      "iteration 139 / 300: loss 0.572890\n",
      "iteration 139 / 300: loss 0.596152\n",
      "iteration 139 / 300: loss 0.607951\n",
      "iteration 139 / 300: loss 0.610839\n",
      "iteration 139 / 300: loss 0.606266\n",
      "iteration 139 / 300: loss 0.583791\n",
      "iteration 139 / 300: loss 0.589627\n",
      "iteration 139 / 300: loss 0.595184\n",
      "iteration 139 / 300: loss 0.598955\n",
      "iteration 139 / 300: loss 0.596133\n",
      "iteration 139 / 300: loss 0.589770\n",
      "iteration 139 / 300: loss 0.591136\n",
      "iteration 139 / 300: loss 0.584854\n",
      "iteration 139 / 300: loss 0.599647\n",
      "iteration 139 / 300: loss 0.598902\n",
      "iteration 139 / 300: loss 0.614283\n",
      "iteration 139 / 300: loss 0.597797\n",
      "iteration 139 / 300: loss 0.599299\n",
      "iteration 139 / 300: loss 0.603318\n",
      "iteration 139 / 300: loss 0.592866\n",
      "iteration 139 / 300: loss 0.592391\n",
      "iteration 139 / 300: loss 0.589041\n",
      "iteration 139 / 300: loss 0.596446\n",
      "iteration 139 / 300: loss 0.605709\n",
      "iteration 139 / 300: loss 0.610562\n",
      "iteration 139 / 300: loss 0.587782\n",
      "iteration 139 / 300: loss 0.599351\n",
      "iteration 139 / 300: loss 0.602792\n",
      "iteration 139 / 300: loss 0.605029\n",
      "iteration 139 / 300: loss 0.603848\n",
      "iteration 139 / 300: loss 0.624144\n",
      "iteration 139 / 300: loss 0.587219\n",
      "iteration 139 / 300: loss 0.580755\n",
      "iteration 139 / 300: loss 0.625046\n",
      "iteration 139 / 300: loss 0.603310\n",
      "iteration 139 / 300: loss 0.604322\n",
      "iteration 139 / 300: loss 0.595476\n",
      "iteration 139 / 300: loss 0.597543\n",
      "iteration 139 / 300: loss 0.592741\n",
      "iteration 139 / 300: loss 0.589494\n",
      "iteration 139 / 300: loss 0.599265\n",
      "iteration 139 / 300: loss 0.611380\n",
      "iteration 139 / 300: loss 0.592463\n",
      "iteration 139 / 300: loss 0.599425\n",
      "iteration 139 / 300: loss 0.603101\n",
      "iteration 139 / 300: loss 0.602411\n",
      "iteration 139 / 300: loss 0.579812\n",
      "iteration 139 / 300: loss 0.601592\n",
      "iteration 140 / 300: loss 0.585528\n",
      "iteration 140 / 300: loss 0.588428\n",
      "iteration 140 / 300: loss 0.567517\n",
      "iteration 140 / 300: loss 0.592380\n",
      "iteration 140 / 300: loss 0.593619\n",
      "iteration 140 / 300: loss 0.595296\n",
      "iteration 140 / 300: loss 0.608784\n",
      "iteration 140 / 300: loss 0.592732\n",
      "iteration 140 / 300: loss 0.628061\n",
      "iteration 140 / 300: loss 0.580152\n",
      "iteration 140 / 300: loss 0.607923\n",
      "iteration 140 / 300: loss 0.587395\n",
      "iteration 140 / 300: loss 0.591687\n",
      "iteration 140 / 300: loss 0.571370\n",
      "iteration 140 / 300: loss 0.583025\n",
      "iteration 140 / 300: loss 0.608441\n",
      "iteration 140 / 300: loss 0.598359\n",
      "iteration 140 / 300: loss 0.583858\n",
      "iteration 140 / 300: loss 0.615253\n",
      "iteration 140 / 300: loss 0.591650\n",
      "iteration 140 / 300: loss 0.585499\n",
      "iteration 140 / 300: loss 0.591325\n",
      "iteration 140 / 300: loss 0.604341\n",
      "iteration 140 / 300: loss 0.595787\n",
      "iteration 140 / 300: loss 0.614950\n",
      "iteration 140 / 300: loss 0.608389\n",
      "iteration 140 / 300: loss 0.598223\n",
      "iteration 140 / 300: loss 0.588936\n",
      "iteration 140 / 300: loss 0.617757\n",
      "iteration 140 / 300: loss 0.594770\n",
      "iteration 140 / 300: loss 0.601685\n",
      "iteration 140 / 300: loss 0.631031\n",
      "iteration 140 / 300: loss 0.587513\n",
      "iteration 140 / 300: loss 0.606562\n",
      "iteration 140 / 300: loss 0.588034\n",
      "iteration 140 / 300: loss 0.600890\n",
      "iteration 140 / 300: loss 0.595958\n",
      "iteration 140 / 300: loss 0.589291\n",
      "iteration 140 / 300: loss 0.599526\n",
      "iteration 140 / 300: loss 0.604856\n",
      "iteration 140 / 300: loss 0.619414\n",
      "iteration 140 / 300: loss 0.588808\n",
      "iteration 140 / 300: loss 0.593645\n",
      "iteration 140 / 300: loss 0.585595\n",
      "iteration 140 / 300: loss 0.613213\n",
      "iteration 140 / 300: loss 0.587524\n",
      "iteration 140 / 300: loss 0.578329\n",
      "iteration 140 / 300: loss 0.567435\n",
      "iteration 140 / 300: loss 0.562235\n",
      "iteration 140 / 300: loss 0.594184\n",
      "iteration 140 / 300: loss 0.578821\n",
      "iteration 140 / 300: loss 0.586361\n",
      "iteration 140 / 300: loss 0.572890\n",
      "iteration 140 / 300: loss 0.596152\n",
      "iteration 140 / 300: loss 0.607951\n",
      "iteration 140 / 300: loss 0.610839\n",
      "iteration 140 / 300: loss 0.606266\n",
      "iteration 140 / 300: loss 0.583790\n",
      "iteration 140 / 300: loss 0.589627\n",
      "iteration 140 / 300: loss 0.595184\n",
      "iteration 140 / 300: loss 0.598955\n",
      "iteration 140 / 300: loss 0.596133\n",
      "iteration 140 / 300: loss 0.589770\n",
      "iteration 140 / 300: loss 0.591136\n",
      "iteration 140 / 300: loss 0.584854\n",
      "iteration 140 / 300: loss 0.599647\n",
      "iteration 140 / 300: loss 0.598902\n",
      "iteration 140 / 300: loss 0.614283\n",
      "iteration 140 / 300: loss 0.597797\n",
      "iteration 140 / 300: loss 0.599299\n",
      "iteration 140 / 300: loss 0.603318\n",
      "iteration 140 / 300: loss 0.592866\n",
      "iteration 140 / 300: loss 0.592391\n",
      "iteration 140 / 300: loss 0.589041\n",
      "iteration 140 / 300: loss 0.596446\n",
      "iteration 140 / 300: loss 0.605709\n",
      "iteration 140 / 300: loss 0.610562\n",
      "iteration 140 / 300: loss 0.587782\n",
      "iteration 140 / 300: loss 0.599351\n",
      "iteration 140 / 300: loss 0.602792\n",
      "iteration 140 / 300: loss 0.605029\n",
      "iteration 140 / 300: loss 0.603848\n",
      "iteration 140 / 300: loss 0.624144\n",
      "iteration 140 / 300: loss 0.587219\n",
      "iteration 140 / 300: loss 0.580755\n",
      "iteration 140 / 300: loss 0.625046\n",
      "iteration 140 / 300: loss 0.603310\n",
      "iteration 140 / 300: loss 0.604322\n",
      "iteration 140 / 300: loss 0.595476\n",
      "iteration 140 / 300: loss 0.597543\n",
      "iteration 140 / 300: loss 0.592741\n",
      "iteration 140 / 300: loss 0.589494\n",
      "iteration 140 / 300: loss 0.599264\n",
      "iteration 140 / 300: loss 0.611380\n",
      "iteration 140 / 300: loss 0.592463\n",
      "iteration 140 / 300: loss 0.599425\n",
      "iteration 140 / 300: loss 0.603101\n",
      "iteration 140 / 300: loss 0.602411\n",
      "iteration 140 / 300: loss 0.579812\n",
      "iteration 140 / 300: loss 0.601592\n",
      "iteration 141 / 300: loss 0.585528\n",
      "iteration 141 / 300: loss 0.588428\n",
      "iteration 141 / 300: loss 0.567517\n",
      "iteration 141 / 300: loss 0.592380\n",
      "iteration 141 / 300: loss 0.593618\n",
      "iteration 141 / 300: loss 0.595295\n",
      "iteration 141 / 300: loss 0.608784\n",
      "iteration 141 / 300: loss 0.592732\n",
      "iteration 141 / 300: loss 0.628061\n",
      "iteration 141 / 300: loss 0.580152\n",
      "iteration 141 / 300: loss 0.607923\n",
      "iteration 141 / 300: loss 0.587395\n",
      "iteration 141 / 300: loss 0.591687\n",
      "iteration 141 / 300: loss 0.571370\n",
      "iteration 141 / 300: loss 0.583025\n",
      "iteration 141 / 300: loss 0.608441\n",
      "iteration 141 / 300: loss 0.598359\n",
      "iteration 141 / 300: loss 0.583858\n",
      "iteration 141 / 300: loss 0.615253\n",
      "iteration 141 / 300: loss 0.591650\n",
      "iteration 141 / 300: loss 0.585499\n",
      "iteration 141 / 300: loss 0.591325\n",
      "iteration 141 / 300: loss 0.604341\n",
      "iteration 141 / 300: loss 0.595787\n",
      "iteration 141 / 300: loss 0.614950\n",
      "iteration 141 / 300: loss 0.608389\n",
      "iteration 141 / 300: loss 0.598223\n",
      "iteration 141 / 300: loss 0.588936\n",
      "iteration 141 / 300: loss 0.617757\n",
      "iteration 141 / 300: loss 0.594770\n",
      "iteration 141 / 300: loss 0.601685\n",
      "iteration 141 / 300: loss 0.631031\n",
      "iteration 141 / 300: loss 0.587513\n",
      "iteration 141 / 300: loss 0.606562\n",
      "iteration 141 / 300: loss 0.588034\n",
      "iteration 141 / 300: loss 0.600890\n",
      "iteration 141 / 300: loss 0.595958\n",
      "iteration 141 / 300: loss 0.589291\n",
      "iteration 141 / 300: loss 0.599526\n",
      "iteration 141 / 300: loss 0.604856\n",
      "iteration 141 / 300: loss 0.619414\n",
      "iteration 141 / 300: loss 0.588808\n",
      "iteration 141 / 300: loss 0.593645\n",
      "iteration 141 / 300: loss 0.585595\n",
      "iteration 141 / 300: loss 0.613213\n",
      "iteration 141 / 300: loss 0.587524\n",
      "iteration 141 / 300: loss 0.578329\n",
      "iteration 141 / 300: loss 0.567435\n",
      "iteration 141 / 300: loss 0.562235\n",
      "iteration 141 / 300: loss 0.594184\n",
      "iteration 141 / 300: loss 0.578821\n",
      "iteration 141 / 300: loss 0.586361\n",
      "iteration 141 / 300: loss 0.572890\n",
      "iteration 141 / 300: loss 0.596151\n",
      "iteration 141 / 300: loss 0.607951\n",
      "iteration 141 / 300: loss 0.610839\n",
      "iteration 141 / 300: loss 0.606266\n",
      "iteration 141 / 300: loss 0.583790\n",
      "iteration 141 / 300: loss 0.589627\n",
      "iteration 141 / 300: loss 0.595184\n",
      "iteration 141 / 300: loss 0.598955\n",
      "iteration 141 / 300: loss 0.596133\n",
      "iteration 141 / 300: loss 0.589770\n",
      "iteration 141 / 300: loss 0.591136\n",
      "iteration 141 / 300: loss 0.584854\n",
      "iteration 141 / 300: loss 0.599647\n",
      "iteration 141 / 300: loss 0.598902\n",
      "iteration 141 / 300: loss 0.614283\n",
      "iteration 141 / 300: loss 0.597797\n",
      "iteration 141 / 300: loss 0.599299\n",
      "iteration 141 / 300: loss 0.603318\n",
      "iteration 141 / 300: loss 0.592866\n",
      "iteration 141 / 300: loss 0.592391\n",
      "iteration 141 / 300: loss 0.589041\n",
      "iteration 141 / 300: loss 0.596446\n",
      "iteration 141 / 300: loss 0.605709\n",
      "iteration 141 / 300: loss 0.610562\n",
      "iteration 141 / 300: loss 0.587782\n",
      "iteration 141 / 300: loss 0.599351\n",
      "iteration 141 / 300: loss 0.602792\n",
      "iteration 141 / 300: loss 0.605029\n",
      "iteration 141 / 300: loss 0.603848\n",
      "iteration 141 / 300: loss 0.624144\n",
      "iteration 141 / 300: loss 0.587219\n",
      "iteration 141 / 300: loss 0.580755\n",
      "iteration 141 / 300: loss 0.625046\n",
      "iteration 141 / 300: loss 0.603310\n",
      "iteration 141 / 300: loss 0.604322\n",
      "iteration 141 / 300: loss 0.595476\n",
      "iteration 141 / 300: loss 0.597543\n",
      "iteration 141 / 300: loss 0.592740\n",
      "iteration 141 / 300: loss 0.589494\n",
      "iteration 141 / 300: loss 0.599264\n",
      "iteration 141 / 300: loss 0.611380\n",
      "iteration 141 / 300: loss 0.592463\n",
      "iteration 141 / 300: loss 0.599425\n",
      "iteration 141 / 300: loss 0.603101\n",
      "iteration 141 / 300: loss 0.602411\n",
      "iteration 141 / 300: loss 0.579812\n",
      "iteration 141 / 300: loss 0.601592\n",
      "iteration 142 / 300: loss 0.585528\n",
      "iteration 142 / 300: loss 0.588428\n",
      "iteration 142 / 300: loss 0.567517\n",
      "iteration 142 / 300: loss 0.592380\n",
      "iteration 142 / 300: loss 0.593618\n",
      "iteration 142 / 300: loss 0.595295\n",
      "iteration 142 / 300: loss 0.608784\n",
      "iteration 142 / 300: loss 0.592732\n",
      "iteration 142 / 300: loss 0.628061\n",
      "iteration 142 / 300: loss 0.580152\n",
      "iteration 142 / 300: loss 0.607923\n",
      "iteration 142 / 300: loss 0.587395\n",
      "iteration 142 / 300: loss 0.591686\n",
      "iteration 142 / 300: loss 0.571370\n",
      "iteration 142 / 300: loss 0.583025\n",
      "iteration 142 / 300: loss 0.608441\n",
      "iteration 142 / 300: loss 0.598359\n",
      "iteration 142 / 300: loss 0.583858\n",
      "iteration 142 / 300: loss 0.615253\n",
      "iteration 142 / 300: loss 0.591650\n",
      "iteration 142 / 300: loss 0.585499\n",
      "iteration 142 / 300: loss 0.591325\n",
      "iteration 142 / 300: loss 0.604341\n",
      "iteration 142 / 300: loss 0.595787\n",
      "iteration 142 / 300: loss 0.614950\n",
      "iteration 142 / 300: loss 0.608389\n",
      "iteration 142 / 300: loss 0.598223\n",
      "iteration 142 / 300: loss 0.588936\n",
      "iteration 142 / 300: loss 0.617757\n",
      "iteration 142 / 300: loss 0.594770\n",
      "iteration 142 / 300: loss 0.601685\n",
      "iteration 142 / 300: loss 0.631031\n",
      "iteration 142 / 300: loss 0.587513\n",
      "iteration 142 / 300: loss 0.606562\n",
      "iteration 142 / 300: loss 0.588034\n",
      "iteration 142 / 300: loss 0.600890\n",
      "iteration 142 / 300: loss 0.595958\n",
      "iteration 142 / 300: loss 0.589291\n",
      "iteration 142 / 300: loss 0.599526\n",
      "iteration 142 / 300: loss 0.604856\n",
      "iteration 142 / 300: loss 0.619414\n",
      "iteration 142 / 300: loss 0.588808\n",
      "iteration 142 / 300: loss 0.593645\n",
      "iteration 142 / 300: loss 0.585595\n",
      "iteration 142 / 300: loss 0.613213\n",
      "iteration 142 / 300: loss 0.587524\n",
      "iteration 142 / 300: loss 0.578328\n",
      "iteration 142 / 300: loss 0.567435\n",
      "iteration 142 / 300: loss 0.562235\n",
      "iteration 142 / 300: loss 0.594184\n",
      "iteration 142 / 300: loss 0.578821\n",
      "iteration 142 / 300: loss 0.586360\n",
      "iteration 142 / 300: loss 0.572890\n",
      "iteration 142 / 300: loss 0.596151\n",
      "iteration 142 / 300: loss 0.607951\n",
      "iteration 142 / 300: loss 0.610839\n",
      "iteration 142 / 300: loss 0.606266\n",
      "iteration 142 / 300: loss 0.583790\n",
      "iteration 142 / 300: loss 0.589627\n",
      "iteration 142 / 300: loss 0.595184\n",
      "iteration 142 / 300: loss 0.598955\n",
      "iteration 142 / 300: loss 0.596133\n",
      "iteration 142 / 300: loss 0.589770\n",
      "iteration 142 / 300: loss 0.591136\n",
      "iteration 142 / 300: loss 0.584854\n",
      "iteration 142 / 300: loss 0.599647\n",
      "iteration 142 / 300: loss 0.598902\n",
      "iteration 142 / 300: loss 0.614283\n",
      "iteration 142 / 300: loss 0.597797\n",
      "iteration 142 / 300: loss 0.599299\n",
      "iteration 142 / 300: loss 0.603318\n",
      "iteration 142 / 300: loss 0.592866\n",
      "iteration 142 / 300: loss 0.592391\n",
      "iteration 142 / 300: loss 0.589041\n",
      "iteration 142 / 300: loss 0.596446\n",
      "iteration 142 / 300: loss 0.605709\n",
      "iteration 142 / 300: loss 0.610562\n",
      "iteration 142 / 300: loss 0.587782\n",
      "iteration 142 / 300: loss 0.599351\n",
      "iteration 142 / 300: loss 0.602792\n",
      "iteration 142 / 300: loss 0.605028\n",
      "iteration 142 / 300: loss 0.603848\n",
      "iteration 142 / 300: loss 0.624144\n",
      "iteration 142 / 300: loss 0.587219\n",
      "iteration 142 / 300: loss 0.580755\n",
      "iteration 142 / 300: loss 0.625046\n",
      "iteration 142 / 300: loss 0.603310\n",
      "iteration 142 / 300: loss 0.604322\n",
      "iteration 142 / 300: loss 0.595476\n",
      "iteration 142 / 300: loss 0.597543\n",
      "iteration 142 / 300: loss 0.592740\n",
      "iteration 142 / 300: loss 0.589494\n",
      "iteration 142 / 300: loss 0.599264\n",
      "iteration 142 / 300: loss 0.611380\n",
      "iteration 142 / 300: loss 0.592463\n",
      "iteration 142 / 300: loss 0.599425\n",
      "iteration 142 / 300: loss 0.603101\n",
      "iteration 142 / 300: loss 0.602411\n",
      "iteration 142 / 300: loss 0.579812\n",
      "iteration 142 / 300: loss 0.601592\n",
      "iteration 143 / 300: loss 0.585528\n",
      "iteration 143 / 300: loss 0.588428\n",
      "iteration 143 / 300: loss 0.567517\n",
      "iteration 143 / 300: loss 0.592380\n",
      "iteration 143 / 300: loss 0.593618\n",
      "iteration 143 / 300: loss 0.595295\n",
      "iteration 143 / 300: loss 0.608784\n",
      "iteration 143 / 300: loss 0.592732\n",
      "iteration 143 / 300: loss 0.628061\n",
      "iteration 143 / 300: loss 0.580152\n",
      "iteration 143 / 300: loss 0.607923\n",
      "iteration 143 / 300: loss 0.587395\n",
      "iteration 143 / 300: loss 0.591686\n",
      "iteration 143 / 300: loss 0.571370\n",
      "iteration 143 / 300: loss 0.583025\n",
      "iteration 143 / 300: loss 0.608441\n",
      "iteration 143 / 300: loss 0.598359\n",
      "iteration 143 / 300: loss 0.583858\n",
      "iteration 143 / 300: loss 0.615253\n",
      "iteration 143 / 300: loss 0.591650\n",
      "iteration 143 / 300: loss 0.585499\n",
      "iteration 143 / 300: loss 0.591325\n",
      "iteration 143 / 300: loss 0.604341\n",
      "iteration 143 / 300: loss 0.595787\n",
      "iteration 143 / 300: loss 0.614950\n",
      "iteration 143 / 300: loss 0.608389\n",
      "iteration 143 / 300: loss 0.598223\n",
      "iteration 143 / 300: loss 0.588936\n",
      "iteration 143 / 300: loss 0.617757\n",
      "iteration 143 / 300: loss 0.594770\n",
      "iteration 143 / 300: loss 0.601685\n",
      "iteration 143 / 300: loss 0.631031\n",
      "iteration 143 / 300: loss 0.587513\n",
      "iteration 143 / 300: loss 0.606562\n",
      "iteration 143 / 300: loss 0.588034\n",
      "iteration 143 / 300: loss 0.600890\n",
      "iteration 143 / 300: loss 0.595958\n",
      "iteration 143 / 300: loss 0.589291\n",
      "iteration 143 / 300: loss 0.599526\n",
      "iteration 143 / 300: loss 0.604856\n",
      "iteration 143 / 300: loss 0.619414\n",
      "iteration 143 / 300: loss 0.588808\n",
      "iteration 143 / 300: loss 0.593645\n",
      "iteration 143 / 300: loss 0.585595\n",
      "iteration 143 / 300: loss 0.613213\n",
      "iteration 143 / 300: loss 0.587524\n",
      "iteration 143 / 300: loss 0.578328\n",
      "iteration 143 / 300: loss 0.567435\n",
      "iteration 143 / 300: loss 0.562235\n",
      "iteration 143 / 300: loss 0.594184\n",
      "iteration 143 / 300: loss 0.578821\n",
      "iteration 143 / 300: loss 0.586360\n",
      "iteration 143 / 300: loss 0.572890\n",
      "iteration 143 / 300: loss 0.596151\n",
      "iteration 143 / 300: loss 0.607951\n",
      "iteration 143 / 300: loss 0.610839\n",
      "iteration 143 / 300: loss 0.606266\n",
      "iteration 143 / 300: loss 0.583790\n",
      "iteration 143 / 300: loss 0.589627\n",
      "iteration 143 / 300: loss 0.595184\n",
      "iteration 143 / 300: loss 0.598955\n",
      "iteration 143 / 300: loss 0.596133\n",
      "iteration 143 / 300: loss 0.589770\n",
      "iteration 143 / 300: loss 0.591136\n",
      "iteration 143 / 300: loss 0.584854\n",
      "iteration 143 / 300: loss 0.599647\n",
      "iteration 143 / 300: loss 0.598902\n",
      "iteration 143 / 300: loss 0.614283\n",
      "iteration 143 / 300: loss 0.597797\n",
      "iteration 143 / 300: loss 0.599298\n",
      "iteration 143 / 300: loss 0.603317\n",
      "iteration 143 / 300: loss 0.592866\n",
      "iteration 143 / 300: loss 0.592391\n",
      "iteration 143 / 300: loss 0.589041\n",
      "iteration 143 / 300: loss 0.596446\n",
      "iteration 143 / 300: loss 0.605709\n",
      "iteration 143 / 300: loss 0.610562\n",
      "iteration 143 / 300: loss 0.587782\n",
      "iteration 143 / 300: loss 0.599351\n",
      "iteration 143 / 300: loss 0.602792\n",
      "iteration 143 / 300: loss 0.605028\n",
      "iteration 143 / 300: loss 0.603848\n",
      "iteration 143 / 300: loss 0.624144\n",
      "iteration 143 / 300: loss 0.587219\n",
      "iteration 143 / 300: loss 0.580755\n",
      "iteration 143 / 300: loss 0.625046\n",
      "iteration 143 / 300: loss 0.603310\n",
      "iteration 143 / 300: loss 0.604322\n",
      "iteration 143 / 300: loss 0.595476\n",
      "iteration 143 / 300: loss 0.597543\n",
      "iteration 143 / 300: loss 0.592740\n",
      "iteration 143 / 300: loss 0.589494\n",
      "iteration 143 / 300: loss 0.599264\n",
      "iteration 143 / 300: loss 0.611380\n",
      "iteration 143 / 300: loss 0.592463\n",
      "iteration 143 / 300: loss 0.599425\n",
      "iteration 143 / 300: loss 0.603101\n",
      "iteration 143 / 300: loss 0.602410\n",
      "iteration 143 / 300: loss 0.579812\n",
      "iteration 143 / 300: loss 0.601592\n",
      "iteration 144 / 300: loss 0.585528\n",
      "iteration 144 / 300: loss 0.588428\n",
      "iteration 144 / 300: loss 0.567517\n",
      "iteration 144 / 300: loss 0.592380\n",
      "iteration 144 / 300: loss 0.593618\n",
      "iteration 144 / 300: loss 0.595295\n",
      "iteration 144 / 300: loss 0.608784\n",
      "iteration 144 / 300: loss 0.592732\n",
      "iteration 144 / 300: loss 0.628061\n",
      "iteration 144 / 300: loss 0.580152\n",
      "iteration 144 / 300: loss 0.607923\n",
      "iteration 144 / 300: loss 0.587395\n",
      "iteration 144 / 300: loss 0.591686\n",
      "iteration 144 / 300: loss 0.571370\n",
      "iteration 144 / 300: loss 0.583025\n",
      "iteration 144 / 300: loss 0.608441\n",
      "iteration 144 / 300: loss 0.598359\n",
      "iteration 144 / 300: loss 0.583858\n",
      "iteration 144 / 300: loss 0.615253\n",
      "iteration 144 / 300: loss 0.591650\n",
      "iteration 144 / 300: loss 0.585499\n",
      "iteration 144 / 300: loss 0.591325\n",
      "iteration 144 / 300: loss 0.604341\n",
      "iteration 144 / 300: loss 0.595787\n",
      "iteration 144 / 300: loss 0.614950\n",
      "iteration 144 / 300: loss 0.608389\n",
      "iteration 144 / 300: loss 0.598223\n",
      "iteration 144 / 300: loss 0.588936\n",
      "iteration 144 / 300: loss 0.617757\n",
      "iteration 144 / 300: loss 0.594770\n",
      "iteration 144 / 300: loss 0.601685\n",
      "iteration 144 / 300: loss 0.631031\n",
      "iteration 144 / 300: loss 0.587513\n",
      "iteration 144 / 300: loss 0.606562\n",
      "iteration 144 / 300: loss 0.588034\n",
      "iteration 144 / 300: loss 0.600890\n",
      "iteration 144 / 300: loss 0.595958\n",
      "iteration 144 / 300: loss 0.589291\n",
      "iteration 144 / 300: loss 0.599526\n",
      "iteration 144 / 300: loss 0.604856\n",
      "iteration 144 / 300: loss 0.619414\n",
      "iteration 144 / 300: loss 0.588808\n",
      "iteration 144 / 300: loss 0.593645\n",
      "iteration 144 / 300: loss 0.585595\n",
      "iteration 144 / 300: loss 0.613213\n",
      "iteration 144 / 300: loss 0.587523\n",
      "iteration 144 / 300: loss 0.578328\n",
      "iteration 144 / 300: loss 0.567435\n",
      "iteration 144 / 300: loss 0.562235\n",
      "iteration 144 / 300: loss 0.594184\n",
      "iteration 144 / 300: loss 0.578821\n",
      "iteration 144 / 300: loss 0.586360\n",
      "iteration 144 / 300: loss 0.572890\n",
      "iteration 144 / 300: loss 0.596151\n",
      "iteration 144 / 300: loss 0.607951\n",
      "iteration 144 / 300: loss 0.610839\n",
      "iteration 144 / 300: loss 0.606266\n",
      "iteration 144 / 300: loss 0.583790\n",
      "iteration 144 / 300: loss 0.589627\n",
      "iteration 144 / 300: loss 0.595184\n",
      "iteration 144 / 300: loss 0.598955\n",
      "iteration 144 / 300: loss 0.596133\n",
      "iteration 144 / 300: loss 0.589770\n",
      "iteration 144 / 300: loss 0.591136\n",
      "iteration 144 / 300: loss 0.584854\n",
      "iteration 144 / 300: loss 0.599647\n",
      "iteration 144 / 300: loss 0.598902\n",
      "iteration 144 / 300: loss 0.614283\n",
      "iteration 144 / 300: loss 0.597797\n",
      "iteration 144 / 300: loss 0.599298\n",
      "iteration 144 / 300: loss 0.603317\n",
      "iteration 144 / 300: loss 0.592866\n",
      "iteration 144 / 300: loss 0.592391\n",
      "iteration 144 / 300: loss 0.589041\n",
      "iteration 144 / 300: loss 0.596446\n",
      "iteration 144 / 300: loss 0.605709\n",
      "iteration 144 / 300: loss 0.610562\n",
      "iteration 144 / 300: loss 0.587782\n",
      "iteration 144 / 300: loss 0.599351\n",
      "iteration 144 / 300: loss 0.602792\n",
      "iteration 144 / 300: loss 0.605028\n",
      "iteration 144 / 300: loss 0.603848\n",
      "iteration 144 / 300: loss 0.624144\n",
      "iteration 144 / 300: loss 0.587219\n",
      "iteration 144 / 300: loss 0.580755\n",
      "iteration 144 / 300: loss 0.625046\n",
      "iteration 144 / 300: loss 0.603310\n",
      "iteration 144 / 300: loss 0.604322\n",
      "iteration 144 / 300: loss 0.595476\n",
      "iteration 144 / 300: loss 0.597543\n",
      "iteration 144 / 300: loss 0.592740\n",
      "iteration 144 / 300: loss 0.589494\n",
      "iteration 144 / 300: loss 0.599264\n",
      "iteration 144 / 300: loss 0.611380\n",
      "iteration 144 / 300: loss 0.592463\n",
      "iteration 144 / 300: loss 0.599425\n",
      "iteration 144 / 300: loss 0.603101\n",
      "iteration 144 / 300: loss 0.602410\n",
      "iteration 144 / 300: loss 0.579812\n",
      "iteration 144 / 300: loss 0.601592\n",
      "iteration 145 / 300: loss 0.585528\n",
      "iteration 145 / 300: loss 0.588428\n",
      "iteration 145 / 300: loss 0.567516\n",
      "iteration 145 / 300: loss 0.592380\n",
      "iteration 145 / 300: loss 0.593618\n",
      "iteration 145 / 300: loss 0.595295\n",
      "iteration 145 / 300: loss 0.608784\n",
      "iteration 145 / 300: loss 0.592732\n",
      "iteration 145 / 300: loss 0.628060\n",
      "iteration 145 / 300: loss 0.580152\n",
      "iteration 145 / 300: loss 0.607923\n",
      "iteration 145 / 300: loss 0.587395\n",
      "iteration 145 / 300: loss 0.591686\n",
      "iteration 145 / 300: loss 0.571370\n",
      "iteration 145 / 300: loss 0.583025\n",
      "iteration 145 / 300: loss 0.608441\n",
      "iteration 145 / 300: loss 0.598359\n",
      "iteration 145 / 300: loss 0.583858\n",
      "iteration 145 / 300: loss 0.615253\n",
      "iteration 145 / 300: loss 0.591650\n",
      "iteration 145 / 300: loss 0.585499\n",
      "iteration 145 / 300: loss 0.591325\n",
      "iteration 145 / 300: loss 0.604341\n",
      "iteration 145 / 300: loss 0.595787\n",
      "iteration 145 / 300: loss 0.614950\n",
      "iteration 145 / 300: loss 0.608389\n",
      "iteration 145 / 300: loss 0.598223\n",
      "iteration 145 / 300: loss 0.588936\n",
      "iteration 145 / 300: loss 0.617757\n",
      "iteration 145 / 300: loss 0.594770\n",
      "iteration 145 / 300: loss 0.601685\n",
      "iteration 145 / 300: loss 0.631031\n",
      "iteration 145 / 300: loss 0.587513\n",
      "iteration 145 / 300: loss 0.606562\n",
      "iteration 145 / 300: loss 0.588034\n",
      "iteration 145 / 300: loss 0.600890\n",
      "iteration 145 / 300: loss 0.595958\n",
      "iteration 145 / 300: loss 0.589291\n",
      "iteration 145 / 300: loss 0.599526\n",
      "iteration 145 / 300: loss 0.604856\n",
      "iteration 145 / 300: loss 0.619414\n",
      "iteration 145 / 300: loss 0.588808\n",
      "iteration 145 / 300: loss 0.593645\n",
      "iteration 145 / 300: loss 0.585595\n",
      "iteration 145 / 300: loss 0.613213\n",
      "iteration 145 / 300: loss 0.587523\n",
      "iteration 145 / 300: loss 0.578328\n",
      "iteration 145 / 300: loss 0.567435\n",
      "iteration 145 / 300: loss 0.562235\n",
      "iteration 145 / 300: loss 0.594184\n",
      "iteration 145 / 300: loss 0.578821\n",
      "iteration 145 / 300: loss 0.586360\n",
      "iteration 145 / 300: loss 0.572890\n",
      "iteration 145 / 300: loss 0.596151\n",
      "iteration 145 / 300: loss 0.607951\n",
      "iteration 145 / 300: loss 0.610839\n",
      "iteration 145 / 300: loss 0.606266\n",
      "iteration 145 / 300: loss 0.583790\n",
      "iteration 145 / 300: loss 0.589627\n",
      "iteration 145 / 300: loss 0.595184\n",
      "iteration 145 / 300: loss 0.598955\n",
      "iteration 145 / 300: loss 0.596133\n",
      "iteration 145 / 300: loss 0.589770\n",
      "iteration 145 / 300: loss 0.591136\n",
      "iteration 145 / 300: loss 0.584854\n",
      "iteration 145 / 300: loss 0.599647\n",
      "iteration 145 / 300: loss 0.598902\n",
      "iteration 145 / 300: loss 0.614283\n",
      "iteration 145 / 300: loss 0.597797\n",
      "iteration 145 / 300: loss 0.599298\n",
      "iteration 145 / 300: loss 0.603317\n",
      "iteration 145 / 300: loss 0.592866\n",
      "iteration 145 / 300: loss 0.592391\n",
      "iteration 145 / 300: loss 0.589041\n",
      "iteration 145 / 300: loss 0.596446\n",
      "iteration 145 / 300: loss 0.605709\n",
      "iteration 145 / 300: loss 0.610562\n",
      "iteration 145 / 300: loss 0.587782\n",
      "iteration 145 / 300: loss 0.599351\n",
      "iteration 145 / 300: loss 0.602792\n",
      "iteration 145 / 300: loss 0.605028\n",
      "iteration 145 / 300: loss 0.603848\n",
      "iteration 145 / 300: loss 0.624144\n",
      "iteration 145 / 300: loss 0.587219\n",
      "iteration 145 / 300: loss 0.580755\n",
      "iteration 145 / 300: loss 0.625046\n",
      "iteration 145 / 300: loss 0.603310\n",
      "iteration 145 / 300: loss 0.604322\n",
      "iteration 145 / 300: loss 0.595476\n",
      "iteration 145 / 300: loss 0.597543\n",
      "iteration 145 / 300: loss 0.592740\n",
      "iteration 145 / 300: loss 0.589494\n",
      "iteration 145 / 300: loss 0.599264\n",
      "iteration 145 / 300: loss 0.611380\n",
      "iteration 145 / 300: loss 0.592463\n",
      "iteration 145 / 300: loss 0.599425\n",
      "iteration 145 / 300: loss 0.603101\n",
      "iteration 145 / 300: loss 0.602410\n",
      "iteration 145 / 300: loss 0.579812\n",
      "iteration 145 / 300: loss 0.601592\n",
      "iteration 146 / 300: loss 0.585528\n",
      "iteration 146 / 300: loss 0.588428\n",
      "iteration 146 / 300: loss 0.567516\n",
      "iteration 146 / 300: loss 0.592380\n",
      "iteration 146 / 300: loss 0.593618\n",
      "iteration 146 / 300: loss 0.595295\n",
      "iteration 146 / 300: loss 0.608784\n",
      "iteration 146 / 300: loss 0.592732\n",
      "iteration 146 / 300: loss 0.628060\n",
      "iteration 146 / 300: loss 0.580152\n",
      "iteration 146 / 300: loss 0.607923\n",
      "iteration 146 / 300: loss 0.587395\n",
      "iteration 146 / 300: loss 0.591686\n",
      "iteration 146 / 300: loss 0.571370\n",
      "iteration 146 / 300: loss 0.583025\n",
      "iteration 146 / 300: loss 0.608441\n",
      "iteration 146 / 300: loss 0.598359\n",
      "iteration 146 / 300: loss 0.583858\n",
      "iteration 146 / 300: loss 0.615253\n",
      "iteration 146 / 300: loss 0.591650\n",
      "iteration 146 / 300: loss 0.585499\n",
      "iteration 146 / 300: loss 0.591325\n",
      "iteration 146 / 300: loss 0.604341\n",
      "iteration 146 / 300: loss 0.595787\n",
      "iteration 146 / 300: loss 0.614949\n",
      "iteration 146 / 300: loss 0.608389\n",
      "iteration 146 / 300: loss 0.598223\n",
      "iteration 146 / 300: loss 0.588936\n",
      "iteration 146 / 300: loss 0.617757\n",
      "iteration 146 / 300: loss 0.594770\n",
      "iteration 146 / 300: loss 0.601685\n",
      "iteration 146 / 300: loss 0.631031\n",
      "iteration 146 / 300: loss 0.587513\n",
      "iteration 146 / 300: loss 0.606562\n",
      "iteration 146 / 300: loss 0.588034\n",
      "iteration 146 / 300: loss 0.600890\n",
      "iteration 146 / 300: loss 0.595958\n",
      "iteration 146 / 300: loss 0.589291\n",
      "iteration 146 / 300: loss 0.599526\n",
      "iteration 146 / 300: loss 0.604856\n",
      "iteration 146 / 300: loss 0.619414\n",
      "iteration 146 / 300: loss 0.588808\n",
      "iteration 146 / 300: loss 0.593645\n",
      "iteration 146 / 300: loss 0.585595\n",
      "iteration 146 / 300: loss 0.613213\n",
      "iteration 146 / 300: loss 0.587523\n",
      "iteration 146 / 300: loss 0.578328\n",
      "iteration 146 / 300: loss 0.567435\n",
      "iteration 146 / 300: loss 0.562235\n",
      "iteration 146 / 300: loss 0.594184\n",
      "iteration 146 / 300: loss 0.578821\n",
      "iteration 146 / 300: loss 0.586360\n",
      "iteration 146 / 300: loss 0.572890\n",
      "iteration 146 / 300: loss 0.596151\n",
      "iteration 146 / 300: loss 0.607951\n",
      "iteration 146 / 300: loss 0.610839\n",
      "iteration 146 / 300: loss 0.606266\n",
      "iteration 146 / 300: loss 0.583790\n",
      "iteration 146 / 300: loss 0.589627\n",
      "iteration 146 / 300: loss 0.595184\n",
      "iteration 146 / 300: loss 0.598955\n",
      "iteration 146 / 300: loss 0.596133\n",
      "iteration 146 / 300: loss 0.589770\n",
      "iteration 146 / 300: loss 0.591136\n",
      "iteration 146 / 300: loss 0.584854\n",
      "iteration 146 / 300: loss 0.599647\n",
      "iteration 146 / 300: loss 0.598902\n",
      "iteration 146 / 300: loss 0.614283\n",
      "iteration 146 / 300: loss 0.597797\n",
      "iteration 146 / 300: loss 0.599298\n",
      "iteration 146 / 300: loss 0.603317\n",
      "iteration 146 / 300: loss 0.592866\n",
      "iteration 146 / 300: loss 0.592391\n",
      "iteration 146 / 300: loss 0.589041\n",
      "iteration 146 / 300: loss 0.596446\n",
      "iteration 146 / 300: loss 0.605709\n",
      "iteration 146 / 300: loss 0.610562\n",
      "iteration 146 / 300: loss 0.587782\n",
      "iteration 146 / 300: loss 0.599351\n",
      "iteration 146 / 300: loss 0.602792\n",
      "iteration 146 / 300: loss 0.605028\n",
      "iteration 146 / 300: loss 0.603848\n",
      "iteration 146 / 300: loss 0.624144\n",
      "iteration 146 / 300: loss 0.587219\n",
      "iteration 146 / 300: loss 0.580755\n",
      "iteration 146 / 300: loss 0.625046\n",
      "iteration 146 / 300: loss 0.603310\n",
      "iteration 146 / 300: loss 0.604322\n",
      "iteration 146 / 300: loss 0.595476\n",
      "iteration 146 / 300: loss 0.597543\n",
      "iteration 146 / 300: loss 0.592740\n",
      "iteration 146 / 300: loss 0.589494\n",
      "iteration 146 / 300: loss 0.599264\n",
      "iteration 146 / 300: loss 0.611380\n",
      "iteration 146 / 300: loss 0.592463\n",
      "iteration 146 / 300: loss 0.599425\n",
      "iteration 146 / 300: loss 0.603101\n",
      "iteration 146 / 300: loss 0.602410\n",
      "iteration 146 / 300: loss 0.579812\n",
      "iteration 146 / 300: loss 0.601592\n",
      "iteration 147 / 300: loss 0.585528\n",
      "iteration 147 / 300: loss 0.588428\n",
      "iteration 147 / 300: loss 0.567516\n",
      "iteration 147 / 300: loss 0.592380\n",
      "iteration 147 / 300: loss 0.593618\n",
      "iteration 147 / 300: loss 0.595295\n",
      "iteration 147 / 300: loss 0.608784\n",
      "iteration 147 / 300: loss 0.592732\n",
      "iteration 147 / 300: loss 0.628060\n",
      "iteration 147 / 300: loss 0.580152\n",
      "iteration 147 / 300: loss 0.607923\n",
      "iteration 147 / 300: loss 0.587395\n",
      "iteration 147 / 300: loss 0.591686\n",
      "iteration 147 / 300: loss 0.571370\n",
      "iteration 147 / 300: loss 0.583025\n",
      "iteration 147 / 300: loss 0.608441\n",
      "iteration 147 / 300: loss 0.598359\n",
      "iteration 147 / 300: loss 0.583858\n",
      "iteration 147 / 300: loss 0.615253\n",
      "iteration 147 / 300: loss 0.591650\n",
      "iteration 147 / 300: loss 0.585499\n",
      "iteration 147 / 300: loss 0.591325\n",
      "iteration 147 / 300: loss 0.604341\n",
      "iteration 147 / 300: loss 0.595786\n",
      "iteration 147 / 300: loss 0.614949\n",
      "iteration 147 / 300: loss 0.608389\n",
      "iteration 147 / 300: loss 0.598222\n",
      "iteration 147 / 300: loss 0.588936\n",
      "iteration 147 / 300: loss 0.617757\n",
      "iteration 147 / 300: loss 0.594770\n",
      "iteration 147 / 300: loss 0.601685\n",
      "iteration 147 / 300: loss 0.631031\n",
      "iteration 147 / 300: loss 0.587513\n",
      "iteration 147 / 300: loss 0.606562\n",
      "iteration 147 / 300: loss 0.588034\n",
      "iteration 147 / 300: loss 0.600890\n",
      "iteration 147 / 300: loss 0.595958\n",
      "iteration 147 / 300: loss 0.589291\n",
      "iteration 147 / 300: loss 0.599526\n",
      "iteration 147 / 300: loss 0.604856\n",
      "iteration 147 / 300: loss 0.619414\n",
      "iteration 147 / 300: loss 0.588808\n",
      "iteration 147 / 300: loss 0.593645\n",
      "iteration 147 / 300: loss 0.585595\n",
      "iteration 147 / 300: loss 0.613213\n",
      "iteration 147 / 300: loss 0.587523\n",
      "iteration 147 / 300: loss 0.578328\n",
      "iteration 147 / 300: loss 0.567435\n",
      "iteration 147 / 300: loss 0.562235\n",
      "iteration 147 / 300: loss 0.594183\n",
      "iteration 147 / 300: loss 0.578821\n",
      "iteration 147 / 300: loss 0.586360\n",
      "iteration 147 / 300: loss 0.572890\n",
      "iteration 147 / 300: loss 0.596151\n",
      "iteration 147 / 300: loss 0.607951\n",
      "iteration 147 / 300: loss 0.610839\n",
      "iteration 147 / 300: loss 0.606266\n",
      "iteration 147 / 300: loss 0.583790\n",
      "iteration 147 / 300: loss 0.589627\n",
      "iteration 147 / 300: loss 0.595184\n",
      "iteration 147 / 300: loss 0.598955\n",
      "iteration 147 / 300: loss 0.596133\n",
      "iteration 147 / 300: loss 0.589769\n",
      "iteration 147 / 300: loss 0.591136\n",
      "iteration 147 / 300: loss 0.584854\n",
      "iteration 147 / 300: loss 0.599647\n",
      "iteration 147 / 300: loss 0.598902\n",
      "iteration 147 / 300: loss 0.614283\n",
      "iteration 147 / 300: loss 0.597797\n",
      "iteration 147 / 300: loss 0.599298\n",
      "iteration 147 / 300: loss 0.603317\n",
      "iteration 147 / 300: loss 0.592866\n",
      "iteration 147 / 300: loss 0.592391\n",
      "iteration 147 / 300: loss 0.589041\n",
      "iteration 147 / 300: loss 0.596446\n",
      "iteration 147 / 300: loss 0.605709\n",
      "iteration 147 / 300: loss 0.610562\n",
      "iteration 147 / 300: loss 0.587782\n",
      "iteration 147 / 300: loss 0.599351\n",
      "iteration 147 / 300: loss 0.602792\n",
      "iteration 147 / 300: loss 0.605028\n",
      "iteration 147 / 300: loss 0.603848\n",
      "iteration 147 / 300: loss 0.624144\n",
      "iteration 147 / 300: loss 0.587219\n",
      "iteration 147 / 300: loss 0.580755\n",
      "iteration 147 / 300: loss 0.625046\n",
      "iteration 147 / 300: loss 0.603310\n",
      "iteration 147 / 300: loss 0.604322\n",
      "iteration 147 / 300: loss 0.595476\n",
      "iteration 147 / 300: loss 0.597543\n",
      "iteration 147 / 300: loss 0.592740\n",
      "iteration 147 / 300: loss 0.589494\n",
      "iteration 147 / 300: loss 0.599264\n",
      "iteration 147 / 300: loss 0.611380\n",
      "iteration 147 / 300: loss 0.592463\n",
      "iteration 147 / 300: loss 0.599425\n",
      "iteration 147 / 300: loss 0.603101\n",
      "iteration 147 / 300: loss 0.602410\n",
      "iteration 147 / 300: loss 0.579812\n",
      "iteration 147 / 300: loss 0.601592\n",
      "iteration 148 / 300: loss 0.585528\n",
      "iteration 148 / 300: loss 0.588428\n",
      "iteration 148 / 300: loss 0.567516\n",
      "iteration 148 / 300: loss 0.592380\n",
      "iteration 148 / 300: loss 0.593618\n",
      "iteration 148 / 300: loss 0.595295\n",
      "iteration 148 / 300: loss 0.608784\n",
      "iteration 148 / 300: loss 0.592732\n",
      "iteration 148 / 300: loss 0.628060\n",
      "iteration 148 / 300: loss 0.580152\n",
      "iteration 148 / 300: loss 0.607923\n",
      "iteration 148 / 300: loss 0.587395\n",
      "iteration 148 / 300: loss 0.591686\n",
      "iteration 148 / 300: loss 0.571370\n",
      "iteration 148 / 300: loss 0.583025\n",
      "iteration 148 / 300: loss 0.608441\n",
      "iteration 148 / 300: loss 0.598359\n",
      "iteration 148 / 300: loss 0.583858\n",
      "iteration 148 / 300: loss 0.615253\n",
      "iteration 148 / 300: loss 0.591650\n",
      "iteration 148 / 300: loss 0.585499\n",
      "iteration 148 / 300: loss 0.591325\n",
      "iteration 148 / 300: loss 0.604341\n",
      "iteration 148 / 300: loss 0.595786\n",
      "iteration 148 / 300: loss 0.614949\n",
      "iteration 148 / 300: loss 0.608389\n",
      "iteration 148 / 300: loss 0.598222\n",
      "iteration 148 / 300: loss 0.588936\n",
      "iteration 148 / 300: loss 0.617757\n",
      "iteration 148 / 300: loss 0.594770\n",
      "iteration 148 / 300: loss 0.601685\n",
      "iteration 148 / 300: loss 0.631031\n",
      "iteration 148 / 300: loss 0.587513\n",
      "iteration 148 / 300: loss 0.606562\n",
      "iteration 148 / 300: loss 0.588034\n",
      "iteration 148 / 300: loss 0.600890\n",
      "iteration 148 / 300: loss 0.595958\n",
      "iteration 148 / 300: loss 0.589291\n",
      "iteration 148 / 300: loss 0.599526\n",
      "iteration 148 / 300: loss 0.604856\n",
      "iteration 148 / 300: loss 0.619414\n",
      "iteration 148 / 300: loss 0.588808\n",
      "iteration 148 / 300: loss 0.593645\n",
      "iteration 148 / 300: loss 0.585595\n",
      "iteration 148 / 300: loss 0.613213\n",
      "iteration 148 / 300: loss 0.587523\n",
      "iteration 148 / 300: loss 0.578328\n",
      "iteration 148 / 300: loss 0.567435\n",
      "iteration 148 / 300: loss 0.562235\n",
      "iteration 148 / 300: loss 0.594183\n",
      "iteration 148 / 300: loss 0.578821\n",
      "iteration 148 / 300: loss 0.586360\n",
      "iteration 148 / 300: loss 0.572890\n",
      "iteration 148 / 300: loss 0.596151\n",
      "iteration 148 / 300: loss 0.607951\n",
      "iteration 148 / 300: loss 0.610839\n",
      "iteration 148 / 300: loss 0.606266\n",
      "iteration 148 / 300: loss 0.583790\n",
      "iteration 148 / 300: loss 0.589627\n",
      "iteration 148 / 300: loss 0.595184\n",
      "iteration 148 / 300: loss 0.598955\n",
      "iteration 148 / 300: loss 0.596133\n",
      "iteration 148 / 300: loss 0.589769\n",
      "iteration 148 / 300: loss 0.591136\n",
      "iteration 148 / 300: loss 0.584854\n",
      "iteration 148 / 300: loss 0.599647\n",
      "iteration 148 / 300: loss 0.598902\n",
      "iteration 148 / 300: loss 0.614283\n",
      "iteration 148 / 300: loss 0.597797\n",
      "iteration 148 / 300: loss 0.599298\n",
      "iteration 148 / 300: loss 0.603317\n",
      "iteration 148 / 300: loss 0.592866\n",
      "iteration 148 / 300: loss 0.592391\n",
      "iteration 148 / 300: loss 0.589041\n",
      "iteration 148 / 300: loss 0.596446\n",
      "iteration 148 / 300: loss 0.605709\n",
      "iteration 148 / 300: loss 0.610562\n",
      "iteration 148 / 300: loss 0.587782\n",
      "iteration 148 / 300: loss 0.599351\n",
      "iteration 148 / 300: loss 0.602792\n",
      "iteration 148 / 300: loss 0.605028\n",
      "iteration 148 / 300: loss 0.603848\n",
      "iteration 148 / 300: loss 0.624144\n",
      "iteration 148 / 300: loss 0.587219\n",
      "iteration 148 / 300: loss 0.580755\n",
      "iteration 148 / 300: loss 0.625046\n",
      "iteration 148 / 300: loss 0.603310\n",
      "iteration 148 / 300: loss 0.604322\n",
      "iteration 148 / 300: loss 0.595476\n",
      "iteration 148 / 300: loss 0.597543\n",
      "iteration 148 / 300: loss 0.592740\n",
      "iteration 148 / 300: loss 0.589494\n",
      "iteration 148 / 300: loss 0.599264\n",
      "iteration 148 / 300: loss 0.611380\n",
      "iteration 148 / 300: loss 0.592463\n",
      "iteration 148 / 300: loss 0.599425\n",
      "iteration 148 / 300: loss 0.603101\n",
      "iteration 148 / 300: loss 0.602410\n",
      "iteration 148 / 300: loss 0.579812\n",
      "iteration 148 / 300: loss 0.601592\n",
      "iteration 149 / 300: loss 0.585528\n",
      "iteration 149 / 300: loss 0.588428\n",
      "iteration 149 / 300: loss 0.567516\n",
      "iteration 149 / 300: loss 0.592380\n",
      "iteration 149 / 300: loss 0.593618\n",
      "iteration 149 / 300: loss 0.595295\n",
      "iteration 149 / 300: loss 0.608784\n",
      "iteration 149 / 300: loss 0.592732\n",
      "iteration 149 / 300: loss 0.628060\n",
      "iteration 149 / 300: loss 0.580152\n",
      "iteration 149 / 300: loss 0.607923\n",
      "iteration 149 / 300: loss 0.587395\n",
      "iteration 149 / 300: loss 0.591686\n",
      "iteration 149 / 300: loss 0.571370\n",
      "iteration 149 / 300: loss 0.583025\n",
      "iteration 149 / 300: loss 0.608441\n",
      "iteration 149 / 300: loss 0.598359\n",
      "iteration 149 / 300: loss 0.583858\n",
      "iteration 149 / 300: loss 0.615253\n",
      "iteration 149 / 300: loss 0.591650\n",
      "iteration 149 / 300: loss 0.585499\n",
      "iteration 149 / 300: loss 0.591325\n",
      "iteration 149 / 300: loss 0.604341\n",
      "iteration 149 / 300: loss 0.595786\n",
      "iteration 149 / 300: loss 0.614949\n",
      "iteration 149 / 300: loss 0.608389\n",
      "iteration 149 / 300: loss 0.598222\n",
      "iteration 149 / 300: loss 0.588936\n",
      "iteration 149 / 300: loss 0.617757\n",
      "iteration 149 / 300: loss 0.594770\n",
      "iteration 149 / 300: loss 0.601684\n",
      "iteration 149 / 300: loss 0.631031\n",
      "iteration 149 / 300: loss 0.587513\n",
      "iteration 149 / 300: loss 0.606562\n",
      "iteration 149 / 300: loss 0.588034\n",
      "iteration 149 / 300: loss 0.600890\n",
      "iteration 149 / 300: loss 0.595958\n",
      "iteration 149 / 300: loss 0.589291\n",
      "iteration 149 / 300: loss 0.599526\n",
      "iteration 149 / 300: loss 0.604855\n",
      "iteration 149 / 300: loss 0.619414\n",
      "iteration 149 / 300: loss 0.588808\n",
      "iteration 149 / 300: loss 0.593645\n",
      "iteration 149 / 300: loss 0.585595\n",
      "iteration 149 / 300: loss 0.613213\n",
      "iteration 149 / 300: loss 0.587523\n",
      "iteration 149 / 300: loss 0.578328\n",
      "iteration 149 / 300: loss 0.567435\n",
      "iteration 149 / 300: loss 0.562235\n",
      "iteration 149 / 300: loss 0.594183\n",
      "iteration 149 / 300: loss 0.578821\n",
      "iteration 149 / 300: loss 0.586360\n",
      "iteration 149 / 300: loss 0.572890\n",
      "iteration 149 / 300: loss 0.596151\n",
      "iteration 149 / 300: loss 0.607951\n",
      "iteration 149 / 300: loss 0.610839\n",
      "iteration 149 / 300: loss 0.606266\n",
      "iteration 149 / 300: loss 0.583790\n",
      "iteration 149 / 300: loss 0.589627\n",
      "iteration 149 / 300: loss 0.595184\n",
      "iteration 149 / 300: loss 0.598955\n",
      "iteration 149 / 300: loss 0.596133\n",
      "iteration 149 / 300: loss 0.589769\n",
      "iteration 149 / 300: loss 0.591136\n",
      "iteration 149 / 300: loss 0.584854\n",
      "iteration 149 / 300: loss 0.599647\n",
      "iteration 149 / 300: loss 0.598902\n",
      "iteration 149 / 300: loss 0.614283\n",
      "iteration 149 / 300: loss 0.597797\n",
      "iteration 149 / 300: loss 0.599298\n",
      "iteration 149 / 300: loss 0.603317\n",
      "iteration 149 / 300: loss 0.592866\n",
      "iteration 149 / 300: loss 0.592391\n",
      "iteration 149 / 300: loss 0.589041\n",
      "iteration 149 / 300: loss 0.596446\n",
      "iteration 149 / 300: loss 0.605709\n",
      "iteration 149 / 300: loss 0.610562\n",
      "iteration 149 / 300: loss 0.587782\n",
      "iteration 149 / 300: loss 0.599351\n",
      "iteration 149 / 300: loss 0.602792\n",
      "iteration 149 / 300: loss 0.605028\n",
      "iteration 149 / 300: loss 0.603848\n",
      "iteration 149 / 300: loss 0.624144\n",
      "iteration 149 / 300: loss 0.587219\n",
      "iteration 149 / 300: loss 0.580755\n",
      "iteration 149 / 300: loss 0.625046\n",
      "iteration 149 / 300: loss 0.603310\n",
      "iteration 149 / 300: loss 0.604322\n",
      "iteration 149 / 300: loss 0.595476\n",
      "iteration 149 / 300: loss 0.597543\n",
      "iteration 149 / 300: loss 0.592740\n",
      "iteration 149 / 300: loss 0.589494\n",
      "iteration 149 / 300: loss 0.599264\n",
      "iteration 149 / 300: loss 0.611380\n",
      "iteration 149 / 300: loss 0.592463\n",
      "iteration 149 / 300: loss 0.599425\n",
      "iteration 149 / 300: loss 0.603101\n",
      "iteration 149 / 300: loss 0.602410\n",
      "iteration 149 / 300: loss 0.579812\n",
      "iteration 149 / 300: loss 0.601592\n",
      "iteration 150 / 300: loss 0.585528\n",
      "iteration 150 / 300: loss 0.588428\n",
      "iteration 150 / 300: loss 0.567516\n",
      "iteration 150 / 300: loss 0.592380\n",
      "iteration 150 / 300: loss 0.593618\n",
      "iteration 150 / 300: loss 0.595295\n",
      "iteration 150 / 300: loss 0.608784\n",
      "iteration 150 / 300: loss 0.592732\n",
      "iteration 150 / 300: loss 0.628060\n",
      "iteration 150 / 300: loss 0.580152\n",
      "iteration 150 / 300: loss 0.607923\n",
      "iteration 150 / 300: loss 0.587395\n",
      "iteration 150 / 300: loss 0.591686\n",
      "iteration 150 / 300: loss 0.571370\n",
      "iteration 150 / 300: loss 0.583025\n",
      "iteration 150 / 300: loss 0.608441\n",
      "iteration 150 / 300: loss 0.598359\n",
      "iteration 150 / 300: loss 0.583858\n",
      "iteration 150 / 300: loss 0.615253\n",
      "iteration 150 / 300: loss 0.591650\n",
      "iteration 150 / 300: loss 0.585499\n",
      "iteration 150 / 300: loss 0.591325\n",
      "iteration 150 / 300: loss 0.604341\n",
      "iteration 150 / 300: loss 0.595786\n",
      "iteration 150 / 300: loss 0.614949\n",
      "iteration 150 / 300: loss 0.608389\n",
      "iteration 150 / 300: loss 0.598222\n",
      "iteration 150 / 300: loss 0.588936\n",
      "iteration 150 / 300: loss 0.617757\n",
      "iteration 150 / 300: loss 0.594770\n",
      "iteration 150 / 300: loss 0.601684\n",
      "iteration 150 / 300: loss 0.631031\n",
      "iteration 150 / 300: loss 0.587513\n",
      "iteration 150 / 300: loss 0.606562\n",
      "iteration 150 / 300: loss 0.588034\n",
      "iteration 150 / 300: loss 0.600890\n",
      "iteration 150 / 300: loss 0.595958\n",
      "iteration 150 / 300: loss 0.589291\n",
      "iteration 150 / 300: loss 0.599526\n",
      "iteration 150 / 300: loss 0.604855\n",
      "iteration 150 / 300: loss 0.619414\n",
      "iteration 150 / 300: loss 0.588808\n",
      "iteration 150 / 300: loss 0.593645\n",
      "iteration 150 / 300: loss 0.585595\n",
      "iteration 150 / 300: loss 0.613213\n",
      "iteration 150 / 300: loss 0.587523\n",
      "iteration 150 / 300: loss 0.578328\n",
      "iteration 150 / 300: loss 0.567435\n",
      "iteration 150 / 300: loss 0.562235\n",
      "iteration 150 / 300: loss 0.594183\n",
      "iteration 150 / 300: loss 0.578821\n",
      "iteration 150 / 300: loss 0.586360\n",
      "iteration 150 / 300: loss 0.572890\n",
      "iteration 150 / 300: loss 0.596151\n",
      "iteration 150 / 300: loss 0.607951\n",
      "iteration 150 / 300: loss 0.610839\n",
      "iteration 150 / 300: loss 0.606266\n",
      "iteration 150 / 300: loss 0.583790\n",
      "iteration 150 / 300: loss 0.589627\n",
      "iteration 150 / 300: loss 0.595184\n",
      "iteration 150 / 300: loss 0.598955\n",
      "iteration 150 / 300: loss 0.596133\n",
      "iteration 150 / 300: loss 0.589769\n",
      "iteration 150 / 300: loss 0.591136\n",
      "iteration 150 / 300: loss 0.584854\n",
      "iteration 150 / 300: loss 0.599647\n",
      "iteration 150 / 300: loss 0.598902\n",
      "iteration 150 / 300: loss 0.614283\n",
      "iteration 150 / 300: loss 0.597797\n",
      "iteration 150 / 300: loss 0.599298\n",
      "iteration 150 / 300: loss 0.603317\n",
      "iteration 150 / 300: loss 0.592866\n",
      "iteration 150 / 300: loss 0.592391\n",
      "iteration 150 / 300: loss 0.589041\n",
      "iteration 150 / 300: loss 0.596446\n",
      "iteration 150 / 300: loss 0.605709\n",
      "iteration 150 / 300: loss 0.610562\n",
      "iteration 150 / 300: loss 0.587782\n",
      "iteration 150 / 300: loss 0.599351\n",
      "iteration 150 / 300: loss 0.602792\n",
      "iteration 150 / 300: loss 0.605028\n",
      "iteration 150 / 300: loss 0.603848\n",
      "iteration 150 / 300: loss 0.624144\n",
      "iteration 150 / 300: loss 0.587219\n",
      "iteration 150 / 300: loss 0.580755\n",
      "iteration 150 / 300: loss 0.625046\n",
      "iteration 150 / 300: loss 0.603310\n",
      "iteration 150 / 300: loss 0.604322\n",
      "iteration 150 / 300: loss 0.595476\n",
      "iteration 150 / 300: loss 0.597543\n",
      "iteration 150 / 300: loss 0.592740\n",
      "iteration 150 / 300: loss 0.589494\n",
      "iteration 150 / 300: loss 0.599264\n",
      "iteration 150 / 300: loss 0.611380\n",
      "iteration 150 / 300: loss 0.592463\n",
      "iteration 150 / 300: loss 0.599425\n",
      "iteration 150 / 300: loss 0.603101\n",
      "iteration 150 / 300: loss 0.602410\n",
      "iteration 150 / 300: loss 0.579812\n",
      "iteration 150 / 300: loss 0.601592\n",
      "iteration 151 / 300: loss 0.585528\n",
      "iteration 151 / 300: loss 0.588428\n",
      "iteration 151 / 300: loss 0.567516\n",
      "iteration 151 / 300: loss 0.592380\n",
      "iteration 151 / 300: loss 0.593618\n",
      "iteration 151 / 300: loss 0.595295\n",
      "iteration 151 / 300: loss 0.608784\n",
      "iteration 151 / 300: loss 0.592732\n",
      "iteration 151 / 300: loss 0.628060\n",
      "iteration 151 / 300: loss 0.580152\n",
      "iteration 151 / 300: loss 0.607923\n",
      "iteration 151 / 300: loss 0.587395\n",
      "iteration 151 / 300: loss 0.591686\n",
      "iteration 151 / 300: loss 0.571370\n",
      "iteration 151 / 300: loss 0.583025\n",
      "iteration 151 / 300: loss 0.608441\n",
      "iteration 151 / 300: loss 0.598359\n",
      "iteration 151 / 300: loss 0.583858\n",
      "iteration 151 / 300: loss 0.615253\n",
      "iteration 151 / 300: loss 0.591649\n",
      "iteration 151 / 300: loss 0.585499\n",
      "iteration 151 / 300: loss 0.591325\n",
      "iteration 151 / 300: loss 0.604341\n",
      "iteration 151 / 300: loss 0.595786\n",
      "iteration 151 / 300: loss 0.614949\n",
      "iteration 151 / 300: loss 0.608389\n",
      "iteration 151 / 300: loss 0.598222\n",
      "iteration 151 / 300: loss 0.588936\n",
      "iteration 151 / 300: loss 0.617757\n",
      "iteration 151 / 300: loss 0.594770\n",
      "iteration 151 / 300: loss 0.601684\n",
      "iteration 151 / 300: loss 0.631031\n",
      "iteration 151 / 300: loss 0.587513\n",
      "iteration 151 / 300: loss 0.606562\n",
      "iteration 151 / 300: loss 0.588034\n",
      "iteration 151 / 300: loss 0.600890\n",
      "iteration 151 / 300: loss 0.595958\n",
      "iteration 151 / 300: loss 0.589291\n",
      "iteration 151 / 300: loss 0.599526\n",
      "iteration 151 / 300: loss 0.604855\n",
      "iteration 151 / 300: loss 0.619414\n",
      "iteration 151 / 300: loss 0.588808\n",
      "iteration 151 / 300: loss 0.593645\n",
      "iteration 151 / 300: loss 0.585595\n",
      "iteration 151 / 300: loss 0.613213\n",
      "iteration 151 / 300: loss 0.587523\n",
      "iteration 151 / 300: loss 0.578328\n",
      "iteration 151 / 300: loss 0.567435\n",
      "iteration 151 / 300: loss 0.562235\n",
      "iteration 151 / 300: loss 0.594183\n",
      "iteration 151 / 300: loss 0.578821\n",
      "iteration 151 / 300: loss 0.586360\n",
      "iteration 151 / 300: loss 0.572890\n",
      "iteration 151 / 300: loss 0.596151\n",
      "iteration 151 / 300: loss 0.607951\n",
      "iteration 151 / 300: loss 0.610839\n",
      "iteration 151 / 300: loss 0.606266\n",
      "iteration 151 / 300: loss 0.583790\n",
      "iteration 151 / 300: loss 0.589627\n",
      "iteration 151 / 300: loss 0.595184\n",
      "iteration 151 / 300: loss 0.598955\n",
      "iteration 151 / 300: loss 0.596133\n",
      "iteration 151 / 300: loss 0.589769\n",
      "iteration 151 / 300: loss 0.591136\n",
      "iteration 151 / 300: loss 0.584854\n",
      "iteration 151 / 300: loss 0.599647\n",
      "iteration 151 / 300: loss 0.598902\n",
      "iteration 151 / 300: loss 0.614283\n",
      "iteration 151 / 300: loss 0.597797\n",
      "iteration 151 / 300: loss 0.599298\n",
      "iteration 151 / 300: loss 0.603317\n",
      "iteration 151 / 300: loss 0.592866\n",
      "iteration 151 / 300: loss 0.592391\n",
      "iteration 151 / 300: loss 0.589041\n",
      "iteration 151 / 300: loss 0.596446\n",
      "iteration 151 / 300: loss 0.605709\n",
      "iteration 151 / 300: loss 0.610562\n",
      "iteration 151 / 300: loss 0.587782\n",
      "iteration 151 / 300: loss 0.599351\n",
      "iteration 151 / 300: loss 0.602792\n",
      "iteration 151 / 300: loss 0.605028\n",
      "iteration 151 / 300: loss 0.603848\n",
      "iteration 151 / 300: loss 0.624144\n",
      "iteration 151 / 300: loss 0.587219\n",
      "iteration 151 / 300: loss 0.580755\n",
      "iteration 151 / 300: loss 0.625046\n",
      "iteration 151 / 300: loss 0.603310\n",
      "iteration 151 / 300: loss 0.604322\n",
      "iteration 151 / 300: loss 0.595476\n",
      "iteration 151 / 300: loss 0.597543\n",
      "iteration 151 / 300: loss 0.592740\n",
      "iteration 151 / 300: loss 0.589494\n",
      "iteration 151 / 300: loss 0.599264\n",
      "iteration 151 / 300: loss 0.611380\n",
      "iteration 151 / 300: loss 0.592463\n",
      "iteration 151 / 300: loss 0.599425\n",
      "iteration 151 / 300: loss 0.603101\n",
      "iteration 151 / 300: loss 0.602410\n",
      "iteration 151 / 300: loss 0.579812\n",
      "iteration 151 / 300: loss 0.601592\n",
      "iteration 152 / 300: loss 0.585528\n",
      "iteration 152 / 300: loss 0.588428\n",
      "iteration 152 / 300: loss 0.567516\n",
      "iteration 152 / 300: loss 0.592380\n",
      "iteration 152 / 300: loss 0.593618\n",
      "iteration 152 / 300: loss 0.595295\n",
      "iteration 152 / 300: loss 0.608784\n",
      "iteration 152 / 300: loss 0.592732\n",
      "iteration 152 / 300: loss 0.628060\n",
      "iteration 152 / 300: loss 0.580152\n",
      "iteration 152 / 300: loss 0.607923\n",
      "iteration 152 / 300: loss 0.587395\n",
      "iteration 152 / 300: loss 0.591686\n",
      "iteration 152 / 300: loss 0.571370\n",
      "iteration 152 / 300: loss 0.583025\n",
      "iteration 152 / 300: loss 0.608441\n",
      "iteration 152 / 300: loss 0.598359\n",
      "iteration 152 / 300: loss 0.583858\n",
      "iteration 152 / 300: loss 0.615253\n",
      "iteration 152 / 300: loss 0.591649\n",
      "iteration 152 / 300: loss 0.585499\n",
      "iteration 152 / 300: loss 0.591325\n",
      "iteration 152 / 300: loss 0.604341\n",
      "iteration 152 / 300: loss 0.595786\n",
      "iteration 152 / 300: loss 0.614949\n",
      "iteration 152 / 300: loss 0.608389\n",
      "iteration 152 / 300: loss 0.598222\n",
      "iteration 152 / 300: loss 0.588936\n",
      "iteration 152 / 300: loss 0.617757\n",
      "iteration 152 / 300: loss 0.594770\n",
      "iteration 152 / 300: loss 0.601684\n",
      "iteration 152 / 300: loss 0.631031\n",
      "iteration 152 / 300: loss 0.587513\n",
      "iteration 152 / 300: loss 0.606562\n",
      "iteration 152 / 300: loss 0.588034\n",
      "iteration 152 / 300: loss 0.600890\n",
      "iteration 152 / 300: loss 0.595958\n",
      "iteration 152 / 300: loss 0.589291\n",
      "iteration 152 / 300: loss 0.599526\n",
      "iteration 152 / 300: loss 0.604855\n",
      "iteration 152 / 300: loss 0.619414\n",
      "iteration 152 / 300: loss 0.588808\n",
      "iteration 152 / 300: loss 0.593645\n",
      "iteration 152 / 300: loss 0.585595\n",
      "iteration 152 / 300: loss 0.613213\n",
      "iteration 152 / 300: loss 0.587523\n",
      "iteration 152 / 300: loss 0.578328\n",
      "iteration 152 / 300: loss 0.567435\n",
      "iteration 152 / 300: loss 0.562235\n",
      "iteration 152 / 300: loss 0.594183\n",
      "iteration 152 / 300: loss 0.578821\n",
      "iteration 152 / 300: loss 0.586360\n",
      "iteration 152 / 300: loss 0.572890\n",
      "iteration 152 / 300: loss 0.596151\n",
      "iteration 152 / 300: loss 0.607951\n",
      "iteration 152 / 300: loss 0.610839\n",
      "iteration 152 / 300: loss 0.606266\n",
      "iteration 152 / 300: loss 0.583790\n",
      "iteration 152 / 300: loss 0.589627\n",
      "iteration 152 / 300: loss 0.595184\n",
      "iteration 152 / 300: loss 0.598955\n",
      "iteration 152 / 300: loss 0.596133\n",
      "iteration 152 / 300: loss 0.589769\n",
      "iteration 152 / 300: loss 0.591136\n",
      "iteration 152 / 300: loss 0.584854\n",
      "iteration 152 / 300: loss 0.599647\n",
      "iteration 152 / 300: loss 0.598902\n",
      "iteration 152 / 300: loss 0.614283\n",
      "iteration 152 / 300: loss 0.597797\n",
      "iteration 152 / 300: loss 0.599298\n",
      "iteration 152 / 300: loss 0.603317\n",
      "iteration 152 / 300: loss 0.592866\n",
      "iteration 152 / 300: loss 0.592391\n",
      "iteration 152 / 300: loss 0.589041\n",
      "iteration 152 / 300: loss 0.596446\n",
      "iteration 152 / 300: loss 0.605709\n",
      "iteration 152 / 300: loss 0.610562\n",
      "iteration 152 / 300: loss 0.587782\n",
      "iteration 152 / 300: loss 0.599351\n",
      "iteration 152 / 300: loss 0.602792\n",
      "iteration 152 / 300: loss 0.605028\n",
      "iteration 152 / 300: loss 0.603848\n",
      "iteration 152 / 300: loss 0.624144\n",
      "iteration 152 / 300: loss 0.587219\n",
      "iteration 152 / 300: loss 0.580755\n",
      "iteration 152 / 300: loss 0.625045\n",
      "iteration 152 / 300: loss 0.603310\n",
      "iteration 152 / 300: loss 0.604322\n",
      "iteration 152 / 300: loss 0.595476\n",
      "iteration 152 / 300: loss 0.597543\n",
      "iteration 152 / 300: loss 0.592740\n",
      "iteration 152 / 300: loss 0.589494\n",
      "iteration 152 / 300: loss 0.599264\n",
      "iteration 152 / 300: loss 0.611380\n",
      "iteration 152 / 300: loss 0.592463\n",
      "iteration 152 / 300: loss 0.599425\n",
      "iteration 152 / 300: loss 0.603101\n",
      "iteration 152 / 300: loss 0.602410\n",
      "iteration 152 / 300: loss 0.579812\n",
      "iteration 152 / 300: loss 0.601592\n",
      "iteration 153 / 300: loss 0.585528\n",
      "iteration 153 / 300: loss 0.588428\n",
      "iteration 153 / 300: loss 0.567516\n",
      "iteration 153 / 300: loss 0.592380\n",
      "iteration 153 / 300: loss 0.593618\n",
      "iteration 153 / 300: loss 0.595295\n",
      "iteration 153 / 300: loss 0.608784\n",
      "iteration 153 / 300: loss 0.592732\n",
      "iteration 153 / 300: loss 0.628060\n",
      "iteration 153 / 300: loss 0.580152\n",
      "iteration 153 / 300: loss 0.607923\n",
      "iteration 153 / 300: loss 0.587395\n",
      "iteration 153 / 300: loss 0.591686\n",
      "iteration 153 / 300: loss 0.571370\n",
      "iteration 153 / 300: loss 0.583025\n",
      "iteration 153 / 300: loss 0.608441\n",
      "iteration 153 / 300: loss 0.598359\n",
      "iteration 153 / 300: loss 0.583858\n",
      "iteration 153 / 300: loss 0.615253\n",
      "iteration 153 / 300: loss 0.591649\n",
      "iteration 153 / 300: loss 0.585499\n",
      "iteration 153 / 300: loss 0.591325\n",
      "iteration 153 / 300: loss 0.604341\n",
      "iteration 153 / 300: loss 0.595786\n",
      "iteration 153 / 300: loss 0.614949\n",
      "iteration 153 / 300: loss 0.608389\n",
      "iteration 153 / 300: loss 0.598222\n",
      "iteration 153 / 300: loss 0.588936\n",
      "iteration 153 / 300: loss 0.617757\n",
      "iteration 153 / 300: loss 0.594770\n",
      "iteration 153 / 300: loss 0.601684\n",
      "iteration 153 / 300: loss 0.631031\n",
      "iteration 153 / 300: loss 0.587513\n",
      "iteration 153 / 300: loss 0.606562\n",
      "iteration 153 / 300: loss 0.588034\n",
      "iteration 153 / 300: loss 0.600890\n",
      "iteration 153 / 300: loss 0.595958\n",
      "iteration 153 / 300: loss 0.589291\n",
      "iteration 153 / 300: loss 0.599526\n",
      "iteration 153 / 300: loss 0.604855\n",
      "iteration 153 / 300: loss 0.619414\n",
      "iteration 153 / 300: loss 0.588808\n",
      "iteration 153 / 300: loss 0.593645\n",
      "iteration 153 / 300: loss 0.585595\n",
      "iteration 153 / 300: loss 0.613213\n",
      "iteration 153 / 300: loss 0.587523\n",
      "iteration 153 / 300: loss 0.578328\n",
      "iteration 153 / 300: loss 0.567435\n",
      "iteration 153 / 300: loss 0.562235\n",
      "iteration 153 / 300: loss 0.594183\n",
      "iteration 153 / 300: loss 0.578821\n",
      "iteration 153 / 300: loss 0.586360\n",
      "iteration 153 / 300: loss 0.572890\n",
      "iteration 153 / 300: loss 0.596151\n",
      "iteration 153 / 300: loss 0.607951\n",
      "iteration 153 / 300: loss 0.610839\n",
      "iteration 153 / 300: loss 0.606266\n",
      "iteration 153 / 300: loss 0.583790\n",
      "iteration 153 / 300: loss 0.589627\n",
      "iteration 153 / 300: loss 0.595184\n",
      "iteration 153 / 300: loss 0.598955\n",
      "iteration 153 / 300: loss 0.596133\n",
      "iteration 153 / 300: loss 0.589769\n",
      "iteration 153 / 300: loss 0.591136\n",
      "iteration 153 / 300: loss 0.584854\n",
      "iteration 153 / 300: loss 0.599647\n",
      "iteration 153 / 300: loss 0.598902\n",
      "iteration 153 / 300: loss 0.614282\n",
      "iteration 153 / 300: loss 0.597796\n",
      "iteration 153 / 300: loss 0.599298\n",
      "iteration 153 / 300: loss 0.603317\n",
      "iteration 153 / 300: loss 0.592866\n",
      "iteration 153 / 300: loss 0.592391\n",
      "iteration 153 / 300: loss 0.589041\n",
      "iteration 153 / 300: loss 0.596446\n",
      "iteration 153 / 300: loss 0.605709\n",
      "iteration 153 / 300: loss 0.610562\n",
      "iteration 153 / 300: loss 0.587782\n",
      "iteration 153 / 300: loss 0.599351\n",
      "iteration 153 / 300: loss 0.602792\n",
      "iteration 153 / 300: loss 0.605028\n",
      "iteration 153 / 300: loss 0.603848\n",
      "iteration 153 / 300: loss 0.624144\n",
      "iteration 153 / 300: loss 0.587219\n",
      "iteration 153 / 300: loss 0.580755\n",
      "iteration 153 / 300: loss 0.625045\n",
      "iteration 153 / 300: loss 0.603310\n",
      "iteration 153 / 300: loss 0.604322\n",
      "iteration 153 / 300: loss 0.595476\n",
      "iteration 153 / 300: loss 0.597543\n",
      "iteration 153 / 300: loss 0.592740\n",
      "iteration 153 / 300: loss 0.589494\n",
      "iteration 153 / 300: loss 0.599264\n",
      "iteration 153 / 300: loss 0.611380\n",
      "iteration 153 / 300: loss 0.592463\n",
      "iteration 153 / 300: loss 0.599425\n",
      "iteration 153 / 300: loss 0.603100\n",
      "iteration 153 / 300: loss 0.602410\n",
      "iteration 153 / 300: loss 0.579812\n",
      "iteration 153 / 300: loss 0.601592\n",
      "iteration 154 / 300: loss 0.585528\n",
      "iteration 154 / 300: loss 0.588428\n",
      "iteration 154 / 300: loss 0.567516\n",
      "iteration 154 / 300: loss 0.592380\n",
      "iteration 154 / 300: loss 0.593618\n",
      "iteration 154 / 300: loss 0.595295\n",
      "iteration 154 / 300: loss 0.608784\n",
      "iteration 154 / 300: loss 0.592732\n",
      "iteration 154 / 300: loss 0.628060\n",
      "iteration 154 / 300: loss 0.580152\n",
      "iteration 154 / 300: loss 0.607923\n",
      "iteration 154 / 300: loss 0.587395\n",
      "iteration 154 / 300: loss 0.591686\n",
      "iteration 154 / 300: loss 0.571370\n",
      "iteration 154 / 300: loss 0.583025\n",
      "iteration 154 / 300: loss 0.608441\n",
      "iteration 154 / 300: loss 0.598359\n",
      "iteration 154 / 300: loss 0.583858\n",
      "iteration 154 / 300: loss 0.615253\n",
      "iteration 154 / 300: loss 0.591649\n",
      "iteration 154 / 300: loss 0.585499\n",
      "iteration 154 / 300: loss 0.591325\n",
      "iteration 154 / 300: loss 0.604341\n",
      "iteration 154 / 300: loss 0.595786\n",
      "iteration 154 / 300: loss 0.614949\n",
      "iteration 154 / 300: loss 0.608389\n",
      "iteration 154 / 300: loss 0.598222\n",
      "iteration 154 / 300: loss 0.588936\n",
      "iteration 154 / 300: loss 0.617757\n",
      "iteration 154 / 300: loss 0.594770\n",
      "iteration 154 / 300: loss 0.601684\n",
      "iteration 154 / 300: loss 0.631031\n",
      "iteration 154 / 300: loss 0.587513\n",
      "iteration 154 / 300: loss 0.606562\n",
      "iteration 154 / 300: loss 0.588034\n",
      "iteration 154 / 300: loss 0.600890\n",
      "iteration 154 / 300: loss 0.595958\n",
      "iteration 154 / 300: loss 0.589291\n",
      "iteration 154 / 300: loss 0.599526\n",
      "iteration 154 / 300: loss 0.604855\n",
      "iteration 154 / 300: loss 0.619414\n",
      "iteration 154 / 300: loss 0.588808\n",
      "iteration 154 / 300: loss 0.593645\n",
      "iteration 154 / 300: loss 0.585595\n",
      "iteration 154 / 300: loss 0.613213\n",
      "iteration 154 / 300: loss 0.587523\n",
      "iteration 154 / 300: loss 0.578328\n",
      "iteration 154 / 300: loss 0.567435\n",
      "iteration 154 / 300: loss 0.562235\n",
      "iteration 154 / 300: loss 0.594183\n",
      "iteration 154 / 300: loss 0.578821\n",
      "iteration 154 / 300: loss 0.586360\n",
      "iteration 154 / 300: loss 0.572890\n",
      "iteration 154 / 300: loss 0.596151\n",
      "iteration 154 / 300: loss 0.607951\n",
      "iteration 154 / 300: loss 0.610839\n",
      "iteration 154 / 300: loss 0.606266\n",
      "iteration 154 / 300: loss 0.583790\n",
      "iteration 154 / 300: loss 0.589627\n",
      "iteration 154 / 300: loss 0.595184\n",
      "iteration 154 / 300: loss 0.598955\n",
      "iteration 154 / 300: loss 0.596133\n",
      "iteration 154 / 300: loss 0.589769\n",
      "iteration 154 / 300: loss 0.591136\n",
      "iteration 154 / 300: loss 0.584854\n",
      "iteration 154 / 300: loss 0.599647\n",
      "iteration 154 / 300: loss 0.598902\n",
      "iteration 154 / 300: loss 0.614282\n",
      "iteration 154 / 300: loss 0.597796\n",
      "iteration 154 / 300: loss 0.599298\n",
      "iteration 154 / 300: loss 0.603317\n",
      "iteration 154 / 300: loss 0.592866\n",
      "iteration 154 / 300: loss 0.592391\n",
      "iteration 154 / 300: loss 0.589041\n",
      "iteration 154 / 300: loss 0.596446\n",
      "iteration 154 / 300: loss 0.605709\n",
      "iteration 154 / 300: loss 0.610562\n",
      "iteration 154 / 300: loss 0.587782\n",
      "iteration 154 / 300: loss 0.599351\n",
      "iteration 154 / 300: loss 0.602792\n",
      "iteration 154 / 300: loss 0.605028\n",
      "iteration 154 / 300: loss 0.603848\n",
      "iteration 154 / 300: loss 0.624144\n",
      "iteration 154 / 300: loss 0.587219\n",
      "iteration 154 / 300: loss 0.580754\n",
      "iteration 154 / 300: loss 0.625045\n",
      "iteration 154 / 300: loss 0.603310\n",
      "iteration 154 / 300: loss 0.604322\n",
      "iteration 154 / 300: loss 0.595476\n",
      "iteration 154 / 300: loss 0.597543\n",
      "iteration 154 / 300: loss 0.592740\n",
      "iteration 154 / 300: loss 0.589494\n",
      "iteration 154 / 300: loss 0.599264\n",
      "iteration 154 / 300: loss 0.611380\n",
      "iteration 154 / 300: loss 0.592463\n",
      "iteration 154 / 300: loss 0.599425\n",
      "iteration 154 / 300: loss 0.603100\n",
      "iteration 154 / 300: loss 0.602410\n",
      "iteration 154 / 300: loss 0.579812\n",
      "iteration 154 / 300: loss 0.601592\n",
      "iteration 155 / 300: loss 0.585528\n",
      "iteration 155 / 300: loss 0.588428\n",
      "iteration 155 / 300: loss 0.567516\n",
      "iteration 155 / 300: loss 0.592380\n",
      "iteration 155 / 300: loss 0.593618\n",
      "iteration 155 / 300: loss 0.595295\n",
      "iteration 155 / 300: loss 0.608784\n",
      "iteration 155 / 300: loss 0.592732\n",
      "iteration 155 / 300: loss 0.628060\n",
      "iteration 155 / 300: loss 0.580152\n",
      "iteration 155 / 300: loss 0.607923\n",
      "iteration 155 / 300: loss 0.587395\n",
      "iteration 155 / 300: loss 0.591686\n",
      "iteration 155 / 300: loss 0.571370\n",
      "iteration 155 / 300: loss 0.583025\n",
      "iteration 155 / 300: loss 0.608441\n",
      "iteration 155 / 300: loss 0.598359\n",
      "iteration 155 / 300: loss 0.583858\n",
      "iteration 155 / 300: loss 0.615253\n",
      "iteration 155 / 300: loss 0.591649\n",
      "iteration 155 / 300: loss 0.585499\n",
      "iteration 155 / 300: loss 0.591325\n",
      "iteration 155 / 300: loss 0.604341\n",
      "iteration 155 / 300: loss 0.595786\n",
      "iteration 155 / 300: loss 0.614949\n",
      "iteration 155 / 300: loss 0.608389\n",
      "iteration 155 / 300: loss 0.598222\n",
      "iteration 155 / 300: loss 0.588936\n",
      "iteration 155 / 300: loss 0.617757\n",
      "iteration 155 / 300: loss 0.594770\n",
      "iteration 155 / 300: loss 0.601684\n",
      "iteration 155 / 300: loss 0.631031\n",
      "iteration 155 / 300: loss 0.587513\n",
      "iteration 155 / 300: loss 0.606561\n",
      "iteration 155 / 300: loss 0.588034\n",
      "iteration 155 / 300: loss 0.600890\n",
      "iteration 155 / 300: loss 0.595958\n",
      "iteration 155 / 300: loss 0.589291\n",
      "iteration 155 / 300: loss 0.599526\n",
      "iteration 155 / 300: loss 0.604855\n",
      "iteration 155 / 300: loss 0.619414\n",
      "iteration 155 / 300: loss 0.588808\n",
      "iteration 155 / 300: loss 0.593645\n",
      "iteration 155 / 300: loss 0.585595\n",
      "iteration 155 / 300: loss 0.613213\n",
      "iteration 155 / 300: loss 0.587523\n",
      "iteration 155 / 300: loss 0.578328\n",
      "iteration 155 / 300: loss 0.567435\n",
      "iteration 155 / 300: loss 0.562235\n",
      "iteration 155 / 300: loss 0.594183\n",
      "iteration 155 / 300: loss 0.578821\n",
      "iteration 155 / 300: loss 0.586360\n",
      "iteration 155 / 300: loss 0.572890\n",
      "iteration 155 / 300: loss 0.596151\n",
      "iteration 155 / 300: loss 0.607951\n",
      "iteration 155 / 300: loss 0.610839\n",
      "iteration 155 / 300: loss 0.606266\n",
      "iteration 155 / 300: loss 0.583790\n",
      "iteration 155 / 300: loss 0.589627\n",
      "iteration 155 / 300: loss 0.595184\n",
      "iteration 155 / 300: loss 0.598955\n",
      "iteration 155 / 300: loss 0.596133\n",
      "iteration 155 / 300: loss 0.589769\n",
      "iteration 155 / 300: loss 0.591136\n",
      "iteration 155 / 300: loss 0.584854\n",
      "iteration 155 / 300: loss 0.599647\n",
      "iteration 155 / 300: loss 0.598902\n",
      "iteration 155 / 300: loss 0.614282\n",
      "iteration 155 / 300: loss 0.597796\n",
      "iteration 155 / 300: loss 0.599298\n",
      "iteration 155 / 300: loss 0.603317\n",
      "iteration 155 / 300: loss 0.592866\n",
      "iteration 155 / 300: loss 0.592391\n",
      "iteration 155 / 300: loss 0.589041\n",
      "iteration 155 / 300: loss 0.596446\n",
      "iteration 155 / 300: loss 0.605709\n",
      "iteration 155 / 300: loss 0.610562\n",
      "iteration 155 / 300: loss 0.587782\n",
      "iteration 155 / 300: loss 0.599351\n",
      "iteration 155 / 300: loss 0.602792\n",
      "iteration 155 / 300: loss 0.605028\n",
      "iteration 155 / 300: loss 0.603848\n",
      "iteration 155 / 300: loss 0.624144\n",
      "iteration 155 / 300: loss 0.587219\n",
      "iteration 155 / 300: loss 0.580754\n",
      "iteration 155 / 300: loss 0.625045\n",
      "iteration 155 / 300: loss 0.603310\n",
      "iteration 155 / 300: loss 0.604321\n",
      "iteration 155 / 300: loss 0.595476\n",
      "iteration 155 / 300: loss 0.597543\n",
      "iteration 155 / 300: loss 0.592740\n",
      "iteration 155 / 300: loss 0.589494\n",
      "iteration 155 / 300: loss 0.599264\n",
      "iteration 155 / 300: loss 0.611380\n",
      "iteration 155 / 300: loss 0.592463\n",
      "iteration 155 / 300: loss 0.599425\n",
      "iteration 155 / 300: loss 0.603100\n",
      "iteration 155 / 300: loss 0.602410\n",
      "iteration 155 / 300: loss 0.579812\n",
      "iteration 155 / 300: loss 0.601592\n",
      "iteration 156 / 300: loss 0.585528\n",
      "iteration 156 / 300: loss 0.588428\n",
      "iteration 156 / 300: loss 0.567516\n",
      "iteration 156 / 300: loss 0.592380\n",
      "iteration 156 / 300: loss 0.593618\n",
      "iteration 156 / 300: loss 0.595295\n",
      "iteration 156 / 300: loss 0.608784\n",
      "iteration 156 / 300: loss 0.592732\n",
      "iteration 156 / 300: loss 0.628060\n",
      "iteration 156 / 300: loss 0.580152\n",
      "iteration 156 / 300: loss 0.607923\n",
      "iteration 156 / 300: loss 0.587394\n",
      "iteration 156 / 300: loss 0.591686\n",
      "iteration 156 / 300: loss 0.571370\n",
      "iteration 156 / 300: loss 0.583025\n",
      "iteration 156 / 300: loss 0.608441\n",
      "iteration 156 / 300: loss 0.598359\n",
      "iteration 156 / 300: loss 0.583858\n",
      "iteration 156 / 300: loss 0.615253\n",
      "iteration 156 / 300: loss 0.591649\n",
      "iteration 156 / 300: loss 0.585499\n",
      "iteration 156 / 300: loss 0.591325\n",
      "iteration 156 / 300: loss 0.604341\n",
      "iteration 156 / 300: loss 0.595786\n",
      "iteration 156 / 300: loss 0.614949\n",
      "iteration 156 / 300: loss 0.608389\n",
      "iteration 156 / 300: loss 0.598222\n",
      "iteration 156 / 300: loss 0.588936\n",
      "iteration 156 / 300: loss 0.617757\n",
      "iteration 156 / 300: loss 0.594770\n",
      "iteration 156 / 300: loss 0.601684\n",
      "iteration 156 / 300: loss 0.631031\n",
      "iteration 156 / 300: loss 0.587513\n",
      "iteration 156 / 300: loss 0.606561\n",
      "iteration 156 / 300: loss 0.588034\n",
      "iteration 156 / 300: loss 0.600890\n",
      "iteration 156 / 300: loss 0.595958\n",
      "iteration 156 / 300: loss 0.589291\n",
      "iteration 156 / 300: loss 0.599526\n",
      "iteration 156 / 300: loss 0.604855\n",
      "iteration 156 / 300: loss 0.619414\n",
      "iteration 156 / 300: loss 0.588808\n",
      "iteration 156 / 300: loss 0.593645\n",
      "iteration 156 / 300: loss 0.585595\n",
      "iteration 156 / 300: loss 0.613213\n",
      "iteration 156 / 300: loss 0.587523\n",
      "iteration 156 / 300: loss 0.578328\n",
      "iteration 156 / 300: loss 0.567435\n",
      "iteration 156 / 300: loss 0.562235\n",
      "iteration 156 / 300: loss 0.594183\n",
      "iteration 156 / 300: loss 0.578821\n",
      "iteration 156 / 300: loss 0.586360\n",
      "iteration 156 / 300: loss 0.572890\n",
      "iteration 156 / 300: loss 0.596151\n",
      "iteration 156 / 300: loss 0.607951\n",
      "iteration 156 / 300: loss 0.610839\n",
      "iteration 156 / 300: loss 0.606266\n",
      "iteration 156 / 300: loss 0.583790\n",
      "iteration 156 / 300: loss 0.589627\n",
      "iteration 156 / 300: loss 0.595184\n",
      "iteration 156 / 300: loss 0.598955\n",
      "iteration 156 / 300: loss 0.596133\n",
      "iteration 156 / 300: loss 0.589769\n",
      "iteration 156 / 300: loss 0.591136\n",
      "iteration 156 / 300: loss 0.584854\n",
      "iteration 156 / 300: loss 0.599647\n",
      "iteration 156 / 300: loss 0.598902\n",
      "iteration 156 / 300: loss 0.614282\n",
      "iteration 156 / 300: loss 0.597796\n",
      "iteration 156 / 300: loss 0.599298\n",
      "iteration 156 / 300: loss 0.603317\n",
      "iteration 156 / 300: loss 0.592866\n",
      "iteration 156 / 300: loss 0.592391\n",
      "iteration 156 / 300: loss 0.589041\n",
      "iteration 156 / 300: loss 0.596446\n",
      "iteration 156 / 300: loss 0.605709\n",
      "iteration 156 / 300: loss 0.610562\n",
      "iteration 156 / 300: loss 0.587782\n",
      "iteration 156 / 300: loss 0.599351\n",
      "iteration 156 / 300: loss 0.602792\n",
      "iteration 156 / 300: loss 0.605028\n",
      "iteration 156 / 300: loss 0.603848\n",
      "iteration 156 / 300: loss 0.624144\n",
      "iteration 156 / 300: loss 0.587219\n",
      "iteration 156 / 300: loss 0.580754\n",
      "iteration 156 / 300: loss 0.625045\n",
      "iteration 156 / 300: loss 0.603310\n",
      "iteration 156 / 300: loss 0.604321\n",
      "iteration 156 / 300: loss 0.595476\n",
      "iteration 156 / 300: loss 0.597543\n",
      "iteration 156 / 300: loss 0.592740\n",
      "iteration 156 / 300: loss 0.589494\n",
      "iteration 156 / 300: loss 0.599264\n",
      "iteration 156 / 300: loss 0.611380\n",
      "iteration 156 / 300: loss 0.592463\n",
      "iteration 156 / 300: loss 0.599425\n",
      "iteration 156 / 300: loss 0.603100\n",
      "iteration 156 / 300: loss 0.602410\n",
      "iteration 156 / 300: loss 0.579812\n",
      "iteration 156 / 300: loss 0.601592\n",
      "iteration 157 / 300: loss 0.585528\n",
      "iteration 157 / 300: loss 0.588428\n",
      "iteration 157 / 300: loss 0.567516\n",
      "iteration 157 / 300: loss 0.592380\n",
      "iteration 157 / 300: loss 0.593618\n",
      "iteration 157 / 300: loss 0.595295\n",
      "iteration 157 / 300: loss 0.608784\n",
      "iteration 157 / 300: loss 0.592732\n",
      "iteration 157 / 300: loss 0.628060\n",
      "iteration 157 / 300: loss 0.580152\n",
      "iteration 157 / 300: loss 0.607923\n",
      "iteration 157 / 300: loss 0.587394\n",
      "iteration 157 / 300: loss 0.591686\n",
      "iteration 157 / 300: loss 0.571370\n",
      "iteration 157 / 300: loss 0.583025\n",
      "iteration 157 / 300: loss 0.608441\n",
      "iteration 157 / 300: loss 0.598359\n",
      "iteration 157 / 300: loss 0.583858\n",
      "iteration 157 / 300: loss 0.615253\n",
      "iteration 157 / 300: loss 0.591649\n",
      "iteration 157 / 300: loss 0.585499\n",
      "iteration 157 / 300: loss 0.591325\n",
      "iteration 157 / 300: loss 0.604341\n",
      "iteration 157 / 300: loss 0.595786\n",
      "iteration 157 / 300: loss 0.614949\n",
      "iteration 157 / 300: loss 0.608389\n",
      "iteration 157 / 300: loss 0.598222\n",
      "iteration 157 / 300: loss 0.588936\n",
      "iteration 157 / 300: loss 0.617757\n",
      "iteration 157 / 300: loss 0.594770\n",
      "iteration 157 / 300: loss 0.601684\n",
      "iteration 157 / 300: loss 0.631031\n",
      "iteration 157 / 300: loss 0.587513\n",
      "iteration 157 / 300: loss 0.606561\n",
      "iteration 157 / 300: loss 0.588034\n",
      "iteration 157 / 300: loss 0.600890\n",
      "iteration 157 / 300: loss 0.595958\n",
      "iteration 157 / 300: loss 0.589291\n",
      "iteration 157 / 300: loss 0.599526\n",
      "iteration 157 / 300: loss 0.604855\n",
      "iteration 157 / 300: loss 0.619414\n",
      "iteration 157 / 300: loss 0.588808\n",
      "iteration 157 / 300: loss 0.593645\n",
      "iteration 157 / 300: loss 0.585595\n",
      "iteration 157 / 300: loss 0.613213\n",
      "iteration 157 / 300: loss 0.587523\n",
      "iteration 157 / 300: loss 0.578328\n",
      "iteration 157 / 300: loss 0.567435\n",
      "iteration 157 / 300: loss 0.562235\n",
      "iteration 157 / 300: loss 0.594183\n",
      "iteration 157 / 300: loss 0.578821\n",
      "iteration 157 / 300: loss 0.586360\n",
      "iteration 157 / 300: loss 0.572890\n",
      "iteration 157 / 300: loss 0.596151\n",
      "iteration 157 / 300: loss 0.607951\n",
      "iteration 157 / 300: loss 0.610839\n",
      "iteration 157 / 300: loss 0.606266\n",
      "iteration 157 / 300: loss 0.583790\n",
      "iteration 157 / 300: loss 0.589627\n",
      "iteration 157 / 300: loss 0.595184\n",
      "iteration 157 / 300: loss 0.598955\n",
      "iteration 157 / 300: loss 0.596133\n",
      "iteration 157 / 300: loss 0.589769\n",
      "iteration 157 / 300: loss 0.591136\n",
      "iteration 157 / 300: loss 0.584854\n",
      "iteration 157 / 300: loss 0.599647\n",
      "iteration 157 / 300: loss 0.598902\n",
      "iteration 157 / 300: loss 0.614282\n",
      "iteration 157 / 300: loss 0.597796\n",
      "iteration 157 / 300: loss 0.599298\n",
      "iteration 157 / 300: loss 0.603317\n",
      "iteration 157 / 300: loss 0.592866\n",
      "iteration 157 / 300: loss 0.592391\n",
      "iteration 157 / 300: loss 0.589041\n",
      "iteration 157 / 300: loss 0.596446\n",
      "iteration 157 / 300: loss 0.605709\n",
      "iteration 157 / 300: loss 0.610562\n",
      "iteration 157 / 300: loss 0.587782\n",
      "iteration 157 / 300: loss 0.599351\n",
      "iteration 157 / 300: loss 0.602792\n",
      "iteration 157 / 300: loss 0.605028\n",
      "iteration 157 / 300: loss 0.603848\n",
      "iteration 157 / 300: loss 0.624144\n",
      "iteration 157 / 300: loss 0.587219\n",
      "iteration 157 / 300: loss 0.580754\n",
      "iteration 157 / 300: loss 0.625045\n",
      "iteration 157 / 300: loss 0.603310\n",
      "iteration 157 / 300: loss 0.604321\n",
      "iteration 157 / 300: loss 0.595476\n",
      "iteration 157 / 300: loss 0.597543\n",
      "iteration 157 / 300: loss 0.592740\n",
      "iteration 157 / 300: loss 0.589494\n",
      "iteration 157 / 300: loss 0.599264\n",
      "iteration 157 / 300: loss 0.611380\n",
      "iteration 157 / 300: loss 0.592463\n",
      "iteration 157 / 300: loss 0.599425\n",
      "iteration 157 / 300: loss 0.603100\n",
      "iteration 157 / 300: loss 0.602410\n",
      "iteration 157 / 300: loss 0.579812\n",
      "iteration 157 / 300: loss 0.601592\n",
      "iteration 158 / 300: loss 0.585528\n",
      "iteration 158 / 300: loss 0.588428\n",
      "iteration 158 / 300: loss 0.567516\n",
      "iteration 158 / 300: loss 0.592380\n",
      "iteration 158 / 300: loss 0.593618\n",
      "iteration 158 / 300: loss 0.595295\n",
      "iteration 158 / 300: loss 0.608784\n",
      "iteration 158 / 300: loss 0.592732\n",
      "iteration 158 / 300: loss 0.628060\n",
      "iteration 158 / 300: loss 0.580152\n",
      "iteration 158 / 300: loss 0.607923\n",
      "iteration 158 / 300: loss 0.587394\n",
      "iteration 158 / 300: loss 0.591686\n",
      "iteration 158 / 300: loss 0.571370\n",
      "iteration 158 / 300: loss 0.583025\n",
      "iteration 158 / 300: loss 0.608441\n",
      "iteration 158 / 300: loss 0.598359\n",
      "iteration 158 / 300: loss 0.583858\n",
      "iteration 158 / 300: loss 0.615253\n",
      "iteration 158 / 300: loss 0.591649\n",
      "iteration 158 / 300: loss 0.585499\n",
      "iteration 158 / 300: loss 0.591325\n",
      "iteration 158 / 300: loss 0.604341\n",
      "iteration 158 / 300: loss 0.595786\n",
      "iteration 158 / 300: loss 0.614949\n",
      "iteration 158 / 300: loss 0.608389\n",
      "iteration 158 / 300: loss 0.598222\n",
      "iteration 158 / 300: loss 0.588936\n",
      "iteration 158 / 300: loss 0.617757\n",
      "iteration 158 / 300: loss 0.594770\n",
      "iteration 158 / 300: loss 0.601684\n",
      "iteration 158 / 300: loss 0.631031\n",
      "iteration 158 / 300: loss 0.587513\n",
      "iteration 158 / 300: loss 0.606561\n",
      "iteration 158 / 300: loss 0.588034\n",
      "iteration 158 / 300: loss 0.600890\n",
      "iteration 158 / 300: loss 0.595958\n",
      "iteration 158 / 300: loss 0.589291\n",
      "iteration 158 / 300: loss 0.599526\n",
      "iteration 158 / 300: loss 0.604855\n",
      "iteration 158 / 300: loss 0.619414\n",
      "iteration 158 / 300: loss 0.588808\n",
      "iteration 158 / 300: loss 0.593645\n",
      "iteration 158 / 300: loss 0.585595\n",
      "iteration 158 / 300: loss 0.613213\n",
      "iteration 158 / 300: loss 0.587523\n",
      "iteration 158 / 300: loss 0.578328\n",
      "iteration 158 / 300: loss 0.567435\n",
      "iteration 158 / 300: loss 0.562235\n",
      "iteration 158 / 300: loss 0.594183\n",
      "iteration 158 / 300: loss 0.578821\n",
      "iteration 158 / 300: loss 0.586360\n",
      "iteration 158 / 300: loss 0.572890\n",
      "iteration 158 / 300: loss 0.596151\n",
      "iteration 158 / 300: loss 0.607951\n",
      "iteration 158 / 300: loss 0.610839\n",
      "iteration 158 / 300: loss 0.606266\n",
      "iteration 158 / 300: loss 0.583790\n",
      "iteration 158 / 300: loss 0.589627\n",
      "iteration 158 / 300: loss 0.595184\n",
      "iteration 158 / 300: loss 0.598955\n",
      "iteration 158 / 300: loss 0.596133\n",
      "iteration 158 / 300: loss 0.589769\n",
      "iteration 158 / 300: loss 0.591136\n",
      "iteration 158 / 300: loss 0.584854\n",
      "iteration 158 / 300: loss 0.599647\n",
      "iteration 158 / 300: loss 0.598902\n",
      "iteration 158 / 300: loss 0.614282\n",
      "iteration 158 / 300: loss 0.597796\n",
      "iteration 158 / 300: loss 0.599298\n",
      "iteration 158 / 300: loss 0.603317\n",
      "iteration 158 / 300: loss 0.592866\n",
      "iteration 158 / 300: loss 0.592391\n",
      "iteration 158 / 300: loss 0.589041\n",
      "iteration 158 / 300: loss 0.596446\n",
      "iteration 158 / 300: loss 0.605709\n",
      "iteration 158 / 300: loss 0.610562\n",
      "iteration 158 / 300: loss 0.587782\n",
      "iteration 158 / 300: loss 0.599351\n",
      "iteration 158 / 300: loss 0.602792\n",
      "iteration 158 / 300: loss 0.605028\n",
      "iteration 158 / 300: loss 0.603848\n",
      "iteration 158 / 300: loss 0.624144\n",
      "iteration 158 / 300: loss 0.587219\n",
      "iteration 158 / 300: loss 0.580754\n",
      "iteration 158 / 300: loss 0.625045\n",
      "iteration 158 / 300: loss 0.603310\n",
      "iteration 158 / 300: loss 0.604321\n",
      "iteration 158 / 300: loss 0.595476\n",
      "iteration 158 / 300: loss 0.597543\n",
      "iteration 158 / 300: loss 0.592740\n",
      "iteration 158 / 300: loss 0.589494\n",
      "iteration 158 / 300: loss 0.599264\n",
      "iteration 158 / 300: loss 0.611380\n",
      "iteration 158 / 300: loss 0.592463\n",
      "iteration 158 / 300: loss 0.599424\n",
      "iteration 158 / 300: loss 0.603100\n",
      "iteration 158 / 300: loss 0.602410\n",
      "iteration 158 / 300: loss 0.579812\n",
      "iteration 158 / 300: loss 0.601592\n",
      "iteration 159 / 300: loss 0.585528\n",
      "iteration 159 / 300: loss 0.588428\n",
      "iteration 159 / 300: loss 0.567516\n",
      "iteration 159 / 300: loss 0.592380\n",
      "iteration 159 / 300: loss 0.593618\n",
      "iteration 159 / 300: loss 0.595295\n",
      "iteration 159 / 300: loss 0.608784\n",
      "iteration 159 / 300: loss 0.592732\n",
      "iteration 159 / 300: loss 0.628060\n",
      "iteration 159 / 300: loss 0.580152\n",
      "iteration 159 / 300: loss 0.607923\n",
      "iteration 159 / 300: loss 0.587394\n",
      "iteration 159 / 300: loss 0.591686\n",
      "iteration 159 / 300: loss 0.571370\n",
      "iteration 159 / 300: loss 0.583025\n",
      "iteration 159 / 300: loss 0.608441\n",
      "iteration 159 / 300: loss 0.598359\n",
      "iteration 159 / 300: loss 0.583858\n",
      "iteration 159 / 300: loss 0.615253\n",
      "iteration 159 / 300: loss 0.591649\n",
      "iteration 159 / 300: loss 0.585499\n",
      "iteration 159 / 300: loss 0.591325\n",
      "iteration 159 / 300: loss 0.604341\n",
      "iteration 159 / 300: loss 0.595786\n",
      "iteration 159 / 300: loss 0.614949\n",
      "iteration 159 / 300: loss 0.608389\n",
      "iteration 159 / 300: loss 0.598222\n",
      "iteration 159 / 300: loss 0.588936\n",
      "iteration 159 / 300: loss 0.617757\n",
      "iteration 159 / 300: loss 0.594770\n",
      "iteration 159 / 300: loss 0.601684\n",
      "iteration 159 / 300: loss 0.631031\n",
      "iteration 159 / 300: loss 0.587513\n",
      "iteration 159 / 300: loss 0.606561\n",
      "iteration 159 / 300: loss 0.588034\n",
      "iteration 159 / 300: loss 0.600890\n",
      "iteration 159 / 300: loss 0.595958\n",
      "iteration 159 / 300: loss 0.589291\n",
      "iteration 159 / 300: loss 0.599526\n",
      "iteration 159 / 300: loss 0.604855\n",
      "iteration 159 / 300: loss 0.619414\n",
      "iteration 159 / 300: loss 0.588808\n",
      "iteration 159 / 300: loss 0.593645\n",
      "iteration 159 / 300: loss 0.585595\n",
      "iteration 159 / 300: loss 0.613213\n",
      "iteration 159 / 300: loss 0.587523\n",
      "iteration 159 / 300: loss 0.578328\n",
      "iteration 159 / 300: loss 0.567435\n",
      "iteration 159 / 300: loss 0.562235\n",
      "iteration 159 / 300: loss 0.594183\n",
      "iteration 159 / 300: loss 0.578821\n",
      "iteration 159 / 300: loss 0.586360\n",
      "iteration 159 / 300: loss 0.572890\n",
      "iteration 159 / 300: loss 0.596151\n",
      "iteration 159 / 300: loss 0.607951\n",
      "iteration 159 / 300: loss 0.610839\n",
      "iteration 159 / 300: loss 0.606266\n",
      "iteration 159 / 300: loss 0.583790\n",
      "iteration 159 / 300: loss 0.589627\n",
      "iteration 159 / 300: loss 0.595184\n",
      "iteration 159 / 300: loss 0.598955\n",
      "iteration 159 / 300: loss 0.596133\n",
      "iteration 159 / 300: loss 0.589769\n",
      "iteration 159 / 300: loss 0.591136\n",
      "iteration 159 / 300: loss 0.584854\n",
      "iteration 159 / 300: loss 0.599646\n",
      "iteration 159 / 300: loss 0.598902\n",
      "iteration 159 / 300: loss 0.614282\n",
      "iteration 159 / 300: loss 0.597796\n",
      "iteration 159 / 300: loss 0.599298\n",
      "iteration 159 / 300: loss 0.603317\n",
      "iteration 159 / 300: loss 0.592866\n",
      "iteration 159 / 300: loss 0.592391\n",
      "iteration 159 / 300: loss 0.589041\n",
      "iteration 159 / 300: loss 0.596446\n",
      "iteration 159 / 300: loss 0.605709\n",
      "iteration 159 / 300: loss 0.610562\n",
      "iteration 159 / 300: loss 0.587782\n",
      "iteration 159 / 300: loss 0.599351\n",
      "iteration 159 / 300: loss 0.602792\n",
      "iteration 159 / 300: loss 0.605028\n",
      "iteration 159 / 300: loss 0.603848\n",
      "iteration 159 / 300: loss 0.624144\n",
      "iteration 159 / 300: loss 0.587219\n",
      "iteration 159 / 300: loss 0.580754\n",
      "iteration 159 / 300: loss 0.625045\n",
      "iteration 159 / 300: loss 0.603310\n",
      "iteration 159 / 300: loss 0.604321\n",
      "iteration 159 / 300: loss 0.595476\n",
      "iteration 159 / 300: loss 0.597543\n",
      "iteration 159 / 300: loss 0.592740\n",
      "iteration 159 / 300: loss 0.589494\n",
      "iteration 159 / 300: loss 0.599264\n",
      "iteration 159 / 300: loss 0.611380\n",
      "iteration 159 / 300: loss 0.592463\n",
      "iteration 159 / 300: loss 0.599424\n",
      "iteration 159 / 300: loss 0.603100\n",
      "iteration 159 / 300: loss 0.602410\n",
      "iteration 159 / 300: loss 0.579812\n",
      "iteration 159 / 300: loss 0.601592\n",
      "iteration 160 / 300: loss 0.585528\n",
      "iteration 160 / 300: loss 0.588428\n",
      "iteration 160 / 300: loss 0.567516\n",
      "iteration 160 / 300: loss 0.592380\n",
      "iteration 160 / 300: loss 0.593618\n",
      "iteration 160 / 300: loss 0.595295\n",
      "iteration 160 / 300: loss 0.608784\n",
      "iteration 160 / 300: loss 0.592732\n",
      "iteration 160 / 300: loss 0.628060\n",
      "iteration 160 / 300: loss 0.580152\n",
      "iteration 160 / 300: loss 0.607923\n",
      "iteration 160 / 300: loss 0.587394\n",
      "iteration 160 / 300: loss 0.591686\n",
      "iteration 160 / 300: loss 0.571370\n",
      "iteration 160 / 300: loss 0.583025\n",
      "iteration 160 / 300: loss 0.608441\n",
      "iteration 160 / 300: loss 0.598359\n",
      "iteration 160 / 300: loss 0.583858\n",
      "iteration 160 / 300: loss 0.615253\n",
      "iteration 160 / 300: loss 0.591649\n",
      "iteration 160 / 300: loss 0.585499\n",
      "iteration 160 / 300: loss 0.591325\n",
      "iteration 160 / 300: loss 0.604341\n",
      "iteration 160 / 300: loss 0.595786\n",
      "iteration 160 / 300: loss 0.614949\n",
      "iteration 160 / 300: loss 0.608389\n",
      "iteration 160 / 300: loss 0.598222\n",
      "iteration 160 / 300: loss 0.588936\n",
      "iteration 160 / 300: loss 0.617757\n",
      "iteration 160 / 300: loss 0.594770\n",
      "iteration 160 / 300: loss 0.601684\n",
      "iteration 160 / 300: loss 0.631031\n",
      "iteration 160 / 300: loss 0.587513\n",
      "iteration 160 / 300: loss 0.606561\n",
      "iteration 160 / 300: loss 0.588034\n",
      "iteration 160 / 300: loss 0.600890\n",
      "iteration 160 / 300: loss 0.595958\n",
      "iteration 160 / 300: loss 0.589291\n",
      "iteration 160 / 300: loss 0.599526\n",
      "iteration 160 / 300: loss 0.604855\n",
      "iteration 160 / 300: loss 0.619414\n",
      "iteration 160 / 300: loss 0.588808\n",
      "iteration 160 / 300: loss 0.593645\n",
      "iteration 160 / 300: loss 0.585595\n",
      "iteration 160 / 300: loss 0.613213\n",
      "iteration 160 / 300: loss 0.587523\n",
      "iteration 160 / 300: loss 0.578328\n",
      "iteration 160 / 300: loss 0.567435\n",
      "iteration 160 / 300: loss 0.562235\n",
      "iteration 160 / 300: loss 0.594183\n",
      "iteration 160 / 300: loss 0.578821\n",
      "iteration 160 / 300: loss 0.586360\n",
      "iteration 160 / 300: loss 0.572890\n",
      "iteration 160 / 300: loss 0.596151\n",
      "iteration 160 / 300: loss 0.607951\n",
      "iteration 160 / 300: loss 0.610839\n",
      "iteration 160 / 300: loss 0.606266\n",
      "iteration 160 / 300: loss 0.583790\n",
      "iteration 160 / 300: loss 0.589627\n",
      "iteration 160 / 300: loss 0.595184\n",
      "iteration 160 / 300: loss 0.598955\n",
      "iteration 160 / 300: loss 0.596133\n",
      "iteration 160 / 300: loss 0.589769\n",
      "iteration 160 / 300: loss 0.591136\n",
      "iteration 160 / 300: loss 0.584854\n",
      "iteration 160 / 300: loss 0.599646\n",
      "iteration 160 / 300: loss 0.598902\n",
      "iteration 160 / 300: loss 0.614282\n",
      "iteration 160 / 300: loss 0.597796\n",
      "iteration 160 / 300: loss 0.599298\n",
      "iteration 160 / 300: loss 0.603317\n",
      "iteration 160 / 300: loss 0.592866\n",
      "iteration 160 / 300: loss 0.592391\n",
      "iteration 160 / 300: loss 0.589041\n",
      "iteration 160 / 300: loss 0.596446\n",
      "iteration 160 / 300: loss 0.605709\n",
      "iteration 160 / 300: loss 0.610562\n",
      "iteration 160 / 300: loss 0.587782\n",
      "iteration 160 / 300: loss 0.599351\n",
      "iteration 160 / 300: loss 0.602792\n",
      "iteration 160 / 300: loss 0.605028\n",
      "iteration 160 / 300: loss 0.603848\n",
      "iteration 160 / 300: loss 0.624144\n",
      "iteration 160 / 300: loss 0.587219\n",
      "iteration 160 / 300: loss 0.580754\n",
      "iteration 160 / 300: loss 0.625045\n",
      "iteration 160 / 300: loss 0.603310\n",
      "iteration 160 / 300: loss 0.604321\n",
      "iteration 160 / 300: loss 0.595476\n",
      "iteration 160 / 300: loss 0.597543\n",
      "iteration 160 / 300: loss 0.592740\n",
      "iteration 160 / 300: loss 0.589494\n",
      "iteration 160 / 300: loss 0.599264\n",
      "iteration 160 / 300: loss 0.611380\n",
      "iteration 160 / 300: loss 0.592463\n",
      "iteration 160 / 300: loss 0.599424\n",
      "iteration 160 / 300: loss 0.603100\n",
      "iteration 160 / 300: loss 0.602410\n",
      "iteration 160 / 300: loss 0.579812\n",
      "iteration 160 / 300: loss 0.601592\n",
      "iteration 161 / 300: loss 0.585528\n",
      "iteration 161 / 300: loss 0.588428\n",
      "iteration 161 / 300: loss 0.567516\n",
      "iteration 161 / 300: loss 0.592380\n",
      "iteration 161 / 300: loss 0.593618\n",
      "iteration 161 / 300: loss 0.595295\n",
      "iteration 161 / 300: loss 0.608784\n",
      "iteration 161 / 300: loss 0.592732\n",
      "iteration 161 / 300: loss 0.628060\n",
      "iteration 161 / 300: loss 0.580152\n",
      "iteration 161 / 300: loss 0.607923\n",
      "iteration 161 / 300: loss 0.587394\n",
      "iteration 161 / 300: loss 0.591686\n",
      "iteration 161 / 300: loss 0.571370\n",
      "iteration 161 / 300: loss 0.583025\n",
      "iteration 161 / 300: loss 0.608441\n",
      "iteration 161 / 300: loss 0.598359\n",
      "iteration 161 / 300: loss 0.583858\n",
      "iteration 161 / 300: loss 0.615253\n",
      "iteration 161 / 300: loss 0.591649\n",
      "iteration 161 / 300: loss 0.585499\n",
      "iteration 161 / 300: loss 0.591325\n",
      "iteration 161 / 300: loss 0.604341\n",
      "iteration 161 / 300: loss 0.595786\n",
      "iteration 161 / 300: loss 0.614949\n",
      "iteration 161 / 300: loss 0.608389\n",
      "iteration 161 / 300: loss 0.598222\n",
      "iteration 161 / 300: loss 0.588936\n",
      "iteration 161 / 300: loss 0.617757\n",
      "iteration 161 / 300: loss 0.594770\n",
      "iteration 161 / 300: loss 0.601684\n",
      "iteration 161 / 300: loss 0.631031\n",
      "iteration 161 / 300: loss 0.587513\n",
      "iteration 161 / 300: loss 0.606561\n",
      "iteration 161 / 300: loss 0.588034\n",
      "iteration 161 / 300: loss 0.600890\n",
      "iteration 161 / 300: loss 0.595958\n",
      "iteration 161 / 300: loss 0.589291\n",
      "iteration 161 / 300: loss 0.599526\n",
      "iteration 161 / 300: loss 0.604855\n",
      "iteration 161 / 300: loss 0.619414\n",
      "iteration 161 / 300: loss 0.588808\n",
      "iteration 161 / 300: loss 0.593645\n",
      "iteration 161 / 300: loss 0.585595\n",
      "iteration 161 / 300: loss 0.613213\n",
      "iteration 161 / 300: loss 0.587523\n",
      "iteration 161 / 300: loss 0.578328\n",
      "iteration 161 / 300: loss 0.567435\n",
      "iteration 161 / 300: loss 0.562235\n",
      "iteration 161 / 300: loss 0.594183\n",
      "iteration 161 / 300: loss 0.578821\n",
      "iteration 161 / 300: loss 0.586360\n",
      "iteration 161 / 300: loss 0.572890\n",
      "iteration 161 / 300: loss 0.596151\n",
      "iteration 161 / 300: loss 0.607951\n",
      "iteration 161 / 300: loss 0.610839\n",
      "iteration 161 / 300: loss 0.606266\n",
      "iteration 161 / 300: loss 0.583790\n",
      "iteration 161 / 300: loss 0.589627\n",
      "iteration 161 / 300: loss 0.595184\n",
      "iteration 161 / 300: loss 0.598955\n",
      "iteration 161 / 300: loss 0.596133\n",
      "iteration 161 / 300: loss 0.589769\n",
      "iteration 161 / 300: loss 0.591136\n",
      "iteration 161 / 300: loss 0.584854\n",
      "iteration 161 / 300: loss 0.599646\n",
      "iteration 161 / 300: loss 0.598902\n",
      "iteration 161 / 300: loss 0.614282\n",
      "iteration 161 / 300: loss 0.597796\n",
      "iteration 161 / 300: loss 0.599298\n",
      "iteration 161 / 300: loss 0.603317\n",
      "iteration 161 / 300: loss 0.592866\n",
      "iteration 161 / 300: loss 0.592391\n",
      "iteration 161 / 300: loss 0.589041\n",
      "iteration 161 / 300: loss 0.596446\n",
      "iteration 161 / 300: loss 0.605709\n",
      "iteration 161 / 300: loss 0.610562\n",
      "iteration 161 / 300: loss 0.587782\n",
      "iteration 161 / 300: loss 0.599351\n",
      "iteration 161 / 300: loss 0.602792\n",
      "iteration 161 / 300: loss 0.605028\n",
      "iteration 161 / 300: loss 0.603848\n",
      "iteration 161 / 300: loss 0.624144\n",
      "iteration 161 / 300: loss 0.587219\n",
      "iteration 161 / 300: loss 0.580754\n",
      "iteration 161 / 300: loss 0.625045\n",
      "iteration 161 / 300: loss 0.603310\n",
      "iteration 161 / 300: loss 0.604321\n",
      "iteration 161 / 300: loss 0.595476\n",
      "iteration 161 / 300: loss 0.597543\n",
      "iteration 161 / 300: loss 0.592740\n",
      "iteration 161 / 300: loss 0.589494\n",
      "iteration 161 / 300: loss 0.599264\n",
      "iteration 161 / 300: loss 0.611380\n",
      "iteration 161 / 300: loss 0.592463\n",
      "iteration 161 / 300: loss 0.599424\n",
      "iteration 161 / 300: loss 0.603100\n",
      "iteration 161 / 300: loss 0.602410\n",
      "iteration 161 / 300: loss 0.579812\n",
      "iteration 161 / 300: loss 0.601592\n",
      "iteration 162 / 300: loss 0.585528\n",
      "iteration 162 / 300: loss 0.588428\n",
      "iteration 162 / 300: loss 0.567516\n",
      "iteration 162 / 300: loss 0.592380\n",
      "iteration 162 / 300: loss 0.593618\n",
      "iteration 162 / 300: loss 0.595295\n",
      "iteration 162 / 300: loss 0.608784\n",
      "iteration 162 / 300: loss 0.592732\n",
      "iteration 162 / 300: loss 0.628060\n",
      "iteration 162 / 300: loss 0.580152\n",
      "iteration 162 / 300: loss 0.607923\n",
      "iteration 162 / 300: loss 0.587394\n",
      "iteration 162 / 300: loss 0.591686\n",
      "iteration 162 / 300: loss 0.571370\n",
      "iteration 162 / 300: loss 0.583025\n",
      "iteration 162 / 300: loss 0.608441\n",
      "iteration 162 / 300: loss 0.598359\n",
      "iteration 162 / 300: loss 0.583858\n",
      "iteration 162 / 300: loss 0.615253\n",
      "iteration 162 / 300: loss 0.591649\n",
      "iteration 162 / 300: loss 0.585499\n",
      "iteration 162 / 300: loss 0.591325\n",
      "iteration 162 / 300: loss 0.604341\n",
      "iteration 162 / 300: loss 0.595786\n",
      "iteration 162 / 300: loss 0.614949\n",
      "iteration 162 / 300: loss 0.608389\n",
      "iteration 162 / 300: loss 0.598222\n",
      "iteration 162 / 300: loss 0.588936\n",
      "iteration 162 / 300: loss 0.617757\n",
      "iteration 162 / 300: loss 0.594770\n",
      "iteration 162 / 300: loss 0.601684\n",
      "iteration 162 / 300: loss 0.631031\n",
      "iteration 162 / 300: loss 0.587513\n",
      "iteration 162 / 300: loss 0.606561\n",
      "iteration 162 / 300: loss 0.588034\n",
      "iteration 162 / 300: loss 0.600890\n",
      "iteration 162 / 300: loss 0.595958\n",
      "iteration 162 / 300: loss 0.589291\n",
      "iteration 162 / 300: loss 0.599526\n",
      "iteration 162 / 300: loss 0.604855\n",
      "iteration 162 / 300: loss 0.619414\n",
      "iteration 162 / 300: loss 0.588808\n",
      "iteration 162 / 300: loss 0.593645\n",
      "iteration 162 / 300: loss 0.585595\n",
      "iteration 162 / 300: loss 0.613213\n",
      "iteration 162 / 300: loss 0.587523\n",
      "iteration 162 / 300: loss 0.578328\n",
      "iteration 162 / 300: loss 0.567435\n",
      "iteration 162 / 300: loss 0.562235\n",
      "iteration 162 / 300: loss 0.594183\n",
      "iteration 162 / 300: loss 0.578821\n",
      "iteration 162 / 300: loss 0.586360\n",
      "iteration 162 / 300: loss 0.572890\n",
      "iteration 162 / 300: loss 0.596151\n",
      "iteration 162 / 300: loss 0.607951\n",
      "iteration 162 / 300: loss 0.610839\n",
      "iteration 162 / 300: loss 0.606266\n",
      "iteration 162 / 300: loss 0.583790\n",
      "iteration 162 / 300: loss 0.589627\n",
      "iteration 162 / 300: loss 0.595184\n",
      "iteration 162 / 300: loss 0.598955\n",
      "iteration 162 / 300: loss 0.596133\n",
      "iteration 162 / 300: loss 0.589769\n",
      "iteration 162 / 300: loss 0.591136\n",
      "iteration 162 / 300: loss 0.584854\n",
      "iteration 162 / 300: loss 0.599646\n",
      "iteration 162 / 300: loss 0.598902\n",
      "iteration 162 / 300: loss 0.614282\n",
      "iteration 162 / 300: loss 0.597796\n",
      "iteration 162 / 300: loss 0.599298\n",
      "iteration 162 / 300: loss 0.603317\n",
      "iteration 162 / 300: loss 0.592866\n",
      "iteration 162 / 300: loss 0.592391\n",
      "iteration 162 / 300: loss 0.589041\n",
      "iteration 162 / 300: loss 0.596446\n",
      "iteration 162 / 300: loss 0.605709\n",
      "iteration 162 / 300: loss 0.610562\n",
      "iteration 162 / 300: loss 0.587782\n",
      "iteration 162 / 300: loss 0.599351\n",
      "iteration 162 / 300: loss 0.602792\n",
      "iteration 162 / 300: loss 0.605028\n",
      "iteration 162 / 300: loss 0.603848\n",
      "iteration 162 / 300: loss 0.624144\n",
      "iteration 162 / 300: loss 0.587219\n",
      "iteration 162 / 300: loss 0.580754\n",
      "iteration 162 / 300: loss 0.625045\n",
      "iteration 162 / 300: loss 0.603310\n",
      "iteration 162 / 300: loss 0.604321\n",
      "iteration 162 / 300: loss 0.595476\n",
      "iteration 162 / 300: loss 0.597543\n",
      "iteration 162 / 300: loss 0.592740\n",
      "iteration 162 / 300: loss 0.589494\n",
      "iteration 162 / 300: loss 0.599264\n",
      "iteration 162 / 300: loss 0.611380\n",
      "iteration 162 / 300: loss 0.592463\n",
      "iteration 162 / 300: loss 0.599424\n",
      "iteration 162 / 300: loss 0.603100\n",
      "iteration 162 / 300: loss 0.602410\n",
      "iteration 162 / 300: loss 0.579812\n",
      "iteration 162 / 300: loss 0.601592\n",
      "iteration 163 / 300: loss 0.585528\n",
      "iteration 163 / 300: loss 0.588428\n",
      "iteration 163 / 300: loss 0.567516\n",
      "iteration 163 / 300: loss 0.592380\n",
      "iteration 163 / 300: loss 0.593618\n",
      "iteration 163 / 300: loss 0.595295\n",
      "iteration 163 / 300: loss 0.608784\n",
      "iteration 163 / 300: loss 0.592732\n",
      "iteration 163 / 300: loss 0.628060\n",
      "iteration 163 / 300: loss 0.580152\n",
      "iteration 163 / 300: loss 0.607923\n",
      "iteration 163 / 300: loss 0.587394\n",
      "iteration 163 / 300: loss 0.591686\n",
      "iteration 163 / 300: loss 0.571370\n",
      "iteration 163 / 300: loss 0.583025\n",
      "iteration 163 / 300: loss 0.608441\n",
      "iteration 163 / 300: loss 0.598359\n",
      "iteration 163 / 300: loss 0.583858\n",
      "iteration 163 / 300: loss 0.615253\n",
      "iteration 163 / 300: loss 0.591649\n",
      "iteration 163 / 300: loss 0.585499\n",
      "iteration 163 / 300: loss 0.591325\n",
      "iteration 163 / 300: loss 0.604341\n",
      "iteration 163 / 300: loss 0.595786\n",
      "iteration 163 / 300: loss 0.614949\n",
      "iteration 163 / 300: loss 0.608389\n",
      "iteration 163 / 300: loss 0.598222\n",
      "iteration 163 / 300: loss 0.588936\n",
      "iteration 163 / 300: loss 0.617757\n",
      "iteration 163 / 300: loss 0.594770\n",
      "iteration 163 / 300: loss 0.601684\n",
      "iteration 163 / 300: loss 0.631031\n",
      "iteration 163 / 300: loss 0.587513\n",
      "iteration 163 / 300: loss 0.606561\n",
      "iteration 163 / 300: loss 0.588034\n",
      "iteration 163 / 300: loss 0.600890\n",
      "iteration 163 / 300: loss 0.595958\n",
      "iteration 163 / 300: loss 0.589291\n",
      "iteration 163 / 300: loss 0.599526\n",
      "iteration 163 / 300: loss 0.604855\n",
      "iteration 163 / 300: loss 0.619414\n",
      "iteration 163 / 300: loss 0.588808\n",
      "iteration 163 / 300: loss 0.593645\n",
      "iteration 163 / 300: loss 0.585595\n",
      "iteration 163 / 300: loss 0.613213\n",
      "iteration 163 / 300: loss 0.587523\n",
      "iteration 163 / 300: loss 0.578328\n",
      "iteration 163 / 300: loss 0.567435\n",
      "iteration 163 / 300: loss 0.562235\n",
      "iteration 163 / 300: loss 0.594183\n",
      "iteration 163 / 300: loss 0.578821\n",
      "iteration 163 / 300: loss 0.586360\n",
      "iteration 163 / 300: loss 0.572890\n",
      "iteration 163 / 300: loss 0.596151\n",
      "iteration 163 / 300: loss 0.607951\n",
      "iteration 163 / 300: loss 0.610839\n",
      "iteration 163 / 300: loss 0.606266\n",
      "iteration 163 / 300: loss 0.583790\n",
      "iteration 163 / 300: loss 0.589627\n",
      "iteration 163 / 300: loss 0.595184\n",
      "iteration 163 / 300: loss 0.598955\n",
      "iteration 163 / 300: loss 0.596133\n",
      "iteration 163 / 300: loss 0.589769\n",
      "iteration 163 / 300: loss 0.591136\n",
      "iteration 163 / 300: loss 0.584854\n",
      "iteration 163 / 300: loss 0.599646\n",
      "iteration 163 / 300: loss 0.598902\n",
      "iteration 163 / 300: loss 0.614282\n",
      "iteration 163 / 300: loss 0.597796\n",
      "iteration 163 / 300: loss 0.599298\n",
      "iteration 163 / 300: loss 0.603317\n",
      "iteration 163 / 300: loss 0.592866\n",
      "iteration 163 / 300: loss 0.592391\n",
      "iteration 163 / 300: loss 0.589041\n",
      "iteration 163 / 300: loss 0.596446\n",
      "iteration 163 / 300: loss 0.605709\n",
      "iteration 163 / 300: loss 0.610562\n",
      "iteration 163 / 300: loss 0.587782\n",
      "iteration 163 / 300: loss 0.599351\n",
      "iteration 163 / 300: loss 0.602792\n",
      "iteration 163 / 300: loss 0.605028\n",
      "iteration 163 / 300: loss 0.603848\n",
      "iteration 163 / 300: loss 0.624144\n",
      "iteration 163 / 300: loss 0.587219\n",
      "iteration 163 / 300: loss 0.580754\n",
      "iteration 163 / 300: loss 0.625045\n",
      "iteration 163 / 300: loss 0.603310\n",
      "iteration 163 / 300: loss 0.604321\n",
      "iteration 163 / 300: loss 0.595476\n",
      "iteration 163 / 300: loss 0.597543\n",
      "iteration 163 / 300: loss 0.592740\n",
      "iteration 163 / 300: loss 0.589494\n",
      "iteration 163 / 300: loss 0.599264\n",
      "iteration 163 / 300: loss 0.611380\n",
      "iteration 163 / 300: loss 0.592463\n",
      "iteration 163 / 300: loss 0.599424\n",
      "iteration 163 / 300: loss 0.603100\n",
      "iteration 163 / 300: loss 0.602410\n",
      "iteration 163 / 300: loss 0.579811\n",
      "iteration 163 / 300: loss 0.601592\n",
      "iteration 164 / 300: loss 0.585528\n",
      "iteration 164 / 300: loss 0.588428\n",
      "iteration 164 / 300: loss 0.567516\n",
      "iteration 164 / 300: loss 0.592380\n",
      "iteration 164 / 300: loss 0.593618\n",
      "iteration 164 / 300: loss 0.595295\n",
      "iteration 164 / 300: loss 0.608784\n",
      "iteration 164 / 300: loss 0.592732\n",
      "iteration 164 / 300: loss 0.628060\n",
      "iteration 164 / 300: loss 0.580152\n",
      "iteration 164 / 300: loss 0.607923\n",
      "iteration 164 / 300: loss 0.587394\n",
      "iteration 164 / 300: loss 0.591686\n",
      "iteration 164 / 300: loss 0.571370\n",
      "iteration 164 / 300: loss 0.583025\n",
      "iteration 164 / 300: loss 0.608441\n",
      "iteration 164 / 300: loss 0.598359\n",
      "iteration 164 / 300: loss 0.583858\n",
      "iteration 164 / 300: loss 0.615253\n",
      "iteration 164 / 300: loss 0.591649\n",
      "iteration 164 / 300: loss 0.585499\n",
      "iteration 164 / 300: loss 0.591325\n",
      "iteration 164 / 300: loss 0.604341\n",
      "iteration 164 / 300: loss 0.595786\n",
      "iteration 164 / 300: loss 0.614949\n",
      "iteration 164 / 300: loss 0.608389\n",
      "iteration 164 / 300: loss 0.598222\n",
      "iteration 164 / 300: loss 0.588936\n",
      "iteration 164 / 300: loss 0.617757\n",
      "iteration 164 / 300: loss 0.594770\n",
      "iteration 164 / 300: loss 0.601684\n",
      "iteration 164 / 300: loss 0.631031\n",
      "iteration 164 / 300: loss 0.587513\n",
      "iteration 164 / 300: loss 0.606561\n",
      "iteration 164 / 300: loss 0.588034\n",
      "iteration 164 / 300: loss 0.600890\n",
      "iteration 164 / 300: loss 0.595958\n",
      "iteration 164 / 300: loss 0.589291\n",
      "iteration 164 / 300: loss 0.599526\n",
      "iteration 164 / 300: loss 0.604855\n",
      "iteration 164 / 300: loss 0.619414\n",
      "iteration 164 / 300: loss 0.588808\n",
      "iteration 164 / 300: loss 0.593645\n",
      "iteration 164 / 300: loss 0.585595\n",
      "iteration 164 / 300: loss 0.613213\n",
      "iteration 164 / 300: loss 0.587523\n",
      "iteration 164 / 300: loss 0.578328\n",
      "iteration 164 / 300: loss 0.567435\n",
      "iteration 164 / 300: loss 0.562235\n",
      "iteration 164 / 300: loss 0.594183\n",
      "iteration 164 / 300: loss 0.578821\n",
      "iteration 164 / 300: loss 0.586360\n",
      "iteration 164 / 300: loss 0.572890\n",
      "iteration 164 / 300: loss 0.596151\n",
      "iteration 164 / 300: loss 0.607951\n",
      "iteration 164 / 300: loss 0.610839\n",
      "iteration 164 / 300: loss 0.606266\n",
      "iteration 164 / 300: loss 0.583790\n",
      "iteration 164 / 300: loss 0.589627\n",
      "iteration 164 / 300: loss 0.595184\n",
      "iteration 164 / 300: loss 0.598955\n",
      "iteration 164 / 300: loss 0.596133\n",
      "iteration 164 / 300: loss 0.589769\n",
      "iteration 164 / 300: loss 0.591136\n",
      "iteration 164 / 300: loss 0.584854\n",
      "iteration 164 / 300: loss 0.599646\n",
      "iteration 164 / 300: loss 0.598902\n",
      "iteration 164 / 300: loss 0.614282\n",
      "iteration 164 / 300: loss 0.597796\n",
      "iteration 164 / 300: loss 0.599298\n",
      "iteration 164 / 300: loss 0.603317\n",
      "iteration 164 / 300: loss 0.592866\n",
      "iteration 164 / 300: loss 0.592391\n",
      "iteration 164 / 300: loss 0.589041\n",
      "iteration 164 / 300: loss 0.596446\n",
      "iteration 164 / 300: loss 0.605709\n",
      "iteration 164 / 300: loss 0.610562\n",
      "iteration 164 / 300: loss 0.587782\n",
      "iteration 164 / 300: loss 0.599351\n",
      "iteration 164 / 300: loss 0.602792\n",
      "iteration 164 / 300: loss 0.605028\n",
      "iteration 164 / 300: loss 0.603848\n",
      "iteration 164 / 300: loss 0.624144\n",
      "iteration 164 / 300: loss 0.587219\n",
      "iteration 164 / 300: loss 0.580754\n",
      "iteration 164 / 300: loss 0.625045\n",
      "iteration 164 / 300: loss 0.603310\n",
      "iteration 164 / 300: loss 0.604321\n",
      "iteration 164 / 300: loss 0.595476\n",
      "iteration 164 / 300: loss 0.597543\n",
      "iteration 164 / 300: loss 0.592740\n",
      "iteration 164 / 300: loss 0.589494\n",
      "iteration 164 / 300: loss 0.599264\n",
      "iteration 164 / 300: loss 0.611380\n",
      "iteration 164 / 300: loss 0.592463\n",
      "iteration 164 / 300: loss 0.599424\n",
      "iteration 164 / 300: loss 0.603100\n",
      "iteration 164 / 300: loss 0.602410\n",
      "iteration 164 / 300: loss 0.579811\n",
      "iteration 164 / 300: loss 0.601592\n",
      "iteration 165 / 300: loss 0.585528\n",
      "iteration 165 / 300: loss 0.588428\n",
      "iteration 165 / 300: loss 0.567516\n",
      "iteration 165 / 300: loss 0.592380\n",
      "iteration 165 / 300: loss 0.593618\n",
      "iteration 165 / 300: loss 0.595295\n",
      "iteration 165 / 300: loss 0.608784\n",
      "iteration 165 / 300: loss 0.592732\n",
      "iteration 165 / 300: loss 0.628060\n",
      "iteration 165 / 300: loss 0.580152\n",
      "iteration 165 / 300: loss 0.607923\n",
      "iteration 165 / 300: loss 0.587394\n",
      "iteration 165 / 300: loss 0.591686\n",
      "iteration 165 / 300: loss 0.571370\n",
      "iteration 165 / 300: loss 0.583025\n",
      "iteration 165 / 300: loss 0.608441\n",
      "iteration 165 / 300: loss 0.598359\n",
      "iteration 165 / 300: loss 0.583858\n",
      "iteration 165 / 300: loss 0.615253\n",
      "iteration 165 / 300: loss 0.591649\n",
      "iteration 165 / 300: loss 0.585499\n",
      "iteration 165 / 300: loss 0.591325\n",
      "iteration 165 / 300: loss 0.604341\n",
      "iteration 165 / 300: loss 0.595786\n",
      "iteration 165 / 300: loss 0.614949\n",
      "iteration 165 / 300: loss 0.608389\n",
      "iteration 165 / 300: loss 0.598222\n",
      "iteration 165 / 300: loss 0.588936\n",
      "iteration 165 / 300: loss 0.617757\n",
      "iteration 165 / 300: loss 0.594770\n",
      "iteration 165 / 300: loss 0.601684\n",
      "iteration 165 / 300: loss 0.631031\n",
      "iteration 165 / 300: loss 0.587513\n",
      "iteration 165 / 300: loss 0.606561\n",
      "iteration 165 / 300: loss 0.588034\n",
      "iteration 165 / 300: loss 0.600890\n",
      "iteration 165 / 300: loss 0.595958\n",
      "iteration 165 / 300: loss 0.589291\n",
      "iteration 165 / 300: loss 0.599526\n",
      "iteration 165 / 300: loss 0.604855\n",
      "iteration 165 / 300: loss 0.619414\n",
      "iteration 165 / 300: loss 0.588808\n",
      "iteration 165 / 300: loss 0.593645\n",
      "iteration 165 / 300: loss 0.585595\n",
      "iteration 165 / 300: loss 0.613213\n",
      "iteration 165 / 300: loss 0.587523\n",
      "iteration 165 / 300: loss 0.578328\n",
      "iteration 165 / 300: loss 0.567435\n",
      "iteration 165 / 300: loss 0.562235\n",
      "iteration 165 / 300: loss 0.594183\n",
      "iteration 165 / 300: loss 0.578821\n",
      "iteration 165 / 300: loss 0.586360\n",
      "iteration 165 / 300: loss 0.572890\n",
      "iteration 165 / 300: loss 0.596151\n",
      "iteration 165 / 300: loss 0.607951\n",
      "iteration 165 / 300: loss 0.610839\n",
      "iteration 165 / 300: loss 0.606266\n",
      "iteration 165 / 300: loss 0.583790\n",
      "iteration 165 / 300: loss 0.589627\n",
      "iteration 165 / 300: loss 0.595184\n",
      "iteration 165 / 300: loss 0.598955\n",
      "iteration 165 / 300: loss 0.596133\n",
      "iteration 165 / 300: loss 0.589769\n",
      "iteration 165 / 300: loss 0.591136\n",
      "iteration 165 / 300: loss 0.584854\n",
      "iteration 165 / 300: loss 0.599646\n",
      "iteration 165 / 300: loss 0.598902\n",
      "iteration 165 / 300: loss 0.614282\n",
      "iteration 165 / 300: loss 0.597796\n",
      "iteration 165 / 300: loss 0.599298\n",
      "iteration 165 / 300: loss 0.603317\n",
      "iteration 165 / 300: loss 0.592866\n",
      "iteration 165 / 300: loss 0.592391\n",
      "iteration 165 / 300: loss 0.589041\n",
      "iteration 165 / 300: loss 0.596446\n",
      "iteration 165 / 300: loss 0.605709\n",
      "iteration 165 / 300: loss 0.610562\n",
      "iteration 165 / 300: loss 0.587782\n",
      "iteration 165 / 300: loss 0.599351\n",
      "iteration 165 / 300: loss 0.602792\n",
      "iteration 165 / 300: loss 0.605028\n",
      "iteration 165 / 300: loss 0.603848\n",
      "iteration 165 / 300: loss 0.624144\n",
      "iteration 165 / 300: loss 0.587219\n",
      "iteration 165 / 300: loss 0.580754\n",
      "iteration 165 / 300: loss 0.625045\n",
      "iteration 165 / 300: loss 0.603310\n",
      "iteration 165 / 300: loss 0.604321\n",
      "iteration 165 / 300: loss 0.595476\n",
      "iteration 165 / 300: loss 0.597543\n",
      "iteration 165 / 300: loss 0.592740\n",
      "iteration 165 / 300: loss 0.589494\n",
      "iteration 165 / 300: loss 0.599264\n",
      "iteration 165 / 300: loss 0.611380\n",
      "iteration 165 / 300: loss 0.592463\n",
      "iteration 165 / 300: loss 0.599424\n",
      "iteration 165 / 300: loss 0.603100\n",
      "iteration 165 / 300: loss 0.602410\n",
      "iteration 165 / 300: loss 0.579811\n",
      "iteration 165 / 300: loss 0.601592\n",
      "iteration 166 / 300: loss 0.585528\n",
      "iteration 166 / 300: loss 0.588428\n",
      "iteration 166 / 300: loss 0.567516\n",
      "iteration 166 / 300: loss 0.592380\n",
      "iteration 166 / 300: loss 0.593618\n",
      "iteration 166 / 300: loss 0.595295\n",
      "iteration 166 / 300: loss 0.608784\n",
      "iteration 166 / 300: loss 0.592732\n",
      "iteration 166 / 300: loss 0.628060\n",
      "iteration 166 / 300: loss 0.580152\n",
      "iteration 166 / 300: loss 0.607923\n",
      "iteration 166 / 300: loss 0.587394\n",
      "iteration 166 / 300: loss 0.591686\n",
      "iteration 166 / 300: loss 0.571370\n",
      "iteration 166 / 300: loss 0.583025\n",
      "iteration 166 / 300: loss 0.608441\n",
      "iteration 166 / 300: loss 0.598359\n",
      "iteration 166 / 300: loss 0.583858\n",
      "iteration 166 / 300: loss 0.615253\n",
      "iteration 166 / 300: loss 0.591649\n",
      "iteration 166 / 300: loss 0.585499\n",
      "iteration 166 / 300: loss 0.591325\n",
      "iteration 166 / 300: loss 0.604341\n",
      "iteration 166 / 300: loss 0.595786\n",
      "iteration 166 / 300: loss 0.614949\n",
      "iteration 166 / 300: loss 0.608389\n",
      "iteration 166 / 300: loss 0.598222\n",
      "iteration 166 / 300: loss 0.588936\n",
      "iteration 166 / 300: loss 0.617757\n",
      "iteration 166 / 300: loss 0.594770\n",
      "iteration 166 / 300: loss 0.601684\n",
      "iteration 166 / 300: loss 0.631031\n",
      "iteration 166 / 300: loss 0.587513\n",
      "iteration 166 / 300: loss 0.606561\n",
      "iteration 166 / 300: loss 0.588034\n",
      "iteration 166 / 300: loss 0.600890\n",
      "iteration 166 / 300: loss 0.595958\n",
      "iteration 166 / 300: loss 0.589291\n",
      "iteration 166 / 300: loss 0.599526\n",
      "iteration 166 / 300: loss 0.604855\n",
      "iteration 166 / 300: loss 0.619414\n",
      "iteration 166 / 300: loss 0.588808\n",
      "iteration 166 / 300: loss 0.593645\n",
      "iteration 166 / 300: loss 0.585595\n",
      "iteration 166 / 300: loss 0.613213\n",
      "iteration 166 / 300: loss 0.587523\n",
      "iteration 166 / 300: loss 0.578328\n",
      "iteration 166 / 300: loss 0.567435\n",
      "iteration 166 / 300: loss 0.562235\n",
      "iteration 166 / 300: loss 0.594183\n",
      "iteration 166 / 300: loss 0.578821\n",
      "iteration 166 / 300: loss 0.586360\n",
      "iteration 166 / 300: loss 0.572890\n",
      "iteration 166 / 300: loss 0.596151\n",
      "iteration 166 / 300: loss 0.607951\n",
      "iteration 166 / 300: loss 0.610839\n",
      "iteration 166 / 300: loss 0.606266\n",
      "iteration 166 / 300: loss 0.583790\n",
      "iteration 166 / 300: loss 0.589627\n",
      "iteration 166 / 300: loss 0.595184\n",
      "iteration 166 / 300: loss 0.598955\n",
      "iteration 166 / 300: loss 0.596133\n",
      "iteration 166 / 300: loss 0.589769\n",
      "iteration 166 / 300: loss 0.591136\n",
      "iteration 166 / 300: loss 0.584854\n",
      "iteration 166 / 300: loss 0.599646\n",
      "iteration 166 / 300: loss 0.598902\n",
      "iteration 166 / 300: loss 0.614282\n",
      "iteration 166 / 300: loss 0.597796\n",
      "iteration 166 / 300: loss 0.599298\n",
      "iteration 166 / 300: loss 0.603317\n",
      "iteration 166 / 300: loss 0.592866\n",
      "iteration 166 / 300: loss 0.592391\n",
      "iteration 166 / 300: loss 0.589041\n",
      "iteration 166 / 300: loss 0.596446\n",
      "iteration 166 / 300: loss 0.605709\n",
      "iteration 166 / 300: loss 0.610562\n",
      "iteration 166 / 300: loss 0.587782\n",
      "iteration 166 / 300: loss 0.599351\n",
      "iteration 166 / 300: loss 0.602792\n",
      "iteration 166 / 300: loss 0.605028\n",
      "iteration 166 / 300: loss 0.603848\n",
      "iteration 166 / 300: loss 0.624144\n",
      "iteration 166 / 300: loss 0.587219\n",
      "iteration 166 / 300: loss 0.580754\n",
      "iteration 166 / 300: loss 0.625045\n",
      "iteration 166 / 300: loss 0.603310\n",
      "iteration 166 / 300: loss 0.604321\n",
      "iteration 166 / 300: loss 0.595476\n",
      "iteration 166 / 300: loss 0.597543\n",
      "iteration 166 / 300: loss 0.592740\n",
      "iteration 166 / 300: loss 0.589494\n",
      "iteration 166 / 300: loss 0.599264\n",
      "iteration 166 / 300: loss 0.611380\n",
      "iteration 166 / 300: loss 0.592463\n",
      "iteration 166 / 300: loss 0.599424\n",
      "iteration 166 / 300: loss 0.603100\n",
      "iteration 166 / 300: loss 0.602410\n",
      "iteration 166 / 300: loss 0.579811\n",
      "iteration 166 / 300: loss 0.601592\n",
      "iteration 167 / 300: loss 0.585528\n",
      "iteration 167 / 300: loss 0.588428\n",
      "iteration 167 / 300: loss 0.567516\n",
      "iteration 167 / 300: loss 0.592380\n",
      "iteration 167 / 300: loss 0.593618\n",
      "iteration 167 / 300: loss 0.595295\n",
      "iteration 167 / 300: loss 0.608784\n",
      "iteration 167 / 300: loss 0.592732\n",
      "iteration 167 / 300: loss 0.628060\n",
      "iteration 167 / 300: loss 0.580152\n",
      "iteration 167 / 300: loss 0.607923\n",
      "iteration 167 / 300: loss 0.587394\n",
      "iteration 167 / 300: loss 0.591686\n",
      "iteration 167 / 300: loss 0.571370\n",
      "iteration 167 / 300: loss 0.583025\n",
      "iteration 167 / 300: loss 0.608441\n",
      "iteration 167 / 300: loss 0.598359\n",
      "iteration 167 / 300: loss 0.583858\n",
      "iteration 167 / 300: loss 0.615253\n",
      "iteration 167 / 300: loss 0.591649\n",
      "iteration 167 / 300: loss 0.585499\n",
      "iteration 167 / 300: loss 0.591325\n",
      "iteration 167 / 300: loss 0.604341\n",
      "iteration 167 / 300: loss 0.595786\n",
      "iteration 167 / 300: loss 0.614949\n",
      "iteration 167 / 300: loss 0.608389\n",
      "iteration 167 / 300: loss 0.598222\n",
      "iteration 167 / 300: loss 0.588936\n",
      "iteration 167 / 300: loss 0.617757\n",
      "iteration 167 / 300: loss 0.594770\n",
      "iteration 167 / 300: loss 0.601684\n",
      "iteration 167 / 300: loss 0.631031\n",
      "iteration 167 / 300: loss 0.587513\n",
      "iteration 167 / 300: loss 0.606561\n",
      "iteration 167 / 300: loss 0.588034\n",
      "iteration 167 / 300: loss 0.600890\n",
      "iteration 167 / 300: loss 0.595958\n",
      "iteration 167 / 300: loss 0.589291\n",
      "iteration 167 / 300: loss 0.599526\n",
      "iteration 167 / 300: loss 0.604855\n",
      "iteration 167 / 300: loss 0.619414\n",
      "iteration 167 / 300: loss 0.588808\n",
      "iteration 167 / 300: loss 0.593645\n",
      "iteration 167 / 300: loss 0.585595\n",
      "iteration 167 / 300: loss 0.613213\n",
      "iteration 167 / 300: loss 0.587523\n",
      "iteration 167 / 300: loss 0.578328\n",
      "iteration 167 / 300: loss 0.567435\n",
      "iteration 167 / 300: loss 0.562235\n",
      "iteration 167 / 300: loss 0.594183\n",
      "iteration 167 / 300: loss 0.578821\n",
      "iteration 167 / 300: loss 0.586360\n",
      "iteration 167 / 300: loss 0.572890\n",
      "iteration 167 / 300: loss 0.596151\n",
      "iteration 167 / 300: loss 0.607951\n",
      "iteration 167 / 300: loss 0.610839\n",
      "iteration 167 / 300: loss 0.606266\n",
      "iteration 167 / 300: loss 0.583790\n",
      "iteration 167 / 300: loss 0.589627\n",
      "iteration 167 / 300: loss 0.595184\n",
      "iteration 167 / 300: loss 0.598955\n",
      "iteration 167 / 300: loss 0.596133\n",
      "iteration 167 / 300: loss 0.589769\n",
      "iteration 167 / 300: loss 0.591136\n",
      "iteration 167 / 300: loss 0.584854\n",
      "iteration 167 / 300: loss 0.599646\n",
      "iteration 167 / 300: loss 0.598902\n",
      "iteration 167 / 300: loss 0.614282\n",
      "iteration 167 / 300: loss 0.597796\n",
      "iteration 167 / 300: loss 0.599298\n",
      "iteration 167 / 300: loss 0.603317\n",
      "iteration 167 / 300: loss 0.592866\n",
      "iteration 167 / 300: loss 0.592391\n",
      "iteration 167 / 300: loss 0.589041\n",
      "iteration 167 / 300: loss 0.596446\n",
      "iteration 167 / 300: loss 0.605709\n",
      "iteration 167 / 300: loss 0.610562\n",
      "iteration 167 / 300: loss 0.587782\n",
      "iteration 167 / 300: loss 0.599351\n",
      "iteration 167 / 300: loss 0.602792\n",
      "iteration 167 / 300: loss 0.605028\n",
      "iteration 167 / 300: loss 0.603848\n",
      "iteration 167 / 300: loss 0.624144\n",
      "iteration 167 / 300: loss 0.587219\n",
      "iteration 167 / 300: loss 0.580754\n",
      "iteration 167 / 300: loss 0.625045\n",
      "iteration 167 / 300: loss 0.603310\n",
      "iteration 167 / 300: loss 0.604321\n",
      "iteration 167 / 300: loss 0.595476\n",
      "iteration 167 / 300: loss 0.597543\n",
      "iteration 167 / 300: loss 0.592740\n",
      "iteration 167 / 300: loss 0.589494\n",
      "iteration 167 / 300: loss 0.599264\n",
      "iteration 167 / 300: loss 0.611380\n",
      "iteration 167 / 300: loss 0.592463\n",
      "iteration 167 / 300: loss 0.599424\n",
      "iteration 167 / 300: loss 0.603100\n",
      "iteration 167 / 300: loss 0.602410\n",
      "iteration 167 / 300: loss 0.579811\n",
      "iteration 167 / 300: loss 0.601592\n",
      "iteration 168 / 300: loss 0.585528\n",
      "iteration 168 / 300: loss 0.588428\n",
      "iteration 168 / 300: loss 0.567516\n",
      "iteration 168 / 300: loss 0.592380\n",
      "iteration 168 / 300: loss 0.593618\n",
      "iteration 168 / 300: loss 0.595295\n",
      "iteration 168 / 300: loss 0.608784\n",
      "iteration 168 / 300: loss 0.592732\n",
      "iteration 168 / 300: loss 0.628060\n",
      "iteration 168 / 300: loss 0.580152\n",
      "iteration 168 / 300: loss 0.607923\n",
      "iteration 168 / 300: loss 0.587394\n",
      "iteration 168 / 300: loss 0.591686\n",
      "iteration 168 / 300: loss 0.571370\n",
      "iteration 168 / 300: loss 0.583025\n",
      "iteration 168 / 300: loss 0.608441\n",
      "iteration 168 / 300: loss 0.598359\n",
      "iteration 168 / 300: loss 0.583858\n",
      "iteration 168 / 300: loss 0.615253\n",
      "iteration 168 / 300: loss 0.591649\n",
      "iteration 168 / 300: loss 0.585499\n",
      "iteration 168 / 300: loss 0.591325\n",
      "iteration 168 / 300: loss 0.604341\n",
      "iteration 168 / 300: loss 0.595786\n",
      "iteration 168 / 300: loss 0.614949\n",
      "iteration 168 / 300: loss 0.608389\n",
      "iteration 168 / 300: loss 0.598222\n",
      "iteration 168 / 300: loss 0.588936\n",
      "iteration 168 / 300: loss 0.617757\n",
      "iteration 168 / 300: loss 0.594770\n",
      "iteration 168 / 300: loss 0.601684\n",
      "iteration 168 / 300: loss 0.631031\n",
      "iteration 168 / 300: loss 0.587513\n",
      "iteration 168 / 300: loss 0.606561\n",
      "iteration 168 / 300: loss 0.588034\n",
      "iteration 168 / 300: loss 0.600890\n",
      "iteration 168 / 300: loss 0.595958\n",
      "iteration 168 / 300: loss 0.589291\n",
      "iteration 168 / 300: loss 0.599526\n",
      "iteration 168 / 300: loss 0.604855\n",
      "iteration 168 / 300: loss 0.619414\n",
      "iteration 168 / 300: loss 0.588808\n",
      "iteration 168 / 300: loss 0.593645\n",
      "iteration 168 / 300: loss 0.585595\n",
      "iteration 168 / 300: loss 0.613213\n",
      "iteration 168 / 300: loss 0.587523\n",
      "iteration 168 / 300: loss 0.578328\n",
      "iteration 168 / 300: loss 0.567435\n",
      "iteration 168 / 300: loss 0.562235\n",
      "iteration 168 / 300: loss 0.594183\n",
      "iteration 168 / 300: loss 0.578821\n",
      "iteration 168 / 300: loss 0.586360\n",
      "iteration 168 / 300: loss 0.572890\n",
      "iteration 168 / 300: loss 0.596151\n",
      "iteration 168 / 300: loss 0.607951\n",
      "iteration 168 / 300: loss 0.610839\n",
      "iteration 168 / 300: loss 0.606266\n",
      "iteration 168 / 300: loss 0.583790\n",
      "iteration 168 / 300: loss 0.589627\n",
      "iteration 168 / 300: loss 0.595184\n",
      "iteration 168 / 300: loss 0.598955\n",
      "iteration 168 / 300: loss 0.596133\n",
      "iteration 168 / 300: loss 0.589769\n",
      "iteration 168 / 300: loss 0.591136\n",
      "iteration 168 / 300: loss 0.584854\n",
      "iteration 168 / 300: loss 0.599646\n",
      "iteration 168 / 300: loss 0.598902\n",
      "iteration 168 / 300: loss 0.614282\n",
      "iteration 168 / 300: loss 0.597796\n",
      "iteration 168 / 300: loss 0.599298\n",
      "iteration 168 / 300: loss 0.603317\n",
      "iteration 168 / 300: loss 0.592865\n",
      "iteration 168 / 300: loss 0.592391\n",
      "iteration 168 / 300: loss 0.589041\n",
      "iteration 168 / 300: loss 0.596446\n",
      "iteration 168 / 300: loss 0.605709\n",
      "iteration 168 / 300: loss 0.610562\n",
      "iteration 168 / 300: loss 0.587782\n",
      "iteration 168 / 300: loss 0.599351\n",
      "iteration 168 / 300: loss 0.602792\n",
      "iteration 168 / 300: loss 0.605028\n",
      "iteration 168 / 300: loss 0.603848\n",
      "iteration 168 / 300: loss 0.624144\n",
      "iteration 168 / 300: loss 0.587219\n",
      "iteration 168 / 300: loss 0.580754\n",
      "iteration 168 / 300: loss 0.625045\n",
      "iteration 168 / 300: loss 0.603310\n",
      "iteration 168 / 300: loss 0.604321\n",
      "iteration 168 / 300: loss 0.595476\n",
      "iteration 168 / 300: loss 0.597543\n",
      "iteration 168 / 300: loss 0.592740\n",
      "iteration 168 / 300: loss 0.589494\n",
      "iteration 168 / 300: loss 0.599264\n",
      "iteration 168 / 300: loss 0.611380\n",
      "iteration 168 / 300: loss 0.592463\n",
      "iteration 168 / 300: loss 0.599424\n",
      "iteration 168 / 300: loss 0.603100\n",
      "iteration 168 / 300: loss 0.602410\n",
      "iteration 168 / 300: loss 0.579811\n",
      "iteration 168 / 300: loss 0.601592\n",
      "iteration 169 / 300: loss 0.585528\n",
      "iteration 169 / 300: loss 0.588428\n",
      "iteration 169 / 300: loss 0.567516\n",
      "iteration 169 / 300: loss 0.592380\n",
      "iteration 169 / 300: loss 0.593618\n",
      "iteration 169 / 300: loss 0.595295\n",
      "iteration 169 / 300: loss 0.608784\n",
      "iteration 169 / 300: loss 0.592732\n",
      "iteration 169 / 300: loss 0.628060\n",
      "iteration 169 / 300: loss 0.580152\n",
      "iteration 169 / 300: loss 0.607923\n",
      "iteration 169 / 300: loss 0.587394\n",
      "iteration 169 / 300: loss 0.591686\n",
      "iteration 169 / 300: loss 0.571370\n",
      "iteration 169 / 300: loss 0.583025\n",
      "iteration 169 / 300: loss 0.608441\n",
      "iteration 169 / 300: loss 0.598359\n",
      "iteration 169 / 300: loss 0.583858\n",
      "iteration 169 / 300: loss 0.615253\n",
      "iteration 169 / 300: loss 0.591649\n",
      "iteration 169 / 300: loss 0.585499\n",
      "iteration 169 / 300: loss 0.591325\n",
      "iteration 169 / 300: loss 0.604341\n",
      "iteration 169 / 300: loss 0.595786\n",
      "iteration 169 / 300: loss 0.614949\n",
      "iteration 169 / 300: loss 0.608389\n",
      "iteration 169 / 300: loss 0.598222\n",
      "iteration 169 / 300: loss 0.588936\n",
      "iteration 169 / 300: loss 0.617757\n",
      "iteration 169 / 300: loss 0.594770\n",
      "iteration 169 / 300: loss 0.601684\n",
      "iteration 169 / 300: loss 0.631031\n",
      "iteration 169 / 300: loss 0.587513\n",
      "iteration 169 / 300: loss 0.606561\n",
      "iteration 169 / 300: loss 0.588034\n",
      "iteration 169 / 300: loss 0.600890\n",
      "iteration 169 / 300: loss 0.595958\n",
      "iteration 169 / 300: loss 0.589291\n",
      "iteration 169 / 300: loss 0.599526\n",
      "iteration 169 / 300: loss 0.604855\n",
      "iteration 169 / 300: loss 0.619414\n",
      "iteration 169 / 300: loss 0.588808\n",
      "iteration 169 / 300: loss 0.593645\n",
      "iteration 169 / 300: loss 0.585595\n",
      "iteration 169 / 300: loss 0.613213\n",
      "iteration 169 / 300: loss 0.587523\n",
      "iteration 169 / 300: loss 0.578328\n",
      "iteration 169 / 300: loss 0.567435\n",
      "iteration 169 / 300: loss 0.562235\n",
      "iteration 169 / 300: loss 0.594183\n",
      "iteration 169 / 300: loss 0.578821\n",
      "iteration 169 / 300: loss 0.586360\n",
      "iteration 169 / 300: loss 0.572890\n",
      "iteration 169 / 300: loss 0.596151\n",
      "iteration 169 / 300: loss 0.607951\n",
      "iteration 169 / 300: loss 0.610839\n",
      "iteration 169 / 300: loss 0.606266\n",
      "iteration 169 / 300: loss 0.583790\n",
      "iteration 169 / 300: loss 0.589627\n",
      "iteration 169 / 300: loss 0.595184\n",
      "iteration 169 / 300: loss 0.598955\n",
      "iteration 169 / 300: loss 0.596133\n",
      "iteration 169 / 300: loss 0.589769\n",
      "iteration 169 / 300: loss 0.591136\n",
      "iteration 169 / 300: loss 0.584854\n",
      "iteration 169 / 300: loss 0.599646\n",
      "iteration 169 / 300: loss 0.598902\n",
      "iteration 169 / 300: loss 0.614282\n",
      "iteration 169 / 300: loss 0.597796\n",
      "iteration 169 / 300: loss 0.599298\n",
      "iteration 169 / 300: loss 0.603317\n",
      "iteration 169 / 300: loss 0.592865\n",
      "iteration 169 / 300: loss 0.592391\n",
      "iteration 169 / 300: loss 0.589041\n",
      "iteration 169 / 300: loss 0.596446\n",
      "iteration 169 / 300: loss 0.605709\n",
      "iteration 169 / 300: loss 0.610562\n",
      "iteration 169 / 300: loss 0.587782\n",
      "iteration 169 / 300: loss 0.599351\n",
      "iteration 169 / 300: loss 0.602792\n",
      "iteration 169 / 300: loss 0.605028\n",
      "iteration 169 / 300: loss 0.603848\n",
      "iteration 169 / 300: loss 0.624144\n",
      "iteration 169 / 300: loss 0.587219\n",
      "iteration 169 / 300: loss 0.580754\n",
      "iteration 169 / 300: loss 0.625045\n",
      "iteration 169 / 300: loss 0.603310\n",
      "iteration 169 / 300: loss 0.604321\n",
      "iteration 169 / 300: loss 0.595476\n",
      "iteration 169 / 300: loss 0.597543\n",
      "iteration 169 / 300: loss 0.592740\n",
      "iteration 169 / 300: loss 0.589494\n",
      "iteration 169 / 300: loss 0.599264\n",
      "iteration 169 / 300: loss 0.611380\n",
      "iteration 169 / 300: loss 0.592463\n",
      "iteration 169 / 300: loss 0.599424\n",
      "iteration 169 / 300: loss 0.603100\n",
      "iteration 169 / 300: loss 0.602410\n",
      "iteration 169 / 300: loss 0.579811\n",
      "iteration 169 / 300: loss 0.601592\n",
      "iteration 170 / 300: loss 0.585528\n",
      "iteration 170 / 300: loss 0.588428\n",
      "iteration 170 / 300: loss 0.567516\n",
      "iteration 170 / 300: loss 0.592380\n",
      "iteration 170 / 300: loss 0.593618\n",
      "iteration 170 / 300: loss 0.595295\n",
      "iteration 170 / 300: loss 0.608784\n",
      "iteration 170 / 300: loss 0.592732\n",
      "iteration 170 / 300: loss 0.628060\n",
      "iteration 170 / 300: loss 0.580152\n",
      "iteration 170 / 300: loss 0.607923\n",
      "iteration 170 / 300: loss 0.587394\n",
      "iteration 170 / 300: loss 0.591686\n",
      "iteration 170 / 300: loss 0.571370\n",
      "iteration 170 / 300: loss 0.583025\n",
      "iteration 170 / 300: loss 0.608441\n",
      "iteration 170 / 300: loss 0.598359\n",
      "iteration 170 / 300: loss 0.583858\n",
      "iteration 170 / 300: loss 0.615253\n",
      "iteration 170 / 300: loss 0.591649\n",
      "iteration 170 / 300: loss 0.585499\n",
      "iteration 170 / 300: loss 0.591325\n",
      "iteration 170 / 300: loss 0.604341\n",
      "iteration 170 / 300: loss 0.595786\n",
      "iteration 170 / 300: loss 0.614949\n",
      "iteration 170 / 300: loss 0.608389\n",
      "iteration 170 / 300: loss 0.598222\n",
      "iteration 170 / 300: loss 0.588936\n",
      "iteration 170 / 300: loss 0.617757\n",
      "iteration 170 / 300: loss 0.594770\n",
      "iteration 170 / 300: loss 0.601684\n",
      "iteration 170 / 300: loss 0.631031\n",
      "iteration 170 / 300: loss 0.587513\n",
      "iteration 170 / 300: loss 0.606561\n",
      "iteration 170 / 300: loss 0.588034\n",
      "iteration 170 / 300: loss 0.600890\n",
      "iteration 170 / 300: loss 0.595958\n",
      "iteration 170 / 300: loss 0.589291\n",
      "iteration 170 / 300: loss 0.599526\n",
      "iteration 170 / 300: loss 0.604855\n",
      "iteration 170 / 300: loss 0.619414\n",
      "iteration 170 / 300: loss 0.588808\n",
      "iteration 170 / 300: loss 0.593645\n",
      "iteration 170 / 300: loss 0.585595\n",
      "iteration 170 / 300: loss 0.613213\n",
      "iteration 170 / 300: loss 0.587523\n",
      "iteration 170 / 300: loss 0.578328\n",
      "iteration 170 / 300: loss 0.567435\n",
      "iteration 170 / 300: loss 0.562235\n",
      "iteration 170 / 300: loss 0.594183\n",
      "iteration 170 / 300: loss 0.578821\n",
      "iteration 170 / 300: loss 0.586360\n",
      "iteration 170 / 300: loss 0.572890\n",
      "iteration 170 / 300: loss 0.596151\n",
      "iteration 170 / 300: loss 0.607951\n",
      "iteration 170 / 300: loss 0.610839\n",
      "iteration 170 / 300: loss 0.606265\n",
      "iteration 170 / 300: loss 0.583790\n",
      "iteration 170 / 300: loss 0.589627\n",
      "iteration 170 / 300: loss 0.595184\n",
      "iteration 170 / 300: loss 0.598955\n",
      "iteration 170 / 300: loss 0.596133\n",
      "iteration 170 / 300: loss 0.589769\n",
      "iteration 170 / 300: loss 0.591136\n",
      "iteration 170 / 300: loss 0.584854\n",
      "iteration 170 / 300: loss 0.599646\n",
      "iteration 170 / 300: loss 0.598902\n",
      "iteration 170 / 300: loss 0.614282\n",
      "iteration 170 / 300: loss 0.597796\n",
      "iteration 170 / 300: loss 0.599298\n",
      "iteration 170 / 300: loss 0.603317\n",
      "iteration 170 / 300: loss 0.592865\n",
      "iteration 170 / 300: loss 0.592391\n",
      "iteration 170 / 300: loss 0.589041\n",
      "iteration 170 / 300: loss 0.596446\n",
      "iteration 170 / 300: loss 0.605709\n",
      "iteration 170 / 300: loss 0.610562\n",
      "iteration 170 / 300: loss 0.587782\n",
      "iteration 170 / 300: loss 0.599351\n",
      "iteration 170 / 300: loss 0.602792\n",
      "iteration 170 / 300: loss 0.605028\n",
      "iteration 170 / 300: loss 0.603848\n",
      "iteration 170 / 300: loss 0.624144\n",
      "iteration 170 / 300: loss 0.587219\n",
      "iteration 170 / 300: loss 0.580754\n",
      "iteration 170 / 300: loss 0.625045\n",
      "iteration 170 / 300: loss 0.603310\n",
      "iteration 170 / 300: loss 0.604321\n",
      "iteration 170 / 300: loss 0.595476\n",
      "iteration 170 / 300: loss 0.597543\n",
      "iteration 170 / 300: loss 0.592740\n",
      "iteration 170 / 300: loss 0.589494\n",
      "iteration 170 / 300: loss 0.599264\n",
      "iteration 170 / 300: loss 0.611380\n",
      "iteration 170 / 300: loss 0.592463\n",
      "iteration 170 / 300: loss 0.599424\n",
      "iteration 170 / 300: loss 0.603100\n",
      "iteration 170 / 300: loss 0.602410\n",
      "iteration 170 / 300: loss 0.579811\n",
      "iteration 170 / 300: loss 0.601592\n",
      "iteration 171 / 300: loss 0.585528\n",
      "iteration 171 / 300: loss 0.588428\n",
      "iteration 171 / 300: loss 0.567516\n",
      "iteration 171 / 300: loss 0.592380\n",
      "iteration 171 / 300: loss 0.593618\n",
      "iteration 171 / 300: loss 0.595295\n",
      "iteration 171 / 300: loss 0.608784\n",
      "iteration 171 / 300: loss 0.592732\n",
      "iteration 171 / 300: loss 0.628060\n",
      "iteration 171 / 300: loss 0.580152\n",
      "iteration 171 / 300: loss 0.607923\n",
      "iteration 171 / 300: loss 0.587394\n",
      "iteration 171 / 300: loss 0.591686\n",
      "iteration 171 / 300: loss 0.571370\n",
      "iteration 171 / 300: loss 0.583025\n",
      "iteration 171 / 300: loss 0.608441\n",
      "iteration 171 / 300: loss 0.598359\n",
      "iteration 171 / 300: loss 0.583858\n",
      "iteration 171 / 300: loss 0.615253\n",
      "iteration 171 / 300: loss 0.591649\n",
      "iteration 171 / 300: loss 0.585499\n",
      "iteration 171 / 300: loss 0.591325\n",
      "iteration 171 / 300: loss 0.604341\n",
      "iteration 171 / 300: loss 0.595786\n",
      "iteration 171 / 300: loss 0.614949\n",
      "iteration 171 / 300: loss 0.608389\n",
      "iteration 171 / 300: loss 0.598222\n",
      "iteration 171 / 300: loss 0.588936\n",
      "iteration 171 / 300: loss 0.617757\n",
      "iteration 171 / 300: loss 0.594770\n",
      "iteration 171 / 300: loss 0.601684\n",
      "iteration 171 / 300: loss 0.631031\n",
      "iteration 171 / 300: loss 0.587513\n",
      "iteration 171 / 300: loss 0.606561\n",
      "iteration 171 / 300: loss 0.588034\n",
      "iteration 171 / 300: loss 0.600890\n",
      "iteration 171 / 300: loss 0.595958\n",
      "iteration 171 / 300: loss 0.589291\n",
      "iteration 171 / 300: loss 0.599526\n",
      "iteration 171 / 300: loss 0.604855\n",
      "iteration 171 / 300: loss 0.619414\n",
      "iteration 171 / 300: loss 0.588808\n",
      "iteration 171 / 300: loss 0.593645\n",
      "iteration 171 / 300: loss 0.585595\n",
      "iteration 171 / 300: loss 0.613213\n",
      "iteration 171 / 300: loss 0.587523\n",
      "iteration 171 / 300: loss 0.578328\n",
      "iteration 171 / 300: loss 0.567435\n",
      "iteration 171 / 300: loss 0.562235\n",
      "iteration 171 / 300: loss 0.594183\n",
      "iteration 171 / 300: loss 0.578821\n",
      "iteration 171 / 300: loss 0.586360\n",
      "iteration 171 / 300: loss 0.572890\n",
      "iteration 171 / 300: loss 0.596151\n",
      "iteration 171 / 300: loss 0.607951\n",
      "iteration 171 / 300: loss 0.610839\n",
      "iteration 171 / 300: loss 0.606265\n",
      "iteration 171 / 300: loss 0.583790\n",
      "iteration 171 / 300: loss 0.589627\n",
      "iteration 171 / 300: loss 0.595184\n",
      "iteration 171 / 300: loss 0.598955\n",
      "iteration 171 / 300: loss 0.596133\n",
      "iteration 171 / 300: loss 0.589769\n",
      "iteration 171 / 300: loss 0.591136\n",
      "iteration 171 / 300: loss 0.584854\n",
      "iteration 171 / 300: loss 0.599646\n",
      "iteration 171 / 300: loss 0.598902\n",
      "iteration 171 / 300: loss 0.614282\n",
      "iteration 171 / 300: loss 0.597796\n",
      "iteration 171 / 300: loss 0.599298\n",
      "iteration 171 / 300: loss 0.603317\n",
      "iteration 171 / 300: loss 0.592865\n",
      "iteration 171 / 300: loss 0.592391\n",
      "iteration 171 / 300: loss 0.589041\n",
      "iteration 171 / 300: loss 0.596446\n",
      "iteration 171 / 300: loss 0.605709\n",
      "iteration 171 / 300: loss 0.610562\n",
      "iteration 171 / 300: loss 0.587782\n",
      "iteration 171 / 300: loss 0.599351\n",
      "iteration 171 / 300: loss 0.602792\n",
      "iteration 171 / 300: loss 0.605028\n",
      "iteration 171 / 300: loss 0.603848\n",
      "iteration 171 / 300: loss 0.624144\n",
      "iteration 171 / 300: loss 0.587219\n",
      "iteration 171 / 300: loss 0.580754\n",
      "iteration 171 / 300: loss 0.625045\n",
      "iteration 171 / 300: loss 0.603310\n",
      "iteration 171 / 300: loss 0.604321\n",
      "iteration 171 / 300: loss 0.595476\n",
      "iteration 171 / 300: loss 0.597543\n",
      "iteration 171 / 300: loss 0.592740\n",
      "iteration 171 / 300: loss 0.589494\n",
      "iteration 171 / 300: loss 0.599264\n",
      "iteration 171 / 300: loss 0.611380\n",
      "iteration 171 / 300: loss 0.592463\n",
      "iteration 171 / 300: loss 0.599424\n",
      "iteration 171 / 300: loss 0.603100\n",
      "iteration 171 / 300: loss 0.602410\n",
      "iteration 171 / 300: loss 0.579811\n",
      "iteration 171 / 300: loss 0.601592\n",
      "iteration 172 / 300: loss 0.585528\n",
      "iteration 172 / 300: loss 0.588428\n",
      "iteration 172 / 300: loss 0.567516\n",
      "iteration 172 / 300: loss 0.592380\n",
      "iteration 172 / 300: loss 0.593618\n",
      "iteration 172 / 300: loss 0.595295\n",
      "iteration 172 / 300: loss 0.608784\n",
      "iteration 172 / 300: loss 0.592732\n",
      "iteration 172 / 300: loss 0.628060\n",
      "iteration 172 / 300: loss 0.580152\n",
      "iteration 172 / 300: loss 0.607923\n",
      "iteration 172 / 300: loss 0.587394\n",
      "iteration 172 / 300: loss 0.591686\n",
      "iteration 172 / 300: loss 0.571370\n",
      "iteration 172 / 300: loss 0.583025\n",
      "iteration 172 / 300: loss 0.608441\n",
      "iteration 172 / 300: loss 0.598359\n",
      "iteration 172 / 300: loss 0.583858\n",
      "iteration 172 / 300: loss 0.615253\n",
      "iteration 172 / 300: loss 0.591649\n",
      "iteration 172 / 300: loss 0.585499\n",
      "iteration 172 / 300: loss 0.591325\n",
      "iteration 172 / 300: loss 0.604341\n",
      "iteration 172 / 300: loss 0.595786\n",
      "iteration 172 / 300: loss 0.614949\n",
      "iteration 172 / 300: loss 0.608389\n",
      "iteration 172 / 300: loss 0.598222\n",
      "iteration 172 / 300: loss 0.588936\n",
      "iteration 172 / 300: loss 0.617757\n",
      "iteration 172 / 300: loss 0.594770\n",
      "iteration 172 / 300: loss 0.601684\n",
      "iteration 172 / 300: loss 0.631031\n",
      "iteration 172 / 300: loss 0.587513\n",
      "iteration 172 / 300: loss 0.606561\n",
      "iteration 172 / 300: loss 0.588034\n",
      "iteration 172 / 300: loss 0.600890\n",
      "iteration 172 / 300: loss 0.595958\n",
      "iteration 172 / 300: loss 0.589291\n",
      "iteration 172 / 300: loss 0.599526\n",
      "iteration 172 / 300: loss 0.604855\n",
      "iteration 172 / 300: loss 0.619414\n",
      "iteration 172 / 300: loss 0.588808\n",
      "iteration 172 / 300: loss 0.593645\n",
      "iteration 172 / 300: loss 0.585595\n",
      "iteration 172 / 300: loss 0.613213\n",
      "iteration 172 / 300: loss 0.587523\n",
      "iteration 172 / 300: loss 0.578328\n",
      "iteration 172 / 300: loss 0.567435\n",
      "iteration 172 / 300: loss 0.562235\n",
      "iteration 172 / 300: loss 0.594183\n",
      "iteration 172 / 300: loss 0.578821\n",
      "iteration 172 / 300: loss 0.586360\n",
      "iteration 172 / 300: loss 0.572890\n",
      "iteration 172 / 300: loss 0.596151\n",
      "iteration 172 / 300: loss 0.607951\n",
      "iteration 172 / 300: loss 0.610839\n",
      "iteration 172 / 300: loss 0.606265\n",
      "iteration 172 / 300: loss 0.583790\n",
      "iteration 172 / 300: loss 0.589627\n",
      "iteration 172 / 300: loss 0.595184\n",
      "iteration 172 / 300: loss 0.598955\n",
      "iteration 172 / 300: loss 0.596133\n",
      "iteration 172 / 300: loss 0.589769\n",
      "iteration 172 / 300: loss 0.591136\n",
      "iteration 172 / 300: loss 0.584854\n",
      "iteration 172 / 300: loss 0.599646\n",
      "iteration 172 / 300: loss 0.598902\n",
      "iteration 172 / 300: loss 0.614282\n",
      "iteration 172 / 300: loss 0.597796\n",
      "iteration 172 / 300: loss 0.599298\n",
      "iteration 172 / 300: loss 0.603317\n",
      "iteration 172 / 300: loss 0.592865\n",
      "iteration 172 / 300: loss 0.592391\n",
      "iteration 172 / 300: loss 0.589041\n",
      "iteration 172 / 300: loss 0.596446\n",
      "iteration 172 / 300: loss 0.605709\n",
      "iteration 172 / 300: loss 0.610562\n",
      "iteration 172 / 300: loss 0.587782\n",
      "iteration 172 / 300: loss 0.599351\n",
      "iteration 172 / 300: loss 0.602792\n",
      "iteration 172 / 300: loss 0.605028\n",
      "iteration 172 / 300: loss 0.603848\n",
      "iteration 172 / 300: loss 0.624144\n",
      "iteration 172 / 300: loss 0.587219\n",
      "iteration 172 / 300: loss 0.580754\n",
      "iteration 172 / 300: loss 0.625045\n",
      "iteration 172 / 300: loss 0.603310\n",
      "iteration 172 / 300: loss 0.604321\n",
      "iteration 172 / 300: loss 0.595476\n",
      "iteration 172 / 300: loss 0.597543\n",
      "iteration 172 / 300: loss 0.592740\n",
      "iteration 172 / 300: loss 0.589494\n",
      "iteration 172 / 300: loss 0.599264\n",
      "iteration 172 / 300: loss 0.611380\n",
      "iteration 172 / 300: loss 0.592463\n",
      "iteration 172 / 300: loss 0.599424\n",
      "iteration 172 / 300: loss 0.603100\n",
      "iteration 172 / 300: loss 0.602410\n",
      "iteration 172 / 300: loss 0.579811\n",
      "iteration 172 / 300: loss 0.601592\n",
      "iteration 173 / 300: loss 0.585528\n",
      "iteration 173 / 300: loss 0.588428\n",
      "iteration 173 / 300: loss 0.567516\n",
      "iteration 173 / 300: loss 0.592380\n",
      "iteration 173 / 300: loss 0.593618\n",
      "iteration 173 / 300: loss 0.595295\n",
      "iteration 173 / 300: loss 0.608784\n",
      "iteration 173 / 300: loss 0.592732\n",
      "iteration 173 / 300: loss 0.628060\n",
      "iteration 173 / 300: loss 0.580152\n",
      "iteration 173 / 300: loss 0.607923\n",
      "iteration 173 / 300: loss 0.587394\n",
      "iteration 173 / 300: loss 0.591686\n",
      "iteration 173 / 300: loss 0.571370\n",
      "iteration 173 / 300: loss 0.583025\n",
      "iteration 173 / 300: loss 0.608441\n",
      "iteration 173 / 300: loss 0.598359\n",
      "iteration 173 / 300: loss 0.583858\n",
      "iteration 173 / 300: loss 0.615253\n",
      "iteration 173 / 300: loss 0.591649\n",
      "iteration 173 / 300: loss 0.585499\n",
      "iteration 173 / 300: loss 0.591325\n",
      "iteration 173 / 300: loss 0.604341\n",
      "iteration 173 / 300: loss 0.595786\n",
      "iteration 173 / 300: loss 0.614949\n",
      "iteration 173 / 300: loss 0.608389\n",
      "iteration 173 / 300: loss 0.598222\n",
      "iteration 173 / 300: loss 0.588936\n",
      "iteration 173 / 300: loss 0.617757\n",
      "iteration 173 / 300: loss 0.594770\n",
      "iteration 173 / 300: loss 0.601684\n",
      "iteration 173 / 300: loss 0.631031\n",
      "iteration 173 / 300: loss 0.587513\n",
      "iteration 173 / 300: loss 0.606561\n",
      "iteration 173 / 300: loss 0.588034\n",
      "iteration 173 / 300: loss 0.600890\n",
      "iteration 173 / 300: loss 0.595958\n",
      "iteration 173 / 300: loss 0.589291\n",
      "iteration 173 / 300: loss 0.599526\n",
      "iteration 173 / 300: loss 0.604855\n",
      "iteration 173 / 300: loss 0.619414\n",
      "iteration 173 / 300: loss 0.588808\n",
      "iteration 173 / 300: loss 0.593645\n",
      "iteration 173 / 300: loss 0.585595\n",
      "iteration 173 / 300: loss 0.613213\n",
      "iteration 173 / 300: loss 0.587523\n",
      "iteration 173 / 300: loss 0.578328\n",
      "iteration 173 / 300: loss 0.567435\n",
      "iteration 173 / 300: loss 0.562235\n",
      "iteration 173 / 300: loss 0.594183\n",
      "iteration 173 / 300: loss 0.578821\n",
      "iteration 173 / 300: loss 0.586360\n",
      "iteration 173 / 300: loss 0.572890\n",
      "iteration 173 / 300: loss 0.596151\n",
      "iteration 173 / 300: loss 0.607951\n",
      "iteration 173 / 300: loss 0.610839\n",
      "iteration 173 / 300: loss 0.606265\n",
      "iteration 173 / 300: loss 0.583790\n",
      "iteration 173 / 300: loss 0.589627\n",
      "iteration 173 / 300: loss 0.595184\n",
      "iteration 173 / 300: loss 0.598955\n",
      "iteration 173 / 300: loss 0.596133\n",
      "iteration 173 / 300: loss 0.589769\n",
      "iteration 173 / 300: loss 0.591136\n",
      "iteration 173 / 300: loss 0.584854\n",
      "iteration 173 / 300: loss 0.599646\n",
      "iteration 173 / 300: loss 0.598902\n",
      "iteration 173 / 300: loss 0.614282\n",
      "iteration 173 / 300: loss 0.597796\n",
      "iteration 173 / 300: loss 0.599298\n",
      "iteration 173 / 300: loss 0.603317\n",
      "iteration 173 / 300: loss 0.592865\n",
      "iteration 173 / 300: loss 0.592391\n",
      "iteration 173 / 300: loss 0.589041\n",
      "iteration 173 / 300: loss 0.596446\n",
      "iteration 173 / 300: loss 0.605709\n",
      "iteration 173 / 300: loss 0.610562\n",
      "iteration 173 / 300: loss 0.587782\n",
      "iteration 173 / 300: loss 0.599351\n",
      "iteration 173 / 300: loss 0.602792\n",
      "iteration 173 / 300: loss 0.605028\n",
      "iteration 173 / 300: loss 0.603848\n",
      "iteration 173 / 300: loss 0.624144\n",
      "iteration 173 / 300: loss 0.587219\n",
      "iteration 173 / 300: loss 0.580754\n",
      "iteration 173 / 300: loss 0.625045\n",
      "iteration 173 / 300: loss 0.603310\n",
      "iteration 173 / 300: loss 0.604321\n",
      "iteration 173 / 300: loss 0.595476\n",
      "iteration 173 / 300: loss 0.597543\n",
      "iteration 173 / 300: loss 0.592740\n",
      "iteration 173 / 300: loss 0.589494\n",
      "iteration 173 / 300: loss 0.599264\n",
      "iteration 173 / 300: loss 0.611380\n",
      "iteration 173 / 300: loss 0.592463\n",
      "iteration 173 / 300: loss 0.599424\n",
      "iteration 173 / 300: loss 0.603100\n",
      "iteration 173 / 300: loss 0.602410\n",
      "iteration 173 / 300: loss 0.579811\n",
      "iteration 173 / 300: loss 0.601592\n",
      "iteration 174 / 300: loss 0.585528\n",
      "iteration 174 / 300: loss 0.588428\n",
      "iteration 174 / 300: loss 0.567516\n",
      "iteration 174 / 300: loss 0.592380\n",
      "iteration 174 / 300: loss 0.593618\n",
      "iteration 174 / 300: loss 0.595295\n",
      "iteration 174 / 300: loss 0.608784\n",
      "iteration 174 / 300: loss 0.592732\n",
      "iteration 174 / 300: loss 0.628060\n",
      "iteration 174 / 300: loss 0.580152\n",
      "iteration 174 / 300: loss 0.607923\n",
      "iteration 174 / 300: loss 0.587394\n",
      "iteration 174 / 300: loss 0.591686\n",
      "iteration 174 / 300: loss 0.571370\n",
      "iteration 174 / 300: loss 0.583025\n",
      "iteration 174 / 300: loss 0.608441\n",
      "iteration 174 / 300: loss 0.598359\n",
      "iteration 174 / 300: loss 0.583858\n",
      "iteration 174 / 300: loss 0.615253\n",
      "iteration 174 / 300: loss 0.591649\n",
      "iteration 174 / 300: loss 0.585499\n",
      "iteration 174 / 300: loss 0.591325\n",
      "iteration 174 / 300: loss 0.604341\n",
      "iteration 174 / 300: loss 0.595786\n",
      "iteration 174 / 300: loss 0.614949\n",
      "iteration 174 / 300: loss 0.608389\n",
      "iteration 174 / 300: loss 0.598222\n",
      "iteration 174 / 300: loss 0.588936\n",
      "iteration 174 / 300: loss 0.617757\n",
      "iteration 174 / 300: loss 0.594770\n",
      "iteration 174 / 300: loss 0.601684\n",
      "iteration 174 / 300: loss 0.631031\n",
      "iteration 174 / 300: loss 0.587513\n",
      "iteration 174 / 300: loss 0.606561\n",
      "iteration 174 / 300: loss 0.588034\n",
      "iteration 174 / 300: loss 0.600890\n",
      "iteration 174 / 300: loss 0.595958\n",
      "iteration 174 / 300: loss 0.589291\n",
      "iteration 174 / 300: loss 0.599526\n",
      "iteration 174 / 300: loss 0.604855\n",
      "iteration 174 / 300: loss 0.619414\n",
      "iteration 174 / 300: loss 0.588808\n",
      "iteration 174 / 300: loss 0.593645\n",
      "iteration 174 / 300: loss 0.585595\n",
      "iteration 174 / 300: loss 0.613213\n",
      "iteration 174 / 300: loss 0.587523\n",
      "iteration 174 / 300: loss 0.578328\n",
      "iteration 174 / 300: loss 0.567435\n",
      "iteration 174 / 300: loss 0.562235\n",
      "iteration 174 / 300: loss 0.594183\n",
      "iteration 174 / 300: loss 0.578821\n",
      "iteration 174 / 300: loss 0.586360\n",
      "iteration 174 / 300: loss 0.572890\n",
      "iteration 174 / 300: loss 0.596151\n",
      "iteration 174 / 300: loss 0.607951\n",
      "iteration 174 / 300: loss 0.610839\n",
      "iteration 174 / 300: loss 0.606265\n",
      "iteration 174 / 300: loss 0.583790\n",
      "iteration 174 / 300: loss 0.589627\n",
      "iteration 174 / 300: loss 0.595184\n",
      "iteration 174 / 300: loss 0.598955\n",
      "iteration 174 / 300: loss 0.596133\n",
      "iteration 174 / 300: loss 0.589769\n",
      "iteration 174 / 300: loss 0.591136\n",
      "iteration 174 / 300: loss 0.584854\n",
      "iteration 174 / 300: loss 0.599646\n",
      "iteration 174 / 300: loss 0.598902\n",
      "iteration 174 / 300: loss 0.614282\n",
      "iteration 174 / 300: loss 0.597796\n",
      "iteration 174 / 300: loss 0.599298\n",
      "iteration 174 / 300: loss 0.603317\n",
      "iteration 174 / 300: loss 0.592865\n",
      "iteration 174 / 300: loss 0.592391\n",
      "iteration 174 / 300: loss 0.589041\n",
      "iteration 174 / 300: loss 0.596446\n",
      "iteration 174 / 300: loss 0.605709\n",
      "iteration 174 / 300: loss 0.610562\n",
      "iteration 174 / 300: loss 0.587782\n",
      "iteration 174 / 300: loss 0.599351\n",
      "iteration 174 / 300: loss 0.602792\n",
      "iteration 174 / 300: loss 0.605028\n",
      "iteration 174 / 300: loss 0.603848\n",
      "iteration 174 / 300: loss 0.624144\n",
      "iteration 174 / 300: loss 0.587219\n",
      "iteration 174 / 300: loss 0.580754\n",
      "iteration 174 / 300: loss 0.625045\n",
      "iteration 174 / 300: loss 0.603310\n",
      "iteration 174 / 300: loss 0.604321\n",
      "iteration 174 / 300: loss 0.595476\n",
      "iteration 174 / 300: loss 0.597543\n",
      "iteration 174 / 300: loss 0.592740\n",
      "iteration 174 / 300: loss 0.589494\n",
      "iteration 174 / 300: loss 0.599264\n",
      "iteration 174 / 300: loss 0.611380\n",
      "iteration 174 / 300: loss 0.592463\n",
      "iteration 174 / 300: loss 0.599424\n",
      "iteration 174 / 300: loss 0.603100\n",
      "iteration 174 / 300: loss 0.602410\n",
      "iteration 174 / 300: loss 0.579811\n",
      "iteration 174 / 300: loss 0.601592\n",
      "iteration 175 / 300: loss 0.585528\n",
      "iteration 175 / 300: loss 0.588428\n",
      "iteration 175 / 300: loss 0.567516\n",
      "iteration 175 / 300: loss 0.592380\n",
      "iteration 175 / 300: loss 0.593618\n",
      "iteration 175 / 300: loss 0.595295\n",
      "iteration 175 / 300: loss 0.608784\n",
      "iteration 175 / 300: loss 0.592732\n",
      "iteration 175 / 300: loss 0.628060\n",
      "iteration 175 / 300: loss 0.580152\n",
      "iteration 175 / 300: loss 0.607923\n",
      "iteration 175 / 300: loss 0.587394\n",
      "iteration 175 / 300: loss 0.591686\n",
      "iteration 175 / 300: loss 0.571370\n",
      "iteration 175 / 300: loss 0.583025\n",
      "iteration 175 / 300: loss 0.608441\n",
      "iteration 175 / 300: loss 0.598359\n",
      "iteration 175 / 300: loss 0.583858\n",
      "iteration 175 / 300: loss 0.615253\n",
      "iteration 175 / 300: loss 0.591649\n",
      "iteration 175 / 300: loss 0.585499\n",
      "iteration 175 / 300: loss 0.591325\n",
      "iteration 175 / 300: loss 0.604341\n",
      "iteration 175 / 300: loss 0.595786\n",
      "iteration 175 / 300: loss 0.614949\n",
      "iteration 175 / 300: loss 0.608389\n",
      "iteration 175 / 300: loss 0.598222\n",
      "iteration 175 / 300: loss 0.588936\n",
      "iteration 175 / 300: loss 0.617757\n",
      "iteration 175 / 300: loss 0.594770\n",
      "iteration 175 / 300: loss 0.601684\n",
      "iteration 175 / 300: loss 0.631031\n",
      "iteration 175 / 300: loss 0.587513\n",
      "iteration 175 / 300: loss 0.606561\n",
      "iteration 175 / 300: loss 0.588034\n",
      "iteration 175 / 300: loss 0.600890\n",
      "iteration 175 / 300: loss 0.595958\n",
      "iteration 175 / 300: loss 0.589291\n",
      "iteration 175 / 300: loss 0.599526\n",
      "iteration 175 / 300: loss 0.604855\n",
      "iteration 175 / 300: loss 0.619414\n",
      "iteration 175 / 300: loss 0.588808\n",
      "iteration 175 / 300: loss 0.593645\n",
      "iteration 175 / 300: loss 0.585595\n",
      "iteration 175 / 300: loss 0.613213\n",
      "iteration 175 / 300: loss 0.587523\n",
      "iteration 175 / 300: loss 0.578328\n",
      "iteration 175 / 300: loss 0.567435\n",
      "iteration 175 / 300: loss 0.562235\n",
      "iteration 175 / 300: loss 0.594183\n",
      "iteration 175 / 300: loss 0.578821\n",
      "iteration 175 / 300: loss 0.586360\n",
      "iteration 175 / 300: loss 0.572890\n",
      "iteration 175 / 300: loss 0.596151\n",
      "iteration 175 / 300: loss 0.607951\n",
      "iteration 175 / 300: loss 0.610839\n",
      "iteration 175 / 300: loss 0.606265\n",
      "iteration 175 / 300: loss 0.583790\n",
      "iteration 175 / 300: loss 0.589627\n",
      "iteration 175 / 300: loss 0.595184\n",
      "iteration 175 / 300: loss 0.598955\n",
      "iteration 175 / 300: loss 0.596133\n",
      "iteration 175 / 300: loss 0.589769\n",
      "iteration 175 / 300: loss 0.591136\n",
      "iteration 175 / 300: loss 0.584854\n",
      "iteration 175 / 300: loss 0.599646\n",
      "iteration 175 / 300: loss 0.598902\n",
      "iteration 175 / 300: loss 0.614282\n",
      "iteration 175 / 300: loss 0.597796\n",
      "iteration 175 / 300: loss 0.599298\n",
      "iteration 175 / 300: loss 0.603317\n",
      "iteration 175 / 300: loss 0.592865\n",
      "iteration 175 / 300: loss 0.592391\n",
      "iteration 175 / 300: loss 0.589041\n",
      "iteration 175 / 300: loss 0.596446\n",
      "iteration 175 / 300: loss 0.605709\n",
      "iteration 175 / 300: loss 0.610562\n",
      "iteration 175 / 300: loss 0.587782\n",
      "iteration 175 / 300: loss 0.599351\n",
      "iteration 175 / 300: loss 0.602792\n",
      "iteration 175 / 300: loss 0.605028\n",
      "iteration 175 / 300: loss 0.603848\n",
      "iteration 175 / 300: loss 0.624144\n",
      "iteration 175 / 300: loss 0.587219\n",
      "iteration 175 / 300: loss 0.580754\n",
      "iteration 175 / 300: loss 0.625045\n",
      "iteration 175 / 300: loss 0.603310\n",
      "iteration 175 / 300: loss 0.604321\n",
      "iteration 175 / 300: loss 0.595476\n",
      "iteration 175 / 300: loss 0.597543\n",
      "iteration 175 / 300: loss 0.592740\n",
      "iteration 175 / 300: loss 0.589494\n",
      "iteration 175 / 300: loss 0.599264\n",
      "iteration 175 / 300: loss 0.611380\n",
      "iteration 175 / 300: loss 0.592463\n",
      "iteration 175 / 300: loss 0.599424\n",
      "iteration 175 / 300: loss 0.603100\n",
      "iteration 175 / 300: loss 0.602410\n",
      "iteration 175 / 300: loss 0.579811\n",
      "iteration 175 / 300: loss 0.601592\n",
      "iteration 176 / 300: loss 0.585528\n",
      "iteration 176 / 300: loss 0.588428\n",
      "iteration 176 / 300: loss 0.567516\n",
      "iteration 176 / 300: loss 0.592380\n",
      "iteration 176 / 300: loss 0.593618\n",
      "iteration 176 / 300: loss 0.595295\n",
      "iteration 176 / 300: loss 0.608784\n",
      "iteration 176 / 300: loss 0.592732\n",
      "iteration 176 / 300: loss 0.628060\n",
      "iteration 176 / 300: loss 0.580152\n",
      "iteration 176 / 300: loss 0.607923\n",
      "iteration 176 / 300: loss 0.587394\n",
      "iteration 176 / 300: loss 0.591686\n",
      "iteration 176 / 300: loss 0.571370\n",
      "iteration 176 / 300: loss 0.583025\n",
      "iteration 176 / 300: loss 0.608441\n",
      "iteration 176 / 300: loss 0.598359\n",
      "iteration 176 / 300: loss 0.583858\n",
      "iteration 176 / 300: loss 0.615253\n",
      "iteration 176 / 300: loss 0.591649\n",
      "iteration 176 / 300: loss 0.585499\n",
      "iteration 176 / 300: loss 0.591325\n",
      "iteration 176 / 300: loss 0.604341\n",
      "iteration 176 / 300: loss 0.595786\n",
      "iteration 176 / 300: loss 0.614949\n",
      "iteration 176 / 300: loss 0.608389\n",
      "iteration 176 / 300: loss 0.598222\n",
      "iteration 176 / 300: loss 0.588936\n",
      "iteration 176 / 300: loss 0.617757\n",
      "iteration 176 / 300: loss 0.594770\n",
      "iteration 176 / 300: loss 0.601684\n",
      "iteration 176 / 300: loss 0.631031\n",
      "iteration 176 / 300: loss 0.587513\n",
      "iteration 176 / 300: loss 0.606561\n",
      "iteration 176 / 300: loss 0.588034\n",
      "iteration 176 / 300: loss 0.600890\n",
      "iteration 176 / 300: loss 0.595958\n",
      "iteration 176 / 300: loss 0.589291\n",
      "iteration 176 / 300: loss 0.599526\n",
      "iteration 176 / 300: loss 0.604855\n",
      "iteration 176 / 300: loss 0.619414\n",
      "iteration 176 / 300: loss 0.588808\n",
      "iteration 176 / 300: loss 0.593645\n",
      "iteration 176 / 300: loss 0.585595\n",
      "iteration 176 / 300: loss 0.613213\n",
      "iteration 176 / 300: loss 0.587523\n",
      "iteration 176 / 300: loss 0.578328\n",
      "iteration 176 / 300: loss 0.567435\n",
      "iteration 176 / 300: loss 0.562235\n",
      "iteration 176 / 300: loss 0.594183\n",
      "iteration 176 / 300: loss 0.578821\n",
      "iteration 176 / 300: loss 0.586360\n",
      "iteration 176 / 300: loss 0.572890\n",
      "iteration 176 / 300: loss 0.596151\n",
      "iteration 176 / 300: loss 0.607951\n",
      "iteration 176 / 300: loss 0.610839\n",
      "iteration 176 / 300: loss 0.606265\n",
      "iteration 176 / 300: loss 0.583790\n",
      "iteration 176 / 300: loss 0.589627\n",
      "iteration 176 / 300: loss 0.595184\n",
      "iteration 176 / 300: loss 0.598955\n",
      "iteration 176 / 300: loss 0.596133\n",
      "iteration 176 / 300: loss 0.589769\n",
      "iteration 176 / 300: loss 0.591136\n",
      "iteration 176 / 300: loss 0.584854\n",
      "iteration 176 / 300: loss 0.599646\n",
      "iteration 176 / 300: loss 0.598902\n",
      "iteration 176 / 300: loss 0.614282\n",
      "iteration 176 / 300: loss 0.597796\n",
      "iteration 176 / 300: loss 0.599298\n",
      "iteration 176 / 300: loss 0.603317\n",
      "iteration 176 / 300: loss 0.592865\n",
      "iteration 176 / 300: loss 0.592391\n",
      "iteration 176 / 300: loss 0.589041\n",
      "iteration 176 / 300: loss 0.596446\n",
      "iteration 176 / 300: loss 0.605709\n",
      "iteration 176 / 300: loss 0.610562\n",
      "iteration 176 / 300: loss 0.587782\n",
      "iteration 176 / 300: loss 0.599351\n",
      "iteration 176 / 300: loss 0.602792\n",
      "iteration 176 / 300: loss 0.605028\n",
      "iteration 176 / 300: loss 0.603848\n",
      "iteration 176 / 300: loss 0.624144\n",
      "iteration 176 / 300: loss 0.587219\n",
      "iteration 176 / 300: loss 0.580754\n",
      "iteration 176 / 300: loss 0.625045\n",
      "iteration 176 / 300: loss 0.603310\n",
      "iteration 176 / 300: loss 0.604321\n",
      "iteration 176 / 300: loss 0.595476\n",
      "iteration 176 / 300: loss 0.597543\n",
      "iteration 176 / 300: loss 0.592740\n",
      "iteration 176 / 300: loss 0.589494\n",
      "iteration 176 / 300: loss 0.599264\n",
      "iteration 176 / 300: loss 0.611380\n",
      "iteration 176 / 300: loss 0.592463\n",
      "iteration 176 / 300: loss 0.599424\n",
      "iteration 176 / 300: loss 0.603100\n",
      "iteration 176 / 300: loss 0.602410\n",
      "iteration 176 / 300: loss 0.579811\n",
      "iteration 176 / 300: loss 0.601592\n",
      "iteration 177 / 300: loss 0.585528\n",
      "iteration 177 / 300: loss 0.588428\n",
      "iteration 177 / 300: loss 0.567516\n",
      "iteration 177 / 300: loss 0.592380\n",
      "iteration 177 / 300: loss 0.593618\n",
      "iteration 177 / 300: loss 0.595295\n",
      "iteration 177 / 300: loss 0.608784\n",
      "iteration 177 / 300: loss 0.592732\n",
      "iteration 177 / 300: loss 0.628060\n",
      "iteration 177 / 300: loss 0.580152\n",
      "iteration 177 / 300: loss 0.607923\n",
      "iteration 177 / 300: loss 0.587394\n",
      "iteration 177 / 300: loss 0.591686\n",
      "iteration 177 / 300: loss 0.571370\n",
      "iteration 177 / 300: loss 0.583025\n",
      "iteration 177 / 300: loss 0.608441\n",
      "iteration 177 / 300: loss 0.598359\n",
      "iteration 177 / 300: loss 0.583858\n",
      "iteration 177 / 300: loss 0.615253\n",
      "iteration 177 / 300: loss 0.591649\n",
      "iteration 177 / 300: loss 0.585499\n",
      "iteration 177 / 300: loss 0.591325\n",
      "iteration 177 / 300: loss 0.604341\n",
      "iteration 177 / 300: loss 0.595786\n",
      "iteration 177 / 300: loss 0.614949\n",
      "iteration 177 / 300: loss 0.608389\n",
      "iteration 177 / 300: loss 0.598222\n",
      "iteration 177 / 300: loss 0.588936\n",
      "iteration 177 / 300: loss 0.617757\n",
      "iteration 177 / 300: loss 0.594770\n",
      "iteration 177 / 300: loss 0.601684\n",
      "iteration 177 / 300: loss 0.631031\n",
      "iteration 177 / 300: loss 0.587513\n",
      "iteration 177 / 300: loss 0.606561\n",
      "iteration 177 / 300: loss 0.588034\n",
      "iteration 177 / 300: loss 0.600890\n",
      "iteration 177 / 300: loss 0.595958\n",
      "iteration 177 / 300: loss 0.589291\n",
      "iteration 177 / 300: loss 0.599526\n",
      "iteration 177 / 300: loss 0.604855\n",
      "iteration 177 / 300: loss 0.619414\n",
      "iteration 177 / 300: loss 0.588808\n",
      "iteration 177 / 300: loss 0.593645\n",
      "iteration 177 / 300: loss 0.585595\n",
      "iteration 177 / 300: loss 0.613213\n",
      "iteration 177 / 300: loss 0.587523\n",
      "iteration 177 / 300: loss 0.578328\n",
      "iteration 177 / 300: loss 0.567435\n",
      "iteration 177 / 300: loss 0.562235\n",
      "iteration 177 / 300: loss 0.594183\n",
      "iteration 177 / 300: loss 0.578821\n",
      "iteration 177 / 300: loss 0.586360\n",
      "iteration 177 / 300: loss 0.572890\n",
      "iteration 177 / 300: loss 0.596151\n",
      "iteration 177 / 300: loss 0.607951\n",
      "iteration 177 / 300: loss 0.610839\n",
      "iteration 177 / 300: loss 0.606265\n",
      "iteration 177 / 300: loss 0.583790\n",
      "iteration 177 / 300: loss 0.589627\n",
      "iteration 177 / 300: loss 0.595184\n",
      "iteration 177 / 300: loss 0.598955\n",
      "iteration 177 / 300: loss 0.596133\n",
      "iteration 177 / 300: loss 0.589769\n",
      "iteration 177 / 300: loss 0.591136\n",
      "iteration 177 / 300: loss 0.584854\n",
      "iteration 177 / 300: loss 0.599646\n",
      "iteration 177 / 300: loss 0.598902\n",
      "iteration 177 / 300: loss 0.614282\n",
      "iteration 177 / 300: loss 0.597796\n",
      "iteration 177 / 300: loss 0.599298\n",
      "iteration 177 / 300: loss 0.603317\n",
      "iteration 177 / 300: loss 0.592865\n",
      "iteration 177 / 300: loss 0.592391\n",
      "iteration 177 / 300: loss 0.589041\n",
      "iteration 177 / 300: loss 0.596446\n",
      "iteration 177 / 300: loss 0.605709\n",
      "iteration 177 / 300: loss 0.610562\n",
      "iteration 177 / 300: loss 0.587782\n",
      "iteration 177 / 300: loss 0.599351\n",
      "iteration 177 / 300: loss 0.602792\n",
      "iteration 177 / 300: loss 0.605028\n",
      "iteration 177 / 300: loss 0.603848\n",
      "iteration 177 / 300: loss 0.624144\n",
      "iteration 177 / 300: loss 0.587219\n",
      "iteration 177 / 300: loss 0.580754\n",
      "iteration 177 / 300: loss 0.625045\n",
      "iteration 177 / 300: loss 0.603310\n",
      "iteration 177 / 300: loss 0.604321\n",
      "iteration 177 / 300: loss 0.595476\n",
      "iteration 177 / 300: loss 0.597543\n",
      "iteration 177 / 300: loss 0.592740\n",
      "iteration 177 / 300: loss 0.589494\n",
      "iteration 177 / 300: loss 0.599264\n",
      "iteration 177 / 300: loss 0.611380\n",
      "iteration 177 / 300: loss 0.592463\n",
      "iteration 177 / 300: loss 0.599424\n",
      "iteration 177 / 300: loss 0.603100\n",
      "iteration 177 / 300: loss 0.602410\n",
      "iteration 177 / 300: loss 0.579811\n",
      "iteration 177 / 300: loss 0.601592\n",
      "iteration 178 / 300: loss 0.585528\n",
      "iteration 178 / 300: loss 0.588428\n",
      "iteration 178 / 300: loss 0.567516\n",
      "iteration 178 / 300: loss 0.592380\n",
      "iteration 178 / 300: loss 0.593618\n",
      "iteration 178 / 300: loss 0.595295\n",
      "iteration 178 / 300: loss 0.608784\n",
      "iteration 178 / 300: loss 0.592732\n",
      "iteration 178 / 300: loss 0.628060\n",
      "iteration 178 / 300: loss 0.580152\n",
      "iteration 178 / 300: loss 0.607923\n",
      "iteration 178 / 300: loss 0.587394\n",
      "iteration 178 / 300: loss 0.591686\n",
      "iteration 178 / 300: loss 0.571370\n",
      "iteration 178 / 300: loss 0.583025\n",
      "iteration 178 / 300: loss 0.608441\n",
      "iteration 178 / 300: loss 0.598359\n",
      "iteration 178 / 300: loss 0.583858\n",
      "iteration 178 / 300: loss 0.615253\n",
      "iteration 178 / 300: loss 0.591649\n",
      "iteration 178 / 300: loss 0.585499\n",
      "iteration 178 / 300: loss 0.591325\n",
      "iteration 178 / 300: loss 0.604341\n",
      "iteration 178 / 300: loss 0.595786\n",
      "iteration 178 / 300: loss 0.614949\n",
      "iteration 178 / 300: loss 0.608389\n",
      "iteration 178 / 300: loss 0.598222\n",
      "iteration 178 / 300: loss 0.588936\n",
      "iteration 178 / 300: loss 0.617757\n",
      "iteration 178 / 300: loss 0.594770\n",
      "iteration 178 / 300: loss 0.601684\n",
      "iteration 178 / 300: loss 0.631031\n",
      "iteration 178 / 300: loss 0.587513\n",
      "iteration 178 / 300: loss 0.606561\n",
      "iteration 178 / 300: loss 0.588034\n",
      "iteration 178 / 300: loss 0.600890\n",
      "iteration 178 / 300: loss 0.595958\n",
      "iteration 178 / 300: loss 0.589291\n",
      "iteration 178 / 300: loss 0.599526\n",
      "iteration 178 / 300: loss 0.604855\n",
      "iteration 178 / 300: loss 0.619414\n",
      "iteration 178 / 300: loss 0.588808\n",
      "iteration 178 / 300: loss 0.593645\n",
      "iteration 178 / 300: loss 0.585595\n",
      "iteration 178 / 300: loss 0.613213\n",
      "iteration 178 / 300: loss 0.587523\n",
      "iteration 178 / 300: loss 0.578328\n",
      "iteration 178 / 300: loss 0.567435\n",
      "iteration 178 / 300: loss 0.562235\n",
      "iteration 178 / 300: loss 0.594183\n",
      "iteration 178 / 300: loss 0.578821\n",
      "iteration 178 / 300: loss 0.586360\n",
      "iteration 178 / 300: loss 0.572890\n",
      "iteration 178 / 300: loss 0.596151\n",
      "iteration 178 / 300: loss 0.607951\n",
      "iteration 178 / 300: loss 0.610839\n",
      "iteration 178 / 300: loss 0.606265\n",
      "iteration 178 / 300: loss 0.583790\n",
      "iteration 178 / 300: loss 0.589627\n",
      "iteration 178 / 300: loss 0.595184\n",
      "iteration 178 / 300: loss 0.598955\n",
      "iteration 178 / 300: loss 0.596133\n",
      "iteration 178 / 300: loss 0.589769\n",
      "iteration 178 / 300: loss 0.591136\n",
      "iteration 178 / 300: loss 0.584854\n",
      "iteration 178 / 300: loss 0.599646\n",
      "iteration 178 / 300: loss 0.598902\n",
      "iteration 178 / 300: loss 0.614282\n",
      "iteration 178 / 300: loss 0.597796\n",
      "iteration 178 / 300: loss 0.599298\n",
      "iteration 178 / 300: loss 0.603317\n",
      "iteration 178 / 300: loss 0.592865\n",
      "iteration 178 / 300: loss 0.592391\n",
      "iteration 178 / 300: loss 0.589041\n",
      "iteration 178 / 300: loss 0.596446\n",
      "iteration 178 / 300: loss 0.605709\n",
      "iteration 178 / 300: loss 0.610562\n",
      "iteration 178 / 300: loss 0.587782\n",
      "iteration 178 / 300: loss 0.599351\n",
      "iteration 178 / 300: loss 0.602792\n",
      "iteration 178 / 300: loss 0.605028\n",
      "iteration 178 / 300: loss 0.603848\n",
      "iteration 178 / 300: loss 0.624144\n",
      "iteration 178 / 300: loss 0.587219\n",
      "iteration 178 / 300: loss 0.580754\n",
      "iteration 178 / 300: loss 0.625045\n",
      "iteration 178 / 300: loss 0.603310\n",
      "iteration 178 / 300: loss 0.604321\n",
      "iteration 178 / 300: loss 0.595476\n",
      "iteration 178 / 300: loss 0.597543\n",
      "iteration 178 / 300: loss 0.592740\n",
      "iteration 178 / 300: loss 0.589494\n",
      "iteration 178 / 300: loss 0.599264\n",
      "iteration 178 / 300: loss 0.611380\n",
      "iteration 178 / 300: loss 0.592463\n",
      "iteration 178 / 300: loss 0.599424\n",
      "iteration 178 / 300: loss 0.603100\n",
      "iteration 178 / 300: loss 0.602410\n",
      "iteration 178 / 300: loss 0.579811\n",
      "iteration 178 / 300: loss 0.601592\n",
      "iteration 179 / 300: loss 0.585528\n",
      "iteration 179 / 300: loss 0.588428\n",
      "iteration 179 / 300: loss 0.567516\n",
      "iteration 179 / 300: loss 0.592380\n",
      "iteration 179 / 300: loss 0.593618\n",
      "iteration 179 / 300: loss 0.595295\n",
      "iteration 179 / 300: loss 0.608784\n",
      "iteration 179 / 300: loss 0.592732\n",
      "iteration 179 / 300: loss 0.628060\n",
      "iteration 179 / 300: loss 0.580152\n",
      "iteration 179 / 300: loss 0.607923\n",
      "iteration 179 / 300: loss 0.587394\n",
      "iteration 179 / 300: loss 0.591686\n",
      "iteration 179 / 300: loss 0.571370\n",
      "iteration 179 / 300: loss 0.583025\n",
      "iteration 179 / 300: loss 0.608441\n",
      "iteration 179 / 300: loss 0.598359\n",
      "iteration 179 / 300: loss 0.583858\n",
      "iteration 179 / 300: loss 0.615253\n",
      "iteration 179 / 300: loss 0.591649\n",
      "iteration 179 / 300: loss 0.585499\n",
      "iteration 179 / 300: loss 0.591325\n",
      "iteration 179 / 300: loss 0.604341\n",
      "iteration 179 / 300: loss 0.595786\n",
      "iteration 179 / 300: loss 0.614949\n",
      "iteration 179 / 300: loss 0.608389\n",
      "iteration 179 / 300: loss 0.598222\n",
      "iteration 179 / 300: loss 0.588936\n",
      "iteration 179 / 300: loss 0.617757\n",
      "iteration 179 / 300: loss 0.594770\n",
      "iteration 179 / 300: loss 0.601684\n",
      "iteration 179 / 300: loss 0.631031\n",
      "iteration 179 / 300: loss 0.587513\n",
      "iteration 179 / 300: loss 0.606561\n",
      "iteration 179 / 300: loss 0.588034\n",
      "iteration 179 / 300: loss 0.600890\n",
      "iteration 179 / 300: loss 0.595958\n",
      "iteration 179 / 300: loss 0.589291\n",
      "iteration 179 / 300: loss 0.599526\n",
      "iteration 179 / 300: loss 0.604855\n",
      "iteration 179 / 300: loss 0.619414\n",
      "iteration 179 / 300: loss 0.588808\n",
      "iteration 179 / 300: loss 0.593645\n",
      "iteration 179 / 300: loss 0.585595\n",
      "iteration 179 / 300: loss 0.613213\n",
      "iteration 179 / 300: loss 0.587523\n",
      "iteration 179 / 300: loss 0.578328\n",
      "iteration 179 / 300: loss 0.567435\n",
      "iteration 179 / 300: loss 0.562235\n",
      "iteration 179 / 300: loss 0.594183\n",
      "iteration 179 / 300: loss 0.578821\n",
      "iteration 179 / 300: loss 0.586360\n",
      "iteration 179 / 300: loss 0.572890\n",
      "iteration 179 / 300: loss 0.596151\n",
      "iteration 179 / 300: loss 0.607951\n",
      "iteration 179 / 300: loss 0.610839\n",
      "iteration 179 / 300: loss 0.606265\n",
      "iteration 179 / 300: loss 0.583790\n",
      "iteration 179 / 300: loss 0.589627\n",
      "iteration 179 / 300: loss 0.595184\n",
      "iteration 179 / 300: loss 0.598955\n",
      "iteration 179 / 300: loss 0.596133\n",
      "iteration 179 / 300: loss 0.589769\n",
      "iteration 179 / 300: loss 0.591136\n",
      "iteration 179 / 300: loss 0.584854\n",
      "iteration 179 / 300: loss 0.599646\n",
      "iteration 179 / 300: loss 0.598902\n",
      "iteration 179 / 300: loss 0.614282\n",
      "iteration 179 / 300: loss 0.597796\n",
      "iteration 179 / 300: loss 0.599298\n",
      "iteration 179 / 300: loss 0.603317\n",
      "iteration 179 / 300: loss 0.592865\n",
      "iteration 179 / 300: loss 0.592391\n",
      "iteration 179 / 300: loss 0.589041\n",
      "iteration 179 / 300: loss 0.596446\n",
      "iteration 179 / 300: loss 0.605709\n",
      "iteration 179 / 300: loss 0.610562\n",
      "iteration 179 / 300: loss 0.587782\n",
      "iteration 179 / 300: loss 0.599351\n",
      "iteration 179 / 300: loss 0.602792\n",
      "iteration 179 / 300: loss 0.605028\n",
      "iteration 179 / 300: loss 0.603848\n",
      "iteration 179 / 300: loss 0.624144\n",
      "iteration 179 / 300: loss 0.587219\n",
      "iteration 179 / 300: loss 0.580754\n",
      "iteration 179 / 300: loss 0.625045\n",
      "iteration 179 / 300: loss 0.603310\n",
      "iteration 179 / 300: loss 0.604321\n",
      "iteration 179 / 300: loss 0.595476\n",
      "iteration 179 / 300: loss 0.597543\n",
      "iteration 179 / 300: loss 0.592740\n",
      "iteration 179 / 300: loss 0.589494\n",
      "iteration 179 / 300: loss 0.599264\n",
      "iteration 179 / 300: loss 0.611380\n",
      "iteration 179 / 300: loss 0.592463\n",
      "iteration 179 / 300: loss 0.599424\n",
      "iteration 179 / 300: loss 0.603100\n",
      "iteration 179 / 300: loss 0.602410\n",
      "iteration 179 / 300: loss 0.579811\n",
      "iteration 179 / 300: loss 0.601592\n",
      "iteration 180 / 300: loss 0.585528\n",
      "iteration 180 / 300: loss 0.588428\n",
      "iteration 180 / 300: loss 0.567516\n",
      "iteration 180 / 300: loss 0.592380\n",
      "iteration 180 / 300: loss 0.593618\n",
      "iteration 180 / 300: loss 0.595295\n",
      "iteration 180 / 300: loss 0.608784\n",
      "iteration 180 / 300: loss 0.592732\n",
      "iteration 180 / 300: loss 0.628060\n",
      "iteration 180 / 300: loss 0.580152\n",
      "iteration 180 / 300: loss 0.607923\n",
      "iteration 180 / 300: loss 0.587394\n",
      "iteration 180 / 300: loss 0.591686\n",
      "iteration 180 / 300: loss 0.571370\n",
      "iteration 180 / 300: loss 0.583025\n",
      "iteration 180 / 300: loss 0.608441\n",
      "iteration 180 / 300: loss 0.598359\n",
      "iteration 180 / 300: loss 0.583858\n",
      "iteration 180 / 300: loss 0.615253\n",
      "iteration 180 / 300: loss 0.591649\n",
      "iteration 180 / 300: loss 0.585499\n",
      "iteration 180 / 300: loss 0.591325\n",
      "iteration 180 / 300: loss 0.604341\n",
      "iteration 180 / 300: loss 0.595786\n",
      "iteration 180 / 300: loss 0.614949\n",
      "iteration 180 / 300: loss 0.608389\n",
      "iteration 180 / 300: loss 0.598222\n",
      "iteration 180 / 300: loss 0.588936\n",
      "iteration 180 / 300: loss 0.617757\n",
      "iteration 180 / 300: loss 0.594770\n",
      "iteration 180 / 300: loss 0.601684\n",
      "iteration 180 / 300: loss 0.631031\n",
      "iteration 180 / 300: loss 0.587513\n",
      "iteration 180 / 300: loss 0.606561\n",
      "iteration 180 / 300: loss 0.588034\n",
      "iteration 180 / 300: loss 0.600890\n",
      "iteration 180 / 300: loss 0.595958\n",
      "iteration 180 / 300: loss 0.589291\n",
      "iteration 180 / 300: loss 0.599526\n",
      "iteration 180 / 300: loss 0.604855\n",
      "iteration 180 / 300: loss 0.619414\n",
      "iteration 180 / 300: loss 0.588808\n",
      "iteration 180 / 300: loss 0.593645\n",
      "iteration 180 / 300: loss 0.585595\n",
      "iteration 180 / 300: loss 0.613212\n",
      "iteration 180 / 300: loss 0.587523\n",
      "iteration 180 / 300: loss 0.578328\n",
      "iteration 180 / 300: loss 0.567435\n",
      "iteration 180 / 300: loss 0.562235\n",
      "iteration 180 / 300: loss 0.594183\n",
      "iteration 180 / 300: loss 0.578821\n",
      "iteration 180 / 300: loss 0.586360\n",
      "iteration 180 / 300: loss 0.572890\n",
      "iteration 180 / 300: loss 0.596151\n",
      "iteration 180 / 300: loss 0.607951\n",
      "iteration 180 / 300: loss 0.610839\n",
      "iteration 180 / 300: loss 0.606265\n",
      "iteration 180 / 300: loss 0.583790\n",
      "iteration 180 / 300: loss 0.589627\n",
      "iteration 180 / 300: loss 0.595184\n",
      "iteration 180 / 300: loss 0.598955\n",
      "iteration 180 / 300: loss 0.596133\n",
      "iteration 180 / 300: loss 0.589769\n",
      "iteration 180 / 300: loss 0.591136\n",
      "iteration 180 / 300: loss 0.584854\n",
      "iteration 180 / 300: loss 0.599646\n",
      "iteration 180 / 300: loss 0.598902\n",
      "iteration 180 / 300: loss 0.614282\n",
      "iteration 180 / 300: loss 0.597796\n",
      "iteration 180 / 300: loss 0.599298\n",
      "iteration 180 / 300: loss 0.603317\n",
      "iteration 180 / 300: loss 0.592865\n",
      "iteration 180 / 300: loss 0.592391\n",
      "iteration 180 / 300: loss 0.589041\n",
      "iteration 180 / 300: loss 0.596446\n",
      "iteration 180 / 300: loss 0.605709\n",
      "iteration 180 / 300: loss 0.610562\n",
      "iteration 180 / 300: loss 0.587782\n",
      "iteration 180 / 300: loss 0.599351\n",
      "iteration 180 / 300: loss 0.602792\n",
      "iteration 180 / 300: loss 0.605028\n",
      "iteration 180 / 300: loss 0.603848\n",
      "iteration 180 / 300: loss 0.624144\n",
      "iteration 180 / 300: loss 0.587219\n",
      "iteration 180 / 300: loss 0.580754\n",
      "iteration 180 / 300: loss 0.625045\n",
      "iteration 180 / 300: loss 0.603310\n",
      "iteration 180 / 300: loss 0.604321\n",
      "iteration 180 / 300: loss 0.595476\n",
      "iteration 180 / 300: loss 0.597543\n",
      "iteration 180 / 300: loss 0.592740\n",
      "iteration 180 / 300: loss 0.589494\n",
      "iteration 180 / 300: loss 0.599264\n",
      "iteration 180 / 300: loss 0.611380\n",
      "iteration 180 / 300: loss 0.592463\n",
      "iteration 180 / 300: loss 0.599424\n",
      "iteration 180 / 300: loss 0.603100\n",
      "iteration 180 / 300: loss 0.602410\n",
      "iteration 180 / 300: loss 0.579811\n",
      "iteration 180 / 300: loss 0.601592\n",
      "iteration 181 / 300: loss 0.585528\n",
      "iteration 181 / 300: loss 0.588428\n",
      "iteration 181 / 300: loss 0.567516\n",
      "iteration 181 / 300: loss 0.592380\n",
      "iteration 181 / 300: loss 0.593618\n",
      "iteration 181 / 300: loss 0.595295\n",
      "iteration 181 / 300: loss 0.608784\n",
      "iteration 181 / 300: loss 0.592732\n",
      "iteration 181 / 300: loss 0.628060\n",
      "iteration 181 / 300: loss 0.580152\n",
      "iteration 181 / 300: loss 0.607923\n",
      "iteration 181 / 300: loss 0.587394\n",
      "iteration 181 / 300: loss 0.591686\n",
      "iteration 181 / 300: loss 0.571370\n",
      "iteration 181 / 300: loss 0.583025\n",
      "iteration 181 / 300: loss 0.608441\n",
      "iteration 181 / 300: loss 0.598359\n",
      "iteration 181 / 300: loss 0.583858\n",
      "iteration 181 / 300: loss 0.615253\n",
      "iteration 181 / 300: loss 0.591649\n",
      "iteration 181 / 300: loss 0.585499\n",
      "iteration 181 / 300: loss 0.591325\n",
      "iteration 181 / 300: loss 0.604341\n",
      "iteration 181 / 300: loss 0.595786\n",
      "iteration 181 / 300: loss 0.614949\n",
      "iteration 181 / 300: loss 0.608389\n",
      "iteration 181 / 300: loss 0.598222\n",
      "iteration 181 / 300: loss 0.588936\n",
      "iteration 181 / 300: loss 0.617757\n",
      "iteration 181 / 300: loss 0.594770\n",
      "iteration 181 / 300: loss 0.601684\n",
      "iteration 181 / 300: loss 0.631031\n",
      "iteration 181 / 300: loss 0.587513\n",
      "iteration 181 / 300: loss 0.606561\n",
      "iteration 181 / 300: loss 0.588034\n",
      "iteration 181 / 300: loss 0.600890\n",
      "iteration 181 / 300: loss 0.595958\n",
      "iteration 181 / 300: loss 0.589291\n",
      "iteration 181 / 300: loss 0.599526\n",
      "iteration 181 / 300: loss 0.604855\n",
      "iteration 181 / 300: loss 0.619414\n",
      "iteration 181 / 300: loss 0.588808\n",
      "iteration 181 / 300: loss 0.593645\n",
      "iteration 181 / 300: loss 0.585595\n",
      "iteration 181 / 300: loss 0.613212\n",
      "iteration 181 / 300: loss 0.587523\n",
      "iteration 181 / 300: loss 0.578328\n",
      "iteration 181 / 300: loss 0.567435\n",
      "iteration 181 / 300: loss 0.562235\n",
      "iteration 181 / 300: loss 0.594183\n",
      "iteration 181 / 300: loss 0.578821\n",
      "iteration 181 / 300: loss 0.586360\n",
      "iteration 181 / 300: loss 0.572890\n",
      "iteration 181 / 300: loss 0.596151\n",
      "iteration 181 / 300: loss 0.607951\n",
      "iteration 181 / 300: loss 0.610839\n",
      "iteration 181 / 300: loss 0.606265\n",
      "iteration 181 / 300: loss 0.583790\n",
      "iteration 181 / 300: loss 0.589627\n",
      "iteration 181 / 300: loss 0.595184\n",
      "iteration 181 / 300: loss 0.598955\n",
      "iteration 181 / 300: loss 0.596133\n",
      "iteration 181 / 300: loss 0.589769\n",
      "iteration 181 / 300: loss 0.591136\n",
      "iteration 181 / 300: loss 0.584854\n",
      "iteration 181 / 300: loss 0.599646\n",
      "iteration 181 / 300: loss 0.598902\n",
      "iteration 181 / 300: loss 0.614282\n",
      "iteration 181 / 300: loss 0.597796\n",
      "iteration 181 / 300: loss 0.599298\n",
      "iteration 181 / 300: loss 0.603317\n",
      "iteration 181 / 300: loss 0.592865\n",
      "iteration 181 / 300: loss 0.592391\n",
      "iteration 181 / 300: loss 0.589041\n",
      "iteration 181 / 300: loss 0.596446\n",
      "iteration 181 / 300: loss 0.605709\n",
      "iteration 181 / 300: loss 0.610562\n",
      "iteration 181 / 300: loss 0.587782\n",
      "iteration 181 / 300: loss 0.599351\n",
      "iteration 181 / 300: loss 0.602792\n",
      "iteration 181 / 300: loss 0.605028\n",
      "iteration 181 / 300: loss 0.603848\n",
      "iteration 181 / 300: loss 0.624144\n",
      "iteration 181 / 300: loss 0.587219\n",
      "iteration 181 / 300: loss 0.580754\n",
      "iteration 181 / 300: loss 0.625045\n",
      "iteration 181 / 300: loss 0.603310\n",
      "iteration 181 / 300: loss 0.604321\n",
      "iteration 181 / 300: loss 0.595476\n",
      "iteration 181 / 300: loss 0.597543\n",
      "iteration 181 / 300: loss 0.592740\n",
      "iteration 181 / 300: loss 0.589494\n",
      "iteration 181 / 300: loss 0.599264\n",
      "iteration 181 / 300: loss 0.611380\n",
      "iteration 181 / 300: loss 0.592463\n",
      "iteration 181 / 300: loss 0.599424\n",
      "iteration 181 / 300: loss 0.603100\n",
      "iteration 181 / 300: loss 0.602410\n",
      "iteration 181 / 300: loss 0.579811\n",
      "iteration 181 / 300: loss 0.601592\n",
      "iteration 182 / 300: loss 0.585528\n",
      "iteration 182 / 300: loss 0.588428\n",
      "iteration 182 / 300: loss 0.567516\n",
      "iteration 182 / 300: loss 0.592380\n",
      "iteration 182 / 300: loss 0.593618\n",
      "iteration 182 / 300: loss 0.595295\n",
      "iteration 182 / 300: loss 0.608784\n",
      "iteration 182 / 300: loss 0.592732\n",
      "iteration 182 / 300: loss 0.628060\n",
      "iteration 182 / 300: loss 0.580152\n",
      "iteration 182 / 300: loss 0.607923\n",
      "iteration 182 / 300: loss 0.587394\n",
      "iteration 182 / 300: loss 0.591686\n",
      "iteration 182 / 300: loss 0.571370\n",
      "iteration 182 / 300: loss 0.583025\n",
      "iteration 182 / 300: loss 0.608441\n",
      "iteration 182 / 300: loss 0.598359\n",
      "iteration 182 / 300: loss 0.583858\n",
      "iteration 182 / 300: loss 0.615253\n",
      "iteration 182 / 300: loss 0.591649\n",
      "iteration 182 / 300: loss 0.585499\n",
      "iteration 182 / 300: loss 0.591325\n",
      "iteration 182 / 300: loss 0.604341\n",
      "iteration 182 / 300: loss 0.595786\n",
      "iteration 182 / 300: loss 0.614949\n",
      "iteration 182 / 300: loss 0.608389\n",
      "iteration 182 / 300: loss 0.598222\n",
      "iteration 182 / 300: loss 0.588936\n",
      "iteration 182 / 300: loss 0.617757\n",
      "iteration 182 / 300: loss 0.594770\n",
      "iteration 182 / 300: loss 0.601684\n",
      "iteration 182 / 300: loss 0.631031\n",
      "iteration 182 / 300: loss 0.587513\n",
      "iteration 182 / 300: loss 0.606561\n",
      "iteration 182 / 300: loss 0.588034\n",
      "iteration 182 / 300: loss 0.600890\n",
      "iteration 182 / 300: loss 0.595958\n",
      "iteration 182 / 300: loss 0.589291\n",
      "iteration 182 / 300: loss 0.599526\n",
      "iteration 182 / 300: loss 0.604855\n",
      "iteration 182 / 300: loss 0.619414\n",
      "iteration 182 / 300: loss 0.588808\n",
      "iteration 182 / 300: loss 0.593645\n",
      "iteration 182 / 300: loss 0.585595\n",
      "iteration 182 / 300: loss 0.613212\n",
      "iteration 182 / 300: loss 0.587523\n",
      "iteration 182 / 300: loss 0.578328\n",
      "iteration 182 / 300: loss 0.567435\n",
      "iteration 182 / 300: loss 0.562235\n",
      "iteration 182 / 300: loss 0.594183\n",
      "iteration 182 / 300: loss 0.578821\n",
      "iteration 182 / 300: loss 0.586360\n",
      "iteration 182 / 300: loss 0.572890\n",
      "iteration 182 / 300: loss 0.596151\n",
      "iteration 182 / 300: loss 0.607951\n",
      "iteration 182 / 300: loss 0.610839\n",
      "iteration 182 / 300: loss 0.606265\n",
      "iteration 182 / 300: loss 0.583790\n",
      "iteration 182 / 300: loss 0.589627\n",
      "iteration 182 / 300: loss 0.595184\n",
      "iteration 182 / 300: loss 0.598955\n",
      "iteration 182 / 300: loss 0.596133\n",
      "iteration 182 / 300: loss 0.589769\n",
      "iteration 182 / 300: loss 0.591136\n",
      "iteration 182 / 300: loss 0.584854\n",
      "iteration 182 / 300: loss 0.599646\n",
      "iteration 182 / 300: loss 0.598902\n",
      "iteration 182 / 300: loss 0.614282\n",
      "iteration 182 / 300: loss 0.597796\n",
      "iteration 182 / 300: loss 0.599298\n",
      "iteration 182 / 300: loss 0.603317\n",
      "iteration 182 / 300: loss 0.592865\n",
      "iteration 182 / 300: loss 0.592391\n",
      "iteration 182 / 300: loss 0.589041\n",
      "iteration 182 / 300: loss 0.596446\n",
      "iteration 182 / 300: loss 0.605709\n",
      "iteration 182 / 300: loss 0.610562\n",
      "iteration 182 / 300: loss 0.587782\n",
      "iteration 182 / 300: loss 0.599351\n",
      "iteration 182 / 300: loss 0.602792\n",
      "iteration 182 / 300: loss 0.605028\n",
      "iteration 182 / 300: loss 0.603848\n",
      "iteration 182 / 300: loss 0.624144\n",
      "iteration 182 / 300: loss 0.587219\n",
      "iteration 182 / 300: loss 0.580754\n",
      "iteration 182 / 300: loss 0.625045\n",
      "iteration 182 / 300: loss 0.603310\n",
      "iteration 182 / 300: loss 0.604321\n",
      "iteration 182 / 300: loss 0.595476\n",
      "iteration 182 / 300: loss 0.597543\n",
      "iteration 182 / 300: loss 0.592740\n",
      "iteration 182 / 300: loss 0.589494\n",
      "iteration 182 / 300: loss 0.599264\n",
      "iteration 182 / 300: loss 0.611380\n",
      "iteration 182 / 300: loss 0.592463\n",
      "iteration 182 / 300: loss 0.599424\n",
      "iteration 182 / 300: loss 0.603100\n",
      "iteration 182 / 300: loss 0.602410\n",
      "iteration 182 / 300: loss 0.579811\n",
      "iteration 182 / 300: loss 0.601592\n",
      "iteration 183 / 300: loss 0.585528\n",
      "iteration 183 / 300: loss 0.588428\n",
      "iteration 183 / 300: loss 0.567516\n",
      "iteration 183 / 300: loss 0.592380\n",
      "iteration 183 / 300: loss 0.593618\n",
      "iteration 183 / 300: loss 0.595295\n",
      "iteration 183 / 300: loss 0.608784\n",
      "iteration 183 / 300: loss 0.592732\n",
      "iteration 183 / 300: loss 0.628060\n",
      "iteration 183 / 300: loss 0.580152\n",
      "iteration 183 / 300: loss 0.607923\n",
      "iteration 183 / 300: loss 0.587394\n",
      "iteration 183 / 300: loss 0.591686\n",
      "iteration 183 / 300: loss 0.571370\n",
      "iteration 183 / 300: loss 0.583025\n",
      "iteration 183 / 300: loss 0.608441\n",
      "iteration 183 / 300: loss 0.598359\n",
      "iteration 183 / 300: loss 0.583858\n",
      "iteration 183 / 300: loss 0.615253\n",
      "iteration 183 / 300: loss 0.591649\n",
      "iteration 183 / 300: loss 0.585499\n",
      "iteration 183 / 300: loss 0.591325\n",
      "iteration 183 / 300: loss 0.604341\n",
      "iteration 183 / 300: loss 0.595786\n",
      "iteration 183 / 300: loss 0.614949\n",
      "iteration 183 / 300: loss 0.608389\n",
      "iteration 183 / 300: loss 0.598222\n",
      "iteration 183 / 300: loss 0.588936\n",
      "iteration 183 / 300: loss 0.617757\n",
      "iteration 183 / 300: loss 0.594770\n",
      "iteration 183 / 300: loss 0.601684\n",
      "iteration 183 / 300: loss 0.631031\n",
      "iteration 183 / 300: loss 0.587513\n",
      "iteration 183 / 300: loss 0.606561\n",
      "iteration 183 / 300: loss 0.588034\n",
      "iteration 183 / 300: loss 0.600890\n",
      "iteration 183 / 300: loss 0.595958\n",
      "iteration 183 / 300: loss 0.589291\n",
      "iteration 183 / 300: loss 0.599526\n",
      "iteration 183 / 300: loss 0.604855\n",
      "iteration 183 / 300: loss 0.619414\n",
      "iteration 183 / 300: loss 0.588808\n",
      "iteration 183 / 300: loss 0.593645\n",
      "iteration 183 / 300: loss 0.585595\n",
      "iteration 183 / 300: loss 0.613212\n",
      "iteration 183 / 300: loss 0.587523\n",
      "iteration 183 / 300: loss 0.578328\n",
      "iteration 183 / 300: loss 0.567435\n",
      "iteration 183 / 300: loss 0.562235\n",
      "iteration 183 / 300: loss 0.594183\n",
      "iteration 183 / 300: loss 0.578821\n",
      "iteration 183 / 300: loss 0.586360\n",
      "iteration 183 / 300: loss 0.572890\n",
      "iteration 183 / 300: loss 0.596151\n",
      "iteration 183 / 300: loss 0.607951\n",
      "iteration 183 / 300: loss 0.610839\n",
      "iteration 183 / 300: loss 0.606265\n",
      "iteration 183 / 300: loss 0.583790\n",
      "iteration 183 / 300: loss 0.589627\n",
      "iteration 183 / 300: loss 0.595184\n",
      "iteration 183 / 300: loss 0.598955\n",
      "iteration 183 / 300: loss 0.596133\n",
      "iteration 183 / 300: loss 0.589769\n",
      "iteration 183 / 300: loss 0.591136\n",
      "iteration 183 / 300: loss 0.584854\n",
      "iteration 183 / 300: loss 0.599646\n",
      "iteration 183 / 300: loss 0.598902\n",
      "iteration 183 / 300: loss 0.614282\n",
      "iteration 183 / 300: loss 0.597796\n",
      "iteration 183 / 300: loss 0.599298\n",
      "iteration 183 / 300: loss 0.603317\n",
      "iteration 183 / 300: loss 0.592865\n",
      "iteration 183 / 300: loss 0.592391\n",
      "iteration 183 / 300: loss 0.589041\n",
      "iteration 183 / 300: loss 0.596446\n",
      "iteration 183 / 300: loss 0.605709\n",
      "iteration 183 / 300: loss 0.610562\n",
      "iteration 183 / 300: loss 0.587782\n",
      "iteration 183 / 300: loss 0.599351\n",
      "iteration 183 / 300: loss 0.602792\n",
      "iteration 183 / 300: loss 0.605028\n",
      "iteration 183 / 300: loss 0.603848\n",
      "iteration 183 / 300: loss 0.624144\n",
      "iteration 183 / 300: loss 0.587219\n",
      "iteration 183 / 300: loss 0.580754\n",
      "iteration 183 / 300: loss 0.625045\n",
      "iteration 183 / 300: loss 0.603310\n",
      "iteration 183 / 300: loss 0.604321\n",
      "iteration 183 / 300: loss 0.595476\n",
      "iteration 183 / 300: loss 0.597543\n",
      "iteration 183 / 300: loss 0.592740\n",
      "iteration 183 / 300: loss 0.589494\n",
      "iteration 183 / 300: loss 0.599264\n",
      "iteration 183 / 300: loss 0.611380\n",
      "iteration 183 / 300: loss 0.592463\n",
      "iteration 183 / 300: loss 0.599424\n",
      "iteration 183 / 300: loss 0.603100\n",
      "iteration 183 / 300: loss 0.602410\n",
      "iteration 183 / 300: loss 0.579811\n",
      "iteration 183 / 300: loss 0.601592\n",
      "iteration 184 / 300: loss 0.585528\n",
      "iteration 184 / 300: loss 0.588428\n",
      "iteration 184 / 300: loss 0.567516\n",
      "iteration 184 / 300: loss 0.592380\n",
      "iteration 184 / 300: loss 0.593618\n",
      "iteration 184 / 300: loss 0.595295\n",
      "iteration 184 / 300: loss 0.608784\n",
      "iteration 184 / 300: loss 0.592732\n",
      "iteration 184 / 300: loss 0.628060\n",
      "iteration 184 / 300: loss 0.580152\n",
      "iteration 184 / 300: loss 0.607923\n",
      "iteration 184 / 300: loss 0.587394\n",
      "iteration 184 / 300: loss 0.591686\n",
      "iteration 184 / 300: loss 0.571370\n",
      "iteration 184 / 300: loss 0.583025\n",
      "iteration 184 / 300: loss 0.608441\n",
      "iteration 184 / 300: loss 0.598359\n",
      "iteration 184 / 300: loss 0.583858\n",
      "iteration 184 / 300: loss 0.615253\n",
      "iteration 184 / 300: loss 0.591649\n",
      "iteration 184 / 300: loss 0.585499\n",
      "iteration 184 / 300: loss 0.591325\n",
      "iteration 184 / 300: loss 0.604341\n",
      "iteration 184 / 300: loss 0.595786\n",
      "iteration 184 / 300: loss 0.614949\n",
      "iteration 184 / 300: loss 0.608389\n",
      "iteration 184 / 300: loss 0.598222\n",
      "iteration 184 / 300: loss 0.588936\n",
      "iteration 184 / 300: loss 0.617757\n",
      "iteration 184 / 300: loss 0.594770\n",
      "iteration 184 / 300: loss 0.601684\n",
      "iteration 184 / 300: loss 0.631031\n",
      "iteration 184 / 300: loss 0.587513\n",
      "iteration 184 / 300: loss 0.606561\n",
      "iteration 184 / 300: loss 0.588034\n",
      "iteration 184 / 300: loss 0.600890\n",
      "iteration 184 / 300: loss 0.595958\n",
      "iteration 184 / 300: loss 0.589291\n",
      "iteration 184 / 300: loss 0.599526\n",
      "iteration 184 / 300: loss 0.604855\n",
      "iteration 184 / 300: loss 0.619414\n",
      "iteration 184 / 300: loss 0.588808\n",
      "iteration 184 / 300: loss 0.593645\n",
      "iteration 184 / 300: loss 0.585595\n",
      "iteration 184 / 300: loss 0.613212\n",
      "iteration 184 / 300: loss 0.587523\n",
      "iteration 184 / 300: loss 0.578328\n",
      "iteration 184 / 300: loss 0.567435\n",
      "iteration 184 / 300: loss 0.562235\n",
      "iteration 184 / 300: loss 0.594183\n",
      "iteration 184 / 300: loss 0.578821\n",
      "iteration 184 / 300: loss 0.586360\n",
      "iteration 184 / 300: loss 0.572890\n",
      "iteration 184 / 300: loss 0.596151\n",
      "iteration 184 / 300: loss 0.607951\n",
      "iteration 184 / 300: loss 0.610839\n",
      "iteration 184 / 300: loss 0.606265\n",
      "iteration 184 / 300: loss 0.583790\n",
      "iteration 184 / 300: loss 0.589627\n",
      "iteration 184 / 300: loss 0.595184\n",
      "iteration 184 / 300: loss 0.598955\n",
      "iteration 184 / 300: loss 0.596133\n",
      "iteration 184 / 300: loss 0.589769\n",
      "iteration 184 / 300: loss 0.591136\n",
      "iteration 184 / 300: loss 0.584854\n",
      "iteration 184 / 300: loss 0.599646\n",
      "iteration 184 / 300: loss 0.598902\n",
      "iteration 184 / 300: loss 0.614282\n",
      "iteration 184 / 300: loss 0.597796\n",
      "iteration 184 / 300: loss 0.599298\n",
      "iteration 184 / 300: loss 0.603317\n",
      "iteration 184 / 300: loss 0.592865\n",
      "iteration 184 / 300: loss 0.592391\n",
      "iteration 184 / 300: loss 0.589041\n",
      "iteration 184 / 300: loss 0.596446\n",
      "iteration 184 / 300: loss 0.605709\n",
      "iteration 184 / 300: loss 0.610562\n",
      "iteration 184 / 300: loss 0.587782\n",
      "iteration 184 / 300: loss 0.599351\n",
      "iteration 184 / 300: loss 0.602792\n",
      "iteration 184 / 300: loss 0.605028\n",
      "iteration 184 / 300: loss 0.603848\n",
      "iteration 184 / 300: loss 0.624144\n",
      "iteration 184 / 300: loss 0.587219\n",
      "iteration 184 / 300: loss 0.580754\n",
      "iteration 184 / 300: loss 0.625045\n",
      "iteration 184 / 300: loss 0.603310\n",
      "iteration 184 / 300: loss 0.604321\n",
      "iteration 184 / 300: loss 0.595476\n",
      "iteration 184 / 300: loss 0.597543\n",
      "iteration 184 / 300: loss 0.592740\n",
      "iteration 184 / 300: loss 0.589494\n",
      "iteration 184 / 300: loss 0.599264\n",
      "iteration 184 / 300: loss 0.611380\n",
      "iteration 184 / 300: loss 0.592463\n",
      "iteration 184 / 300: loss 0.599424\n",
      "iteration 184 / 300: loss 0.603100\n",
      "iteration 184 / 300: loss 0.602410\n",
      "iteration 184 / 300: loss 0.579811\n",
      "iteration 184 / 300: loss 0.601592\n",
      "iteration 185 / 300: loss 0.585528\n",
      "iteration 185 / 300: loss 0.588428\n",
      "iteration 185 / 300: loss 0.567516\n",
      "iteration 185 / 300: loss 0.592380\n",
      "iteration 185 / 300: loss 0.593618\n",
      "iteration 185 / 300: loss 0.595295\n",
      "iteration 185 / 300: loss 0.608784\n",
      "iteration 185 / 300: loss 0.592732\n",
      "iteration 185 / 300: loss 0.628060\n",
      "iteration 185 / 300: loss 0.580152\n",
      "iteration 185 / 300: loss 0.607923\n",
      "iteration 185 / 300: loss 0.587394\n",
      "iteration 185 / 300: loss 0.591686\n",
      "iteration 185 / 300: loss 0.571370\n",
      "iteration 185 / 300: loss 0.583025\n",
      "iteration 185 / 300: loss 0.608441\n",
      "iteration 185 / 300: loss 0.598359\n",
      "iteration 185 / 300: loss 0.583858\n",
      "iteration 185 / 300: loss 0.615253\n",
      "iteration 185 / 300: loss 0.591649\n",
      "iteration 185 / 300: loss 0.585499\n",
      "iteration 185 / 300: loss 0.591325\n",
      "iteration 185 / 300: loss 0.604341\n",
      "iteration 185 / 300: loss 0.595786\n",
      "iteration 185 / 300: loss 0.614949\n",
      "iteration 185 / 300: loss 0.608389\n",
      "iteration 185 / 300: loss 0.598222\n",
      "iteration 185 / 300: loss 0.588936\n",
      "iteration 185 / 300: loss 0.617757\n",
      "iteration 185 / 300: loss 0.594770\n",
      "iteration 185 / 300: loss 0.601684\n",
      "iteration 185 / 300: loss 0.631031\n",
      "iteration 185 / 300: loss 0.587513\n",
      "iteration 185 / 300: loss 0.606561\n",
      "iteration 185 / 300: loss 0.588034\n",
      "iteration 185 / 300: loss 0.600890\n",
      "iteration 185 / 300: loss 0.595958\n",
      "iteration 185 / 300: loss 0.589291\n",
      "iteration 185 / 300: loss 0.599526\n",
      "iteration 185 / 300: loss 0.604855\n",
      "iteration 185 / 300: loss 0.619414\n",
      "iteration 185 / 300: loss 0.588808\n",
      "iteration 185 / 300: loss 0.593645\n",
      "iteration 185 / 300: loss 0.585595\n",
      "iteration 185 / 300: loss 0.613212\n",
      "iteration 185 / 300: loss 0.587523\n",
      "iteration 185 / 300: loss 0.578328\n",
      "iteration 185 / 300: loss 0.567435\n",
      "iteration 185 / 300: loss 0.562235\n",
      "iteration 185 / 300: loss 0.594183\n",
      "iteration 185 / 300: loss 0.578821\n",
      "iteration 185 / 300: loss 0.586360\n",
      "iteration 185 / 300: loss 0.572890\n",
      "iteration 185 / 300: loss 0.596151\n",
      "iteration 185 / 300: loss 0.607951\n",
      "iteration 185 / 300: loss 0.610839\n",
      "iteration 185 / 300: loss 0.606265\n",
      "iteration 185 / 300: loss 0.583790\n",
      "iteration 185 / 300: loss 0.589627\n",
      "iteration 185 / 300: loss 0.595184\n",
      "iteration 185 / 300: loss 0.598955\n",
      "iteration 185 / 300: loss 0.596133\n",
      "iteration 185 / 300: loss 0.589769\n",
      "iteration 185 / 300: loss 0.591136\n",
      "iteration 185 / 300: loss 0.584854\n",
      "iteration 185 / 300: loss 0.599646\n",
      "iteration 185 / 300: loss 0.598902\n",
      "iteration 185 / 300: loss 0.614282\n",
      "iteration 185 / 300: loss 0.597796\n",
      "iteration 185 / 300: loss 0.599298\n",
      "iteration 185 / 300: loss 0.603317\n",
      "iteration 185 / 300: loss 0.592865\n",
      "iteration 185 / 300: loss 0.592391\n",
      "iteration 185 / 300: loss 0.589041\n",
      "iteration 185 / 300: loss 0.596446\n",
      "iteration 185 / 300: loss 0.605709\n",
      "iteration 185 / 300: loss 0.610562\n",
      "iteration 185 / 300: loss 0.587782\n",
      "iteration 185 / 300: loss 0.599351\n",
      "iteration 185 / 300: loss 0.602792\n",
      "iteration 185 / 300: loss 0.605028\n",
      "iteration 185 / 300: loss 0.603848\n",
      "iteration 185 / 300: loss 0.624144\n",
      "iteration 185 / 300: loss 0.587219\n",
      "iteration 185 / 300: loss 0.580754\n",
      "iteration 185 / 300: loss 0.625045\n",
      "iteration 185 / 300: loss 0.603310\n",
      "iteration 185 / 300: loss 0.604321\n",
      "iteration 185 / 300: loss 0.595476\n",
      "iteration 185 / 300: loss 0.597543\n",
      "iteration 185 / 300: loss 0.592740\n",
      "iteration 185 / 300: loss 0.589494\n",
      "iteration 185 / 300: loss 0.599264\n",
      "iteration 185 / 300: loss 0.611380\n",
      "iteration 185 / 300: loss 0.592463\n",
      "iteration 185 / 300: loss 0.599424\n",
      "iteration 185 / 300: loss 0.603100\n",
      "iteration 185 / 300: loss 0.602410\n",
      "iteration 185 / 300: loss 0.579811\n",
      "iteration 185 / 300: loss 0.601592\n",
      "iteration 186 / 300: loss 0.585528\n",
      "iteration 186 / 300: loss 0.588428\n",
      "iteration 186 / 300: loss 0.567516\n",
      "iteration 186 / 300: loss 0.592380\n",
      "iteration 186 / 300: loss 0.593618\n",
      "iteration 186 / 300: loss 0.595295\n",
      "iteration 186 / 300: loss 0.608784\n",
      "iteration 186 / 300: loss 0.592732\n",
      "iteration 186 / 300: loss 0.628060\n",
      "iteration 186 / 300: loss 0.580152\n",
      "iteration 186 / 300: loss 0.607923\n",
      "iteration 186 / 300: loss 0.587394\n",
      "iteration 186 / 300: loss 0.591686\n",
      "iteration 186 / 300: loss 0.571370\n",
      "iteration 186 / 300: loss 0.583025\n",
      "iteration 186 / 300: loss 0.608441\n",
      "iteration 186 / 300: loss 0.598359\n",
      "iteration 186 / 300: loss 0.583858\n",
      "iteration 186 / 300: loss 0.615253\n",
      "iteration 186 / 300: loss 0.591649\n",
      "iteration 186 / 300: loss 0.585499\n",
      "iteration 186 / 300: loss 0.591325\n",
      "iteration 186 / 300: loss 0.604341\n",
      "iteration 186 / 300: loss 0.595786\n",
      "iteration 186 / 300: loss 0.614949\n",
      "iteration 186 / 300: loss 0.608389\n",
      "iteration 186 / 300: loss 0.598222\n",
      "iteration 186 / 300: loss 0.588936\n",
      "iteration 186 / 300: loss 0.617757\n",
      "iteration 186 / 300: loss 0.594770\n",
      "iteration 186 / 300: loss 0.601684\n",
      "iteration 186 / 300: loss 0.631031\n",
      "iteration 186 / 300: loss 0.587513\n",
      "iteration 186 / 300: loss 0.606561\n",
      "iteration 186 / 300: loss 0.588034\n",
      "iteration 186 / 300: loss 0.600890\n",
      "iteration 186 / 300: loss 0.595958\n",
      "iteration 186 / 300: loss 0.589291\n",
      "iteration 186 / 300: loss 0.599526\n",
      "iteration 186 / 300: loss 0.604855\n",
      "iteration 186 / 300: loss 0.619414\n",
      "iteration 186 / 300: loss 0.588808\n",
      "iteration 186 / 300: loss 0.593645\n",
      "iteration 186 / 300: loss 0.585595\n",
      "iteration 186 / 300: loss 0.613212\n",
      "iteration 186 / 300: loss 0.587523\n",
      "iteration 186 / 300: loss 0.578328\n",
      "iteration 186 / 300: loss 0.567435\n",
      "iteration 186 / 300: loss 0.562235\n",
      "iteration 186 / 300: loss 0.594183\n",
      "iteration 186 / 300: loss 0.578821\n",
      "iteration 186 / 300: loss 0.586360\n",
      "iteration 186 / 300: loss 0.572890\n",
      "iteration 186 / 300: loss 0.596151\n",
      "iteration 186 / 300: loss 0.607951\n",
      "iteration 186 / 300: loss 0.610839\n",
      "iteration 186 / 300: loss 0.606265\n",
      "iteration 186 / 300: loss 0.583790\n",
      "iteration 186 / 300: loss 0.589627\n",
      "iteration 186 / 300: loss 0.595184\n",
      "iteration 186 / 300: loss 0.598955\n",
      "iteration 186 / 300: loss 0.596133\n",
      "iteration 186 / 300: loss 0.589769\n",
      "iteration 186 / 300: loss 0.591136\n",
      "iteration 186 / 300: loss 0.584854\n",
      "iteration 186 / 300: loss 0.599646\n",
      "iteration 186 / 300: loss 0.598902\n",
      "iteration 186 / 300: loss 0.614282\n",
      "iteration 186 / 300: loss 0.597796\n",
      "iteration 186 / 300: loss 0.599298\n",
      "iteration 186 / 300: loss 0.603317\n",
      "iteration 186 / 300: loss 0.592865\n",
      "iteration 186 / 300: loss 0.592391\n",
      "iteration 186 / 300: loss 0.589041\n",
      "iteration 186 / 300: loss 0.596446\n",
      "iteration 186 / 300: loss 0.605709\n",
      "iteration 186 / 300: loss 0.610562\n",
      "iteration 186 / 300: loss 0.587782\n",
      "iteration 186 / 300: loss 0.599351\n",
      "iteration 186 / 300: loss 0.602792\n",
      "iteration 186 / 300: loss 0.605028\n",
      "iteration 186 / 300: loss 0.603848\n",
      "iteration 186 / 300: loss 0.624144\n",
      "iteration 186 / 300: loss 0.587219\n",
      "iteration 186 / 300: loss 0.580754\n",
      "iteration 186 / 300: loss 0.625045\n",
      "iteration 186 / 300: loss 0.603310\n",
      "iteration 186 / 300: loss 0.604321\n",
      "iteration 186 / 300: loss 0.595476\n",
      "iteration 186 / 300: loss 0.597543\n",
      "iteration 186 / 300: loss 0.592740\n",
      "iteration 186 / 300: loss 0.589494\n",
      "iteration 186 / 300: loss 0.599264\n",
      "iteration 186 / 300: loss 0.611380\n",
      "iteration 186 / 300: loss 0.592463\n",
      "iteration 186 / 300: loss 0.599424\n",
      "iteration 186 / 300: loss 0.603100\n",
      "iteration 186 / 300: loss 0.602410\n",
      "iteration 186 / 300: loss 0.579811\n",
      "iteration 186 / 300: loss 0.601592\n",
      "iteration 187 / 300: loss 0.585528\n",
      "iteration 187 / 300: loss 0.588428\n",
      "iteration 187 / 300: loss 0.567516\n",
      "iteration 187 / 300: loss 0.592380\n",
      "iteration 187 / 300: loss 0.593618\n",
      "iteration 187 / 300: loss 0.595295\n",
      "iteration 187 / 300: loss 0.608784\n",
      "iteration 187 / 300: loss 0.592732\n",
      "iteration 187 / 300: loss 0.628060\n",
      "iteration 187 / 300: loss 0.580152\n",
      "iteration 187 / 300: loss 0.607923\n",
      "iteration 187 / 300: loss 0.587394\n",
      "iteration 187 / 300: loss 0.591686\n",
      "iteration 187 / 300: loss 0.571370\n",
      "iteration 187 / 300: loss 0.583025\n",
      "iteration 187 / 300: loss 0.608441\n",
      "iteration 187 / 300: loss 0.598359\n",
      "iteration 187 / 300: loss 0.583858\n",
      "iteration 187 / 300: loss 0.615253\n",
      "iteration 187 / 300: loss 0.591649\n",
      "iteration 187 / 300: loss 0.585499\n",
      "iteration 187 / 300: loss 0.591325\n",
      "iteration 187 / 300: loss 0.604341\n",
      "iteration 187 / 300: loss 0.595786\n",
      "iteration 187 / 300: loss 0.614949\n",
      "iteration 187 / 300: loss 0.608389\n",
      "iteration 187 / 300: loss 0.598222\n",
      "iteration 187 / 300: loss 0.588936\n",
      "iteration 187 / 300: loss 0.617757\n",
      "iteration 187 / 300: loss 0.594770\n",
      "iteration 187 / 300: loss 0.601684\n",
      "iteration 187 / 300: loss 0.631031\n",
      "iteration 187 / 300: loss 0.587513\n",
      "iteration 187 / 300: loss 0.606561\n",
      "iteration 187 / 300: loss 0.588034\n",
      "iteration 187 / 300: loss 0.600890\n",
      "iteration 187 / 300: loss 0.595958\n",
      "iteration 187 / 300: loss 0.589291\n",
      "iteration 187 / 300: loss 0.599526\n",
      "iteration 187 / 300: loss 0.604855\n",
      "iteration 187 / 300: loss 0.619414\n",
      "iteration 187 / 300: loss 0.588808\n",
      "iteration 187 / 300: loss 0.593645\n",
      "iteration 187 / 300: loss 0.585595\n",
      "iteration 187 / 300: loss 0.613212\n",
      "iteration 187 / 300: loss 0.587523\n",
      "iteration 187 / 300: loss 0.578328\n",
      "iteration 187 / 300: loss 0.567435\n",
      "iteration 187 / 300: loss 0.562235\n",
      "iteration 187 / 300: loss 0.594183\n",
      "iteration 187 / 300: loss 0.578821\n",
      "iteration 187 / 300: loss 0.586360\n",
      "iteration 187 / 300: loss 0.572890\n",
      "iteration 187 / 300: loss 0.596151\n",
      "iteration 187 / 300: loss 0.607951\n",
      "iteration 187 / 300: loss 0.610839\n",
      "iteration 187 / 300: loss 0.606265\n",
      "iteration 187 / 300: loss 0.583790\n",
      "iteration 187 / 300: loss 0.589627\n",
      "iteration 187 / 300: loss 0.595184\n",
      "iteration 187 / 300: loss 0.598955\n",
      "iteration 187 / 300: loss 0.596133\n",
      "iteration 187 / 300: loss 0.589769\n",
      "iteration 187 / 300: loss 0.591136\n",
      "iteration 187 / 300: loss 0.584854\n",
      "iteration 187 / 300: loss 0.599646\n",
      "iteration 187 / 300: loss 0.598902\n",
      "iteration 187 / 300: loss 0.614282\n",
      "iteration 187 / 300: loss 0.597796\n",
      "iteration 187 / 300: loss 0.599298\n",
      "iteration 187 / 300: loss 0.603317\n",
      "iteration 187 / 300: loss 0.592865\n",
      "iteration 187 / 300: loss 0.592391\n",
      "iteration 187 / 300: loss 0.589041\n",
      "iteration 187 / 300: loss 0.596446\n",
      "iteration 187 / 300: loss 0.605709\n",
      "iteration 187 / 300: loss 0.610562\n",
      "iteration 187 / 300: loss 0.587782\n",
      "iteration 187 / 300: loss 0.599351\n",
      "iteration 187 / 300: loss 0.602792\n",
      "iteration 187 / 300: loss 0.605028\n",
      "iteration 187 / 300: loss 0.603848\n",
      "iteration 187 / 300: loss 0.624144\n",
      "iteration 187 / 300: loss 0.587219\n",
      "iteration 187 / 300: loss 0.580754\n",
      "iteration 187 / 300: loss 0.625045\n",
      "iteration 187 / 300: loss 0.603310\n",
      "iteration 187 / 300: loss 0.604321\n",
      "iteration 187 / 300: loss 0.595476\n",
      "iteration 187 / 300: loss 0.597543\n",
      "iteration 187 / 300: loss 0.592740\n",
      "iteration 187 / 300: loss 0.589494\n",
      "iteration 187 / 300: loss 0.599264\n",
      "iteration 187 / 300: loss 0.611380\n",
      "iteration 187 / 300: loss 0.592463\n",
      "iteration 187 / 300: loss 0.599424\n",
      "iteration 187 / 300: loss 0.603100\n",
      "iteration 187 / 300: loss 0.602410\n",
      "iteration 187 / 300: loss 0.579811\n",
      "iteration 187 / 300: loss 0.601592\n",
      "iteration 188 / 300: loss 0.585528\n",
      "iteration 188 / 300: loss 0.588428\n",
      "iteration 188 / 300: loss 0.567516\n",
      "iteration 188 / 300: loss 0.592380\n",
      "iteration 188 / 300: loss 0.593618\n",
      "iteration 188 / 300: loss 0.595295\n",
      "iteration 188 / 300: loss 0.608784\n",
      "iteration 188 / 300: loss 0.592732\n",
      "iteration 188 / 300: loss 0.628060\n",
      "iteration 188 / 300: loss 0.580152\n",
      "iteration 188 / 300: loss 0.607923\n",
      "iteration 188 / 300: loss 0.587394\n",
      "iteration 188 / 300: loss 0.591686\n",
      "iteration 188 / 300: loss 0.571370\n",
      "iteration 188 / 300: loss 0.583025\n",
      "iteration 188 / 300: loss 0.608441\n",
      "iteration 188 / 300: loss 0.598359\n",
      "iteration 188 / 300: loss 0.583858\n",
      "iteration 188 / 300: loss 0.615253\n",
      "iteration 188 / 300: loss 0.591649\n",
      "iteration 188 / 300: loss 0.585499\n",
      "iteration 188 / 300: loss 0.591325\n",
      "iteration 188 / 300: loss 0.604341\n",
      "iteration 188 / 300: loss 0.595786\n",
      "iteration 188 / 300: loss 0.614949\n",
      "iteration 188 / 300: loss 0.608389\n",
      "iteration 188 / 300: loss 0.598222\n",
      "iteration 188 / 300: loss 0.588936\n",
      "iteration 188 / 300: loss 0.617757\n",
      "iteration 188 / 300: loss 0.594770\n",
      "iteration 188 / 300: loss 0.601684\n",
      "iteration 188 / 300: loss 0.631031\n",
      "iteration 188 / 300: loss 0.587513\n",
      "iteration 188 / 300: loss 0.606561\n",
      "iteration 188 / 300: loss 0.588034\n",
      "iteration 188 / 300: loss 0.600890\n",
      "iteration 188 / 300: loss 0.595958\n",
      "iteration 188 / 300: loss 0.589291\n",
      "iteration 188 / 300: loss 0.599526\n",
      "iteration 188 / 300: loss 0.604855\n",
      "iteration 188 / 300: loss 0.619414\n",
      "iteration 188 / 300: loss 0.588808\n",
      "iteration 188 / 300: loss 0.593645\n",
      "iteration 188 / 300: loss 0.585595\n",
      "iteration 188 / 300: loss 0.613212\n",
      "iteration 188 / 300: loss 0.587523\n",
      "iteration 188 / 300: loss 0.578328\n",
      "iteration 188 / 300: loss 0.567435\n",
      "iteration 188 / 300: loss 0.562235\n",
      "iteration 188 / 300: loss 0.594183\n",
      "iteration 188 / 300: loss 0.578821\n",
      "iteration 188 / 300: loss 0.586360\n",
      "iteration 188 / 300: loss 0.572890\n",
      "iteration 188 / 300: loss 0.596151\n",
      "iteration 188 / 300: loss 0.607951\n",
      "iteration 188 / 300: loss 0.610839\n",
      "iteration 188 / 300: loss 0.606265\n",
      "iteration 188 / 300: loss 0.583790\n",
      "iteration 188 / 300: loss 0.589627\n",
      "iteration 188 / 300: loss 0.595184\n",
      "iteration 188 / 300: loss 0.598955\n",
      "iteration 188 / 300: loss 0.596133\n",
      "iteration 188 / 300: loss 0.589769\n",
      "iteration 188 / 300: loss 0.591136\n",
      "iteration 188 / 300: loss 0.584854\n",
      "iteration 188 / 300: loss 0.599646\n",
      "iteration 188 / 300: loss 0.598902\n",
      "iteration 188 / 300: loss 0.614282\n",
      "iteration 188 / 300: loss 0.597796\n",
      "iteration 188 / 300: loss 0.599298\n",
      "iteration 188 / 300: loss 0.603317\n",
      "iteration 188 / 300: loss 0.592865\n",
      "iteration 188 / 300: loss 0.592391\n",
      "iteration 188 / 300: loss 0.589041\n",
      "iteration 188 / 300: loss 0.596446\n",
      "iteration 188 / 300: loss 0.605709\n",
      "iteration 188 / 300: loss 0.610562\n",
      "iteration 188 / 300: loss 0.587782\n",
      "iteration 188 / 300: loss 0.599351\n",
      "iteration 188 / 300: loss 0.602792\n",
      "iteration 188 / 300: loss 0.605028\n",
      "iteration 188 / 300: loss 0.603848\n",
      "iteration 188 / 300: loss 0.624144\n",
      "iteration 188 / 300: loss 0.587219\n",
      "iteration 188 / 300: loss 0.580754\n",
      "iteration 188 / 300: loss 0.625045\n",
      "iteration 188 / 300: loss 0.603310\n",
      "iteration 188 / 300: loss 0.604321\n",
      "iteration 188 / 300: loss 0.595476\n",
      "iteration 188 / 300: loss 0.597543\n",
      "iteration 188 / 300: loss 0.592740\n",
      "iteration 188 / 300: loss 0.589494\n",
      "iteration 188 / 300: loss 0.599264\n",
      "iteration 188 / 300: loss 0.611380\n",
      "iteration 188 / 300: loss 0.592463\n",
      "iteration 188 / 300: loss 0.599424\n",
      "iteration 188 / 300: loss 0.603100\n",
      "iteration 188 / 300: loss 0.602410\n",
      "iteration 188 / 300: loss 0.579811\n",
      "iteration 188 / 300: loss 0.601592\n",
      "iteration 189 / 300: loss 0.585528\n",
      "iteration 189 / 300: loss 0.588428\n",
      "iteration 189 / 300: loss 0.567516\n",
      "iteration 189 / 300: loss 0.592380\n",
      "iteration 189 / 300: loss 0.593618\n",
      "iteration 189 / 300: loss 0.595295\n",
      "iteration 189 / 300: loss 0.608784\n",
      "iteration 189 / 300: loss 0.592732\n",
      "iteration 189 / 300: loss 0.628060\n",
      "iteration 189 / 300: loss 0.580152\n",
      "iteration 189 / 300: loss 0.607923\n",
      "iteration 189 / 300: loss 0.587394\n",
      "iteration 189 / 300: loss 0.591686\n",
      "iteration 189 / 300: loss 0.571370\n",
      "iteration 189 / 300: loss 0.583025\n",
      "iteration 189 / 300: loss 0.608441\n",
      "iteration 189 / 300: loss 0.598359\n",
      "iteration 189 / 300: loss 0.583858\n",
      "iteration 189 / 300: loss 0.615253\n",
      "iteration 189 / 300: loss 0.591649\n",
      "iteration 189 / 300: loss 0.585499\n",
      "iteration 189 / 300: loss 0.591325\n",
      "iteration 189 / 300: loss 0.604341\n",
      "iteration 189 / 300: loss 0.595786\n",
      "iteration 189 / 300: loss 0.614949\n",
      "iteration 189 / 300: loss 0.608389\n",
      "iteration 189 / 300: loss 0.598222\n",
      "iteration 189 / 300: loss 0.588936\n",
      "iteration 189 / 300: loss 0.617757\n",
      "iteration 189 / 300: loss 0.594770\n",
      "iteration 189 / 300: loss 0.601684\n",
      "iteration 189 / 300: loss 0.631031\n",
      "iteration 189 / 300: loss 0.587513\n",
      "iteration 189 / 300: loss 0.606561\n",
      "iteration 189 / 300: loss 0.588034\n",
      "iteration 189 / 300: loss 0.600890\n",
      "iteration 189 / 300: loss 0.595958\n",
      "iteration 189 / 300: loss 0.589291\n",
      "iteration 189 / 300: loss 0.599526\n",
      "iteration 189 / 300: loss 0.604855\n",
      "iteration 189 / 300: loss 0.619414\n",
      "iteration 189 / 300: loss 0.588808\n",
      "iteration 189 / 300: loss 0.593645\n",
      "iteration 189 / 300: loss 0.585595\n",
      "iteration 189 / 300: loss 0.613212\n",
      "iteration 189 / 300: loss 0.587523\n",
      "iteration 189 / 300: loss 0.578328\n",
      "iteration 189 / 300: loss 0.567435\n",
      "iteration 189 / 300: loss 0.562235\n",
      "iteration 189 / 300: loss 0.594183\n",
      "iteration 189 / 300: loss 0.578821\n",
      "iteration 189 / 300: loss 0.586360\n",
      "iteration 189 / 300: loss 0.572890\n",
      "iteration 189 / 300: loss 0.596151\n",
      "iteration 189 / 300: loss 0.607951\n",
      "iteration 189 / 300: loss 0.610839\n",
      "iteration 189 / 300: loss 0.606265\n",
      "iteration 189 / 300: loss 0.583790\n",
      "iteration 189 / 300: loss 0.589627\n",
      "iteration 189 / 300: loss 0.595184\n",
      "iteration 189 / 300: loss 0.598955\n",
      "iteration 189 / 300: loss 0.596133\n",
      "iteration 189 / 300: loss 0.589769\n",
      "iteration 189 / 300: loss 0.591136\n",
      "iteration 189 / 300: loss 0.584854\n",
      "iteration 189 / 300: loss 0.599646\n",
      "iteration 189 / 300: loss 0.598902\n",
      "iteration 189 / 300: loss 0.614282\n",
      "iteration 189 / 300: loss 0.597796\n",
      "iteration 189 / 300: loss 0.599298\n",
      "iteration 189 / 300: loss 0.603317\n",
      "iteration 189 / 300: loss 0.592865\n",
      "iteration 189 / 300: loss 0.592391\n",
      "iteration 189 / 300: loss 0.589041\n",
      "iteration 189 / 300: loss 0.596446\n",
      "iteration 189 / 300: loss 0.605709\n",
      "iteration 189 / 300: loss 0.610562\n",
      "iteration 189 / 300: loss 0.587782\n",
      "iteration 189 / 300: loss 0.599351\n",
      "iteration 189 / 300: loss 0.602792\n",
      "iteration 189 / 300: loss 0.605028\n",
      "iteration 189 / 300: loss 0.603848\n",
      "iteration 189 / 300: loss 0.624144\n",
      "iteration 189 / 300: loss 0.587219\n",
      "iteration 189 / 300: loss 0.580754\n",
      "iteration 189 / 300: loss 0.625045\n",
      "iteration 189 / 300: loss 0.603310\n",
      "iteration 189 / 300: loss 0.604321\n",
      "iteration 189 / 300: loss 0.595476\n",
      "iteration 189 / 300: loss 0.597543\n",
      "iteration 189 / 300: loss 0.592740\n",
      "iteration 189 / 300: loss 0.589494\n",
      "iteration 189 / 300: loss 0.599264\n",
      "iteration 189 / 300: loss 0.611380\n",
      "iteration 189 / 300: loss 0.592463\n",
      "iteration 189 / 300: loss 0.599424\n",
      "iteration 189 / 300: loss 0.603100\n",
      "iteration 189 / 300: loss 0.602410\n",
      "iteration 189 / 300: loss 0.579811\n",
      "iteration 189 / 300: loss 0.601592\n",
      "iteration 190 / 300: loss 0.585528\n",
      "iteration 190 / 300: loss 0.588428\n",
      "iteration 190 / 300: loss 0.567516\n",
      "iteration 190 / 300: loss 0.592380\n",
      "iteration 190 / 300: loss 0.593618\n",
      "iteration 190 / 300: loss 0.595295\n",
      "iteration 190 / 300: loss 0.608784\n",
      "iteration 190 / 300: loss 0.592732\n",
      "iteration 190 / 300: loss 0.628060\n",
      "iteration 190 / 300: loss 0.580152\n",
      "iteration 190 / 300: loss 0.607923\n",
      "iteration 190 / 300: loss 0.587394\n",
      "iteration 190 / 300: loss 0.591686\n",
      "iteration 190 / 300: loss 0.571370\n",
      "iteration 190 / 300: loss 0.583025\n",
      "iteration 190 / 300: loss 0.608441\n",
      "iteration 190 / 300: loss 0.598359\n",
      "iteration 190 / 300: loss 0.583858\n",
      "iteration 190 / 300: loss 0.615253\n",
      "iteration 190 / 300: loss 0.591649\n",
      "iteration 190 / 300: loss 0.585499\n",
      "iteration 190 / 300: loss 0.591325\n",
      "iteration 190 / 300: loss 0.604341\n",
      "iteration 190 / 300: loss 0.595786\n",
      "iteration 190 / 300: loss 0.614949\n",
      "iteration 190 / 300: loss 0.608389\n",
      "iteration 190 / 300: loss 0.598222\n",
      "iteration 190 / 300: loss 0.588936\n",
      "iteration 190 / 300: loss 0.617757\n",
      "iteration 190 / 300: loss 0.594770\n",
      "iteration 190 / 300: loss 0.601684\n",
      "iteration 190 / 300: loss 0.631031\n",
      "iteration 190 / 300: loss 0.587513\n",
      "iteration 190 / 300: loss 0.606561\n",
      "iteration 190 / 300: loss 0.588034\n",
      "iteration 190 / 300: loss 0.600890\n",
      "iteration 190 / 300: loss 0.595958\n",
      "iteration 190 / 300: loss 0.589291\n",
      "iteration 190 / 300: loss 0.599526\n",
      "iteration 190 / 300: loss 0.604855\n",
      "iteration 190 / 300: loss 0.619414\n",
      "iteration 190 / 300: loss 0.588808\n",
      "iteration 190 / 300: loss 0.593645\n",
      "iteration 190 / 300: loss 0.585595\n",
      "iteration 190 / 300: loss 0.613212\n",
      "iteration 190 / 300: loss 0.587523\n",
      "iteration 190 / 300: loss 0.578328\n",
      "iteration 190 / 300: loss 0.567435\n",
      "iteration 190 / 300: loss 0.562235\n",
      "iteration 190 / 300: loss 0.594183\n",
      "iteration 190 / 300: loss 0.578821\n",
      "iteration 190 / 300: loss 0.586360\n",
      "iteration 190 / 300: loss 0.572890\n",
      "iteration 190 / 300: loss 0.596151\n",
      "iteration 190 / 300: loss 0.607951\n",
      "iteration 190 / 300: loss 0.610839\n",
      "iteration 190 / 300: loss 0.606265\n",
      "iteration 190 / 300: loss 0.583790\n",
      "iteration 190 / 300: loss 0.589627\n",
      "iteration 190 / 300: loss 0.595184\n",
      "iteration 190 / 300: loss 0.598955\n",
      "iteration 190 / 300: loss 0.596133\n",
      "iteration 190 / 300: loss 0.589769\n",
      "iteration 190 / 300: loss 0.591136\n",
      "iteration 190 / 300: loss 0.584854\n",
      "iteration 190 / 300: loss 0.599646\n",
      "iteration 190 / 300: loss 0.598902\n",
      "iteration 190 / 300: loss 0.614282\n",
      "iteration 190 / 300: loss 0.597796\n",
      "iteration 190 / 300: loss 0.599298\n",
      "iteration 190 / 300: loss 0.603317\n",
      "iteration 190 / 300: loss 0.592865\n",
      "iteration 190 / 300: loss 0.592391\n",
      "iteration 190 / 300: loss 0.589041\n",
      "iteration 190 / 300: loss 0.596446\n",
      "iteration 190 / 300: loss 0.605709\n",
      "iteration 190 / 300: loss 0.610562\n",
      "iteration 190 / 300: loss 0.587782\n",
      "iteration 190 / 300: loss 0.599351\n",
      "iteration 190 / 300: loss 0.602792\n",
      "iteration 190 / 300: loss 0.605028\n",
      "iteration 190 / 300: loss 0.603848\n",
      "iteration 190 / 300: loss 0.624144\n",
      "iteration 190 / 300: loss 0.587219\n",
      "iteration 190 / 300: loss 0.580754\n",
      "iteration 190 / 300: loss 0.625045\n",
      "iteration 190 / 300: loss 0.603310\n",
      "iteration 190 / 300: loss 0.604321\n",
      "iteration 190 / 300: loss 0.595476\n",
      "iteration 190 / 300: loss 0.597543\n",
      "iteration 190 / 300: loss 0.592740\n",
      "iteration 190 / 300: loss 0.589494\n",
      "iteration 190 / 300: loss 0.599264\n",
      "iteration 190 / 300: loss 0.611380\n",
      "iteration 190 / 300: loss 0.592463\n",
      "iteration 190 / 300: loss 0.599424\n",
      "iteration 190 / 300: loss 0.603100\n",
      "iteration 190 / 300: loss 0.602410\n",
      "iteration 190 / 300: loss 0.579811\n",
      "iteration 190 / 300: loss 0.601592\n",
      "iteration 191 / 300: loss 0.585528\n",
      "iteration 191 / 300: loss 0.588428\n",
      "iteration 191 / 300: loss 0.567516\n",
      "iteration 191 / 300: loss 0.592380\n",
      "iteration 191 / 300: loss 0.593618\n",
      "iteration 191 / 300: loss 0.595295\n",
      "iteration 191 / 300: loss 0.608784\n",
      "iteration 191 / 300: loss 0.592732\n",
      "iteration 191 / 300: loss 0.628060\n",
      "iteration 191 / 300: loss 0.580152\n",
      "iteration 191 / 300: loss 0.607923\n",
      "iteration 191 / 300: loss 0.587394\n",
      "iteration 191 / 300: loss 0.591686\n",
      "iteration 191 / 300: loss 0.571370\n",
      "iteration 191 / 300: loss 0.583025\n",
      "iteration 191 / 300: loss 0.608441\n",
      "iteration 191 / 300: loss 0.598359\n",
      "iteration 191 / 300: loss 0.583858\n",
      "iteration 191 / 300: loss 0.615253\n",
      "iteration 191 / 300: loss 0.591649\n",
      "iteration 191 / 300: loss 0.585499\n",
      "iteration 191 / 300: loss 0.591325\n",
      "iteration 191 / 300: loss 0.604341\n",
      "iteration 191 / 300: loss 0.595786\n",
      "iteration 191 / 300: loss 0.614949\n",
      "iteration 191 / 300: loss 0.608389\n",
      "iteration 191 / 300: loss 0.598222\n",
      "iteration 191 / 300: loss 0.588936\n",
      "iteration 191 / 300: loss 0.617757\n",
      "iteration 191 / 300: loss 0.594770\n",
      "iteration 191 / 300: loss 0.601684\n",
      "iteration 191 / 300: loss 0.631031\n",
      "iteration 191 / 300: loss 0.587513\n",
      "iteration 191 / 300: loss 0.606561\n",
      "iteration 191 / 300: loss 0.588034\n",
      "iteration 191 / 300: loss 0.600890\n",
      "iteration 191 / 300: loss 0.595958\n",
      "iteration 191 / 300: loss 0.589291\n",
      "iteration 191 / 300: loss 0.599526\n",
      "iteration 191 / 300: loss 0.604855\n",
      "iteration 191 / 300: loss 0.619414\n",
      "iteration 191 / 300: loss 0.588808\n",
      "iteration 191 / 300: loss 0.593645\n",
      "iteration 191 / 300: loss 0.585595\n",
      "iteration 191 / 300: loss 0.613212\n",
      "iteration 191 / 300: loss 0.587523\n",
      "iteration 191 / 300: loss 0.578328\n",
      "iteration 191 / 300: loss 0.567435\n",
      "iteration 191 / 300: loss 0.562235\n",
      "iteration 191 / 300: loss 0.594183\n",
      "iteration 191 / 300: loss 0.578821\n",
      "iteration 191 / 300: loss 0.586360\n",
      "iteration 191 / 300: loss 0.572890\n",
      "iteration 191 / 300: loss 0.596151\n",
      "iteration 191 / 300: loss 0.607951\n",
      "iteration 191 / 300: loss 0.610839\n",
      "iteration 191 / 300: loss 0.606265\n",
      "iteration 191 / 300: loss 0.583790\n",
      "iteration 191 / 300: loss 0.589627\n",
      "iteration 191 / 300: loss 0.595184\n",
      "iteration 191 / 300: loss 0.598955\n",
      "iteration 191 / 300: loss 0.596133\n",
      "iteration 191 / 300: loss 0.589769\n",
      "iteration 191 / 300: loss 0.591136\n",
      "iteration 191 / 300: loss 0.584854\n",
      "iteration 191 / 300: loss 0.599646\n",
      "iteration 191 / 300: loss 0.598902\n",
      "iteration 191 / 300: loss 0.614282\n",
      "iteration 191 / 300: loss 0.597796\n",
      "iteration 191 / 300: loss 0.599298\n",
      "iteration 191 / 300: loss 0.603317\n",
      "iteration 191 / 300: loss 0.592865\n",
      "iteration 191 / 300: loss 0.592391\n",
      "iteration 191 / 300: loss 0.589041\n",
      "iteration 191 / 300: loss 0.596446\n",
      "iteration 191 / 300: loss 0.605709\n",
      "iteration 191 / 300: loss 0.610562\n",
      "iteration 191 / 300: loss 0.587782\n",
      "iteration 191 / 300: loss 0.599351\n",
      "iteration 191 / 300: loss 0.602792\n",
      "iteration 191 / 300: loss 0.605028\n",
      "iteration 191 / 300: loss 0.603848\n",
      "iteration 191 / 300: loss 0.624144\n",
      "iteration 191 / 300: loss 0.587219\n",
      "iteration 191 / 300: loss 0.580754\n",
      "iteration 191 / 300: loss 0.625045\n",
      "iteration 191 / 300: loss 0.603310\n",
      "iteration 191 / 300: loss 0.604321\n",
      "iteration 191 / 300: loss 0.595476\n",
      "iteration 191 / 300: loss 0.597543\n",
      "iteration 191 / 300: loss 0.592740\n",
      "iteration 191 / 300: loss 0.589494\n",
      "iteration 191 / 300: loss 0.599264\n",
      "iteration 191 / 300: loss 0.611380\n",
      "iteration 191 / 300: loss 0.592463\n",
      "iteration 191 / 300: loss 0.599424\n",
      "iteration 191 / 300: loss 0.603100\n",
      "iteration 191 / 300: loss 0.602410\n",
      "iteration 191 / 300: loss 0.579811\n",
      "iteration 191 / 300: loss 0.601592\n",
      "iteration 192 / 300: loss 0.585528\n",
      "iteration 192 / 300: loss 0.588428\n",
      "iteration 192 / 300: loss 0.567516\n",
      "iteration 192 / 300: loss 0.592380\n",
      "iteration 192 / 300: loss 0.593618\n",
      "iteration 192 / 300: loss 0.595295\n",
      "iteration 192 / 300: loss 0.608784\n",
      "iteration 192 / 300: loss 0.592732\n",
      "iteration 192 / 300: loss 0.628060\n",
      "iteration 192 / 300: loss 0.580152\n",
      "iteration 192 / 300: loss 0.607923\n",
      "iteration 192 / 300: loss 0.587394\n",
      "iteration 192 / 300: loss 0.591686\n",
      "iteration 192 / 300: loss 0.571370\n",
      "iteration 192 / 300: loss 0.583025\n",
      "iteration 192 / 300: loss 0.608441\n",
      "iteration 192 / 300: loss 0.598359\n",
      "iteration 192 / 300: loss 0.583858\n",
      "iteration 192 / 300: loss 0.615253\n",
      "iteration 192 / 300: loss 0.591649\n",
      "iteration 192 / 300: loss 0.585499\n",
      "iteration 192 / 300: loss 0.591325\n",
      "iteration 192 / 300: loss 0.604341\n",
      "iteration 192 / 300: loss 0.595786\n",
      "iteration 192 / 300: loss 0.614949\n",
      "iteration 192 / 300: loss 0.608389\n",
      "iteration 192 / 300: loss 0.598222\n",
      "iteration 192 / 300: loss 0.588936\n",
      "iteration 192 / 300: loss 0.617757\n",
      "iteration 192 / 300: loss 0.594770\n",
      "iteration 192 / 300: loss 0.601684\n",
      "iteration 192 / 300: loss 0.631031\n",
      "iteration 192 / 300: loss 0.587513\n",
      "iteration 192 / 300: loss 0.606561\n",
      "iteration 192 / 300: loss 0.588034\n",
      "iteration 192 / 300: loss 0.600890\n",
      "iteration 192 / 300: loss 0.595958\n",
      "iteration 192 / 300: loss 0.589291\n",
      "iteration 192 / 300: loss 0.599526\n",
      "iteration 192 / 300: loss 0.604855\n",
      "iteration 192 / 300: loss 0.619414\n",
      "iteration 192 / 300: loss 0.588808\n",
      "iteration 192 / 300: loss 0.593645\n",
      "iteration 192 / 300: loss 0.585595\n",
      "iteration 192 / 300: loss 0.613212\n",
      "iteration 192 / 300: loss 0.587523\n",
      "iteration 192 / 300: loss 0.578328\n",
      "iteration 192 / 300: loss 0.567435\n",
      "iteration 192 / 300: loss 0.562235\n",
      "iteration 192 / 300: loss 0.594183\n",
      "iteration 192 / 300: loss 0.578821\n",
      "iteration 192 / 300: loss 0.586360\n",
      "iteration 192 / 300: loss 0.572890\n",
      "iteration 192 / 300: loss 0.596151\n",
      "iteration 192 / 300: loss 0.607951\n",
      "iteration 192 / 300: loss 0.610839\n",
      "iteration 192 / 300: loss 0.606265\n",
      "iteration 192 / 300: loss 0.583790\n",
      "iteration 192 / 300: loss 0.589627\n",
      "iteration 192 / 300: loss 0.595184\n",
      "iteration 192 / 300: loss 0.598955\n",
      "iteration 192 / 300: loss 0.596133\n",
      "iteration 192 / 300: loss 0.589769\n",
      "iteration 192 / 300: loss 0.591136\n",
      "iteration 192 / 300: loss 0.584854\n",
      "iteration 192 / 300: loss 0.599646\n",
      "iteration 192 / 300: loss 0.598902\n",
      "iteration 192 / 300: loss 0.614282\n",
      "iteration 192 / 300: loss 0.597796\n",
      "iteration 192 / 300: loss 0.599298\n",
      "iteration 192 / 300: loss 0.603317\n",
      "iteration 192 / 300: loss 0.592865\n",
      "iteration 192 / 300: loss 0.592391\n",
      "iteration 192 / 300: loss 0.589041\n",
      "iteration 192 / 300: loss 0.596446\n",
      "iteration 192 / 300: loss 0.605709\n",
      "iteration 192 / 300: loss 0.610562\n",
      "iteration 192 / 300: loss 0.587782\n",
      "iteration 192 / 300: loss 0.599351\n",
      "iteration 192 / 300: loss 0.602792\n",
      "iteration 192 / 300: loss 0.605028\n",
      "iteration 192 / 300: loss 0.603848\n",
      "iteration 192 / 300: loss 0.624144\n",
      "iteration 192 / 300: loss 0.587219\n",
      "iteration 192 / 300: loss 0.580754\n",
      "iteration 192 / 300: loss 0.625045\n",
      "iteration 192 / 300: loss 0.603310\n",
      "iteration 192 / 300: loss 0.604321\n",
      "iteration 192 / 300: loss 0.595476\n",
      "iteration 192 / 300: loss 0.597543\n",
      "iteration 192 / 300: loss 0.592740\n",
      "iteration 192 / 300: loss 0.589494\n",
      "iteration 192 / 300: loss 0.599264\n",
      "iteration 192 / 300: loss 0.611380\n",
      "iteration 192 / 300: loss 0.592463\n",
      "iteration 192 / 300: loss 0.599424\n",
      "iteration 192 / 300: loss 0.603100\n",
      "iteration 192 / 300: loss 0.602410\n",
      "iteration 192 / 300: loss 0.579811\n",
      "iteration 192 / 300: loss 0.601592\n",
      "iteration 193 / 300: loss 0.585528\n",
      "iteration 193 / 300: loss 0.588428\n",
      "iteration 193 / 300: loss 0.567516\n",
      "iteration 193 / 300: loss 0.592380\n",
      "iteration 193 / 300: loss 0.593618\n",
      "iteration 193 / 300: loss 0.595295\n",
      "iteration 193 / 300: loss 0.608784\n",
      "iteration 193 / 300: loss 0.592732\n",
      "iteration 193 / 300: loss 0.628060\n",
      "iteration 193 / 300: loss 0.580152\n",
      "iteration 193 / 300: loss 0.607923\n",
      "iteration 193 / 300: loss 0.587394\n",
      "iteration 193 / 300: loss 0.591686\n",
      "iteration 193 / 300: loss 0.571370\n",
      "iteration 193 / 300: loss 0.583025\n",
      "iteration 193 / 300: loss 0.608441\n",
      "iteration 193 / 300: loss 0.598359\n",
      "iteration 193 / 300: loss 0.583858\n",
      "iteration 193 / 300: loss 0.615253\n",
      "iteration 193 / 300: loss 0.591649\n",
      "iteration 193 / 300: loss 0.585499\n",
      "iteration 193 / 300: loss 0.591325\n",
      "iteration 193 / 300: loss 0.604341\n",
      "iteration 193 / 300: loss 0.595786\n",
      "iteration 193 / 300: loss 0.614949\n",
      "iteration 193 / 300: loss 0.608389\n",
      "iteration 193 / 300: loss 0.598222\n",
      "iteration 193 / 300: loss 0.588936\n",
      "iteration 193 / 300: loss 0.617757\n",
      "iteration 193 / 300: loss 0.594770\n",
      "iteration 193 / 300: loss 0.601684\n",
      "iteration 193 / 300: loss 0.631031\n",
      "iteration 193 / 300: loss 0.587513\n",
      "iteration 193 / 300: loss 0.606561\n",
      "iteration 193 / 300: loss 0.588034\n",
      "iteration 193 / 300: loss 0.600890\n",
      "iteration 193 / 300: loss 0.595958\n",
      "iteration 193 / 300: loss 0.589291\n",
      "iteration 193 / 300: loss 0.599526\n",
      "iteration 193 / 300: loss 0.604855\n",
      "iteration 193 / 300: loss 0.619414\n",
      "iteration 193 / 300: loss 0.588808\n",
      "iteration 193 / 300: loss 0.593645\n",
      "iteration 193 / 300: loss 0.585595\n",
      "iteration 193 / 300: loss 0.613212\n",
      "iteration 193 / 300: loss 0.587523\n",
      "iteration 193 / 300: loss 0.578328\n",
      "iteration 193 / 300: loss 0.567435\n",
      "iteration 193 / 300: loss 0.562235\n",
      "iteration 193 / 300: loss 0.594183\n",
      "iteration 193 / 300: loss 0.578821\n",
      "iteration 193 / 300: loss 0.586360\n",
      "iteration 193 / 300: loss 0.572890\n",
      "iteration 193 / 300: loss 0.596151\n",
      "iteration 193 / 300: loss 0.607951\n",
      "iteration 193 / 300: loss 0.610839\n",
      "iteration 193 / 300: loss 0.606265\n",
      "iteration 193 / 300: loss 0.583790\n",
      "iteration 193 / 300: loss 0.589627\n",
      "iteration 193 / 300: loss 0.595184\n",
      "iteration 193 / 300: loss 0.598955\n",
      "iteration 193 / 300: loss 0.596133\n",
      "iteration 193 / 300: loss 0.589769\n",
      "iteration 193 / 300: loss 0.591136\n",
      "iteration 193 / 300: loss 0.584854\n",
      "iteration 193 / 300: loss 0.599646\n",
      "iteration 193 / 300: loss 0.598902\n",
      "iteration 193 / 300: loss 0.614282\n",
      "iteration 193 / 300: loss 0.597796\n",
      "iteration 193 / 300: loss 0.599298\n",
      "iteration 193 / 300: loss 0.603317\n",
      "iteration 193 / 300: loss 0.592865\n",
      "iteration 193 / 300: loss 0.592391\n",
      "iteration 193 / 300: loss 0.589041\n",
      "iteration 193 / 300: loss 0.596446\n",
      "iteration 193 / 300: loss 0.605709\n",
      "iteration 193 / 300: loss 0.610562\n",
      "iteration 193 / 300: loss 0.587782\n",
      "iteration 193 / 300: loss 0.599351\n",
      "iteration 193 / 300: loss 0.602792\n",
      "iteration 193 / 300: loss 0.605028\n",
      "iteration 193 / 300: loss 0.603848\n",
      "iteration 193 / 300: loss 0.624144\n",
      "iteration 193 / 300: loss 0.587219\n",
      "iteration 193 / 300: loss 0.580754\n",
      "iteration 193 / 300: loss 0.625045\n",
      "iteration 193 / 300: loss 0.603310\n",
      "iteration 193 / 300: loss 0.604321\n",
      "iteration 193 / 300: loss 0.595476\n",
      "iteration 193 / 300: loss 0.597543\n",
      "iteration 193 / 300: loss 0.592740\n",
      "iteration 193 / 300: loss 0.589494\n",
      "iteration 193 / 300: loss 0.599264\n",
      "iteration 193 / 300: loss 0.611380\n",
      "iteration 193 / 300: loss 0.592463\n",
      "iteration 193 / 300: loss 0.599424\n",
      "iteration 193 / 300: loss 0.603100\n",
      "iteration 193 / 300: loss 0.602410\n",
      "iteration 193 / 300: loss 0.579811\n",
      "iteration 193 / 300: loss 0.601592\n",
      "iteration 194 / 300: loss 0.585528\n",
      "iteration 194 / 300: loss 0.588428\n",
      "iteration 194 / 300: loss 0.567516\n",
      "iteration 194 / 300: loss 0.592380\n",
      "iteration 194 / 300: loss 0.593618\n",
      "iteration 194 / 300: loss 0.595295\n",
      "iteration 194 / 300: loss 0.608784\n",
      "iteration 194 / 300: loss 0.592732\n",
      "iteration 194 / 300: loss 0.628060\n",
      "iteration 194 / 300: loss 0.580152\n",
      "iteration 194 / 300: loss 0.607923\n",
      "iteration 194 / 300: loss 0.587394\n",
      "iteration 194 / 300: loss 0.591686\n",
      "iteration 194 / 300: loss 0.571370\n",
      "iteration 194 / 300: loss 0.583025\n",
      "iteration 194 / 300: loss 0.608441\n",
      "iteration 194 / 300: loss 0.598359\n",
      "iteration 194 / 300: loss 0.583858\n",
      "iteration 194 / 300: loss 0.615253\n",
      "iteration 194 / 300: loss 0.591649\n",
      "iteration 194 / 300: loss 0.585499\n",
      "iteration 194 / 300: loss 0.591325\n",
      "iteration 194 / 300: loss 0.604341\n",
      "iteration 194 / 300: loss 0.595786\n",
      "iteration 194 / 300: loss 0.614949\n",
      "iteration 194 / 300: loss 0.608389\n",
      "iteration 194 / 300: loss 0.598222\n",
      "iteration 194 / 300: loss 0.588936\n",
      "iteration 194 / 300: loss 0.617757\n",
      "iteration 194 / 300: loss 0.594770\n",
      "iteration 194 / 300: loss 0.601684\n",
      "iteration 194 / 300: loss 0.631031\n",
      "iteration 194 / 300: loss 0.587513\n",
      "iteration 194 / 300: loss 0.606561\n",
      "iteration 194 / 300: loss 0.588034\n",
      "iteration 194 / 300: loss 0.600890\n",
      "iteration 194 / 300: loss 0.595958\n",
      "iteration 194 / 300: loss 0.589291\n",
      "iteration 194 / 300: loss 0.599526\n",
      "iteration 194 / 300: loss 0.604855\n",
      "iteration 194 / 300: loss 0.619414\n",
      "iteration 194 / 300: loss 0.588808\n",
      "iteration 194 / 300: loss 0.593645\n",
      "iteration 194 / 300: loss 0.585595\n",
      "iteration 194 / 300: loss 0.613212\n",
      "iteration 194 / 300: loss 0.587523\n",
      "iteration 194 / 300: loss 0.578328\n",
      "iteration 194 / 300: loss 0.567435\n",
      "iteration 194 / 300: loss 0.562235\n",
      "iteration 194 / 300: loss 0.594183\n",
      "iteration 194 / 300: loss 0.578821\n",
      "iteration 194 / 300: loss 0.586360\n",
      "iteration 194 / 300: loss 0.572890\n",
      "iteration 194 / 300: loss 0.596151\n",
      "iteration 194 / 300: loss 0.607951\n",
      "iteration 194 / 300: loss 0.610839\n",
      "iteration 194 / 300: loss 0.606265\n",
      "iteration 194 / 300: loss 0.583790\n",
      "iteration 194 / 300: loss 0.589627\n",
      "iteration 194 / 300: loss 0.595184\n",
      "iteration 194 / 300: loss 0.598955\n",
      "iteration 194 / 300: loss 0.596133\n",
      "iteration 194 / 300: loss 0.589769\n",
      "iteration 194 / 300: loss 0.591136\n",
      "iteration 194 / 300: loss 0.584854\n",
      "iteration 194 / 300: loss 0.599646\n",
      "iteration 194 / 300: loss 0.598902\n",
      "iteration 194 / 300: loss 0.614282\n",
      "iteration 194 / 300: loss 0.597796\n",
      "iteration 194 / 300: loss 0.599298\n",
      "iteration 194 / 300: loss 0.603317\n",
      "iteration 194 / 300: loss 0.592865\n",
      "iteration 194 / 300: loss 0.592391\n",
      "iteration 194 / 300: loss 0.589041\n",
      "iteration 194 / 300: loss 0.596446\n",
      "iteration 194 / 300: loss 0.605709\n",
      "iteration 194 / 300: loss 0.610562\n",
      "iteration 194 / 300: loss 0.587782\n",
      "iteration 194 / 300: loss 0.599351\n",
      "iteration 194 / 300: loss 0.602792\n",
      "iteration 194 / 300: loss 0.605028\n",
      "iteration 194 / 300: loss 0.603848\n",
      "iteration 194 / 300: loss 0.624144\n",
      "iteration 194 / 300: loss 0.587219\n",
      "iteration 194 / 300: loss 0.580754\n",
      "iteration 194 / 300: loss 0.625045\n",
      "iteration 194 / 300: loss 0.603310\n",
      "iteration 194 / 300: loss 0.604321\n",
      "iteration 194 / 300: loss 0.595476\n",
      "iteration 194 / 300: loss 0.597543\n",
      "iteration 194 / 300: loss 0.592740\n",
      "iteration 194 / 300: loss 0.589494\n",
      "iteration 194 / 300: loss 0.599264\n",
      "iteration 194 / 300: loss 0.611380\n",
      "iteration 194 / 300: loss 0.592463\n",
      "iteration 194 / 300: loss 0.599424\n",
      "iteration 194 / 300: loss 0.603100\n",
      "iteration 194 / 300: loss 0.602410\n",
      "iteration 194 / 300: loss 0.579811\n",
      "iteration 194 / 300: loss 0.601592\n",
      "iteration 195 / 300: loss 0.585528\n",
      "iteration 195 / 300: loss 0.588428\n",
      "iteration 195 / 300: loss 0.567516\n",
      "iteration 195 / 300: loss 0.592380\n",
      "iteration 195 / 300: loss 0.593618\n",
      "iteration 195 / 300: loss 0.595295\n",
      "iteration 195 / 300: loss 0.608784\n",
      "iteration 195 / 300: loss 0.592732\n",
      "iteration 195 / 300: loss 0.628060\n",
      "iteration 195 / 300: loss 0.580152\n",
      "iteration 195 / 300: loss 0.607923\n",
      "iteration 195 / 300: loss 0.587394\n",
      "iteration 195 / 300: loss 0.591686\n",
      "iteration 195 / 300: loss 0.571370\n",
      "iteration 195 / 300: loss 0.583025\n",
      "iteration 195 / 300: loss 0.608441\n",
      "iteration 195 / 300: loss 0.598359\n",
      "iteration 195 / 300: loss 0.583858\n",
      "iteration 195 / 300: loss 0.615253\n",
      "iteration 195 / 300: loss 0.591649\n",
      "iteration 195 / 300: loss 0.585499\n",
      "iteration 195 / 300: loss 0.591325\n",
      "iteration 195 / 300: loss 0.604341\n",
      "iteration 195 / 300: loss 0.595786\n",
      "iteration 195 / 300: loss 0.614949\n",
      "iteration 195 / 300: loss 0.608389\n",
      "iteration 195 / 300: loss 0.598222\n",
      "iteration 195 / 300: loss 0.588936\n",
      "iteration 195 / 300: loss 0.617757\n",
      "iteration 195 / 300: loss 0.594770\n",
      "iteration 195 / 300: loss 0.601684\n",
      "iteration 195 / 300: loss 0.631031\n",
      "iteration 195 / 300: loss 0.587513\n",
      "iteration 195 / 300: loss 0.606561\n",
      "iteration 195 / 300: loss 0.588034\n",
      "iteration 195 / 300: loss 0.600890\n",
      "iteration 195 / 300: loss 0.595958\n",
      "iteration 195 / 300: loss 0.589291\n",
      "iteration 195 / 300: loss 0.599526\n",
      "iteration 195 / 300: loss 0.604855\n",
      "iteration 195 / 300: loss 0.619414\n",
      "iteration 195 / 300: loss 0.588808\n",
      "iteration 195 / 300: loss 0.593645\n",
      "iteration 195 / 300: loss 0.585595\n",
      "iteration 195 / 300: loss 0.613212\n",
      "iteration 195 / 300: loss 0.587523\n",
      "iteration 195 / 300: loss 0.578328\n",
      "iteration 195 / 300: loss 0.567435\n",
      "iteration 195 / 300: loss 0.562235\n",
      "iteration 195 / 300: loss 0.594183\n",
      "iteration 195 / 300: loss 0.578821\n",
      "iteration 195 / 300: loss 0.586360\n",
      "iteration 195 / 300: loss 0.572890\n",
      "iteration 195 / 300: loss 0.596151\n",
      "iteration 195 / 300: loss 0.607951\n",
      "iteration 195 / 300: loss 0.610839\n",
      "iteration 195 / 300: loss 0.606265\n",
      "iteration 195 / 300: loss 0.583790\n",
      "iteration 195 / 300: loss 0.589627\n",
      "iteration 195 / 300: loss 0.595184\n",
      "iteration 195 / 300: loss 0.598955\n",
      "iteration 195 / 300: loss 0.596133\n",
      "iteration 195 / 300: loss 0.589769\n",
      "iteration 195 / 300: loss 0.591136\n",
      "iteration 195 / 300: loss 0.584854\n",
      "iteration 195 / 300: loss 0.599646\n",
      "iteration 195 / 300: loss 0.598902\n",
      "iteration 195 / 300: loss 0.614282\n",
      "iteration 195 / 300: loss 0.597796\n",
      "iteration 195 / 300: loss 0.599298\n",
      "iteration 195 / 300: loss 0.603317\n",
      "iteration 195 / 300: loss 0.592865\n",
      "iteration 195 / 300: loss 0.592391\n",
      "iteration 195 / 300: loss 0.589041\n",
      "iteration 195 / 300: loss 0.596446\n",
      "iteration 195 / 300: loss 0.605709\n",
      "iteration 195 / 300: loss 0.610562\n",
      "iteration 195 / 300: loss 0.587782\n",
      "iteration 195 / 300: loss 0.599351\n",
      "iteration 195 / 300: loss 0.602792\n",
      "iteration 195 / 300: loss 0.605028\n",
      "iteration 195 / 300: loss 0.603848\n",
      "iteration 195 / 300: loss 0.624144\n",
      "iteration 195 / 300: loss 0.587219\n",
      "iteration 195 / 300: loss 0.580754\n",
      "iteration 195 / 300: loss 0.625045\n",
      "iteration 195 / 300: loss 0.603310\n",
      "iteration 195 / 300: loss 0.604321\n",
      "iteration 195 / 300: loss 0.595476\n",
      "iteration 195 / 300: loss 0.597543\n",
      "iteration 195 / 300: loss 0.592740\n",
      "iteration 195 / 300: loss 0.589494\n",
      "iteration 195 / 300: loss 0.599264\n",
      "iteration 195 / 300: loss 0.611380\n",
      "iteration 195 / 300: loss 0.592463\n",
      "iteration 195 / 300: loss 0.599424\n",
      "iteration 195 / 300: loss 0.603100\n",
      "iteration 195 / 300: loss 0.602410\n",
      "iteration 195 / 300: loss 0.579811\n",
      "iteration 195 / 300: loss 0.601592\n",
      "iteration 196 / 300: loss 0.585528\n",
      "iteration 196 / 300: loss 0.588428\n",
      "iteration 196 / 300: loss 0.567516\n",
      "iteration 196 / 300: loss 0.592380\n",
      "iteration 196 / 300: loss 0.593618\n",
      "iteration 196 / 300: loss 0.595295\n",
      "iteration 196 / 300: loss 0.608784\n",
      "iteration 196 / 300: loss 0.592732\n",
      "iteration 196 / 300: loss 0.628060\n",
      "iteration 196 / 300: loss 0.580152\n",
      "iteration 196 / 300: loss 0.607923\n",
      "iteration 196 / 300: loss 0.587394\n",
      "iteration 196 / 300: loss 0.591686\n",
      "iteration 196 / 300: loss 0.571370\n",
      "iteration 196 / 300: loss 0.583025\n",
      "iteration 196 / 300: loss 0.608441\n",
      "iteration 196 / 300: loss 0.598359\n",
      "iteration 196 / 300: loss 0.583858\n",
      "iteration 196 / 300: loss 0.615253\n",
      "iteration 196 / 300: loss 0.591649\n",
      "iteration 196 / 300: loss 0.585499\n",
      "iteration 196 / 300: loss 0.591325\n",
      "iteration 196 / 300: loss 0.604341\n",
      "iteration 196 / 300: loss 0.595786\n",
      "iteration 196 / 300: loss 0.614949\n",
      "iteration 196 / 300: loss 0.608389\n",
      "iteration 196 / 300: loss 0.598222\n",
      "iteration 196 / 300: loss 0.588936\n",
      "iteration 196 / 300: loss 0.617757\n",
      "iteration 196 / 300: loss 0.594770\n",
      "iteration 196 / 300: loss 0.601684\n",
      "iteration 196 / 300: loss 0.631031\n",
      "iteration 196 / 300: loss 0.587513\n",
      "iteration 196 / 300: loss 0.606561\n",
      "iteration 196 / 300: loss 0.588034\n",
      "iteration 196 / 300: loss 0.600890\n",
      "iteration 196 / 300: loss 0.595958\n",
      "iteration 196 / 300: loss 0.589291\n",
      "iteration 196 / 300: loss 0.599526\n",
      "iteration 196 / 300: loss 0.604855\n",
      "iteration 196 / 300: loss 0.619414\n",
      "iteration 196 / 300: loss 0.588808\n",
      "iteration 196 / 300: loss 0.593645\n",
      "iteration 196 / 300: loss 0.585595\n",
      "iteration 196 / 300: loss 0.613212\n",
      "iteration 196 / 300: loss 0.587523\n",
      "iteration 196 / 300: loss 0.578328\n",
      "iteration 196 / 300: loss 0.567435\n",
      "iteration 196 / 300: loss 0.562235\n",
      "iteration 196 / 300: loss 0.594183\n",
      "iteration 196 / 300: loss 0.578821\n",
      "iteration 196 / 300: loss 0.586360\n",
      "iteration 196 / 300: loss 0.572890\n",
      "iteration 196 / 300: loss 0.596151\n",
      "iteration 196 / 300: loss 0.607951\n",
      "iteration 196 / 300: loss 0.610839\n",
      "iteration 196 / 300: loss 0.606265\n",
      "iteration 196 / 300: loss 0.583790\n",
      "iteration 196 / 300: loss 0.589627\n",
      "iteration 196 / 300: loss 0.595184\n",
      "iteration 196 / 300: loss 0.598955\n",
      "iteration 196 / 300: loss 0.596133\n",
      "iteration 196 / 300: loss 0.589769\n",
      "iteration 196 / 300: loss 0.591136\n",
      "iteration 196 / 300: loss 0.584854\n",
      "iteration 196 / 300: loss 0.599646\n",
      "iteration 196 / 300: loss 0.598902\n",
      "iteration 196 / 300: loss 0.614282\n",
      "iteration 196 / 300: loss 0.597796\n",
      "iteration 196 / 300: loss 0.599298\n",
      "iteration 196 / 300: loss 0.603317\n",
      "iteration 196 / 300: loss 0.592865\n",
      "iteration 196 / 300: loss 0.592391\n",
      "iteration 196 / 300: loss 0.589041\n",
      "iteration 196 / 300: loss 0.596446\n",
      "iteration 196 / 300: loss 0.605709\n",
      "iteration 196 / 300: loss 0.610562\n",
      "iteration 196 / 300: loss 0.587782\n",
      "iteration 196 / 300: loss 0.599351\n",
      "iteration 196 / 300: loss 0.602792\n",
      "iteration 196 / 300: loss 0.605028\n",
      "iteration 196 / 300: loss 0.603848\n",
      "iteration 196 / 300: loss 0.624144\n",
      "iteration 196 / 300: loss 0.587219\n",
      "iteration 196 / 300: loss 0.580754\n",
      "iteration 196 / 300: loss 0.625045\n",
      "iteration 196 / 300: loss 0.603310\n",
      "iteration 196 / 300: loss 0.604321\n",
      "iteration 196 / 300: loss 0.595476\n",
      "iteration 196 / 300: loss 0.597543\n",
      "iteration 196 / 300: loss 0.592740\n",
      "iteration 196 / 300: loss 0.589494\n",
      "iteration 196 / 300: loss 0.599264\n",
      "iteration 196 / 300: loss 0.611380\n",
      "iteration 196 / 300: loss 0.592463\n",
      "iteration 196 / 300: loss 0.599424\n",
      "iteration 196 / 300: loss 0.603100\n",
      "iteration 196 / 300: loss 0.602410\n",
      "iteration 196 / 300: loss 0.579811\n",
      "iteration 196 / 300: loss 0.601592\n",
      "iteration 197 / 300: loss 0.585528\n",
      "iteration 197 / 300: loss 0.588428\n",
      "iteration 197 / 300: loss 0.567516\n",
      "iteration 197 / 300: loss 0.592380\n",
      "iteration 197 / 300: loss 0.593618\n",
      "iteration 197 / 300: loss 0.595295\n",
      "iteration 197 / 300: loss 0.608784\n",
      "iteration 197 / 300: loss 0.592732\n",
      "iteration 197 / 300: loss 0.628060\n",
      "iteration 197 / 300: loss 0.580152\n",
      "iteration 197 / 300: loss 0.607923\n",
      "iteration 197 / 300: loss 0.587394\n",
      "iteration 197 / 300: loss 0.591686\n",
      "iteration 197 / 300: loss 0.571370\n",
      "iteration 197 / 300: loss 0.583025\n",
      "iteration 197 / 300: loss 0.608441\n",
      "iteration 197 / 300: loss 0.598359\n",
      "iteration 197 / 300: loss 0.583858\n",
      "iteration 197 / 300: loss 0.615253\n",
      "iteration 197 / 300: loss 0.591649\n",
      "iteration 197 / 300: loss 0.585499\n",
      "iteration 197 / 300: loss 0.591325\n",
      "iteration 197 / 300: loss 0.604341\n",
      "iteration 197 / 300: loss 0.595786\n",
      "iteration 197 / 300: loss 0.614949\n",
      "iteration 197 / 300: loss 0.608389\n",
      "iteration 197 / 300: loss 0.598222\n",
      "iteration 197 / 300: loss 0.588936\n",
      "iteration 197 / 300: loss 0.617757\n",
      "iteration 197 / 300: loss 0.594770\n",
      "iteration 197 / 300: loss 0.601684\n",
      "iteration 197 / 300: loss 0.631031\n",
      "iteration 197 / 300: loss 0.587513\n",
      "iteration 197 / 300: loss 0.606561\n",
      "iteration 197 / 300: loss 0.588034\n",
      "iteration 197 / 300: loss 0.600890\n",
      "iteration 197 / 300: loss 0.595958\n",
      "iteration 197 / 300: loss 0.589291\n",
      "iteration 197 / 300: loss 0.599526\n",
      "iteration 197 / 300: loss 0.604855\n",
      "iteration 197 / 300: loss 0.619414\n",
      "iteration 197 / 300: loss 0.588808\n",
      "iteration 197 / 300: loss 0.593645\n",
      "iteration 197 / 300: loss 0.585595\n",
      "iteration 197 / 300: loss 0.613212\n",
      "iteration 197 / 300: loss 0.587523\n",
      "iteration 197 / 300: loss 0.578328\n",
      "iteration 197 / 300: loss 0.567435\n",
      "iteration 197 / 300: loss 0.562235\n",
      "iteration 197 / 300: loss 0.594183\n",
      "iteration 197 / 300: loss 0.578821\n",
      "iteration 197 / 300: loss 0.586360\n",
      "iteration 197 / 300: loss 0.572890\n",
      "iteration 197 / 300: loss 0.596151\n",
      "iteration 197 / 300: loss 0.607951\n",
      "iteration 197 / 300: loss 0.610839\n",
      "iteration 197 / 300: loss 0.606265\n",
      "iteration 197 / 300: loss 0.583790\n",
      "iteration 197 / 300: loss 0.589627\n",
      "iteration 197 / 300: loss 0.595184\n",
      "iteration 197 / 300: loss 0.598955\n",
      "iteration 197 / 300: loss 0.596133\n",
      "iteration 197 / 300: loss 0.589769\n",
      "iteration 197 / 300: loss 0.591136\n",
      "iteration 197 / 300: loss 0.584854\n",
      "iteration 197 / 300: loss 0.599646\n",
      "iteration 197 / 300: loss 0.598902\n",
      "iteration 197 / 300: loss 0.614282\n",
      "iteration 197 / 300: loss 0.597796\n",
      "iteration 197 / 300: loss 0.599298\n",
      "iteration 197 / 300: loss 0.603317\n",
      "iteration 197 / 300: loss 0.592865\n",
      "iteration 197 / 300: loss 0.592391\n",
      "iteration 197 / 300: loss 0.589041\n",
      "iteration 197 / 300: loss 0.596446\n",
      "iteration 197 / 300: loss 0.605709\n",
      "iteration 197 / 300: loss 0.610562\n",
      "iteration 197 / 300: loss 0.587782\n",
      "iteration 197 / 300: loss 0.599351\n",
      "iteration 197 / 300: loss 0.602792\n",
      "iteration 197 / 300: loss 0.605028\n",
      "iteration 197 / 300: loss 0.603848\n",
      "iteration 197 / 300: loss 0.624144\n",
      "iteration 197 / 300: loss 0.587219\n",
      "iteration 197 / 300: loss 0.580754\n",
      "iteration 197 / 300: loss 0.625045\n",
      "iteration 197 / 300: loss 0.603310\n",
      "iteration 197 / 300: loss 0.604321\n",
      "iteration 197 / 300: loss 0.595476\n",
      "iteration 197 / 300: loss 0.597543\n",
      "iteration 197 / 300: loss 0.592740\n",
      "iteration 197 / 300: loss 0.589494\n",
      "iteration 197 / 300: loss 0.599264\n",
      "iteration 197 / 300: loss 0.611380\n",
      "iteration 197 / 300: loss 0.592463\n",
      "iteration 197 / 300: loss 0.599424\n",
      "iteration 197 / 300: loss 0.603100\n",
      "iteration 197 / 300: loss 0.602410\n",
      "iteration 197 / 300: loss 0.579811\n",
      "iteration 197 / 300: loss 0.601592\n",
      "iteration 198 / 300: loss 0.585528\n",
      "iteration 198 / 300: loss 0.588428\n",
      "iteration 198 / 300: loss 0.567516\n",
      "iteration 198 / 300: loss 0.592380\n",
      "iteration 198 / 300: loss 0.593618\n",
      "iteration 198 / 300: loss 0.595295\n",
      "iteration 198 / 300: loss 0.608784\n",
      "iteration 198 / 300: loss 0.592732\n",
      "iteration 198 / 300: loss 0.628060\n",
      "iteration 198 / 300: loss 0.580152\n",
      "iteration 198 / 300: loss 0.607923\n",
      "iteration 198 / 300: loss 0.587394\n",
      "iteration 198 / 300: loss 0.591686\n",
      "iteration 198 / 300: loss 0.571370\n",
      "iteration 198 / 300: loss 0.583025\n",
      "iteration 198 / 300: loss 0.608441\n",
      "iteration 198 / 300: loss 0.598359\n",
      "iteration 198 / 300: loss 0.583858\n",
      "iteration 198 / 300: loss 0.615253\n",
      "iteration 198 / 300: loss 0.591649\n",
      "iteration 198 / 300: loss 0.585499\n",
      "iteration 198 / 300: loss 0.591325\n",
      "iteration 198 / 300: loss 0.604341\n",
      "iteration 198 / 300: loss 0.595786\n",
      "iteration 198 / 300: loss 0.614949\n",
      "iteration 198 / 300: loss 0.608389\n",
      "iteration 198 / 300: loss 0.598222\n",
      "iteration 198 / 300: loss 0.588936\n",
      "iteration 198 / 300: loss 0.617757\n",
      "iteration 198 / 300: loss 0.594770\n",
      "iteration 198 / 300: loss 0.601684\n",
      "iteration 198 / 300: loss 0.631031\n",
      "iteration 198 / 300: loss 0.587513\n",
      "iteration 198 / 300: loss 0.606561\n",
      "iteration 198 / 300: loss 0.588034\n",
      "iteration 198 / 300: loss 0.600890\n",
      "iteration 198 / 300: loss 0.595958\n",
      "iteration 198 / 300: loss 0.589291\n",
      "iteration 198 / 300: loss 0.599526\n",
      "iteration 198 / 300: loss 0.604855\n",
      "iteration 198 / 300: loss 0.619414\n",
      "iteration 198 / 300: loss 0.588808\n",
      "iteration 198 / 300: loss 0.593645\n",
      "iteration 198 / 300: loss 0.585595\n",
      "iteration 198 / 300: loss 0.613212\n",
      "iteration 198 / 300: loss 0.587523\n",
      "iteration 198 / 300: loss 0.578328\n",
      "iteration 198 / 300: loss 0.567435\n",
      "iteration 198 / 300: loss 0.562235\n",
      "iteration 198 / 300: loss 0.594183\n",
      "iteration 198 / 300: loss 0.578821\n",
      "iteration 198 / 300: loss 0.586360\n",
      "iteration 198 / 300: loss 0.572890\n",
      "iteration 198 / 300: loss 0.596151\n",
      "iteration 198 / 300: loss 0.607951\n",
      "iteration 198 / 300: loss 0.610839\n",
      "iteration 198 / 300: loss 0.606265\n",
      "iteration 198 / 300: loss 0.583790\n",
      "iteration 198 / 300: loss 0.589627\n",
      "iteration 198 / 300: loss 0.595184\n",
      "iteration 198 / 300: loss 0.598955\n",
      "iteration 198 / 300: loss 0.596133\n",
      "iteration 198 / 300: loss 0.589769\n",
      "iteration 198 / 300: loss 0.591136\n",
      "iteration 198 / 300: loss 0.584854\n",
      "iteration 198 / 300: loss 0.599646\n",
      "iteration 198 / 300: loss 0.598902\n",
      "iteration 198 / 300: loss 0.614282\n",
      "iteration 198 / 300: loss 0.597796\n",
      "iteration 198 / 300: loss 0.599298\n",
      "iteration 198 / 300: loss 0.603317\n",
      "iteration 198 / 300: loss 0.592865\n",
      "iteration 198 / 300: loss 0.592391\n",
      "iteration 198 / 300: loss 0.589041\n",
      "iteration 198 / 300: loss 0.596446\n",
      "iteration 198 / 300: loss 0.605709\n",
      "iteration 198 / 300: loss 0.610562\n",
      "iteration 198 / 300: loss 0.587782\n",
      "iteration 198 / 300: loss 0.599351\n",
      "iteration 198 / 300: loss 0.602792\n",
      "iteration 198 / 300: loss 0.605028\n",
      "iteration 198 / 300: loss 0.603848\n",
      "iteration 198 / 300: loss 0.624144\n",
      "iteration 198 / 300: loss 0.587219\n",
      "iteration 198 / 300: loss 0.580754\n",
      "iteration 198 / 300: loss 0.625045\n",
      "iteration 198 / 300: loss 0.603310\n",
      "iteration 198 / 300: loss 0.604321\n",
      "iteration 198 / 300: loss 0.595476\n",
      "iteration 198 / 300: loss 0.597543\n",
      "iteration 198 / 300: loss 0.592740\n",
      "iteration 198 / 300: loss 0.589494\n",
      "iteration 198 / 300: loss 0.599264\n",
      "iteration 198 / 300: loss 0.611380\n",
      "iteration 198 / 300: loss 0.592463\n",
      "iteration 198 / 300: loss 0.599424\n",
      "iteration 198 / 300: loss 0.603100\n",
      "iteration 198 / 300: loss 0.602410\n",
      "iteration 198 / 300: loss 0.579811\n",
      "iteration 198 / 300: loss 0.601592\n",
      "iteration 199 / 300: loss 0.585528\n",
      "iteration 199 / 300: loss 0.588428\n",
      "iteration 199 / 300: loss 0.567516\n",
      "iteration 199 / 300: loss 0.592380\n",
      "iteration 199 / 300: loss 0.593618\n",
      "iteration 199 / 300: loss 0.595295\n",
      "iteration 199 / 300: loss 0.608784\n",
      "iteration 199 / 300: loss 0.592732\n",
      "iteration 199 / 300: loss 0.628060\n",
      "iteration 199 / 300: loss 0.580152\n",
      "iteration 199 / 300: loss 0.607923\n",
      "iteration 199 / 300: loss 0.587394\n",
      "iteration 199 / 300: loss 0.591686\n",
      "iteration 199 / 300: loss 0.571370\n",
      "iteration 199 / 300: loss 0.583025\n",
      "iteration 199 / 300: loss 0.608441\n",
      "iteration 199 / 300: loss 0.598359\n",
      "iteration 199 / 300: loss 0.583858\n",
      "iteration 199 / 300: loss 0.615253\n",
      "iteration 199 / 300: loss 0.591649\n",
      "iteration 199 / 300: loss 0.585499\n",
      "iteration 199 / 300: loss 0.591325\n",
      "iteration 199 / 300: loss 0.604341\n",
      "iteration 199 / 300: loss 0.595786\n",
      "iteration 199 / 300: loss 0.614949\n",
      "iteration 199 / 300: loss 0.608389\n",
      "iteration 199 / 300: loss 0.598222\n",
      "iteration 199 / 300: loss 0.588936\n",
      "iteration 199 / 300: loss 0.617757\n",
      "iteration 199 / 300: loss 0.594770\n",
      "iteration 199 / 300: loss 0.601684\n",
      "iteration 199 / 300: loss 0.631031\n",
      "iteration 199 / 300: loss 0.587513\n",
      "iteration 199 / 300: loss 0.606561\n",
      "iteration 199 / 300: loss 0.588034\n",
      "iteration 199 / 300: loss 0.600890\n",
      "iteration 199 / 300: loss 0.595958\n",
      "iteration 199 / 300: loss 0.589291\n",
      "iteration 199 / 300: loss 0.599526\n",
      "iteration 199 / 300: loss 0.604855\n",
      "iteration 199 / 300: loss 0.619414\n",
      "iteration 199 / 300: loss 0.588808\n",
      "iteration 199 / 300: loss 0.593645\n",
      "iteration 199 / 300: loss 0.585595\n",
      "iteration 199 / 300: loss 0.613212\n",
      "iteration 199 / 300: loss 0.587523\n",
      "iteration 199 / 300: loss 0.578328\n",
      "iteration 199 / 300: loss 0.567435\n",
      "iteration 199 / 300: loss 0.562235\n",
      "iteration 199 / 300: loss 0.594183\n",
      "iteration 199 / 300: loss 0.578821\n",
      "iteration 199 / 300: loss 0.586360\n",
      "iteration 199 / 300: loss 0.572890\n",
      "iteration 199 / 300: loss 0.596151\n",
      "iteration 199 / 300: loss 0.607951\n",
      "iteration 199 / 300: loss 0.610839\n",
      "iteration 199 / 300: loss 0.606265\n",
      "iteration 199 / 300: loss 0.583790\n",
      "iteration 199 / 300: loss 0.589627\n",
      "iteration 199 / 300: loss 0.595184\n",
      "iteration 199 / 300: loss 0.598955\n",
      "iteration 199 / 300: loss 0.596133\n",
      "iteration 199 / 300: loss 0.589769\n",
      "iteration 199 / 300: loss 0.591136\n",
      "iteration 199 / 300: loss 0.584854\n",
      "iteration 199 / 300: loss 0.599646\n",
      "iteration 199 / 300: loss 0.598902\n",
      "iteration 199 / 300: loss 0.614282\n",
      "iteration 199 / 300: loss 0.597796\n",
      "iteration 199 / 300: loss 0.599298\n",
      "iteration 199 / 300: loss 0.603317\n",
      "iteration 199 / 300: loss 0.592865\n",
      "iteration 199 / 300: loss 0.592391\n",
      "iteration 199 / 300: loss 0.589041\n",
      "iteration 199 / 300: loss 0.596446\n",
      "iteration 199 / 300: loss 0.605709\n",
      "iteration 199 / 300: loss 0.610562\n",
      "iteration 199 / 300: loss 0.587782\n",
      "iteration 199 / 300: loss 0.599351\n",
      "iteration 199 / 300: loss 0.602792\n",
      "iteration 199 / 300: loss 0.605028\n",
      "iteration 199 / 300: loss 0.603848\n",
      "iteration 199 / 300: loss 0.624144\n",
      "iteration 199 / 300: loss 0.587219\n",
      "iteration 199 / 300: loss 0.580754\n",
      "iteration 199 / 300: loss 0.625045\n",
      "iteration 199 / 300: loss 0.603310\n",
      "iteration 199 / 300: loss 0.604321\n",
      "iteration 199 / 300: loss 0.595476\n",
      "iteration 199 / 300: loss 0.597543\n",
      "iteration 199 / 300: loss 0.592740\n",
      "iteration 199 / 300: loss 0.589494\n",
      "iteration 199 / 300: loss 0.599264\n",
      "iteration 199 / 300: loss 0.611380\n",
      "iteration 199 / 300: loss 0.592463\n",
      "iteration 199 / 300: loss 0.599424\n",
      "iteration 199 / 300: loss 0.603100\n",
      "iteration 199 / 300: loss 0.602410\n",
      "iteration 199 / 300: loss 0.579811\n",
      "iteration 199 / 300: loss 0.601592\n",
      "iteration 200 / 300: loss 0.585528\n",
      "iteration 200 / 300: loss 0.588428\n",
      "iteration 200 / 300: loss 0.567516\n",
      "iteration 200 / 300: loss 0.592380\n",
      "iteration 200 / 300: loss 0.593618\n",
      "iteration 200 / 300: loss 0.595295\n",
      "iteration 200 / 300: loss 0.608784\n",
      "iteration 200 / 300: loss 0.592732\n",
      "iteration 200 / 300: loss 0.628060\n",
      "iteration 200 / 300: loss 0.580152\n",
      "iteration 200 / 300: loss 0.607923\n",
      "iteration 200 / 300: loss 0.587394\n",
      "iteration 200 / 300: loss 0.591686\n",
      "iteration 200 / 300: loss 0.571370\n",
      "iteration 200 / 300: loss 0.583025\n",
      "iteration 200 / 300: loss 0.608441\n",
      "iteration 200 / 300: loss 0.598359\n",
      "iteration 200 / 300: loss 0.583858\n",
      "iteration 200 / 300: loss 0.615253\n",
      "iteration 200 / 300: loss 0.591649\n",
      "iteration 200 / 300: loss 0.585499\n",
      "iteration 200 / 300: loss 0.591325\n",
      "iteration 200 / 300: loss 0.604341\n",
      "iteration 200 / 300: loss 0.595786\n",
      "iteration 200 / 300: loss 0.614949\n",
      "iteration 200 / 300: loss 0.608389\n",
      "iteration 200 / 300: loss 0.598222\n",
      "iteration 200 / 300: loss 0.588936\n",
      "iteration 200 / 300: loss 0.617757\n",
      "iteration 200 / 300: loss 0.594770\n",
      "iteration 200 / 300: loss 0.601684\n",
      "iteration 200 / 300: loss 0.631031\n",
      "iteration 200 / 300: loss 0.587513\n",
      "iteration 200 / 300: loss 0.606561\n",
      "iteration 200 / 300: loss 0.588034\n",
      "iteration 200 / 300: loss 0.600890\n",
      "iteration 200 / 300: loss 0.595958\n",
      "iteration 200 / 300: loss 0.589291\n",
      "iteration 200 / 300: loss 0.599526\n",
      "iteration 200 / 300: loss 0.604855\n",
      "iteration 200 / 300: loss 0.619414\n",
      "iteration 200 / 300: loss 0.588808\n",
      "iteration 200 / 300: loss 0.593645\n",
      "iteration 200 / 300: loss 0.585595\n",
      "iteration 200 / 300: loss 0.613212\n",
      "iteration 200 / 300: loss 0.587523\n",
      "iteration 200 / 300: loss 0.578328\n",
      "iteration 200 / 300: loss 0.567435\n",
      "iteration 200 / 300: loss 0.562235\n",
      "iteration 200 / 300: loss 0.594183\n",
      "iteration 200 / 300: loss 0.578821\n",
      "iteration 200 / 300: loss 0.586360\n",
      "iteration 200 / 300: loss 0.572890\n",
      "iteration 200 / 300: loss 0.596151\n",
      "iteration 200 / 300: loss 0.607951\n",
      "iteration 200 / 300: loss 0.610839\n",
      "iteration 200 / 300: loss 0.606265\n",
      "iteration 200 / 300: loss 0.583790\n",
      "iteration 200 / 300: loss 0.589627\n",
      "iteration 200 / 300: loss 0.595184\n",
      "iteration 200 / 300: loss 0.598955\n",
      "iteration 200 / 300: loss 0.596133\n",
      "iteration 200 / 300: loss 0.589769\n",
      "iteration 200 / 300: loss 0.591136\n",
      "iteration 200 / 300: loss 0.584854\n",
      "iteration 200 / 300: loss 0.599646\n",
      "iteration 200 / 300: loss 0.598902\n",
      "iteration 200 / 300: loss 0.614282\n",
      "iteration 200 / 300: loss 0.597796\n",
      "iteration 200 / 300: loss 0.599298\n",
      "iteration 200 / 300: loss 0.603317\n",
      "iteration 200 / 300: loss 0.592865\n",
      "iteration 200 / 300: loss 0.592391\n",
      "iteration 200 / 300: loss 0.589041\n",
      "iteration 200 / 300: loss 0.596446\n",
      "iteration 200 / 300: loss 0.605709\n",
      "iteration 200 / 300: loss 0.610562\n",
      "iteration 200 / 300: loss 0.587782\n",
      "iteration 200 / 300: loss 0.599351\n",
      "iteration 200 / 300: loss 0.602792\n",
      "iteration 200 / 300: loss 0.605028\n",
      "iteration 200 / 300: loss 0.603848\n",
      "iteration 200 / 300: loss 0.624144\n",
      "iteration 200 / 300: loss 0.587219\n",
      "iteration 200 / 300: loss 0.580754\n",
      "iteration 200 / 300: loss 0.625045\n",
      "iteration 200 / 300: loss 0.603310\n",
      "iteration 200 / 300: loss 0.604321\n",
      "iteration 200 / 300: loss 0.595476\n",
      "iteration 200 / 300: loss 0.597543\n",
      "iteration 200 / 300: loss 0.592740\n",
      "iteration 200 / 300: loss 0.589494\n",
      "iteration 200 / 300: loss 0.599264\n",
      "iteration 200 / 300: loss 0.611380\n",
      "iteration 200 / 300: loss 0.592463\n",
      "iteration 200 / 300: loss 0.599424\n",
      "iteration 200 / 300: loss 0.603100\n",
      "iteration 200 / 300: loss 0.602410\n",
      "iteration 200 / 300: loss 0.579811\n",
      "iteration 200 / 300: loss 0.601592\n",
      "iteration 201 / 300: loss 0.585528\n",
      "iteration 201 / 300: loss 0.588428\n",
      "iteration 201 / 300: loss 0.567516\n",
      "iteration 201 / 300: loss 0.592380\n",
      "iteration 201 / 300: loss 0.593618\n",
      "iteration 201 / 300: loss 0.595295\n",
      "iteration 201 / 300: loss 0.608784\n",
      "iteration 201 / 300: loss 0.592732\n",
      "iteration 201 / 300: loss 0.628060\n",
      "iteration 201 / 300: loss 0.580152\n",
      "iteration 201 / 300: loss 0.607923\n",
      "iteration 201 / 300: loss 0.587394\n",
      "iteration 201 / 300: loss 0.591686\n",
      "iteration 201 / 300: loss 0.571370\n",
      "iteration 201 / 300: loss 0.583025\n",
      "iteration 201 / 300: loss 0.608441\n",
      "iteration 201 / 300: loss 0.598359\n",
      "iteration 201 / 300: loss 0.583858\n",
      "iteration 201 / 300: loss 0.615253\n",
      "iteration 201 / 300: loss 0.591649\n",
      "iteration 201 / 300: loss 0.585499\n",
      "iteration 201 / 300: loss 0.591325\n",
      "iteration 201 / 300: loss 0.604341\n",
      "iteration 201 / 300: loss 0.595786\n",
      "iteration 201 / 300: loss 0.614949\n",
      "iteration 201 / 300: loss 0.608389\n",
      "iteration 201 / 300: loss 0.598222\n",
      "iteration 201 / 300: loss 0.588936\n",
      "iteration 201 / 300: loss 0.617757\n",
      "iteration 201 / 300: loss 0.594770\n",
      "iteration 201 / 300: loss 0.601684\n",
      "iteration 201 / 300: loss 0.631031\n",
      "iteration 201 / 300: loss 0.587513\n",
      "iteration 201 / 300: loss 0.606561\n",
      "iteration 201 / 300: loss 0.588034\n",
      "iteration 201 / 300: loss 0.600890\n",
      "iteration 201 / 300: loss 0.595958\n",
      "iteration 201 / 300: loss 0.589291\n",
      "iteration 201 / 300: loss 0.599526\n",
      "iteration 201 / 300: loss 0.604855\n",
      "iteration 201 / 300: loss 0.619414\n",
      "iteration 201 / 300: loss 0.588808\n",
      "iteration 201 / 300: loss 0.593645\n",
      "iteration 201 / 300: loss 0.585595\n",
      "iteration 201 / 300: loss 0.613212\n",
      "iteration 201 / 300: loss 0.587523\n",
      "iteration 201 / 300: loss 0.578328\n",
      "iteration 201 / 300: loss 0.567435\n",
      "iteration 201 / 300: loss 0.562235\n",
      "iteration 201 / 300: loss 0.594183\n",
      "iteration 201 / 300: loss 0.578821\n",
      "iteration 201 / 300: loss 0.586360\n",
      "iteration 201 / 300: loss 0.572890\n",
      "iteration 201 / 300: loss 0.596151\n",
      "iteration 201 / 300: loss 0.607951\n",
      "iteration 201 / 300: loss 0.610839\n",
      "iteration 201 / 300: loss 0.606265\n",
      "iteration 201 / 300: loss 0.583790\n",
      "iteration 201 / 300: loss 0.589627\n",
      "iteration 201 / 300: loss 0.595184\n",
      "iteration 201 / 300: loss 0.598955\n",
      "iteration 201 / 300: loss 0.596133\n",
      "iteration 201 / 300: loss 0.589769\n",
      "iteration 201 / 300: loss 0.591136\n",
      "iteration 201 / 300: loss 0.584854\n",
      "iteration 201 / 300: loss 0.599646\n",
      "iteration 201 / 300: loss 0.598902\n",
      "iteration 201 / 300: loss 0.614282\n",
      "iteration 201 / 300: loss 0.597796\n",
      "iteration 201 / 300: loss 0.599298\n",
      "iteration 201 / 300: loss 0.603317\n",
      "iteration 201 / 300: loss 0.592865\n",
      "iteration 201 / 300: loss 0.592391\n",
      "iteration 201 / 300: loss 0.589041\n",
      "iteration 201 / 300: loss 0.596446\n",
      "iteration 201 / 300: loss 0.605709\n",
      "iteration 201 / 300: loss 0.610562\n",
      "iteration 201 / 300: loss 0.587782\n",
      "iteration 201 / 300: loss 0.599351\n",
      "iteration 201 / 300: loss 0.602792\n",
      "iteration 201 / 300: loss 0.605028\n",
      "iteration 201 / 300: loss 0.603848\n",
      "iteration 201 / 300: loss 0.624144\n",
      "iteration 201 / 300: loss 0.587219\n",
      "iteration 201 / 300: loss 0.580754\n",
      "iteration 201 / 300: loss 0.625045\n",
      "iteration 201 / 300: loss 0.603310\n",
      "iteration 201 / 300: loss 0.604321\n",
      "iteration 201 / 300: loss 0.595476\n",
      "iteration 201 / 300: loss 0.597543\n",
      "iteration 201 / 300: loss 0.592740\n",
      "iteration 201 / 300: loss 0.589494\n",
      "iteration 201 / 300: loss 0.599264\n",
      "iteration 201 / 300: loss 0.611380\n",
      "iteration 201 / 300: loss 0.592463\n",
      "iteration 201 / 300: loss 0.599424\n",
      "iteration 201 / 300: loss 0.603100\n",
      "iteration 201 / 300: loss 0.602410\n",
      "iteration 201 / 300: loss 0.579811\n",
      "iteration 201 / 300: loss 0.601592\n",
      "iteration 202 / 300: loss 0.585528\n",
      "iteration 202 / 300: loss 0.588428\n",
      "iteration 202 / 300: loss 0.567516\n",
      "iteration 202 / 300: loss 0.592380\n",
      "iteration 202 / 300: loss 0.593618\n",
      "iteration 202 / 300: loss 0.595295\n",
      "iteration 202 / 300: loss 0.608784\n",
      "iteration 202 / 300: loss 0.592732\n",
      "iteration 202 / 300: loss 0.628060\n",
      "iteration 202 / 300: loss 0.580152\n",
      "iteration 202 / 300: loss 0.607923\n",
      "iteration 202 / 300: loss 0.587394\n",
      "iteration 202 / 300: loss 0.591686\n",
      "iteration 202 / 300: loss 0.571370\n",
      "iteration 202 / 300: loss 0.583025\n",
      "iteration 202 / 300: loss 0.608441\n",
      "iteration 202 / 300: loss 0.598359\n",
      "iteration 202 / 300: loss 0.583858\n",
      "iteration 202 / 300: loss 0.615253\n",
      "iteration 202 / 300: loss 0.591649\n",
      "iteration 202 / 300: loss 0.585499\n",
      "iteration 202 / 300: loss 0.591325\n",
      "iteration 202 / 300: loss 0.604341\n",
      "iteration 202 / 300: loss 0.595786\n",
      "iteration 202 / 300: loss 0.614949\n",
      "iteration 202 / 300: loss 0.608389\n",
      "iteration 202 / 300: loss 0.598222\n",
      "iteration 202 / 300: loss 0.588936\n",
      "iteration 202 / 300: loss 0.617757\n",
      "iteration 202 / 300: loss 0.594770\n",
      "iteration 202 / 300: loss 0.601684\n",
      "iteration 202 / 300: loss 0.631031\n",
      "iteration 202 / 300: loss 0.587513\n",
      "iteration 202 / 300: loss 0.606561\n",
      "iteration 202 / 300: loss 0.588034\n",
      "iteration 202 / 300: loss 0.600890\n",
      "iteration 202 / 300: loss 0.595958\n",
      "iteration 202 / 300: loss 0.589291\n",
      "iteration 202 / 300: loss 0.599526\n",
      "iteration 202 / 300: loss 0.604855\n",
      "iteration 202 / 300: loss 0.619414\n",
      "iteration 202 / 300: loss 0.588808\n",
      "iteration 202 / 300: loss 0.593645\n",
      "iteration 202 / 300: loss 0.585595\n",
      "iteration 202 / 300: loss 0.613212\n",
      "iteration 202 / 300: loss 0.587523\n",
      "iteration 202 / 300: loss 0.578328\n",
      "iteration 202 / 300: loss 0.567435\n",
      "iteration 202 / 300: loss 0.562235\n",
      "iteration 202 / 300: loss 0.594183\n",
      "iteration 202 / 300: loss 0.578821\n",
      "iteration 202 / 300: loss 0.586360\n",
      "iteration 202 / 300: loss 0.572890\n",
      "iteration 202 / 300: loss 0.596151\n",
      "iteration 202 / 300: loss 0.607951\n",
      "iteration 202 / 300: loss 0.610839\n",
      "iteration 202 / 300: loss 0.606265\n",
      "iteration 202 / 300: loss 0.583790\n",
      "iteration 202 / 300: loss 0.589627\n",
      "iteration 202 / 300: loss 0.595184\n",
      "iteration 202 / 300: loss 0.598955\n",
      "iteration 202 / 300: loss 0.596133\n",
      "iteration 202 / 300: loss 0.589769\n",
      "iteration 202 / 300: loss 0.591136\n",
      "iteration 202 / 300: loss 0.584854\n",
      "iteration 202 / 300: loss 0.599646\n",
      "iteration 202 / 300: loss 0.598902\n",
      "iteration 202 / 300: loss 0.614282\n",
      "iteration 202 / 300: loss 0.597796\n",
      "iteration 202 / 300: loss 0.599298\n",
      "iteration 202 / 300: loss 0.603317\n",
      "iteration 202 / 300: loss 0.592865\n",
      "iteration 202 / 300: loss 0.592391\n",
      "iteration 202 / 300: loss 0.589041\n",
      "iteration 202 / 300: loss 0.596446\n",
      "iteration 202 / 300: loss 0.605709\n",
      "iteration 202 / 300: loss 0.610562\n",
      "iteration 202 / 300: loss 0.587782\n",
      "iteration 202 / 300: loss 0.599351\n",
      "iteration 202 / 300: loss 0.602792\n",
      "iteration 202 / 300: loss 0.605028\n",
      "iteration 202 / 300: loss 0.603848\n",
      "iteration 202 / 300: loss 0.624144\n",
      "iteration 202 / 300: loss 0.587219\n",
      "iteration 202 / 300: loss 0.580754\n",
      "iteration 202 / 300: loss 0.625045\n",
      "iteration 202 / 300: loss 0.603310\n",
      "iteration 202 / 300: loss 0.604321\n",
      "iteration 202 / 300: loss 0.595476\n",
      "iteration 202 / 300: loss 0.597543\n",
      "iteration 202 / 300: loss 0.592740\n",
      "iteration 202 / 300: loss 0.589494\n",
      "iteration 202 / 300: loss 0.599264\n",
      "iteration 202 / 300: loss 0.611380\n",
      "iteration 202 / 300: loss 0.592463\n",
      "iteration 202 / 300: loss 0.599424\n",
      "iteration 202 / 300: loss 0.603100\n",
      "iteration 202 / 300: loss 0.602410\n",
      "iteration 202 / 300: loss 0.579811\n",
      "iteration 202 / 300: loss 0.601592\n",
      "iteration 203 / 300: loss 0.585528\n",
      "iteration 203 / 300: loss 0.588428\n",
      "iteration 203 / 300: loss 0.567516\n",
      "iteration 203 / 300: loss 0.592380\n",
      "iteration 203 / 300: loss 0.593618\n",
      "iteration 203 / 300: loss 0.595295\n",
      "iteration 203 / 300: loss 0.608784\n",
      "iteration 203 / 300: loss 0.592732\n",
      "iteration 203 / 300: loss 0.628060\n",
      "iteration 203 / 300: loss 0.580152\n",
      "iteration 203 / 300: loss 0.607923\n",
      "iteration 203 / 300: loss 0.587394\n",
      "iteration 203 / 300: loss 0.591686\n",
      "iteration 203 / 300: loss 0.571370\n",
      "iteration 203 / 300: loss 0.583025\n",
      "iteration 203 / 300: loss 0.608441\n",
      "iteration 203 / 300: loss 0.598359\n",
      "iteration 203 / 300: loss 0.583858\n",
      "iteration 203 / 300: loss 0.615253\n",
      "iteration 203 / 300: loss 0.591649\n",
      "iteration 203 / 300: loss 0.585499\n",
      "iteration 203 / 300: loss 0.591325\n",
      "iteration 203 / 300: loss 0.604341\n",
      "iteration 203 / 300: loss 0.595786\n",
      "iteration 203 / 300: loss 0.614949\n",
      "iteration 203 / 300: loss 0.608389\n",
      "iteration 203 / 300: loss 0.598222\n",
      "iteration 203 / 300: loss 0.588936\n",
      "iteration 203 / 300: loss 0.617757\n",
      "iteration 203 / 300: loss 0.594770\n",
      "iteration 203 / 300: loss 0.601684\n",
      "iteration 203 / 300: loss 0.631031\n",
      "iteration 203 / 300: loss 0.587513\n",
      "iteration 203 / 300: loss 0.606561\n",
      "iteration 203 / 300: loss 0.588034\n",
      "iteration 203 / 300: loss 0.600890\n",
      "iteration 203 / 300: loss 0.595958\n",
      "iteration 203 / 300: loss 0.589291\n",
      "iteration 203 / 300: loss 0.599526\n",
      "iteration 203 / 300: loss 0.604855\n",
      "iteration 203 / 300: loss 0.619414\n",
      "iteration 203 / 300: loss 0.588808\n",
      "iteration 203 / 300: loss 0.593645\n",
      "iteration 203 / 300: loss 0.585595\n",
      "iteration 203 / 300: loss 0.613212\n",
      "iteration 203 / 300: loss 0.587523\n",
      "iteration 203 / 300: loss 0.578328\n",
      "iteration 203 / 300: loss 0.567435\n",
      "iteration 203 / 300: loss 0.562235\n",
      "iteration 203 / 300: loss 0.594183\n",
      "iteration 203 / 300: loss 0.578821\n",
      "iteration 203 / 300: loss 0.586360\n",
      "iteration 203 / 300: loss 0.572890\n",
      "iteration 203 / 300: loss 0.596151\n",
      "iteration 203 / 300: loss 0.607951\n",
      "iteration 203 / 300: loss 0.610839\n",
      "iteration 203 / 300: loss 0.606265\n",
      "iteration 203 / 300: loss 0.583790\n",
      "iteration 203 / 300: loss 0.589627\n",
      "iteration 203 / 300: loss 0.595184\n",
      "iteration 203 / 300: loss 0.598955\n",
      "iteration 203 / 300: loss 0.596133\n",
      "iteration 203 / 300: loss 0.589769\n",
      "iteration 203 / 300: loss 0.591136\n",
      "iteration 203 / 300: loss 0.584854\n",
      "iteration 203 / 300: loss 0.599646\n",
      "iteration 203 / 300: loss 0.598902\n",
      "iteration 203 / 300: loss 0.614282\n",
      "iteration 203 / 300: loss 0.597796\n",
      "iteration 203 / 300: loss 0.599298\n",
      "iteration 203 / 300: loss 0.603317\n",
      "iteration 203 / 300: loss 0.592865\n",
      "iteration 203 / 300: loss 0.592391\n",
      "iteration 203 / 300: loss 0.589041\n",
      "iteration 203 / 300: loss 0.596446\n",
      "iteration 203 / 300: loss 0.605709\n",
      "iteration 203 / 300: loss 0.610562\n",
      "iteration 203 / 300: loss 0.587782\n",
      "iteration 203 / 300: loss 0.599351\n",
      "iteration 203 / 300: loss 0.602792\n",
      "iteration 203 / 300: loss 0.605028\n",
      "iteration 203 / 300: loss 0.603848\n",
      "iteration 203 / 300: loss 0.624144\n",
      "iteration 203 / 300: loss 0.587219\n",
      "iteration 203 / 300: loss 0.580754\n",
      "iteration 203 / 300: loss 0.625045\n",
      "iteration 203 / 300: loss 0.603310\n",
      "iteration 203 / 300: loss 0.604321\n",
      "iteration 203 / 300: loss 0.595476\n",
      "iteration 203 / 300: loss 0.597543\n",
      "iteration 203 / 300: loss 0.592740\n",
      "iteration 203 / 300: loss 0.589494\n",
      "iteration 203 / 300: loss 0.599264\n",
      "iteration 203 / 300: loss 0.611380\n",
      "iteration 203 / 300: loss 0.592463\n",
      "iteration 203 / 300: loss 0.599424\n",
      "iteration 203 / 300: loss 0.603100\n",
      "iteration 203 / 300: loss 0.602410\n",
      "iteration 203 / 300: loss 0.579811\n",
      "iteration 203 / 300: loss 0.601592\n",
      "iteration 204 / 300: loss 0.585528\n",
      "iteration 204 / 300: loss 0.588428\n",
      "iteration 204 / 300: loss 0.567516\n",
      "iteration 204 / 300: loss 0.592380\n",
      "iteration 204 / 300: loss 0.593618\n",
      "iteration 204 / 300: loss 0.595295\n",
      "iteration 204 / 300: loss 0.608784\n",
      "iteration 204 / 300: loss 0.592732\n",
      "iteration 204 / 300: loss 0.628060\n",
      "iteration 204 / 300: loss 0.580152\n",
      "iteration 204 / 300: loss 0.607923\n",
      "iteration 204 / 300: loss 0.587394\n",
      "iteration 204 / 300: loss 0.591686\n",
      "iteration 204 / 300: loss 0.571370\n",
      "iteration 204 / 300: loss 0.583025\n",
      "iteration 204 / 300: loss 0.608441\n",
      "iteration 204 / 300: loss 0.598359\n",
      "iteration 204 / 300: loss 0.583858\n",
      "iteration 204 / 300: loss 0.615253\n",
      "iteration 204 / 300: loss 0.591649\n",
      "iteration 204 / 300: loss 0.585499\n",
      "iteration 204 / 300: loss 0.591325\n",
      "iteration 204 / 300: loss 0.604341\n",
      "iteration 204 / 300: loss 0.595786\n",
      "iteration 204 / 300: loss 0.614949\n",
      "iteration 204 / 300: loss 0.608389\n",
      "iteration 204 / 300: loss 0.598222\n",
      "iteration 204 / 300: loss 0.588936\n",
      "iteration 204 / 300: loss 0.617757\n",
      "iteration 204 / 300: loss 0.594770\n",
      "iteration 204 / 300: loss 0.601684\n",
      "iteration 204 / 300: loss 0.631031\n",
      "iteration 204 / 300: loss 0.587513\n",
      "iteration 204 / 300: loss 0.606561\n",
      "iteration 204 / 300: loss 0.588034\n",
      "iteration 204 / 300: loss 0.600890\n",
      "iteration 204 / 300: loss 0.595958\n",
      "iteration 204 / 300: loss 0.589291\n",
      "iteration 204 / 300: loss 0.599526\n",
      "iteration 204 / 300: loss 0.604855\n",
      "iteration 204 / 300: loss 0.619414\n",
      "iteration 204 / 300: loss 0.588808\n",
      "iteration 204 / 300: loss 0.593645\n",
      "iteration 204 / 300: loss 0.585595\n",
      "iteration 204 / 300: loss 0.613212\n",
      "iteration 204 / 300: loss 0.587523\n",
      "iteration 204 / 300: loss 0.578328\n",
      "iteration 204 / 300: loss 0.567435\n",
      "iteration 204 / 300: loss 0.562235\n",
      "iteration 204 / 300: loss 0.594183\n",
      "iteration 204 / 300: loss 0.578821\n",
      "iteration 204 / 300: loss 0.586360\n",
      "iteration 204 / 300: loss 0.572890\n",
      "iteration 204 / 300: loss 0.596151\n",
      "iteration 204 / 300: loss 0.607951\n",
      "iteration 204 / 300: loss 0.610839\n",
      "iteration 204 / 300: loss 0.606265\n",
      "iteration 204 / 300: loss 0.583790\n",
      "iteration 204 / 300: loss 0.589627\n",
      "iteration 204 / 300: loss 0.595184\n",
      "iteration 204 / 300: loss 0.598955\n",
      "iteration 204 / 300: loss 0.596133\n",
      "iteration 204 / 300: loss 0.589769\n",
      "iteration 204 / 300: loss 0.591136\n",
      "iteration 204 / 300: loss 0.584854\n",
      "iteration 204 / 300: loss 0.599646\n",
      "iteration 204 / 300: loss 0.598902\n",
      "iteration 204 / 300: loss 0.614282\n",
      "iteration 204 / 300: loss 0.597796\n",
      "iteration 204 / 300: loss 0.599298\n",
      "iteration 204 / 300: loss 0.603317\n",
      "iteration 204 / 300: loss 0.592865\n",
      "iteration 204 / 300: loss 0.592391\n",
      "iteration 204 / 300: loss 0.589041\n",
      "iteration 204 / 300: loss 0.596446\n",
      "iteration 204 / 300: loss 0.605709\n",
      "iteration 204 / 300: loss 0.610562\n",
      "iteration 204 / 300: loss 0.587782\n",
      "iteration 204 / 300: loss 0.599351\n",
      "iteration 204 / 300: loss 0.602792\n",
      "iteration 204 / 300: loss 0.605028\n",
      "iteration 204 / 300: loss 0.603848\n",
      "iteration 204 / 300: loss 0.624144\n",
      "iteration 204 / 300: loss 0.587219\n",
      "iteration 204 / 300: loss 0.580754\n",
      "iteration 204 / 300: loss 0.625045\n",
      "iteration 204 / 300: loss 0.603310\n",
      "iteration 204 / 300: loss 0.604321\n",
      "iteration 204 / 300: loss 0.595476\n",
      "iteration 204 / 300: loss 0.597543\n",
      "iteration 204 / 300: loss 0.592740\n",
      "iteration 204 / 300: loss 0.589494\n",
      "iteration 204 / 300: loss 0.599264\n",
      "iteration 204 / 300: loss 0.611380\n",
      "iteration 204 / 300: loss 0.592463\n",
      "iteration 204 / 300: loss 0.599424\n",
      "iteration 204 / 300: loss 0.603100\n",
      "iteration 204 / 300: loss 0.602410\n",
      "iteration 204 / 300: loss 0.579811\n",
      "iteration 204 / 300: loss 0.601592\n",
      "iteration 205 / 300: loss 0.585528\n",
      "iteration 205 / 300: loss 0.588428\n",
      "iteration 205 / 300: loss 0.567516\n",
      "iteration 205 / 300: loss 0.592380\n",
      "iteration 205 / 300: loss 0.593618\n",
      "iteration 205 / 300: loss 0.595295\n",
      "iteration 205 / 300: loss 0.608784\n",
      "iteration 205 / 300: loss 0.592732\n",
      "iteration 205 / 300: loss 0.628060\n",
      "iteration 205 / 300: loss 0.580152\n",
      "iteration 205 / 300: loss 0.607923\n",
      "iteration 205 / 300: loss 0.587394\n",
      "iteration 205 / 300: loss 0.591686\n",
      "iteration 205 / 300: loss 0.571370\n",
      "iteration 205 / 300: loss 0.583025\n",
      "iteration 205 / 300: loss 0.608441\n",
      "iteration 205 / 300: loss 0.598359\n",
      "iteration 205 / 300: loss 0.583858\n",
      "iteration 205 / 300: loss 0.615253\n",
      "iteration 205 / 300: loss 0.591649\n",
      "iteration 205 / 300: loss 0.585499\n",
      "iteration 205 / 300: loss 0.591325\n",
      "iteration 205 / 300: loss 0.604341\n",
      "iteration 205 / 300: loss 0.595786\n",
      "iteration 205 / 300: loss 0.614949\n",
      "iteration 205 / 300: loss 0.608389\n",
      "iteration 205 / 300: loss 0.598222\n",
      "iteration 205 / 300: loss 0.588936\n",
      "iteration 205 / 300: loss 0.617757\n",
      "iteration 205 / 300: loss 0.594770\n",
      "iteration 205 / 300: loss 0.601684\n",
      "iteration 205 / 300: loss 0.631031\n",
      "iteration 205 / 300: loss 0.587513\n",
      "iteration 205 / 300: loss 0.606561\n",
      "iteration 205 / 300: loss 0.588034\n",
      "iteration 205 / 300: loss 0.600890\n",
      "iteration 205 / 300: loss 0.595958\n",
      "iteration 205 / 300: loss 0.589291\n",
      "iteration 205 / 300: loss 0.599526\n",
      "iteration 205 / 300: loss 0.604855\n",
      "iteration 205 / 300: loss 0.619414\n",
      "iteration 205 / 300: loss 0.588808\n",
      "iteration 205 / 300: loss 0.593645\n",
      "iteration 205 / 300: loss 0.585595\n",
      "iteration 205 / 300: loss 0.613212\n",
      "iteration 205 / 300: loss 0.587523\n",
      "iteration 205 / 300: loss 0.578328\n",
      "iteration 205 / 300: loss 0.567435\n",
      "iteration 205 / 300: loss 0.562235\n",
      "iteration 205 / 300: loss 0.594183\n",
      "iteration 205 / 300: loss 0.578821\n",
      "iteration 205 / 300: loss 0.586360\n",
      "iteration 205 / 300: loss 0.572890\n",
      "iteration 205 / 300: loss 0.596151\n",
      "iteration 205 / 300: loss 0.607951\n",
      "iteration 205 / 300: loss 0.610839\n",
      "iteration 205 / 300: loss 0.606265\n",
      "iteration 205 / 300: loss 0.583790\n",
      "iteration 205 / 300: loss 0.589627\n",
      "iteration 205 / 300: loss 0.595184\n",
      "iteration 205 / 300: loss 0.598955\n",
      "iteration 205 / 300: loss 0.596133\n",
      "iteration 205 / 300: loss 0.589769\n",
      "iteration 205 / 300: loss 0.591136\n",
      "iteration 205 / 300: loss 0.584854\n",
      "iteration 205 / 300: loss 0.599646\n",
      "iteration 205 / 300: loss 0.598902\n",
      "iteration 205 / 300: loss 0.614282\n",
      "iteration 205 / 300: loss 0.597796\n",
      "iteration 205 / 300: loss 0.599298\n",
      "iteration 205 / 300: loss 0.603317\n",
      "iteration 205 / 300: loss 0.592865\n",
      "iteration 205 / 300: loss 0.592391\n",
      "iteration 205 / 300: loss 0.589041\n",
      "iteration 205 / 300: loss 0.596446\n",
      "iteration 205 / 300: loss 0.605709\n",
      "iteration 205 / 300: loss 0.610562\n",
      "iteration 205 / 300: loss 0.587782\n",
      "iteration 205 / 300: loss 0.599351\n",
      "iteration 205 / 300: loss 0.602792\n",
      "iteration 205 / 300: loss 0.605028\n",
      "iteration 205 / 300: loss 0.603848\n",
      "iteration 205 / 300: loss 0.624144\n",
      "iteration 205 / 300: loss 0.587219\n",
      "iteration 205 / 300: loss 0.580754\n",
      "iteration 205 / 300: loss 0.625045\n",
      "iteration 205 / 300: loss 0.603310\n",
      "iteration 205 / 300: loss 0.604321\n",
      "iteration 205 / 300: loss 0.595476\n",
      "iteration 205 / 300: loss 0.597543\n",
      "iteration 205 / 300: loss 0.592740\n",
      "iteration 205 / 300: loss 0.589494\n",
      "iteration 205 / 300: loss 0.599264\n",
      "iteration 205 / 300: loss 0.611380\n",
      "iteration 205 / 300: loss 0.592463\n",
      "iteration 205 / 300: loss 0.599424\n",
      "iteration 205 / 300: loss 0.603100\n",
      "iteration 205 / 300: loss 0.602410\n",
      "iteration 205 / 300: loss 0.579811\n",
      "iteration 205 / 300: loss 0.601592\n",
      "iteration 206 / 300: loss 0.585528\n",
      "iteration 206 / 300: loss 0.588428\n",
      "iteration 206 / 300: loss 0.567516\n",
      "iteration 206 / 300: loss 0.592380\n",
      "iteration 206 / 300: loss 0.593618\n",
      "iteration 206 / 300: loss 0.595295\n",
      "iteration 206 / 300: loss 0.608784\n",
      "iteration 206 / 300: loss 0.592732\n",
      "iteration 206 / 300: loss 0.628060\n",
      "iteration 206 / 300: loss 0.580152\n",
      "iteration 206 / 300: loss 0.607923\n",
      "iteration 206 / 300: loss 0.587394\n",
      "iteration 206 / 300: loss 0.591686\n",
      "iteration 206 / 300: loss 0.571370\n",
      "iteration 206 / 300: loss 0.583025\n",
      "iteration 206 / 300: loss 0.608441\n",
      "iteration 206 / 300: loss 0.598359\n",
      "iteration 206 / 300: loss 0.583858\n",
      "iteration 206 / 300: loss 0.615253\n",
      "iteration 206 / 300: loss 0.591649\n",
      "iteration 206 / 300: loss 0.585499\n",
      "iteration 206 / 300: loss 0.591325\n",
      "iteration 206 / 300: loss 0.604341\n",
      "iteration 206 / 300: loss 0.595786\n",
      "iteration 206 / 300: loss 0.614949\n",
      "iteration 206 / 300: loss 0.608389\n",
      "iteration 206 / 300: loss 0.598222\n",
      "iteration 206 / 300: loss 0.588936\n",
      "iteration 206 / 300: loss 0.617757\n",
      "iteration 206 / 300: loss 0.594770\n",
      "iteration 206 / 300: loss 0.601684\n",
      "iteration 206 / 300: loss 0.631031\n",
      "iteration 206 / 300: loss 0.587513\n",
      "iteration 206 / 300: loss 0.606561\n",
      "iteration 206 / 300: loss 0.588034\n",
      "iteration 206 / 300: loss 0.600890\n",
      "iteration 206 / 300: loss 0.595958\n",
      "iteration 206 / 300: loss 0.589291\n",
      "iteration 206 / 300: loss 0.599526\n",
      "iteration 206 / 300: loss 0.604855\n",
      "iteration 206 / 300: loss 0.619414\n",
      "iteration 206 / 300: loss 0.588808\n",
      "iteration 206 / 300: loss 0.593645\n",
      "iteration 206 / 300: loss 0.585595\n",
      "iteration 206 / 300: loss 0.613212\n",
      "iteration 206 / 300: loss 0.587523\n",
      "iteration 206 / 300: loss 0.578328\n",
      "iteration 206 / 300: loss 0.567435\n",
      "iteration 206 / 300: loss 0.562235\n",
      "iteration 206 / 300: loss 0.594183\n",
      "iteration 206 / 300: loss 0.578821\n",
      "iteration 206 / 300: loss 0.586360\n",
      "iteration 206 / 300: loss 0.572890\n",
      "iteration 206 / 300: loss 0.596151\n",
      "iteration 206 / 300: loss 0.607951\n",
      "iteration 206 / 300: loss 0.610839\n",
      "iteration 206 / 300: loss 0.606265\n",
      "iteration 206 / 300: loss 0.583790\n",
      "iteration 206 / 300: loss 0.589627\n",
      "iteration 206 / 300: loss 0.595184\n",
      "iteration 206 / 300: loss 0.598955\n",
      "iteration 206 / 300: loss 0.596133\n",
      "iteration 206 / 300: loss 0.589769\n",
      "iteration 206 / 300: loss 0.591136\n",
      "iteration 206 / 300: loss 0.584854\n",
      "iteration 206 / 300: loss 0.599646\n",
      "iteration 206 / 300: loss 0.598902\n",
      "iteration 206 / 300: loss 0.614282\n",
      "iteration 206 / 300: loss 0.597796\n",
      "iteration 206 / 300: loss 0.599298\n",
      "iteration 206 / 300: loss 0.603317\n",
      "iteration 206 / 300: loss 0.592865\n",
      "iteration 206 / 300: loss 0.592391\n",
      "iteration 206 / 300: loss 0.589041\n",
      "iteration 206 / 300: loss 0.596446\n",
      "iteration 206 / 300: loss 0.605709\n",
      "iteration 206 / 300: loss 0.610562\n",
      "iteration 206 / 300: loss 0.587782\n",
      "iteration 206 / 300: loss 0.599351\n",
      "iteration 206 / 300: loss 0.602792\n",
      "iteration 206 / 300: loss 0.605028\n",
      "iteration 206 / 300: loss 0.603848\n",
      "iteration 206 / 300: loss 0.624144\n",
      "iteration 206 / 300: loss 0.587219\n",
      "iteration 206 / 300: loss 0.580754\n",
      "iteration 206 / 300: loss 0.625045\n",
      "iteration 206 / 300: loss 0.603310\n",
      "iteration 206 / 300: loss 0.604321\n",
      "iteration 206 / 300: loss 0.595476\n",
      "iteration 206 / 300: loss 0.597543\n",
      "iteration 206 / 300: loss 0.592740\n",
      "iteration 206 / 300: loss 0.589494\n",
      "iteration 206 / 300: loss 0.599264\n",
      "iteration 206 / 300: loss 0.611380\n",
      "iteration 206 / 300: loss 0.592463\n",
      "iteration 206 / 300: loss 0.599424\n",
      "iteration 206 / 300: loss 0.603100\n",
      "iteration 206 / 300: loss 0.602410\n",
      "iteration 206 / 300: loss 0.579811\n",
      "iteration 206 / 300: loss 0.601592\n",
      "iteration 207 / 300: loss 0.585528\n",
      "iteration 207 / 300: loss 0.588428\n",
      "iteration 207 / 300: loss 0.567516\n",
      "iteration 207 / 300: loss 0.592380\n",
      "iteration 207 / 300: loss 0.593618\n",
      "iteration 207 / 300: loss 0.595295\n",
      "iteration 207 / 300: loss 0.608784\n",
      "iteration 207 / 300: loss 0.592732\n",
      "iteration 207 / 300: loss 0.628060\n",
      "iteration 207 / 300: loss 0.580152\n",
      "iteration 207 / 300: loss 0.607923\n",
      "iteration 207 / 300: loss 0.587394\n",
      "iteration 207 / 300: loss 0.591686\n",
      "iteration 207 / 300: loss 0.571370\n",
      "iteration 207 / 300: loss 0.583025\n",
      "iteration 207 / 300: loss 0.608441\n",
      "iteration 207 / 300: loss 0.598359\n",
      "iteration 207 / 300: loss 0.583858\n",
      "iteration 207 / 300: loss 0.615253\n",
      "iteration 207 / 300: loss 0.591649\n",
      "iteration 207 / 300: loss 0.585499\n",
      "iteration 207 / 300: loss 0.591325\n",
      "iteration 207 / 300: loss 0.604341\n",
      "iteration 207 / 300: loss 0.595786\n",
      "iteration 207 / 300: loss 0.614949\n",
      "iteration 207 / 300: loss 0.608389\n",
      "iteration 207 / 300: loss 0.598222\n",
      "iteration 207 / 300: loss 0.588936\n",
      "iteration 207 / 300: loss 0.617757\n",
      "iteration 207 / 300: loss 0.594770\n",
      "iteration 207 / 300: loss 0.601684\n",
      "iteration 207 / 300: loss 0.631031\n",
      "iteration 207 / 300: loss 0.587513\n",
      "iteration 207 / 300: loss 0.606561\n",
      "iteration 207 / 300: loss 0.588034\n",
      "iteration 207 / 300: loss 0.600890\n",
      "iteration 207 / 300: loss 0.595958\n",
      "iteration 207 / 300: loss 0.589291\n",
      "iteration 207 / 300: loss 0.599526\n",
      "iteration 207 / 300: loss 0.604855\n",
      "iteration 207 / 300: loss 0.619414\n",
      "iteration 207 / 300: loss 0.588808\n",
      "iteration 207 / 300: loss 0.593645\n",
      "iteration 207 / 300: loss 0.585595\n",
      "iteration 207 / 300: loss 0.613212\n",
      "iteration 207 / 300: loss 0.587523\n",
      "iteration 207 / 300: loss 0.578328\n",
      "iteration 207 / 300: loss 0.567435\n",
      "iteration 207 / 300: loss 0.562235\n",
      "iteration 207 / 300: loss 0.594183\n",
      "iteration 207 / 300: loss 0.578821\n",
      "iteration 207 / 300: loss 0.586360\n",
      "iteration 207 / 300: loss 0.572890\n",
      "iteration 207 / 300: loss 0.596151\n",
      "iteration 207 / 300: loss 0.607951\n",
      "iteration 207 / 300: loss 0.610839\n",
      "iteration 207 / 300: loss 0.606265\n",
      "iteration 207 / 300: loss 0.583790\n",
      "iteration 207 / 300: loss 0.589627\n",
      "iteration 207 / 300: loss 0.595184\n",
      "iteration 207 / 300: loss 0.598955\n",
      "iteration 207 / 300: loss 0.596133\n",
      "iteration 207 / 300: loss 0.589769\n",
      "iteration 207 / 300: loss 0.591136\n",
      "iteration 207 / 300: loss 0.584854\n",
      "iteration 207 / 300: loss 0.599646\n",
      "iteration 207 / 300: loss 0.598902\n",
      "iteration 207 / 300: loss 0.614282\n",
      "iteration 207 / 300: loss 0.597796\n",
      "iteration 207 / 300: loss 0.599298\n",
      "iteration 207 / 300: loss 0.603317\n",
      "iteration 207 / 300: loss 0.592865\n",
      "iteration 207 / 300: loss 0.592391\n",
      "iteration 207 / 300: loss 0.589041\n",
      "iteration 207 / 300: loss 0.596446\n",
      "iteration 207 / 300: loss 0.605709\n",
      "iteration 207 / 300: loss 0.610562\n",
      "iteration 207 / 300: loss 0.587782\n",
      "iteration 207 / 300: loss 0.599351\n",
      "iteration 207 / 300: loss 0.602792\n",
      "iteration 207 / 300: loss 0.605028\n",
      "iteration 207 / 300: loss 0.603848\n",
      "iteration 207 / 300: loss 0.624144\n",
      "iteration 207 / 300: loss 0.587219\n",
      "iteration 207 / 300: loss 0.580754\n",
      "iteration 207 / 300: loss 0.625045\n",
      "iteration 207 / 300: loss 0.603310\n",
      "iteration 207 / 300: loss 0.604321\n",
      "iteration 207 / 300: loss 0.595476\n",
      "iteration 207 / 300: loss 0.597543\n",
      "iteration 207 / 300: loss 0.592740\n",
      "iteration 207 / 300: loss 0.589494\n",
      "iteration 207 / 300: loss 0.599264\n",
      "iteration 207 / 300: loss 0.611380\n",
      "iteration 207 / 300: loss 0.592463\n",
      "iteration 207 / 300: loss 0.599424\n",
      "iteration 207 / 300: loss 0.603100\n",
      "iteration 207 / 300: loss 0.602410\n",
      "iteration 207 / 300: loss 0.579811\n",
      "iteration 207 / 300: loss 0.601592\n",
      "iteration 208 / 300: loss 0.585528\n",
      "iteration 208 / 300: loss 0.588428\n",
      "iteration 208 / 300: loss 0.567516\n",
      "iteration 208 / 300: loss 0.592380\n",
      "iteration 208 / 300: loss 0.593618\n",
      "iteration 208 / 300: loss 0.595295\n",
      "iteration 208 / 300: loss 0.608784\n",
      "iteration 208 / 300: loss 0.592732\n",
      "iteration 208 / 300: loss 0.628060\n",
      "iteration 208 / 300: loss 0.580152\n",
      "iteration 208 / 300: loss 0.607923\n",
      "iteration 208 / 300: loss 0.587394\n",
      "iteration 208 / 300: loss 0.591686\n",
      "iteration 208 / 300: loss 0.571370\n",
      "iteration 208 / 300: loss 0.583025\n",
      "iteration 208 / 300: loss 0.608441\n",
      "iteration 208 / 300: loss 0.598359\n",
      "iteration 208 / 300: loss 0.583858\n",
      "iteration 208 / 300: loss 0.615253\n",
      "iteration 208 / 300: loss 0.591649\n",
      "iteration 208 / 300: loss 0.585499\n",
      "iteration 208 / 300: loss 0.591325\n",
      "iteration 208 / 300: loss 0.604341\n",
      "iteration 208 / 300: loss 0.595786\n",
      "iteration 208 / 300: loss 0.614949\n",
      "iteration 208 / 300: loss 0.608389\n",
      "iteration 208 / 300: loss 0.598222\n",
      "iteration 208 / 300: loss 0.588936\n",
      "iteration 208 / 300: loss 0.617757\n",
      "iteration 208 / 300: loss 0.594770\n",
      "iteration 208 / 300: loss 0.601684\n",
      "iteration 208 / 300: loss 0.631031\n",
      "iteration 208 / 300: loss 0.587513\n",
      "iteration 208 / 300: loss 0.606561\n",
      "iteration 208 / 300: loss 0.588034\n",
      "iteration 208 / 300: loss 0.600890\n",
      "iteration 208 / 300: loss 0.595958\n",
      "iteration 208 / 300: loss 0.589291\n",
      "iteration 208 / 300: loss 0.599526\n",
      "iteration 208 / 300: loss 0.604855\n",
      "iteration 208 / 300: loss 0.619414\n",
      "iteration 208 / 300: loss 0.588808\n",
      "iteration 208 / 300: loss 0.593645\n",
      "iteration 208 / 300: loss 0.585595\n",
      "iteration 208 / 300: loss 0.613212\n",
      "iteration 208 / 300: loss 0.587523\n",
      "iteration 208 / 300: loss 0.578328\n",
      "iteration 208 / 300: loss 0.567435\n",
      "iteration 208 / 300: loss 0.562235\n",
      "iteration 208 / 300: loss 0.594183\n",
      "iteration 208 / 300: loss 0.578821\n",
      "iteration 208 / 300: loss 0.586360\n",
      "iteration 208 / 300: loss 0.572890\n",
      "iteration 208 / 300: loss 0.596151\n",
      "iteration 208 / 300: loss 0.607951\n",
      "iteration 208 / 300: loss 0.610839\n",
      "iteration 208 / 300: loss 0.606265\n",
      "iteration 208 / 300: loss 0.583790\n",
      "iteration 208 / 300: loss 0.589627\n",
      "iteration 208 / 300: loss 0.595184\n",
      "iteration 208 / 300: loss 0.598955\n",
      "iteration 208 / 300: loss 0.596133\n",
      "iteration 208 / 300: loss 0.589769\n",
      "iteration 208 / 300: loss 0.591136\n",
      "iteration 208 / 300: loss 0.584854\n",
      "iteration 208 / 300: loss 0.599646\n",
      "iteration 208 / 300: loss 0.598902\n",
      "iteration 208 / 300: loss 0.614282\n",
      "iteration 208 / 300: loss 0.597796\n",
      "iteration 208 / 300: loss 0.599298\n",
      "iteration 208 / 300: loss 0.603317\n",
      "iteration 208 / 300: loss 0.592865\n",
      "iteration 208 / 300: loss 0.592391\n",
      "iteration 208 / 300: loss 0.589041\n",
      "iteration 208 / 300: loss 0.596446\n",
      "iteration 208 / 300: loss 0.605709\n",
      "iteration 208 / 300: loss 0.610562\n",
      "iteration 208 / 300: loss 0.587782\n",
      "iteration 208 / 300: loss 0.599351\n",
      "iteration 208 / 300: loss 0.602792\n",
      "iteration 208 / 300: loss 0.605028\n",
      "iteration 208 / 300: loss 0.603848\n",
      "iteration 208 / 300: loss 0.624144\n",
      "iteration 208 / 300: loss 0.587219\n",
      "iteration 208 / 300: loss 0.580754\n",
      "iteration 208 / 300: loss 0.625045\n",
      "iteration 208 / 300: loss 0.603310\n",
      "iteration 208 / 300: loss 0.604321\n",
      "iteration 208 / 300: loss 0.595476\n",
      "iteration 208 / 300: loss 0.597543\n",
      "iteration 208 / 300: loss 0.592740\n",
      "iteration 208 / 300: loss 0.589494\n",
      "iteration 208 / 300: loss 0.599264\n",
      "iteration 208 / 300: loss 0.611380\n",
      "iteration 208 / 300: loss 0.592463\n",
      "iteration 208 / 300: loss 0.599424\n",
      "iteration 208 / 300: loss 0.603100\n",
      "iteration 208 / 300: loss 0.602410\n",
      "iteration 208 / 300: loss 0.579811\n",
      "iteration 208 / 300: loss 0.601592\n",
      "iteration 209 / 300: loss 0.585528\n",
      "iteration 209 / 300: loss 0.588428\n",
      "iteration 209 / 300: loss 0.567516\n",
      "iteration 209 / 300: loss 0.592380\n",
      "iteration 209 / 300: loss 0.593618\n",
      "iteration 209 / 300: loss 0.595295\n",
      "iteration 209 / 300: loss 0.608784\n",
      "iteration 209 / 300: loss 0.592732\n",
      "iteration 209 / 300: loss 0.628060\n",
      "iteration 209 / 300: loss 0.580152\n",
      "iteration 209 / 300: loss 0.607923\n",
      "iteration 209 / 300: loss 0.587394\n",
      "iteration 209 / 300: loss 0.591686\n",
      "iteration 209 / 300: loss 0.571370\n",
      "iteration 209 / 300: loss 0.583025\n",
      "iteration 209 / 300: loss 0.608441\n",
      "iteration 209 / 300: loss 0.598359\n",
      "iteration 209 / 300: loss 0.583858\n",
      "iteration 209 / 300: loss 0.615253\n",
      "iteration 209 / 300: loss 0.591649\n",
      "iteration 209 / 300: loss 0.585499\n",
      "iteration 209 / 300: loss 0.591325\n",
      "iteration 209 / 300: loss 0.604341\n",
      "iteration 209 / 300: loss 0.595786\n",
      "iteration 209 / 300: loss 0.614949\n",
      "iteration 209 / 300: loss 0.608389\n",
      "iteration 209 / 300: loss 0.598222\n",
      "iteration 209 / 300: loss 0.588936\n",
      "iteration 209 / 300: loss 0.617757\n",
      "iteration 209 / 300: loss 0.594770\n",
      "iteration 209 / 300: loss 0.601684\n",
      "iteration 209 / 300: loss 0.631031\n",
      "iteration 209 / 300: loss 0.587513\n",
      "iteration 209 / 300: loss 0.606561\n",
      "iteration 209 / 300: loss 0.588034\n",
      "iteration 209 / 300: loss 0.600890\n",
      "iteration 209 / 300: loss 0.595958\n",
      "iteration 209 / 300: loss 0.589291\n",
      "iteration 209 / 300: loss 0.599526\n",
      "iteration 209 / 300: loss 0.604855\n",
      "iteration 209 / 300: loss 0.619414\n",
      "iteration 209 / 300: loss 0.588808\n",
      "iteration 209 / 300: loss 0.593645\n",
      "iteration 209 / 300: loss 0.585595\n",
      "iteration 209 / 300: loss 0.613212\n",
      "iteration 209 / 300: loss 0.587523\n",
      "iteration 209 / 300: loss 0.578328\n",
      "iteration 209 / 300: loss 0.567435\n",
      "iteration 209 / 300: loss 0.562235\n",
      "iteration 209 / 300: loss 0.594183\n",
      "iteration 209 / 300: loss 0.578821\n",
      "iteration 209 / 300: loss 0.586360\n",
      "iteration 209 / 300: loss 0.572890\n",
      "iteration 209 / 300: loss 0.596151\n",
      "iteration 209 / 300: loss 0.607951\n",
      "iteration 209 / 300: loss 0.610839\n",
      "iteration 209 / 300: loss 0.606265\n",
      "iteration 209 / 300: loss 0.583790\n",
      "iteration 209 / 300: loss 0.589627\n",
      "iteration 209 / 300: loss 0.595184\n",
      "iteration 209 / 300: loss 0.598955\n",
      "iteration 209 / 300: loss 0.596133\n",
      "iteration 209 / 300: loss 0.589769\n",
      "iteration 209 / 300: loss 0.591136\n",
      "iteration 209 / 300: loss 0.584854\n",
      "iteration 209 / 300: loss 0.599646\n",
      "iteration 209 / 300: loss 0.598902\n",
      "iteration 209 / 300: loss 0.614282\n",
      "iteration 209 / 300: loss 0.597796\n",
      "iteration 209 / 300: loss 0.599298\n",
      "iteration 209 / 300: loss 0.603317\n",
      "iteration 209 / 300: loss 0.592865\n",
      "iteration 209 / 300: loss 0.592391\n",
      "iteration 209 / 300: loss 0.589041\n",
      "iteration 209 / 300: loss 0.596446\n",
      "iteration 209 / 300: loss 0.605709\n",
      "iteration 209 / 300: loss 0.610562\n",
      "iteration 209 / 300: loss 0.587782\n",
      "iteration 209 / 300: loss 0.599351\n",
      "iteration 209 / 300: loss 0.602792\n",
      "iteration 209 / 300: loss 0.605028\n",
      "iteration 209 / 300: loss 0.603848\n",
      "iteration 209 / 300: loss 0.624144\n",
      "iteration 209 / 300: loss 0.587219\n",
      "iteration 209 / 300: loss 0.580754\n",
      "iteration 209 / 300: loss 0.625045\n",
      "iteration 209 / 300: loss 0.603310\n",
      "iteration 209 / 300: loss 0.604321\n",
      "iteration 209 / 300: loss 0.595476\n",
      "iteration 209 / 300: loss 0.597543\n",
      "iteration 209 / 300: loss 0.592740\n",
      "iteration 209 / 300: loss 0.589494\n",
      "iteration 209 / 300: loss 0.599264\n",
      "iteration 209 / 300: loss 0.611380\n",
      "iteration 209 / 300: loss 0.592463\n",
      "iteration 209 / 300: loss 0.599424\n",
      "iteration 209 / 300: loss 0.603100\n",
      "iteration 209 / 300: loss 0.602410\n",
      "iteration 209 / 300: loss 0.579811\n",
      "iteration 209 / 300: loss 0.601592\n",
      "iteration 210 / 300: loss 0.585528\n",
      "iteration 210 / 300: loss 0.588428\n",
      "iteration 210 / 300: loss 0.567516\n",
      "iteration 210 / 300: loss 0.592380\n",
      "iteration 210 / 300: loss 0.593618\n",
      "iteration 210 / 300: loss 0.595295\n",
      "iteration 210 / 300: loss 0.608784\n",
      "iteration 210 / 300: loss 0.592732\n",
      "iteration 210 / 300: loss 0.628060\n",
      "iteration 210 / 300: loss 0.580152\n",
      "iteration 210 / 300: loss 0.607923\n",
      "iteration 210 / 300: loss 0.587394\n",
      "iteration 210 / 300: loss 0.591686\n",
      "iteration 210 / 300: loss 0.571370\n",
      "iteration 210 / 300: loss 0.583025\n",
      "iteration 210 / 300: loss 0.608441\n",
      "iteration 210 / 300: loss 0.598359\n",
      "iteration 210 / 300: loss 0.583858\n",
      "iteration 210 / 300: loss 0.615253\n",
      "iteration 210 / 300: loss 0.591649\n",
      "iteration 210 / 300: loss 0.585499\n",
      "iteration 210 / 300: loss 0.591325\n",
      "iteration 210 / 300: loss 0.604341\n",
      "iteration 210 / 300: loss 0.595786\n",
      "iteration 210 / 300: loss 0.614949\n",
      "iteration 210 / 300: loss 0.608389\n",
      "iteration 210 / 300: loss 0.598222\n",
      "iteration 210 / 300: loss 0.588936\n",
      "iteration 210 / 300: loss 0.617757\n",
      "iteration 210 / 300: loss 0.594770\n",
      "iteration 210 / 300: loss 0.601684\n",
      "iteration 210 / 300: loss 0.631031\n",
      "iteration 210 / 300: loss 0.587513\n",
      "iteration 210 / 300: loss 0.606561\n",
      "iteration 210 / 300: loss 0.588034\n",
      "iteration 210 / 300: loss 0.600890\n",
      "iteration 210 / 300: loss 0.595958\n",
      "iteration 210 / 300: loss 0.589291\n",
      "iteration 210 / 300: loss 0.599526\n",
      "iteration 210 / 300: loss 0.604855\n",
      "iteration 210 / 300: loss 0.619414\n",
      "iteration 210 / 300: loss 0.588808\n",
      "iteration 210 / 300: loss 0.593645\n",
      "iteration 210 / 300: loss 0.585595\n",
      "iteration 210 / 300: loss 0.613212\n",
      "iteration 210 / 300: loss 0.587523\n",
      "iteration 210 / 300: loss 0.578328\n",
      "iteration 210 / 300: loss 0.567435\n",
      "iteration 210 / 300: loss 0.562235\n",
      "iteration 210 / 300: loss 0.594183\n",
      "iteration 210 / 300: loss 0.578821\n",
      "iteration 210 / 300: loss 0.586360\n",
      "iteration 210 / 300: loss 0.572890\n",
      "iteration 210 / 300: loss 0.596151\n",
      "iteration 210 / 300: loss 0.607951\n",
      "iteration 210 / 300: loss 0.610839\n",
      "iteration 210 / 300: loss 0.606265\n",
      "iteration 210 / 300: loss 0.583790\n",
      "iteration 210 / 300: loss 0.589627\n",
      "iteration 210 / 300: loss 0.595184\n",
      "iteration 210 / 300: loss 0.598955\n",
      "iteration 210 / 300: loss 0.596133\n",
      "iteration 210 / 300: loss 0.589769\n",
      "iteration 210 / 300: loss 0.591136\n",
      "iteration 210 / 300: loss 0.584854\n",
      "iteration 210 / 300: loss 0.599646\n",
      "iteration 210 / 300: loss 0.598902\n",
      "iteration 210 / 300: loss 0.614282\n",
      "iteration 210 / 300: loss 0.597796\n",
      "iteration 210 / 300: loss 0.599298\n",
      "iteration 210 / 300: loss 0.603317\n",
      "iteration 210 / 300: loss 0.592865\n",
      "iteration 210 / 300: loss 0.592391\n",
      "iteration 210 / 300: loss 0.589041\n",
      "iteration 210 / 300: loss 0.596446\n",
      "iteration 210 / 300: loss 0.605709\n",
      "iteration 210 / 300: loss 0.610562\n",
      "iteration 210 / 300: loss 0.587782\n",
      "iteration 210 / 300: loss 0.599351\n",
      "iteration 210 / 300: loss 0.602792\n",
      "iteration 210 / 300: loss 0.605028\n",
      "iteration 210 / 300: loss 0.603848\n",
      "iteration 210 / 300: loss 0.624144\n",
      "iteration 210 / 300: loss 0.587219\n",
      "iteration 210 / 300: loss 0.580754\n",
      "iteration 210 / 300: loss 0.625045\n",
      "iteration 210 / 300: loss 0.603310\n",
      "iteration 210 / 300: loss 0.604321\n",
      "iteration 210 / 300: loss 0.595476\n",
      "iteration 210 / 300: loss 0.597543\n",
      "iteration 210 / 300: loss 0.592740\n",
      "iteration 210 / 300: loss 0.589494\n",
      "iteration 210 / 300: loss 0.599264\n",
      "iteration 210 / 300: loss 0.611379\n",
      "iteration 210 / 300: loss 0.592463\n",
      "iteration 210 / 300: loss 0.599424\n",
      "iteration 210 / 300: loss 0.603100\n",
      "iteration 210 / 300: loss 0.602410\n",
      "iteration 210 / 300: loss 0.579811\n",
      "iteration 210 / 300: loss 0.601592\n",
      "iteration 211 / 300: loss 0.585528\n",
      "iteration 211 / 300: loss 0.588428\n",
      "iteration 211 / 300: loss 0.567516\n",
      "iteration 211 / 300: loss 0.592380\n",
      "iteration 211 / 300: loss 0.593618\n",
      "iteration 211 / 300: loss 0.595295\n",
      "iteration 211 / 300: loss 0.608784\n",
      "iteration 211 / 300: loss 0.592732\n",
      "iteration 211 / 300: loss 0.628060\n",
      "iteration 211 / 300: loss 0.580152\n",
      "iteration 211 / 300: loss 0.607923\n",
      "iteration 211 / 300: loss 0.587394\n",
      "iteration 211 / 300: loss 0.591686\n",
      "iteration 211 / 300: loss 0.571370\n",
      "iteration 211 / 300: loss 0.583025\n",
      "iteration 211 / 300: loss 0.608441\n",
      "iteration 211 / 300: loss 0.598359\n",
      "iteration 211 / 300: loss 0.583858\n",
      "iteration 211 / 300: loss 0.615253\n",
      "iteration 211 / 300: loss 0.591649\n",
      "iteration 211 / 300: loss 0.585499\n",
      "iteration 211 / 300: loss 0.591325\n",
      "iteration 211 / 300: loss 0.604341\n",
      "iteration 211 / 300: loss 0.595786\n",
      "iteration 211 / 300: loss 0.614949\n",
      "iteration 211 / 300: loss 0.608389\n",
      "iteration 211 / 300: loss 0.598222\n",
      "iteration 211 / 300: loss 0.588936\n",
      "iteration 211 / 300: loss 0.617757\n",
      "iteration 211 / 300: loss 0.594770\n",
      "iteration 211 / 300: loss 0.601684\n",
      "iteration 211 / 300: loss 0.631031\n",
      "iteration 211 / 300: loss 0.587513\n",
      "iteration 211 / 300: loss 0.606561\n",
      "iteration 211 / 300: loss 0.588034\n",
      "iteration 211 / 300: loss 0.600890\n",
      "iteration 211 / 300: loss 0.595958\n",
      "iteration 211 / 300: loss 0.589291\n",
      "iteration 211 / 300: loss 0.599526\n",
      "iteration 211 / 300: loss 0.604855\n",
      "iteration 211 / 300: loss 0.619414\n",
      "iteration 211 / 300: loss 0.588808\n",
      "iteration 211 / 300: loss 0.593645\n",
      "iteration 211 / 300: loss 0.585595\n",
      "iteration 211 / 300: loss 0.613212\n",
      "iteration 211 / 300: loss 0.587523\n",
      "iteration 211 / 300: loss 0.578328\n",
      "iteration 211 / 300: loss 0.567435\n",
      "iteration 211 / 300: loss 0.562235\n",
      "iteration 211 / 300: loss 0.594183\n",
      "iteration 211 / 300: loss 0.578821\n",
      "iteration 211 / 300: loss 0.586360\n",
      "iteration 211 / 300: loss 0.572890\n",
      "iteration 211 / 300: loss 0.596151\n",
      "iteration 211 / 300: loss 0.607951\n",
      "iteration 211 / 300: loss 0.610839\n",
      "iteration 211 / 300: loss 0.606265\n",
      "iteration 211 / 300: loss 0.583790\n",
      "iteration 211 / 300: loss 0.589627\n",
      "iteration 211 / 300: loss 0.595184\n",
      "iteration 211 / 300: loss 0.598955\n",
      "iteration 211 / 300: loss 0.596133\n",
      "iteration 211 / 300: loss 0.589769\n",
      "iteration 211 / 300: loss 0.591136\n",
      "iteration 211 / 300: loss 0.584854\n",
      "iteration 211 / 300: loss 0.599646\n",
      "iteration 211 / 300: loss 0.598902\n",
      "iteration 211 / 300: loss 0.614282\n",
      "iteration 211 / 300: loss 0.597796\n",
      "iteration 211 / 300: loss 0.599298\n",
      "iteration 211 / 300: loss 0.603317\n",
      "iteration 211 / 300: loss 0.592865\n",
      "iteration 211 / 300: loss 0.592391\n",
      "iteration 211 / 300: loss 0.589041\n",
      "iteration 211 / 300: loss 0.596446\n",
      "iteration 211 / 300: loss 0.605709\n",
      "iteration 211 / 300: loss 0.610562\n",
      "iteration 211 / 300: loss 0.587782\n",
      "iteration 211 / 300: loss 0.599351\n",
      "iteration 211 / 300: loss 0.602792\n",
      "iteration 211 / 300: loss 0.605028\n",
      "iteration 211 / 300: loss 0.603848\n",
      "iteration 211 / 300: loss 0.624144\n",
      "iteration 211 / 300: loss 0.587219\n",
      "iteration 211 / 300: loss 0.580754\n",
      "iteration 211 / 300: loss 0.625045\n",
      "iteration 211 / 300: loss 0.603310\n",
      "iteration 211 / 300: loss 0.604321\n",
      "iteration 211 / 300: loss 0.595476\n",
      "iteration 211 / 300: loss 0.597543\n",
      "iteration 211 / 300: loss 0.592740\n",
      "iteration 211 / 300: loss 0.589494\n",
      "iteration 211 / 300: loss 0.599264\n",
      "iteration 211 / 300: loss 0.611379\n",
      "iteration 211 / 300: loss 0.592463\n",
      "iteration 211 / 300: loss 0.599424\n",
      "iteration 211 / 300: loss 0.603100\n",
      "iteration 211 / 300: loss 0.602410\n",
      "iteration 211 / 300: loss 0.579811\n",
      "iteration 211 / 300: loss 0.601592\n",
      "iteration 212 / 300: loss 0.585528\n",
      "iteration 212 / 300: loss 0.588428\n",
      "iteration 212 / 300: loss 0.567516\n",
      "iteration 212 / 300: loss 0.592380\n",
      "iteration 212 / 300: loss 0.593618\n",
      "iteration 212 / 300: loss 0.595295\n",
      "iteration 212 / 300: loss 0.608784\n",
      "iteration 212 / 300: loss 0.592732\n",
      "iteration 212 / 300: loss 0.628060\n",
      "iteration 212 / 300: loss 0.580152\n",
      "iteration 212 / 300: loss 0.607923\n",
      "iteration 212 / 300: loss 0.587394\n",
      "iteration 212 / 300: loss 0.591686\n",
      "iteration 212 / 300: loss 0.571370\n",
      "iteration 212 / 300: loss 0.583025\n",
      "iteration 212 / 300: loss 0.608441\n",
      "iteration 212 / 300: loss 0.598359\n",
      "iteration 212 / 300: loss 0.583858\n",
      "iteration 212 / 300: loss 0.615253\n",
      "iteration 212 / 300: loss 0.591649\n",
      "iteration 212 / 300: loss 0.585499\n",
      "iteration 212 / 300: loss 0.591325\n",
      "iteration 212 / 300: loss 0.604341\n",
      "iteration 212 / 300: loss 0.595786\n",
      "iteration 212 / 300: loss 0.614949\n",
      "iteration 212 / 300: loss 0.608389\n",
      "iteration 212 / 300: loss 0.598222\n",
      "iteration 212 / 300: loss 0.588936\n",
      "iteration 212 / 300: loss 0.617757\n",
      "iteration 212 / 300: loss 0.594770\n",
      "iteration 212 / 300: loss 0.601684\n",
      "iteration 212 / 300: loss 0.631031\n",
      "iteration 212 / 300: loss 0.587513\n",
      "iteration 212 / 300: loss 0.606561\n",
      "iteration 212 / 300: loss 0.588034\n",
      "iteration 212 / 300: loss 0.600890\n",
      "iteration 212 / 300: loss 0.595958\n",
      "iteration 212 / 300: loss 0.589291\n",
      "iteration 212 / 300: loss 0.599526\n",
      "iteration 212 / 300: loss 0.604855\n",
      "iteration 212 / 300: loss 0.619414\n",
      "iteration 212 / 300: loss 0.588808\n",
      "iteration 212 / 300: loss 0.593645\n",
      "iteration 212 / 300: loss 0.585595\n",
      "iteration 212 / 300: loss 0.613212\n",
      "iteration 212 / 300: loss 0.587523\n",
      "iteration 212 / 300: loss 0.578328\n",
      "iteration 212 / 300: loss 0.567435\n",
      "iteration 212 / 300: loss 0.562235\n",
      "iteration 212 / 300: loss 0.594183\n",
      "iteration 212 / 300: loss 0.578821\n",
      "iteration 212 / 300: loss 0.586360\n",
      "iteration 212 / 300: loss 0.572890\n",
      "iteration 212 / 300: loss 0.596151\n",
      "iteration 212 / 300: loss 0.607951\n",
      "iteration 212 / 300: loss 0.610839\n",
      "iteration 212 / 300: loss 0.606265\n",
      "iteration 212 / 300: loss 0.583790\n",
      "iteration 212 / 300: loss 0.589627\n",
      "iteration 212 / 300: loss 0.595184\n",
      "iteration 212 / 300: loss 0.598955\n",
      "iteration 212 / 300: loss 0.596133\n",
      "iteration 212 / 300: loss 0.589769\n",
      "iteration 212 / 300: loss 0.591136\n",
      "iteration 212 / 300: loss 0.584854\n",
      "iteration 212 / 300: loss 0.599646\n",
      "iteration 212 / 300: loss 0.598902\n",
      "iteration 212 / 300: loss 0.614282\n",
      "iteration 212 / 300: loss 0.597796\n",
      "iteration 212 / 300: loss 0.599298\n",
      "iteration 212 / 300: loss 0.603317\n",
      "iteration 212 / 300: loss 0.592865\n",
      "iteration 212 / 300: loss 0.592391\n",
      "iteration 212 / 300: loss 0.589041\n",
      "iteration 212 / 300: loss 0.596446\n",
      "iteration 212 / 300: loss 0.605709\n",
      "iteration 212 / 300: loss 0.610562\n",
      "iteration 212 / 300: loss 0.587782\n",
      "iteration 212 / 300: loss 0.599351\n",
      "iteration 212 / 300: loss 0.602792\n",
      "iteration 212 / 300: loss 0.605028\n",
      "iteration 212 / 300: loss 0.603848\n",
      "iteration 212 / 300: loss 0.624144\n",
      "iteration 212 / 300: loss 0.587219\n",
      "iteration 212 / 300: loss 0.580754\n",
      "iteration 212 / 300: loss 0.625045\n",
      "iteration 212 / 300: loss 0.603310\n",
      "iteration 212 / 300: loss 0.604321\n",
      "iteration 212 / 300: loss 0.595476\n",
      "iteration 212 / 300: loss 0.597543\n",
      "iteration 212 / 300: loss 0.592740\n",
      "iteration 212 / 300: loss 0.589494\n",
      "iteration 212 / 300: loss 0.599264\n",
      "iteration 212 / 300: loss 0.611379\n",
      "iteration 212 / 300: loss 0.592463\n",
      "iteration 212 / 300: loss 0.599424\n",
      "iteration 212 / 300: loss 0.603100\n",
      "iteration 212 / 300: loss 0.602410\n",
      "iteration 212 / 300: loss 0.579811\n",
      "iteration 212 / 300: loss 0.601592\n",
      "iteration 213 / 300: loss 0.585528\n",
      "iteration 213 / 300: loss 0.588428\n",
      "iteration 213 / 300: loss 0.567516\n",
      "iteration 213 / 300: loss 0.592380\n",
      "iteration 213 / 300: loss 0.593618\n",
      "iteration 213 / 300: loss 0.595295\n",
      "iteration 213 / 300: loss 0.608784\n",
      "iteration 213 / 300: loss 0.592732\n",
      "iteration 213 / 300: loss 0.628060\n",
      "iteration 213 / 300: loss 0.580152\n",
      "iteration 213 / 300: loss 0.607923\n",
      "iteration 213 / 300: loss 0.587394\n",
      "iteration 213 / 300: loss 0.591686\n",
      "iteration 213 / 300: loss 0.571370\n",
      "iteration 213 / 300: loss 0.583025\n",
      "iteration 213 / 300: loss 0.608441\n",
      "iteration 213 / 300: loss 0.598359\n",
      "iteration 213 / 300: loss 0.583858\n",
      "iteration 213 / 300: loss 0.615253\n",
      "iteration 213 / 300: loss 0.591649\n",
      "iteration 213 / 300: loss 0.585499\n",
      "iteration 213 / 300: loss 0.591325\n",
      "iteration 213 / 300: loss 0.604341\n",
      "iteration 213 / 300: loss 0.595786\n",
      "iteration 213 / 300: loss 0.614949\n",
      "iteration 213 / 300: loss 0.608389\n",
      "iteration 213 / 300: loss 0.598222\n",
      "iteration 213 / 300: loss 0.588936\n",
      "iteration 213 / 300: loss 0.617757\n",
      "iteration 213 / 300: loss 0.594770\n",
      "iteration 213 / 300: loss 0.601684\n",
      "iteration 213 / 300: loss 0.631031\n",
      "iteration 213 / 300: loss 0.587513\n",
      "iteration 213 / 300: loss 0.606561\n",
      "iteration 213 / 300: loss 0.588034\n",
      "iteration 213 / 300: loss 0.600890\n",
      "iteration 213 / 300: loss 0.595958\n",
      "iteration 213 / 300: loss 0.589291\n",
      "iteration 213 / 300: loss 0.599526\n",
      "iteration 213 / 300: loss 0.604855\n",
      "iteration 213 / 300: loss 0.619414\n",
      "iteration 213 / 300: loss 0.588808\n",
      "iteration 213 / 300: loss 0.593645\n",
      "iteration 213 / 300: loss 0.585595\n",
      "iteration 213 / 300: loss 0.613212\n",
      "iteration 213 / 300: loss 0.587523\n",
      "iteration 213 / 300: loss 0.578328\n",
      "iteration 213 / 300: loss 0.567435\n",
      "iteration 213 / 300: loss 0.562235\n",
      "iteration 213 / 300: loss 0.594183\n",
      "iteration 213 / 300: loss 0.578821\n",
      "iteration 213 / 300: loss 0.586360\n",
      "iteration 213 / 300: loss 0.572890\n",
      "iteration 213 / 300: loss 0.596151\n",
      "iteration 213 / 300: loss 0.607951\n",
      "iteration 213 / 300: loss 0.610839\n",
      "iteration 213 / 300: loss 0.606265\n",
      "iteration 213 / 300: loss 0.583790\n",
      "iteration 213 / 300: loss 0.589627\n",
      "iteration 213 / 300: loss 0.595184\n",
      "iteration 213 / 300: loss 0.598955\n",
      "iteration 213 / 300: loss 0.596133\n",
      "iteration 213 / 300: loss 0.589769\n",
      "iteration 213 / 300: loss 0.591136\n",
      "iteration 213 / 300: loss 0.584854\n",
      "iteration 213 / 300: loss 0.599646\n",
      "iteration 213 / 300: loss 0.598902\n",
      "iteration 213 / 300: loss 0.614282\n",
      "iteration 213 / 300: loss 0.597796\n",
      "iteration 213 / 300: loss 0.599298\n",
      "iteration 213 / 300: loss 0.603317\n",
      "iteration 213 / 300: loss 0.592865\n",
      "iteration 213 / 300: loss 0.592391\n",
      "iteration 213 / 300: loss 0.589041\n",
      "iteration 213 / 300: loss 0.596446\n",
      "iteration 213 / 300: loss 0.605709\n",
      "iteration 213 / 300: loss 0.610562\n",
      "iteration 213 / 300: loss 0.587782\n",
      "iteration 213 / 300: loss 0.599351\n",
      "iteration 213 / 300: loss 0.602792\n",
      "iteration 213 / 300: loss 0.605028\n",
      "iteration 213 / 300: loss 0.603848\n",
      "iteration 213 / 300: loss 0.624144\n",
      "iteration 213 / 300: loss 0.587219\n",
      "iteration 213 / 300: loss 0.580754\n",
      "iteration 213 / 300: loss 0.625045\n",
      "iteration 213 / 300: loss 0.603310\n",
      "iteration 213 / 300: loss 0.604321\n",
      "iteration 213 / 300: loss 0.595476\n",
      "iteration 213 / 300: loss 0.597543\n",
      "iteration 213 / 300: loss 0.592740\n",
      "iteration 213 / 300: loss 0.589494\n",
      "iteration 213 / 300: loss 0.599264\n",
      "iteration 213 / 300: loss 0.611379\n",
      "iteration 213 / 300: loss 0.592463\n",
      "iteration 213 / 300: loss 0.599424\n",
      "iteration 213 / 300: loss 0.603100\n",
      "iteration 213 / 300: loss 0.602410\n",
      "iteration 213 / 300: loss 0.579811\n",
      "iteration 213 / 300: loss 0.601592\n",
      "iteration 214 / 300: loss 0.585528\n",
      "iteration 214 / 300: loss 0.588428\n",
      "iteration 214 / 300: loss 0.567516\n",
      "iteration 214 / 300: loss 0.592380\n",
      "iteration 214 / 300: loss 0.593618\n",
      "iteration 214 / 300: loss 0.595295\n",
      "iteration 214 / 300: loss 0.608784\n",
      "iteration 214 / 300: loss 0.592732\n",
      "iteration 214 / 300: loss 0.628060\n",
      "iteration 214 / 300: loss 0.580152\n",
      "iteration 214 / 300: loss 0.607923\n",
      "iteration 214 / 300: loss 0.587394\n",
      "iteration 214 / 300: loss 0.591686\n",
      "iteration 214 / 300: loss 0.571370\n",
      "iteration 214 / 300: loss 0.583025\n",
      "iteration 214 / 300: loss 0.608441\n",
      "iteration 214 / 300: loss 0.598359\n",
      "iteration 214 / 300: loss 0.583858\n",
      "iteration 214 / 300: loss 0.615253\n",
      "iteration 214 / 300: loss 0.591649\n",
      "iteration 214 / 300: loss 0.585499\n",
      "iteration 214 / 300: loss 0.591325\n",
      "iteration 214 / 300: loss 0.604341\n",
      "iteration 214 / 300: loss 0.595786\n",
      "iteration 214 / 300: loss 0.614949\n",
      "iteration 214 / 300: loss 0.608389\n",
      "iteration 214 / 300: loss 0.598222\n",
      "iteration 214 / 300: loss 0.588936\n",
      "iteration 214 / 300: loss 0.617757\n",
      "iteration 214 / 300: loss 0.594770\n",
      "iteration 214 / 300: loss 0.601684\n",
      "iteration 214 / 300: loss 0.631031\n",
      "iteration 214 / 300: loss 0.587513\n",
      "iteration 214 / 300: loss 0.606561\n",
      "iteration 214 / 300: loss 0.588034\n",
      "iteration 214 / 300: loss 0.600890\n",
      "iteration 214 / 300: loss 0.595958\n",
      "iteration 214 / 300: loss 0.589291\n",
      "iteration 214 / 300: loss 0.599526\n",
      "iteration 214 / 300: loss 0.604855\n",
      "iteration 214 / 300: loss 0.619414\n",
      "iteration 214 / 300: loss 0.588808\n",
      "iteration 214 / 300: loss 0.593645\n",
      "iteration 214 / 300: loss 0.585595\n",
      "iteration 214 / 300: loss 0.613212\n",
      "iteration 214 / 300: loss 0.587523\n",
      "iteration 214 / 300: loss 0.578328\n",
      "iteration 214 / 300: loss 0.567435\n",
      "iteration 214 / 300: loss 0.562235\n",
      "iteration 214 / 300: loss 0.594183\n",
      "iteration 214 / 300: loss 0.578821\n",
      "iteration 214 / 300: loss 0.586360\n",
      "iteration 214 / 300: loss 0.572890\n",
      "iteration 214 / 300: loss 0.596151\n",
      "iteration 214 / 300: loss 0.607951\n",
      "iteration 214 / 300: loss 0.610839\n",
      "iteration 214 / 300: loss 0.606265\n",
      "iteration 214 / 300: loss 0.583790\n",
      "iteration 214 / 300: loss 0.589627\n",
      "iteration 214 / 300: loss 0.595184\n",
      "iteration 214 / 300: loss 0.598955\n",
      "iteration 214 / 300: loss 0.596133\n",
      "iteration 214 / 300: loss 0.589769\n",
      "iteration 214 / 300: loss 0.591136\n",
      "iteration 214 / 300: loss 0.584854\n",
      "iteration 214 / 300: loss 0.599646\n",
      "iteration 214 / 300: loss 0.598902\n",
      "iteration 214 / 300: loss 0.614282\n",
      "iteration 214 / 300: loss 0.597796\n",
      "iteration 214 / 300: loss 0.599298\n",
      "iteration 214 / 300: loss 0.603317\n",
      "iteration 214 / 300: loss 0.592865\n",
      "iteration 214 / 300: loss 0.592391\n",
      "iteration 214 / 300: loss 0.589041\n",
      "iteration 214 / 300: loss 0.596446\n",
      "iteration 214 / 300: loss 0.605709\n",
      "iteration 214 / 300: loss 0.610562\n",
      "iteration 214 / 300: loss 0.587782\n",
      "iteration 214 / 300: loss 0.599351\n",
      "iteration 214 / 300: loss 0.602792\n",
      "iteration 214 / 300: loss 0.605028\n",
      "iteration 214 / 300: loss 0.603848\n",
      "iteration 214 / 300: loss 0.624144\n",
      "iteration 214 / 300: loss 0.587219\n",
      "iteration 214 / 300: loss 0.580754\n",
      "iteration 214 / 300: loss 0.625045\n",
      "iteration 214 / 300: loss 0.603310\n",
      "iteration 214 / 300: loss 0.604321\n",
      "iteration 214 / 300: loss 0.595476\n",
      "iteration 214 / 300: loss 0.597543\n",
      "iteration 214 / 300: loss 0.592740\n",
      "iteration 214 / 300: loss 0.589494\n",
      "iteration 214 / 300: loss 0.599264\n",
      "iteration 214 / 300: loss 0.611379\n",
      "iteration 214 / 300: loss 0.592463\n",
      "iteration 214 / 300: loss 0.599424\n",
      "iteration 214 / 300: loss 0.603100\n",
      "iteration 214 / 300: loss 0.602410\n",
      "iteration 214 / 300: loss 0.579811\n",
      "iteration 214 / 300: loss 0.601592\n",
      "iteration 215 / 300: loss 0.585528\n",
      "iteration 215 / 300: loss 0.588428\n",
      "iteration 215 / 300: loss 0.567516\n",
      "iteration 215 / 300: loss 0.592380\n",
      "iteration 215 / 300: loss 0.593618\n",
      "iteration 215 / 300: loss 0.595295\n",
      "iteration 215 / 300: loss 0.608784\n",
      "iteration 215 / 300: loss 0.592732\n",
      "iteration 215 / 300: loss 0.628060\n",
      "iteration 215 / 300: loss 0.580152\n",
      "iteration 215 / 300: loss 0.607923\n",
      "iteration 215 / 300: loss 0.587394\n",
      "iteration 215 / 300: loss 0.591686\n",
      "iteration 215 / 300: loss 0.571370\n",
      "iteration 215 / 300: loss 0.583025\n",
      "iteration 215 / 300: loss 0.608441\n",
      "iteration 215 / 300: loss 0.598359\n",
      "iteration 215 / 300: loss 0.583858\n",
      "iteration 215 / 300: loss 0.615253\n",
      "iteration 215 / 300: loss 0.591649\n",
      "iteration 215 / 300: loss 0.585499\n",
      "iteration 215 / 300: loss 0.591325\n",
      "iteration 215 / 300: loss 0.604341\n",
      "iteration 215 / 300: loss 0.595786\n",
      "iteration 215 / 300: loss 0.614949\n",
      "iteration 215 / 300: loss 0.608389\n",
      "iteration 215 / 300: loss 0.598222\n",
      "iteration 215 / 300: loss 0.588936\n",
      "iteration 215 / 300: loss 0.617757\n",
      "iteration 215 / 300: loss 0.594770\n",
      "iteration 215 / 300: loss 0.601684\n",
      "iteration 215 / 300: loss 0.631031\n",
      "iteration 215 / 300: loss 0.587513\n",
      "iteration 215 / 300: loss 0.606561\n",
      "iteration 215 / 300: loss 0.588034\n",
      "iteration 215 / 300: loss 0.600890\n",
      "iteration 215 / 300: loss 0.595958\n",
      "iteration 215 / 300: loss 0.589291\n",
      "iteration 215 / 300: loss 0.599526\n",
      "iteration 215 / 300: loss 0.604855\n",
      "iteration 215 / 300: loss 0.619414\n",
      "iteration 215 / 300: loss 0.588808\n",
      "iteration 215 / 300: loss 0.593645\n",
      "iteration 215 / 300: loss 0.585595\n",
      "iteration 215 / 300: loss 0.613212\n",
      "iteration 215 / 300: loss 0.587523\n",
      "iteration 215 / 300: loss 0.578328\n",
      "iteration 215 / 300: loss 0.567435\n",
      "iteration 215 / 300: loss 0.562235\n",
      "iteration 215 / 300: loss 0.594183\n",
      "iteration 215 / 300: loss 0.578821\n",
      "iteration 215 / 300: loss 0.586360\n",
      "iteration 215 / 300: loss 0.572890\n",
      "iteration 215 / 300: loss 0.596151\n",
      "iteration 215 / 300: loss 0.607951\n",
      "iteration 215 / 300: loss 0.610839\n",
      "iteration 215 / 300: loss 0.606265\n",
      "iteration 215 / 300: loss 0.583790\n",
      "iteration 215 / 300: loss 0.589627\n",
      "iteration 215 / 300: loss 0.595184\n",
      "iteration 215 / 300: loss 0.598955\n",
      "iteration 215 / 300: loss 0.596133\n",
      "iteration 215 / 300: loss 0.589769\n",
      "iteration 215 / 300: loss 0.591136\n",
      "iteration 215 / 300: loss 0.584854\n",
      "iteration 215 / 300: loss 0.599646\n",
      "iteration 215 / 300: loss 0.598902\n",
      "iteration 215 / 300: loss 0.614282\n",
      "iteration 215 / 300: loss 0.597796\n",
      "iteration 215 / 300: loss 0.599298\n",
      "iteration 215 / 300: loss 0.603317\n",
      "iteration 215 / 300: loss 0.592865\n",
      "iteration 215 / 300: loss 0.592391\n",
      "iteration 215 / 300: loss 0.589041\n",
      "iteration 215 / 300: loss 0.596446\n",
      "iteration 215 / 300: loss 0.605709\n",
      "iteration 215 / 300: loss 0.610562\n",
      "iteration 215 / 300: loss 0.587782\n",
      "iteration 215 / 300: loss 0.599351\n",
      "iteration 215 / 300: loss 0.602792\n",
      "iteration 215 / 300: loss 0.605028\n",
      "iteration 215 / 300: loss 0.603848\n",
      "iteration 215 / 300: loss 0.624144\n",
      "iteration 215 / 300: loss 0.587219\n",
      "iteration 215 / 300: loss 0.580754\n",
      "iteration 215 / 300: loss 0.625045\n",
      "iteration 215 / 300: loss 0.603310\n",
      "iteration 215 / 300: loss 0.604321\n",
      "iteration 215 / 300: loss 0.595476\n",
      "iteration 215 / 300: loss 0.597543\n",
      "iteration 215 / 300: loss 0.592740\n",
      "iteration 215 / 300: loss 0.589494\n",
      "iteration 215 / 300: loss 0.599264\n",
      "iteration 215 / 300: loss 0.611379\n",
      "iteration 215 / 300: loss 0.592463\n",
      "iteration 215 / 300: loss 0.599424\n",
      "iteration 215 / 300: loss 0.603100\n",
      "iteration 215 / 300: loss 0.602410\n",
      "iteration 215 / 300: loss 0.579811\n",
      "iteration 215 / 300: loss 0.601592\n",
      "iteration 216 / 300: loss 0.585528\n",
      "iteration 216 / 300: loss 0.588428\n",
      "iteration 216 / 300: loss 0.567516\n",
      "iteration 216 / 300: loss 0.592380\n",
      "iteration 216 / 300: loss 0.593618\n",
      "iteration 216 / 300: loss 0.595295\n",
      "iteration 216 / 300: loss 0.608784\n",
      "iteration 216 / 300: loss 0.592732\n",
      "iteration 216 / 300: loss 0.628060\n",
      "iteration 216 / 300: loss 0.580152\n",
      "iteration 216 / 300: loss 0.607923\n",
      "iteration 216 / 300: loss 0.587394\n",
      "iteration 216 / 300: loss 0.591686\n",
      "iteration 216 / 300: loss 0.571370\n",
      "iteration 216 / 300: loss 0.583025\n",
      "iteration 216 / 300: loss 0.608441\n",
      "iteration 216 / 300: loss 0.598359\n",
      "iteration 216 / 300: loss 0.583858\n",
      "iteration 216 / 300: loss 0.615253\n",
      "iteration 216 / 300: loss 0.591649\n",
      "iteration 216 / 300: loss 0.585499\n",
      "iteration 216 / 300: loss 0.591325\n",
      "iteration 216 / 300: loss 0.604341\n",
      "iteration 216 / 300: loss 0.595786\n",
      "iteration 216 / 300: loss 0.614949\n",
      "iteration 216 / 300: loss 0.608389\n",
      "iteration 216 / 300: loss 0.598222\n",
      "iteration 216 / 300: loss 0.588936\n",
      "iteration 216 / 300: loss 0.617757\n",
      "iteration 216 / 300: loss 0.594770\n",
      "iteration 216 / 300: loss 0.601684\n",
      "iteration 216 / 300: loss 0.631031\n",
      "iteration 216 / 300: loss 0.587513\n",
      "iteration 216 / 300: loss 0.606561\n",
      "iteration 216 / 300: loss 0.588034\n",
      "iteration 216 / 300: loss 0.600890\n",
      "iteration 216 / 300: loss 0.595958\n",
      "iteration 216 / 300: loss 0.589291\n",
      "iteration 216 / 300: loss 0.599526\n",
      "iteration 216 / 300: loss 0.604855\n",
      "iteration 216 / 300: loss 0.619414\n",
      "iteration 216 / 300: loss 0.588808\n",
      "iteration 216 / 300: loss 0.593645\n",
      "iteration 216 / 300: loss 0.585595\n",
      "iteration 216 / 300: loss 0.613212\n",
      "iteration 216 / 300: loss 0.587523\n",
      "iteration 216 / 300: loss 0.578328\n",
      "iteration 216 / 300: loss 0.567435\n",
      "iteration 216 / 300: loss 0.562235\n",
      "iteration 216 / 300: loss 0.594183\n",
      "iteration 216 / 300: loss 0.578821\n",
      "iteration 216 / 300: loss 0.586360\n",
      "iteration 216 / 300: loss 0.572890\n",
      "iteration 216 / 300: loss 0.596151\n",
      "iteration 216 / 300: loss 0.607951\n",
      "iteration 216 / 300: loss 0.610839\n",
      "iteration 216 / 300: loss 0.606265\n",
      "iteration 216 / 300: loss 0.583790\n",
      "iteration 216 / 300: loss 0.589627\n",
      "iteration 216 / 300: loss 0.595184\n",
      "iteration 216 / 300: loss 0.598955\n",
      "iteration 216 / 300: loss 0.596133\n",
      "iteration 216 / 300: loss 0.589769\n",
      "iteration 216 / 300: loss 0.591136\n",
      "iteration 216 / 300: loss 0.584854\n",
      "iteration 216 / 300: loss 0.599646\n",
      "iteration 216 / 300: loss 0.598902\n",
      "iteration 216 / 300: loss 0.614282\n",
      "iteration 216 / 300: loss 0.597796\n",
      "iteration 216 / 300: loss 0.599298\n",
      "iteration 216 / 300: loss 0.603317\n",
      "iteration 216 / 300: loss 0.592865\n",
      "iteration 216 / 300: loss 0.592391\n",
      "iteration 216 / 300: loss 0.589041\n",
      "iteration 216 / 300: loss 0.596446\n",
      "iteration 216 / 300: loss 0.605709\n",
      "iteration 216 / 300: loss 0.610562\n",
      "iteration 216 / 300: loss 0.587782\n",
      "iteration 216 / 300: loss 0.599351\n",
      "iteration 216 / 300: loss 0.602792\n",
      "iteration 216 / 300: loss 0.605028\n",
      "iteration 216 / 300: loss 0.603848\n",
      "iteration 216 / 300: loss 0.624144\n",
      "iteration 216 / 300: loss 0.587219\n",
      "iteration 216 / 300: loss 0.580754\n",
      "iteration 216 / 300: loss 0.625045\n",
      "iteration 216 / 300: loss 0.603310\n",
      "iteration 216 / 300: loss 0.604321\n",
      "iteration 216 / 300: loss 0.595476\n",
      "iteration 216 / 300: loss 0.597543\n",
      "iteration 216 / 300: loss 0.592740\n",
      "iteration 216 / 300: loss 0.589494\n",
      "iteration 216 / 300: loss 0.599264\n",
      "iteration 216 / 300: loss 0.611379\n",
      "iteration 216 / 300: loss 0.592463\n",
      "iteration 216 / 300: loss 0.599424\n",
      "iteration 216 / 300: loss 0.603100\n",
      "iteration 216 / 300: loss 0.602410\n",
      "iteration 216 / 300: loss 0.579811\n",
      "iteration 216 / 300: loss 0.601592\n",
      "iteration 217 / 300: loss 0.585528\n",
      "iteration 217 / 300: loss 0.588428\n",
      "iteration 217 / 300: loss 0.567516\n",
      "iteration 217 / 300: loss 0.592380\n",
      "iteration 217 / 300: loss 0.593618\n",
      "iteration 217 / 300: loss 0.595295\n",
      "iteration 217 / 300: loss 0.608784\n",
      "iteration 217 / 300: loss 0.592732\n",
      "iteration 217 / 300: loss 0.628060\n",
      "iteration 217 / 300: loss 0.580152\n",
      "iteration 217 / 300: loss 0.607923\n",
      "iteration 217 / 300: loss 0.587394\n",
      "iteration 217 / 300: loss 0.591686\n",
      "iteration 217 / 300: loss 0.571370\n",
      "iteration 217 / 300: loss 0.583025\n",
      "iteration 217 / 300: loss 0.608441\n",
      "iteration 217 / 300: loss 0.598359\n",
      "iteration 217 / 300: loss 0.583858\n",
      "iteration 217 / 300: loss 0.615253\n",
      "iteration 217 / 300: loss 0.591649\n",
      "iteration 217 / 300: loss 0.585499\n",
      "iteration 217 / 300: loss 0.591325\n",
      "iteration 217 / 300: loss 0.604341\n",
      "iteration 217 / 300: loss 0.595786\n",
      "iteration 217 / 300: loss 0.614949\n",
      "iteration 217 / 300: loss 0.608389\n",
      "iteration 217 / 300: loss 0.598222\n",
      "iteration 217 / 300: loss 0.588936\n",
      "iteration 217 / 300: loss 0.617757\n",
      "iteration 217 / 300: loss 0.594770\n",
      "iteration 217 / 300: loss 0.601684\n",
      "iteration 217 / 300: loss 0.631031\n",
      "iteration 217 / 300: loss 0.587513\n",
      "iteration 217 / 300: loss 0.606561\n",
      "iteration 217 / 300: loss 0.588034\n",
      "iteration 217 / 300: loss 0.600890\n",
      "iteration 217 / 300: loss 0.595958\n",
      "iteration 217 / 300: loss 0.589291\n",
      "iteration 217 / 300: loss 0.599526\n",
      "iteration 217 / 300: loss 0.604855\n",
      "iteration 217 / 300: loss 0.619414\n",
      "iteration 217 / 300: loss 0.588808\n",
      "iteration 217 / 300: loss 0.593645\n",
      "iteration 217 / 300: loss 0.585595\n",
      "iteration 217 / 300: loss 0.613212\n",
      "iteration 217 / 300: loss 0.587523\n",
      "iteration 217 / 300: loss 0.578328\n",
      "iteration 217 / 300: loss 0.567435\n",
      "iteration 217 / 300: loss 0.562235\n",
      "iteration 217 / 300: loss 0.594183\n",
      "iteration 217 / 300: loss 0.578821\n",
      "iteration 217 / 300: loss 0.586360\n",
      "iteration 217 / 300: loss 0.572890\n",
      "iteration 217 / 300: loss 0.596151\n",
      "iteration 217 / 300: loss 0.607951\n",
      "iteration 217 / 300: loss 0.610839\n",
      "iteration 217 / 300: loss 0.606265\n",
      "iteration 217 / 300: loss 0.583790\n",
      "iteration 217 / 300: loss 0.589627\n",
      "iteration 217 / 300: loss 0.595184\n",
      "iteration 217 / 300: loss 0.598955\n",
      "iteration 217 / 300: loss 0.596133\n",
      "iteration 217 / 300: loss 0.589769\n",
      "iteration 217 / 300: loss 0.591136\n",
      "iteration 217 / 300: loss 0.584854\n",
      "iteration 217 / 300: loss 0.599646\n",
      "iteration 217 / 300: loss 0.598902\n",
      "iteration 217 / 300: loss 0.614282\n",
      "iteration 217 / 300: loss 0.597796\n",
      "iteration 217 / 300: loss 0.599298\n",
      "iteration 217 / 300: loss 0.603317\n",
      "iteration 217 / 300: loss 0.592865\n",
      "iteration 217 / 300: loss 0.592391\n",
      "iteration 217 / 300: loss 0.589041\n",
      "iteration 217 / 300: loss 0.596446\n",
      "iteration 217 / 300: loss 0.605709\n",
      "iteration 217 / 300: loss 0.610562\n",
      "iteration 217 / 300: loss 0.587782\n",
      "iteration 217 / 300: loss 0.599351\n",
      "iteration 217 / 300: loss 0.602792\n",
      "iteration 217 / 300: loss 0.605028\n",
      "iteration 217 / 300: loss 0.603848\n",
      "iteration 217 / 300: loss 0.624144\n",
      "iteration 217 / 300: loss 0.587219\n",
      "iteration 217 / 300: loss 0.580754\n",
      "iteration 217 / 300: loss 0.625045\n",
      "iteration 217 / 300: loss 0.603310\n",
      "iteration 217 / 300: loss 0.604321\n",
      "iteration 217 / 300: loss 0.595476\n",
      "iteration 217 / 300: loss 0.597543\n",
      "iteration 217 / 300: loss 0.592740\n",
      "iteration 217 / 300: loss 0.589494\n",
      "iteration 217 / 300: loss 0.599264\n",
      "iteration 217 / 300: loss 0.611379\n",
      "iteration 217 / 300: loss 0.592463\n",
      "iteration 217 / 300: loss 0.599424\n",
      "iteration 217 / 300: loss 0.603100\n",
      "iteration 217 / 300: loss 0.602410\n",
      "iteration 217 / 300: loss 0.579811\n",
      "iteration 217 / 300: loss 0.601592\n",
      "iteration 218 / 300: loss 0.585528\n",
      "iteration 218 / 300: loss 0.588428\n",
      "iteration 218 / 300: loss 0.567516\n",
      "iteration 218 / 300: loss 0.592380\n",
      "iteration 218 / 300: loss 0.593618\n",
      "iteration 218 / 300: loss 0.595295\n",
      "iteration 218 / 300: loss 0.608784\n",
      "iteration 218 / 300: loss 0.592732\n",
      "iteration 218 / 300: loss 0.628060\n",
      "iteration 218 / 300: loss 0.580152\n",
      "iteration 218 / 300: loss 0.607923\n",
      "iteration 218 / 300: loss 0.587394\n",
      "iteration 218 / 300: loss 0.591686\n",
      "iteration 218 / 300: loss 0.571370\n",
      "iteration 218 / 300: loss 0.583025\n",
      "iteration 218 / 300: loss 0.608441\n",
      "iteration 218 / 300: loss 0.598359\n",
      "iteration 218 / 300: loss 0.583858\n",
      "iteration 218 / 300: loss 0.615253\n",
      "iteration 218 / 300: loss 0.591649\n",
      "iteration 218 / 300: loss 0.585499\n",
      "iteration 218 / 300: loss 0.591325\n",
      "iteration 218 / 300: loss 0.604341\n",
      "iteration 218 / 300: loss 0.595786\n",
      "iteration 218 / 300: loss 0.614949\n",
      "iteration 218 / 300: loss 0.608389\n",
      "iteration 218 / 300: loss 0.598222\n",
      "iteration 218 / 300: loss 0.588936\n",
      "iteration 218 / 300: loss 0.617757\n",
      "iteration 218 / 300: loss 0.594770\n",
      "iteration 218 / 300: loss 0.601684\n",
      "iteration 218 / 300: loss 0.631031\n",
      "iteration 218 / 300: loss 0.587513\n",
      "iteration 218 / 300: loss 0.606561\n",
      "iteration 218 / 300: loss 0.588034\n",
      "iteration 218 / 300: loss 0.600890\n",
      "iteration 218 / 300: loss 0.595958\n",
      "iteration 218 / 300: loss 0.589291\n",
      "iteration 218 / 300: loss 0.599526\n",
      "iteration 218 / 300: loss 0.604855\n",
      "iteration 218 / 300: loss 0.619414\n",
      "iteration 218 / 300: loss 0.588808\n",
      "iteration 218 / 300: loss 0.593645\n",
      "iteration 218 / 300: loss 0.585595\n",
      "iteration 218 / 300: loss 0.613212\n",
      "iteration 218 / 300: loss 0.587523\n",
      "iteration 218 / 300: loss 0.578328\n",
      "iteration 218 / 300: loss 0.567435\n",
      "iteration 218 / 300: loss 0.562235\n",
      "iteration 218 / 300: loss 0.594183\n",
      "iteration 218 / 300: loss 0.578821\n",
      "iteration 218 / 300: loss 0.586360\n",
      "iteration 218 / 300: loss 0.572890\n",
      "iteration 218 / 300: loss 0.596151\n",
      "iteration 218 / 300: loss 0.607951\n",
      "iteration 218 / 300: loss 0.610839\n",
      "iteration 218 / 300: loss 0.606265\n",
      "iteration 218 / 300: loss 0.583790\n",
      "iteration 218 / 300: loss 0.589627\n",
      "iteration 218 / 300: loss 0.595184\n",
      "iteration 218 / 300: loss 0.598955\n",
      "iteration 218 / 300: loss 0.596133\n",
      "iteration 218 / 300: loss 0.589769\n",
      "iteration 218 / 300: loss 0.591136\n",
      "iteration 218 / 300: loss 0.584854\n",
      "iteration 218 / 300: loss 0.599646\n",
      "iteration 218 / 300: loss 0.598902\n",
      "iteration 218 / 300: loss 0.614282\n",
      "iteration 218 / 300: loss 0.597796\n",
      "iteration 218 / 300: loss 0.599298\n",
      "iteration 218 / 300: loss 0.603317\n",
      "iteration 218 / 300: loss 0.592865\n",
      "iteration 218 / 300: loss 0.592391\n",
      "iteration 218 / 300: loss 0.589041\n",
      "iteration 218 / 300: loss 0.596446\n",
      "iteration 218 / 300: loss 0.605709\n",
      "iteration 218 / 300: loss 0.610562\n",
      "iteration 218 / 300: loss 0.587782\n",
      "iteration 218 / 300: loss 0.599351\n",
      "iteration 218 / 300: loss 0.602792\n",
      "iteration 218 / 300: loss 0.605028\n",
      "iteration 218 / 300: loss 0.603848\n",
      "iteration 218 / 300: loss 0.624144\n",
      "iteration 218 / 300: loss 0.587219\n",
      "iteration 218 / 300: loss 0.580754\n",
      "iteration 218 / 300: loss 0.625045\n",
      "iteration 218 / 300: loss 0.603310\n",
      "iteration 218 / 300: loss 0.604321\n",
      "iteration 218 / 300: loss 0.595476\n",
      "iteration 218 / 300: loss 0.597543\n",
      "iteration 218 / 300: loss 0.592740\n",
      "iteration 218 / 300: loss 0.589494\n",
      "iteration 218 / 300: loss 0.599264\n",
      "iteration 218 / 300: loss 0.611379\n",
      "iteration 218 / 300: loss 0.592463\n",
      "iteration 218 / 300: loss 0.599424\n",
      "iteration 218 / 300: loss 0.603100\n",
      "iteration 218 / 300: loss 0.602410\n",
      "iteration 218 / 300: loss 0.579811\n",
      "iteration 218 / 300: loss 0.601592\n",
      "iteration 219 / 300: loss 0.585528\n",
      "iteration 219 / 300: loss 0.588428\n",
      "iteration 219 / 300: loss 0.567516\n",
      "iteration 219 / 300: loss 0.592380\n",
      "iteration 219 / 300: loss 0.593618\n",
      "iteration 219 / 300: loss 0.595295\n",
      "iteration 219 / 300: loss 0.608784\n",
      "iteration 219 / 300: loss 0.592732\n",
      "iteration 219 / 300: loss 0.628060\n",
      "iteration 219 / 300: loss 0.580152\n",
      "iteration 219 / 300: loss 0.607923\n",
      "iteration 219 / 300: loss 0.587394\n",
      "iteration 219 / 300: loss 0.591686\n",
      "iteration 219 / 300: loss 0.571370\n",
      "iteration 219 / 300: loss 0.583025\n",
      "iteration 219 / 300: loss 0.608441\n",
      "iteration 219 / 300: loss 0.598359\n",
      "iteration 219 / 300: loss 0.583858\n",
      "iteration 219 / 300: loss 0.615253\n",
      "iteration 219 / 300: loss 0.591649\n",
      "iteration 219 / 300: loss 0.585499\n",
      "iteration 219 / 300: loss 0.591325\n",
      "iteration 219 / 300: loss 0.604341\n",
      "iteration 219 / 300: loss 0.595786\n",
      "iteration 219 / 300: loss 0.614949\n",
      "iteration 219 / 300: loss 0.608389\n",
      "iteration 219 / 300: loss 0.598222\n",
      "iteration 219 / 300: loss 0.588936\n",
      "iteration 219 / 300: loss 0.617757\n",
      "iteration 219 / 300: loss 0.594770\n",
      "iteration 219 / 300: loss 0.601684\n",
      "iteration 219 / 300: loss 0.631031\n",
      "iteration 219 / 300: loss 0.587513\n",
      "iteration 219 / 300: loss 0.606561\n",
      "iteration 219 / 300: loss 0.588034\n",
      "iteration 219 / 300: loss 0.600890\n",
      "iteration 219 / 300: loss 0.595958\n",
      "iteration 219 / 300: loss 0.589291\n",
      "iteration 219 / 300: loss 0.599526\n",
      "iteration 219 / 300: loss 0.604855\n",
      "iteration 219 / 300: loss 0.619414\n",
      "iteration 219 / 300: loss 0.588808\n",
      "iteration 219 / 300: loss 0.593645\n",
      "iteration 219 / 300: loss 0.585595\n",
      "iteration 219 / 300: loss 0.613212\n",
      "iteration 219 / 300: loss 0.587523\n",
      "iteration 219 / 300: loss 0.578328\n",
      "iteration 219 / 300: loss 0.567435\n",
      "iteration 219 / 300: loss 0.562235\n",
      "iteration 219 / 300: loss 0.594183\n",
      "iteration 219 / 300: loss 0.578821\n",
      "iteration 219 / 300: loss 0.586360\n",
      "iteration 219 / 300: loss 0.572890\n",
      "iteration 219 / 300: loss 0.596151\n",
      "iteration 219 / 300: loss 0.607951\n",
      "iteration 219 / 300: loss 0.610839\n",
      "iteration 219 / 300: loss 0.606265\n",
      "iteration 219 / 300: loss 0.583790\n",
      "iteration 219 / 300: loss 0.589627\n",
      "iteration 219 / 300: loss 0.595184\n",
      "iteration 219 / 300: loss 0.598955\n",
      "iteration 219 / 300: loss 0.596133\n",
      "iteration 219 / 300: loss 0.589769\n",
      "iteration 219 / 300: loss 0.591136\n",
      "iteration 219 / 300: loss 0.584854\n",
      "iteration 219 / 300: loss 0.599646\n",
      "iteration 219 / 300: loss 0.598902\n",
      "iteration 219 / 300: loss 0.614282\n",
      "iteration 219 / 300: loss 0.597796\n",
      "iteration 219 / 300: loss 0.599298\n",
      "iteration 219 / 300: loss 0.603317\n",
      "iteration 219 / 300: loss 0.592865\n",
      "iteration 219 / 300: loss 0.592391\n",
      "iteration 219 / 300: loss 0.589041\n",
      "iteration 219 / 300: loss 0.596446\n",
      "iteration 219 / 300: loss 0.605709\n",
      "iteration 219 / 300: loss 0.610562\n",
      "iteration 219 / 300: loss 0.587782\n",
      "iteration 219 / 300: loss 0.599351\n",
      "iteration 219 / 300: loss 0.602792\n",
      "iteration 219 / 300: loss 0.605028\n",
      "iteration 219 / 300: loss 0.603848\n",
      "iteration 219 / 300: loss 0.624144\n",
      "iteration 219 / 300: loss 0.587219\n",
      "iteration 219 / 300: loss 0.580754\n",
      "iteration 219 / 300: loss 0.625045\n",
      "iteration 219 / 300: loss 0.603310\n",
      "iteration 219 / 300: loss 0.604321\n",
      "iteration 219 / 300: loss 0.595476\n",
      "iteration 219 / 300: loss 0.597543\n",
      "iteration 219 / 300: loss 0.592740\n",
      "iteration 219 / 300: loss 0.589494\n",
      "iteration 219 / 300: loss 0.599264\n",
      "iteration 219 / 300: loss 0.611379\n",
      "iteration 219 / 300: loss 0.592463\n",
      "iteration 219 / 300: loss 0.599424\n",
      "iteration 219 / 300: loss 0.603100\n",
      "iteration 219 / 300: loss 0.602410\n",
      "iteration 219 / 300: loss 0.579811\n",
      "iteration 219 / 300: loss 0.601592\n",
      "iteration 220 / 300: loss 0.585528\n",
      "iteration 220 / 300: loss 0.588428\n",
      "iteration 220 / 300: loss 0.567516\n",
      "iteration 220 / 300: loss 0.592380\n",
      "iteration 220 / 300: loss 0.593618\n",
      "iteration 220 / 300: loss 0.595295\n",
      "iteration 220 / 300: loss 0.608784\n",
      "iteration 220 / 300: loss 0.592732\n",
      "iteration 220 / 300: loss 0.628060\n",
      "iteration 220 / 300: loss 0.580152\n",
      "iteration 220 / 300: loss 0.607923\n",
      "iteration 220 / 300: loss 0.587394\n",
      "iteration 220 / 300: loss 0.591686\n",
      "iteration 220 / 300: loss 0.571370\n",
      "iteration 220 / 300: loss 0.583025\n",
      "iteration 220 / 300: loss 0.608441\n",
      "iteration 220 / 300: loss 0.598359\n",
      "iteration 220 / 300: loss 0.583858\n",
      "iteration 220 / 300: loss 0.615253\n",
      "iteration 220 / 300: loss 0.591649\n",
      "iteration 220 / 300: loss 0.585499\n",
      "iteration 220 / 300: loss 0.591325\n",
      "iteration 220 / 300: loss 0.604341\n",
      "iteration 220 / 300: loss 0.595786\n",
      "iteration 220 / 300: loss 0.614949\n",
      "iteration 220 / 300: loss 0.608389\n",
      "iteration 220 / 300: loss 0.598222\n",
      "iteration 220 / 300: loss 0.588936\n",
      "iteration 220 / 300: loss 0.617757\n",
      "iteration 220 / 300: loss 0.594770\n",
      "iteration 220 / 300: loss 0.601684\n",
      "iteration 220 / 300: loss 0.631031\n",
      "iteration 220 / 300: loss 0.587513\n",
      "iteration 220 / 300: loss 0.606561\n",
      "iteration 220 / 300: loss 0.588034\n",
      "iteration 220 / 300: loss 0.600890\n",
      "iteration 220 / 300: loss 0.595958\n",
      "iteration 220 / 300: loss 0.589291\n",
      "iteration 220 / 300: loss 0.599526\n",
      "iteration 220 / 300: loss 0.604855\n",
      "iteration 220 / 300: loss 0.619414\n",
      "iteration 220 / 300: loss 0.588808\n",
      "iteration 220 / 300: loss 0.593645\n",
      "iteration 220 / 300: loss 0.585595\n",
      "iteration 220 / 300: loss 0.613212\n",
      "iteration 220 / 300: loss 0.587523\n",
      "iteration 220 / 300: loss 0.578328\n",
      "iteration 220 / 300: loss 0.567435\n",
      "iteration 220 / 300: loss 0.562235\n",
      "iteration 220 / 300: loss 0.594183\n",
      "iteration 220 / 300: loss 0.578821\n",
      "iteration 220 / 300: loss 0.586360\n",
      "iteration 220 / 300: loss 0.572890\n",
      "iteration 220 / 300: loss 0.596151\n",
      "iteration 220 / 300: loss 0.607951\n",
      "iteration 220 / 300: loss 0.610839\n",
      "iteration 220 / 300: loss 0.606265\n",
      "iteration 220 / 300: loss 0.583790\n",
      "iteration 220 / 300: loss 0.589627\n",
      "iteration 220 / 300: loss 0.595184\n",
      "iteration 220 / 300: loss 0.598955\n",
      "iteration 220 / 300: loss 0.596133\n",
      "iteration 220 / 300: loss 0.589769\n",
      "iteration 220 / 300: loss 0.591136\n",
      "iteration 220 / 300: loss 0.584854\n",
      "iteration 220 / 300: loss 0.599646\n",
      "iteration 220 / 300: loss 0.598902\n",
      "iteration 220 / 300: loss 0.614282\n",
      "iteration 220 / 300: loss 0.597796\n",
      "iteration 220 / 300: loss 0.599298\n",
      "iteration 220 / 300: loss 0.603317\n",
      "iteration 220 / 300: loss 0.592865\n",
      "iteration 220 / 300: loss 0.592391\n",
      "iteration 220 / 300: loss 0.589041\n",
      "iteration 220 / 300: loss 0.596446\n",
      "iteration 220 / 300: loss 0.605709\n",
      "iteration 220 / 300: loss 0.610562\n",
      "iteration 220 / 300: loss 0.587782\n",
      "iteration 220 / 300: loss 0.599351\n",
      "iteration 220 / 300: loss 0.602792\n",
      "iteration 220 / 300: loss 0.605028\n",
      "iteration 220 / 300: loss 0.603848\n",
      "iteration 220 / 300: loss 0.624144\n",
      "iteration 220 / 300: loss 0.587219\n",
      "iteration 220 / 300: loss 0.580754\n",
      "iteration 220 / 300: loss 0.625045\n",
      "iteration 220 / 300: loss 0.603310\n",
      "iteration 220 / 300: loss 0.604321\n",
      "iteration 220 / 300: loss 0.595476\n",
      "iteration 220 / 300: loss 0.597543\n",
      "iteration 220 / 300: loss 0.592740\n",
      "iteration 220 / 300: loss 0.589494\n",
      "iteration 220 / 300: loss 0.599264\n",
      "iteration 220 / 300: loss 0.611379\n",
      "iteration 220 / 300: loss 0.592463\n",
      "iteration 220 / 300: loss 0.599424\n",
      "iteration 220 / 300: loss 0.603100\n",
      "iteration 220 / 300: loss 0.602410\n",
      "iteration 220 / 300: loss 0.579811\n",
      "iteration 220 / 300: loss 0.601592\n",
      "iteration 221 / 300: loss 0.585528\n",
      "iteration 221 / 300: loss 0.588428\n",
      "iteration 221 / 300: loss 0.567516\n",
      "iteration 221 / 300: loss 0.592380\n",
      "iteration 221 / 300: loss 0.593618\n",
      "iteration 221 / 300: loss 0.595295\n",
      "iteration 221 / 300: loss 0.608784\n",
      "iteration 221 / 300: loss 0.592732\n",
      "iteration 221 / 300: loss 0.628060\n",
      "iteration 221 / 300: loss 0.580152\n",
      "iteration 221 / 300: loss 0.607923\n",
      "iteration 221 / 300: loss 0.587394\n",
      "iteration 221 / 300: loss 0.591686\n",
      "iteration 221 / 300: loss 0.571370\n",
      "iteration 221 / 300: loss 0.583025\n",
      "iteration 221 / 300: loss 0.608441\n",
      "iteration 221 / 300: loss 0.598359\n",
      "iteration 221 / 300: loss 0.583858\n",
      "iteration 221 / 300: loss 0.615253\n",
      "iteration 221 / 300: loss 0.591649\n",
      "iteration 221 / 300: loss 0.585499\n",
      "iteration 221 / 300: loss 0.591325\n",
      "iteration 221 / 300: loss 0.604341\n",
      "iteration 221 / 300: loss 0.595786\n",
      "iteration 221 / 300: loss 0.614949\n",
      "iteration 221 / 300: loss 0.608389\n",
      "iteration 221 / 300: loss 0.598222\n",
      "iteration 221 / 300: loss 0.588936\n",
      "iteration 221 / 300: loss 0.617757\n",
      "iteration 221 / 300: loss 0.594770\n",
      "iteration 221 / 300: loss 0.601684\n",
      "iteration 221 / 300: loss 0.631031\n",
      "iteration 221 / 300: loss 0.587513\n",
      "iteration 221 / 300: loss 0.606561\n",
      "iteration 221 / 300: loss 0.588034\n",
      "iteration 221 / 300: loss 0.600890\n",
      "iteration 221 / 300: loss 0.595958\n",
      "iteration 221 / 300: loss 0.589291\n",
      "iteration 221 / 300: loss 0.599526\n",
      "iteration 221 / 300: loss 0.604855\n",
      "iteration 221 / 300: loss 0.619414\n",
      "iteration 221 / 300: loss 0.588808\n",
      "iteration 221 / 300: loss 0.593645\n",
      "iteration 221 / 300: loss 0.585595\n",
      "iteration 221 / 300: loss 0.613212\n",
      "iteration 221 / 300: loss 0.587523\n",
      "iteration 221 / 300: loss 0.578328\n",
      "iteration 221 / 300: loss 0.567435\n",
      "iteration 221 / 300: loss 0.562235\n",
      "iteration 221 / 300: loss 0.594183\n",
      "iteration 221 / 300: loss 0.578821\n",
      "iteration 221 / 300: loss 0.586360\n",
      "iteration 221 / 300: loss 0.572890\n",
      "iteration 221 / 300: loss 0.596151\n",
      "iteration 221 / 300: loss 0.607951\n",
      "iteration 221 / 300: loss 0.610839\n",
      "iteration 221 / 300: loss 0.606265\n",
      "iteration 221 / 300: loss 0.583790\n",
      "iteration 221 / 300: loss 0.589627\n",
      "iteration 221 / 300: loss 0.595184\n",
      "iteration 221 / 300: loss 0.598955\n",
      "iteration 221 / 300: loss 0.596133\n",
      "iteration 221 / 300: loss 0.589769\n",
      "iteration 221 / 300: loss 0.591136\n",
      "iteration 221 / 300: loss 0.584854\n",
      "iteration 221 / 300: loss 0.599646\n",
      "iteration 221 / 300: loss 0.598902\n",
      "iteration 221 / 300: loss 0.614282\n",
      "iteration 221 / 300: loss 0.597796\n",
      "iteration 221 / 300: loss 0.599298\n",
      "iteration 221 / 300: loss 0.603317\n",
      "iteration 221 / 300: loss 0.592865\n",
      "iteration 221 / 300: loss 0.592391\n",
      "iteration 221 / 300: loss 0.589041\n",
      "iteration 221 / 300: loss 0.596446\n",
      "iteration 221 / 300: loss 0.605709\n",
      "iteration 221 / 300: loss 0.610562\n",
      "iteration 221 / 300: loss 0.587782\n",
      "iteration 221 / 300: loss 0.599351\n",
      "iteration 221 / 300: loss 0.602792\n",
      "iteration 221 / 300: loss 0.605028\n",
      "iteration 221 / 300: loss 0.603848\n",
      "iteration 221 / 300: loss 0.624144\n",
      "iteration 221 / 300: loss 0.587219\n",
      "iteration 221 / 300: loss 0.580754\n",
      "iteration 221 / 300: loss 0.625045\n",
      "iteration 221 / 300: loss 0.603310\n",
      "iteration 221 / 300: loss 0.604321\n",
      "iteration 221 / 300: loss 0.595476\n",
      "iteration 221 / 300: loss 0.597543\n",
      "iteration 221 / 300: loss 0.592740\n",
      "iteration 221 / 300: loss 0.589494\n",
      "iteration 221 / 300: loss 0.599264\n",
      "iteration 221 / 300: loss 0.611379\n",
      "iteration 221 / 300: loss 0.592463\n",
      "iteration 221 / 300: loss 0.599424\n",
      "iteration 221 / 300: loss 0.603100\n",
      "iteration 221 / 300: loss 0.602410\n",
      "iteration 221 / 300: loss 0.579811\n",
      "iteration 221 / 300: loss 0.601592\n",
      "iteration 222 / 300: loss 0.585528\n",
      "iteration 222 / 300: loss 0.588428\n",
      "iteration 222 / 300: loss 0.567516\n",
      "iteration 222 / 300: loss 0.592380\n",
      "iteration 222 / 300: loss 0.593618\n",
      "iteration 222 / 300: loss 0.595295\n",
      "iteration 222 / 300: loss 0.608784\n",
      "iteration 222 / 300: loss 0.592732\n",
      "iteration 222 / 300: loss 0.628060\n",
      "iteration 222 / 300: loss 0.580152\n",
      "iteration 222 / 300: loss 0.607923\n",
      "iteration 222 / 300: loss 0.587394\n",
      "iteration 222 / 300: loss 0.591686\n",
      "iteration 222 / 300: loss 0.571370\n",
      "iteration 222 / 300: loss 0.583025\n",
      "iteration 222 / 300: loss 0.608441\n",
      "iteration 222 / 300: loss 0.598359\n",
      "iteration 222 / 300: loss 0.583858\n",
      "iteration 222 / 300: loss 0.615253\n",
      "iteration 222 / 300: loss 0.591649\n",
      "iteration 222 / 300: loss 0.585499\n",
      "iteration 222 / 300: loss 0.591325\n",
      "iteration 222 / 300: loss 0.604341\n",
      "iteration 222 / 300: loss 0.595786\n",
      "iteration 222 / 300: loss 0.614949\n",
      "iteration 222 / 300: loss 0.608389\n",
      "iteration 222 / 300: loss 0.598222\n",
      "iteration 222 / 300: loss 0.588936\n",
      "iteration 222 / 300: loss 0.617757\n",
      "iteration 222 / 300: loss 0.594770\n",
      "iteration 222 / 300: loss 0.601684\n",
      "iteration 222 / 300: loss 0.631031\n",
      "iteration 222 / 300: loss 0.587513\n",
      "iteration 222 / 300: loss 0.606561\n",
      "iteration 222 / 300: loss 0.588034\n",
      "iteration 222 / 300: loss 0.600890\n",
      "iteration 222 / 300: loss 0.595958\n",
      "iteration 222 / 300: loss 0.589291\n",
      "iteration 222 / 300: loss 0.599526\n",
      "iteration 222 / 300: loss 0.604855\n",
      "iteration 222 / 300: loss 0.619414\n",
      "iteration 222 / 300: loss 0.588808\n",
      "iteration 222 / 300: loss 0.593645\n",
      "iteration 222 / 300: loss 0.585595\n",
      "iteration 222 / 300: loss 0.613212\n",
      "iteration 222 / 300: loss 0.587523\n",
      "iteration 222 / 300: loss 0.578328\n",
      "iteration 222 / 300: loss 0.567435\n",
      "iteration 222 / 300: loss 0.562235\n",
      "iteration 222 / 300: loss 0.594183\n",
      "iteration 222 / 300: loss 0.578821\n",
      "iteration 222 / 300: loss 0.586360\n",
      "iteration 222 / 300: loss 0.572890\n",
      "iteration 222 / 300: loss 0.596151\n",
      "iteration 222 / 300: loss 0.607951\n",
      "iteration 222 / 300: loss 0.610839\n",
      "iteration 222 / 300: loss 0.606265\n",
      "iteration 222 / 300: loss 0.583790\n",
      "iteration 222 / 300: loss 0.589627\n",
      "iteration 222 / 300: loss 0.595184\n",
      "iteration 222 / 300: loss 0.598955\n",
      "iteration 222 / 300: loss 0.596133\n",
      "iteration 222 / 300: loss 0.589769\n",
      "iteration 222 / 300: loss 0.591136\n",
      "iteration 222 / 300: loss 0.584854\n",
      "iteration 222 / 300: loss 0.599646\n",
      "iteration 222 / 300: loss 0.598902\n",
      "iteration 222 / 300: loss 0.614282\n",
      "iteration 222 / 300: loss 0.597796\n",
      "iteration 222 / 300: loss 0.599298\n",
      "iteration 222 / 300: loss 0.603317\n",
      "iteration 222 / 300: loss 0.592865\n",
      "iteration 222 / 300: loss 0.592391\n",
      "iteration 222 / 300: loss 0.589041\n",
      "iteration 222 / 300: loss 0.596446\n",
      "iteration 222 / 300: loss 0.605709\n",
      "iteration 222 / 300: loss 0.610562\n",
      "iteration 222 / 300: loss 0.587782\n",
      "iteration 222 / 300: loss 0.599351\n",
      "iteration 222 / 300: loss 0.602792\n",
      "iteration 222 / 300: loss 0.605028\n",
      "iteration 222 / 300: loss 0.603848\n",
      "iteration 222 / 300: loss 0.624144\n",
      "iteration 222 / 300: loss 0.587219\n",
      "iteration 222 / 300: loss 0.580754\n",
      "iteration 222 / 300: loss 0.625045\n",
      "iteration 222 / 300: loss 0.603310\n",
      "iteration 222 / 300: loss 0.604321\n",
      "iteration 222 / 300: loss 0.595476\n",
      "iteration 222 / 300: loss 0.597543\n",
      "iteration 222 / 300: loss 0.592740\n",
      "iteration 222 / 300: loss 0.589494\n",
      "iteration 222 / 300: loss 0.599264\n",
      "iteration 222 / 300: loss 0.611379\n",
      "iteration 222 / 300: loss 0.592463\n",
      "iteration 222 / 300: loss 0.599424\n",
      "iteration 222 / 300: loss 0.603100\n",
      "iteration 222 / 300: loss 0.602410\n",
      "iteration 222 / 300: loss 0.579811\n",
      "iteration 222 / 300: loss 0.601592\n",
      "iteration 223 / 300: loss 0.585528\n",
      "iteration 223 / 300: loss 0.588428\n",
      "iteration 223 / 300: loss 0.567516\n",
      "iteration 223 / 300: loss 0.592380\n",
      "iteration 223 / 300: loss 0.593618\n",
      "iteration 223 / 300: loss 0.595295\n",
      "iteration 223 / 300: loss 0.608784\n",
      "iteration 223 / 300: loss 0.592732\n",
      "iteration 223 / 300: loss 0.628060\n",
      "iteration 223 / 300: loss 0.580152\n",
      "iteration 223 / 300: loss 0.607923\n",
      "iteration 223 / 300: loss 0.587394\n",
      "iteration 223 / 300: loss 0.591686\n",
      "iteration 223 / 300: loss 0.571370\n",
      "iteration 223 / 300: loss 0.583025\n",
      "iteration 223 / 300: loss 0.608441\n",
      "iteration 223 / 300: loss 0.598359\n",
      "iteration 223 / 300: loss 0.583858\n",
      "iteration 223 / 300: loss 0.615253\n",
      "iteration 223 / 300: loss 0.591649\n",
      "iteration 223 / 300: loss 0.585499\n",
      "iteration 223 / 300: loss 0.591325\n",
      "iteration 223 / 300: loss 0.604341\n",
      "iteration 223 / 300: loss 0.595786\n",
      "iteration 223 / 300: loss 0.614949\n",
      "iteration 223 / 300: loss 0.608389\n",
      "iteration 223 / 300: loss 0.598222\n",
      "iteration 223 / 300: loss 0.588936\n",
      "iteration 223 / 300: loss 0.617757\n",
      "iteration 223 / 300: loss 0.594770\n",
      "iteration 223 / 300: loss 0.601684\n",
      "iteration 223 / 300: loss 0.631031\n",
      "iteration 223 / 300: loss 0.587513\n",
      "iteration 223 / 300: loss 0.606561\n",
      "iteration 223 / 300: loss 0.588034\n",
      "iteration 223 / 300: loss 0.600890\n",
      "iteration 223 / 300: loss 0.595958\n",
      "iteration 223 / 300: loss 0.589291\n",
      "iteration 223 / 300: loss 0.599526\n",
      "iteration 223 / 300: loss 0.604855\n",
      "iteration 223 / 300: loss 0.619414\n",
      "iteration 223 / 300: loss 0.588808\n",
      "iteration 223 / 300: loss 0.593645\n",
      "iteration 223 / 300: loss 0.585595\n",
      "iteration 223 / 300: loss 0.613212\n",
      "iteration 223 / 300: loss 0.587523\n",
      "iteration 223 / 300: loss 0.578328\n",
      "iteration 223 / 300: loss 0.567435\n",
      "iteration 223 / 300: loss 0.562235\n",
      "iteration 223 / 300: loss 0.594183\n",
      "iteration 223 / 300: loss 0.578821\n",
      "iteration 223 / 300: loss 0.586360\n",
      "iteration 223 / 300: loss 0.572890\n",
      "iteration 223 / 300: loss 0.596151\n",
      "iteration 223 / 300: loss 0.607951\n",
      "iteration 223 / 300: loss 0.610839\n",
      "iteration 223 / 300: loss 0.606265\n",
      "iteration 223 / 300: loss 0.583790\n",
      "iteration 223 / 300: loss 0.589627\n",
      "iteration 223 / 300: loss 0.595184\n",
      "iteration 223 / 300: loss 0.598955\n",
      "iteration 223 / 300: loss 0.596133\n",
      "iteration 223 / 300: loss 0.589769\n",
      "iteration 223 / 300: loss 0.591136\n",
      "iteration 223 / 300: loss 0.584854\n",
      "iteration 223 / 300: loss 0.599646\n",
      "iteration 223 / 300: loss 0.598902\n",
      "iteration 223 / 300: loss 0.614282\n",
      "iteration 223 / 300: loss 0.597796\n",
      "iteration 223 / 300: loss 0.599298\n",
      "iteration 223 / 300: loss 0.603317\n",
      "iteration 223 / 300: loss 0.592865\n",
      "iteration 223 / 300: loss 0.592391\n",
      "iteration 223 / 300: loss 0.589041\n",
      "iteration 223 / 300: loss 0.596446\n",
      "iteration 223 / 300: loss 0.605709\n",
      "iteration 223 / 300: loss 0.610562\n",
      "iteration 223 / 300: loss 0.587782\n",
      "iteration 223 / 300: loss 0.599351\n",
      "iteration 223 / 300: loss 0.602792\n",
      "iteration 223 / 300: loss 0.605028\n",
      "iteration 223 / 300: loss 0.603848\n",
      "iteration 223 / 300: loss 0.624144\n",
      "iteration 223 / 300: loss 0.587219\n",
      "iteration 223 / 300: loss 0.580754\n",
      "iteration 223 / 300: loss 0.625045\n",
      "iteration 223 / 300: loss 0.603310\n",
      "iteration 223 / 300: loss 0.604321\n",
      "iteration 223 / 300: loss 0.595476\n",
      "iteration 223 / 300: loss 0.597543\n",
      "iteration 223 / 300: loss 0.592740\n",
      "iteration 223 / 300: loss 0.589494\n",
      "iteration 223 / 300: loss 0.599264\n",
      "iteration 223 / 300: loss 0.611379\n",
      "iteration 223 / 300: loss 0.592463\n",
      "iteration 223 / 300: loss 0.599424\n",
      "iteration 223 / 300: loss 0.603100\n",
      "iteration 223 / 300: loss 0.602410\n",
      "iteration 223 / 300: loss 0.579811\n",
      "iteration 223 / 300: loss 0.601592\n",
      "iteration 224 / 300: loss 0.585528\n",
      "iteration 224 / 300: loss 0.588428\n",
      "iteration 224 / 300: loss 0.567516\n",
      "iteration 224 / 300: loss 0.592380\n",
      "iteration 224 / 300: loss 0.593618\n",
      "iteration 224 / 300: loss 0.595295\n",
      "iteration 224 / 300: loss 0.608784\n",
      "iteration 224 / 300: loss 0.592732\n",
      "iteration 224 / 300: loss 0.628060\n",
      "iteration 224 / 300: loss 0.580152\n",
      "iteration 224 / 300: loss 0.607923\n",
      "iteration 224 / 300: loss 0.587394\n",
      "iteration 224 / 300: loss 0.591686\n",
      "iteration 224 / 300: loss 0.571370\n",
      "iteration 224 / 300: loss 0.583025\n",
      "iteration 224 / 300: loss 0.608441\n",
      "iteration 224 / 300: loss 0.598359\n",
      "iteration 224 / 300: loss 0.583858\n",
      "iteration 224 / 300: loss 0.615253\n",
      "iteration 224 / 300: loss 0.591649\n",
      "iteration 224 / 300: loss 0.585499\n",
      "iteration 224 / 300: loss 0.591325\n",
      "iteration 224 / 300: loss 0.604341\n",
      "iteration 224 / 300: loss 0.595786\n",
      "iteration 224 / 300: loss 0.614949\n",
      "iteration 224 / 300: loss 0.608389\n",
      "iteration 224 / 300: loss 0.598222\n",
      "iteration 224 / 300: loss 0.588936\n",
      "iteration 224 / 300: loss 0.617757\n",
      "iteration 224 / 300: loss 0.594770\n",
      "iteration 224 / 300: loss 0.601684\n",
      "iteration 224 / 300: loss 0.631031\n",
      "iteration 224 / 300: loss 0.587513\n",
      "iteration 224 / 300: loss 0.606561\n",
      "iteration 224 / 300: loss 0.588034\n",
      "iteration 224 / 300: loss 0.600890\n",
      "iteration 224 / 300: loss 0.595958\n",
      "iteration 224 / 300: loss 0.589291\n",
      "iteration 224 / 300: loss 0.599526\n",
      "iteration 224 / 300: loss 0.604855\n",
      "iteration 224 / 300: loss 0.619414\n",
      "iteration 224 / 300: loss 0.588808\n",
      "iteration 224 / 300: loss 0.593645\n",
      "iteration 224 / 300: loss 0.585595\n",
      "iteration 224 / 300: loss 0.613212\n",
      "iteration 224 / 300: loss 0.587523\n",
      "iteration 224 / 300: loss 0.578328\n",
      "iteration 224 / 300: loss 0.567435\n",
      "iteration 224 / 300: loss 0.562235\n",
      "iteration 224 / 300: loss 0.594183\n",
      "iteration 224 / 300: loss 0.578821\n",
      "iteration 224 / 300: loss 0.586360\n",
      "iteration 224 / 300: loss 0.572890\n",
      "iteration 224 / 300: loss 0.596151\n",
      "iteration 224 / 300: loss 0.607951\n",
      "iteration 224 / 300: loss 0.610839\n",
      "iteration 224 / 300: loss 0.606265\n",
      "iteration 224 / 300: loss 0.583790\n",
      "iteration 224 / 300: loss 0.589627\n",
      "iteration 224 / 300: loss 0.595184\n",
      "iteration 224 / 300: loss 0.598955\n",
      "iteration 224 / 300: loss 0.596133\n",
      "iteration 224 / 300: loss 0.589769\n",
      "iteration 224 / 300: loss 0.591136\n",
      "iteration 224 / 300: loss 0.584854\n",
      "iteration 224 / 300: loss 0.599646\n",
      "iteration 224 / 300: loss 0.598902\n",
      "iteration 224 / 300: loss 0.614282\n",
      "iteration 224 / 300: loss 0.597796\n",
      "iteration 224 / 300: loss 0.599298\n",
      "iteration 224 / 300: loss 0.603317\n",
      "iteration 224 / 300: loss 0.592865\n",
      "iteration 224 / 300: loss 0.592391\n",
      "iteration 224 / 300: loss 0.589041\n",
      "iteration 224 / 300: loss 0.596446\n",
      "iteration 224 / 300: loss 0.605709\n",
      "iteration 224 / 300: loss 0.610562\n",
      "iteration 224 / 300: loss 0.587782\n",
      "iteration 224 / 300: loss 0.599351\n",
      "iteration 224 / 300: loss 0.602792\n",
      "iteration 224 / 300: loss 0.605028\n",
      "iteration 224 / 300: loss 0.603848\n",
      "iteration 224 / 300: loss 0.624144\n",
      "iteration 224 / 300: loss 0.587219\n",
      "iteration 224 / 300: loss 0.580754\n",
      "iteration 224 / 300: loss 0.625045\n",
      "iteration 224 / 300: loss 0.603310\n",
      "iteration 224 / 300: loss 0.604321\n",
      "iteration 224 / 300: loss 0.595476\n",
      "iteration 224 / 300: loss 0.597543\n",
      "iteration 224 / 300: loss 0.592740\n",
      "iteration 224 / 300: loss 0.589494\n",
      "iteration 224 / 300: loss 0.599264\n",
      "iteration 224 / 300: loss 0.611379\n",
      "iteration 224 / 300: loss 0.592463\n",
      "iteration 224 / 300: loss 0.599424\n",
      "iteration 224 / 300: loss 0.603100\n",
      "iteration 224 / 300: loss 0.602410\n",
      "iteration 224 / 300: loss 0.579811\n",
      "iteration 224 / 300: loss 0.601592\n",
      "iteration 225 / 300: loss 0.585528\n",
      "iteration 225 / 300: loss 0.588428\n",
      "iteration 225 / 300: loss 0.567516\n",
      "iteration 225 / 300: loss 0.592380\n",
      "iteration 225 / 300: loss 0.593618\n",
      "iteration 225 / 300: loss 0.595295\n",
      "iteration 225 / 300: loss 0.608784\n",
      "iteration 225 / 300: loss 0.592732\n",
      "iteration 225 / 300: loss 0.628060\n",
      "iteration 225 / 300: loss 0.580152\n",
      "iteration 225 / 300: loss 0.607923\n",
      "iteration 225 / 300: loss 0.587394\n",
      "iteration 225 / 300: loss 0.591686\n",
      "iteration 225 / 300: loss 0.571370\n",
      "iteration 225 / 300: loss 0.583025\n",
      "iteration 225 / 300: loss 0.608441\n",
      "iteration 225 / 300: loss 0.598359\n",
      "iteration 225 / 300: loss 0.583858\n",
      "iteration 225 / 300: loss 0.615253\n",
      "iteration 225 / 300: loss 0.591649\n",
      "iteration 225 / 300: loss 0.585499\n",
      "iteration 225 / 300: loss 0.591325\n",
      "iteration 225 / 300: loss 0.604341\n",
      "iteration 225 / 300: loss 0.595786\n",
      "iteration 225 / 300: loss 0.614949\n",
      "iteration 225 / 300: loss 0.608389\n",
      "iteration 225 / 300: loss 0.598222\n",
      "iteration 225 / 300: loss 0.588936\n",
      "iteration 225 / 300: loss 0.617757\n",
      "iteration 225 / 300: loss 0.594770\n",
      "iteration 225 / 300: loss 0.601684\n",
      "iteration 225 / 300: loss 0.631031\n",
      "iteration 225 / 300: loss 0.587513\n",
      "iteration 225 / 300: loss 0.606561\n",
      "iteration 225 / 300: loss 0.588034\n",
      "iteration 225 / 300: loss 0.600890\n",
      "iteration 225 / 300: loss 0.595958\n",
      "iteration 225 / 300: loss 0.589291\n",
      "iteration 225 / 300: loss 0.599526\n",
      "iteration 225 / 300: loss 0.604855\n",
      "iteration 225 / 300: loss 0.619414\n",
      "iteration 225 / 300: loss 0.588808\n",
      "iteration 225 / 300: loss 0.593645\n",
      "iteration 225 / 300: loss 0.585595\n",
      "iteration 225 / 300: loss 0.613212\n",
      "iteration 225 / 300: loss 0.587523\n",
      "iteration 225 / 300: loss 0.578328\n",
      "iteration 225 / 300: loss 0.567435\n",
      "iteration 225 / 300: loss 0.562235\n",
      "iteration 225 / 300: loss 0.594183\n",
      "iteration 225 / 300: loss 0.578821\n",
      "iteration 225 / 300: loss 0.586360\n",
      "iteration 225 / 300: loss 0.572890\n",
      "iteration 225 / 300: loss 0.596151\n",
      "iteration 225 / 300: loss 0.607951\n",
      "iteration 225 / 300: loss 0.610839\n",
      "iteration 225 / 300: loss 0.606265\n",
      "iteration 225 / 300: loss 0.583790\n",
      "iteration 225 / 300: loss 0.589627\n",
      "iteration 225 / 300: loss 0.595184\n",
      "iteration 225 / 300: loss 0.598955\n",
      "iteration 225 / 300: loss 0.596133\n",
      "iteration 225 / 300: loss 0.589769\n",
      "iteration 225 / 300: loss 0.591136\n",
      "iteration 225 / 300: loss 0.584854\n",
      "iteration 225 / 300: loss 0.599646\n",
      "iteration 225 / 300: loss 0.598902\n",
      "iteration 225 / 300: loss 0.614282\n",
      "iteration 225 / 300: loss 0.597796\n",
      "iteration 225 / 300: loss 0.599298\n",
      "iteration 225 / 300: loss 0.603317\n",
      "iteration 225 / 300: loss 0.592865\n",
      "iteration 225 / 300: loss 0.592391\n",
      "iteration 225 / 300: loss 0.589041\n",
      "iteration 225 / 300: loss 0.596446\n",
      "iteration 225 / 300: loss 0.605709\n",
      "iteration 225 / 300: loss 0.610562\n",
      "iteration 225 / 300: loss 0.587782\n",
      "iteration 225 / 300: loss 0.599351\n",
      "iteration 225 / 300: loss 0.602792\n",
      "iteration 225 / 300: loss 0.605028\n",
      "iteration 225 / 300: loss 0.603848\n",
      "iteration 225 / 300: loss 0.624144\n",
      "iteration 225 / 300: loss 0.587219\n",
      "iteration 225 / 300: loss 0.580754\n",
      "iteration 225 / 300: loss 0.625045\n",
      "iteration 225 / 300: loss 0.603310\n",
      "iteration 225 / 300: loss 0.604321\n",
      "iteration 225 / 300: loss 0.595476\n",
      "iteration 225 / 300: loss 0.597543\n",
      "iteration 225 / 300: loss 0.592740\n",
      "iteration 225 / 300: loss 0.589494\n",
      "iteration 225 / 300: loss 0.599264\n",
      "iteration 225 / 300: loss 0.611379\n",
      "iteration 225 / 300: loss 0.592463\n",
      "iteration 225 / 300: loss 0.599424\n",
      "iteration 225 / 300: loss 0.603100\n",
      "iteration 225 / 300: loss 0.602410\n",
      "iteration 225 / 300: loss 0.579811\n",
      "iteration 225 / 300: loss 0.601592\n",
      "iteration 226 / 300: loss 0.585528\n",
      "iteration 226 / 300: loss 0.588428\n",
      "iteration 226 / 300: loss 0.567516\n",
      "iteration 226 / 300: loss 0.592380\n",
      "iteration 226 / 300: loss 0.593618\n",
      "iteration 226 / 300: loss 0.595295\n",
      "iteration 226 / 300: loss 0.608784\n",
      "iteration 226 / 300: loss 0.592732\n",
      "iteration 226 / 300: loss 0.628060\n",
      "iteration 226 / 300: loss 0.580152\n",
      "iteration 226 / 300: loss 0.607923\n",
      "iteration 226 / 300: loss 0.587394\n",
      "iteration 226 / 300: loss 0.591686\n",
      "iteration 226 / 300: loss 0.571370\n",
      "iteration 226 / 300: loss 0.583025\n",
      "iteration 226 / 300: loss 0.608441\n",
      "iteration 226 / 300: loss 0.598359\n",
      "iteration 226 / 300: loss 0.583858\n",
      "iteration 226 / 300: loss 0.615253\n",
      "iteration 226 / 300: loss 0.591649\n",
      "iteration 226 / 300: loss 0.585499\n",
      "iteration 226 / 300: loss 0.591325\n",
      "iteration 226 / 300: loss 0.604341\n",
      "iteration 226 / 300: loss 0.595786\n",
      "iteration 226 / 300: loss 0.614949\n",
      "iteration 226 / 300: loss 0.608389\n",
      "iteration 226 / 300: loss 0.598222\n",
      "iteration 226 / 300: loss 0.588936\n",
      "iteration 226 / 300: loss 0.617757\n",
      "iteration 226 / 300: loss 0.594770\n",
      "iteration 226 / 300: loss 0.601684\n",
      "iteration 226 / 300: loss 0.631031\n",
      "iteration 226 / 300: loss 0.587513\n",
      "iteration 226 / 300: loss 0.606561\n",
      "iteration 226 / 300: loss 0.588034\n",
      "iteration 226 / 300: loss 0.600890\n",
      "iteration 226 / 300: loss 0.595958\n",
      "iteration 226 / 300: loss 0.589291\n",
      "iteration 226 / 300: loss 0.599526\n",
      "iteration 226 / 300: loss 0.604855\n",
      "iteration 226 / 300: loss 0.619414\n",
      "iteration 226 / 300: loss 0.588808\n",
      "iteration 226 / 300: loss 0.593645\n",
      "iteration 226 / 300: loss 0.585595\n",
      "iteration 226 / 300: loss 0.613212\n",
      "iteration 226 / 300: loss 0.587523\n",
      "iteration 226 / 300: loss 0.578328\n",
      "iteration 226 / 300: loss 0.567435\n",
      "iteration 226 / 300: loss 0.562235\n",
      "iteration 226 / 300: loss 0.594183\n",
      "iteration 226 / 300: loss 0.578821\n",
      "iteration 226 / 300: loss 0.586360\n",
      "iteration 226 / 300: loss 0.572890\n",
      "iteration 226 / 300: loss 0.596151\n",
      "iteration 226 / 300: loss 0.607951\n",
      "iteration 226 / 300: loss 0.610839\n",
      "iteration 226 / 300: loss 0.606265\n",
      "iteration 226 / 300: loss 0.583790\n",
      "iteration 226 / 300: loss 0.589627\n",
      "iteration 226 / 300: loss 0.595184\n",
      "iteration 226 / 300: loss 0.598955\n",
      "iteration 226 / 300: loss 0.596133\n",
      "iteration 226 / 300: loss 0.589769\n",
      "iteration 226 / 300: loss 0.591136\n",
      "iteration 226 / 300: loss 0.584854\n",
      "iteration 226 / 300: loss 0.599646\n",
      "iteration 226 / 300: loss 0.598902\n",
      "iteration 226 / 300: loss 0.614282\n",
      "iteration 226 / 300: loss 0.597796\n",
      "iteration 226 / 300: loss 0.599298\n",
      "iteration 226 / 300: loss 0.603317\n",
      "iteration 226 / 300: loss 0.592865\n",
      "iteration 226 / 300: loss 0.592391\n",
      "iteration 226 / 300: loss 0.589041\n",
      "iteration 226 / 300: loss 0.596446\n",
      "iteration 226 / 300: loss 0.605709\n",
      "iteration 226 / 300: loss 0.610562\n",
      "iteration 226 / 300: loss 0.587782\n",
      "iteration 226 / 300: loss 0.599351\n",
      "iteration 226 / 300: loss 0.602792\n",
      "iteration 226 / 300: loss 0.605028\n",
      "iteration 226 / 300: loss 0.603848\n",
      "iteration 226 / 300: loss 0.624144\n",
      "iteration 226 / 300: loss 0.587219\n",
      "iteration 226 / 300: loss 0.580754\n",
      "iteration 226 / 300: loss 0.625045\n",
      "iteration 226 / 300: loss 0.603310\n",
      "iteration 226 / 300: loss 0.604321\n",
      "iteration 226 / 300: loss 0.595476\n",
      "iteration 226 / 300: loss 0.597543\n",
      "iteration 226 / 300: loss 0.592740\n",
      "iteration 226 / 300: loss 0.589494\n",
      "iteration 226 / 300: loss 0.599264\n",
      "iteration 226 / 300: loss 0.611379\n",
      "iteration 226 / 300: loss 0.592463\n",
      "iteration 226 / 300: loss 0.599424\n",
      "iteration 226 / 300: loss 0.603100\n",
      "iteration 226 / 300: loss 0.602410\n",
      "iteration 226 / 300: loss 0.579811\n",
      "iteration 226 / 300: loss 0.601592\n",
      "iteration 227 / 300: loss 0.585528\n",
      "iteration 227 / 300: loss 0.588428\n",
      "iteration 227 / 300: loss 0.567516\n",
      "iteration 227 / 300: loss 0.592380\n",
      "iteration 227 / 300: loss 0.593618\n",
      "iteration 227 / 300: loss 0.595295\n",
      "iteration 227 / 300: loss 0.608784\n",
      "iteration 227 / 300: loss 0.592732\n",
      "iteration 227 / 300: loss 0.628060\n",
      "iteration 227 / 300: loss 0.580152\n",
      "iteration 227 / 300: loss 0.607923\n",
      "iteration 227 / 300: loss 0.587394\n",
      "iteration 227 / 300: loss 0.591686\n",
      "iteration 227 / 300: loss 0.571370\n",
      "iteration 227 / 300: loss 0.583025\n",
      "iteration 227 / 300: loss 0.608441\n",
      "iteration 227 / 300: loss 0.598359\n",
      "iteration 227 / 300: loss 0.583858\n",
      "iteration 227 / 300: loss 0.615253\n",
      "iteration 227 / 300: loss 0.591649\n",
      "iteration 227 / 300: loss 0.585499\n",
      "iteration 227 / 300: loss 0.591325\n",
      "iteration 227 / 300: loss 0.604341\n",
      "iteration 227 / 300: loss 0.595786\n",
      "iteration 227 / 300: loss 0.614949\n",
      "iteration 227 / 300: loss 0.608389\n",
      "iteration 227 / 300: loss 0.598222\n",
      "iteration 227 / 300: loss 0.588936\n",
      "iteration 227 / 300: loss 0.617757\n",
      "iteration 227 / 300: loss 0.594770\n",
      "iteration 227 / 300: loss 0.601684\n",
      "iteration 227 / 300: loss 0.631031\n",
      "iteration 227 / 300: loss 0.587513\n",
      "iteration 227 / 300: loss 0.606561\n",
      "iteration 227 / 300: loss 0.588034\n",
      "iteration 227 / 300: loss 0.600890\n",
      "iteration 227 / 300: loss 0.595958\n",
      "iteration 227 / 300: loss 0.589291\n",
      "iteration 227 / 300: loss 0.599526\n",
      "iteration 227 / 300: loss 0.604855\n",
      "iteration 227 / 300: loss 0.619414\n",
      "iteration 227 / 300: loss 0.588808\n",
      "iteration 227 / 300: loss 0.593645\n",
      "iteration 227 / 300: loss 0.585595\n",
      "iteration 227 / 300: loss 0.613212\n",
      "iteration 227 / 300: loss 0.587523\n",
      "iteration 227 / 300: loss 0.578328\n",
      "iteration 227 / 300: loss 0.567435\n",
      "iteration 227 / 300: loss 0.562235\n",
      "iteration 227 / 300: loss 0.594183\n",
      "iteration 227 / 300: loss 0.578821\n",
      "iteration 227 / 300: loss 0.586360\n",
      "iteration 227 / 300: loss 0.572890\n",
      "iteration 227 / 300: loss 0.596151\n",
      "iteration 227 / 300: loss 0.607951\n",
      "iteration 227 / 300: loss 0.610839\n",
      "iteration 227 / 300: loss 0.606265\n",
      "iteration 227 / 300: loss 0.583790\n",
      "iteration 227 / 300: loss 0.589627\n",
      "iteration 227 / 300: loss 0.595184\n",
      "iteration 227 / 300: loss 0.598955\n",
      "iteration 227 / 300: loss 0.596133\n",
      "iteration 227 / 300: loss 0.589769\n",
      "iteration 227 / 300: loss 0.591136\n",
      "iteration 227 / 300: loss 0.584854\n",
      "iteration 227 / 300: loss 0.599646\n",
      "iteration 227 / 300: loss 0.598902\n",
      "iteration 227 / 300: loss 0.614282\n",
      "iteration 227 / 300: loss 0.597796\n",
      "iteration 227 / 300: loss 0.599298\n",
      "iteration 227 / 300: loss 0.603317\n",
      "iteration 227 / 300: loss 0.592865\n",
      "iteration 227 / 300: loss 0.592391\n",
      "iteration 227 / 300: loss 0.589041\n",
      "iteration 227 / 300: loss 0.596446\n",
      "iteration 227 / 300: loss 0.605709\n",
      "iteration 227 / 300: loss 0.610562\n",
      "iteration 227 / 300: loss 0.587782\n",
      "iteration 227 / 300: loss 0.599351\n",
      "iteration 227 / 300: loss 0.602792\n",
      "iteration 227 / 300: loss 0.605028\n",
      "iteration 227 / 300: loss 0.603848\n",
      "iteration 227 / 300: loss 0.624144\n",
      "iteration 227 / 300: loss 0.587219\n",
      "iteration 227 / 300: loss 0.580754\n",
      "iteration 227 / 300: loss 0.625045\n",
      "iteration 227 / 300: loss 0.603310\n",
      "iteration 227 / 300: loss 0.604321\n",
      "iteration 227 / 300: loss 0.595476\n",
      "iteration 227 / 300: loss 0.597543\n",
      "iteration 227 / 300: loss 0.592740\n",
      "iteration 227 / 300: loss 0.589494\n",
      "iteration 227 / 300: loss 0.599264\n",
      "iteration 227 / 300: loss 0.611379\n",
      "iteration 227 / 300: loss 0.592463\n",
      "iteration 227 / 300: loss 0.599424\n",
      "iteration 227 / 300: loss 0.603100\n",
      "iteration 227 / 300: loss 0.602410\n",
      "iteration 227 / 300: loss 0.579811\n",
      "iteration 227 / 300: loss 0.601592\n",
      "iteration 228 / 300: loss 0.585528\n",
      "iteration 228 / 300: loss 0.588428\n",
      "iteration 228 / 300: loss 0.567516\n",
      "iteration 228 / 300: loss 0.592380\n",
      "iteration 228 / 300: loss 0.593618\n",
      "iteration 228 / 300: loss 0.595295\n",
      "iteration 228 / 300: loss 0.608784\n",
      "iteration 228 / 300: loss 0.592732\n",
      "iteration 228 / 300: loss 0.628060\n",
      "iteration 228 / 300: loss 0.580152\n",
      "iteration 228 / 300: loss 0.607923\n",
      "iteration 228 / 300: loss 0.587394\n",
      "iteration 228 / 300: loss 0.591686\n",
      "iteration 228 / 300: loss 0.571370\n",
      "iteration 228 / 300: loss 0.583025\n",
      "iteration 228 / 300: loss 0.608441\n",
      "iteration 228 / 300: loss 0.598359\n",
      "iteration 228 / 300: loss 0.583858\n",
      "iteration 228 / 300: loss 0.615253\n",
      "iteration 228 / 300: loss 0.591649\n",
      "iteration 228 / 300: loss 0.585499\n",
      "iteration 228 / 300: loss 0.591325\n",
      "iteration 228 / 300: loss 0.604341\n",
      "iteration 228 / 300: loss 0.595786\n",
      "iteration 228 / 300: loss 0.614949\n",
      "iteration 228 / 300: loss 0.608389\n",
      "iteration 228 / 300: loss 0.598222\n",
      "iteration 228 / 300: loss 0.588936\n",
      "iteration 228 / 300: loss 0.617757\n",
      "iteration 228 / 300: loss 0.594770\n",
      "iteration 228 / 300: loss 0.601684\n",
      "iteration 228 / 300: loss 0.631031\n",
      "iteration 228 / 300: loss 0.587513\n",
      "iteration 228 / 300: loss 0.606561\n",
      "iteration 228 / 300: loss 0.588034\n",
      "iteration 228 / 300: loss 0.600890\n",
      "iteration 228 / 300: loss 0.595958\n",
      "iteration 228 / 300: loss 0.589291\n",
      "iteration 228 / 300: loss 0.599526\n",
      "iteration 228 / 300: loss 0.604855\n",
      "iteration 228 / 300: loss 0.619414\n",
      "iteration 228 / 300: loss 0.588808\n",
      "iteration 228 / 300: loss 0.593645\n",
      "iteration 228 / 300: loss 0.585595\n",
      "iteration 228 / 300: loss 0.613212\n",
      "iteration 228 / 300: loss 0.587523\n",
      "iteration 228 / 300: loss 0.578328\n",
      "iteration 228 / 300: loss 0.567435\n",
      "iteration 228 / 300: loss 0.562235\n",
      "iteration 228 / 300: loss 0.594183\n",
      "iteration 228 / 300: loss 0.578821\n",
      "iteration 228 / 300: loss 0.586360\n",
      "iteration 228 / 300: loss 0.572890\n",
      "iteration 228 / 300: loss 0.596151\n",
      "iteration 228 / 300: loss 0.607951\n",
      "iteration 228 / 300: loss 0.610839\n",
      "iteration 228 / 300: loss 0.606265\n",
      "iteration 228 / 300: loss 0.583790\n",
      "iteration 228 / 300: loss 0.589627\n",
      "iteration 228 / 300: loss 0.595184\n",
      "iteration 228 / 300: loss 0.598955\n",
      "iteration 228 / 300: loss 0.596133\n",
      "iteration 228 / 300: loss 0.589769\n",
      "iteration 228 / 300: loss 0.591136\n",
      "iteration 228 / 300: loss 0.584854\n",
      "iteration 228 / 300: loss 0.599646\n",
      "iteration 228 / 300: loss 0.598902\n",
      "iteration 228 / 300: loss 0.614282\n",
      "iteration 228 / 300: loss 0.597796\n",
      "iteration 228 / 300: loss 0.599298\n",
      "iteration 228 / 300: loss 0.603317\n",
      "iteration 228 / 300: loss 0.592865\n",
      "iteration 228 / 300: loss 0.592391\n",
      "iteration 228 / 300: loss 0.589041\n",
      "iteration 228 / 300: loss 0.596446\n",
      "iteration 228 / 300: loss 0.605709\n",
      "iteration 228 / 300: loss 0.610562\n",
      "iteration 228 / 300: loss 0.587782\n",
      "iteration 228 / 300: loss 0.599351\n",
      "iteration 228 / 300: loss 0.602792\n",
      "iteration 228 / 300: loss 0.605028\n",
      "iteration 228 / 300: loss 0.603848\n",
      "iteration 228 / 300: loss 0.624144\n",
      "iteration 228 / 300: loss 0.587219\n",
      "iteration 228 / 300: loss 0.580754\n",
      "iteration 228 / 300: loss 0.625045\n",
      "iteration 228 / 300: loss 0.603310\n",
      "iteration 228 / 300: loss 0.604321\n",
      "iteration 228 / 300: loss 0.595476\n",
      "iteration 228 / 300: loss 0.597543\n",
      "iteration 228 / 300: loss 0.592740\n",
      "iteration 228 / 300: loss 0.589494\n",
      "iteration 228 / 300: loss 0.599264\n",
      "iteration 228 / 300: loss 0.611379\n",
      "iteration 228 / 300: loss 0.592463\n",
      "iteration 228 / 300: loss 0.599424\n",
      "iteration 228 / 300: loss 0.603100\n",
      "iteration 228 / 300: loss 0.602410\n",
      "iteration 228 / 300: loss 0.579811\n",
      "iteration 228 / 300: loss 0.601592\n",
      "iteration 229 / 300: loss 0.585528\n",
      "iteration 229 / 300: loss 0.588428\n",
      "iteration 229 / 300: loss 0.567516\n",
      "iteration 229 / 300: loss 0.592380\n",
      "iteration 229 / 300: loss 0.593618\n",
      "iteration 229 / 300: loss 0.595295\n",
      "iteration 229 / 300: loss 0.608784\n",
      "iteration 229 / 300: loss 0.592732\n",
      "iteration 229 / 300: loss 0.628060\n",
      "iteration 229 / 300: loss 0.580152\n",
      "iteration 229 / 300: loss 0.607923\n",
      "iteration 229 / 300: loss 0.587394\n",
      "iteration 229 / 300: loss 0.591686\n",
      "iteration 229 / 300: loss 0.571370\n",
      "iteration 229 / 300: loss 0.583025\n",
      "iteration 229 / 300: loss 0.608441\n",
      "iteration 229 / 300: loss 0.598359\n",
      "iteration 229 / 300: loss 0.583858\n",
      "iteration 229 / 300: loss 0.615253\n",
      "iteration 229 / 300: loss 0.591649\n",
      "iteration 229 / 300: loss 0.585499\n",
      "iteration 229 / 300: loss 0.591325\n",
      "iteration 229 / 300: loss 0.604341\n",
      "iteration 229 / 300: loss 0.595786\n",
      "iteration 229 / 300: loss 0.614949\n",
      "iteration 229 / 300: loss 0.608389\n",
      "iteration 229 / 300: loss 0.598222\n",
      "iteration 229 / 300: loss 0.588936\n",
      "iteration 229 / 300: loss 0.617757\n",
      "iteration 229 / 300: loss 0.594770\n",
      "iteration 229 / 300: loss 0.601684\n",
      "iteration 229 / 300: loss 0.631031\n",
      "iteration 229 / 300: loss 0.587513\n",
      "iteration 229 / 300: loss 0.606561\n",
      "iteration 229 / 300: loss 0.588034\n",
      "iteration 229 / 300: loss 0.600890\n",
      "iteration 229 / 300: loss 0.595958\n",
      "iteration 229 / 300: loss 0.589291\n",
      "iteration 229 / 300: loss 0.599526\n",
      "iteration 229 / 300: loss 0.604855\n",
      "iteration 229 / 300: loss 0.619414\n",
      "iteration 229 / 300: loss 0.588808\n",
      "iteration 229 / 300: loss 0.593645\n",
      "iteration 229 / 300: loss 0.585595\n",
      "iteration 229 / 300: loss 0.613212\n",
      "iteration 229 / 300: loss 0.587523\n",
      "iteration 229 / 300: loss 0.578328\n",
      "iteration 229 / 300: loss 0.567435\n",
      "iteration 229 / 300: loss 0.562235\n",
      "iteration 229 / 300: loss 0.594183\n",
      "iteration 229 / 300: loss 0.578821\n",
      "iteration 229 / 300: loss 0.586360\n",
      "iteration 229 / 300: loss 0.572890\n",
      "iteration 229 / 300: loss 0.596151\n",
      "iteration 229 / 300: loss 0.607951\n",
      "iteration 229 / 300: loss 0.610839\n",
      "iteration 229 / 300: loss 0.606265\n",
      "iteration 229 / 300: loss 0.583790\n",
      "iteration 229 / 300: loss 0.589627\n",
      "iteration 229 / 300: loss 0.595184\n",
      "iteration 229 / 300: loss 0.598955\n",
      "iteration 229 / 300: loss 0.596133\n",
      "iteration 229 / 300: loss 0.589769\n",
      "iteration 229 / 300: loss 0.591136\n",
      "iteration 229 / 300: loss 0.584854\n",
      "iteration 229 / 300: loss 0.599646\n",
      "iteration 229 / 300: loss 0.598902\n",
      "iteration 229 / 300: loss 0.614282\n",
      "iteration 229 / 300: loss 0.597796\n",
      "iteration 229 / 300: loss 0.599298\n",
      "iteration 229 / 300: loss 0.603317\n",
      "iteration 229 / 300: loss 0.592865\n",
      "iteration 229 / 300: loss 0.592391\n",
      "iteration 229 / 300: loss 0.589041\n",
      "iteration 229 / 300: loss 0.596446\n",
      "iteration 229 / 300: loss 0.605709\n",
      "iteration 229 / 300: loss 0.610562\n",
      "iteration 229 / 300: loss 0.587782\n",
      "iteration 229 / 300: loss 0.599351\n",
      "iteration 229 / 300: loss 0.602792\n",
      "iteration 229 / 300: loss 0.605028\n",
      "iteration 229 / 300: loss 0.603848\n",
      "iteration 229 / 300: loss 0.624144\n",
      "iteration 229 / 300: loss 0.587219\n",
      "iteration 229 / 300: loss 0.580754\n",
      "iteration 229 / 300: loss 0.625045\n",
      "iteration 229 / 300: loss 0.603310\n",
      "iteration 229 / 300: loss 0.604321\n",
      "iteration 229 / 300: loss 0.595476\n",
      "iteration 229 / 300: loss 0.597543\n",
      "iteration 229 / 300: loss 0.592740\n",
      "iteration 229 / 300: loss 0.589494\n",
      "iteration 229 / 300: loss 0.599264\n",
      "iteration 229 / 300: loss 0.611379\n",
      "iteration 229 / 300: loss 0.592463\n",
      "iteration 229 / 300: loss 0.599424\n",
      "iteration 229 / 300: loss 0.603100\n",
      "iteration 229 / 300: loss 0.602410\n",
      "iteration 229 / 300: loss 0.579811\n",
      "iteration 229 / 300: loss 0.601592\n",
      "iteration 230 / 300: loss 0.585528\n",
      "iteration 230 / 300: loss 0.588428\n",
      "iteration 230 / 300: loss 0.567516\n",
      "iteration 230 / 300: loss 0.592380\n",
      "iteration 230 / 300: loss 0.593618\n",
      "iteration 230 / 300: loss 0.595295\n",
      "iteration 230 / 300: loss 0.608784\n",
      "iteration 230 / 300: loss 0.592732\n",
      "iteration 230 / 300: loss 0.628060\n",
      "iteration 230 / 300: loss 0.580152\n",
      "iteration 230 / 300: loss 0.607923\n",
      "iteration 230 / 300: loss 0.587394\n",
      "iteration 230 / 300: loss 0.591686\n",
      "iteration 230 / 300: loss 0.571370\n",
      "iteration 230 / 300: loss 0.583025\n",
      "iteration 230 / 300: loss 0.608441\n",
      "iteration 230 / 300: loss 0.598359\n",
      "iteration 230 / 300: loss 0.583858\n",
      "iteration 230 / 300: loss 0.615253\n",
      "iteration 230 / 300: loss 0.591649\n",
      "iteration 230 / 300: loss 0.585499\n",
      "iteration 230 / 300: loss 0.591325\n",
      "iteration 230 / 300: loss 0.604341\n",
      "iteration 230 / 300: loss 0.595786\n",
      "iteration 230 / 300: loss 0.614949\n",
      "iteration 230 / 300: loss 0.608389\n",
      "iteration 230 / 300: loss 0.598222\n",
      "iteration 230 / 300: loss 0.588936\n",
      "iteration 230 / 300: loss 0.617757\n",
      "iteration 230 / 300: loss 0.594770\n",
      "iteration 230 / 300: loss 0.601684\n",
      "iteration 230 / 300: loss 0.631031\n",
      "iteration 230 / 300: loss 0.587513\n",
      "iteration 230 / 300: loss 0.606561\n",
      "iteration 230 / 300: loss 0.588034\n",
      "iteration 230 / 300: loss 0.600890\n",
      "iteration 230 / 300: loss 0.595958\n",
      "iteration 230 / 300: loss 0.589291\n",
      "iteration 230 / 300: loss 0.599526\n",
      "iteration 230 / 300: loss 0.604855\n",
      "iteration 230 / 300: loss 0.619414\n",
      "iteration 230 / 300: loss 0.588808\n",
      "iteration 230 / 300: loss 0.593645\n",
      "iteration 230 / 300: loss 0.585595\n",
      "iteration 230 / 300: loss 0.613212\n",
      "iteration 230 / 300: loss 0.587523\n",
      "iteration 230 / 300: loss 0.578328\n",
      "iteration 230 / 300: loss 0.567435\n",
      "iteration 230 / 300: loss 0.562235\n",
      "iteration 230 / 300: loss 0.594183\n",
      "iteration 230 / 300: loss 0.578821\n",
      "iteration 230 / 300: loss 0.586360\n",
      "iteration 230 / 300: loss 0.572890\n",
      "iteration 230 / 300: loss 0.596151\n",
      "iteration 230 / 300: loss 0.607951\n",
      "iteration 230 / 300: loss 0.610839\n",
      "iteration 230 / 300: loss 0.606265\n",
      "iteration 230 / 300: loss 0.583790\n",
      "iteration 230 / 300: loss 0.589627\n",
      "iteration 230 / 300: loss 0.595184\n",
      "iteration 230 / 300: loss 0.598955\n",
      "iteration 230 / 300: loss 0.596133\n",
      "iteration 230 / 300: loss 0.589769\n",
      "iteration 230 / 300: loss 0.591136\n",
      "iteration 230 / 300: loss 0.584854\n",
      "iteration 230 / 300: loss 0.599646\n",
      "iteration 230 / 300: loss 0.598902\n",
      "iteration 230 / 300: loss 0.614282\n",
      "iteration 230 / 300: loss 0.597796\n",
      "iteration 230 / 300: loss 0.599298\n",
      "iteration 230 / 300: loss 0.603317\n",
      "iteration 230 / 300: loss 0.592865\n",
      "iteration 230 / 300: loss 0.592391\n",
      "iteration 230 / 300: loss 0.589041\n",
      "iteration 230 / 300: loss 0.596446\n",
      "iteration 230 / 300: loss 0.605709\n",
      "iteration 230 / 300: loss 0.610562\n",
      "iteration 230 / 300: loss 0.587782\n",
      "iteration 230 / 300: loss 0.599351\n",
      "iteration 230 / 300: loss 0.602792\n",
      "iteration 230 / 300: loss 0.605028\n",
      "iteration 230 / 300: loss 0.603848\n",
      "iteration 230 / 300: loss 0.624144\n",
      "iteration 230 / 300: loss 0.587219\n",
      "iteration 230 / 300: loss 0.580754\n",
      "iteration 230 / 300: loss 0.625045\n",
      "iteration 230 / 300: loss 0.603310\n",
      "iteration 230 / 300: loss 0.604321\n",
      "iteration 230 / 300: loss 0.595476\n",
      "iteration 230 / 300: loss 0.597543\n",
      "iteration 230 / 300: loss 0.592740\n",
      "iteration 230 / 300: loss 0.589494\n",
      "iteration 230 / 300: loss 0.599264\n",
      "iteration 230 / 300: loss 0.611379\n",
      "iteration 230 / 300: loss 0.592463\n",
      "iteration 230 / 300: loss 0.599424\n",
      "iteration 230 / 300: loss 0.603100\n",
      "iteration 230 / 300: loss 0.602410\n",
      "iteration 230 / 300: loss 0.579811\n",
      "iteration 230 / 300: loss 0.601592\n",
      "iteration 231 / 300: loss 0.585528\n",
      "iteration 231 / 300: loss 0.588428\n",
      "iteration 231 / 300: loss 0.567516\n",
      "iteration 231 / 300: loss 0.592380\n",
      "iteration 231 / 300: loss 0.593618\n",
      "iteration 231 / 300: loss 0.595295\n",
      "iteration 231 / 300: loss 0.608784\n",
      "iteration 231 / 300: loss 0.592732\n",
      "iteration 231 / 300: loss 0.628060\n",
      "iteration 231 / 300: loss 0.580152\n",
      "iteration 231 / 300: loss 0.607923\n",
      "iteration 231 / 300: loss 0.587394\n",
      "iteration 231 / 300: loss 0.591686\n",
      "iteration 231 / 300: loss 0.571370\n",
      "iteration 231 / 300: loss 0.583025\n",
      "iteration 231 / 300: loss 0.608441\n",
      "iteration 231 / 300: loss 0.598359\n",
      "iteration 231 / 300: loss 0.583858\n",
      "iteration 231 / 300: loss 0.615253\n",
      "iteration 231 / 300: loss 0.591649\n",
      "iteration 231 / 300: loss 0.585499\n",
      "iteration 231 / 300: loss 0.591325\n",
      "iteration 231 / 300: loss 0.604341\n",
      "iteration 231 / 300: loss 0.595786\n",
      "iteration 231 / 300: loss 0.614949\n",
      "iteration 231 / 300: loss 0.608389\n",
      "iteration 231 / 300: loss 0.598222\n",
      "iteration 231 / 300: loss 0.588936\n",
      "iteration 231 / 300: loss 0.617757\n",
      "iteration 231 / 300: loss 0.594770\n",
      "iteration 231 / 300: loss 0.601684\n",
      "iteration 231 / 300: loss 0.631031\n",
      "iteration 231 / 300: loss 0.587513\n",
      "iteration 231 / 300: loss 0.606561\n",
      "iteration 231 / 300: loss 0.588034\n",
      "iteration 231 / 300: loss 0.600890\n",
      "iteration 231 / 300: loss 0.595958\n",
      "iteration 231 / 300: loss 0.589291\n",
      "iteration 231 / 300: loss 0.599526\n",
      "iteration 231 / 300: loss 0.604855\n",
      "iteration 231 / 300: loss 0.619414\n",
      "iteration 231 / 300: loss 0.588808\n",
      "iteration 231 / 300: loss 0.593645\n",
      "iteration 231 / 300: loss 0.585595\n",
      "iteration 231 / 300: loss 0.613212\n",
      "iteration 231 / 300: loss 0.587523\n",
      "iteration 231 / 300: loss 0.578328\n",
      "iteration 231 / 300: loss 0.567435\n",
      "iteration 231 / 300: loss 0.562235\n",
      "iteration 231 / 300: loss 0.594183\n",
      "iteration 231 / 300: loss 0.578821\n",
      "iteration 231 / 300: loss 0.586360\n",
      "iteration 231 / 300: loss 0.572890\n",
      "iteration 231 / 300: loss 0.596151\n",
      "iteration 231 / 300: loss 0.607951\n",
      "iteration 231 / 300: loss 0.610839\n",
      "iteration 231 / 300: loss 0.606265\n",
      "iteration 231 / 300: loss 0.583790\n",
      "iteration 231 / 300: loss 0.589627\n",
      "iteration 231 / 300: loss 0.595184\n",
      "iteration 231 / 300: loss 0.598955\n",
      "iteration 231 / 300: loss 0.596133\n",
      "iteration 231 / 300: loss 0.589769\n",
      "iteration 231 / 300: loss 0.591136\n",
      "iteration 231 / 300: loss 0.584854\n",
      "iteration 231 / 300: loss 0.599646\n",
      "iteration 231 / 300: loss 0.598902\n",
      "iteration 231 / 300: loss 0.614282\n",
      "iteration 231 / 300: loss 0.597796\n",
      "iteration 231 / 300: loss 0.599298\n",
      "iteration 231 / 300: loss 0.603317\n",
      "iteration 231 / 300: loss 0.592865\n",
      "iteration 231 / 300: loss 0.592391\n",
      "iteration 231 / 300: loss 0.589041\n",
      "iteration 231 / 300: loss 0.596446\n",
      "iteration 231 / 300: loss 0.605709\n",
      "iteration 231 / 300: loss 0.610562\n",
      "iteration 231 / 300: loss 0.587782\n",
      "iteration 231 / 300: loss 0.599351\n",
      "iteration 231 / 300: loss 0.602792\n",
      "iteration 231 / 300: loss 0.605028\n",
      "iteration 231 / 300: loss 0.603848\n",
      "iteration 231 / 300: loss 0.624144\n",
      "iteration 231 / 300: loss 0.587219\n",
      "iteration 231 / 300: loss 0.580754\n",
      "iteration 231 / 300: loss 0.625045\n",
      "iteration 231 / 300: loss 0.603310\n",
      "iteration 231 / 300: loss 0.604321\n",
      "iteration 231 / 300: loss 0.595476\n",
      "iteration 231 / 300: loss 0.597543\n",
      "iteration 231 / 300: loss 0.592740\n",
      "iteration 231 / 300: loss 0.589494\n",
      "iteration 231 / 300: loss 0.599264\n",
      "iteration 231 / 300: loss 0.611379\n",
      "iteration 231 / 300: loss 0.592463\n",
      "iteration 231 / 300: loss 0.599424\n",
      "iteration 231 / 300: loss 0.603100\n",
      "iteration 231 / 300: loss 0.602410\n",
      "iteration 231 / 300: loss 0.579811\n",
      "iteration 231 / 300: loss 0.601592\n",
      "iteration 232 / 300: loss 0.585528\n",
      "iteration 232 / 300: loss 0.588428\n",
      "iteration 232 / 300: loss 0.567516\n",
      "iteration 232 / 300: loss 0.592380\n",
      "iteration 232 / 300: loss 0.593618\n",
      "iteration 232 / 300: loss 0.595295\n",
      "iteration 232 / 300: loss 0.608784\n",
      "iteration 232 / 300: loss 0.592732\n",
      "iteration 232 / 300: loss 0.628060\n",
      "iteration 232 / 300: loss 0.580152\n",
      "iteration 232 / 300: loss 0.607923\n",
      "iteration 232 / 300: loss 0.587394\n",
      "iteration 232 / 300: loss 0.591686\n",
      "iteration 232 / 300: loss 0.571370\n",
      "iteration 232 / 300: loss 0.583025\n",
      "iteration 232 / 300: loss 0.608441\n",
      "iteration 232 / 300: loss 0.598359\n",
      "iteration 232 / 300: loss 0.583858\n",
      "iteration 232 / 300: loss 0.615253\n",
      "iteration 232 / 300: loss 0.591649\n",
      "iteration 232 / 300: loss 0.585499\n",
      "iteration 232 / 300: loss 0.591325\n",
      "iteration 232 / 300: loss 0.604341\n",
      "iteration 232 / 300: loss 0.595786\n",
      "iteration 232 / 300: loss 0.614949\n",
      "iteration 232 / 300: loss 0.608389\n",
      "iteration 232 / 300: loss 0.598222\n",
      "iteration 232 / 300: loss 0.588936\n",
      "iteration 232 / 300: loss 0.617757\n",
      "iteration 232 / 300: loss 0.594770\n",
      "iteration 232 / 300: loss 0.601684\n",
      "iteration 232 / 300: loss 0.631031\n",
      "iteration 232 / 300: loss 0.587513\n",
      "iteration 232 / 300: loss 0.606561\n",
      "iteration 232 / 300: loss 0.588034\n",
      "iteration 232 / 300: loss 0.600890\n",
      "iteration 232 / 300: loss 0.595958\n",
      "iteration 232 / 300: loss 0.589291\n",
      "iteration 232 / 300: loss 0.599526\n",
      "iteration 232 / 300: loss 0.604855\n",
      "iteration 232 / 300: loss 0.619414\n",
      "iteration 232 / 300: loss 0.588808\n",
      "iteration 232 / 300: loss 0.593645\n",
      "iteration 232 / 300: loss 0.585595\n",
      "iteration 232 / 300: loss 0.613212\n",
      "iteration 232 / 300: loss 0.587523\n",
      "iteration 232 / 300: loss 0.578328\n",
      "iteration 232 / 300: loss 0.567435\n",
      "iteration 232 / 300: loss 0.562235\n",
      "iteration 232 / 300: loss 0.594183\n",
      "iteration 232 / 300: loss 0.578821\n",
      "iteration 232 / 300: loss 0.586360\n",
      "iteration 232 / 300: loss 0.572890\n",
      "iteration 232 / 300: loss 0.596151\n",
      "iteration 232 / 300: loss 0.607951\n",
      "iteration 232 / 300: loss 0.610839\n",
      "iteration 232 / 300: loss 0.606265\n",
      "iteration 232 / 300: loss 0.583790\n",
      "iteration 232 / 300: loss 0.589627\n",
      "iteration 232 / 300: loss 0.595184\n",
      "iteration 232 / 300: loss 0.598955\n",
      "iteration 232 / 300: loss 0.596133\n",
      "iteration 232 / 300: loss 0.589769\n",
      "iteration 232 / 300: loss 0.591136\n",
      "iteration 232 / 300: loss 0.584854\n",
      "iteration 232 / 300: loss 0.599646\n",
      "iteration 232 / 300: loss 0.598902\n",
      "iteration 232 / 300: loss 0.614282\n",
      "iteration 232 / 300: loss 0.597796\n",
      "iteration 232 / 300: loss 0.599298\n",
      "iteration 232 / 300: loss 0.603317\n",
      "iteration 232 / 300: loss 0.592865\n",
      "iteration 232 / 300: loss 0.592391\n",
      "iteration 232 / 300: loss 0.589041\n",
      "iteration 232 / 300: loss 0.596446\n",
      "iteration 232 / 300: loss 0.605709\n",
      "iteration 232 / 300: loss 0.610562\n",
      "iteration 232 / 300: loss 0.587782\n",
      "iteration 232 / 300: loss 0.599351\n",
      "iteration 232 / 300: loss 0.602792\n",
      "iteration 232 / 300: loss 0.605028\n",
      "iteration 232 / 300: loss 0.603848\n",
      "iteration 232 / 300: loss 0.624144\n",
      "iteration 232 / 300: loss 0.587219\n",
      "iteration 232 / 300: loss 0.580754\n",
      "iteration 232 / 300: loss 0.625045\n",
      "iteration 232 / 300: loss 0.603310\n",
      "iteration 232 / 300: loss 0.604321\n",
      "iteration 232 / 300: loss 0.595476\n",
      "iteration 232 / 300: loss 0.597543\n",
      "iteration 232 / 300: loss 0.592740\n",
      "iteration 232 / 300: loss 0.589494\n",
      "iteration 232 / 300: loss 0.599264\n",
      "iteration 232 / 300: loss 0.611379\n",
      "iteration 232 / 300: loss 0.592463\n",
      "iteration 232 / 300: loss 0.599424\n",
      "iteration 232 / 300: loss 0.603100\n",
      "iteration 232 / 300: loss 0.602410\n",
      "iteration 232 / 300: loss 0.579811\n",
      "iteration 232 / 300: loss 0.601592\n",
      "iteration 233 / 300: loss 0.585528\n",
      "iteration 233 / 300: loss 0.588428\n",
      "iteration 233 / 300: loss 0.567516\n",
      "iteration 233 / 300: loss 0.592380\n",
      "iteration 233 / 300: loss 0.593618\n",
      "iteration 233 / 300: loss 0.595295\n",
      "iteration 233 / 300: loss 0.608784\n",
      "iteration 233 / 300: loss 0.592732\n",
      "iteration 233 / 300: loss 0.628060\n",
      "iteration 233 / 300: loss 0.580152\n",
      "iteration 233 / 300: loss 0.607923\n",
      "iteration 233 / 300: loss 0.587394\n",
      "iteration 233 / 300: loss 0.591686\n",
      "iteration 233 / 300: loss 0.571370\n",
      "iteration 233 / 300: loss 0.583025\n",
      "iteration 233 / 300: loss 0.608441\n",
      "iteration 233 / 300: loss 0.598359\n",
      "iteration 233 / 300: loss 0.583858\n",
      "iteration 233 / 300: loss 0.615253\n",
      "iteration 233 / 300: loss 0.591649\n",
      "iteration 233 / 300: loss 0.585499\n",
      "iteration 233 / 300: loss 0.591325\n",
      "iteration 233 / 300: loss 0.604341\n",
      "iteration 233 / 300: loss 0.595786\n",
      "iteration 233 / 300: loss 0.614949\n",
      "iteration 233 / 300: loss 0.608389\n",
      "iteration 233 / 300: loss 0.598222\n",
      "iteration 233 / 300: loss 0.588936\n",
      "iteration 233 / 300: loss 0.617757\n",
      "iteration 233 / 300: loss 0.594770\n",
      "iteration 233 / 300: loss 0.601684\n",
      "iteration 233 / 300: loss 0.631031\n",
      "iteration 233 / 300: loss 0.587513\n",
      "iteration 233 / 300: loss 0.606561\n",
      "iteration 233 / 300: loss 0.588034\n",
      "iteration 233 / 300: loss 0.600890\n",
      "iteration 233 / 300: loss 0.595958\n",
      "iteration 233 / 300: loss 0.589291\n",
      "iteration 233 / 300: loss 0.599526\n",
      "iteration 233 / 300: loss 0.604855\n",
      "iteration 233 / 300: loss 0.619414\n",
      "iteration 233 / 300: loss 0.588808\n",
      "iteration 233 / 300: loss 0.593645\n",
      "iteration 233 / 300: loss 0.585595\n",
      "iteration 233 / 300: loss 0.613212\n",
      "iteration 233 / 300: loss 0.587523\n",
      "iteration 233 / 300: loss 0.578328\n",
      "iteration 233 / 300: loss 0.567435\n",
      "iteration 233 / 300: loss 0.562235\n",
      "iteration 233 / 300: loss 0.594183\n",
      "iteration 233 / 300: loss 0.578821\n",
      "iteration 233 / 300: loss 0.586360\n",
      "iteration 233 / 300: loss 0.572890\n",
      "iteration 233 / 300: loss 0.596151\n",
      "iteration 233 / 300: loss 0.607951\n",
      "iteration 233 / 300: loss 0.610839\n",
      "iteration 233 / 300: loss 0.606265\n",
      "iteration 233 / 300: loss 0.583790\n",
      "iteration 233 / 300: loss 0.589627\n",
      "iteration 233 / 300: loss 0.595184\n",
      "iteration 233 / 300: loss 0.598955\n",
      "iteration 233 / 300: loss 0.596133\n",
      "iteration 233 / 300: loss 0.589769\n",
      "iteration 233 / 300: loss 0.591136\n",
      "iteration 233 / 300: loss 0.584854\n",
      "iteration 233 / 300: loss 0.599646\n",
      "iteration 233 / 300: loss 0.598902\n",
      "iteration 233 / 300: loss 0.614282\n",
      "iteration 233 / 300: loss 0.597796\n",
      "iteration 233 / 300: loss 0.599298\n",
      "iteration 233 / 300: loss 0.603317\n",
      "iteration 233 / 300: loss 0.592865\n",
      "iteration 233 / 300: loss 0.592391\n",
      "iteration 233 / 300: loss 0.589041\n",
      "iteration 233 / 300: loss 0.596446\n",
      "iteration 233 / 300: loss 0.605709\n",
      "iteration 233 / 300: loss 0.610562\n",
      "iteration 233 / 300: loss 0.587782\n",
      "iteration 233 / 300: loss 0.599351\n",
      "iteration 233 / 300: loss 0.602792\n",
      "iteration 233 / 300: loss 0.605028\n",
      "iteration 233 / 300: loss 0.603848\n",
      "iteration 233 / 300: loss 0.624144\n",
      "iteration 233 / 300: loss 0.587219\n",
      "iteration 233 / 300: loss 0.580754\n",
      "iteration 233 / 300: loss 0.625045\n",
      "iteration 233 / 300: loss 0.603310\n",
      "iteration 233 / 300: loss 0.604321\n",
      "iteration 233 / 300: loss 0.595476\n",
      "iteration 233 / 300: loss 0.597543\n",
      "iteration 233 / 300: loss 0.592740\n",
      "iteration 233 / 300: loss 0.589494\n",
      "iteration 233 / 300: loss 0.599264\n",
      "iteration 233 / 300: loss 0.611379\n",
      "iteration 233 / 300: loss 0.592463\n",
      "iteration 233 / 300: loss 0.599424\n",
      "iteration 233 / 300: loss 0.603100\n",
      "iteration 233 / 300: loss 0.602410\n",
      "iteration 233 / 300: loss 0.579811\n",
      "iteration 233 / 300: loss 0.601592\n",
      "iteration 234 / 300: loss 0.585528\n",
      "iteration 234 / 300: loss 0.588428\n",
      "iteration 234 / 300: loss 0.567516\n",
      "iteration 234 / 300: loss 0.592380\n",
      "iteration 234 / 300: loss 0.593618\n",
      "iteration 234 / 300: loss 0.595295\n",
      "iteration 234 / 300: loss 0.608784\n",
      "iteration 234 / 300: loss 0.592732\n",
      "iteration 234 / 300: loss 0.628060\n",
      "iteration 234 / 300: loss 0.580152\n",
      "iteration 234 / 300: loss 0.607923\n",
      "iteration 234 / 300: loss 0.587394\n",
      "iteration 234 / 300: loss 0.591686\n",
      "iteration 234 / 300: loss 0.571370\n",
      "iteration 234 / 300: loss 0.583025\n",
      "iteration 234 / 300: loss 0.608441\n",
      "iteration 234 / 300: loss 0.598359\n",
      "iteration 234 / 300: loss 0.583858\n",
      "iteration 234 / 300: loss 0.615253\n",
      "iteration 234 / 300: loss 0.591649\n",
      "iteration 234 / 300: loss 0.585499\n",
      "iteration 234 / 300: loss 0.591325\n",
      "iteration 234 / 300: loss 0.604341\n",
      "iteration 234 / 300: loss 0.595786\n",
      "iteration 234 / 300: loss 0.614949\n",
      "iteration 234 / 300: loss 0.608389\n",
      "iteration 234 / 300: loss 0.598222\n",
      "iteration 234 / 300: loss 0.588936\n",
      "iteration 234 / 300: loss 0.617757\n",
      "iteration 234 / 300: loss 0.594770\n",
      "iteration 234 / 300: loss 0.601684\n",
      "iteration 234 / 300: loss 0.631031\n",
      "iteration 234 / 300: loss 0.587513\n",
      "iteration 234 / 300: loss 0.606561\n",
      "iteration 234 / 300: loss 0.588034\n",
      "iteration 234 / 300: loss 0.600890\n",
      "iteration 234 / 300: loss 0.595958\n",
      "iteration 234 / 300: loss 0.589291\n",
      "iteration 234 / 300: loss 0.599526\n",
      "iteration 234 / 300: loss 0.604855\n",
      "iteration 234 / 300: loss 0.619414\n",
      "iteration 234 / 300: loss 0.588808\n",
      "iteration 234 / 300: loss 0.593645\n",
      "iteration 234 / 300: loss 0.585595\n",
      "iteration 234 / 300: loss 0.613212\n",
      "iteration 234 / 300: loss 0.587523\n",
      "iteration 234 / 300: loss 0.578328\n",
      "iteration 234 / 300: loss 0.567435\n",
      "iteration 234 / 300: loss 0.562235\n",
      "iteration 234 / 300: loss 0.594183\n",
      "iteration 234 / 300: loss 0.578821\n",
      "iteration 234 / 300: loss 0.586360\n",
      "iteration 234 / 300: loss 0.572890\n",
      "iteration 234 / 300: loss 0.596151\n",
      "iteration 234 / 300: loss 0.607951\n",
      "iteration 234 / 300: loss 0.610839\n",
      "iteration 234 / 300: loss 0.606265\n",
      "iteration 234 / 300: loss 0.583790\n",
      "iteration 234 / 300: loss 0.589627\n",
      "iteration 234 / 300: loss 0.595184\n",
      "iteration 234 / 300: loss 0.598955\n",
      "iteration 234 / 300: loss 0.596133\n",
      "iteration 234 / 300: loss 0.589769\n",
      "iteration 234 / 300: loss 0.591136\n",
      "iteration 234 / 300: loss 0.584854\n",
      "iteration 234 / 300: loss 0.599646\n",
      "iteration 234 / 300: loss 0.598902\n",
      "iteration 234 / 300: loss 0.614282\n",
      "iteration 234 / 300: loss 0.597796\n",
      "iteration 234 / 300: loss 0.599298\n",
      "iteration 234 / 300: loss 0.603317\n",
      "iteration 234 / 300: loss 0.592865\n",
      "iteration 234 / 300: loss 0.592391\n",
      "iteration 234 / 300: loss 0.589041\n",
      "iteration 234 / 300: loss 0.596446\n",
      "iteration 234 / 300: loss 0.605709\n",
      "iteration 234 / 300: loss 0.610562\n",
      "iteration 234 / 300: loss 0.587782\n",
      "iteration 234 / 300: loss 0.599351\n",
      "iteration 234 / 300: loss 0.602792\n",
      "iteration 234 / 300: loss 0.605028\n",
      "iteration 234 / 300: loss 0.603848\n",
      "iteration 234 / 300: loss 0.624144\n",
      "iteration 234 / 300: loss 0.587219\n",
      "iteration 234 / 300: loss 0.580754\n",
      "iteration 234 / 300: loss 0.625045\n",
      "iteration 234 / 300: loss 0.603310\n",
      "iteration 234 / 300: loss 0.604321\n",
      "iteration 234 / 300: loss 0.595476\n",
      "iteration 234 / 300: loss 0.597543\n",
      "iteration 234 / 300: loss 0.592740\n",
      "iteration 234 / 300: loss 0.589494\n",
      "iteration 234 / 300: loss 0.599264\n",
      "iteration 234 / 300: loss 0.611379\n",
      "iteration 234 / 300: loss 0.592463\n",
      "iteration 234 / 300: loss 0.599424\n",
      "iteration 234 / 300: loss 0.603100\n",
      "iteration 234 / 300: loss 0.602410\n",
      "iteration 234 / 300: loss 0.579811\n",
      "iteration 234 / 300: loss 0.601592\n",
      "iteration 235 / 300: loss 0.585528\n",
      "iteration 235 / 300: loss 0.588428\n",
      "iteration 235 / 300: loss 0.567516\n",
      "iteration 235 / 300: loss 0.592380\n",
      "iteration 235 / 300: loss 0.593618\n",
      "iteration 235 / 300: loss 0.595295\n",
      "iteration 235 / 300: loss 0.608784\n",
      "iteration 235 / 300: loss 0.592732\n",
      "iteration 235 / 300: loss 0.628060\n",
      "iteration 235 / 300: loss 0.580152\n",
      "iteration 235 / 300: loss 0.607923\n",
      "iteration 235 / 300: loss 0.587394\n",
      "iteration 235 / 300: loss 0.591686\n",
      "iteration 235 / 300: loss 0.571370\n",
      "iteration 235 / 300: loss 0.583025\n",
      "iteration 235 / 300: loss 0.608441\n",
      "iteration 235 / 300: loss 0.598359\n",
      "iteration 235 / 300: loss 0.583858\n",
      "iteration 235 / 300: loss 0.615253\n",
      "iteration 235 / 300: loss 0.591649\n",
      "iteration 235 / 300: loss 0.585499\n",
      "iteration 235 / 300: loss 0.591325\n",
      "iteration 235 / 300: loss 0.604341\n",
      "iteration 235 / 300: loss 0.595786\n",
      "iteration 235 / 300: loss 0.614949\n",
      "iteration 235 / 300: loss 0.608389\n",
      "iteration 235 / 300: loss 0.598222\n",
      "iteration 235 / 300: loss 0.588936\n",
      "iteration 235 / 300: loss 0.617757\n",
      "iteration 235 / 300: loss 0.594770\n",
      "iteration 235 / 300: loss 0.601684\n",
      "iteration 235 / 300: loss 0.631031\n",
      "iteration 235 / 300: loss 0.587513\n",
      "iteration 235 / 300: loss 0.606561\n",
      "iteration 235 / 300: loss 0.588034\n",
      "iteration 235 / 300: loss 0.600890\n",
      "iteration 235 / 300: loss 0.595958\n",
      "iteration 235 / 300: loss 0.589291\n",
      "iteration 235 / 300: loss 0.599526\n",
      "iteration 235 / 300: loss 0.604855\n",
      "iteration 235 / 300: loss 0.619414\n",
      "iteration 235 / 300: loss 0.588808\n",
      "iteration 235 / 300: loss 0.593645\n",
      "iteration 235 / 300: loss 0.585595\n",
      "iteration 235 / 300: loss 0.613212\n",
      "iteration 235 / 300: loss 0.587523\n",
      "iteration 235 / 300: loss 0.578328\n",
      "iteration 235 / 300: loss 0.567435\n",
      "iteration 235 / 300: loss 0.562235\n",
      "iteration 235 / 300: loss 0.594183\n",
      "iteration 235 / 300: loss 0.578821\n",
      "iteration 235 / 300: loss 0.586360\n",
      "iteration 235 / 300: loss 0.572890\n",
      "iteration 235 / 300: loss 0.596151\n",
      "iteration 235 / 300: loss 0.607951\n",
      "iteration 235 / 300: loss 0.610839\n",
      "iteration 235 / 300: loss 0.606265\n",
      "iteration 235 / 300: loss 0.583790\n",
      "iteration 235 / 300: loss 0.589627\n",
      "iteration 235 / 300: loss 0.595184\n",
      "iteration 235 / 300: loss 0.598955\n",
      "iteration 235 / 300: loss 0.596133\n",
      "iteration 235 / 300: loss 0.589769\n",
      "iteration 235 / 300: loss 0.591136\n",
      "iteration 235 / 300: loss 0.584854\n",
      "iteration 235 / 300: loss 0.599646\n",
      "iteration 235 / 300: loss 0.598902\n",
      "iteration 235 / 300: loss 0.614282\n",
      "iteration 235 / 300: loss 0.597796\n",
      "iteration 235 / 300: loss 0.599298\n",
      "iteration 235 / 300: loss 0.603317\n",
      "iteration 235 / 300: loss 0.592865\n",
      "iteration 235 / 300: loss 0.592391\n",
      "iteration 235 / 300: loss 0.589041\n",
      "iteration 235 / 300: loss 0.596446\n",
      "iteration 235 / 300: loss 0.605709\n",
      "iteration 235 / 300: loss 0.610562\n",
      "iteration 235 / 300: loss 0.587782\n",
      "iteration 235 / 300: loss 0.599351\n",
      "iteration 235 / 300: loss 0.602792\n",
      "iteration 235 / 300: loss 0.605028\n",
      "iteration 235 / 300: loss 0.603848\n",
      "iteration 235 / 300: loss 0.624144\n",
      "iteration 235 / 300: loss 0.587219\n",
      "iteration 235 / 300: loss 0.580754\n",
      "iteration 235 / 300: loss 0.625045\n",
      "iteration 235 / 300: loss 0.603310\n",
      "iteration 235 / 300: loss 0.604321\n",
      "iteration 235 / 300: loss 0.595476\n",
      "iteration 235 / 300: loss 0.597543\n",
      "iteration 235 / 300: loss 0.592740\n",
      "iteration 235 / 300: loss 0.589494\n",
      "iteration 235 / 300: loss 0.599264\n",
      "iteration 235 / 300: loss 0.611379\n",
      "iteration 235 / 300: loss 0.592463\n",
      "iteration 235 / 300: loss 0.599424\n",
      "iteration 235 / 300: loss 0.603100\n",
      "iteration 235 / 300: loss 0.602410\n",
      "iteration 235 / 300: loss 0.579811\n",
      "iteration 235 / 300: loss 0.601592\n",
      "iteration 236 / 300: loss 0.585528\n",
      "iteration 236 / 300: loss 0.588428\n",
      "iteration 236 / 300: loss 0.567516\n",
      "iteration 236 / 300: loss 0.592380\n",
      "iteration 236 / 300: loss 0.593618\n",
      "iteration 236 / 300: loss 0.595295\n",
      "iteration 236 / 300: loss 0.608784\n",
      "iteration 236 / 300: loss 0.592732\n",
      "iteration 236 / 300: loss 0.628060\n",
      "iteration 236 / 300: loss 0.580152\n",
      "iteration 236 / 300: loss 0.607923\n",
      "iteration 236 / 300: loss 0.587394\n",
      "iteration 236 / 300: loss 0.591686\n",
      "iteration 236 / 300: loss 0.571370\n",
      "iteration 236 / 300: loss 0.583025\n",
      "iteration 236 / 300: loss 0.608441\n",
      "iteration 236 / 300: loss 0.598359\n",
      "iteration 236 / 300: loss 0.583858\n",
      "iteration 236 / 300: loss 0.615253\n",
      "iteration 236 / 300: loss 0.591649\n",
      "iteration 236 / 300: loss 0.585499\n",
      "iteration 236 / 300: loss 0.591325\n",
      "iteration 236 / 300: loss 0.604341\n",
      "iteration 236 / 300: loss 0.595786\n",
      "iteration 236 / 300: loss 0.614949\n",
      "iteration 236 / 300: loss 0.608389\n",
      "iteration 236 / 300: loss 0.598222\n",
      "iteration 236 / 300: loss 0.588936\n",
      "iteration 236 / 300: loss 0.617757\n",
      "iteration 236 / 300: loss 0.594770\n",
      "iteration 236 / 300: loss 0.601684\n",
      "iteration 236 / 300: loss 0.631031\n",
      "iteration 236 / 300: loss 0.587513\n",
      "iteration 236 / 300: loss 0.606561\n",
      "iteration 236 / 300: loss 0.588034\n",
      "iteration 236 / 300: loss 0.600890\n",
      "iteration 236 / 300: loss 0.595958\n",
      "iteration 236 / 300: loss 0.589291\n",
      "iteration 236 / 300: loss 0.599526\n",
      "iteration 236 / 300: loss 0.604855\n",
      "iteration 236 / 300: loss 0.619414\n",
      "iteration 236 / 300: loss 0.588808\n",
      "iteration 236 / 300: loss 0.593645\n",
      "iteration 236 / 300: loss 0.585595\n",
      "iteration 236 / 300: loss 0.613212\n",
      "iteration 236 / 300: loss 0.587523\n",
      "iteration 236 / 300: loss 0.578328\n",
      "iteration 236 / 300: loss 0.567435\n",
      "iteration 236 / 300: loss 0.562235\n",
      "iteration 236 / 300: loss 0.594183\n",
      "iteration 236 / 300: loss 0.578821\n",
      "iteration 236 / 300: loss 0.586360\n",
      "iteration 236 / 300: loss 0.572890\n",
      "iteration 236 / 300: loss 0.596151\n",
      "iteration 236 / 300: loss 0.607951\n",
      "iteration 236 / 300: loss 0.610839\n",
      "iteration 236 / 300: loss 0.606265\n",
      "iteration 236 / 300: loss 0.583790\n",
      "iteration 236 / 300: loss 0.589627\n",
      "iteration 236 / 300: loss 0.595184\n",
      "iteration 236 / 300: loss 0.598955\n",
      "iteration 236 / 300: loss 0.596133\n",
      "iteration 236 / 300: loss 0.589769\n",
      "iteration 236 / 300: loss 0.591136\n",
      "iteration 236 / 300: loss 0.584854\n",
      "iteration 236 / 300: loss 0.599646\n",
      "iteration 236 / 300: loss 0.598902\n",
      "iteration 236 / 300: loss 0.614282\n",
      "iteration 236 / 300: loss 0.597796\n",
      "iteration 236 / 300: loss 0.599298\n",
      "iteration 236 / 300: loss 0.603317\n",
      "iteration 236 / 300: loss 0.592865\n",
      "iteration 236 / 300: loss 0.592391\n",
      "iteration 236 / 300: loss 0.589041\n",
      "iteration 236 / 300: loss 0.596446\n",
      "iteration 236 / 300: loss 0.605709\n",
      "iteration 236 / 300: loss 0.610562\n",
      "iteration 236 / 300: loss 0.587782\n",
      "iteration 236 / 300: loss 0.599351\n",
      "iteration 236 / 300: loss 0.602792\n",
      "iteration 236 / 300: loss 0.605028\n",
      "iteration 236 / 300: loss 0.603848\n",
      "iteration 236 / 300: loss 0.624144\n",
      "iteration 236 / 300: loss 0.587219\n",
      "iteration 236 / 300: loss 0.580754\n",
      "iteration 236 / 300: loss 0.625045\n",
      "iteration 236 / 300: loss 0.603310\n",
      "iteration 236 / 300: loss 0.604321\n",
      "iteration 236 / 300: loss 0.595476\n",
      "iteration 236 / 300: loss 0.597543\n",
      "iteration 236 / 300: loss 0.592740\n",
      "iteration 236 / 300: loss 0.589494\n",
      "iteration 236 / 300: loss 0.599264\n",
      "iteration 236 / 300: loss 0.611379\n",
      "iteration 236 / 300: loss 0.592463\n",
      "iteration 236 / 300: loss 0.599424\n",
      "iteration 236 / 300: loss 0.603100\n",
      "iteration 236 / 300: loss 0.602410\n",
      "iteration 236 / 300: loss 0.579811\n",
      "iteration 236 / 300: loss 0.601592\n",
      "iteration 237 / 300: loss 0.585528\n",
      "iteration 237 / 300: loss 0.588428\n",
      "iteration 237 / 300: loss 0.567516\n",
      "iteration 237 / 300: loss 0.592380\n",
      "iteration 237 / 300: loss 0.593618\n",
      "iteration 237 / 300: loss 0.595295\n",
      "iteration 237 / 300: loss 0.608784\n",
      "iteration 237 / 300: loss 0.592732\n",
      "iteration 237 / 300: loss 0.628060\n",
      "iteration 237 / 300: loss 0.580152\n",
      "iteration 237 / 300: loss 0.607923\n",
      "iteration 237 / 300: loss 0.587394\n",
      "iteration 237 / 300: loss 0.591686\n",
      "iteration 237 / 300: loss 0.571370\n",
      "iteration 237 / 300: loss 0.583025\n",
      "iteration 237 / 300: loss 0.608441\n",
      "iteration 237 / 300: loss 0.598359\n",
      "iteration 237 / 300: loss 0.583858\n",
      "iteration 237 / 300: loss 0.615253\n",
      "iteration 237 / 300: loss 0.591649\n",
      "iteration 237 / 300: loss 0.585499\n",
      "iteration 237 / 300: loss 0.591325\n",
      "iteration 237 / 300: loss 0.604341\n",
      "iteration 237 / 300: loss 0.595786\n",
      "iteration 237 / 300: loss 0.614949\n",
      "iteration 237 / 300: loss 0.608389\n",
      "iteration 237 / 300: loss 0.598222\n",
      "iteration 237 / 300: loss 0.588936\n",
      "iteration 237 / 300: loss 0.617757\n",
      "iteration 237 / 300: loss 0.594770\n",
      "iteration 237 / 300: loss 0.601684\n",
      "iteration 237 / 300: loss 0.631031\n",
      "iteration 237 / 300: loss 0.587513\n",
      "iteration 237 / 300: loss 0.606561\n",
      "iteration 237 / 300: loss 0.588034\n",
      "iteration 237 / 300: loss 0.600890\n",
      "iteration 237 / 300: loss 0.595958\n",
      "iteration 237 / 300: loss 0.589291\n",
      "iteration 237 / 300: loss 0.599526\n",
      "iteration 237 / 300: loss 0.604855\n",
      "iteration 237 / 300: loss 0.619414\n",
      "iteration 237 / 300: loss 0.588808\n",
      "iteration 237 / 300: loss 0.593645\n",
      "iteration 237 / 300: loss 0.585595\n",
      "iteration 237 / 300: loss 0.613212\n",
      "iteration 237 / 300: loss 0.587523\n",
      "iteration 237 / 300: loss 0.578328\n",
      "iteration 237 / 300: loss 0.567435\n",
      "iteration 237 / 300: loss 0.562235\n",
      "iteration 237 / 300: loss 0.594183\n",
      "iteration 237 / 300: loss 0.578821\n",
      "iteration 237 / 300: loss 0.586360\n",
      "iteration 237 / 300: loss 0.572890\n",
      "iteration 237 / 300: loss 0.596151\n",
      "iteration 237 / 300: loss 0.607951\n",
      "iteration 237 / 300: loss 0.610839\n",
      "iteration 237 / 300: loss 0.606265\n",
      "iteration 237 / 300: loss 0.583790\n",
      "iteration 237 / 300: loss 0.589627\n",
      "iteration 237 / 300: loss 0.595184\n",
      "iteration 237 / 300: loss 0.598955\n",
      "iteration 237 / 300: loss 0.596133\n",
      "iteration 237 / 300: loss 0.589769\n",
      "iteration 237 / 300: loss 0.591136\n",
      "iteration 237 / 300: loss 0.584854\n",
      "iteration 237 / 300: loss 0.599646\n",
      "iteration 237 / 300: loss 0.598902\n",
      "iteration 237 / 300: loss 0.614282\n",
      "iteration 237 / 300: loss 0.597796\n",
      "iteration 237 / 300: loss 0.599298\n",
      "iteration 237 / 300: loss 0.603317\n",
      "iteration 237 / 300: loss 0.592865\n",
      "iteration 237 / 300: loss 0.592391\n",
      "iteration 237 / 300: loss 0.589041\n",
      "iteration 237 / 300: loss 0.596446\n",
      "iteration 237 / 300: loss 0.605709\n",
      "iteration 237 / 300: loss 0.610562\n",
      "iteration 237 / 300: loss 0.587782\n",
      "iteration 237 / 300: loss 0.599351\n",
      "iteration 237 / 300: loss 0.602792\n",
      "iteration 237 / 300: loss 0.605028\n",
      "iteration 237 / 300: loss 0.603848\n",
      "iteration 237 / 300: loss 0.624144\n",
      "iteration 237 / 300: loss 0.587219\n",
      "iteration 237 / 300: loss 0.580754\n",
      "iteration 237 / 300: loss 0.625045\n",
      "iteration 237 / 300: loss 0.603310\n",
      "iteration 237 / 300: loss 0.604321\n",
      "iteration 237 / 300: loss 0.595476\n",
      "iteration 237 / 300: loss 0.597543\n",
      "iteration 237 / 300: loss 0.592740\n",
      "iteration 237 / 300: loss 0.589494\n",
      "iteration 237 / 300: loss 0.599264\n",
      "iteration 237 / 300: loss 0.611379\n",
      "iteration 237 / 300: loss 0.592463\n",
      "iteration 237 / 300: loss 0.599424\n",
      "iteration 237 / 300: loss 0.603100\n",
      "iteration 237 / 300: loss 0.602410\n",
      "iteration 237 / 300: loss 0.579811\n",
      "iteration 237 / 300: loss 0.601592\n",
      "iteration 238 / 300: loss 0.585528\n",
      "iteration 238 / 300: loss 0.588428\n",
      "iteration 238 / 300: loss 0.567516\n",
      "iteration 238 / 300: loss 0.592380\n",
      "iteration 238 / 300: loss 0.593618\n",
      "iteration 238 / 300: loss 0.595295\n",
      "iteration 238 / 300: loss 0.608784\n",
      "iteration 238 / 300: loss 0.592732\n",
      "iteration 238 / 300: loss 0.628060\n",
      "iteration 238 / 300: loss 0.580152\n",
      "iteration 238 / 300: loss 0.607923\n",
      "iteration 238 / 300: loss 0.587394\n",
      "iteration 238 / 300: loss 0.591686\n",
      "iteration 238 / 300: loss 0.571370\n",
      "iteration 238 / 300: loss 0.583025\n",
      "iteration 238 / 300: loss 0.608441\n",
      "iteration 238 / 300: loss 0.598359\n",
      "iteration 238 / 300: loss 0.583858\n",
      "iteration 238 / 300: loss 0.615253\n",
      "iteration 238 / 300: loss 0.591649\n",
      "iteration 238 / 300: loss 0.585499\n",
      "iteration 238 / 300: loss 0.591325\n",
      "iteration 238 / 300: loss 0.604341\n",
      "iteration 238 / 300: loss 0.595786\n",
      "iteration 238 / 300: loss 0.614949\n",
      "iteration 238 / 300: loss 0.608389\n",
      "iteration 238 / 300: loss 0.598222\n",
      "iteration 238 / 300: loss 0.588936\n",
      "iteration 238 / 300: loss 0.617757\n",
      "iteration 238 / 300: loss 0.594770\n",
      "iteration 238 / 300: loss 0.601684\n",
      "iteration 238 / 300: loss 0.631031\n",
      "iteration 238 / 300: loss 0.587513\n",
      "iteration 238 / 300: loss 0.606561\n",
      "iteration 238 / 300: loss 0.588034\n",
      "iteration 238 / 300: loss 0.600890\n",
      "iteration 238 / 300: loss 0.595958\n",
      "iteration 238 / 300: loss 0.589291\n",
      "iteration 238 / 300: loss 0.599526\n",
      "iteration 238 / 300: loss 0.604855\n",
      "iteration 238 / 300: loss 0.619414\n",
      "iteration 238 / 300: loss 0.588808\n",
      "iteration 238 / 300: loss 0.593645\n",
      "iteration 238 / 300: loss 0.585595\n",
      "iteration 238 / 300: loss 0.613212\n",
      "iteration 238 / 300: loss 0.587523\n",
      "iteration 238 / 300: loss 0.578328\n",
      "iteration 238 / 300: loss 0.567435\n",
      "iteration 238 / 300: loss 0.562235\n",
      "iteration 238 / 300: loss 0.594183\n",
      "iteration 238 / 300: loss 0.578821\n",
      "iteration 238 / 300: loss 0.586360\n",
      "iteration 238 / 300: loss 0.572890\n",
      "iteration 238 / 300: loss 0.596151\n",
      "iteration 238 / 300: loss 0.607951\n",
      "iteration 238 / 300: loss 0.610839\n",
      "iteration 238 / 300: loss 0.606265\n",
      "iteration 238 / 300: loss 0.583790\n",
      "iteration 238 / 300: loss 0.589627\n",
      "iteration 238 / 300: loss 0.595184\n",
      "iteration 238 / 300: loss 0.598955\n",
      "iteration 238 / 300: loss 0.596133\n",
      "iteration 238 / 300: loss 0.589769\n",
      "iteration 238 / 300: loss 0.591136\n",
      "iteration 238 / 300: loss 0.584854\n",
      "iteration 238 / 300: loss 0.599646\n",
      "iteration 238 / 300: loss 0.598902\n",
      "iteration 238 / 300: loss 0.614282\n",
      "iteration 238 / 300: loss 0.597796\n",
      "iteration 238 / 300: loss 0.599298\n",
      "iteration 238 / 300: loss 0.603317\n",
      "iteration 238 / 300: loss 0.592865\n",
      "iteration 238 / 300: loss 0.592391\n",
      "iteration 238 / 300: loss 0.589041\n",
      "iteration 238 / 300: loss 0.596446\n",
      "iteration 238 / 300: loss 0.605709\n",
      "iteration 238 / 300: loss 0.610562\n",
      "iteration 238 / 300: loss 0.587782\n",
      "iteration 238 / 300: loss 0.599351\n",
      "iteration 238 / 300: loss 0.602792\n",
      "iteration 238 / 300: loss 0.605028\n",
      "iteration 238 / 300: loss 0.603848\n",
      "iteration 238 / 300: loss 0.624144\n",
      "iteration 238 / 300: loss 0.587219\n",
      "iteration 238 / 300: loss 0.580754\n",
      "iteration 238 / 300: loss 0.625045\n",
      "iteration 238 / 300: loss 0.603310\n",
      "iteration 238 / 300: loss 0.604321\n",
      "iteration 238 / 300: loss 0.595476\n",
      "iteration 238 / 300: loss 0.597543\n",
      "iteration 238 / 300: loss 0.592740\n",
      "iteration 238 / 300: loss 0.589494\n",
      "iteration 238 / 300: loss 0.599264\n",
      "iteration 238 / 300: loss 0.611379\n",
      "iteration 238 / 300: loss 0.592463\n",
      "iteration 238 / 300: loss 0.599424\n",
      "iteration 238 / 300: loss 0.603100\n",
      "iteration 238 / 300: loss 0.602410\n",
      "iteration 238 / 300: loss 0.579811\n",
      "iteration 238 / 300: loss 0.601592\n",
      "iteration 239 / 300: loss 0.585528\n",
      "iteration 239 / 300: loss 0.588428\n",
      "iteration 239 / 300: loss 0.567516\n",
      "iteration 239 / 300: loss 0.592380\n",
      "iteration 239 / 300: loss 0.593618\n",
      "iteration 239 / 300: loss 0.595295\n",
      "iteration 239 / 300: loss 0.608784\n",
      "iteration 239 / 300: loss 0.592732\n",
      "iteration 239 / 300: loss 0.628060\n",
      "iteration 239 / 300: loss 0.580152\n",
      "iteration 239 / 300: loss 0.607923\n",
      "iteration 239 / 300: loss 0.587394\n",
      "iteration 239 / 300: loss 0.591686\n",
      "iteration 239 / 300: loss 0.571370\n",
      "iteration 239 / 300: loss 0.583025\n",
      "iteration 239 / 300: loss 0.608441\n",
      "iteration 239 / 300: loss 0.598359\n",
      "iteration 239 / 300: loss 0.583858\n",
      "iteration 239 / 300: loss 0.615253\n",
      "iteration 239 / 300: loss 0.591649\n",
      "iteration 239 / 300: loss 0.585499\n",
      "iteration 239 / 300: loss 0.591325\n",
      "iteration 239 / 300: loss 0.604341\n",
      "iteration 239 / 300: loss 0.595786\n",
      "iteration 239 / 300: loss 0.614949\n",
      "iteration 239 / 300: loss 0.608389\n",
      "iteration 239 / 300: loss 0.598222\n",
      "iteration 239 / 300: loss 0.588936\n",
      "iteration 239 / 300: loss 0.617757\n",
      "iteration 239 / 300: loss 0.594770\n",
      "iteration 239 / 300: loss 0.601684\n",
      "iteration 239 / 300: loss 0.631031\n",
      "iteration 239 / 300: loss 0.587513\n",
      "iteration 239 / 300: loss 0.606561\n",
      "iteration 239 / 300: loss 0.588034\n",
      "iteration 239 / 300: loss 0.600890\n",
      "iteration 239 / 300: loss 0.595958\n",
      "iteration 239 / 300: loss 0.589291\n",
      "iteration 239 / 300: loss 0.599526\n",
      "iteration 239 / 300: loss 0.604855\n",
      "iteration 239 / 300: loss 0.619414\n",
      "iteration 239 / 300: loss 0.588808\n",
      "iteration 239 / 300: loss 0.593645\n",
      "iteration 239 / 300: loss 0.585595\n",
      "iteration 239 / 300: loss 0.613212\n",
      "iteration 239 / 300: loss 0.587523\n",
      "iteration 239 / 300: loss 0.578328\n",
      "iteration 239 / 300: loss 0.567435\n",
      "iteration 239 / 300: loss 0.562235\n",
      "iteration 239 / 300: loss 0.594183\n",
      "iteration 239 / 300: loss 0.578821\n",
      "iteration 239 / 300: loss 0.586360\n",
      "iteration 239 / 300: loss 0.572890\n",
      "iteration 239 / 300: loss 0.596151\n",
      "iteration 239 / 300: loss 0.607951\n",
      "iteration 239 / 300: loss 0.610839\n",
      "iteration 239 / 300: loss 0.606265\n",
      "iteration 239 / 300: loss 0.583790\n",
      "iteration 239 / 300: loss 0.589627\n",
      "iteration 239 / 300: loss 0.595184\n",
      "iteration 239 / 300: loss 0.598955\n",
      "iteration 239 / 300: loss 0.596133\n",
      "iteration 239 / 300: loss 0.589769\n",
      "iteration 239 / 300: loss 0.591136\n",
      "iteration 239 / 300: loss 0.584854\n",
      "iteration 239 / 300: loss 0.599646\n",
      "iteration 239 / 300: loss 0.598902\n",
      "iteration 239 / 300: loss 0.614282\n",
      "iteration 239 / 300: loss 0.597796\n",
      "iteration 239 / 300: loss 0.599298\n",
      "iteration 239 / 300: loss 0.603317\n",
      "iteration 239 / 300: loss 0.592865\n",
      "iteration 239 / 300: loss 0.592391\n",
      "iteration 239 / 300: loss 0.589041\n",
      "iteration 239 / 300: loss 0.596446\n",
      "iteration 239 / 300: loss 0.605709\n",
      "iteration 239 / 300: loss 0.610562\n",
      "iteration 239 / 300: loss 0.587782\n",
      "iteration 239 / 300: loss 0.599351\n",
      "iteration 239 / 300: loss 0.602792\n",
      "iteration 239 / 300: loss 0.605028\n",
      "iteration 239 / 300: loss 0.603848\n",
      "iteration 239 / 300: loss 0.624144\n",
      "iteration 239 / 300: loss 0.587219\n",
      "iteration 239 / 300: loss 0.580754\n",
      "iteration 239 / 300: loss 0.625045\n",
      "iteration 239 / 300: loss 0.603310\n",
      "iteration 239 / 300: loss 0.604321\n",
      "iteration 239 / 300: loss 0.595476\n",
      "iteration 239 / 300: loss 0.597543\n",
      "iteration 239 / 300: loss 0.592740\n",
      "iteration 239 / 300: loss 0.589494\n",
      "iteration 239 / 300: loss 0.599264\n",
      "iteration 239 / 300: loss 0.611379\n",
      "iteration 239 / 300: loss 0.592463\n",
      "iteration 239 / 300: loss 0.599424\n",
      "iteration 239 / 300: loss 0.603100\n",
      "iteration 239 / 300: loss 0.602410\n",
      "iteration 239 / 300: loss 0.579811\n",
      "iteration 239 / 300: loss 0.601592\n",
      "iteration 240 / 300: loss 0.585528\n",
      "iteration 240 / 300: loss 0.588428\n",
      "iteration 240 / 300: loss 0.567516\n",
      "iteration 240 / 300: loss 0.592380\n",
      "iteration 240 / 300: loss 0.593618\n",
      "iteration 240 / 300: loss 0.595295\n",
      "iteration 240 / 300: loss 0.608784\n",
      "iteration 240 / 300: loss 0.592732\n",
      "iteration 240 / 300: loss 0.628060\n",
      "iteration 240 / 300: loss 0.580152\n",
      "iteration 240 / 300: loss 0.607923\n",
      "iteration 240 / 300: loss 0.587394\n",
      "iteration 240 / 300: loss 0.591686\n",
      "iteration 240 / 300: loss 0.571370\n",
      "iteration 240 / 300: loss 0.583025\n",
      "iteration 240 / 300: loss 0.608441\n",
      "iteration 240 / 300: loss 0.598359\n",
      "iteration 240 / 300: loss 0.583858\n",
      "iteration 240 / 300: loss 0.615253\n",
      "iteration 240 / 300: loss 0.591649\n",
      "iteration 240 / 300: loss 0.585499\n",
      "iteration 240 / 300: loss 0.591325\n",
      "iteration 240 / 300: loss 0.604341\n",
      "iteration 240 / 300: loss 0.595786\n",
      "iteration 240 / 300: loss 0.614949\n",
      "iteration 240 / 300: loss 0.608389\n",
      "iteration 240 / 300: loss 0.598222\n",
      "iteration 240 / 300: loss 0.588936\n",
      "iteration 240 / 300: loss 0.617757\n",
      "iteration 240 / 300: loss 0.594770\n",
      "iteration 240 / 300: loss 0.601684\n",
      "iteration 240 / 300: loss 0.631031\n",
      "iteration 240 / 300: loss 0.587513\n",
      "iteration 240 / 300: loss 0.606561\n",
      "iteration 240 / 300: loss 0.588034\n",
      "iteration 240 / 300: loss 0.600890\n",
      "iteration 240 / 300: loss 0.595958\n",
      "iteration 240 / 300: loss 0.589291\n",
      "iteration 240 / 300: loss 0.599526\n",
      "iteration 240 / 300: loss 0.604855\n",
      "iteration 240 / 300: loss 0.619414\n",
      "iteration 240 / 300: loss 0.588808\n",
      "iteration 240 / 300: loss 0.593645\n",
      "iteration 240 / 300: loss 0.585595\n",
      "iteration 240 / 300: loss 0.613212\n",
      "iteration 240 / 300: loss 0.587523\n",
      "iteration 240 / 300: loss 0.578328\n",
      "iteration 240 / 300: loss 0.567435\n",
      "iteration 240 / 300: loss 0.562235\n",
      "iteration 240 / 300: loss 0.594183\n",
      "iteration 240 / 300: loss 0.578821\n",
      "iteration 240 / 300: loss 0.586360\n",
      "iteration 240 / 300: loss 0.572890\n",
      "iteration 240 / 300: loss 0.596151\n",
      "iteration 240 / 300: loss 0.607951\n",
      "iteration 240 / 300: loss 0.610839\n",
      "iteration 240 / 300: loss 0.606265\n",
      "iteration 240 / 300: loss 0.583790\n",
      "iteration 240 / 300: loss 0.589627\n",
      "iteration 240 / 300: loss 0.595184\n",
      "iteration 240 / 300: loss 0.598955\n",
      "iteration 240 / 300: loss 0.596133\n",
      "iteration 240 / 300: loss 0.589769\n",
      "iteration 240 / 300: loss 0.591136\n",
      "iteration 240 / 300: loss 0.584854\n",
      "iteration 240 / 300: loss 0.599646\n",
      "iteration 240 / 300: loss 0.598902\n",
      "iteration 240 / 300: loss 0.614282\n",
      "iteration 240 / 300: loss 0.597796\n",
      "iteration 240 / 300: loss 0.599298\n",
      "iteration 240 / 300: loss 0.603317\n",
      "iteration 240 / 300: loss 0.592865\n",
      "iteration 240 / 300: loss 0.592391\n",
      "iteration 240 / 300: loss 0.589041\n",
      "iteration 240 / 300: loss 0.596446\n",
      "iteration 240 / 300: loss 0.605709\n",
      "iteration 240 / 300: loss 0.610562\n",
      "iteration 240 / 300: loss 0.587782\n",
      "iteration 240 / 300: loss 0.599351\n",
      "iteration 240 / 300: loss 0.602792\n",
      "iteration 240 / 300: loss 0.605028\n",
      "iteration 240 / 300: loss 0.603848\n",
      "iteration 240 / 300: loss 0.624144\n",
      "iteration 240 / 300: loss 0.587219\n",
      "iteration 240 / 300: loss 0.580754\n",
      "iteration 240 / 300: loss 0.625045\n",
      "iteration 240 / 300: loss 0.603310\n",
      "iteration 240 / 300: loss 0.604321\n",
      "iteration 240 / 300: loss 0.595476\n",
      "iteration 240 / 300: loss 0.597543\n",
      "iteration 240 / 300: loss 0.592740\n",
      "iteration 240 / 300: loss 0.589494\n",
      "iteration 240 / 300: loss 0.599264\n",
      "iteration 240 / 300: loss 0.611379\n",
      "iteration 240 / 300: loss 0.592463\n",
      "iteration 240 / 300: loss 0.599424\n",
      "iteration 240 / 300: loss 0.603100\n",
      "iteration 240 / 300: loss 0.602410\n",
      "iteration 240 / 300: loss 0.579811\n",
      "iteration 240 / 300: loss 0.601592\n",
      "iteration 241 / 300: loss 0.585528\n",
      "iteration 241 / 300: loss 0.588428\n",
      "iteration 241 / 300: loss 0.567516\n",
      "iteration 241 / 300: loss 0.592380\n",
      "iteration 241 / 300: loss 0.593618\n",
      "iteration 241 / 300: loss 0.595295\n",
      "iteration 241 / 300: loss 0.608784\n",
      "iteration 241 / 300: loss 0.592732\n",
      "iteration 241 / 300: loss 0.628060\n",
      "iteration 241 / 300: loss 0.580152\n",
      "iteration 241 / 300: loss 0.607923\n",
      "iteration 241 / 300: loss 0.587394\n",
      "iteration 241 / 300: loss 0.591686\n",
      "iteration 241 / 300: loss 0.571370\n",
      "iteration 241 / 300: loss 0.583025\n",
      "iteration 241 / 300: loss 0.608441\n",
      "iteration 241 / 300: loss 0.598359\n",
      "iteration 241 / 300: loss 0.583858\n",
      "iteration 241 / 300: loss 0.615253\n",
      "iteration 241 / 300: loss 0.591649\n",
      "iteration 241 / 300: loss 0.585499\n",
      "iteration 241 / 300: loss 0.591325\n",
      "iteration 241 / 300: loss 0.604341\n",
      "iteration 241 / 300: loss 0.595786\n",
      "iteration 241 / 300: loss 0.614949\n",
      "iteration 241 / 300: loss 0.608389\n",
      "iteration 241 / 300: loss 0.598222\n",
      "iteration 241 / 300: loss 0.588936\n",
      "iteration 241 / 300: loss 0.617757\n",
      "iteration 241 / 300: loss 0.594770\n",
      "iteration 241 / 300: loss 0.601684\n",
      "iteration 241 / 300: loss 0.631031\n",
      "iteration 241 / 300: loss 0.587513\n",
      "iteration 241 / 300: loss 0.606561\n",
      "iteration 241 / 300: loss 0.588034\n",
      "iteration 241 / 300: loss 0.600890\n",
      "iteration 241 / 300: loss 0.595958\n",
      "iteration 241 / 300: loss 0.589291\n",
      "iteration 241 / 300: loss 0.599526\n",
      "iteration 241 / 300: loss 0.604855\n",
      "iteration 241 / 300: loss 0.619414\n",
      "iteration 241 / 300: loss 0.588808\n",
      "iteration 241 / 300: loss 0.593645\n",
      "iteration 241 / 300: loss 0.585595\n",
      "iteration 241 / 300: loss 0.613212\n",
      "iteration 241 / 300: loss 0.587523\n",
      "iteration 241 / 300: loss 0.578328\n",
      "iteration 241 / 300: loss 0.567435\n",
      "iteration 241 / 300: loss 0.562235\n",
      "iteration 241 / 300: loss 0.594183\n",
      "iteration 241 / 300: loss 0.578821\n",
      "iteration 241 / 300: loss 0.586360\n",
      "iteration 241 / 300: loss 0.572890\n",
      "iteration 241 / 300: loss 0.596151\n",
      "iteration 241 / 300: loss 0.607951\n",
      "iteration 241 / 300: loss 0.610839\n",
      "iteration 241 / 300: loss 0.606265\n",
      "iteration 241 / 300: loss 0.583790\n",
      "iteration 241 / 300: loss 0.589627\n",
      "iteration 241 / 300: loss 0.595184\n",
      "iteration 241 / 300: loss 0.598955\n",
      "iteration 241 / 300: loss 0.596133\n",
      "iteration 241 / 300: loss 0.589769\n",
      "iteration 241 / 300: loss 0.591136\n",
      "iteration 241 / 300: loss 0.584854\n",
      "iteration 241 / 300: loss 0.599646\n",
      "iteration 241 / 300: loss 0.598902\n",
      "iteration 241 / 300: loss 0.614282\n",
      "iteration 241 / 300: loss 0.597796\n",
      "iteration 241 / 300: loss 0.599298\n",
      "iteration 241 / 300: loss 0.603317\n",
      "iteration 241 / 300: loss 0.592865\n",
      "iteration 241 / 300: loss 0.592391\n",
      "iteration 241 / 300: loss 0.589041\n",
      "iteration 241 / 300: loss 0.596446\n",
      "iteration 241 / 300: loss 0.605709\n",
      "iteration 241 / 300: loss 0.610562\n",
      "iteration 241 / 300: loss 0.587782\n",
      "iteration 241 / 300: loss 0.599351\n",
      "iteration 241 / 300: loss 0.602792\n",
      "iteration 241 / 300: loss 0.605028\n",
      "iteration 241 / 300: loss 0.603848\n",
      "iteration 241 / 300: loss 0.624144\n",
      "iteration 241 / 300: loss 0.587219\n",
      "iteration 241 / 300: loss 0.580754\n",
      "iteration 241 / 300: loss 0.625045\n",
      "iteration 241 / 300: loss 0.603310\n",
      "iteration 241 / 300: loss 0.604321\n",
      "iteration 241 / 300: loss 0.595476\n",
      "iteration 241 / 300: loss 0.597543\n",
      "iteration 241 / 300: loss 0.592740\n",
      "iteration 241 / 300: loss 0.589494\n",
      "iteration 241 / 300: loss 0.599264\n",
      "iteration 241 / 300: loss 0.611379\n",
      "iteration 241 / 300: loss 0.592463\n",
      "iteration 241 / 300: loss 0.599424\n",
      "iteration 241 / 300: loss 0.603100\n",
      "iteration 241 / 300: loss 0.602410\n",
      "iteration 241 / 300: loss 0.579811\n",
      "iteration 241 / 300: loss 0.601592\n",
      "iteration 242 / 300: loss 0.585528\n",
      "iteration 242 / 300: loss 0.588428\n",
      "iteration 242 / 300: loss 0.567516\n",
      "iteration 242 / 300: loss 0.592380\n",
      "iteration 242 / 300: loss 0.593618\n",
      "iteration 242 / 300: loss 0.595295\n",
      "iteration 242 / 300: loss 0.608784\n",
      "iteration 242 / 300: loss 0.592732\n",
      "iteration 242 / 300: loss 0.628060\n",
      "iteration 242 / 300: loss 0.580152\n",
      "iteration 242 / 300: loss 0.607923\n",
      "iteration 242 / 300: loss 0.587394\n",
      "iteration 242 / 300: loss 0.591686\n",
      "iteration 242 / 300: loss 0.571370\n",
      "iteration 242 / 300: loss 0.583025\n",
      "iteration 242 / 300: loss 0.608441\n",
      "iteration 242 / 300: loss 0.598359\n",
      "iteration 242 / 300: loss 0.583858\n",
      "iteration 242 / 300: loss 0.615253\n",
      "iteration 242 / 300: loss 0.591649\n",
      "iteration 242 / 300: loss 0.585499\n",
      "iteration 242 / 300: loss 0.591325\n",
      "iteration 242 / 300: loss 0.604341\n",
      "iteration 242 / 300: loss 0.595786\n",
      "iteration 242 / 300: loss 0.614949\n",
      "iteration 242 / 300: loss 0.608389\n",
      "iteration 242 / 300: loss 0.598222\n",
      "iteration 242 / 300: loss 0.588936\n",
      "iteration 242 / 300: loss 0.617757\n",
      "iteration 242 / 300: loss 0.594770\n",
      "iteration 242 / 300: loss 0.601684\n",
      "iteration 242 / 300: loss 0.631031\n",
      "iteration 242 / 300: loss 0.587513\n",
      "iteration 242 / 300: loss 0.606561\n",
      "iteration 242 / 300: loss 0.588034\n",
      "iteration 242 / 300: loss 0.600890\n",
      "iteration 242 / 300: loss 0.595958\n",
      "iteration 242 / 300: loss 0.589291\n",
      "iteration 242 / 300: loss 0.599526\n",
      "iteration 242 / 300: loss 0.604855\n",
      "iteration 242 / 300: loss 0.619414\n",
      "iteration 242 / 300: loss 0.588808\n",
      "iteration 242 / 300: loss 0.593645\n",
      "iteration 242 / 300: loss 0.585595\n",
      "iteration 242 / 300: loss 0.613212\n",
      "iteration 242 / 300: loss 0.587523\n",
      "iteration 242 / 300: loss 0.578328\n",
      "iteration 242 / 300: loss 0.567435\n",
      "iteration 242 / 300: loss 0.562235\n",
      "iteration 242 / 300: loss 0.594183\n",
      "iteration 242 / 300: loss 0.578821\n",
      "iteration 242 / 300: loss 0.586360\n",
      "iteration 242 / 300: loss 0.572890\n",
      "iteration 242 / 300: loss 0.596151\n",
      "iteration 242 / 300: loss 0.607951\n",
      "iteration 242 / 300: loss 0.610839\n",
      "iteration 242 / 300: loss 0.606265\n",
      "iteration 242 / 300: loss 0.583790\n",
      "iteration 242 / 300: loss 0.589627\n",
      "iteration 242 / 300: loss 0.595184\n",
      "iteration 242 / 300: loss 0.598955\n",
      "iteration 242 / 300: loss 0.596133\n",
      "iteration 242 / 300: loss 0.589769\n",
      "iteration 242 / 300: loss 0.591136\n",
      "iteration 242 / 300: loss 0.584854\n",
      "iteration 242 / 300: loss 0.599646\n",
      "iteration 242 / 300: loss 0.598902\n",
      "iteration 242 / 300: loss 0.614282\n",
      "iteration 242 / 300: loss 0.597796\n",
      "iteration 242 / 300: loss 0.599298\n",
      "iteration 242 / 300: loss 0.603317\n",
      "iteration 242 / 300: loss 0.592865\n",
      "iteration 242 / 300: loss 0.592391\n",
      "iteration 242 / 300: loss 0.589041\n",
      "iteration 242 / 300: loss 0.596446\n",
      "iteration 242 / 300: loss 0.605709\n",
      "iteration 242 / 300: loss 0.610562\n",
      "iteration 242 / 300: loss 0.587782\n",
      "iteration 242 / 300: loss 0.599351\n",
      "iteration 242 / 300: loss 0.602792\n",
      "iteration 242 / 300: loss 0.605028\n",
      "iteration 242 / 300: loss 0.603848\n",
      "iteration 242 / 300: loss 0.624144\n",
      "iteration 242 / 300: loss 0.587219\n",
      "iteration 242 / 300: loss 0.580754\n",
      "iteration 242 / 300: loss 0.625045\n",
      "iteration 242 / 300: loss 0.603310\n",
      "iteration 242 / 300: loss 0.604321\n",
      "iteration 242 / 300: loss 0.595476\n",
      "iteration 242 / 300: loss 0.597543\n",
      "iteration 242 / 300: loss 0.592740\n",
      "iteration 242 / 300: loss 0.589494\n",
      "iteration 242 / 300: loss 0.599264\n",
      "iteration 242 / 300: loss 0.611379\n",
      "iteration 242 / 300: loss 0.592463\n",
      "iteration 242 / 300: loss 0.599424\n",
      "iteration 242 / 300: loss 0.603100\n",
      "iteration 242 / 300: loss 0.602410\n",
      "iteration 242 / 300: loss 0.579811\n",
      "iteration 242 / 300: loss 0.601592\n",
      "iteration 243 / 300: loss 0.585528\n",
      "iteration 243 / 300: loss 0.588428\n",
      "iteration 243 / 300: loss 0.567516\n",
      "iteration 243 / 300: loss 0.592380\n",
      "iteration 243 / 300: loss 0.593618\n",
      "iteration 243 / 300: loss 0.595295\n",
      "iteration 243 / 300: loss 0.608784\n",
      "iteration 243 / 300: loss 0.592732\n",
      "iteration 243 / 300: loss 0.628060\n",
      "iteration 243 / 300: loss 0.580152\n",
      "iteration 243 / 300: loss 0.607923\n",
      "iteration 243 / 300: loss 0.587394\n",
      "iteration 243 / 300: loss 0.591686\n",
      "iteration 243 / 300: loss 0.571370\n",
      "iteration 243 / 300: loss 0.583025\n",
      "iteration 243 / 300: loss 0.608441\n",
      "iteration 243 / 300: loss 0.598359\n",
      "iteration 243 / 300: loss 0.583858\n",
      "iteration 243 / 300: loss 0.615253\n",
      "iteration 243 / 300: loss 0.591649\n",
      "iteration 243 / 300: loss 0.585499\n",
      "iteration 243 / 300: loss 0.591325\n",
      "iteration 243 / 300: loss 0.604341\n",
      "iteration 243 / 300: loss 0.595786\n",
      "iteration 243 / 300: loss 0.614949\n",
      "iteration 243 / 300: loss 0.608389\n",
      "iteration 243 / 300: loss 0.598222\n",
      "iteration 243 / 300: loss 0.588936\n",
      "iteration 243 / 300: loss 0.617757\n",
      "iteration 243 / 300: loss 0.594770\n",
      "iteration 243 / 300: loss 0.601684\n",
      "iteration 243 / 300: loss 0.631031\n",
      "iteration 243 / 300: loss 0.587513\n",
      "iteration 243 / 300: loss 0.606561\n",
      "iteration 243 / 300: loss 0.588034\n",
      "iteration 243 / 300: loss 0.600890\n",
      "iteration 243 / 300: loss 0.595958\n",
      "iteration 243 / 300: loss 0.589291\n",
      "iteration 243 / 300: loss 0.599526\n",
      "iteration 243 / 300: loss 0.604855\n",
      "iteration 243 / 300: loss 0.619414\n",
      "iteration 243 / 300: loss 0.588808\n",
      "iteration 243 / 300: loss 0.593645\n",
      "iteration 243 / 300: loss 0.585595\n",
      "iteration 243 / 300: loss 0.613212\n",
      "iteration 243 / 300: loss 0.587523\n",
      "iteration 243 / 300: loss 0.578328\n",
      "iteration 243 / 300: loss 0.567435\n",
      "iteration 243 / 300: loss 0.562235\n",
      "iteration 243 / 300: loss 0.594183\n",
      "iteration 243 / 300: loss 0.578821\n",
      "iteration 243 / 300: loss 0.586360\n",
      "iteration 243 / 300: loss 0.572890\n",
      "iteration 243 / 300: loss 0.596151\n",
      "iteration 243 / 300: loss 0.607951\n",
      "iteration 243 / 300: loss 0.610839\n",
      "iteration 243 / 300: loss 0.606265\n",
      "iteration 243 / 300: loss 0.583790\n",
      "iteration 243 / 300: loss 0.589627\n",
      "iteration 243 / 300: loss 0.595184\n",
      "iteration 243 / 300: loss 0.598955\n",
      "iteration 243 / 300: loss 0.596133\n",
      "iteration 243 / 300: loss 0.589769\n",
      "iteration 243 / 300: loss 0.591136\n",
      "iteration 243 / 300: loss 0.584854\n",
      "iteration 243 / 300: loss 0.599646\n",
      "iteration 243 / 300: loss 0.598902\n",
      "iteration 243 / 300: loss 0.614282\n",
      "iteration 243 / 300: loss 0.597796\n",
      "iteration 243 / 300: loss 0.599298\n",
      "iteration 243 / 300: loss 0.603317\n",
      "iteration 243 / 300: loss 0.592865\n",
      "iteration 243 / 300: loss 0.592391\n",
      "iteration 243 / 300: loss 0.589041\n",
      "iteration 243 / 300: loss 0.596446\n",
      "iteration 243 / 300: loss 0.605709\n",
      "iteration 243 / 300: loss 0.610562\n",
      "iteration 243 / 300: loss 0.587782\n",
      "iteration 243 / 300: loss 0.599351\n",
      "iteration 243 / 300: loss 0.602792\n",
      "iteration 243 / 300: loss 0.605028\n",
      "iteration 243 / 300: loss 0.603848\n",
      "iteration 243 / 300: loss 0.624144\n",
      "iteration 243 / 300: loss 0.587219\n",
      "iteration 243 / 300: loss 0.580754\n",
      "iteration 243 / 300: loss 0.625045\n",
      "iteration 243 / 300: loss 0.603310\n",
      "iteration 243 / 300: loss 0.604321\n",
      "iteration 243 / 300: loss 0.595476\n",
      "iteration 243 / 300: loss 0.597543\n",
      "iteration 243 / 300: loss 0.592740\n",
      "iteration 243 / 300: loss 0.589494\n",
      "iteration 243 / 300: loss 0.599264\n",
      "iteration 243 / 300: loss 0.611379\n",
      "iteration 243 / 300: loss 0.592463\n",
      "iteration 243 / 300: loss 0.599424\n",
      "iteration 243 / 300: loss 0.603100\n",
      "iteration 243 / 300: loss 0.602410\n",
      "iteration 243 / 300: loss 0.579811\n",
      "iteration 243 / 300: loss 0.601592\n",
      "iteration 244 / 300: loss 0.585528\n",
      "iteration 244 / 300: loss 0.588428\n",
      "iteration 244 / 300: loss 0.567516\n",
      "iteration 244 / 300: loss 0.592380\n",
      "iteration 244 / 300: loss 0.593618\n",
      "iteration 244 / 300: loss 0.595295\n",
      "iteration 244 / 300: loss 0.608784\n",
      "iteration 244 / 300: loss 0.592732\n",
      "iteration 244 / 300: loss 0.628060\n",
      "iteration 244 / 300: loss 0.580152\n",
      "iteration 244 / 300: loss 0.607923\n",
      "iteration 244 / 300: loss 0.587394\n",
      "iteration 244 / 300: loss 0.591686\n",
      "iteration 244 / 300: loss 0.571370\n",
      "iteration 244 / 300: loss 0.583025\n",
      "iteration 244 / 300: loss 0.608441\n",
      "iteration 244 / 300: loss 0.598359\n",
      "iteration 244 / 300: loss 0.583858\n",
      "iteration 244 / 300: loss 0.615253\n",
      "iteration 244 / 300: loss 0.591649\n",
      "iteration 244 / 300: loss 0.585499\n",
      "iteration 244 / 300: loss 0.591325\n",
      "iteration 244 / 300: loss 0.604341\n",
      "iteration 244 / 300: loss 0.595786\n",
      "iteration 244 / 300: loss 0.614949\n",
      "iteration 244 / 300: loss 0.608389\n",
      "iteration 244 / 300: loss 0.598222\n",
      "iteration 244 / 300: loss 0.588936\n",
      "iteration 244 / 300: loss 0.617757\n",
      "iteration 244 / 300: loss 0.594770\n",
      "iteration 244 / 300: loss 0.601684\n",
      "iteration 244 / 300: loss 0.631031\n",
      "iteration 244 / 300: loss 0.587513\n",
      "iteration 244 / 300: loss 0.606561\n",
      "iteration 244 / 300: loss 0.588034\n",
      "iteration 244 / 300: loss 0.600890\n",
      "iteration 244 / 300: loss 0.595958\n",
      "iteration 244 / 300: loss 0.589291\n",
      "iteration 244 / 300: loss 0.599526\n",
      "iteration 244 / 300: loss 0.604855\n",
      "iteration 244 / 300: loss 0.619414\n",
      "iteration 244 / 300: loss 0.588808\n",
      "iteration 244 / 300: loss 0.593645\n",
      "iteration 244 / 300: loss 0.585595\n",
      "iteration 244 / 300: loss 0.613212\n",
      "iteration 244 / 300: loss 0.587523\n",
      "iteration 244 / 300: loss 0.578328\n",
      "iteration 244 / 300: loss 0.567435\n",
      "iteration 244 / 300: loss 0.562235\n",
      "iteration 244 / 300: loss 0.594183\n",
      "iteration 244 / 300: loss 0.578821\n",
      "iteration 244 / 300: loss 0.586360\n",
      "iteration 244 / 300: loss 0.572890\n",
      "iteration 244 / 300: loss 0.596151\n",
      "iteration 244 / 300: loss 0.607951\n",
      "iteration 244 / 300: loss 0.610839\n",
      "iteration 244 / 300: loss 0.606265\n",
      "iteration 244 / 300: loss 0.583790\n",
      "iteration 244 / 300: loss 0.589627\n",
      "iteration 244 / 300: loss 0.595184\n",
      "iteration 244 / 300: loss 0.598955\n",
      "iteration 244 / 300: loss 0.596133\n",
      "iteration 244 / 300: loss 0.589769\n",
      "iteration 244 / 300: loss 0.591136\n",
      "iteration 244 / 300: loss 0.584854\n",
      "iteration 244 / 300: loss 0.599646\n",
      "iteration 244 / 300: loss 0.598902\n",
      "iteration 244 / 300: loss 0.614282\n",
      "iteration 244 / 300: loss 0.597796\n",
      "iteration 244 / 300: loss 0.599298\n",
      "iteration 244 / 300: loss 0.603317\n",
      "iteration 244 / 300: loss 0.592865\n",
      "iteration 244 / 300: loss 0.592391\n",
      "iteration 244 / 300: loss 0.589041\n",
      "iteration 244 / 300: loss 0.596446\n",
      "iteration 244 / 300: loss 0.605709\n",
      "iteration 244 / 300: loss 0.610562\n",
      "iteration 244 / 300: loss 0.587782\n",
      "iteration 244 / 300: loss 0.599351\n",
      "iteration 244 / 300: loss 0.602792\n",
      "iteration 244 / 300: loss 0.605028\n",
      "iteration 244 / 300: loss 0.603848\n",
      "iteration 244 / 300: loss 0.624144\n",
      "iteration 244 / 300: loss 0.587219\n",
      "iteration 244 / 300: loss 0.580754\n",
      "iteration 244 / 300: loss 0.625045\n",
      "iteration 244 / 300: loss 0.603310\n",
      "iteration 244 / 300: loss 0.604321\n",
      "iteration 244 / 300: loss 0.595476\n",
      "iteration 244 / 300: loss 0.597543\n",
      "iteration 244 / 300: loss 0.592740\n",
      "iteration 244 / 300: loss 0.589494\n",
      "iteration 244 / 300: loss 0.599264\n",
      "iteration 244 / 300: loss 0.611379\n",
      "iteration 244 / 300: loss 0.592463\n",
      "iteration 244 / 300: loss 0.599424\n",
      "iteration 244 / 300: loss 0.603100\n",
      "iteration 244 / 300: loss 0.602410\n",
      "iteration 244 / 300: loss 0.579811\n",
      "iteration 244 / 300: loss 0.601592\n",
      "iteration 245 / 300: loss 0.585528\n",
      "iteration 245 / 300: loss 0.588428\n",
      "iteration 245 / 300: loss 0.567516\n",
      "iteration 245 / 300: loss 0.592380\n",
      "iteration 245 / 300: loss 0.593618\n",
      "iteration 245 / 300: loss 0.595295\n",
      "iteration 245 / 300: loss 0.608784\n",
      "iteration 245 / 300: loss 0.592732\n",
      "iteration 245 / 300: loss 0.628060\n",
      "iteration 245 / 300: loss 0.580152\n",
      "iteration 245 / 300: loss 0.607923\n",
      "iteration 245 / 300: loss 0.587394\n",
      "iteration 245 / 300: loss 0.591686\n",
      "iteration 245 / 300: loss 0.571370\n",
      "iteration 245 / 300: loss 0.583025\n",
      "iteration 245 / 300: loss 0.608441\n",
      "iteration 245 / 300: loss 0.598359\n",
      "iteration 245 / 300: loss 0.583858\n",
      "iteration 245 / 300: loss 0.615253\n",
      "iteration 245 / 300: loss 0.591649\n",
      "iteration 245 / 300: loss 0.585499\n",
      "iteration 245 / 300: loss 0.591325\n",
      "iteration 245 / 300: loss 0.604341\n",
      "iteration 245 / 300: loss 0.595786\n",
      "iteration 245 / 300: loss 0.614949\n",
      "iteration 245 / 300: loss 0.608389\n",
      "iteration 245 / 300: loss 0.598222\n",
      "iteration 245 / 300: loss 0.588936\n",
      "iteration 245 / 300: loss 0.617757\n",
      "iteration 245 / 300: loss 0.594770\n",
      "iteration 245 / 300: loss 0.601684\n",
      "iteration 245 / 300: loss 0.631031\n",
      "iteration 245 / 300: loss 0.587513\n",
      "iteration 245 / 300: loss 0.606561\n",
      "iteration 245 / 300: loss 0.588034\n",
      "iteration 245 / 300: loss 0.600890\n",
      "iteration 245 / 300: loss 0.595958\n",
      "iteration 245 / 300: loss 0.589291\n",
      "iteration 245 / 300: loss 0.599526\n",
      "iteration 245 / 300: loss 0.604855\n",
      "iteration 245 / 300: loss 0.619414\n",
      "iteration 245 / 300: loss 0.588808\n",
      "iteration 245 / 300: loss 0.593645\n",
      "iteration 245 / 300: loss 0.585595\n",
      "iteration 245 / 300: loss 0.613212\n",
      "iteration 245 / 300: loss 0.587523\n",
      "iteration 245 / 300: loss 0.578328\n",
      "iteration 245 / 300: loss 0.567435\n",
      "iteration 245 / 300: loss 0.562235\n",
      "iteration 245 / 300: loss 0.594183\n",
      "iteration 245 / 300: loss 0.578821\n",
      "iteration 245 / 300: loss 0.586360\n",
      "iteration 245 / 300: loss 0.572890\n",
      "iteration 245 / 300: loss 0.596151\n",
      "iteration 245 / 300: loss 0.607951\n",
      "iteration 245 / 300: loss 0.610839\n",
      "iteration 245 / 300: loss 0.606265\n",
      "iteration 245 / 300: loss 0.583790\n",
      "iteration 245 / 300: loss 0.589627\n",
      "iteration 245 / 300: loss 0.595184\n",
      "iteration 245 / 300: loss 0.598955\n",
      "iteration 245 / 300: loss 0.596133\n",
      "iteration 245 / 300: loss 0.589769\n",
      "iteration 245 / 300: loss 0.591136\n",
      "iteration 245 / 300: loss 0.584854\n",
      "iteration 245 / 300: loss 0.599646\n",
      "iteration 245 / 300: loss 0.598902\n",
      "iteration 245 / 300: loss 0.614282\n",
      "iteration 245 / 300: loss 0.597796\n",
      "iteration 245 / 300: loss 0.599298\n",
      "iteration 245 / 300: loss 0.603317\n",
      "iteration 245 / 300: loss 0.592865\n",
      "iteration 245 / 300: loss 0.592391\n",
      "iteration 245 / 300: loss 0.589041\n",
      "iteration 245 / 300: loss 0.596446\n",
      "iteration 245 / 300: loss 0.605709\n",
      "iteration 245 / 300: loss 0.610562\n",
      "iteration 245 / 300: loss 0.587782\n",
      "iteration 245 / 300: loss 0.599351\n",
      "iteration 245 / 300: loss 0.602792\n",
      "iteration 245 / 300: loss 0.605028\n",
      "iteration 245 / 300: loss 0.603848\n",
      "iteration 245 / 300: loss 0.624144\n",
      "iteration 245 / 300: loss 0.587219\n",
      "iteration 245 / 300: loss 0.580754\n",
      "iteration 245 / 300: loss 0.625045\n",
      "iteration 245 / 300: loss 0.603310\n",
      "iteration 245 / 300: loss 0.604321\n",
      "iteration 245 / 300: loss 0.595476\n",
      "iteration 245 / 300: loss 0.597543\n",
      "iteration 245 / 300: loss 0.592740\n",
      "iteration 245 / 300: loss 0.589494\n",
      "iteration 245 / 300: loss 0.599264\n",
      "iteration 245 / 300: loss 0.611379\n",
      "iteration 245 / 300: loss 0.592463\n",
      "iteration 245 / 300: loss 0.599424\n",
      "iteration 245 / 300: loss 0.603100\n",
      "iteration 245 / 300: loss 0.602410\n",
      "iteration 245 / 300: loss 0.579811\n",
      "iteration 245 / 300: loss 0.601592\n",
      "iteration 246 / 300: loss 0.585528\n",
      "iteration 246 / 300: loss 0.588428\n",
      "iteration 246 / 300: loss 0.567516\n",
      "iteration 246 / 300: loss 0.592380\n",
      "iteration 246 / 300: loss 0.593618\n",
      "iteration 246 / 300: loss 0.595295\n",
      "iteration 246 / 300: loss 0.608784\n",
      "iteration 246 / 300: loss 0.592732\n",
      "iteration 246 / 300: loss 0.628060\n",
      "iteration 246 / 300: loss 0.580152\n",
      "iteration 246 / 300: loss 0.607923\n",
      "iteration 246 / 300: loss 0.587394\n",
      "iteration 246 / 300: loss 0.591686\n",
      "iteration 246 / 300: loss 0.571370\n",
      "iteration 246 / 300: loss 0.583025\n",
      "iteration 246 / 300: loss 0.608441\n",
      "iteration 246 / 300: loss 0.598359\n",
      "iteration 246 / 300: loss 0.583858\n",
      "iteration 246 / 300: loss 0.615253\n",
      "iteration 246 / 300: loss 0.591649\n",
      "iteration 246 / 300: loss 0.585499\n",
      "iteration 246 / 300: loss 0.591325\n",
      "iteration 246 / 300: loss 0.604341\n",
      "iteration 246 / 300: loss 0.595786\n",
      "iteration 246 / 300: loss 0.614949\n",
      "iteration 246 / 300: loss 0.608389\n",
      "iteration 246 / 300: loss 0.598222\n",
      "iteration 246 / 300: loss 0.588936\n",
      "iteration 246 / 300: loss 0.617757\n",
      "iteration 246 / 300: loss 0.594770\n",
      "iteration 246 / 300: loss 0.601684\n",
      "iteration 246 / 300: loss 0.631031\n",
      "iteration 246 / 300: loss 0.587513\n",
      "iteration 246 / 300: loss 0.606561\n",
      "iteration 246 / 300: loss 0.588034\n",
      "iteration 246 / 300: loss 0.600890\n",
      "iteration 246 / 300: loss 0.595958\n",
      "iteration 246 / 300: loss 0.589291\n",
      "iteration 246 / 300: loss 0.599526\n",
      "iteration 246 / 300: loss 0.604855\n",
      "iteration 246 / 300: loss 0.619414\n",
      "iteration 246 / 300: loss 0.588808\n",
      "iteration 246 / 300: loss 0.593645\n",
      "iteration 246 / 300: loss 0.585595\n",
      "iteration 246 / 300: loss 0.613212\n",
      "iteration 246 / 300: loss 0.587523\n",
      "iteration 246 / 300: loss 0.578328\n",
      "iteration 246 / 300: loss 0.567435\n",
      "iteration 246 / 300: loss 0.562235\n",
      "iteration 246 / 300: loss 0.594183\n",
      "iteration 246 / 300: loss 0.578821\n",
      "iteration 246 / 300: loss 0.586360\n",
      "iteration 246 / 300: loss 0.572890\n",
      "iteration 246 / 300: loss 0.596151\n",
      "iteration 246 / 300: loss 0.607951\n",
      "iteration 246 / 300: loss 0.610839\n",
      "iteration 246 / 300: loss 0.606265\n",
      "iteration 246 / 300: loss 0.583790\n",
      "iteration 246 / 300: loss 0.589627\n",
      "iteration 246 / 300: loss 0.595184\n",
      "iteration 246 / 300: loss 0.598955\n",
      "iteration 246 / 300: loss 0.596133\n",
      "iteration 246 / 300: loss 0.589769\n",
      "iteration 246 / 300: loss 0.591136\n",
      "iteration 246 / 300: loss 0.584854\n",
      "iteration 246 / 300: loss 0.599646\n",
      "iteration 246 / 300: loss 0.598902\n",
      "iteration 246 / 300: loss 0.614282\n",
      "iteration 246 / 300: loss 0.597796\n",
      "iteration 246 / 300: loss 0.599298\n",
      "iteration 246 / 300: loss 0.603317\n",
      "iteration 246 / 300: loss 0.592865\n",
      "iteration 246 / 300: loss 0.592391\n",
      "iteration 246 / 300: loss 0.589041\n",
      "iteration 246 / 300: loss 0.596446\n",
      "iteration 246 / 300: loss 0.605709\n",
      "iteration 246 / 300: loss 0.610562\n",
      "iteration 246 / 300: loss 0.587782\n",
      "iteration 246 / 300: loss 0.599351\n",
      "iteration 246 / 300: loss 0.602792\n",
      "iteration 246 / 300: loss 0.605028\n",
      "iteration 246 / 300: loss 0.603848\n",
      "iteration 246 / 300: loss 0.624144\n",
      "iteration 246 / 300: loss 0.587219\n",
      "iteration 246 / 300: loss 0.580754\n",
      "iteration 246 / 300: loss 0.625045\n",
      "iteration 246 / 300: loss 0.603310\n",
      "iteration 246 / 300: loss 0.604321\n",
      "iteration 246 / 300: loss 0.595476\n",
      "iteration 246 / 300: loss 0.597543\n",
      "iteration 246 / 300: loss 0.592740\n",
      "iteration 246 / 300: loss 0.589494\n",
      "iteration 246 / 300: loss 0.599264\n",
      "iteration 246 / 300: loss 0.611379\n",
      "iteration 246 / 300: loss 0.592463\n",
      "iteration 246 / 300: loss 0.599424\n",
      "iteration 246 / 300: loss 0.603100\n",
      "iteration 246 / 300: loss 0.602410\n",
      "iteration 246 / 300: loss 0.579811\n",
      "iteration 246 / 300: loss 0.601592\n",
      "iteration 247 / 300: loss 0.585528\n",
      "iteration 247 / 300: loss 0.588428\n",
      "iteration 247 / 300: loss 0.567516\n",
      "iteration 247 / 300: loss 0.592380\n",
      "iteration 247 / 300: loss 0.593618\n",
      "iteration 247 / 300: loss 0.595295\n",
      "iteration 247 / 300: loss 0.608784\n",
      "iteration 247 / 300: loss 0.592732\n",
      "iteration 247 / 300: loss 0.628060\n",
      "iteration 247 / 300: loss 0.580152\n",
      "iteration 247 / 300: loss 0.607923\n",
      "iteration 247 / 300: loss 0.587394\n",
      "iteration 247 / 300: loss 0.591686\n",
      "iteration 247 / 300: loss 0.571370\n",
      "iteration 247 / 300: loss 0.583025\n",
      "iteration 247 / 300: loss 0.608441\n",
      "iteration 247 / 300: loss 0.598359\n",
      "iteration 247 / 300: loss 0.583858\n",
      "iteration 247 / 300: loss 0.615253\n",
      "iteration 247 / 300: loss 0.591649\n",
      "iteration 247 / 300: loss 0.585499\n",
      "iteration 247 / 300: loss 0.591325\n",
      "iteration 247 / 300: loss 0.604341\n",
      "iteration 247 / 300: loss 0.595786\n",
      "iteration 247 / 300: loss 0.614949\n",
      "iteration 247 / 300: loss 0.608389\n",
      "iteration 247 / 300: loss 0.598222\n",
      "iteration 247 / 300: loss 0.588936\n",
      "iteration 247 / 300: loss 0.617757\n",
      "iteration 247 / 300: loss 0.594770\n",
      "iteration 247 / 300: loss 0.601684\n",
      "iteration 247 / 300: loss 0.631031\n",
      "iteration 247 / 300: loss 0.587513\n",
      "iteration 247 / 300: loss 0.606561\n",
      "iteration 247 / 300: loss 0.588034\n",
      "iteration 247 / 300: loss 0.600890\n",
      "iteration 247 / 300: loss 0.595958\n",
      "iteration 247 / 300: loss 0.589291\n",
      "iteration 247 / 300: loss 0.599526\n",
      "iteration 247 / 300: loss 0.604855\n",
      "iteration 247 / 300: loss 0.619414\n",
      "iteration 247 / 300: loss 0.588808\n",
      "iteration 247 / 300: loss 0.593645\n",
      "iteration 247 / 300: loss 0.585595\n",
      "iteration 247 / 300: loss 0.613212\n",
      "iteration 247 / 300: loss 0.587523\n",
      "iteration 247 / 300: loss 0.578328\n",
      "iteration 247 / 300: loss 0.567435\n",
      "iteration 247 / 300: loss 0.562235\n",
      "iteration 247 / 300: loss 0.594183\n",
      "iteration 247 / 300: loss 0.578821\n",
      "iteration 247 / 300: loss 0.586360\n",
      "iteration 247 / 300: loss 0.572890\n",
      "iteration 247 / 300: loss 0.596151\n",
      "iteration 247 / 300: loss 0.607951\n",
      "iteration 247 / 300: loss 0.610839\n",
      "iteration 247 / 300: loss 0.606265\n",
      "iteration 247 / 300: loss 0.583790\n",
      "iteration 247 / 300: loss 0.589627\n",
      "iteration 247 / 300: loss 0.595184\n",
      "iteration 247 / 300: loss 0.598955\n",
      "iteration 247 / 300: loss 0.596133\n",
      "iteration 247 / 300: loss 0.589769\n",
      "iteration 247 / 300: loss 0.591136\n",
      "iteration 247 / 300: loss 0.584854\n",
      "iteration 247 / 300: loss 0.599646\n",
      "iteration 247 / 300: loss 0.598902\n",
      "iteration 247 / 300: loss 0.614282\n",
      "iteration 247 / 300: loss 0.597796\n",
      "iteration 247 / 300: loss 0.599298\n",
      "iteration 247 / 300: loss 0.603317\n",
      "iteration 247 / 300: loss 0.592865\n",
      "iteration 247 / 300: loss 0.592391\n",
      "iteration 247 / 300: loss 0.589041\n",
      "iteration 247 / 300: loss 0.596446\n",
      "iteration 247 / 300: loss 0.605709\n",
      "iteration 247 / 300: loss 0.610562\n",
      "iteration 247 / 300: loss 0.587782\n",
      "iteration 247 / 300: loss 0.599351\n",
      "iteration 247 / 300: loss 0.602792\n",
      "iteration 247 / 300: loss 0.605028\n",
      "iteration 247 / 300: loss 0.603848\n",
      "iteration 247 / 300: loss 0.624144\n",
      "iteration 247 / 300: loss 0.587219\n",
      "iteration 247 / 300: loss 0.580754\n",
      "iteration 247 / 300: loss 0.625045\n",
      "iteration 247 / 300: loss 0.603310\n",
      "iteration 247 / 300: loss 0.604321\n",
      "iteration 247 / 300: loss 0.595476\n",
      "iteration 247 / 300: loss 0.597543\n",
      "iteration 247 / 300: loss 0.592740\n",
      "iteration 247 / 300: loss 0.589494\n",
      "iteration 247 / 300: loss 0.599264\n",
      "iteration 247 / 300: loss 0.611379\n",
      "iteration 247 / 300: loss 0.592463\n",
      "iteration 247 / 300: loss 0.599424\n",
      "iteration 247 / 300: loss 0.603100\n",
      "iteration 247 / 300: loss 0.602410\n",
      "iteration 247 / 300: loss 0.579811\n",
      "iteration 247 / 300: loss 0.601592\n",
      "iteration 248 / 300: loss 0.585528\n",
      "iteration 248 / 300: loss 0.588428\n",
      "iteration 248 / 300: loss 0.567516\n",
      "iteration 248 / 300: loss 0.592380\n",
      "iteration 248 / 300: loss 0.593618\n",
      "iteration 248 / 300: loss 0.595295\n",
      "iteration 248 / 300: loss 0.608784\n",
      "iteration 248 / 300: loss 0.592732\n",
      "iteration 248 / 300: loss 0.628060\n",
      "iteration 248 / 300: loss 0.580152\n",
      "iteration 248 / 300: loss 0.607923\n",
      "iteration 248 / 300: loss 0.587394\n",
      "iteration 248 / 300: loss 0.591686\n",
      "iteration 248 / 300: loss 0.571370\n",
      "iteration 248 / 300: loss 0.583025\n",
      "iteration 248 / 300: loss 0.608441\n",
      "iteration 248 / 300: loss 0.598359\n",
      "iteration 248 / 300: loss 0.583858\n",
      "iteration 248 / 300: loss 0.615253\n",
      "iteration 248 / 300: loss 0.591649\n",
      "iteration 248 / 300: loss 0.585499\n",
      "iteration 248 / 300: loss 0.591325\n",
      "iteration 248 / 300: loss 0.604341\n",
      "iteration 248 / 300: loss 0.595786\n",
      "iteration 248 / 300: loss 0.614949\n",
      "iteration 248 / 300: loss 0.608389\n",
      "iteration 248 / 300: loss 0.598222\n",
      "iteration 248 / 300: loss 0.588936\n",
      "iteration 248 / 300: loss 0.617757\n",
      "iteration 248 / 300: loss 0.594770\n",
      "iteration 248 / 300: loss 0.601684\n",
      "iteration 248 / 300: loss 0.631031\n",
      "iteration 248 / 300: loss 0.587513\n",
      "iteration 248 / 300: loss 0.606561\n",
      "iteration 248 / 300: loss 0.588034\n",
      "iteration 248 / 300: loss 0.600890\n",
      "iteration 248 / 300: loss 0.595958\n",
      "iteration 248 / 300: loss 0.589291\n",
      "iteration 248 / 300: loss 0.599526\n",
      "iteration 248 / 300: loss 0.604855\n",
      "iteration 248 / 300: loss 0.619414\n",
      "iteration 248 / 300: loss 0.588808\n",
      "iteration 248 / 300: loss 0.593645\n",
      "iteration 248 / 300: loss 0.585595\n",
      "iteration 248 / 300: loss 0.613212\n",
      "iteration 248 / 300: loss 0.587523\n",
      "iteration 248 / 300: loss 0.578328\n",
      "iteration 248 / 300: loss 0.567435\n",
      "iteration 248 / 300: loss 0.562235\n",
      "iteration 248 / 300: loss 0.594183\n",
      "iteration 248 / 300: loss 0.578821\n",
      "iteration 248 / 300: loss 0.586360\n",
      "iteration 248 / 300: loss 0.572890\n",
      "iteration 248 / 300: loss 0.596151\n",
      "iteration 248 / 300: loss 0.607951\n",
      "iteration 248 / 300: loss 0.610839\n",
      "iteration 248 / 300: loss 0.606265\n",
      "iteration 248 / 300: loss 0.583790\n",
      "iteration 248 / 300: loss 0.589627\n",
      "iteration 248 / 300: loss 0.595184\n",
      "iteration 248 / 300: loss 0.598955\n",
      "iteration 248 / 300: loss 0.596133\n",
      "iteration 248 / 300: loss 0.589769\n",
      "iteration 248 / 300: loss 0.591136\n",
      "iteration 248 / 300: loss 0.584854\n",
      "iteration 248 / 300: loss 0.599646\n",
      "iteration 248 / 300: loss 0.598902\n",
      "iteration 248 / 300: loss 0.614282\n",
      "iteration 248 / 300: loss 0.597796\n",
      "iteration 248 / 300: loss 0.599298\n",
      "iteration 248 / 300: loss 0.603317\n",
      "iteration 248 / 300: loss 0.592865\n",
      "iteration 248 / 300: loss 0.592391\n",
      "iteration 248 / 300: loss 0.589041\n",
      "iteration 248 / 300: loss 0.596446\n",
      "iteration 248 / 300: loss 0.605709\n",
      "iteration 248 / 300: loss 0.610562\n",
      "iteration 248 / 300: loss 0.587782\n",
      "iteration 248 / 300: loss 0.599351\n",
      "iteration 248 / 300: loss 0.602792\n",
      "iteration 248 / 300: loss 0.605028\n",
      "iteration 248 / 300: loss 0.603848\n",
      "iteration 248 / 300: loss 0.624144\n",
      "iteration 248 / 300: loss 0.587219\n",
      "iteration 248 / 300: loss 0.580754\n",
      "iteration 248 / 300: loss 0.625045\n",
      "iteration 248 / 300: loss 0.603310\n",
      "iteration 248 / 300: loss 0.604321\n",
      "iteration 248 / 300: loss 0.595476\n",
      "iteration 248 / 300: loss 0.597543\n",
      "iteration 248 / 300: loss 0.592740\n",
      "iteration 248 / 300: loss 0.589494\n",
      "iteration 248 / 300: loss 0.599264\n",
      "iteration 248 / 300: loss 0.611379\n",
      "iteration 248 / 300: loss 0.592463\n",
      "iteration 248 / 300: loss 0.599424\n",
      "iteration 248 / 300: loss 0.603100\n",
      "iteration 248 / 300: loss 0.602410\n",
      "iteration 248 / 300: loss 0.579811\n",
      "iteration 248 / 300: loss 0.601592\n",
      "iteration 249 / 300: loss 0.585528\n",
      "iteration 249 / 300: loss 0.588428\n",
      "iteration 249 / 300: loss 0.567516\n",
      "iteration 249 / 300: loss 0.592380\n",
      "iteration 249 / 300: loss 0.593618\n",
      "iteration 249 / 300: loss 0.595295\n",
      "iteration 249 / 300: loss 0.608784\n",
      "iteration 249 / 300: loss 0.592732\n",
      "iteration 249 / 300: loss 0.628060\n",
      "iteration 249 / 300: loss 0.580152\n",
      "iteration 249 / 300: loss 0.607923\n",
      "iteration 249 / 300: loss 0.587394\n",
      "iteration 249 / 300: loss 0.591686\n",
      "iteration 249 / 300: loss 0.571370\n",
      "iteration 249 / 300: loss 0.583025\n",
      "iteration 249 / 300: loss 0.608441\n",
      "iteration 249 / 300: loss 0.598359\n",
      "iteration 249 / 300: loss 0.583858\n",
      "iteration 249 / 300: loss 0.615253\n",
      "iteration 249 / 300: loss 0.591649\n",
      "iteration 249 / 300: loss 0.585499\n",
      "iteration 249 / 300: loss 0.591325\n",
      "iteration 249 / 300: loss 0.604341\n",
      "iteration 249 / 300: loss 0.595786\n",
      "iteration 249 / 300: loss 0.614949\n",
      "iteration 249 / 300: loss 0.608389\n",
      "iteration 249 / 300: loss 0.598222\n",
      "iteration 249 / 300: loss 0.588936\n",
      "iteration 249 / 300: loss 0.617757\n",
      "iteration 249 / 300: loss 0.594770\n",
      "iteration 249 / 300: loss 0.601684\n",
      "iteration 249 / 300: loss 0.631031\n",
      "iteration 249 / 300: loss 0.587513\n",
      "iteration 249 / 300: loss 0.606561\n",
      "iteration 249 / 300: loss 0.588034\n",
      "iteration 249 / 300: loss 0.600890\n",
      "iteration 249 / 300: loss 0.595958\n",
      "iteration 249 / 300: loss 0.589291\n",
      "iteration 249 / 300: loss 0.599526\n",
      "iteration 249 / 300: loss 0.604855\n",
      "iteration 249 / 300: loss 0.619414\n",
      "iteration 249 / 300: loss 0.588808\n",
      "iteration 249 / 300: loss 0.593645\n",
      "iteration 249 / 300: loss 0.585595\n",
      "iteration 249 / 300: loss 0.613212\n",
      "iteration 249 / 300: loss 0.587523\n",
      "iteration 249 / 300: loss 0.578328\n",
      "iteration 249 / 300: loss 0.567435\n",
      "iteration 249 / 300: loss 0.562235\n",
      "iteration 249 / 300: loss 0.594183\n",
      "iteration 249 / 300: loss 0.578821\n",
      "iteration 249 / 300: loss 0.586360\n",
      "iteration 249 / 300: loss 0.572890\n",
      "iteration 249 / 300: loss 0.596151\n",
      "iteration 249 / 300: loss 0.607951\n",
      "iteration 249 / 300: loss 0.610839\n",
      "iteration 249 / 300: loss 0.606265\n",
      "iteration 249 / 300: loss 0.583790\n",
      "iteration 249 / 300: loss 0.589627\n",
      "iteration 249 / 300: loss 0.595184\n",
      "iteration 249 / 300: loss 0.598955\n",
      "iteration 249 / 300: loss 0.596133\n",
      "iteration 249 / 300: loss 0.589769\n",
      "iteration 249 / 300: loss 0.591136\n",
      "iteration 249 / 300: loss 0.584854\n",
      "iteration 249 / 300: loss 0.599646\n",
      "iteration 249 / 300: loss 0.598902\n",
      "iteration 249 / 300: loss 0.614282\n",
      "iteration 249 / 300: loss 0.597796\n",
      "iteration 249 / 300: loss 0.599298\n",
      "iteration 249 / 300: loss 0.603317\n",
      "iteration 249 / 300: loss 0.592865\n",
      "iteration 249 / 300: loss 0.592391\n",
      "iteration 249 / 300: loss 0.589041\n",
      "iteration 249 / 300: loss 0.596446\n",
      "iteration 249 / 300: loss 0.605709\n",
      "iteration 249 / 300: loss 0.610562\n",
      "iteration 249 / 300: loss 0.587782\n",
      "iteration 249 / 300: loss 0.599351\n",
      "iteration 249 / 300: loss 0.602792\n",
      "iteration 249 / 300: loss 0.605028\n",
      "iteration 249 / 300: loss 0.603848\n",
      "iteration 249 / 300: loss 0.624144\n",
      "iteration 249 / 300: loss 0.587219\n",
      "iteration 249 / 300: loss 0.580754\n",
      "iteration 249 / 300: loss 0.625045\n",
      "iteration 249 / 300: loss 0.603310\n",
      "iteration 249 / 300: loss 0.604321\n",
      "iteration 249 / 300: loss 0.595476\n",
      "iteration 249 / 300: loss 0.597543\n",
      "iteration 249 / 300: loss 0.592740\n",
      "iteration 249 / 300: loss 0.589494\n",
      "iteration 249 / 300: loss 0.599264\n",
      "iteration 249 / 300: loss 0.611379\n",
      "iteration 249 / 300: loss 0.592463\n",
      "iteration 249 / 300: loss 0.599424\n",
      "iteration 249 / 300: loss 0.603100\n",
      "iteration 249 / 300: loss 0.602410\n",
      "iteration 249 / 300: loss 0.579811\n",
      "iteration 249 / 300: loss 0.601592\n",
      "iteration 250 / 300: loss 0.585528\n",
      "iteration 250 / 300: loss 0.588428\n",
      "iteration 250 / 300: loss 0.567516\n",
      "iteration 250 / 300: loss 0.592380\n",
      "iteration 250 / 300: loss 0.593618\n",
      "iteration 250 / 300: loss 0.595295\n",
      "iteration 250 / 300: loss 0.608784\n",
      "iteration 250 / 300: loss 0.592732\n",
      "iteration 250 / 300: loss 0.628060\n",
      "iteration 250 / 300: loss 0.580152\n",
      "iteration 250 / 300: loss 0.607923\n",
      "iteration 250 / 300: loss 0.587394\n",
      "iteration 250 / 300: loss 0.591686\n",
      "iteration 250 / 300: loss 0.571370\n",
      "iteration 250 / 300: loss 0.583025\n",
      "iteration 250 / 300: loss 0.608441\n",
      "iteration 250 / 300: loss 0.598359\n",
      "iteration 250 / 300: loss 0.583858\n",
      "iteration 250 / 300: loss 0.615253\n",
      "iteration 250 / 300: loss 0.591649\n",
      "iteration 250 / 300: loss 0.585499\n",
      "iteration 250 / 300: loss 0.591325\n",
      "iteration 250 / 300: loss 0.604341\n",
      "iteration 250 / 300: loss 0.595786\n",
      "iteration 250 / 300: loss 0.614949\n",
      "iteration 250 / 300: loss 0.608389\n",
      "iteration 250 / 300: loss 0.598222\n",
      "iteration 250 / 300: loss 0.588936\n",
      "iteration 250 / 300: loss 0.617757\n",
      "iteration 250 / 300: loss 0.594770\n",
      "iteration 250 / 300: loss 0.601684\n",
      "iteration 250 / 300: loss 0.631031\n",
      "iteration 250 / 300: loss 0.587513\n",
      "iteration 250 / 300: loss 0.606561\n",
      "iteration 250 / 300: loss 0.588034\n",
      "iteration 250 / 300: loss 0.600890\n",
      "iteration 250 / 300: loss 0.595958\n",
      "iteration 250 / 300: loss 0.589291\n",
      "iteration 250 / 300: loss 0.599526\n",
      "iteration 250 / 300: loss 0.604855\n",
      "iteration 250 / 300: loss 0.619414\n",
      "iteration 250 / 300: loss 0.588808\n",
      "iteration 250 / 300: loss 0.593645\n",
      "iteration 250 / 300: loss 0.585595\n",
      "iteration 250 / 300: loss 0.613212\n",
      "iteration 250 / 300: loss 0.587523\n",
      "iteration 250 / 300: loss 0.578328\n",
      "iteration 250 / 300: loss 0.567435\n",
      "iteration 250 / 300: loss 0.562235\n",
      "iteration 250 / 300: loss 0.594183\n",
      "iteration 250 / 300: loss 0.578821\n",
      "iteration 250 / 300: loss 0.586360\n",
      "iteration 250 / 300: loss 0.572890\n",
      "iteration 250 / 300: loss 0.596151\n",
      "iteration 250 / 300: loss 0.607951\n",
      "iteration 250 / 300: loss 0.610839\n",
      "iteration 250 / 300: loss 0.606265\n",
      "iteration 250 / 300: loss 0.583790\n",
      "iteration 250 / 300: loss 0.589627\n",
      "iteration 250 / 300: loss 0.595184\n",
      "iteration 250 / 300: loss 0.598955\n",
      "iteration 250 / 300: loss 0.596133\n",
      "iteration 250 / 300: loss 0.589769\n",
      "iteration 250 / 300: loss 0.591136\n",
      "iteration 250 / 300: loss 0.584854\n",
      "iteration 250 / 300: loss 0.599646\n",
      "iteration 250 / 300: loss 0.598902\n",
      "iteration 250 / 300: loss 0.614282\n",
      "iteration 250 / 300: loss 0.597796\n",
      "iteration 250 / 300: loss 0.599298\n",
      "iteration 250 / 300: loss 0.603317\n",
      "iteration 250 / 300: loss 0.592865\n",
      "iteration 250 / 300: loss 0.592391\n",
      "iteration 250 / 300: loss 0.589041\n",
      "iteration 250 / 300: loss 0.596446\n",
      "iteration 250 / 300: loss 0.605709\n",
      "iteration 250 / 300: loss 0.610562\n",
      "iteration 250 / 300: loss 0.587782\n",
      "iteration 250 / 300: loss 0.599351\n",
      "iteration 250 / 300: loss 0.602792\n",
      "iteration 250 / 300: loss 0.605028\n",
      "iteration 250 / 300: loss 0.603848\n",
      "iteration 250 / 300: loss 0.624144\n",
      "iteration 250 / 300: loss 0.587219\n",
      "iteration 250 / 300: loss 0.580754\n",
      "iteration 250 / 300: loss 0.625045\n",
      "iteration 250 / 300: loss 0.603310\n",
      "iteration 250 / 300: loss 0.604321\n",
      "iteration 250 / 300: loss 0.595476\n",
      "iteration 250 / 300: loss 0.597543\n",
      "iteration 250 / 300: loss 0.592740\n",
      "iteration 250 / 300: loss 0.589494\n",
      "iteration 250 / 300: loss 0.599264\n",
      "iteration 250 / 300: loss 0.611379\n",
      "iteration 250 / 300: loss 0.592463\n",
      "iteration 250 / 300: loss 0.599424\n",
      "iteration 250 / 300: loss 0.603100\n",
      "iteration 250 / 300: loss 0.602410\n",
      "iteration 250 / 300: loss 0.579811\n",
      "iteration 250 / 300: loss 0.601592\n",
      "iteration 251 / 300: loss 0.585528\n",
      "iteration 251 / 300: loss 0.588428\n",
      "iteration 251 / 300: loss 0.567516\n",
      "iteration 251 / 300: loss 0.592380\n",
      "iteration 251 / 300: loss 0.593618\n",
      "iteration 251 / 300: loss 0.595295\n",
      "iteration 251 / 300: loss 0.608784\n",
      "iteration 251 / 300: loss 0.592732\n",
      "iteration 251 / 300: loss 0.628060\n",
      "iteration 251 / 300: loss 0.580152\n",
      "iteration 251 / 300: loss 0.607923\n",
      "iteration 251 / 300: loss 0.587394\n",
      "iteration 251 / 300: loss 0.591686\n",
      "iteration 251 / 300: loss 0.571370\n",
      "iteration 251 / 300: loss 0.583025\n",
      "iteration 251 / 300: loss 0.608441\n",
      "iteration 251 / 300: loss 0.598359\n",
      "iteration 251 / 300: loss 0.583858\n",
      "iteration 251 / 300: loss 0.615253\n",
      "iteration 251 / 300: loss 0.591649\n",
      "iteration 251 / 300: loss 0.585499\n",
      "iteration 251 / 300: loss 0.591325\n",
      "iteration 251 / 300: loss 0.604341\n",
      "iteration 251 / 300: loss 0.595786\n",
      "iteration 251 / 300: loss 0.614949\n",
      "iteration 251 / 300: loss 0.608389\n",
      "iteration 251 / 300: loss 0.598222\n",
      "iteration 251 / 300: loss 0.588936\n",
      "iteration 251 / 300: loss 0.617757\n",
      "iteration 251 / 300: loss 0.594770\n",
      "iteration 251 / 300: loss 0.601684\n",
      "iteration 251 / 300: loss 0.631031\n",
      "iteration 251 / 300: loss 0.587513\n",
      "iteration 251 / 300: loss 0.606561\n",
      "iteration 251 / 300: loss 0.588034\n",
      "iteration 251 / 300: loss 0.600890\n",
      "iteration 251 / 300: loss 0.595958\n",
      "iteration 251 / 300: loss 0.589291\n",
      "iteration 251 / 300: loss 0.599526\n",
      "iteration 251 / 300: loss 0.604855\n",
      "iteration 251 / 300: loss 0.619414\n",
      "iteration 251 / 300: loss 0.588808\n",
      "iteration 251 / 300: loss 0.593645\n",
      "iteration 251 / 300: loss 0.585595\n",
      "iteration 251 / 300: loss 0.613212\n",
      "iteration 251 / 300: loss 0.587523\n",
      "iteration 251 / 300: loss 0.578328\n",
      "iteration 251 / 300: loss 0.567435\n",
      "iteration 251 / 300: loss 0.562235\n",
      "iteration 251 / 300: loss 0.594183\n",
      "iteration 251 / 300: loss 0.578821\n",
      "iteration 251 / 300: loss 0.586360\n",
      "iteration 251 / 300: loss 0.572890\n",
      "iteration 251 / 300: loss 0.596151\n",
      "iteration 251 / 300: loss 0.607951\n",
      "iteration 251 / 300: loss 0.610839\n",
      "iteration 251 / 300: loss 0.606265\n",
      "iteration 251 / 300: loss 0.583790\n",
      "iteration 251 / 300: loss 0.589627\n",
      "iteration 251 / 300: loss 0.595184\n",
      "iteration 251 / 300: loss 0.598955\n",
      "iteration 251 / 300: loss 0.596133\n",
      "iteration 251 / 300: loss 0.589769\n",
      "iteration 251 / 300: loss 0.591136\n",
      "iteration 251 / 300: loss 0.584854\n",
      "iteration 251 / 300: loss 0.599646\n",
      "iteration 251 / 300: loss 0.598902\n",
      "iteration 251 / 300: loss 0.614282\n",
      "iteration 251 / 300: loss 0.597796\n",
      "iteration 251 / 300: loss 0.599298\n",
      "iteration 251 / 300: loss 0.603317\n",
      "iteration 251 / 300: loss 0.592865\n",
      "iteration 251 / 300: loss 0.592391\n",
      "iteration 251 / 300: loss 0.589041\n",
      "iteration 251 / 300: loss 0.596446\n",
      "iteration 251 / 300: loss 0.605709\n",
      "iteration 251 / 300: loss 0.610562\n",
      "iteration 251 / 300: loss 0.587782\n",
      "iteration 251 / 300: loss 0.599351\n",
      "iteration 251 / 300: loss 0.602792\n",
      "iteration 251 / 300: loss 0.605028\n",
      "iteration 251 / 300: loss 0.603848\n",
      "iteration 251 / 300: loss 0.624144\n",
      "iteration 251 / 300: loss 0.587219\n",
      "iteration 251 / 300: loss 0.580754\n",
      "iteration 251 / 300: loss 0.625045\n",
      "iteration 251 / 300: loss 0.603310\n",
      "iteration 251 / 300: loss 0.604321\n",
      "iteration 251 / 300: loss 0.595476\n",
      "iteration 251 / 300: loss 0.597543\n",
      "iteration 251 / 300: loss 0.592740\n",
      "iteration 251 / 300: loss 0.589494\n",
      "iteration 251 / 300: loss 0.599264\n",
      "iteration 251 / 300: loss 0.611379\n",
      "iteration 251 / 300: loss 0.592463\n",
      "iteration 251 / 300: loss 0.599424\n",
      "iteration 251 / 300: loss 0.603100\n",
      "iteration 251 / 300: loss 0.602410\n",
      "iteration 251 / 300: loss 0.579811\n",
      "iteration 251 / 300: loss 0.601592\n",
      "iteration 252 / 300: loss 0.585528\n",
      "iteration 252 / 300: loss 0.588428\n",
      "iteration 252 / 300: loss 0.567516\n",
      "iteration 252 / 300: loss 0.592380\n",
      "iteration 252 / 300: loss 0.593618\n",
      "iteration 252 / 300: loss 0.595295\n",
      "iteration 252 / 300: loss 0.608784\n",
      "iteration 252 / 300: loss 0.592732\n",
      "iteration 252 / 300: loss 0.628060\n",
      "iteration 252 / 300: loss 0.580152\n",
      "iteration 252 / 300: loss 0.607923\n",
      "iteration 252 / 300: loss 0.587394\n",
      "iteration 252 / 300: loss 0.591686\n",
      "iteration 252 / 300: loss 0.571370\n",
      "iteration 252 / 300: loss 0.583025\n",
      "iteration 252 / 300: loss 0.608441\n",
      "iteration 252 / 300: loss 0.598359\n",
      "iteration 252 / 300: loss 0.583858\n",
      "iteration 252 / 300: loss 0.615253\n",
      "iteration 252 / 300: loss 0.591649\n",
      "iteration 252 / 300: loss 0.585499\n",
      "iteration 252 / 300: loss 0.591325\n",
      "iteration 252 / 300: loss 0.604341\n",
      "iteration 252 / 300: loss 0.595786\n",
      "iteration 252 / 300: loss 0.614949\n",
      "iteration 252 / 300: loss 0.608389\n",
      "iteration 252 / 300: loss 0.598222\n",
      "iteration 252 / 300: loss 0.588936\n",
      "iteration 252 / 300: loss 0.617757\n",
      "iteration 252 / 300: loss 0.594770\n",
      "iteration 252 / 300: loss 0.601684\n",
      "iteration 252 / 300: loss 0.631031\n",
      "iteration 252 / 300: loss 0.587513\n",
      "iteration 252 / 300: loss 0.606561\n",
      "iteration 252 / 300: loss 0.588034\n",
      "iteration 252 / 300: loss 0.600890\n",
      "iteration 252 / 300: loss 0.595958\n",
      "iteration 252 / 300: loss 0.589291\n",
      "iteration 252 / 300: loss 0.599526\n",
      "iteration 252 / 300: loss 0.604855\n",
      "iteration 252 / 300: loss 0.619414\n",
      "iteration 252 / 300: loss 0.588808\n",
      "iteration 252 / 300: loss 0.593645\n",
      "iteration 252 / 300: loss 0.585595\n",
      "iteration 252 / 300: loss 0.613212\n",
      "iteration 252 / 300: loss 0.587523\n",
      "iteration 252 / 300: loss 0.578328\n",
      "iteration 252 / 300: loss 0.567435\n",
      "iteration 252 / 300: loss 0.562235\n",
      "iteration 252 / 300: loss 0.594183\n",
      "iteration 252 / 300: loss 0.578821\n",
      "iteration 252 / 300: loss 0.586360\n",
      "iteration 252 / 300: loss 0.572890\n",
      "iteration 252 / 300: loss 0.596151\n",
      "iteration 252 / 300: loss 0.607951\n",
      "iteration 252 / 300: loss 0.610839\n",
      "iteration 252 / 300: loss 0.606265\n",
      "iteration 252 / 300: loss 0.583790\n",
      "iteration 252 / 300: loss 0.589627\n",
      "iteration 252 / 300: loss 0.595184\n",
      "iteration 252 / 300: loss 0.598955\n",
      "iteration 252 / 300: loss 0.596133\n",
      "iteration 252 / 300: loss 0.589769\n",
      "iteration 252 / 300: loss 0.591136\n",
      "iteration 252 / 300: loss 0.584854\n",
      "iteration 252 / 300: loss 0.599646\n",
      "iteration 252 / 300: loss 0.598902\n",
      "iteration 252 / 300: loss 0.614282\n",
      "iteration 252 / 300: loss 0.597796\n",
      "iteration 252 / 300: loss 0.599298\n",
      "iteration 252 / 300: loss 0.603317\n",
      "iteration 252 / 300: loss 0.592865\n",
      "iteration 252 / 300: loss 0.592391\n",
      "iteration 252 / 300: loss 0.589041\n",
      "iteration 252 / 300: loss 0.596446\n",
      "iteration 252 / 300: loss 0.605709\n",
      "iteration 252 / 300: loss 0.610562\n",
      "iteration 252 / 300: loss 0.587782\n",
      "iteration 252 / 300: loss 0.599351\n",
      "iteration 252 / 300: loss 0.602792\n",
      "iteration 252 / 300: loss 0.605028\n",
      "iteration 252 / 300: loss 0.603848\n",
      "iteration 252 / 300: loss 0.624144\n",
      "iteration 252 / 300: loss 0.587219\n",
      "iteration 252 / 300: loss 0.580754\n",
      "iteration 252 / 300: loss 0.625045\n",
      "iteration 252 / 300: loss 0.603310\n",
      "iteration 252 / 300: loss 0.604321\n",
      "iteration 252 / 300: loss 0.595476\n",
      "iteration 252 / 300: loss 0.597543\n",
      "iteration 252 / 300: loss 0.592740\n",
      "iteration 252 / 300: loss 0.589494\n",
      "iteration 252 / 300: loss 0.599264\n",
      "iteration 252 / 300: loss 0.611379\n",
      "iteration 252 / 300: loss 0.592463\n",
      "iteration 252 / 300: loss 0.599424\n",
      "iteration 252 / 300: loss 0.603100\n",
      "iteration 252 / 300: loss 0.602410\n",
      "iteration 252 / 300: loss 0.579811\n",
      "iteration 252 / 300: loss 0.601592\n",
      "iteration 253 / 300: loss 0.585528\n",
      "iteration 253 / 300: loss 0.588428\n",
      "iteration 253 / 300: loss 0.567516\n",
      "iteration 253 / 300: loss 0.592380\n",
      "iteration 253 / 300: loss 0.593618\n",
      "iteration 253 / 300: loss 0.595295\n",
      "iteration 253 / 300: loss 0.608784\n",
      "iteration 253 / 300: loss 0.592732\n",
      "iteration 253 / 300: loss 0.628060\n",
      "iteration 253 / 300: loss 0.580152\n",
      "iteration 253 / 300: loss 0.607923\n",
      "iteration 253 / 300: loss 0.587394\n",
      "iteration 253 / 300: loss 0.591686\n",
      "iteration 253 / 300: loss 0.571370\n",
      "iteration 253 / 300: loss 0.583025\n",
      "iteration 253 / 300: loss 0.608441\n",
      "iteration 253 / 300: loss 0.598359\n",
      "iteration 253 / 300: loss 0.583858\n",
      "iteration 253 / 300: loss 0.615253\n",
      "iteration 253 / 300: loss 0.591649\n",
      "iteration 253 / 300: loss 0.585499\n",
      "iteration 253 / 300: loss 0.591325\n",
      "iteration 253 / 300: loss 0.604341\n",
      "iteration 253 / 300: loss 0.595786\n",
      "iteration 253 / 300: loss 0.614949\n",
      "iteration 253 / 300: loss 0.608389\n",
      "iteration 253 / 300: loss 0.598222\n",
      "iteration 253 / 300: loss 0.588936\n",
      "iteration 253 / 300: loss 0.617757\n",
      "iteration 253 / 300: loss 0.594770\n",
      "iteration 253 / 300: loss 0.601684\n",
      "iteration 253 / 300: loss 0.631031\n",
      "iteration 253 / 300: loss 0.587513\n",
      "iteration 253 / 300: loss 0.606561\n",
      "iteration 253 / 300: loss 0.588034\n",
      "iteration 253 / 300: loss 0.600890\n",
      "iteration 253 / 300: loss 0.595958\n",
      "iteration 253 / 300: loss 0.589291\n",
      "iteration 253 / 300: loss 0.599526\n",
      "iteration 253 / 300: loss 0.604855\n",
      "iteration 253 / 300: loss 0.619414\n",
      "iteration 253 / 300: loss 0.588808\n",
      "iteration 253 / 300: loss 0.593645\n",
      "iteration 253 / 300: loss 0.585595\n",
      "iteration 253 / 300: loss 0.613212\n",
      "iteration 253 / 300: loss 0.587523\n",
      "iteration 253 / 300: loss 0.578328\n",
      "iteration 253 / 300: loss 0.567435\n",
      "iteration 253 / 300: loss 0.562235\n",
      "iteration 253 / 300: loss 0.594183\n",
      "iteration 253 / 300: loss 0.578821\n",
      "iteration 253 / 300: loss 0.586360\n",
      "iteration 253 / 300: loss 0.572890\n",
      "iteration 253 / 300: loss 0.596151\n",
      "iteration 253 / 300: loss 0.607951\n",
      "iteration 253 / 300: loss 0.610839\n",
      "iteration 253 / 300: loss 0.606265\n",
      "iteration 253 / 300: loss 0.583790\n",
      "iteration 253 / 300: loss 0.589627\n",
      "iteration 253 / 300: loss 0.595184\n",
      "iteration 253 / 300: loss 0.598955\n",
      "iteration 253 / 300: loss 0.596133\n",
      "iteration 253 / 300: loss 0.589769\n",
      "iteration 253 / 300: loss 0.591136\n",
      "iteration 253 / 300: loss 0.584854\n",
      "iteration 253 / 300: loss 0.599646\n",
      "iteration 253 / 300: loss 0.598902\n",
      "iteration 253 / 300: loss 0.614282\n",
      "iteration 253 / 300: loss 0.597796\n",
      "iteration 253 / 300: loss 0.599298\n",
      "iteration 253 / 300: loss 0.603317\n",
      "iteration 253 / 300: loss 0.592865\n",
      "iteration 253 / 300: loss 0.592391\n",
      "iteration 253 / 300: loss 0.589041\n",
      "iteration 253 / 300: loss 0.596446\n",
      "iteration 253 / 300: loss 0.605709\n",
      "iteration 253 / 300: loss 0.610562\n",
      "iteration 253 / 300: loss 0.587782\n",
      "iteration 253 / 300: loss 0.599351\n",
      "iteration 253 / 300: loss 0.602792\n",
      "iteration 253 / 300: loss 0.605028\n",
      "iteration 253 / 300: loss 0.603848\n",
      "iteration 253 / 300: loss 0.624144\n",
      "iteration 253 / 300: loss 0.587219\n",
      "iteration 253 / 300: loss 0.580754\n",
      "iteration 253 / 300: loss 0.625045\n",
      "iteration 253 / 300: loss 0.603310\n",
      "iteration 253 / 300: loss 0.604321\n",
      "iteration 253 / 300: loss 0.595476\n",
      "iteration 253 / 300: loss 0.597543\n",
      "iteration 253 / 300: loss 0.592740\n",
      "iteration 253 / 300: loss 0.589494\n",
      "iteration 253 / 300: loss 0.599264\n",
      "iteration 253 / 300: loss 0.611379\n",
      "iteration 253 / 300: loss 0.592463\n",
      "iteration 253 / 300: loss 0.599424\n",
      "iteration 253 / 300: loss 0.603100\n",
      "iteration 253 / 300: loss 0.602410\n",
      "iteration 253 / 300: loss 0.579811\n",
      "iteration 253 / 300: loss 0.601592\n",
      "iteration 254 / 300: loss 0.585528\n",
      "iteration 254 / 300: loss 0.588428\n",
      "iteration 254 / 300: loss 0.567516\n",
      "iteration 254 / 300: loss 0.592380\n",
      "iteration 254 / 300: loss 0.593618\n",
      "iteration 254 / 300: loss 0.595295\n",
      "iteration 254 / 300: loss 0.608784\n",
      "iteration 254 / 300: loss 0.592732\n",
      "iteration 254 / 300: loss 0.628060\n",
      "iteration 254 / 300: loss 0.580152\n",
      "iteration 254 / 300: loss 0.607923\n",
      "iteration 254 / 300: loss 0.587394\n",
      "iteration 254 / 300: loss 0.591686\n",
      "iteration 254 / 300: loss 0.571370\n",
      "iteration 254 / 300: loss 0.583025\n",
      "iteration 254 / 300: loss 0.608441\n",
      "iteration 254 / 300: loss 0.598359\n",
      "iteration 254 / 300: loss 0.583858\n",
      "iteration 254 / 300: loss 0.615253\n",
      "iteration 254 / 300: loss 0.591649\n",
      "iteration 254 / 300: loss 0.585499\n",
      "iteration 254 / 300: loss 0.591325\n",
      "iteration 254 / 300: loss 0.604341\n",
      "iteration 254 / 300: loss 0.595786\n",
      "iteration 254 / 300: loss 0.614949\n",
      "iteration 254 / 300: loss 0.608389\n",
      "iteration 254 / 300: loss 0.598222\n",
      "iteration 254 / 300: loss 0.588936\n",
      "iteration 254 / 300: loss 0.617757\n",
      "iteration 254 / 300: loss 0.594770\n",
      "iteration 254 / 300: loss 0.601684\n",
      "iteration 254 / 300: loss 0.631031\n",
      "iteration 254 / 300: loss 0.587513\n",
      "iteration 254 / 300: loss 0.606561\n",
      "iteration 254 / 300: loss 0.588034\n",
      "iteration 254 / 300: loss 0.600890\n",
      "iteration 254 / 300: loss 0.595958\n",
      "iteration 254 / 300: loss 0.589291\n",
      "iteration 254 / 300: loss 0.599526\n",
      "iteration 254 / 300: loss 0.604855\n",
      "iteration 254 / 300: loss 0.619414\n",
      "iteration 254 / 300: loss 0.588808\n",
      "iteration 254 / 300: loss 0.593645\n",
      "iteration 254 / 300: loss 0.585595\n",
      "iteration 254 / 300: loss 0.613212\n",
      "iteration 254 / 300: loss 0.587523\n",
      "iteration 254 / 300: loss 0.578328\n",
      "iteration 254 / 300: loss 0.567435\n",
      "iteration 254 / 300: loss 0.562235\n",
      "iteration 254 / 300: loss 0.594183\n",
      "iteration 254 / 300: loss 0.578821\n",
      "iteration 254 / 300: loss 0.586360\n",
      "iteration 254 / 300: loss 0.572890\n",
      "iteration 254 / 300: loss 0.596151\n",
      "iteration 254 / 300: loss 0.607951\n",
      "iteration 254 / 300: loss 0.610839\n",
      "iteration 254 / 300: loss 0.606265\n",
      "iteration 254 / 300: loss 0.583790\n",
      "iteration 254 / 300: loss 0.589627\n",
      "iteration 254 / 300: loss 0.595184\n",
      "iteration 254 / 300: loss 0.598955\n",
      "iteration 254 / 300: loss 0.596133\n",
      "iteration 254 / 300: loss 0.589769\n",
      "iteration 254 / 300: loss 0.591136\n",
      "iteration 254 / 300: loss 0.584854\n",
      "iteration 254 / 300: loss 0.599646\n",
      "iteration 254 / 300: loss 0.598902\n",
      "iteration 254 / 300: loss 0.614282\n",
      "iteration 254 / 300: loss 0.597796\n",
      "iteration 254 / 300: loss 0.599298\n",
      "iteration 254 / 300: loss 0.603317\n",
      "iteration 254 / 300: loss 0.592865\n",
      "iteration 254 / 300: loss 0.592391\n",
      "iteration 254 / 300: loss 0.589041\n",
      "iteration 254 / 300: loss 0.596446\n",
      "iteration 254 / 300: loss 0.605709\n",
      "iteration 254 / 300: loss 0.610562\n",
      "iteration 254 / 300: loss 0.587782\n",
      "iteration 254 / 300: loss 0.599351\n",
      "iteration 254 / 300: loss 0.602792\n",
      "iteration 254 / 300: loss 0.605028\n",
      "iteration 254 / 300: loss 0.603848\n",
      "iteration 254 / 300: loss 0.624144\n",
      "iteration 254 / 300: loss 0.587219\n",
      "iteration 254 / 300: loss 0.580754\n",
      "iteration 254 / 300: loss 0.625045\n",
      "iteration 254 / 300: loss 0.603310\n",
      "iteration 254 / 300: loss 0.604321\n",
      "iteration 254 / 300: loss 0.595476\n",
      "iteration 254 / 300: loss 0.597543\n",
      "iteration 254 / 300: loss 0.592740\n",
      "iteration 254 / 300: loss 0.589494\n",
      "iteration 254 / 300: loss 0.599264\n",
      "iteration 254 / 300: loss 0.611379\n",
      "iteration 254 / 300: loss 0.592463\n",
      "iteration 254 / 300: loss 0.599424\n",
      "iteration 254 / 300: loss 0.603100\n",
      "iteration 254 / 300: loss 0.602410\n",
      "iteration 254 / 300: loss 0.579811\n",
      "iteration 254 / 300: loss 0.601592\n",
      "iteration 255 / 300: loss 0.585528\n",
      "iteration 255 / 300: loss 0.588428\n",
      "iteration 255 / 300: loss 0.567516\n",
      "iteration 255 / 300: loss 0.592380\n",
      "iteration 255 / 300: loss 0.593618\n",
      "iteration 255 / 300: loss 0.595295\n",
      "iteration 255 / 300: loss 0.608784\n",
      "iteration 255 / 300: loss 0.592732\n",
      "iteration 255 / 300: loss 0.628060\n",
      "iteration 255 / 300: loss 0.580152\n",
      "iteration 255 / 300: loss 0.607923\n",
      "iteration 255 / 300: loss 0.587394\n",
      "iteration 255 / 300: loss 0.591686\n",
      "iteration 255 / 300: loss 0.571370\n",
      "iteration 255 / 300: loss 0.583025\n",
      "iteration 255 / 300: loss 0.608441\n",
      "iteration 255 / 300: loss 0.598359\n",
      "iteration 255 / 300: loss 0.583858\n",
      "iteration 255 / 300: loss 0.615253\n",
      "iteration 255 / 300: loss 0.591649\n",
      "iteration 255 / 300: loss 0.585499\n",
      "iteration 255 / 300: loss 0.591325\n",
      "iteration 255 / 300: loss 0.604341\n",
      "iteration 255 / 300: loss 0.595786\n",
      "iteration 255 / 300: loss 0.614949\n",
      "iteration 255 / 300: loss 0.608389\n",
      "iteration 255 / 300: loss 0.598222\n",
      "iteration 255 / 300: loss 0.588936\n",
      "iteration 255 / 300: loss 0.617757\n",
      "iteration 255 / 300: loss 0.594770\n",
      "iteration 255 / 300: loss 0.601684\n",
      "iteration 255 / 300: loss 0.631031\n",
      "iteration 255 / 300: loss 0.587513\n",
      "iteration 255 / 300: loss 0.606561\n",
      "iteration 255 / 300: loss 0.588034\n",
      "iteration 255 / 300: loss 0.600890\n",
      "iteration 255 / 300: loss 0.595958\n",
      "iteration 255 / 300: loss 0.589291\n",
      "iteration 255 / 300: loss 0.599526\n",
      "iteration 255 / 300: loss 0.604855\n",
      "iteration 255 / 300: loss 0.619414\n",
      "iteration 255 / 300: loss 0.588808\n",
      "iteration 255 / 300: loss 0.593645\n",
      "iteration 255 / 300: loss 0.585595\n",
      "iteration 255 / 300: loss 0.613212\n",
      "iteration 255 / 300: loss 0.587523\n",
      "iteration 255 / 300: loss 0.578328\n",
      "iteration 255 / 300: loss 0.567435\n",
      "iteration 255 / 300: loss 0.562235\n",
      "iteration 255 / 300: loss 0.594183\n",
      "iteration 255 / 300: loss 0.578821\n",
      "iteration 255 / 300: loss 0.586360\n",
      "iteration 255 / 300: loss 0.572890\n",
      "iteration 255 / 300: loss 0.596151\n",
      "iteration 255 / 300: loss 0.607951\n",
      "iteration 255 / 300: loss 0.610839\n",
      "iteration 255 / 300: loss 0.606265\n",
      "iteration 255 / 300: loss 0.583790\n",
      "iteration 255 / 300: loss 0.589627\n",
      "iteration 255 / 300: loss 0.595184\n",
      "iteration 255 / 300: loss 0.598955\n",
      "iteration 255 / 300: loss 0.596133\n",
      "iteration 255 / 300: loss 0.589769\n",
      "iteration 255 / 300: loss 0.591136\n",
      "iteration 255 / 300: loss 0.584854\n",
      "iteration 255 / 300: loss 0.599646\n",
      "iteration 255 / 300: loss 0.598902\n",
      "iteration 255 / 300: loss 0.614282\n",
      "iteration 255 / 300: loss 0.597796\n",
      "iteration 255 / 300: loss 0.599298\n",
      "iteration 255 / 300: loss 0.603317\n",
      "iteration 255 / 300: loss 0.592865\n",
      "iteration 255 / 300: loss 0.592391\n",
      "iteration 255 / 300: loss 0.589041\n",
      "iteration 255 / 300: loss 0.596446\n",
      "iteration 255 / 300: loss 0.605709\n",
      "iteration 255 / 300: loss 0.610562\n",
      "iteration 255 / 300: loss 0.587782\n",
      "iteration 255 / 300: loss 0.599351\n",
      "iteration 255 / 300: loss 0.602792\n",
      "iteration 255 / 300: loss 0.605028\n",
      "iteration 255 / 300: loss 0.603848\n",
      "iteration 255 / 300: loss 0.624144\n",
      "iteration 255 / 300: loss 0.587219\n",
      "iteration 255 / 300: loss 0.580754\n",
      "iteration 255 / 300: loss 0.625045\n",
      "iteration 255 / 300: loss 0.603310\n",
      "iteration 255 / 300: loss 0.604321\n",
      "iteration 255 / 300: loss 0.595476\n",
      "iteration 255 / 300: loss 0.597543\n",
      "iteration 255 / 300: loss 0.592740\n",
      "iteration 255 / 300: loss 0.589494\n",
      "iteration 255 / 300: loss 0.599264\n",
      "iteration 255 / 300: loss 0.611379\n",
      "iteration 255 / 300: loss 0.592463\n",
      "iteration 255 / 300: loss 0.599424\n",
      "iteration 255 / 300: loss 0.603100\n",
      "iteration 255 / 300: loss 0.602410\n",
      "iteration 255 / 300: loss 0.579811\n",
      "iteration 255 / 300: loss 0.601592\n",
      "iteration 256 / 300: loss 0.585528\n",
      "iteration 256 / 300: loss 0.588428\n",
      "iteration 256 / 300: loss 0.567516\n",
      "iteration 256 / 300: loss 0.592380\n",
      "iteration 256 / 300: loss 0.593618\n",
      "iteration 256 / 300: loss 0.595295\n",
      "iteration 256 / 300: loss 0.608784\n",
      "iteration 256 / 300: loss 0.592732\n",
      "iteration 256 / 300: loss 0.628060\n",
      "iteration 256 / 300: loss 0.580152\n",
      "iteration 256 / 300: loss 0.607923\n",
      "iteration 256 / 300: loss 0.587394\n",
      "iteration 256 / 300: loss 0.591686\n",
      "iteration 256 / 300: loss 0.571370\n",
      "iteration 256 / 300: loss 0.583025\n",
      "iteration 256 / 300: loss 0.608441\n",
      "iteration 256 / 300: loss 0.598359\n",
      "iteration 256 / 300: loss 0.583858\n",
      "iteration 256 / 300: loss 0.615253\n",
      "iteration 256 / 300: loss 0.591649\n",
      "iteration 256 / 300: loss 0.585499\n",
      "iteration 256 / 300: loss 0.591325\n",
      "iteration 256 / 300: loss 0.604341\n",
      "iteration 256 / 300: loss 0.595786\n",
      "iteration 256 / 300: loss 0.614949\n",
      "iteration 256 / 300: loss 0.608389\n",
      "iteration 256 / 300: loss 0.598222\n",
      "iteration 256 / 300: loss 0.588936\n",
      "iteration 256 / 300: loss 0.617757\n",
      "iteration 256 / 300: loss 0.594770\n",
      "iteration 256 / 300: loss 0.601684\n",
      "iteration 256 / 300: loss 0.631031\n",
      "iteration 256 / 300: loss 0.587513\n",
      "iteration 256 / 300: loss 0.606561\n",
      "iteration 256 / 300: loss 0.588034\n",
      "iteration 256 / 300: loss 0.600890\n",
      "iteration 256 / 300: loss 0.595958\n",
      "iteration 256 / 300: loss 0.589291\n",
      "iteration 256 / 300: loss 0.599526\n",
      "iteration 256 / 300: loss 0.604855\n",
      "iteration 256 / 300: loss 0.619414\n",
      "iteration 256 / 300: loss 0.588808\n",
      "iteration 256 / 300: loss 0.593645\n",
      "iteration 256 / 300: loss 0.585595\n",
      "iteration 256 / 300: loss 0.613212\n",
      "iteration 256 / 300: loss 0.587523\n",
      "iteration 256 / 300: loss 0.578328\n",
      "iteration 256 / 300: loss 0.567435\n",
      "iteration 256 / 300: loss 0.562235\n",
      "iteration 256 / 300: loss 0.594183\n",
      "iteration 256 / 300: loss 0.578821\n",
      "iteration 256 / 300: loss 0.586360\n",
      "iteration 256 / 300: loss 0.572890\n",
      "iteration 256 / 300: loss 0.596151\n",
      "iteration 256 / 300: loss 0.607951\n",
      "iteration 256 / 300: loss 0.610839\n",
      "iteration 256 / 300: loss 0.606265\n",
      "iteration 256 / 300: loss 0.583790\n",
      "iteration 256 / 300: loss 0.589627\n",
      "iteration 256 / 300: loss 0.595184\n",
      "iteration 256 / 300: loss 0.598955\n",
      "iteration 256 / 300: loss 0.596133\n",
      "iteration 256 / 300: loss 0.589769\n",
      "iteration 256 / 300: loss 0.591136\n",
      "iteration 256 / 300: loss 0.584854\n",
      "iteration 256 / 300: loss 0.599646\n",
      "iteration 256 / 300: loss 0.598902\n",
      "iteration 256 / 300: loss 0.614282\n",
      "iteration 256 / 300: loss 0.597796\n",
      "iteration 256 / 300: loss 0.599298\n",
      "iteration 256 / 300: loss 0.603317\n",
      "iteration 256 / 300: loss 0.592865\n",
      "iteration 256 / 300: loss 0.592391\n",
      "iteration 256 / 300: loss 0.589041\n",
      "iteration 256 / 300: loss 0.596446\n",
      "iteration 256 / 300: loss 0.605709\n",
      "iteration 256 / 300: loss 0.610562\n",
      "iteration 256 / 300: loss 0.587782\n",
      "iteration 256 / 300: loss 0.599351\n",
      "iteration 256 / 300: loss 0.602792\n",
      "iteration 256 / 300: loss 0.605028\n",
      "iteration 256 / 300: loss 0.603848\n",
      "iteration 256 / 300: loss 0.624144\n",
      "iteration 256 / 300: loss 0.587219\n",
      "iteration 256 / 300: loss 0.580754\n",
      "iteration 256 / 300: loss 0.625045\n",
      "iteration 256 / 300: loss 0.603310\n",
      "iteration 256 / 300: loss 0.604321\n",
      "iteration 256 / 300: loss 0.595476\n",
      "iteration 256 / 300: loss 0.597543\n",
      "iteration 256 / 300: loss 0.592740\n",
      "iteration 256 / 300: loss 0.589494\n",
      "iteration 256 / 300: loss 0.599264\n",
      "iteration 256 / 300: loss 0.611379\n",
      "iteration 256 / 300: loss 0.592463\n",
      "iteration 256 / 300: loss 0.599424\n",
      "iteration 256 / 300: loss 0.603100\n",
      "iteration 256 / 300: loss 0.602410\n",
      "iteration 256 / 300: loss 0.579811\n",
      "iteration 256 / 300: loss 0.601592\n",
      "iteration 257 / 300: loss 0.585528\n",
      "iteration 257 / 300: loss 0.588428\n",
      "iteration 257 / 300: loss 0.567516\n",
      "iteration 257 / 300: loss 0.592380\n",
      "iteration 257 / 300: loss 0.593618\n",
      "iteration 257 / 300: loss 0.595295\n",
      "iteration 257 / 300: loss 0.608784\n",
      "iteration 257 / 300: loss 0.592732\n",
      "iteration 257 / 300: loss 0.628060\n",
      "iteration 257 / 300: loss 0.580152\n",
      "iteration 257 / 300: loss 0.607923\n",
      "iteration 257 / 300: loss 0.587394\n",
      "iteration 257 / 300: loss 0.591686\n",
      "iteration 257 / 300: loss 0.571370\n",
      "iteration 257 / 300: loss 0.583025\n",
      "iteration 257 / 300: loss 0.608441\n",
      "iteration 257 / 300: loss 0.598359\n",
      "iteration 257 / 300: loss 0.583858\n",
      "iteration 257 / 300: loss 0.615253\n",
      "iteration 257 / 300: loss 0.591649\n",
      "iteration 257 / 300: loss 0.585499\n",
      "iteration 257 / 300: loss 0.591325\n",
      "iteration 257 / 300: loss 0.604341\n",
      "iteration 257 / 300: loss 0.595786\n",
      "iteration 257 / 300: loss 0.614949\n",
      "iteration 257 / 300: loss 0.608389\n",
      "iteration 257 / 300: loss 0.598222\n",
      "iteration 257 / 300: loss 0.588936\n",
      "iteration 257 / 300: loss 0.617757\n",
      "iteration 257 / 300: loss 0.594770\n",
      "iteration 257 / 300: loss 0.601684\n",
      "iteration 257 / 300: loss 0.631031\n",
      "iteration 257 / 300: loss 0.587513\n",
      "iteration 257 / 300: loss 0.606561\n",
      "iteration 257 / 300: loss 0.588034\n",
      "iteration 257 / 300: loss 0.600890\n",
      "iteration 257 / 300: loss 0.595958\n",
      "iteration 257 / 300: loss 0.589291\n",
      "iteration 257 / 300: loss 0.599526\n",
      "iteration 257 / 300: loss 0.604855\n",
      "iteration 257 / 300: loss 0.619414\n",
      "iteration 257 / 300: loss 0.588808\n",
      "iteration 257 / 300: loss 0.593645\n",
      "iteration 257 / 300: loss 0.585595\n",
      "iteration 257 / 300: loss 0.613212\n",
      "iteration 257 / 300: loss 0.587523\n",
      "iteration 257 / 300: loss 0.578328\n",
      "iteration 257 / 300: loss 0.567435\n",
      "iteration 257 / 300: loss 0.562235\n",
      "iteration 257 / 300: loss 0.594183\n",
      "iteration 257 / 300: loss 0.578821\n",
      "iteration 257 / 300: loss 0.586360\n",
      "iteration 257 / 300: loss 0.572890\n",
      "iteration 257 / 300: loss 0.596151\n",
      "iteration 257 / 300: loss 0.607951\n",
      "iteration 257 / 300: loss 0.610839\n",
      "iteration 257 / 300: loss 0.606265\n",
      "iteration 257 / 300: loss 0.583790\n",
      "iteration 257 / 300: loss 0.589627\n",
      "iteration 257 / 300: loss 0.595184\n",
      "iteration 257 / 300: loss 0.598955\n",
      "iteration 257 / 300: loss 0.596133\n",
      "iteration 257 / 300: loss 0.589769\n",
      "iteration 257 / 300: loss 0.591136\n",
      "iteration 257 / 300: loss 0.584854\n",
      "iteration 257 / 300: loss 0.599646\n",
      "iteration 257 / 300: loss 0.598902\n",
      "iteration 257 / 300: loss 0.614282\n",
      "iteration 257 / 300: loss 0.597796\n",
      "iteration 257 / 300: loss 0.599298\n",
      "iteration 257 / 300: loss 0.603317\n",
      "iteration 257 / 300: loss 0.592865\n",
      "iteration 257 / 300: loss 0.592391\n",
      "iteration 257 / 300: loss 0.589041\n",
      "iteration 257 / 300: loss 0.596446\n",
      "iteration 257 / 300: loss 0.605709\n",
      "iteration 257 / 300: loss 0.610562\n",
      "iteration 257 / 300: loss 0.587782\n",
      "iteration 257 / 300: loss 0.599351\n",
      "iteration 257 / 300: loss 0.602792\n",
      "iteration 257 / 300: loss 0.605028\n",
      "iteration 257 / 300: loss 0.603848\n",
      "iteration 257 / 300: loss 0.624144\n",
      "iteration 257 / 300: loss 0.587219\n",
      "iteration 257 / 300: loss 0.580754\n",
      "iteration 257 / 300: loss 0.625045\n",
      "iteration 257 / 300: loss 0.603310\n",
      "iteration 257 / 300: loss 0.604321\n",
      "iteration 257 / 300: loss 0.595476\n",
      "iteration 257 / 300: loss 0.597543\n",
      "iteration 257 / 300: loss 0.592740\n",
      "iteration 257 / 300: loss 0.589494\n",
      "iteration 257 / 300: loss 0.599264\n",
      "iteration 257 / 300: loss 0.611379\n",
      "iteration 257 / 300: loss 0.592463\n",
      "iteration 257 / 300: loss 0.599424\n",
      "iteration 257 / 300: loss 0.603100\n",
      "iteration 257 / 300: loss 0.602410\n",
      "iteration 257 / 300: loss 0.579811\n",
      "iteration 257 / 300: loss 0.601592\n",
      "iteration 258 / 300: loss 0.585528\n",
      "iteration 258 / 300: loss 0.588428\n",
      "iteration 258 / 300: loss 0.567516\n",
      "iteration 258 / 300: loss 0.592380\n",
      "iteration 258 / 300: loss 0.593618\n",
      "iteration 258 / 300: loss 0.595295\n",
      "iteration 258 / 300: loss 0.608784\n",
      "iteration 258 / 300: loss 0.592732\n",
      "iteration 258 / 300: loss 0.628060\n",
      "iteration 258 / 300: loss 0.580152\n",
      "iteration 258 / 300: loss 0.607923\n",
      "iteration 258 / 300: loss 0.587394\n",
      "iteration 258 / 300: loss 0.591686\n",
      "iteration 258 / 300: loss 0.571370\n",
      "iteration 258 / 300: loss 0.583025\n",
      "iteration 258 / 300: loss 0.608441\n",
      "iteration 258 / 300: loss 0.598359\n",
      "iteration 258 / 300: loss 0.583858\n",
      "iteration 258 / 300: loss 0.615253\n",
      "iteration 258 / 300: loss 0.591649\n",
      "iteration 258 / 300: loss 0.585499\n",
      "iteration 258 / 300: loss 0.591325\n",
      "iteration 258 / 300: loss 0.604341\n",
      "iteration 258 / 300: loss 0.595786\n",
      "iteration 258 / 300: loss 0.614949\n",
      "iteration 258 / 300: loss 0.608389\n",
      "iteration 258 / 300: loss 0.598222\n",
      "iteration 258 / 300: loss 0.588936\n",
      "iteration 258 / 300: loss 0.617757\n",
      "iteration 258 / 300: loss 0.594770\n",
      "iteration 258 / 300: loss 0.601684\n",
      "iteration 258 / 300: loss 0.631031\n",
      "iteration 258 / 300: loss 0.587513\n",
      "iteration 258 / 300: loss 0.606561\n",
      "iteration 258 / 300: loss 0.588034\n",
      "iteration 258 / 300: loss 0.600890\n",
      "iteration 258 / 300: loss 0.595958\n",
      "iteration 258 / 300: loss 0.589291\n",
      "iteration 258 / 300: loss 0.599526\n",
      "iteration 258 / 300: loss 0.604855\n",
      "iteration 258 / 300: loss 0.619414\n",
      "iteration 258 / 300: loss 0.588808\n",
      "iteration 258 / 300: loss 0.593645\n",
      "iteration 258 / 300: loss 0.585595\n",
      "iteration 258 / 300: loss 0.613212\n",
      "iteration 258 / 300: loss 0.587523\n",
      "iteration 258 / 300: loss 0.578328\n",
      "iteration 258 / 300: loss 0.567435\n",
      "iteration 258 / 300: loss 0.562235\n",
      "iteration 258 / 300: loss 0.594183\n",
      "iteration 258 / 300: loss 0.578821\n",
      "iteration 258 / 300: loss 0.586360\n",
      "iteration 258 / 300: loss 0.572890\n",
      "iteration 258 / 300: loss 0.596151\n",
      "iteration 258 / 300: loss 0.607951\n",
      "iteration 258 / 300: loss 0.610839\n",
      "iteration 258 / 300: loss 0.606265\n",
      "iteration 258 / 300: loss 0.583790\n",
      "iteration 258 / 300: loss 0.589627\n",
      "iteration 258 / 300: loss 0.595184\n",
      "iteration 258 / 300: loss 0.598955\n",
      "iteration 258 / 300: loss 0.596133\n",
      "iteration 258 / 300: loss 0.589769\n",
      "iteration 258 / 300: loss 0.591136\n",
      "iteration 258 / 300: loss 0.584854\n",
      "iteration 258 / 300: loss 0.599646\n",
      "iteration 258 / 300: loss 0.598902\n",
      "iteration 258 / 300: loss 0.614282\n",
      "iteration 258 / 300: loss 0.597796\n",
      "iteration 258 / 300: loss 0.599298\n",
      "iteration 258 / 300: loss 0.603317\n",
      "iteration 258 / 300: loss 0.592865\n",
      "iteration 258 / 300: loss 0.592391\n",
      "iteration 258 / 300: loss 0.589041\n",
      "iteration 258 / 300: loss 0.596446\n",
      "iteration 258 / 300: loss 0.605709\n",
      "iteration 258 / 300: loss 0.610562\n",
      "iteration 258 / 300: loss 0.587782\n",
      "iteration 258 / 300: loss 0.599351\n",
      "iteration 258 / 300: loss 0.602792\n",
      "iteration 258 / 300: loss 0.605028\n",
      "iteration 258 / 300: loss 0.603848\n",
      "iteration 258 / 300: loss 0.624144\n",
      "iteration 258 / 300: loss 0.587219\n",
      "iteration 258 / 300: loss 0.580754\n",
      "iteration 258 / 300: loss 0.625045\n",
      "iteration 258 / 300: loss 0.603310\n",
      "iteration 258 / 300: loss 0.604321\n",
      "iteration 258 / 300: loss 0.595476\n",
      "iteration 258 / 300: loss 0.597543\n",
      "iteration 258 / 300: loss 0.592740\n",
      "iteration 258 / 300: loss 0.589494\n",
      "iteration 258 / 300: loss 0.599264\n",
      "iteration 258 / 300: loss 0.611379\n",
      "iteration 258 / 300: loss 0.592463\n",
      "iteration 258 / 300: loss 0.599424\n",
      "iteration 258 / 300: loss 0.603100\n",
      "iteration 258 / 300: loss 0.602410\n",
      "iteration 258 / 300: loss 0.579811\n",
      "iteration 258 / 300: loss 0.601592\n",
      "iteration 259 / 300: loss 0.585528\n",
      "iteration 259 / 300: loss 0.588428\n",
      "iteration 259 / 300: loss 0.567516\n",
      "iteration 259 / 300: loss 0.592380\n",
      "iteration 259 / 300: loss 0.593618\n",
      "iteration 259 / 300: loss 0.595295\n",
      "iteration 259 / 300: loss 0.608784\n",
      "iteration 259 / 300: loss 0.592732\n",
      "iteration 259 / 300: loss 0.628060\n",
      "iteration 259 / 300: loss 0.580152\n",
      "iteration 259 / 300: loss 0.607923\n",
      "iteration 259 / 300: loss 0.587394\n",
      "iteration 259 / 300: loss 0.591686\n",
      "iteration 259 / 300: loss 0.571370\n",
      "iteration 259 / 300: loss 0.583025\n",
      "iteration 259 / 300: loss 0.608441\n",
      "iteration 259 / 300: loss 0.598359\n",
      "iteration 259 / 300: loss 0.583858\n",
      "iteration 259 / 300: loss 0.615253\n",
      "iteration 259 / 300: loss 0.591649\n",
      "iteration 259 / 300: loss 0.585499\n",
      "iteration 259 / 300: loss 0.591325\n",
      "iteration 259 / 300: loss 0.604341\n",
      "iteration 259 / 300: loss 0.595786\n",
      "iteration 259 / 300: loss 0.614949\n",
      "iteration 259 / 300: loss 0.608389\n",
      "iteration 259 / 300: loss 0.598222\n",
      "iteration 259 / 300: loss 0.588936\n",
      "iteration 259 / 300: loss 0.617757\n",
      "iteration 259 / 300: loss 0.594770\n",
      "iteration 259 / 300: loss 0.601684\n",
      "iteration 259 / 300: loss 0.631031\n",
      "iteration 259 / 300: loss 0.587513\n",
      "iteration 259 / 300: loss 0.606561\n",
      "iteration 259 / 300: loss 0.588034\n",
      "iteration 259 / 300: loss 0.600890\n",
      "iteration 259 / 300: loss 0.595958\n",
      "iteration 259 / 300: loss 0.589291\n",
      "iteration 259 / 300: loss 0.599526\n",
      "iteration 259 / 300: loss 0.604855\n",
      "iteration 259 / 300: loss 0.619414\n",
      "iteration 259 / 300: loss 0.588808\n",
      "iteration 259 / 300: loss 0.593645\n",
      "iteration 259 / 300: loss 0.585595\n",
      "iteration 259 / 300: loss 0.613212\n",
      "iteration 259 / 300: loss 0.587523\n",
      "iteration 259 / 300: loss 0.578328\n",
      "iteration 259 / 300: loss 0.567435\n",
      "iteration 259 / 300: loss 0.562235\n",
      "iteration 259 / 300: loss 0.594183\n",
      "iteration 259 / 300: loss 0.578821\n",
      "iteration 259 / 300: loss 0.586360\n",
      "iteration 259 / 300: loss 0.572890\n",
      "iteration 259 / 300: loss 0.596151\n",
      "iteration 259 / 300: loss 0.607951\n",
      "iteration 259 / 300: loss 0.610839\n",
      "iteration 259 / 300: loss 0.606265\n",
      "iteration 259 / 300: loss 0.583790\n",
      "iteration 259 / 300: loss 0.589627\n",
      "iteration 259 / 300: loss 0.595184\n",
      "iteration 259 / 300: loss 0.598955\n",
      "iteration 259 / 300: loss 0.596133\n",
      "iteration 259 / 300: loss 0.589769\n",
      "iteration 259 / 300: loss 0.591136\n",
      "iteration 259 / 300: loss 0.584854\n",
      "iteration 259 / 300: loss 0.599646\n",
      "iteration 259 / 300: loss 0.598902\n",
      "iteration 259 / 300: loss 0.614282\n",
      "iteration 259 / 300: loss 0.597796\n",
      "iteration 259 / 300: loss 0.599298\n",
      "iteration 259 / 300: loss 0.603317\n",
      "iteration 259 / 300: loss 0.592865\n",
      "iteration 259 / 300: loss 0.592391\n",
      "iteration 259 / 300: loss 0.589041\n",
      "iteration 259 / 300: loss 0.596446\n",
      "iteration 259 / 300: loss 0.605709\n",
      "iteration 259 / 300: loss 0.610562\n",
      "iteration 259 / 300: loss 0.587782\n",
      "iteration 259 / 300: loss 0.599351\n",
      "iteration 259 / 300: loss 0.602792\n",
      "iteration 259 / 300: loss 0.605028\n",
      "iteration 259 / 300: loss 0.603848\n",
      "iteration 259 / 300: loss 0.624144\n",
      "iteration 259 / 300: loss 0.587219\n",
      "iteration 259 / 300: loss 0.580754\n",
      "iteration 259 / 300: loss 0.625045\n",
      "iteration 259 / 300: loss 0.603310\n",
      "iteration 259 / 300: loss 0.604321\n",
      "iteration 259 / 300: loss 0.595476\n",
      "iteration 259 / 300: loss 0.597543\n",
      "iteration 259 / 300: loss 0.592740\n",
      "iteration 259 / 300: loss 0.589494\n",
      "iteration 259 / 300: loss 0.599264\n",
      "iteration 259 / 300: loss 0.611379\n",
      "iteration 259 / 300: loss 0.592463\n",
      "iteration 259 / 300: loss 0.599424\n",
      "iteration 259 / 300: loss 0.603100\n",
      "iteration 259 / 300: loss 0.602410\n",
      "iteration 259 / 300: loss 0.579811\n",
      "iteration 259 / 300: loss 0.601592\n",
      "iteration 260 / 300: loss 0.585528\n",
      "iteration 260 / 300: loss 0.588428\n",
      "iteration 260 / 300: loss 0.567516\n",
      "iteration 260 / 300: loss 0.592380\n",
      "iteration 260 / 300: loss 0.593618\n",
      "iteration 260 / 300: loss 0.595295\n",
      "iteration 260 / 300: loss 0.608784\n",
      "iteration 260 / 300: loss 0.592732\n",
      "iteration 260 / 300: loss 0.628060\n",
      "iteration 260 / 300: loss 0.580152\n",
      "iteration 260 / 300: loss 0.607923\n",
      "iteration 260 / 300: loss 0.587394\n",
      "iteration 260 / 300: loss 0.591686\n",
      "iteration 260 / 300: loss 0.571370\n",
      "iteration 260 / 300: loss 0.583025\n",
      "iteration 260 / 300: loss 0.608441\n",
      "iteration 260 / 300: loss 0.598359\n",
      "iteration 260 / 300: loss 0.583858\n",
      "iteration 260 / 300: loss 0.615253\n",
      "iteration 260 / 300: loss 0.591649\n",
      "iteration 260 / 300: loss 0.585499\n",
      "iteration 260 / 300: loss 0.591325\n",
      "iteration 260 / 300: loss 0.604341\n",
      "iteration 260 / 300: loss 0.595786\n",
      "iteration 260 / 300: loss 0.614949\n",
      "iteration 260 / 300: loss 0.608389\n",
      "iteration 260 / 300: loss 0.598222\n",
      "iteration 260 / 300: loss 0.588936\n",
      "iteration 260 / 300: loss 0.617757\n",
      "iteration 260 / 300: loss 0.594770\n",
      "iteration 260 / 300: loss 0.601684\n",
      "iteration 260 / 300: loss 0.631031\n",
      "iteration 260 / 300: loss 0.587513\n",
      "iteration 260 / 300: loss 0.606561\n",
      "iteration 260 / 300: loss 0.588034\n",
      "iteration 260 / 300: loss 0.600890\n",
      "iteration 260 / 300: loss 0.595958\n",
      "iteration 260 / 300: loss 0.589291\n",
      "iteration 260 / 300: loss 0.599526\n",
      "iteration 260 / 300: loss 0.604855\n",
      "iteration 260 / 300: loss 0.619414\n",
      "iteration 260 / 300: loss 0.588808\n",
      "iteration 260 / 300: loss 0.593645\n",
      "iteration 260 / 300: loss 0.585595\n",
      "iteration 260 / 300: loss 0.613212\n",
      "iteration 260 / 300: loss 0.587523\n",
      "iteration 260 / 300: loss 0.578328\n",
      "iteration 260 / 300: loss 0.567435\n",
      "iteration 260 / 300: loss 0.562235\n",
      "iteration 260 / 300: loss 0.594183\n",
      "iteration 260 / 300: loss 0.578821\n",
      "iteration 260 / 300: loss 0.586360\n",
      "iteration 260 / 300: loss 0.572890\n",
      "iteration 260 / 300: loss 0.596151\n",
      "iteration 260 / 300: loss 0.607951\n",
      "iteration 260 / 300: loss 0.610839\n",
      "iteration 260 / 300: loss 0.606265\n",
      "iteration 260 / 300: loss 0.583790\n",
      "iteration 260 / 300: loss 0.589627\n",
      "iteration 260 / 300: loss 0.595184\n",
      "iteration 260 / 300: loss 0.598955\n",
      "iteration 260 / 300: loss 0.596133\n",
      "iteration 260 / 300: loss 0.589769\n",
      "iteration 260 / 300: loss 0.591136\n",
      "iteration 260 / 300: loss 0.584854\n",
      "iteration 260 / 300: loss 0.599646\n",
      "iteration 260 / 300: loss 0.598902\n",
      "iteration 260 / 300: loss 0.614282\n",
      "iteration 260 / 300: loss 0.597796\n",
      "iteration 260 / 300: loss 0.599298\n",
      "iteration 260 / 300: loss 0.603317\n",
      "iteration 260 / 300: loss 0.592865\n",
      "iteration 260 / 300: loss 0.592391\n",
      "iteration 260 / 300: loss 0.589041\n",
      "iteration 260 / 300: loss 0.596446\n",
      "iteration 260 / 300: loss 0.605709\n",
      "iteration 260 / 300: loss 0.610562\n",
      "iteration 260 / 300: loss 0.587782\n",
      "iteration 260 / 300: loss 0.599351\n",
      "iteration 260 / 300: loss 0.602792\n",
      "iteration 260 / 300: loss 0.605028\n",
      "iteration 260 / 300: loss 0.603848\n",
      "iteration 260 / 300: loss 0.624144\n",
      "iteration 260 / 300: loss 0.587219\n",
      "iteration 260 / 300: loss 0.580754\n",
      "iteration 260 / 300: loss 0.625045\n",
      "iteration 260 / 300: loss 0.603310\n",
      "iteration 260 / 300: loss 0.604321\n",
      "iteration 260 / 300: loss 0.595476\n",
      "iteration 260 / 300: loss 0.597543\n",
      "iteration 260 / 300: loss 0.592740\n",
      "iteration 260 / 300: loss 0.589494\n",
      "iteration 260 / 300: loss 0.599264\n",
      "iteration 260 / 300: loss 0.611379\n",
      "iteration 260 / 300: loss 0.592463\n",
      "iteration 260 / 300: loss 0.599424\n",
      "iteration 260 / 300: loss 0.603100\n",
      "iteration 260 / 300: loss 0.602410\n",
      "iteration 260 / 300: loss 0.579811\n",
      "iteration 260 / 300: loss 0.601592\n",
      "iteration 261 / 300: loss 0.585528\n",
      "iteration 261 / 300: loss 0.588428\n",
      "iteration 261 / 300: loss 0.567516\n",
      "iteration 261 / 300: loss 0.592380\n",
      "iteration 261 / 300: loss 0.593618\n",
      "iteration 261 / 300: loss 0.595295\n",
      "iteration 261 / 300: loss 0.608784\n",
      "iteration 261 / 300: loss 0.592732\n",
      "iteration 261 / 300: loss 0.628060\n",
      "iteration 261 / 300: loss 0.580152\n",
      "iteration 261 / 300: loss 0.607923\n",
      "iteration 261 / 300: loss 0.587394\n",
      "iteration 261 / 300: loss 0.591686\n",
      "iteration 261 / 300: loss 0.571370\n",
      "iteration 261 / 300: loss 0.583025\n",
      "iteration 261 / 300: loss 0.608441\n",
      "iteration 261 / 300: loss 0.598359\n",
      "iteration 261 / 300: loss 0.583858\n",
      "iteration 261 / 300: loss 0.615253\n",
      "iteration 261 / 300: loss 0.591649\n",
      "iteration 261 / 300: loss 0.585499\n",
      "iteration 261 / 300: loss 0.591325\n",
      "iteration 261 / 300: loss 0.604341\n",
      "iteration 261 / 300: loss 0.595786\n",
      "iteration 261 / 300: loss 0.614949\n",
      "iteration 261 / 300: loss 0.608389\n",
      "iteration 261 / 300: loss 0.598222\n",
      "iteration 261 / 300: loss 0.588936\n",
      "iteration 261 / 300: loss 0.617757\n",
      "iteration 261 / 300: loss 0.594770\n",
      "iteration 261 / 300: loss 0.601684\n",
      "iteration 261 / 300: loss 0.631031\n",
      "iteration 261 / 300: loss 0.587513\n",
      "iteration 261 / 300: loss 0.606561\n",
      "iteration 261 / 300: loss 0.588034\n",
      "iteration 261 / 300: loss 0.600890\n",
      "iteration 261 / 300: loss 0.595958\n",
      "iteration 261 / 300: loss 0.589291\n",
      "iteration 261 / 300: loss 0.599526\n",
      "iteration 261 / 300: loss 0.604855\n",
      "iteration 261 / 300: loss 0.619414\n",
      "iteration 261 / 300: loss 0.588808\n",
      "iteration 261 / 300: loss 0.593645\n",
      "iteration 261 / 300: loss 0.585595\n",
      "iteration 261 / 300: loss 0.613212\n",
      "iteration 261 / 300: loss 0.587523\n",
      "iteration 261 / 300: loss 0.578328\n",
      "iteration 261 / 300: loss 0.567435\n",
      "iteration 261 / 300: loss 0.562235\n",
      "iteration 261 / 300: loss 0.594183\n",
      "iteration 261 / 300: loss 0.578821\n",
      "iteration 261 / 300: loss 0.586360\n",
      "iteration 261 / 300: loss 0.572890\n",
      "iteration 261 / 300: loss 0.596151\n",
      "iteration 261 / 300: loss 0.607951\n",
      "iteration 261 / 300: loss 0.610839\n",
      "iteration 261 / 300: loss 0.606265\n",
      "iteration 261 / 300: loss 0.583790\n",
      "iteration 261 / 300: loss 0.589627\n",
      "iteration 261 / 300: loss 0.595184\n",
      "iteration 261 / 300: loss 0.598955\n",
      "iteration 261 / 300: loss 0.596133\n",
      "iteration 261 / 300: loss 0.589769\n",
      "iteration 261 / 300: loss 0.591136\n",
      "iteration 261 / 300: loss 0.584854\n",
      "iteration 261 / 300: loss 0.599646\n",
      "iteration 261 / 300: loss 0.598902\n",
      "iteration 261 / 300: loss 0.614282\n",
      "iteration 261 / 300: loss 0.597796\n",
      "iteration 261 / 300: loss 0.599298\n",
      "iteration 261 / 300: loss 0.603317\n",
      "iteration 261 / 300: loss 0.592865\n",
      "iteration 261 / 300: loss 0.592391\n",
      "iteration 261 / 300: loss 0.589041\n",
      "iteration 261 / 300: loss 0.596446\n",
      "iteration 261 / 300: loss 0.605709\n",
      "iteration 261 / 300: loss 0.610562\n",
      "iteration 261 / 300: loss 0.587782\n",
      "iteration 261 / 300: loss 0.599351\n",
      "iteration 261 / 300: loss 0.602792\n",
      "iteration 261 / 300: loss 0.605028\n",
      "iteration 261 / 300: loss 0.603848\n",
      "iteration 261 / 300: loss 0.624144\n",
      "iteration 261 / 300: loss 0.587219\n",
      "iteration 261 / 300: loss 0.580754\n",
      "iteration 261 / 300: loss 0.625045\n",
      "iteration 261 / 300: loss 0.603310\n",
      "iteration 261 / 300: loss 0.604321\n",
      "iteration 261 / 300: loss 0.595476\n",
      "iteration 261 / 300: loss 0.597543\n",
      "iteration 261 / 300: loss 0.592740\n",
      "iteration 261 / 300: loss 0.589494\n",
      "iteration 261 / 300: loss 0.599264\n",
      "iteration 261 / 300: loss 0.611379\n",
      "iteration 261 / 300: loss 0.592463\n",
      "iteration 261 / 300: loss 0.599424\n",
      "iteration 261 / 300: loss 0.603100\n",
      "iteration 261 / 300: loss 0.602410\n",
      "iteration 261 / 300: loss 0.579811\n",
      "iteration 261 / 300: loss 0.601592\n",
      "iteration 262 / 300: loss 0.585528\n",
      "iteration 262 / 300: loss 0.588428\n",
      "iteration 262 / 300: loss 0.567516\n",
      "iteration 262 / 300: loss 0.592380\n",
      "iteration 262 / 300: loss 0.593618\n",
      "iteration 262 / 300: loss 0.595295\n",
      "iteration 262 / 300: loss 0.608784\n",
      "iteration 262 / 300: loss 0.592732\n",
      "iteration 262 / 300: loss 0.628060\n",
      "iteration 262 / 300: loss 0.580152\n",
      "iteration 262 / 300: loss 0.607923\n",
      "iteration 262 / 300: loss 0.587394\n",
      "iteration 262 / 300: loss 0.591686\n",
      "iteration 262 / 300: loss 0.571370\n",
      "iteration 262 / 300: loss 0.583025\n",
      "iteration 262 / 300: loss 0.608441\n",
      "iteration 262 / 300: loss 0.598359\n",
      "iteration 262 / 300: loss 0.583858\n",
      "iteration 262 / 300: loss 0.615253\n",
      "iteration 262 / 300: loss 0.591649\n",
      "iteration 262 / 300: loss 0.585499\n",
      "iteration 262 / 300: loss 0.591325\n",
      "iteration 262 / 300: loss 0.604341\n",
      "iteration 262 / 300: loss 0.595786\n",
      "iteration 262 / 300: loss 0.614949\n",
      "iteration 262 / 300: loss 0.608389\n",
      "iteration 262 / 300: loss 0.598222\n",
      "iteration 262 / 300: loss 0.588936\n",
      "iteration 262 / 300: loss 0.617757\n",
      "iteration 262 / 300: loss 0.594770\n",
      "iteration 262 / 300: loss 0.601684\n",
      "iteration 262 / 300: loss 0.631031\n",
      "iteration 262 / 300: loss 0.587513\n",
      "iteration 262 / 300: loss 0.606561\n",
      "iteration 262 / 300: loss 0.588034\n",
      "iteration 262 / 300: loss 0.600890\n",
      "iteration 262 / 300: loss 0.595958\n",
      "iteration 262 / 300: loss 0.589291\n",
      "iteration 262 / 300: loss 0.599526\n",
      "iteration 262 / 300: loss 0.604855\n",
      "iteration 262 / 300: loss 0.619414\n",
      "iteration 262 / 300: loss 0.588808\n",
      "iteration 262 / 300: loss 0.593645\n",
      "iteration 262 / 300: loss 0.585595\n",
      "iteration 262 / 300: loss 0.613212\n",
      "iteration 262 / 300: loss 0.587523\n",
      "iteration 262 / 300: loss 0.578328\n",
      "iteration 262 / 300: loss 0.567435\n",
      "iteration 262 / 300: loss 0.562235\n",
      "iteration 262 / 300: loss 0.594183\n",
      "iteration 262 / 300: loss 0.578821\n",
      "iteration 262 / 300: loss 0.586360\n",
      "iteration 262 / 300: loss 0.572890\n",
      "iteration 262 / 300: loss 0.596151\n",
      "iteration 262 / 300: loss 0.607951\n",
      "iteration 262 / 300: loss 0.610839\n",
      "iteration 262 / 300: loss 0.606265\n",
      "iteration 262 / 300: loss 0.583790\n",
      "iteration 262 / 300: loss 0.589627\n",
      "iteration 262 / 300: loss 0.595184\n",
      "iteration 262 / 300: loss 0.598955\n",
      "iteration 262 / 300: loss 0.596133\n",
      "iteration 262 / 300: loss 0.589769\n",
      "iteration 262 / 300: loss 0.591136\n",
      "iteration 262 / 300: loss 0.584854\n",
      "iteration 262 / 300: loss 0.599646\n",
      "iteration 262 / 300: loss 0.598902\n",
      "iteration 262 / 300: loss 0.614282\n",
      "iteration 262 / 300: loss 0.597796\n",
      "iteration 262 / 300: loss 0.599298\n",
      "iteration 262 / 300: loss 0.603317\n",
      "iteration 262 / 300: loss 0.592865\n",
      "iteration 262 / 300: loss 0.592391\n",
      "iteration 262 / 300: loss 0.589041\n",
      "iteration 262 / 300: loss 0.596446\n",
      "iteration 262 / 300: loss 0.605709\n",
      "iteration 262 / 300: loss 0.610562\n",
      "iteration 262 / 300: loss 0.587782\n",
      "iteration 262 / 300: loss 0.599351\n",
      "iteration 262 / 300: loss 0.602792\n",
      "iteration 262 / 300: loss 0.605028\n",
      "iteration 262 / 300: loss 0.603848\n",
      "iteration 262 / 300: loss 0.624144\n",
      "iteration 262 / 300: loss 0.587219\n",
      "iteration 262 / 300: loss 0.580754\n",
      "iteration 262 / 300: loss 0.625045\n",
      "iteration 262 / 300: loss 0.603310\n",
      "iteration 262 / 300: loss 0.604321\n",
      "iteration 262 / 300: loss 0.595476\n",
      "iteration 262 / 300: loss 0.597543\n",
      "iteration 262 / 300: loss 0.592740\n",
      "iteration 262 / 300: loss 0.589494\n",
      "iteration 262 / 300: loss 0.599264\n",
      "iteration 262 / 300: loss 0.611379\n",
      "iteration 262 / 300: loss 0.592463\n",
      "iteration 262 / 300: loss 0.599424\n",
      "iteration 262 / 300: loss 0.603100\n",
      "iteration 262 / 300: loss 0.602410\n",
      "iteration 262 / 300: loss 0.579811\n",
      "iteration 262 / 300: loss 0.601592\n",
      "iteration 263 / 300: loss 0.585528\n",
      "iteration 263 / 300: loss 0.588428\n",
      "iteration 263 / 300: loss 0.567516\n",
      "iteration 263 / 300: loss 0.592380\n",
      "iteration 263 / 300: loss 0.593618\n",
      "iteration 263 / 300: loss 0.595295\n",
      "iteration 263 / 300: loss 0.608784\n",
      "iteration 263 / 300: loss 0.592732\n",
      "iteration 263 / 300: loss 0.628060\n",
      "iteration 263 / 300: loss 0.580152\n",
      "iteration 263 / 300: loss 0.607923\n",
      "iteration 263 / 300: loss 0.587394\n",
      "iteration 263 / 300: loss 0.591686\n",
      "iteration 263 / 300: loss 0.571370\n",
      "iteration 263 / 300: loss 0.583025\n",
      "iteration 263 / 300: loss 0.608441\n",
      "iteration 263 / 300: loss 0.598359\n",
      "iteration 263 / 300: loss 0.583858\n",
      "iteration 263 / 300: loss 0.615253\n",
      "iteration 263 / 300: loss 0.591649\n",
      "iteration 263 / 300: loss 0.585499\n",
      "iteration 263 / 300: loss 0.591325\n",
      "iteration 263 / 300: loss 0.604341\n",
      "iteration 263 / 300: loss 0.595786\n",
      "iteration 263 / 300: loss 0.614949\n",
      "iteration 263 / 300: loss 0.608389\n",
      "iteration 263 / 300: loss 0.598222\n",
      "iteration 263 / 300: loss 0.588936\n",
      "iteration 263 / 300: loss 0.617757\n",
      "iteration 263 / 300: loss 0.594770\n",
      "iteration 263 / 300: loss 0.601684\n",
      "iteration 263 / 300: loss 0.631031\n",
      "iteration 263 / 300: loss 0.587513\n",
      "iteration 263 / 300: loss 0.606561\n",
      "iteration 263 / 300: loss 0.588034\n",
      "iteration 263 / 300: loss 0.600890\n",
      "iteration 263 / 300: loss 0.595958\n",
      "iteration 263 / 300: loss 0.589291\n",
      "iteration 263 / 300: loss 0.599526\n",
      "iteration 263 / 300: loss 0.604855\n",
      "iteration 263 / 300: loss 0.619414\n",
      "iteration 263 / 300: loss 0.588808\n",
      "iteration 263 / 300: loss 0.593645\n",
      "iteration 263 / 300: loss 0.585595\n",
      "iteration 263 / 300: loss 0.613212\n",
      "iteration 263 / 300: loss 0.587523\n",
      "iteration 263 / 300: loss 0.578328\n",
      "iteration 263 / 300: loss 0.567435\n",
      "iteration 263 / 300: loss 0.562235\n",
      "iteration 263 / 300: loss 0.594183\n",
      "iteration 263 / 300: loss 0.578821\n",
      "iteration 263 / 300: loss 0.586360\n",
      "iteration 263 / 300: loss 0.572890\n",
      "iteration 263 / 300: loss 0.596151\n",
      "iteration 263 / 300: loss 0.607951\n",
      "iteration 263 / 300: loss 0.610839\n",
      "iteration 263 / 300: loss 0.606265\n",
      "iteration 263 / 300: loss 0.583790\n",
      "iteration 263 / 300: loss 0.589627\n",
      "iteration 263 / 300: loss 0.595184\n",
      "iteration 263 / 300: loss 0.598955\n",
      "iteration 263 / 300: loss 0.596133\n",
      "iteration 263 / 300: loss 0.589769\n",
      "iteration 263 / 300: loss 0.591136\n",
      "iteration 263 / 300: loss 0.584854\n",
      "iteration 263 / 300: loss 0.599646\n",
      "iteration 263 / 300: loss 0.598902\n",
      "iteration 263 / 300: loss 0.614282\n",
      "iteration 263 / 300: loss 0.597796\n",
      "iteration 263 / 300: loss 0.599298\n",
      "iteration 263 / 300: loss 0.603317\n",
      "iteration 263 / 300: loss 0.592865\n",
      "iteration 263 / 300: loss 0.592391\n",
      "iteration 263 / 300: loss 0.589041\n",
      "iteration 263 / 300: loss 0.596446\n",
      "iteration 263 / 300: loss 0.605709\n",
      "iteration 263 / 300: loss 0.610562\n",
      "iteration 263 / 300: loss 0.587782\n",
      "iteration 263 / 300: loss 0.599351\n",
      "iteration 263 / 300: loss 0.602792\n",
      "iteration 263 / 300: loss 0.605028\n",
      "iteration 263 / 300: loss 0.603848\n",
      "iteration 263 / 300: loss 0.624144\n",
      "iteration 263 / 300: loss 0.587219\n",
      "iteration 263 / 300: loss 0.580754\n",
      "iteration 263 / 300: loss 0.625045\n",
      "iteration 263 / 300: loss 0.603310\n",
      "iteration 263 / 300: loss 0.604321\n",
      "iteration 263 / 300: loss 0.595476\n",
      "iteration 263 / 300: loss 0.597543\n",
      "iteration 263 / 300: loss 0.592740\n",
      "iteration 263 / 300: loss 0.589494\n",
      "iteration 263 / 300: loss 0.599264\n",
      "iteration 263 / 300: loss 0.611379\n",
      "iteration 263 / 300: loss 0.592463\n",
      "iteration 263 / 300: loss 0.599424\n",
      "iteration 263 / 300: loss 0.603100\n",
      "iteration 263 / 300: loss 0.602410\n",
      "iteration 263 / 300: loss 0.579811\n",
      "iteration 263 / 300: loss 0.601592\n",
      "iteration 264 / 300: loss 0.585528\n",
      "iteration 264 / 300: loss 0.588428\n",
      "iteration 264 / 300: loss 0.567516\n",
      "iteration 264 / 300: loss 0.592380\n",
      "iteration 264 / 300: loss 0.593618\n",
      "iteration 264 / 300: loss 0.595295\n",
      "iteration 264 / 300: loss 0.608784\n",
      "iteration 264 / 300: loss 0.592732\n",
      "iteration 264 / 300: loss 0.628060\n",
      "iteration 264 / 300: loss 0.580152\n",
      "iteration 264 / 300: loss 0.607923\n",
      "iteration 264 / 300: loss 0.587394\n",
      "iteration 264 / 300: loss 0.591686\n",
      "iteration 264 / 300: loss 0.571370\n",
      "iteration 264 / 300: loss 0.583025\n",
      "iteration 264 / 300: loss 0.608441\n",
      "iteration 264 / 300: loss 0.598359\n",
      "iteration 264 / 300: loss 0.583858\n",
      "iteration 264 / 300: loss 0.615253\n",
      "iteration 264 / 300: loss 0.591649\n",
      "iteration 264 / 300: loss 0.585499\n",
      "iteration 264 / 300: loss 0.591325\n",
      "iteration 264 / 300: loss 0.604341\n",
      "iteration 264 / 300: loss 0.595786\n",
      "iteration 264 / 300: loss 0.614949\n",
      "iteration 264 / 300: loss 0.608389\n",
      "iteration 264 / 300: loss 0.598222\n",
      "iteration 264 / 300: loss 0.588936\n",
      "iteration 264 / 300: loss 0.617757\n",
      "iteration 264 / 300: loss 0.594770\n",
      "iteration 264 / 300: loss 0.601684\n",
      "iteration 264 / 300: loss 0.631031\n",
      "iteration 264 / 300: loss 0.587513\n",
      "iteration 264 / 300: loss 0.606561\n",
      "iteration 264 / 300: loss 0.588034\n",
      "iteration 264 / 300: loss 0.600890\n",
      "iteration 264 / 300: loss 0.595958\n",
      "iteration 264 / 300: loss 0.589291\n",
      "iteration 264 / 300: loss 0.599526\n",
      "iteration 264 / 300: loss 0.604855\n",
      "iteration 264 / 300: loss 0.619414\n",
      "iteration 264 / 300: loss 0.588808\n",
      "iteration 264 / 300: loss 0.593645\n",
      "iteration 264 / 300: loss 0.585595\n",
      "iteration 264 / 300: loss 0.613212\n",
      "iteration 264 / 300: loss 0.587523\n",
      "iteration 264 / 300: loss 0.578328\n",
      "iteration 264 / 300: loss 0.567435\n",
      "iteration 264 / 300: loss 0.562235\n",
      "iteration 264 / 300: loss 0.594183\n",
      "iteration 264 / 300: loss 0.578821\n",
      "iteration 264 / 300: loss 0.586360\n",
      "iteration 264 / 300: loss 0.572890\n",
      "iteration 264 / 300: loss 0.596151\n",
      "iteration 264 / 300: loss 0.607951\n",
      "iteration 264 / 300: loss 0.610839\n",
      "iteration 264 / 300: loss 0.606265\n",
      "iteration 264 / 300: loss 0.583790\n",
      "iteration 264 / 300: loss 0.589627\n",
      "iteration 264 / 300: loss 0.595184\n",
      "iteration 264 / 300: loss 0.598955\n",
      "iteration 264 / 300: loss 0.596133\n",
      "iteration 264 / 300: loss 0.589769\n",
      "iteration 264 / 300: loss 0.591136\n",
      "iteration 264 / 300: loss 0.584854\n",
      "iteration 264 / 300: loss 0.599646\n",
      "iteration 264 / 300: loss 0.598902\n",
      "iteration 264 / 300: loss 0.614282\n",
      "iteration 264 / 300: loss 0.597796\n",
      "iteration 264 / 300: loss 0.599298\n",
      "iteration 264 / 300: loss 0.603317\n",
      "iteration 264 / 300: loss 0.592865\n",
      "iteration 264 / 300: loss 0.592391\n",
      "iteration 264 / 300: loss 0.589041\n",
      "iteration 264 / 300: loss 0.596446\n",
      "iteration 264 / 300: loss 0.605709\n",
      "iteration 264 / 300: loss 0.610562\n",
      "iteration 264 / 300: loss 0.587782\n",
      "iteration 264 / 300: loss 0.599351\n",
      "iteration 264 / 300: loss 0.602792\n",
      "iteration 264 / 300: loss 0.605028\n",
      "iteration 264 / 300: loss 0.603848\n",
      "iteration 264 / 300: loss 0.624144\n",
      "iteration 264 / 300: loss 0.587219\n",
      "iteration 264 / 300: loss 0.580754\n",
      "iteration 264 / 300: loss 0.625045\n",
      "iteration 264 / 300: loss 0.603310\n",
      "iteration 264 / 300: loss 0.604321\n",
      "iteration 264 / 300: loss 0.595476\n",
      "iteration 264 / 300: loss 0.597543\n",
      "iteration 264 / 300: loss 0.592740\n",
      "iteration 264 / 300: loss 0.589494\n",
      "iteration 264 / 300: loss 0.599264\n",
      "iteration 264 / 300: loss 0.611379\n",
      "iteration 264 / 300: loss 0.592463\n",
      "iteration 264 / 300: loss 0.599424\n",
      "iteration 264 / 300: loss 0.603100\n",
      "iteration 264 / 300: loss 0.602410\n",
      "iteration 264 / 300: loss 0.579811\n",
      "iteration 264 / 300: loss 0.601592\n",
      "iteration 265 / 300: loss 0.585528\n",
      "iteration 265 / 300: loss 0.588428\n",
      "iteration 265 / 300: loss 0.567516\n",
      "iteration 265 / 300: loss 0.592380\n",
      "iteration 265 / 300: loss 0.593618\n",
      "iteration 265 / 300: loss 0.595295\n",
      "iteration 265 / 300: loss 0.608784\n",
      "iteration 265 / 300: loss 0.592732\n",
      "iteration 265 / 300: loss 0.628060\n",
      "iteration 265 / 300: loss 0.580152\n",
      "iteration 265 / 300: loss 0.607923\n",
      "iteration 265 / 300: loss 0.587394\n",
      "iteration 265 / 300: loss 0.591686\n",
      "iteration 265 / 300: loss 0.571370\n",
      "iteration 265 / 300: loss 0.583025\n",
      "iteration 265 / 300: loss 0.608441\n",
      "iteration 265 / 300: loss 0.598359\n",
      "iteration 265 / 300: loss 0.583858\n",
      "iteration 265 / 300: loss 0.615253\n",
      "iteration 265 / 300: loss 0.591649\n",
      "iteration 265 / 300: loss 0.585499\n",
      "iteration 265 / 300: loss 0.591325\n",
      "iteration 265 / 300: loss 0.604341\n",
      "iteration 265 / 300: loss 0.595786\n",
      "iteration 265 / 300: loss 0.614949\n",
      "iteration 265 / 300: loss 0.608389\n",
      "iteration 265 / 300: loss 0.598222\n",
      "iteration 265 / 300: loss 0.588936\n",
      "iteration 265 / 300: loss 0.617757\n",
      "iteration 265 / 300: loss 0.594770\n",
      "iteration 265 / 300: loss 0.601684\n",
      "iteration 265 / 300: loss 0.631031\n",
      "iteration 265 / 300: loss 0.587513\n",
      "iteration 265 / 300: loss 0.606561\n",
      "iteration 265 / 300: loss 0.588034\n",
      "iteration 265 / 300: loss 0.600890\n",
      "iteration 265 / 300: loss 0.595958\n",
      "iteration 265 / 300: loss 0.589291\n",
      "iteration 265 / 300: loss 0.599526\n",
      "iteration 265 / 300: loss 0.604855\n",
      "iteration 265 / 300: loss 0.619414\n",
      "iteration 265 / 300: loss 0.588808\n",
      "iteration 265 / 300: loss 0.593645\n",
      "iteration 265 / 300: loss 0.585595\n",
      "iteration 265 / 300: loss 0.613212\n",
      "iteration 265 / 300: loss 0.587523\n",
      "iteration 265 / 300: loss 0.578328\n",
      "iteration 265 / 300: loss 0.567435\n",
      "iteration 265 / 300: loss 0.562235\n",
      "iteration 265 / 300: loss 0.594183\n",
      "iteration 265 / 300: loss 0.578821\n",
      "iteration 265 / 300: loss 0.586360\n",
      "iteration 265 / 300: loss 0.572890\n",
      "iteration 265 / 300: loss 0.596151\n",
      "iteration 265 / 300: loss 0.607951\n",
      "iteration 265 / 300: loss 0.610839\n",
      "iteration 265 / 300: loss 0.606265\n",
      "iteration 265 / 300: loss 0.583790\n",
      "iteration 265 / 300: loss 0.589627\n",
      "iteration 265 / 300: loss 0.595184\n",
      "iteration 265 / 300: loss 0.598955\n",
      "iteration 265 / 300: loss 0.596133\n",
      "iteration 265 / 300: loss 0.589769\n",
      "iteration 265 / 300: loss 0.591136\n",
      "iteration 265 / 300: loss 0.584854\n",
      "iteration 265 / 300: loss 0.599646\n",
      "iteration 265 / 300: loss 0.598902\n",
      "iteration 265 / 300: loss 0.614282\n",
      "iteration 265 / 300: loss 0.597796\n",
      "iteration 265 / 300: loss 0.599298\n",
      "iteration 265 / 300: loss 0.603317\n",
      "iteration 265 / 300: loss 0.592865\n",
      "iteration 265 / 300: loss 0.592391\n",
      "iteration 265 / 300: loss 0.589041\n",
      "iteration 265 / 300: loss 0.596446\n",
      "iteration 265 / 300: loss 0.605709\n",
      "iteration 265 / 300: loss 0.610562\n",
      "iteration 265 / 300: loss 0.587782\n",
      "iteration 265 / 300: loss 0.599351\n",
      "iteration 265 / 300: loss 0.602792\n",
      "iteration 265 / 300: loss 0.605028\n",
      "iteration 265 / 300: loss 0.603848\n",
      "iteration 265 / 300: loss 0.624144\n",
      "iteration 265 / 300: loss 0.587219\n",
      "iteration 265 / 300: loss 0.580754\n",
      "iteration 265 / 300: loss 0.625045\n",
      "iteration 265 / 300: loss 0.603310\n",
      "iteration 265 / 300: loss 0.604321\n",
      "iteration 265 / 300: loss 0.595476\n",
      "iteration 265 / 300: loss 0.597543\n",
      "iteration 265 / 300: loss 0.592740\n",
      "iteration 265 / 300: loss 0.589494\n",
      "iteration 265 / 300: loss 0.599264\n",
      "iteration 265 / 300: loss 0.611379\n",
      "iteration 265 / 300: loss 0.592463\n",
      "iteration 265 / 300: loss 0.599424\n",
      "iteration 265 / 300: loss 0.603100\n",
      "iteration 265 / 300: loss 0.602410\n",
      "iteration 265 / 300: loss 0.579811\n",
      "iteration 265 / 300: loss 0.601592\n",
      "iteration 266 / 300: loss 0.585528\n",
      "iteration 266 / 300: loss 0.588428\n",
      "iteration 266 / 300: loss 0.567516\n",
      "iteration 266 / 300: loss 0.592380\n",
      "iteration 266 / 300: loss 0.593618\n",
      "iteration 266 / 300: loss 0.595295\n",
      "iteration 266 / 300: loss 0.608784\n",
      "iteration 266 / 300: loss 0.592732\n",
      "iteration 266 / 300: loss 0.628060\n",
      "iteration 266 / 300: loss 0.580152\n",
      "iteration 266 / 300: loss 0.607923\n",
      "iteration 266 / 300: loss 0.587394\n",
      "iteration 266 / 300: loss 0.591686\n",
      "iteration 266 / 300: loss 0.571370\n",
      "iteration 266 / 300: loss 0.583025\n",
      "iteration 266 / 300: loss 0.608441\n",
      "iteration 266 / 300: loss 0.598359\n",
      "iteration 266 / 300: loss 0.583858\n",
      "iteration 266 / 300: loss 0.615253\n",
      "iteration 266 / 300: loss 0.591649\n",
      "iteration 266 / 300: loss 0.585499\n",
      "iteration 266 / 300: loss 0.591325\n",
      "iteration 266 / 300: loss 0.604341\n",
      "iteration 266 / 300: loss 0.595786\n",
      "iteration 266 / 300: loss 0.614949\n",
      "iteration 266 / 300: loss 0.608389\n",
      "iteration 266 / 300: loss 0.598222\n",
      "iteration 266 / 300: loss 0.588936\n",
      "iteration 266 / 300: loss 0.617757\n",
      "iteration 266 / 300: loss 0.594770\n",
      "iteration 266 / 300: loss 0.601684\n",
      "iteration 266 / 300: loss 0.631031\n",
      "iteration 266 / 300: loss 0.587513\n",
      "iteration 266 / 300: loss 0.606561\n",
      "iteration 266 / 300: loss 0.588034\n",
      "iteration 266 / 300: loss 0.600890\n",
      "iteration 266 / 300: loss 0.595958\n",
      "iteration 266 / 300: loss 0.589291\n",
      "iteration 266 / 300: loss 0.599526\n",
      "iteration 266 / 300: loss 0.604855\n",
      "iteration 266 / 300: loss 0.619414\n",
      "iteration 266 / 300: loss 0.588808\n",
      "iteration 266 / 300: loss 0.593645\n",
      "iteration 266 / 300: loss 0.585595\n",
      "iteration 266 / 300: loss 0.613212\n",
      "iteration 266 / 300: loss 0.587523\n",
      "iteration 266 / 300: loss 0.578328\n",
      "iteration 266 / 300: loss 0.567435\n",
      "iteration 266 / 300: loss 0.562235\n",
      "iteration 266 / 300: loss 0.594183\n",
      "iteration 266 / 300: loss 0.578821\n",
      "iteration 266 / 300: loss 0.586360\n",
      "iteration 266 / 300: loss 0.572890\n",
      "iteration 266 / 300: loss 0.596151\n",
      "iteration 266 / 300: loss 0.607951\n",
      "iteration 266 / 300: loss 0.610839\n",
      "iteration 266 / 300: loss 0.606265\n",
      "iteration 266 / 300: loss 0.583790\n",
      "iteration 266 / 300: loss 0.589627\n",
      "iteration 266 / 300: loss 0.595184\n",
      "iteration 266 / 300: loss 0.598955\n",
      "iteration 266 / 300: loss 0.596133\n",
      "iteration 266 / 300: loss 0.589769\n",
      "iteration 266 / 300: loss 0.591136\n",
      "iteration 266 / 300: loss 0.584854\n",
      "iteration 266 / 300: loss 0.599646\n",
      "iteration 266 / 300: loss 0.598902\n",
      "iteration 266 / 300: loss 0.614282\n",
      "iteration 266 / 300: loss 0.597796\n",
      "iteration 266 / 300: loss 0.599298\n",
      "iteration 266 / 300: loss 0.603317\n",
      "iteration 266 / 300: loss 0.592865\n",
      "iteration 266 / 300: loss 0.592391\n",
      "iteration 266 / 300: loss 0.589041\n",
      "iteration 266 / 300: loss 0.596446\n",
      "iteration 266 / 300: loss 0.605709\n",
      "iteration 266 / 300: loss 0.610562\n",
      "iteration 266 / 300: loss 0.587782\n",
      "iteration 266 / 300: loss 0.599351\n",
      "iteration 266 / 300: loss 0.602792\n",
      "iteration 266 / 300: loss 0.605028\n",
      "iteration 266 / 300: loss 0.603848\n",
      "iteration 266 / 300: loss 0.624144\n",
      "iteration 266 / 300: loss 0.587219\n",
      "iteration 266 / 300: loss 0.580754\n",
      "iteration 266 / 300: loss 0.625045\n",
      "iteration 266 / 300: loss 0.603310\n",
      "iteration 266 / 300: loss 0.604321\n",
      "iteration 266 / 300: loss 0.595476\n",
      "iteration 266 / 300: loss 0.597543\n",
      "iteration 266 / 300: loss 0.592740\n",
      "iteration 266 / 300: loss 0.589494\n",
      "iteration 266 / 300: loss 0.599264\n",
      "iteration 266 / 300: loss 0.611379\n",
      "iteration 266 / 300: loss 0.592463\n",
      "iteration 266 / 300: loss 0.599424\n",
      "iteration 266 / 300: loss 0.603100\n",
      "iteration 266 / 300: loss 0.602410\n",
      "iteration 266 / 300: loss 0.579811\n",
      "iteration 266 / 300: loss 0.601592\n",
      "iteration 267 / 300: loss 0.585528\n",
      "iteration 267 / 300: loss 0.588428\n",
      "iteration 267 / 300: loss 0.567516\n",
      "iteration 267 / 300: loss 0.592380\n",
      "iteration 267 / 300: loss 0.593618\n",
      "iteration 267 / 300: loss 0.595295\n",
      "iteration 267 / 300: loss 0.608784\n",
      "iteration 267 / 300: loss 0.592732\n",
      "iteration 267 / 300: loss 0.628060\n",
      "iteration 267 / 300: loss 0.580152\n",
      "iteration 267 / 300: loss 0.607923\n",
      "iteration 267 / 300: loss 0.587394\n",
      "iteration 267 / 300: loss 0.591686\n",
      "iteration 267 / 300: loss 0.571370\n",
      "iteration 267 / 300: loss 0.583025\n",
      "iteration 267 / 300: loss 0.608441\n",
      "iteration 267 / 300: loss 0.598359\n",
      "iteration 267 / 300: loss 0.583858\n",
      "iteration 267 / 300: loss 0.615253\n",
      "iteration 267 / 300: loss 0.591649\n",
      "iteration 267 / 300: loss 0.585499\n",
      "iteration 267 / 300: loss 0.591325\n",
      "iteration 267 / 300: loss 0.604341\n",
      "iteration 267 / 300: loss 0.595786\n",
      "iteration 267 / 300: loss 0.614949\n",
      "iteration 267 / 300: loss 0.608389\n",
      "iteration 267 / 300: loss 0.598222\n",
      "iteration 267 / 300: loss 0.588936\n",
      "iteration 267 / 300: loss 0.617757\n",
      "iteration 267 / 300: loss 0.594770\n",
      "iteration 267 / 300: loss 0.601684\n",
      "iteration 267 / 300: loss 0.631031\n",
      "iteration 267 / 300: loss 0.587513\n",
      "iteration 267 / 300: loss 0.606561\n",
      "iteration 267 / 300: loss 0.588034\n",
      "iteration 267 / 300: loss 0.600890\n",
      "iteration 267 / 300: loss 0.595958\n",
      "iteration 267 / 300: loss 0.589291\n",
      "iteration 267 / 300: loss 0.599526\n",
      "iteration 267 / 300: loss 0.604855\n",
      "iteration 267 / 300: loss 0.619414\n",
      "iteration 267 / 300: loss 0.588808\n",
      "iteration 267 / 300: loss 0.593645\n",
      "iteration 267 / 300: loss 0.585595\n",
      "iteration 267 / 300: loss 0.613212\n",
      "iteration 267 / 300: loss 0.587523\n",
      "iteration 267 / 300: loss 0.578328\n",
      "iteration 267 / 300: loss 0.567435\n",
      "iteration 267 / 300: loss 0.562235\n",
      "iteration 267 / 300: loss 0.594183\n",
      "iteration 267 / 300: loss 0.578821\n",
      "iteration 267 / 300: loss 0.586360\n",
      "iteration 267 / 300: loss 0.572890\n",
      "iteration 267 / 300: loss 0.596151\n",
      "iteration 267 / 300: loss 0.607951\n",
      "iteration 267 / 300: loss 0.610839\n",
      "iteration 267 / 300: loss 0.606265\n",
      "iteration 267 / 300: loss 0.583790\n",
      "iteration 267 / 300: loss 0.589627\n",
      "iteration 267 / 300: loss 0.595184\n",
      "iteration 267 / 300: loss 0.598955\n",
      "iteration 267 / 300: loss 0.596133\n",
      "iteration 267 / 300: loss 0.589769\n",
      "iteration 267 / 300: loss 0.591136\n",
      "iteration 267 / 300: loss 0.584854\n",
      "iteration 267 / 300: loss 0.599646\n",
      "iteration 267 / 300: loss 0.598902\n",
      "iteration 267 / 300: loss 0.614282\n",
      "iteration 267 / 300: loss 0.597796\n",
      "iteration 267 / 300: loss 0.599298\n",
      "iteration 267 / 300: loss 0.603317\n",
      "iteration 267 / 300: loss 0.592865\n",
      "iteration 267 / 300: loss 0.592391\n",
      "iteration 267 / 300: loss 0.589041\n",
      "iteration 267 / 300: loss 0.596446\n",
      "iteration 267 / 300: loss 0.605709\n",
      "iteration 267 / 300: loss 0.610562\n",
      "iteration 267 / 300: loss 0.587782\n",
      "iteration 267 / 300: loss 0.599351\n",
      "iteration 267 / 300: loss 0.602792\n",
      "iteration 267 / 300: loss 0.605028\n",
      "iteration 267 / 300: loss 0.603848\n",
      "iteration 267 / 300: loss 0.624144\n",
      "iteration 267 / 300: loss 0.587219\n",
      "iteration 267 / 300: loss 0.580754\n",
      "iteration 267 / 300: loss 0.625045\n",
      "iteration 267 / 300: loss 0.603310\n",
      "iteration 267 / 300: loss 0.604321\n",
      "iteration 267 / 300: loss 0.595476\n",
      "iteration 267 / 300: loss 0.597543\n",
      "iteration 267 / 300: loss 0.592740\n",
      "iteration 267 / 300: loss 0.589494\n",
      "iteration 267 / 300: loss 0.599264\n",
      "iteration 267 / 300: loss 0.611379\n",
      "iteration 267 / 300: loss 0.592463\n",
      "iteration 267 / 300: loss 0.599424\n",
      "iteration 267 / 300: loss 0.603100\n",
      "iteration 267 / 300: loss 0.602410\n",
      "iteration 267 / 300: loss 0.579811\n",
      "iteration 267 / 300: loss 0.601592\n",
      "iteration 268 / 300: loss 0.585528\n",
      "iteration 268 / 300: loss 0.588428\n",
      "iteration 268 / 300: loss 0.567516\n",
      "iteration 268 / 300: loss 0.592380\n",
      "iteration 268 / 300: loss 0.593618\n",
      "iteration 268 / 300: loss 0.595295\n",
      "iteration 268 / 300: loss 0.608784\n",
      "iteration 268 / 300: loss 0.592732\n",
      "iteration 268 / 300: loss 0.628060\n",
      "iteration 268 / 300: loss 0.580152\n",
      "iteration 268 / 300: loss 0.607923\n",
      "iteration 268 / 300: loss 0.587394\n",
      "iteration 268 / 300: loss 0.591686\n",
      "iteration 268 / 300: loss 0.571370\n",
      "iteration 268 / 300: loss 0.583025\n",
      "iteration 268 / 300: loss 0.608441\n",
      "iteration 268 / 300: loss 0.598359\n",
      "iteration 268 / 300: loss 0.583858\n",
      "iteration 268 / 300: loss 0.615253\n",
      "iteration 268 / 300: loss 0.591649\n",
      "iteration 268 / 300: loss 0.585499\n",
      "iteration 268 / 300: loss 0.591325\n",
      "iteration 268 / 300: loss 0.604341\n",
      "iteration 268 / 300: loss 0.595786\n",
      "iteration 268 / 300: loss 0.614949\n",
      "iteration 268 / 300: loss 0.608389\n",
      "iteration 268 / 300: loss 0.598222\n",
      "iteration 268 / 300: loss 0.588936\n",
      "iteration 268 / 300: loss 0.617757\n",
      "iteration 268 / 300: loss 0.594770\n",
      "iteration 268 / 300: loss 0.601684\n",
      "iteration 268 / 300: loss 0.631031\n",
      "iteration 268 / 300: loss 0.587513\n",
      "iteration 268 / 300: loss 0.606561\n",
      "iteration 268 / 300: loss 0.588034\n",
      "iteration 268 / 300: loss 0.600890\n",
      "iteration 268 / 300: loss 0.595958\n",
      "iteration 268 / 300: loss 0.589291\n",
      "iteration 268 / 300: loss 0.599526\n",
      "iteration 268 / 300: loss 0.604855\n",
      "iteration 268 / 300: loss 0.619414\n",
      "iteration 268 / 300: loss 0.588808\n",
      "iteration 268 / 300: loss 0.593645\n",
      "iteration 268 / 300: loss 0.585595\n",
      "iteration 268 / 300: loss 0.613212\n",
      "iteration 268 / 300: loss 0.587523\n",
      "iteration 268 / 300: loss 0.578328\n",
      "iteration 268 / 300: loss 0.567435\n",
      "iteration 268 / 300: loss 0.562235\n",
      "iteration 268 / 300: loss 0.594183\n",
      "iteration 268 / 300: loss 0.578821\n",
      "iteration 268 / 300: loss 0.586360\n",
      "iteration 268 / 300: loss 0.572890\n",
      "iteration 268 / 300: loss 0.596151\n",
      "iteration 268 / 300: loss 0.607951\n",
      "iteration 268 / 300: loss 0.610839\n",
      "iteration 268 / 300: loss 0.606265\n",
      "iteration 268 / 300: loss 0.583790\n",
      "iteration 268 / 300: loss 0.589627\n",
      "iteration 268 / 300: loss 0.595184\n",
      "iteration 268 / 300: loss 0.598955\n",
      "iteration 268 / 300: loss 0.596133\n",
      "iteration 268 / 300: loss 0.589769\n",
      "iteration 268 / 300: loss 0.591136\n",
      "iteration 268 / 300: loss 0.584854\n",
      "iteration 268 / 300: loss 0.599646\n",
      "iteration 268 / 300: loss 0.598902\n",
      "iteration 268 / 300: loss 0.614282\n",
      "iteration 268 / 300: loss 0.597796\n",
      "iteration 268 / 300: loss 0.599298\n",
      "iteration 268 / 300: loss 0.603317\n",
      "iteration 268 / 300: loss 0.592865\n",
      "iteration 268 / 300: loss 0.592391\n",
      "iteration 268 / 300: loss 0.589041\n",
      "iteration 268 / 300: loss 0.596446\n",
      "iteration 268 / 300: loss 0.605709\n",
      "iteration 268 / 300: loss 0.610562\n",
      "iteration 268 / 300: loss 0.587782\n",
      "iteration 268 / 300: loss 0.599351\n",
      "iteration 268 / 300: loss 0.602792\n",
      "iteration 268 / 300: loss 0.605028\n",
      "iteration 268 / 300: loss 0.603848\n",
      "iteration 268 / 300: loss 0.624144\n",
      "iteration 268 / 300: loss 0.587219\n",
      "iteration 268 / 300: loss 0.580754\n",
      "iteration 268 / 300: loss 0.625045\n",
      "iteration 268 / 300: loss 0.603310\n",
      "iteration 268 / 300: loss 0.604321\n",
      "iteration 268 / 300: loss 0.595476\n",
      "iteration 268 / 300: loss 0.597543\n",
      "iteration 268 / 300: loss 0.592740\n",
      "iteration 268 / 300: loss 0.589494\n",
      "iteration 268 / 300: loss 0.599264\n",
      "iteration 268 / 300: loss 0.611379\n",
      "iteration 268 / 300: loss 0.592463\n",
      "iteration 268 / 300: loss 0.599424\n",
      "iteration 268 / 300: loss 0.603100\n",
      "iteration 268 / 300: loss 0.602410\n",
      "iteration 268 / 300: loss 0.579811\n",
      "iteration 268 / 300: loss 0.601592\n",
      "iteration 269 / 300: loss 0.585528\n",
      "iteration 269 / 300: loss 0.588428\n",
      "iteration 269 / 300: loss 0.567516\n",
      "iteration 269 / 300: loss 0.592380\n",
      "iteration 269 / 300: loss 0.593618\n",
      "iteration 269 / 300: loss 0.595295\n",
      "iteration 269 / 300: loss 0.608784\n",
      "iteration 269 / 300: loss 0.592732\n",
      "iteration 269 / 300: loss 0.628060\n",
      "iteration 269 / 300: loss 0.580152\n",
      "iteration 269 / 300: loss 0.607923\n",
      "iteration 269 / 300: loss 0.587394\n",
      "iteration 269 / 300: loss 0.591686\n",
      "iteration 269 / 300: loss 0.571370\n",
      "iteration 269 / 300: loss 0.583025\n",
      "iteration 269 / 300: loss 0.608441\n",
      "iteration 269 / 300: loss 0.598359\n",
      "iteration 269 / 300: loss 0.583858\n",
      "iteration 269 / 300: loss 0.615253\n",
      "iteration 269 / 300: loss 0.591649\n",
      "iteration 269 / 300: loss 0.585499\n",
      "iteration 269 / 300: loss 0.591325\n",
      "iteration 269 / 300: loss 0.604341\n",
      "iteration 269 / 300: loss 0.595786\n",
      "iteration 269 / 300: loss 0.614949\n",
      "iteration 269 / 300: loss 0.608389\n",
      "iteration 269 / 300: loss 0.598222\n",
      "iteration 269 / 300: loss 0.588936\n",
      "iteration 269 / 300: loss 0.617757\n",
      "iteration 269 / 300: loss 0.594770\n",
      "iteration 269 / 300: loss 0.601684\n",
      "iteration 269 / 300: loss 0.631031\n",
      "iteration 269 / 300: loss 0.587513\n",
      "iteration 269 / 300: loss 0.606561\n",
      "iteration 269 / 300: loss 0.588034\n",
      "iteration 269 / 300: loss 0.600890\n",
      "iteration 269 / 300: loss 0.595958\n",
      "iteration 269 / 300: loss 0.589291\n",
      "iteration 269 / 300: loss 0.599526\n",
      "iteration 269 / 300: loss 0.604855\n",
      "iteration 269 / 300: loss 0.619414\n",
      "iteration 269 / 300: loss 0.588808\n",
      "iteration 269 / 300: loss 0.593645\n",
      "iteration 269 / 300: loss 0.585595\n",
      "iteration 269 / 300: loss 0.613212\n",
      "iteration 269 / 300: loss 0.587523\n",
      "iteration 269 / 300: loss 0.578328\n",
      "iteration 269 / 300: loss 0.567435\n",
      "iteration 269 / 300: loss 0.562235\n",
      "iteration 269 / 300: loss 0.594183\n",
      "iteration 269 / 300: loss 0.578821\n",
      "iteration 269 / 300: loss 0.586360\n",
      "iteration 269 / 300: loss 0.572890\n",
      "iteration 269 / 300: loss 0.596151\n",
      "iteration 269 / 300: loss 0.607951\n",
      "iteration 269 / 300: loss 0.610839\n",
      "iteration 269 / 300: loss 0.606265\n",
      "iteration 269 / 300: loss 0.583790\n",
      "iteration 269 / 300: loss 0.589627\n",
      "iteration 269 / 300: loss 0.595184\n",
      "iteration 269 / 300: loss 0.598955\n",
      "iteration 269 / 300: loss 0.596133\n",
      "iteration 269 / 300: loss 0.589769\n",
      "iteration 269 / 300: loss 0.591136\n",
      "iteration 269 / 300: loss 0.584854\n",
      "iteration 269 / 300: loss 0.599646\n",
      "iteration 269 / 300: loss 0.598902\n",
      "iteration 269 / 300: loss 0.614282\n",
      "iteration 269 / 300: loss 0.597796\n",
      "iteration 269 / 300: loss 0.599298\n",
      "iteration 269 / 300: loss 0.603317\n",
      "iteration 269 / 300: loss 0.592865\n",
      "iteration 269 / 300: loss 0.592391\n",
      "iteration 269 / 300: loss 0.589041\n",
      "iteration 269 / 300: loss 0.596446\n",
      "iteration 269 / 300: loss 0.605709\n",
      "iteration 269 / 300: loss 0.610562\n",
      "iteration 269 / 300: loss 0.587782\n",
      "iteration 269 / 300: loss 0.599351\n",
      "iteration 269 / 300: loss 0.602792\n",
      "iteration 269 / 300: loss 0.605028\n",
      "iteration 269 / 300: loss 0.603848\n",
      "iteration 269 / 300: loss 0.624144\n",
      "iteration 269 / 300: loss 0.587219\n",
      "iteration 269 / 300: loss 0.580754\n",
      "iteration 269 / 300: loss 0.625045\n",
      "iteration 269 / 300: loss 0.603310\n",
      "iteration 269 / 300: loss 0.604321\n",
      "iteration 269 / 300: loss 0.595476\n",
      "iteration 269 / 300: loss 0.597543\n",
      "iteration 269 / 300: loss 0.592740\n",
      "iteration 269 / 300: loss 0.589494\n",
      "iteration 269 / 300: loss 0.599264\n",
      "iteration 269 / 300: loss 0.611379\n",
      "iteration 269 / 300: loss 0.592463\n",
      "iteration 269 / 300: loss 0.599424\n",
      "iteration 269 / 300: loss 0.603100\n",
      "iteration 269 / 300: loss 0.602410\n",
      "iteration 269 / 300: loss 0.579811\n",
      "iteration 269 / 300: loss 0.601592\n",
      "iteration 270 / 300: loss 0.585528\n",
      "iteration 270 / 300: loss 0.588428\n",
      "iteration 270 / 300: loss 0.567516\n",
      "iteration 270 / 300: loss 0.592380\n",
      "iteration 270 / 300: loss 0.593618\n",
      "iteration 270 / 300: loss 0.595295\n",
      "iteration 270 / 300: loss 0.608784\n",
      "iteration 270 / 300: loss 0.592732\n",
      "iteration 270 / 300: loss 0.628060\n",
      "iteration 270 / 300: loss 0.580152\n",
      "iteration 270 / 300: loss 0.607923\n",
      "iteration 270 / 300: loss 0.587394\n",
      "iteration 270 / 300: loss 0.591686\n",
      "iteration 270 / 300: loss 0.571370\n",
      "iteration 270 / 300: loss 0.583025\n",
      "iteration 270 / 300: loss 0.608441\n",
      "iteration 270 / 300: loss 0.598359\n",
      "iteration 270 / 300: loss 0.583858\n",
      "iteration 270 / 300: loss 0.615253\n",
      "iteration 270 / 300: loss 0.591649\n",
      "iteration 270 / 300: loss 0.585499\n",
      "iteration 270 / 300: loss 0.591325\n",
      "iteration 270 / 300: loss 0.604341\n",
      "iteration 270 / 300: loss 0.595786\n",
      "iteration 270 / 300: loss 0.614949\n",
      "iteration 270 / 300: loss 0.608389\n",
      "iteration 270 / 300: loss 0.598222\n",
      "iteration 270 / 300: loss 0.588936\n",
      "iteration 270 / 300: loss 0.617757\n",
      "iteration 270 / 300: loss 0.594770\n",
      "iteration 270 / 300: loss 0.601684\n",
      "iteration 270 / 300: loss 0.631031\n",
      "iteration 270 / 300: loss 0.587513\n",
      "iteration 270 / 300: loss 0.606561\n",
      "iteration 270 / 300: loss 0.588034\n",
      "iteration 270 / 300: loss 0.600890\n",
      "iteration 270 / 300: loss 0.595958\n",
      "iteration 270 / 300: loss 0.589291\n",
      "iteration 270 / 300: loss 0.599526\n",
      "iteration 270 / 300: loss 0.604855\n",
      "iteration 270 / 300: loss 0.619414\n",
      "iteration 270 / 300: loss 0.588808\n",
      "iteration 270 / 300: loss 0.593645\n",
      "iteration 270 / 300: loss 0.585595\n",
      "iteration 270 / 300: loss 0.613212\n",
      "iteration 270 / 300: loss 0.587523\n",
      "iteration 270 / 300: loss 0.578328\n",
      "iteration 270 / 300: loss 0.567435\n",
      "iteration 270 / 300: loss 0.562235\n",
      "iteration 270 / 300: loss 0.594183\n",
      "iteration 270 / 300: loss 0.578821\n",
      "iteration 270 / 300: loss 0.586360\n",
      "iteration 270 / 300: loss 0.572890\n",
      "iteration 270 / 300: loss 0.596151\n",
      "iteration 270 / 300: loss 0.607951\n",
      "iteration 270 / 300: loss 0.610839\n",
      "iteration 270 / 300: loss 0.606265\n",
      "iteration 270 / 300: loss 0.583790\n",
      "iteration 270 / 300: loss 0.589627\n",
      "iteration 270 / 300: loss 0.595184\n",
      "iteration 270 / 300: loss 0.598955\n",
      "iteration 270 / 300: loss 0.596133\n",
      "iteration 270 / 300: loss 0.589769\n",
      "iteration 270 / 300: loss 0.591136\n",
      "iteration 270 / 300: loss 0.584854\n",
      "iteration 270 / 300: loss 0.599646\n",
      "iteration 270 / 300: loss 0.598902\n",
      "iteration 270 / 300: loss 0.614282\n",
      "iteration 270 / 300: loss 0.597796\n",
      "iteration 270 / 300: loss 0.599298\n",
      "iteration 270 / 300: loss 0.603317\n",
      "iteration 270 / 300: loss 0.592865\n",
      "iteration 270 / 300: loss 0.592391\n",
      "iteration 270 / 300: loss 0.589041\n",
      "iteration 270 / 300: loss 0.596446\n",
      "iteration 270 / 300: loss 0.605709\n",
      "iteration 270 / 300: loss 0.610562\n",
      "iteration 270 / 300: loss 0.587782\n",
      "iteration 270 / 300: loss 0.599351\n",
      "iteration 270 / 300: loss 0.602792\n",
      "iteration 270 / 300: loss 0.605028\n",
      "iteration 270 / 300: loss 0.603848\n",
      "iteration 270 / 300: loss 0.624144\n",
      "iteration 270 / 300: loss 0.587219\n",
      "iteration 270 / 300: loss 0.580754\n",
      "iteration 270 / 300: loss 0.625045\n",
      "iteration 270 / 300: loss 0.603310\n",
      "iteration 270 / 300: loss 0.604321\n",
      "iteration 270 / 300: loss 0.595476\n",
      "iteration 270 / 300: loss 0.597543\n",
      "iteration 270 / 300: loss 0.592740\n",
      "iteration 270 / 300: loss 0.589494\n",
      "iteration 270 / 300: loss 0.599264\n",
      "iteration 270 / 300: loss 0.611379\n",
      "iteration 270 / 300: loss 0.592463\n",
      "iteration 270 / 300: loss 0.599424\n",
      "iteration 270 / 300: loss 0.603100\n",
      "iteration 270 / 300: loss 0.602410\n",
      "iteration 270 / 300: loss 0.579811\n",
      "iteration 270 / 300: loss 0.601592\n",
      "iteration 271 / 300: loss 0.585528\n",
      "iteration 271 / 300: loss 0.588428\n",
      "iteration 271 / 300: loss 0.567516\n",
      "iteration 271 / 300: loss 0.592380\n",
      "iteration 271 / 300: loss 0.593618\n",
      "iteration 271 / 300: loss 0.595295\n",
      "iteration 271 / 300: loss 0.608784\n",
      "iteration 271 / 300: loss 0.592732\n",
      "iteration 271 / 300: loss 0.628060\n",
      "iteration 271 / 300: loss 0.580152\n",
      "iteration 271 / 300: loss 0.607923\n",
      "iteration 271 / 300: loss 0.587394\n",
      "iteration 271 / 300: loss 0.591686\n",
      "iteration 271 / 300: loss 0.571370\n",
      "iteration 271 / 300: loss 0.583025\n",
      "iteration 271 / 300: loss 0.608441\n",
      "iteration 271 / 300: loss 0.598359\n",
      "iteration 271 / 300: loss 0.583858\n",
      "iteration 271 / 300: loss 0.615253\n",
      "iteration 271 / 300: loss 0.591649\n",
      "iteration 271 / 300: loss 0.585499\n",
      "iteration 271 / 300: loss 0.591325\n",
      "iteration 271 / 300: loss 0.604341\n",
      "iteration 271 / 300: loss 0.595786\n",
      "iteration 271 / 300: loss 0.614949\n",
      "iteration 271 / 300: loss 0.608389\n",
      "iteration 271 / 300: loss 0.598222\n",
      "iteration 271 / 300: loss 0.588936\n",
      "iteration 271 / 300: loss 0.617757\n",
      "iteration 271 / 300: loss 0.594770\n",
      "iteration 271 / 300: loss 0.601684\n",
      "iteration 271 / 300: loss 0.631031\n",
      "iteration 271 / 300: loss 0.587513\n",
      "iteration 271 / 300: loss 0.606561\n",
      "iteration 271 / 300: loss 0.588034\n",
      "iteration 271 / 300: loss 0.600890\n",
      "iteration 271 / 300: loss 0.595958\n",
      "iteration 271 / 300: loss 0.589291\n",
      "iteration 271 / 300: loss 0.599526\n",
      "iteration 271 / 300: loss 0.604855\n",
      "iteration 271 / 300: loss 0.619414\n",
      "iteration 271 / 300: loss 0.588808\n",
      "iteration 271 / 300: loss 0.593645\n",
      "iteration 271 / 300: loss 0.585595\n",
      "iteration 271 / 300: loss 0.613212\n",
      "iteration 271 / 300: loss 0.587523\n",
      "iteration 271 / 300: loss 0.578328\n",
      "iteration 271 / 300: loss 0.567435\n",
      "iteration 271 / 300: loss 0.562235\n",
      "iteration 271 / 300: loss 0.594183\n",
      "iteration 271 / 300: loss 0.578821\n",
      "iteration 271 / 300: loss 0.586360\n",
      "iteration 271 / 300: loss 0.572890\n",
      "iteration 271 / 300: loss 0.596151\n",
      "iteration 271 / 300: loss 0.607951\n",
      "iteration 271 / 300: loss 0.610839\n",
      "iteration 271 / 300: loss 0.606265\n",
      "iteration 271 / 300: loss 0.583790\n",
      "iteration 271 / 300: loss 0.589627\n",
      "iteration 271 / 300: loss 0.595184\n",
      "iteration 271 / 300: loss 0.598955\n",
      "iteration 271 / 300: loss 0.596133\n",
      "iteration 271 / 300: loss 0.589769\n",
      "iteration 271 / 300: loss 0.591136\n",
      "iteration 271 / 300: loss 0.584854\n",
      "iteration 271 / 300: loss 0.599646\n",
      "iteration 271 / 300: loss 0.598902\n",
      "iteration 271 / 300: loss 0.614282\n",
      "iteration 271 / 300: loss 0.597796\n",
      "iteration 271 / 300: loss 0.599298\n",
      "iteration 271 / 300: loss 0.603317\n",
      "iteration 271 / 300: loss 0.592865\n",
      "iteration 271 / 300: loss 0.592391\n",
      "iteration 271 / 300: loss 0.589041\n",
      "iteration 271 / 300: loss 0.596446\n",
      "iteration 271 / 300: loss 0.605709\n",
      "iteration 271 / 300: loss 0.610562\n",
      "iteration 271 / 300: loss 0.587782\n",
      "iteration 271 / 300: loss 0.599351\n",
      "iteration 271 / 300: loss 0.602792\n",
      "iteration 271 / 300: loss 0.605028\n",
      "iteration 271 / 300: loss 0.603848\n",
      "iteration 271 / 300: loss 0.624144\n",
      "iteration 271 / 300: loss 0.587219\n",
      "iteration 271 / 300: loss 0.580754\n",
      "iteration 271 / 300: loss 0.625045\n",
      "iteration 271 / 300: loss 0.603310\n",
      "iteration 271 / 300: loss 0.604321\n",
      "iteration 271 / 300: loss 0.595476\n",
      "iteration 271 / 300: loss 0.597543\n",
      "iteration 271 / 300: loss 0.592740\n",
      "iteration 271 / 300: loss 0.589494\n",
      "iteration 271 / 300: loss 0.599264\n",
      "iteration 271 / 300: loss 0.611379\n",
      "iteration 271 / 300: loss 0.592463\n",
      "iteration 271 / 300: loss 0.599424\n",
      "iteration 271 / 300: loss 0.603100\n",
      "iteration 271 / 300: loss 0.602410\n",
      "iteration 271 / 300: loss 0.579811\n",
      "iteration 271 / 300: loss 0.601592\n",
      "iteration 272 / 300: loss 0.585528\n",
      "iteration 272 / 300: loss 0.588428\n",
      "iteration 272 / 300: loss 0.567516\n",
      "iteration 272 / 300: loss 0.592380\n",
      "iteration 272 / 300: loss 0.593618\n",
      "iteration 272 / 300: loss 0.595295\n",
      "iteration 272 / 300: loss 0.608784\n",
      "iteration 272 / 300: loss 0.592732\n",
      "iteration 272 / 300: loss 0.628060\n",
      "iteration 272 / 300: loss 0.580152\n",
      "iteration 272 / 300: loss 0.607923\n",
      "iteration 272 / 300: loss 0.587394\n",
      "iteration 272 / 300: loss 0.591686\n",
      "iteration 272 / 300: loss 0.571370\n",
      "iteration 272 / 300: loss 0.583025\n",
      "iteration 272 / 300: loss 0.608441\n",
      "iteration 272 / 300: loss 0.598359\n",
      "iteration 272 / 300: loss 0.583858\n",
      "iteration 272 / 300: loss 0.615253\n",
      "iteration 272 / 300: loss 0.591649\n",
      "iteration 272 / 300: loss 0.585499\n",
      "iteration 272 / 300: loss 0.591325\n",
      "iteration 272 / 300: loss 0.604341\n",
      "iteration 272 / 300: loss 0.595786\n",
      "iteration 272 / 300: loss 0.614949\n",
      "iteration 272 / 300: loss 0.608389\n",
      "iteration 272 / 300: loss 0.598222\n",
      "iteration 272 / 300: loss 0.588936\n",
      "iteration 272 / 300: loss 0.617757\n",
      "iteration 272 / 300: loss 0.594770\n",
      "iteration 272 / 300: loss 0.601684\n",
      "iteration 272 / 300: loss 0.631031\n",
      "iteration 272 / 300: loss 0.587513\n",
      "iteration 272 / 300: loss 0.606561\n",
      "iteration 272 / 300: loss 0.588034\n",
      "iteration 272 / 300: loss 0.600890\n",
      "iteration 272 / 300: loss 0.595958\n",
      "iteration 272 / 300: loss 0.589291\n",
      "iteration 272 / 300: loss 0.599526\n",
      "iteration 272 / 300: loss 0.604855\n",
      "iteration 272 / 300: loss 0.619414\n",
      "iteration 272 / 300: loss 0.588808\n",
      "iteration 272 / 300: loss 0.593645\n",
      "iteration 272 / 300: loss 0.585595\n",
      "iteration 272 / 300: loss 0.613212\n",
      "iteration 272 / 300: loss 0.587523\n",
      "iteration 272 / 300: loss 0.578328\n",
      "iteration 272 / 300: loss 0.567435\n",
      "iteration 272 / 300: loss 0.562235\n",
      "iteration 272 / 300: loss 0.594183\n",
      "iteration 272 / 300: loss 0.578821\n",
      "iteration 272 / 300: loss 0.586360\n",
      "iteration 272 / 300: loss 0.572890\n",
      "iteration 272 / 300: loss 0.596151\n",
      "iteration 272 / 300: loss 0.607951\n",
      "iteration 272 / 300: loss 0.610839\n",
      "iteration 272 / 300: loss 0.606265\n",
      "iteration 272 / 300: loss 0.583790\n",
      "iteration 272 / 300: loss 0.589627\n",
      "iteration 272 / 300: loss 0.595184\n",
      "iteration 272 / 300: loss 0.598955\n",
      "iteration 272 / 300: loss 0.596133\n",
      "iteration 272 / 300: loss 0.589769\n",
      "iteration 272 / 300: loss 0.591136\n",
      "iteration 272 / 300: loss 0.584854\n",
      "iteration 272 / 300: loss 0.599646\n",
      "iteration 272 / 300: loss 0.598902\n",
      "iteration 272 / 300: loss 0.614282\n",
      "iteration 272 / 300: loss 0.597796\n",
      "iteration 272 / 300: loss 0.599298\n",
      "iteration 272 / 300: loss 0.603317\n",
      "iteration 272 / 300: loss 0.592865\n",
      "iteration 272 / 300: loss 0.592391\n",
      "iteration 272 / 300: loss 0.589041\n",
      "iteration 272 / 300: loss 0.596446\n",
      "iteration 272 / 300: loss 0.605709\n",
      "iteration 272 / 300: loss 0.610562\n",
      "iteration 272 / 300: loss 0.587782\n",
      "iteration 272 / 300: loss 0.599351\n",
      "iteration 272 / 300: loss 0.602792\n",
      "iteration 272 / 300: loss 0.605028\n",
      "iteration 272 / 300: loss 0.603848\n",
      "iteration 272 / 300: loss 0.624144\n",
      "iteration 272 / 300: loss 0.587219\n",
      "iteration 272 / 300: loss 0.580754\n",
      "iteration 272 / 300: loss 0.625045\n",
      "iteration 272 / 300: loss 0.603310\n",
      "iteration 272 / 300: loss 0.604321\n",
      "iteration 272 / 300: loss 0.595476\n",
      "iteration 272 / 300: loss 0.597543\n",
      "iteration 272 / 300: loss 0.592740\n",
      "iteration 272 / 300: loss 0.589494\n",
      "iteration 272 / 300: loss 0.599264\n",
      "iteration 272 / 300: loss 0.611379\n",
      "iteration 272 / 300: loss 0.592463\n",
      "iteration 272 / 300: loss 0.599424\n",
      "iteration 272 / 300: loss 0.603100\n",
      "iteration 272 / 300: loss 0.602410\n",
      "iteration 272 / 300: loss 0.579811\n",
      "iteration 272 / 300: loss 0.601592\n",
      "iteration 273 / 300: loss 0.585528\n",
      "iteration 273 / 300: loss 0.588428\n",
      "iteration 273 / 300: loss 0.567516\n",
      "iteration 273 / 300: loss 0.592380\n",
      "iteration 273 / 300: loss 0.593618\n",
      "iteration 273 / 300: loss 0.595295\n",
      "iteration 273 / 300: loss 0.608784\n",
      "iteration 273 / 300: loss 0.592732\n",
      "iteration 273 / 300: loss 0.628060\n",
      "iteration 273 / 300: loss 0.580152\n",
      "iteration 273 / 300: loss 0.607923\n",
      "iteration 273 / 300: loss 0.587394\n",
      "iteration 273 / 300: loss 0.591686\n",
      "iteration 273 / 300: loss 0.571370\n",
      "iteration 273 / 300: loss 0.583025\n",
      "iteration 273 / 300: loss 0.608441\n",
      "iteration 273 / 300: loss 0.598359\n",
      "iteration 273 / 300: loss 0.583858\n",
      "iteration 273 / 300: loss 0.615253\n",
      "iteration 273 / 300: loss 0.591649\n",
      "iteration 273 / 300: loss 0.585499\n",
      "iteration 273 / 300: loss 0.591325\n",
      "iteration 273 / 300: loss 0.604341\n",
      "iteration 273 / 300: loss 0.595786\n",
      "iteration 273 / 300: loss 0.614949\n",
      "iteration 273 / 300: loss 0.608389\n",
      "iteration 273 / 300: loss 0.598222\n",
      "iteration 273 / 300: loss 0.588936\n",
      "iteration 273 / 300: loss 0.617757\n",
      "iteration 273 / 300: loss 0.594770\n",
      "iteration 273 / 300: loss 0.601684\n",
      "iteration 273 / 300: loss 0.631031\n",
      "iteration 273 / 300: loss 0.587513\n",
      "iteration 273 / 300: loss 0.606561\n",
      "iteration 273 / 300: loss 0.588034\n",
      "iteration 273 / 300: loss 0.600890\n",
      "iteration 273 / 300: loss 0.595958\n",
      "iteration 273 / 300: loss 0.589291\n",
      "iteration 273 / 300: loss 0.599526\n",
      "iteration 273 / 300: loss 0.604855\n",
      "iteration 273 / 300: loss 0.619414\n",
      "iteration 273 / 300: loss 0.588808\n",
      "iteration 273 / 300: loss 0.593645\n",
      "iteration 273 / 300: loss 0.585595\n",
      "iteration 273 / 300: loss 0.613212\n",
      "iteration 273 / 300: loss 0.587523\n",
      "iteration 273 / 300: loss 0.578328\n",
      "iteration 273 / 300: loss 0.567435\n",
      "iteration 273 / 300: loss 0.562235\n",
      "iteration 273 / 300: loss 0.594183\n",
      "iteration 273 / 300: loss 0.578821\n",
      "iteration 273 / 300: loss 0.586360\n",
      "iteration 273 / 300: loss 0.572890\n",
      "iteration 273 / 300: loss 0.596151\n",
      "iteration 273 / 300: loss 0.607951\n",
      "iteration 273 / 300: loss 0.610839\n",
      "iteration 273 / 300: loss 0.606265\n",
      "iteration 273 / 300: loss 0.583790\n",
      "iteration 273 / 300: loss 0.589627\n",
      "iteration 273 / 300: loss 0.595184\n",
      "iteration 273 / 300: loss 0.598955\n",
      "iteration 273 / 300: loss 0.596133\n",
      "iteration 273 / 300: loss 0.589769\n",
      "iteration 273 / 300: loss 0.591136\n",
      "iteration 273 / 300: loss 0.584854\n",
      "iteration 273 / 300: loss 0.599646\n",
      "iteration 273 / 300: loss 0.598902\n",
      "iteration 273 / 300: loss 0.614282\n",
      "iteration 273 / 300: loss 0.597796\n",
      "iteration 273 / 300: loss 0.599298\n",
      "iteration 273 / 300: loss 0.603317\n",
      "iteration 273 / 300: loss 0.592865\n",
      "iteration 273 / 300: loss 0.592391\n",
      "iteration 273 / 300: loss 0.589041\n",
      "iteration 273 / 300: loss 0.596446\n",
      "iteration 273 / 300: loss 0.605709\n",
      "iteration 273 / 300: loss 0.610562\n",
      "iteration 273 / 300: loss 0.587782\n",
      "iteration 273 / 300: loss 0.599351\n",
      "iteration 273 / 300: loss 0.602792\n",
      "iteration 273 / 300: loss 0.605028\n",
      "iteration 273 / 300: loss 0.603848\n",
      "iteration 273 / 300: loss 0.624144\n",
      "iteration 273 / 300: loss 0.587219\n",
      "iteration 273 / 300: loss 0.580754\n",
      "iteration 273 / 300: loss 0.625045\n",
      "iteration 273 / 300: loss 0.603310\n",
      "iteration 273 / 300: loss 0.604321\n",
      "iteration 273 / 300: loss 0.595476\n",
      "iteration 273 / 300: loss 0.597543\n",
      "iteration 273 / 300: loss 0.592740\n",
      "iteration 273 / 300: loss 0.589494\n",
      "iteration 273 / 300: loss 0.599264\n",
      "iteration 273 / 300: loss 0.611379\n",
      "iteration 273 / 300: loss 0.592463\n",
      "iteration 273 / 300: loss 0.599424\n",
      "iteration 273 / 300: loss 0.603100\n",
      "iteration 273 / 300: loss 0.602410\n",
      "iteration 273 / 300: loss 0.579811\n",
      "iteration 273 / 300: loss 0.601592\n",
      "iteration 274 / 300: loss 0.585528\n",
      "iteration 274 / 300: loss 0.588428\n",
      "iteration 274 / 300: loss 0.567516\n",
      "iteration 274 / 300: loss 0.592380\n",
      "iteration 274 / 300: loss 0.593618\n",
      "iteration 274 / 300: loss 0.595295\n",
      "iteration 274 / 300: loss 0.608784\n",
      "iteration 274 / 300: loss 0.592732\n",
      "iteration 274 / 300: loss 0.628060\n",
      "iteration 274 / 300: loss 0.580152\n",
      "iteration 274 / 300: loss 0.607923\n",
      "iteration 274 / 300: loss 0.587394\n",
      "iteration 274 / 300: loss 0.591686\n",
      "iteration 274 / 300: loss 0.571370\n",
      "iteration 274 / 300: loss 0.583025\n",
      "iteration 274 / 300: loss 0.608441\n",
      "iteration 274 / 300: loss 0.598359\n",
      "iteration 274 / 300: loss 0.583858\n",
      "iteration 274 / 300: loss 0.615253\n",
      "iteration 274 / 300: loss 0.591649\n",
      "iteration 274 / 300: loss 0.585499\n",
      "iteration 274 / 300: loss 0.591325\n",
      "iteration 274 / 300: loss 0.604341\n",
      "iteration 274 / 300: loss 0.595786\n",
      "iteration 274 / 300: loss 0.614949\n",
      "iteration 274 / 300: loss 0.608389\n",
      "iteration 274 / 300: loss 0.598222\n",
      "iteration 274 / 300: loss 0.588936\n",
      "iteration 274 / 300: loss 0.617757\n",
      "iteration 274 / 300: loss 0.594770\n",
      "iteration 274 / 300: loss 0.601684\n",
      "iteration 274 / 300: loss 0.631031\n",
      "iteration 274 / 300: loss 0.587513\n",
      "iteration 274 / 300: loss 0.606561\n",
      "iteration 274 / 300: loss 0.588034\n",
      "iteration 274 / 300: loss 0.600890\n",
      "iteration 274 / 300: loss 0.595958\n",
      "iteration 274 / 300: loss 0.589291\n",
      "iteration 274 / 300: loss 0.599526\n",
      "iteration 274 / 300: loss 0.604855\n",
      "iteration 274 / 300: loss 0.619414\n",
      "iteration 274 / 300: loss 0.588808\n",
      "iteration 274 / 300: loss 0.593645\n",
      "iteration 274 / 300: loss 0.585595\n",
      "iteration 274 / 300: loss 0.613212\n",
      "iteration 274 / 300: loss 0.587523\n",
      "iteration 274 / 300: loss 0.578328\n",
      "iteration 274 / 300: loss 0.567435\n",
      "iteration 274 / 300: loss 0.562235\n",
      "iteration 274 / 300: loss 0.594183\n",
      "iteration 274 / 300: loss 0.578821\n",
      "iteration 274 / 300: loss 0.586360\n",
      "iteration 274 / 300: loss 0.572890\n",
      "iteration 274 / 300: loss 0.596151\n",
      "iteration 274 / 300: loss 0.607951\n",
      "iteration 274 / 300: loss 0.610839\n",
      "iteration 274 / 300: loss 0.606265\n",
      "iteration 274 / 300: loss 0.583790\n",
      "iteration 274 / 300: loss 0.589627\n",
      "iteration 274 / 300: loss 0.595184\n",
      "iteration 274 / 300: loss 0.598955\n",
      "iteration 274 / 300: loss 0.596133\n",
      "iteration 274 / 300: loss 0.589769\n",
      "iteration 274 / 300: loss 0.591136\n",
      "iteration 274 / 300: loss 0.584854\n",
      "iteration 274 / 300: loss 0.599646\n",
      "iteration 274 / 300: loss 0.598902\n",
      "iteration 274 / 300: loss 0.614282\n",
      "iteration 274 / 300: loss 0.597796\n",
      "iteration 274 / 300: loss 0.599298\n",
      "iteration 274 / 300: loss 0.603317\n",
      "iteration 274 / 300: loss 0.592865\n",
      "iteration 274 / 300: loss 0.592391\n",
      "iteration 274 / 300: loss 0.589041\n",
      "iteration 274 / 300: loss 0.596446\n",
      "iteration 274 / 300: loss 0.605709\n",
      "iteration 274 / 300: loss 0.610562\n",
      "iteration 274 / 300: loss 0.587782\n",
      "iteration 274 / 300: loss 0.599351\n",
      "iteration 274 / 300: loss 0.602792\n",
      "iteration 274 / 300: loss 0.605028\n",
      "iteration 274 / 300: loss 0.603848\n",
      "iteration 274 / 300: loss 0.624144\n",
      "iteration 274 / 300: loss 0.587219\n",
      "iteration 274 / 300: loss 0.580754\n",
      "iteration 274 / 300: loss 0.625045\n",
      "iteration 274 / 300: loss 0.603310\n",
      "iteration 274 / 300: loss 0.604321\n",
      "iteration 274 / 300: loss 0.595476\n",
      "iteration 274 / 300: loss 0.597543\n",
      "iteration 274 / 300: loss 0.592740\n",
      "iteration 274 / 300: loss 0.589494\n",
      "iteration 274 / 300: loss 0.599264\n",
      "iteration 274 / 300: loss 0.611379\n",
      "iteration 274 / 300: loss 0.592463\n",
      "iteration 274 / 300: loss 0.599424\n",
      "iteration 274 / 300: loss 0.603100\n",
      "iteration 274 / 300: loss 0.602410\n",
      "iteration 274 / 300: loss 0.579811\n",
      "iteration 274 / 300: loss 0.601592\n",
      "iteration 275 / 300: loss 0.585528\n",
      "iteration 275 / 300: loss 0.588428\n",
      "iteration 275 / 300: loss 0.567516\n",
      "iteration 275 / 300: loss 0.592380\n",
      "iteration 275 / 300: loss 0.593618\n",
      "iteration 275 / 300: loss 0.595295\n",
      "iteration 275 / 300: loss 0.608784\n",
      "iteration 275 / 300: loss 0.592732\n",
      "iteration 275 / 300: loss 0.628060\n",
      "iteration 275 / 300: loss 0.580152\n",
      "iteration 275 / 300: loss 0.607923\n",
      "iteration 275 / 300: loss 0.587394\n",
      "iteration 275 / 300: loss 0.591686\n",
      "iteration 275 / 300: loss 0.571370\n",
      "iteration 275 / 300: loss 0.583025\n",
      "iteration 275 / 300: loss 0.608441\n",
      "iteration 275 / 300: loss 0.598359\n",
      "iteration 275 / 300: loss 0.583858\n",
      "iteration 275 / 300: loss 0.615253\n",
      "iteration 275 / 300: loss 0.591649\n",
      "iteration 275 / 300: loss 0.585499\n",
      "iteration 275 / 300: loss 0.591325\n",
      "iteration 275 / 300: loss 0.604341\n",
      "iteration 275 / 300: loss 0.595786\n",
      "iteration 275 / 300: loss 0.614949\n",
      "iteration 275 / 300: loss 0.608389\n",
      "iteration 275 / 300: loss 0.598222\n",
      "iteration 275 / 300: loss 0.588936\n",
      "iteration 275 / 300: loss 0.617757\n",
      "iteration 275 / 300: loss 0.594770\n",
      "iteration 275 / 300: loss 0.601684\n",
      "iteration 275 / 300: loss 0.631031\n",
      "iteration 275 / 300: loss 0.587513\n",
      "iteration 275 / 300: loss 0.606561\n",
      "iteration 275 / 300: loss 0.588034\n",
      "iteration 275 / 300: loss 0.600890\n",
      "iteration 275 / 300: loss 0.595958\n",
      "iteration 275 / 300: loss 0.589291\n",
      "iteration 275 / 300: loss 0.599526\n",
      "iteration 275 / 300: loss 0.604855\n",
      "iteration 275 / 300: loss 0.619414\n",
      "iteration 275 / 300: loss 0.588808\n",
      "iteration 275 / 300: loss 0.593645\n",
      "iteration 275 / 300: loss 0.585595\n",
      "iteration 275 / 300: loss 0.613212\n",
      "iteration 275 / 300: loss 0.587523\n",
      "iteration 275 / 300: loss 0.578328\n",
      "iteration 275 / 300: loss 0.567435\n",
      "iteration 275 / 300: loss 0.562235\n",
      "iteration 275 / 300: loss 0.594183\n",
      "iteration 275 / 300: loss 0.578821\n",
      "iteration 275 / 300: loss 0.586360\n",
      "iteration 275 / 300: loss 0.572890\n",
      "iteration 275 / 300: loss 0.596151\n",
      "iteration 275 / 300: loss 0.607951\n",
      "iteration 275 / 300: loss 0.610839\n",
      "iteration 275 / 300: loss 0.606265\n",
      "iteration 275 / 300: loss 0.583790\n",
      "iteration 275 / 300: loss 0.589627\n",
      "iteration 275 / 300: loss 0.595184\n",
      "iteration 275 / 300: loss 0.598955\n",
      "iteration 275 / 300: loss 0.596133\n",
      "iteration 275 / 300: loss 0.589769\n",
      "iteration 275 / 300: loss 0.591136\n",
      "iteration 275 / 300: loss 0.584854\n",
      "iteration 275 / 300: loss 0.599646\n",
      "iteration 275 / 300: loss 0.598902\n",
      "iteration 275 / 300: loss 0.614282\n",
      "iteration 275 / 300: loss 0.597796\n",
      "iteration 275 / 300: loss 0.599298\n",
      "iteration 275 / 300: loss 0.603317\n",
      "iteration 275 / 300: loss 0.592865\n",
      "iteration 275 / 300: loss 0.592391\n",
      "iteration 275 / 300: loss 0.589041\n",
      "iteration 275 / 300: loss 0.596446\n",
      "iteration 275 / 300: loss 0.605709\n",
      "iteration 275 / 300: loss 0.610562\n",
      "iteration 275 / 300: loss 0.587782\n",
      "iteration 275 / 300: loss 0.599351\n",
      "iteration 275 / 300: loss 0.602792\n",
      "iteration 275 / 300: loss 0.605028\n",
      "iteration 275 / 300: loss 0.603848\n",
      "iteration 275 / 300: loss 0.624144\n",
      "iteration 275 / 300: loss 0.587219\n",
      "iteration 275 / 300: loss 0.580754\n",
      "iteration 275 / 300: loss 0.625045\n",
      "iteration 275 / 300: loss 0.603310\n",
      "iteration 275 / 300: loss 0.604321\n",
      "iteration 275 / 300: loss 0.595476\n",
      "iteration 275 / 300: loss 0.597543\n",
      "iteration 275 / 300: loss 0.592740\n",
      "iteration 275 / 300: loss 0.589494\n",
      "iteration 275 / 300: loss 0.599264\n",
      "iteration 275 / 300: loss 0.611379\n",
      "iteration 275 / 300: loss 0.592463\n",
      "iteration 275 / 300: loss 0.599424\n",
      "iteration 275 / 300: loss 0.603100\n",
      "iteration 275 / 300: loss 0.602410\n",
      "iteration 275 / 300: loss 0.579811\n",
      "iteration 275 / 300: loss 0.601592\n",
      "iteration 276 / 300: loss 0.585528\n",
      "iteration 276 / 300: loss 0.588428\n",
      "iteration 276 / 300: loss 0.567516\n",
      "iteration 276 / 300: loss 0.592380\n",
      "iteration 276 / 300: loss 0.593618\n",
      "iteration 276 / 300: loss 0.595295\n",
      "iteration 276 / 300: loss 0.608784\n",
      "iteration 276 / 300: loss 0.592732\n",
      "iteration 276 / 300: loss 0.628060\n",
      "iteration 276 / 300: loss 0.580152\n",
      "iteration 276 / 300: loss 0.607923\n",
      "iteration 276 / 300: loss 0.587394\n",
      "iteration 276 / 300: loss 0.591686\n",
      "iteration 276 / 300: loss 0.571370\n",
      "iteration 276 / 300: loss 0.583025\n",
      "iteration 276 / 300: loss 0.608441\n",
      "iteration 276 / 300: loss 0.598359\n",
      "iteration 276 / 300: loss 0.583858\n",
      "iteration 276 / 300: loss 0.615253\n",
      "iteration 276 / 300: loss 0.591649\n",
      "iteration 276 / 300: loss 0.585499\n",
      "iteration 276 / 300: loss 0.591325\n",
      "iteration 276 / 300: loss 0.604341\n",
      "iteration 276 / 300: loss 0.595786\n",
      "iteration 276 / 300: loss 0.614949\n",
      "iteration 276 / 300: loss 0.608389\n",
      "iteration 276 / 300: loss 0.598222\n",
      "iteration 276 / 300: loss 0.588936\n",
      "iteration 276 / 300: loss 0.617757\n",
      "iteration 276 / 300: loss 0.594770\n",
      "iteration 276 / 300: loss 0.601684\n",
      "iteration 276 / 300: loss 0.631031\n",
      "iteration 276 / 300: loss 0.587513\n",
      "iteration 276 / 300: loss 0.606561\n",
      "iteration 276 / 300: loss 0.588034\n",
      "iteration 276 / 300: loss 0.600890\n",
      "iteration 276 / 300: loss 0.595958\n",
      "iteration 276 / 300: loss 0.589291\n",
      "iteration 276 / 300: loss 0.599526\n",
      "iteration 276 / 300: loss 0.604855\n",
      "iteration 276 / 300: loss 0.619414\n",
      "iteration 276 / 300: loss 0.588808\n",
      "iteration 276 / 300: loss 0.593645\n",
      "iteration 276 / 300: loss 0.585595\n",
      "iteration 276 / 300: loss 0.613212\n",
      "iteration 276 / 300: loss 0.587523\n",
      "iteration 276 / 300: loss 0.578328\n",
      "iteration 276 / 300: loss 0.567435\n",
      "iteration 276 / 300: loss 0.562235\n",
      "iteration 276 / 300: loss 0.594183\n",
      "iteration 276 / 300: loss 0.578821\n",
      "iteration 276 / 300: loss 0.586360\n",
      "iteration 276 / 300: loss 0.572890\n",
      "iteration 276 / 300: loss 0.596151\n",
      "iteration 276 / 300: loss 0.607951\n",
      "iteration 276 / 300: loss 0.610839\n",
      "iteration 276 / 300: loss 0.606265\n",
      "iteration 276 / 300: loss 0.583790\n",
      "iteration 276 / 300: loss 0.589627\n",
      "iteration 276 / 300: loss 0.595184\n",
      "iteration 276 / 300: loss 0.598955\n",
      "iteration 276 / 300: loss 0.596133\n",
      "iteration 276 / 300: loss 0.589769\n",
      "iteration 276 / 300: loss 0.591136\n",
      "iteration 276 / 300: loss 0.584854\n",
      "iteration 276 / 300: loss 0.599646\n",
      "iteration 276 / 300: loss 0.598902\n",
      "iteration 276 / 300: loss 0.614282\n",
      "iteration 276 / 300: loss 0.597796\n",
      "iteration 276 / 300: loss 0.599298\n",
      "iteration 276 / 300: loss 0.603317\n",
      "iteration 276 / 300: loss 0.592865\n",
      "iteration 276 / 300: loss 0.592391\n",
      "iteration 276 / 300: loss 0.589041\n",
      "iteration 276 / 300: loss 0.596446\n",
      "iteration 276 / 300: loss 0.605709\n",
      "iteration 276 / 300: loss 0.610562\n",
      "iteration 276 / 300: loss 0.587782\n",
      "iteration 276 / 300: loss 0.599351\n",
      "iteration 276 / 300: loss 0.602792\n",
      "iteration 276 / 300: loss 0.605028\n",
      "iteration 276 / 300: loss 0.603848\n",
      "iteration 276 / 300: loss 0.624144\n",
      "iteration 276 / 300: loss 0.587219\n",
      "iteration 276 / 300: loss 0.580754\n",
      "iteration 276 / 300: loss 0.625045\n",
      "iteration 276 / 300: loss 0.603310\n",
      "iteration 276 / 300: loss 0.604321\n",
      "iteration 276 / 300: loss 0.595476\n",
      "iteration 276 / 300: loss 0.597543\n",
      "iteration 276 / 300: loss 0.592740\n",
      "iteration 276 / 300: loss 0.589494\n",
      "iteration 276 / 300: loss 0.599264\n",
      "iteration 276 / 300: loss 0.611379\n",
      "iteration 276 / 300: loss 0.592463\n",
      "iteration 276 / 300: loss 0.599424\n",
      "iteration 276 / 300: loss 0.603100\n",
      "iteration 276 / 300: loss 0.602410\n",
      "iteration 276 / 300: loss 0.579811\n",
      "iteration 276 / 300: loss 0.601592\n",
      "iteration 277 / 300: loss 0.585528\n",
      "iteration 277 / 300: loss 0.588428\n",
      "iteration 277 / 300: loss 0.567516\n",
      "iteration 277 / 300: loss 0.592380\n",
      "iteration 277 / 300: loss 0.593618\n",
      "iteration 277 / 300: loss 0.595295\n",
      "iteration 277 / 300: loss 0.608784\n",
      "iteration 277 / 300: loss 0.592732\n",
      "iteration 277 / 300: loss 0.628060\n",
      "iteration 277 / 300: loss 0.580152\n",
      "iteration 277 / 300: loss 0.607923\n",
      "iteration 277 / 300: loss 0.587394\n",
      "iteration 277 / 300: loss 0.591686\n",
      "iteration 277 / 300: loss 0.571370\n",
      "iteration 277 / 300: loss 0.583025\n",
      "iteration 277 / 300: loss 0.608441\n",
      "iteration 277 / 300: loss 0.598359\n",
      "iteration 277 / 300: loss 0.583858\n",
      "iteration 277 / 300: loss 0.615253\n",
      "iteration 277 / 300: loss 0.591649\n",
      "iteration 277 / 300: loss 0.585499\n",
      "iteration 277 / 300: loss 0.591325\n",
      "iteration 277 / 300: loss 0.604341\n",
      "iteration 277 / 300: loss 0.595786\n",
      "iteration 277 / 300: loss 0.614949\n",
      "iteration 277 / 300: loss 0.608389\n",
      "iteration 277 / 300: loss 0.598222\n",
      "iteration 277 / 300: loss 0.588936\n",
      "iteration 277 / 300: loss 0.617757\n",
      "iteration 277 / 300: loss 0.594770\n",
      "iteration 277 / 300: loss 0.601684\n",
      "iteration 277 / 300: loss 0.631031\n",
      "iteration 277 / 300: loss 0.587513\n",
      "iteration 277 / 300: loss 0.606561\n",
      "iteration 277 / 300: loss 0.588034\n",
      "iteration 277 / 300: loss 0.600890\n",
      "iteration 277 / 300: loss 0.595958\n",
      "iteration 277 / 300: loss 0.589291\n",
      "iteration 277 / 300: loss 0.599526\n",
      "iteration 277 / 300: loss 0.604855\n",
      "iteration 277 / 300: loss 0.619414\n",
      "iteration 277 / 300: loss 0.588808\n",
      "iteration 277 / 300: loss 0.593645\n",
      "iteration 277 / 300: loss 0.585595\n",
      "iteration 277 / 300: loss 0.613212\n",
      "iteration 277 / 300: loss 0.587523\n",
      "iteration 277 / 300: loss 0.578328\n",
      "iteration 277 / 300: loss 0.567435\n",
      "iteration 277 / 300: loss 0.562235\n",
      "iteration 277 / 300: loss 0.594183\n",
      "iteration 277 / 300: loss 0.578821\n",
      "iteration 277 / 300: loss 0.586360\n",
      "iteration 277 / 300: loss 0.572890\n",
      "iteration 277 / 300: loss 0.596151\n",
      "iteration 277 / 300: loss 0.607951\n",
      "iteration 277 / 300: loss 0.610839\n",
      "iteration 277 / 300: loss 0.606265\n",
      "iteration 277 / 300: loss 0.583790\n",
      "iteration 277 / 300: loss 0.589627\n",
      "iteration 277 / 300: loss 0.595184\n",
      "iteration 277 / 300: loss 0.598955\n",
      "iteration 277 / 300: loss 0.596133\n",
      "iteration 277 / 300: loss 0.589769\n",
      "iteration 277 / 300: loss 0.591136\n",
      "iteration 277 / 300: loss 0.584854\n",
      "iteration 277 / 300: loss 0.599646\n",
      "iteration 277 / 300: loss 0.598902\n",
      "iteration 277 / 300: loss 0.614282\n",
      "iteration 277 / 300: loss 0.597796\n",
      "iteration 277 / 300: loss 0.599298\n",
      "iteration 277 / 300: loss 0.603317\n",
      "iteration 277 / 300: loss 0.592865\n",
      "iteration 277 / 300: loss 0.592391\n",
      "iteration 277 / 300: loss 0.589041\n",
      "iteration 277 / 300: loss 0.596446\n",
      "iteration 277 / 300: loss 0.605709\n",
      "iteration 277 / 300: loss 0.610562\n",
      "iteration 277 / 300: loss 0.587782\n",
      "iteration 277 / 300: loss 0.599351\n",
      "iteration 277 / 300: loss 0.602792\n",
      "iteration 277 / 300: loss 0.605028\n",
      "iteration 277 / 300: loss 0.603848\n",
      "iteration 277 / 300: loss 0.624144\n",
      "iteration 277 / 300: loss 0.587219\n",
      "iteration 277 / 300: loss 0.580754\n",
      "iteration 277 / 300: loss 0.625045\n",
      "iteration 277 / 300: loss 0.603310\n",
      "iteration 277 / 300: loss 0.604321\n",
      "iteration 277 / 300: loss 0.595476\n",
      "iteration 277 / 300: loss 0.597543\n",
      "iteration 277 / 300: loss 0.592740\n",
      "iteration 277 / 300: loss 0.589494\n",
      "iteration 277 / 300: loss 0.599264\n",
      "iteration 277 / 300: loss 0.611379\n",
      "iteration 277 / 300: loss 0.592463\n",
      "iteration 277 / 300: loss 0.599424\n",
      "iteration 277 / 300: loss 0.603100\n",
      "iteration 277 / 300: loss 0.602410\n",
      "iteration 277 / 300: loss 0.579811\n",
      "iteration 277 / 300: loss 0.601592\n",
      "iteration 278 / 300: loss 0.585528\n",
      "iteration 278 / 300: loss 0.588428\n",
      "iteration 278 / 300: loss 0.567516\n",
      "iteration 278 / 300: loss 0.592380\n",
      "iteration 278 / 300: loss 0.593618\n",
      "iteration 278 / 300: loss 0.595295\n",
      "iteration 278 / 300: loss 0.608784\n",
      "iteration 278 / 300: loss 0.592732\n",
      "iteration 278 / 300: loss 0.628060\n",
      "iteration 278 / 300: loss 0.580152\n",
      "iteration 278 / 300: loss 0.607923\n",
      "iteration 278 / 300: loss 0.587394\n",
      "iteration 278 / 300: loss 0.591686\n",
      "iteration 278 / 300: loss 0.571370\n",
      "iteration 278 / 300: loss 0.583025\n",
      "iteration 278 / 300: loss 0.608441\n",
      "iteration 278 / 300: loss 0.598359\n",
      "iteration 278 / 300: loss 0.583858\n",
      "iteration 278 / 300: loss 0.615253\n",
      "iteration 278 / 300: loss 0.591649\n",
      "iteration 278 / 300: loss 0.585499\n",
      "iteration 278 / 300: loss 0.591325\n",
      "iteration 278 / 300: loss 0.604341\n",
      "iteration 278 / 300: loss 0.595786\n",
      "iteration 278 / 300: loss 0.614949\n",
      "iteration 278 / 300: loss 0.608389\n",
      "iteration 278 / 300: loss 0.598222\n",
      "iteration 278 / 300: loss 0.588936\n",
      "iteration 278 / 300: loss 0.617757\n",
      "iteration 278 / 300: loss 0.594770\n",
      "iteration 278 / 300: loss 0.601684\n",
      "iteration 278 / 300: loss 0.631031\n",
      "iteration 278 / 300: loss 0.587513\n",
      "iteration 278 / 300: loss 0.606561\n",
      "iteration 278 / 300: loss 0.588034\n",
      "iteration 278 / 300: loss 0.600890\n",
      "iteration 278 / 300: loss 0.595958\n",
      "iteration 278 / 300: loss 0.589291\n",
      "iteration 278 / 300: loss 0.599526\n",
      "iteration 278 / 300: loss 0.604855\n",
      "iteration 278 / 300: loss 0.619414\n",
      "iteration 278 / 300: loss 0.588808\n",
      "iteration 278 / 300: loss 0.593645\n",
      "iteration 278 / 300: loss 0.585595\n",
      "iteration 278 / 300: loss 0.613212\n",
      "iteration 278 / 300: loss 0.587523\n",
      "iteration 278 / 300: loss 0.578328\n",
      "iteration 278 / 300: loss 0.567435\n",
      "iteration 278 / 300: loss 0.562235\n",
      "iteration 278 / 300: loss 0.594183\n",
      "iteration 278 / 300: loss 0.578821\n",
      "iteration 278 / 300: loss 0.586360\n",
      "iteration 278 / 300: loss 0.572890\n",
      "iteration 278 / 300: loss 0.596151\n",
      "iteration 278 / 300: loss 0.607951\n",
      "iteration 278 / 300: loss 0.610839\n",
      "iteration 278 / 300: loss 0.606265\n",
      "iteration 278 / 300: loss 0.583790\n",
      "iteration 278 / 300: loss 0.589627\n",
      "iteration 278 / 300: loss 0.595184\n",
      "iteration 278 / 300: loss 0.598955\n",
      "iteration 278 / 300: loss 0.596133\n",
      "iteration 278 / 300: loss 0.589769\n",
      "iteration 278 / 300: loss 0.591136\n",
      "iteration 278 / 300: loss 0.584854\n",
      "iteration 278 / 300: loss 0.599646\n",
      "iteration 278 / 300: loss 0.598902\n",
      "iteration 278 / 300: loss 0.614282\n",
      "iteration 278 / 300: loss 0.597796\n",
      "iteration 278 / 300: loss 0.599298\n",
      "iteration 278 / 300: loss 0.603317\n",
      "iteration 278 / 300: loss 0.592865\n",
      "iteration 278 / 300: loss 0.592391\n",
      "iteration 278 / 300: loss 0.589041\n",
      "iteration 278 / 300: loss 0.596446\n",
      "iteration 278 / 300: loss 0.605709\n",
      "iteration 278 / 300: loss 0.610562\n",
      "iteration 278 / 300: loss 0.587782\n",
      "iteration 278 / 300: loss 0.599351\n",
      "iteration 278 / 300: loss 0.602792\n",
      "iteration 278 / 300: loss 0.605028\n",
      "iteration 278 / 300: loss 0.603848\n",
      "iteration 278 / 300: loss 0.624144\n",
      "iteration 278 / 300: loss 0.587219\n",
      "iteration 278 / 300: loss 0.580754\n",
      "iteration 278 / 300: loss 0.625045\n",
      "iteration 278 / 300: loss 0.603310\n",
      "iteration 278 / 300: loss 0.604321\n",
      "iteration 278 / 300: loss 0.595476\n",
      "iteration 278 / 300: loss 0.597543\n",
      "iteration 278 / 300: loss 0.592740\n",
      "iteration 278 / 300: loss 0.589494\n",
      "iteration 278 / 300: loss 0.599264\n",
      "iteration 278 / 300: loss 0.611379\n",
      "iteration 278 / 300: loss 0.592463\n",
      "iteration 278 / 300: loss 0.599424\n",
      "iteration 278 / 300: loss 0.603100\n",
      "iteration 278 / 300: loss 0.602410\n",
      "iteration 278 / 300: loss 0.579811\n",
      "iteration 278 / 300: loss 0.601592\n",
      "iteration 279 / 300: loss 0.585528\n",
      "iteration 279 / 300: loss 0.588428\n",
      "iteration 279 / 300: loss 0.567516\n",
      "iteration 279 / 300: loss 0.592380\n",
      "iteration 279 / 300: loss 0.593618\n",
      "iteration 279 / 300: loss 0.595295\n",
      "iteration 279 / 300: loss 0.608784\n",
      "iteration 279 / 300: loss 0.592732\n",
      "iteration 279 / 300: loss 0.628060\n",
      "iteration 279 / 300: loss 0.580152\n",
      "iteration 279 / 300: loss 0.607923\n",
      "iteration 279 / 300: loss 0.587394\n",
      "iteration 279 / 300: loss 0.591686\n",
      "iteration 279 / 300: loss 0.571370\n",
      "iteration 279 / 300: loss 0.583025\n",
      "iteration 279 / 300: loss 0.608441\n",
      "iteration 279 / 300: loss 0.598359\n",
      "iteration 279 / 300: loss 0.583858\n",
      "iteration 279 / 300: loss 0.615253\n",
      "iteration 279 / 300: loss 0.591649\n",
      "iteration 279 / 300: loss 0.585499\n",
      "iteration 279 / 300: loss 0.591325\n",
      "iteration 279 / 300: loss 0.604341\n",
      "iteration 279 / 300: loss 0.595786\n",
      "iteration 279 / 300: loss 0.614949\n",
      "iteration 279 / 300: loss 0.608389\n",
      "iteration 279 / 300: loss 0.598222\n",
      "iteration 279 / 300: loss 0.588936\n",
      "iteration 279 / 300: loss 0.617757\n",
      "iteration 279 / 300: loss 0.594770\n",
      "iteration 279 / 300: loss 0.601684\n",
      "iteration 279 / 300: loss 0.631031\n",
      "iteration 279 / 300: loss 0.587513\n",
      "iteration 279 / 300: loss 0.606561\n",
      "iteration 279 / 300: loss 0.588034\n",
      "iteration 279 / 300: loss 0.600890\n",
      "iteration 279 / 300: loss 0.595958\n",
      "iteration 279 / 300: loss 0.589291\n",
      "iteration 279 / 300: loss 0.599526\n",
      "iteration 279 / 300: loss 0.604855\n",
      "iteration 279 / 300: loss 0.619414\n",
      "iteration 279 / 300: loss 0.588808\n",
      "iteration 279 / 300: loss 0.593645\n",
      "iteration 279 / 300: loss 0.585595\n",
      "iteration 279 / 300: loss 0.613212\n",
      "iteration 279 / 300: loss 0.587523\n",
      "iteration 279 / 300: loss 0.578328\n",
      "iteration 279 / 300: loss 0.567435\n",
      "iteration 279 / 300: loss 0.562235\n",
      "iteration 279 / 300: loss 0.594183\n",
      "iteration 279 / 300: loss 0.578821\n",
      "iteration 279 / 300: loss 0.586360\n",
      "iteration 279 / 300: loss 0.572890\n",
      "iteration 279 / 300: loss 0.596151\n",
      "iteration 279 / 300: loss 0.607951\n",
      "iteration 279 / 300: loss 0.610839\n",
      "iteration 279 / 300: loss 0.606265\n",
      "iteration 279 / 300: loss 0.583790\n",
      "iteration 279 / 300: loss 0.589627\n",
      "iteration 279 / 300: loss 0.595184\n",
      "iteration 279 / 300: loss 0.598955\n",
      "iteration 279 / 300: loss 0.596133\n",
      "iteration 279 / 300: loss 0.589769\n",
      "iteration 279 / 300: loss 0.591136\n",
      "iteration 279 / 300: loss 0.584854\n",
      "iteration 279 / 300: loss 0.599646\n",
      "iteration 279 / 300: loss 0.598902\n",
      "iteration 279 / 300: loss 0.614282\n",
      "iteration 279 / 300: loss 0.597796\n",
      "iteration 279 / 300: loss 0.599298\n",
      "iteration 279 / 300: loss 0.603317\n",
      "iteration 279 / 300: loss 0.592865\n",
      "iteration 279 / 300: loss 0.592391\n",
      "iteration 279 / 300: loss 0.589041\n",
      "iteration 279 / 300: loss 0.596446\n",
      "iteration 279 / 300: loss 0.605709\n",
      "iteration 279 / 300: loss 0.610562\n",
      "iteration 279 / 300: loss 0.587782\n",
      "iteration 279 / 300: loss 0.599351\n",
      "iteration 279 / 300: loss 0.602792\n",
      "iteration 279 / 300: loss 0.605028\n",
      "iteration 279 / 300: loss 0.603848\n",
      "iteration 279 / 300: loss 0.624144\n",
      "iteration 279 / 300: loss 0.587219\n",
      "iteration 279 / 300: loss 0.580754\n",
      "iteration 279 / 300: loss 0.625045\n",
      "iteration 279 / 300: loss 0.603310\n",
      "iteration 279 / 300: loss 0.604321\n",
      "iteration 279 / 300: loss 0.595476\n",
      "iteration 279 / 300: loss 0.597543\n",
      "iteration 279 / 300: loss 0.592740\n",
      "iteration 279 / 300: loss 0.589494\n",
      "iteration 279 / 300: loss 0.599264\n",
      "iteration 279 / 300: loss 0.611379\n",
      "iteration 279 / 300: loss 0.592463\n",
      "iteration 279 / 300: loss 0.599424\n",
      "iteration 279 / 300: loss 0.603100\n",
      "iteration 279 / 300: loss 0.602410\n",
      "iteration 279 / 300: loss 0.579811\n",
      "iteration 279 / 300: loss 0.601592\n",
      "iteration 280 / 300: loss 0.585528\n",
      "iteration 280 / 300: loss 0.588428\n",
      "iteration 280 / 300: loss 0.567516\n",
      "iteration 280 / 300: loss 0.592380\n",
      "iteration 280 / 300: loss 0.593618\n",
      "iteration 280 / 300: loss 0.595295\n",
      "iteration 280 / 300: loss 0.608784\n",
      "iteration 280 / 300: loss 0.592732\n",
      "iteration 280 / 300: loss 0.628060\n",
      "iteration 280 / 300: loss 0.580152\n",
      "iteration 280 / 300: loss 0.607923\n",
      "iteration 280 / 300: loss 0.587394\n",
      "iteration 280 / 300: loss 0.591686\n",
      "iteration 280 / 300: loss 0.571370\n",
      "iteration 280 / 300: loss 0.583025\n",
      "iteration 280 / 300: loss 0.608441\n",
      "iteration 280 / 300: loss 0.598359\n",
      "iteration 280 / 300: loss 0.583858\n",
      "iteration 280 / 300: loss 0.615253\n",
      "iteration 280 / 300: loss 0.591649\n",
      "iteration 280 / 300: loss 0.585499\n",
      "iteration 280 / 300: loss 0.591325\n",
      "iteration 280 / 300: loss 0.604341\n",
      "iteration 280 / 300: loss 0.595786\n",
      "iteration 280 / 300: loss 0.614949\n",
      "iteration 280 / 300: loss 0.608389\n",
      "iteration 280 / 300: loss 0.598222\n",
      "iteration 280 / 300: loss 0.588936\n",
      "iteration 280 / 300: loss 0.617757\n",
      "iteration 280 / 300: loss 0.594770\n",
      "iteration 280 / 300: loss 0.601684\n",
      "iteration 280 / 300: loss 0.631031\n",
      "iteration 280 / 300: loss 0.587513\n",
      "iteration 280 / 300: loss 0.606561\n",
      "iteration 280 / 300: loss 0.588034\n",
      "iteration 280 / 300: loss 0.600890\n",
      "iteration 280 / 300: loss 0.595958\n",
      "iteration 280 / 300: loss 0.589291\n",
      "iteration 280 / 300: loss 0.599526\n",
      "iteration 280 / 300: loss 0.604855\n",
      "iteration 280 / 300: loss 0.619414\n",
      "iteration 280 / 300: loss 0.588808\n",
      "iteration 280 / 300: loss 0.593645\n",
      "iteration 280 / 300: loss 0.585595\n",
      "iteration 280 / 300: loss 0.613212\n",
      "iteration 280 / 300: loss 0.587523\n",
      "iteration 280 / 300: loss 0.578328\n",
      "iteration 280 / 300: loss 0.567435\n",
      "iteration 280 / 300: loss 0.562235\n",
      "iteration 280 / 300: loss 0.594183\n",
      "iteration 280 / 300: loss 0.578821\n",
      "iteration 280 / 300: loss 0.586360\n",
      "iteration 280 / 300: loss 0.572890\n",
      "iteration 280 / 300: loss 0.596151\n",
      "iteration 280 / 300: loss 0.607951\n",
      "iteration 280 / 300: loss 0.610839\n",
      "iteration 280 / 300: loss 0.606265\n",
      "iteration 280 / 300: loss 0.583790\n",
      "iteration 280 / 300: loss 0.589627\n",
      "iteration 280 / 300: loss 0.595184\n",
      "iteration 280 / 300: loss 0.598955\n",
      "iteration 280 / 300: loss 0.596133\n",
      "iteration 280 / 300: loss 0.589769\n",
      "iteration 280 / 300: loss 0.591136\n",
      "iteration 280 / 300: loss 0.584854\n",
      "iteration 280 / 300: loss 0.599646\n",
      "iteration 280 / 300: loss 0.598902\n",
      "iteration 280 / 300: loss 0.614282\n",
      "iteration 280 / 300: loss 0.597796\n",
      "iteration 280 / 300: loss 0.599298\n",
      "iteration 280 / 300: loss 0.603317\n",
      "iteration 280 / 300: loss 0.592865\n",
      "iteration 280 / 300: loss 0.592391\n",
      "iteration 280 / 300: loss 0.589041\n",
      "iteration 280 / 300: loss 0.596446\n",
      "iteration 280 / 300: loss 0.605709\n",
      "iteration 280 / 300: loss 0.610562\n",
      "iteration 280 / 300: loss 0.587782\n",
      "iteration 280 / 300: loss 0.599351\n",
      "iteration 280 / 300: loss 0.602792\n",
      "iteration 280 / 300: loss 0.605028\n",
      "iteration 280 / 300: loss 0.603848\n",
      "iteration 280 / 300: loss 0.624144\n",
      "iteration 280 / 300: loss 0.587219\n",
      "iteration 280 / 300: loss 0.580754\n",
      "iteration 280 / 300: loss 0.625045\n",
      "iteration 280 / 300: loss 0.603310\n",
      "iteration 280 / 300: loss 0.604321\n",
      "iteration 280 / 300: loss 0.595476\n",
      "iteration 280 / 300: loss 0.597543\n",
      "iteration 280 / 300: loss 0.592740\n",
      "iteration 280 / 300: loss 0.589494\n",
      "iteration 280 / 300: loss 0.599264\n",
      "iteration 280 / 300: loss 0.611379\n",
      "iteration 280 / 300: loss 0.592463\n",
      "iteration 280 / 300: loss 0.599424\n",
      "iteration 280 / 300: loss 0.603100\n",
      "iteration 280 / 300: loss 0.602410\n",
      "iteration 280 / 300: loss 0.579811\n",
      "iteration 280 / 300: loss 0.601592\n",
      "iteration 281 / 300: loss 0.585528\n",
      "iteration 281 / 300: loss 0.588428\n",
      "iteration 281 / 300: loss 0.567516\n",
      "iteration 281 / 300: loss 0.592380\n",
      "iteration 281 / 300: loss 0.593618\n",
      "iteration 281 / 300: loss 0.595295\n",
      "iteration 281 / 300: loss 0.608784\n",
      "iteration 281 / 300: loss 0.592732\n",
      "iteration 281 / 300: loss 0.628060\n",
      "iteration 281 / 300: loss 0.580152\n",
      "iteration 281 / 300: loss 0.607923\n",
      "iteration 281 / 300: loss 0.587394\n",
      "iteration 281 / 300: loss 0.591686\n",
      "iteration 281 / 300: loss 0.571370\n",
      "iteration 281 / 300: loss 0.583025\n",
      "iteration 281 / 300: loss 0.608441\n",
      "iteration 281 / 300: loss 0.598359\n",
      "iteration 281 / 300: loss 0.583858\n",
      "iteration 281 / 300: loss 0.615253\n",
      "iteration 281 / 300: loss 0.591649\n",
      "iteration 281 / 300: loss 0.585499\n",
      "iteration 281 / 300: loss 0.591325\n",
      "iteration 281 / 300: loss 0.604341\n",
      "iteration 281 / 300: loss 0.595786\n",
      "iteration 281 / 300: loss 0.614949\n",
      "iteration 281 / 300: loss 0.608389\n",
      "iteration 281 / 300: loss 0.598222\n",
      "iteration 281 / 300: loss 0.588936\n",
      "iteration 281 / 300: loss 0.617757\n",
      "iteration 281 / 300: loss 0.594770\n",
      "iteration 281 / 300: loss 0.601684\n",
      "iteration 281 / 300: loss 0.631031\n",
      "iteration 281 / 300: loss 0.587513\n",
      "iteration 281 / 300: loss 0.606561\n",
      "iteration 281 / 300: loss 0.588034\n",
      "iteration 281 / 300: loss 0.600890\n",
      "iteration 281 / 300: loss 0.595958\n",
      "iteration 281 / 300: loss 0.589291\n",
      "iteration 281 / 300: loss 0.599526\n",
      "iteration 281 / 300: loss 0.604855\n",
      "iteration 281 / 300: loss 0.619414\n",
      "iteration 281 / 300: loss 0.588808\n",
      "iteration 281 / 300: loss 0.593645\n",
      "iteration 281 / 300: loss 0.585595\n",
      "iteration 281 / 300: loss 0.613212\n",
      "iteration 281 / 300: loss 0.587523\n",
      "iteration 281 / 300: loss 0.578328\n",
      "iteration 281 / 300: loss 0.567435\n",
      "iteration 281 / 300: loss 0.562235\n",
      "iteration 281 / 300: loss 0.594183\n",
      "iteration 281 / 300: loss 0.578821\n",
      "iteration 281 / 300: loss 0.586360\n",
      "iteration 281 / 300: loss 0.572890\n",
      "iteration 281 / 300: loss 0.596151\n",
      "iteration 281 / 300: loss 0.607951\n",
      "iteration 281 / 300: loss 0.610839\n",
      "iteration 281 / 300: loss 0.606265\n",
      "iteration 281 / 300: loss 0.583790\n",
      "iteration 281 / 300: loss 0.589627\n",
      "iteration 281 / 300: loss 0.595184\n",
      "iteration 281 / 300: loss 0.598955\n",
      "iteration 281 / 300: loss 0.596133\n",
      "iteration 281 / 300: loss 0.589769\n",
      "iteration 281 / 300: loss 0.591136\n",
      "iteration 281 / 300: loss 0.584854\n",
      "iteration 281 / 300: loss 0.599646\n",
      "iteration 281 / 300: loss 0.598902\n",
      "iteration 281 / 300: loss 0.614282\n",
      "iteration 281 / 300: loss 0.597796\n",
      "iteration 281 / 300: loss 0.599298\n",
      "iteration 281 / 300: loss 0.603317\n",
      "iteration 281 / 300: loss 0.592865\n",
      "iteration 281 / 300: loss 0.592391\n",
      "iteration 281 / 300: loss 0.589041\n",
      "iteration 281 / 300: loss 0.596446\n",
      "iteration 281 / 300: loss 0.605709\n",
      "iteration 281 / 300: loss 0.610562\n",
      "iteration 281 / 300: loss 0.587782\n",
      "iteration 281 / 300: loss 0.599351\n",
      "iteration 281 / 300: loss 0.602792\n",
      "iteration 281 / 300: loss 0.605028\n",
      "iteration 281 / 300: loss 0.603848\n",
      "iteration 281 / 300: loss 0.624144\n",
      "iteration 281 / 300: loss 0.587219\n",
      "iteration 281 / 300: loss 0.580754\n",
      "iteration 281 / 300: loss 0.625045\n",
      "iteration 281 / 300: loss 0.603310\n",
      "iteration 281 / 300: loss 0.604321\n",
      "iteration 281 / 300: loss 0.595476\n",
      "iteration 281 / 300: loss 0.597543\n",
      "iteration 281 / 300: loss 0.592740\n",
      "iteration 281 / 300: loss 0.589494\n",
      "iteration 281 / 300: loss 0.599264\n",
      "iteration 281 / 300: loss 0.611379\n",
      "iteration 281 / 300: loss 0.592463\n",
      "iteration 281 / 300: loss 0.599424\n",
      "iteration 281 / 300: loss 0.603100\n",
      "iteration 281 / 300: loss 0.602410\n",
      "iteration 281 / 300: loss 0.579811\n",
      "iteration 281 / 300: loss 0.601592\n",
      "iteration 282 / 300: loss 0.585528\n",
      "iteration 282 / 300: loss 0.588428\n",
      "iteration 282 / 300: loss 0.567516\n",
      "iteration 282 / 300: loss 0.592380\n",
      "iteration 282 / 300: loss 0.593618\n",
      "iteration 282 / 300: loss 0.595295\n",
      "iteration 282 / 300: loss 0.608784\n",
      "iteration 282 / 300: loss 0.592732\n",
      "iteration 282 / 300: loss 0.628060\n",
      "iteration 282 / 300: loss 0.580152\n",
      "iteration 282 / 300: loss 0.607923\n",
      "iteration 282 / 300: loss 0.587394\n",
      "iteration 282 / 300: loss 0.591686\n",
      "iteration 282 / 300: loss 0.571370\n",
      "iteration 282 / 300: loss 0.583025\n",
      "iteration 282 / 300: loss 0.608441\n",
      "iteration 282 / 300: loss 0.598359\n",
      "iteration 282 / 300: loss 0.583858\n",
      "iteration 282 / 300: loss 0.615253\n",
      "iteration 282 / 300: loss 0.591649\n",
      "iteration 282 / 300: loss 0.585499\n",
      "iteration 282 / 300: loss 0.591325\n",
      "iteration 282 / 300: loss 0.604341\n",
      "iteration 282 / 300: loss 0.595786\n",
      "iteration 282 / 300: loss 0.614949\n",
      "iteration 282 / 300: loss 0.608389\n",
      "iteration 282 / 300: loss 0.598222\n",
      "iteration 282 / 300: loss 0.588936\n",
      "iteration 282 / 300: loss 0.617757\n",
      "iteration 282 / 300: loss 0.594770\n",
      "iteration 282 / 300: loss 0.601684\n",
      "iteration 282 / 300: loss 0.631031\n",
      "iteration 282 / 300: loss 0.587513\n",
      "iteration 282 / 300: loss 0.606561\n",
      "iteration 282 / 300: loss 0.588034\n",
      "iteration 282 / 300: loss 0.600890\n",
      "iteration 282 / 300: loss 0.595958\n",
      "iteration 282 / 300: loss 0.589291\n",
      "iteration 282 / 300: loss 0.599526\n",
      "iteration 282 / 300: loss 0.604855\n",
      "iteration 282 / 300: loss 0.619414\n",
      "iteration 282 / 300: loss 0.588808\n",
      "iteration 282 / 300: loss 0.593645\n",
      "iteration 282 / 300: loss 0.585595\n",
      "iteration 282 / 300: loss 0.613212\n",
      "iteration 282 / 300: loss 0.587523\n",
      "iteration 282 / 300: loss 0.578328\n",
      "iteration 282 / 300: loss 0.567435\n",
      "iteration 282 / 300: loss 0.562235\n",
      "iteration 282 / 300: loss 0.594183\n",
      "iteration 282 / 300: loss 0.578821\n",
      "iteration 282 / 300: loss 0.586360\n",
      "iteration 282 / 300: loss 0.572890\n",
      "iteration 282 / 300: loss 0.596151\n",
      "iteration 282 / 300: loss 0.607951\n",
      "iteration 282 / 300: loss 0.610839\n",
      "iteration 282 / 300: loss 0.606265\n",
      "iteration 282 / 300: loss 0.583790\n",
      "iteration 282 / 300: loss 0.589627\n",
      "iteration 282 / 300: loss 0.595184\n",
      "iteration 282 / 300: loss 0.598955\n",
      "iteration 282 / 300: loss 0.596133\n",
      "iteration 282 / 300: loss 0.589769\n",
      "iteration 282 / 300: loss 0.591136\n",
      "iteration 282 / 300: loss 0.584854\n",
      "iteration 282 / 300: loss 0.599646\n",
      "iteration 282 / 300: loss 0.598902\n",
      "iteration 282 / 300: loss 0.614282\n",
      "iteration 282 / 300: loss 0.597796\n",
      "iteration 282 / 300: loss 0.599298\n",
      "iteration 282 / 300: loss 0.603317\n",
      "iteration 282 / 300: loss 0.592865\n",
      "iteration 282 / 300: loss 0.592391\n",
      "iteration 282 / 300: loss 0.589041\n",
      "iteration 282 / 300: loss 0.596446\n",
      "iteration 282 / 300: loss 0.605709\n",
      "iteration 282 / 300: loss 0.610562\n",
      "iteration 282 / 300: loss 0.587782\n",
      "iteration 282 / 300: loss 0.599351\n",
      "iteration 282 / 300: loss 0.602792\n",
      "iteration 282 / 300: loss 0.605028\n",
      "iteration 282 / 300: loss 0.603848\n",
      "iteration 282 / 300: loss 0.624144\n",
      "iteration 282 / 300: loss 0.587219\n",
      "iteration 282 / 300: loss 0.580754\n",
      "iteration 282 / 300: loss 0.625045\n",
      "iteration 282 / 300: loss 0.603310\n",
      "iteration 282 / 300: loss 0.604321\n",
      "iteration 282 / 300: loss 0.595476\n",
      "iteration 282 / 300: loss 0.597543\n",
      "iteration 282 / 300: loss 0.592740\n",
      "iteration 282 / 300: loss 0.589494\n",
      "iteration 282 / 300: loss 0.599264\n",
      "iteration 282 / 300: loss 0.611379\n",
      "iteration 282 / 300: loss 0.592463\n",
      "iteration 282 / 300: loss 0.599424\n",
      "iteration 282 / 300: loss 0.603100\n",
      "iteration 282 / 300: loss 0.602410\n",
      "iteration 282 / 300: loss 0.579811\n",
      "iteration 282 / 300: loss 0.601592\n",
      "iteration 283 / 300: loss 0.585528\n",
      "iteration 283 / 300: loss 0.588428\n",
      "iteration 283 / 300: loss 0.567516\n",
      "iteration 283 / 300: loss 0.592380\n",
      "iteration 283 / 300: loss 0.593618\n",
      "iteration 283 / 300: loss 0.595295\n",
      "iteration 283 / 300: loss 0.608784\n",
      "iteration 283 / 300: loss 0.592732\n",
      "iteration 283 / 300: loss 0.628060\n",
      "iteration 283 / 300: loss 0.580152\n",
      "iteration 283 / 300: loss 0.607923\n",
      "iteration 283 / 300: loss 0.587394\n",
      "iteration 283 / 300: loss 0.591686\n",
      "iteration 283 / 300: loss 0.571370\n",
      "iteration 283 / 300: loss 0.583025\n",
      "iteration 283 / 300: loss 0.608441\n",
      "iteration 283 / 300: loss 0.598359\n",
      "iteration 283 / 300: loss 0.583858\n",
      "iteration 283 / 300: loss 0.615253\n",
      "iteration 283 / 300: loss 0.591649\n",
      "iteration 283 / 300: loss 0.585499\n",
      "iteration 283 / 300: loss 0.591325\n",
      "iteration 283 / 300: loss 0.604341\n",
      "iteration 283 / 300: loss 0.595786\n",
      "iteration 283 / 300: loss 0.614949\n",
      "iteration 283 / 300: loss 0.608389\n",
      "iteration 283 / 300: loss 0.598222\n",
      "iteration 283 / 300: loss 0.588936\n",
      "iteration 283 / 300: loss 0.617757\n",
      "iteration 283 / 300: loss 0.594770\n",
      "iteration 283 / 300: loss 0.601684\n",
      "iteration 283 / 300: loss 0.631031\n",
      "iteration 283 / 300: loss 0.587513\n",
      "iteration 283 / 300: loss 0.606561\n",
      "iteration 283 / 300: loss 0.588034\n",
      "iteration 283 / 300: loss 0.600890\n",
      "iteration 283 / 300: loss 0.595958\n",
      "iteration 283 / 300: loss 0.589291\n",
      "iteration 283 / 300: loss 0.599526\n",
      "iteration 283 / 300: loss 0.604855\n",
      "iteration 283 / 300: loss 0.619414\n",
      "iteration 283 / 300: loss 0.588808\n",
      "iteration 283 / 300: loss 0.593645\n",
      "iteration 283 / 300: loss 0.585595\n",
      "iteration 283 / 300: loss 0.613212\n",
      "iteration 283 / 300: loss 0.587523\n",
      "iteration 283 / 300: loss 0.578328\n",
      "iteration 283 / 300: loss 0.567435\n",
      "iteration 283 / 300: loss 0.562235\n",
      "iteration 283 / 300: loss 0.594183\n",
      "iteration 283 / 300: loss 0.578821\n",
      "iteration 283 / 300: loss 0.586360\n",
      "iteration 283 / 300: loss 0.572890\n",
      "iteration 283 / 300: loss 0.596151\n",
      "iteration 283 / 300: loss 0.607951\n",
      "iteration 283 / 300: loss 0.610839\n",
      "iteration 283 / 300: loss 0.606265\n",
      "iteration 283 / 300: loss 0.583790\n",
      "iteration 283 / 300: loss 0.589627\n",
      "iteration 283 / 300: loss 0.595184\n",
      "iteration 283 / 300: loss 0.598955\n",
      "iteration 283 / 300: loss 0.596133\n",
      "iteration 283 / 300: loss 0.589769\n",
      "iteration 283 / 300: loss 0.591136\n",
      "iteration 283 / 300: loss 0.584854\n",
      "iteration 283 / 300: loss 0.599646\n",
      "iteration 283 / 300: loss 0.598902\n",
      "iteration 283 / 300: loss 0.614282\n",
      "iteration 283 / 300: loss 0.597796\n",
      "iteration 283 / 300: loss 0.599298\n",
      "iteration 283 / 300: loss 0.603317\n",
      "iteration 283 / 300: loss 0.592865\n",
      "iteration 283 / 300: loss 0.592391\n",
      "iteration 283 / 300: loss 0.589041\n",
      "iteration 283 / 300: loss 0.596446\n",
      "iteration 283 / 300: loss 0.605709\n",
      "iteration 283 / 300: loss 0.610562\n",
      "iteration 283 / 300: loss 0.587782\n",
      "iteration 283 / 300: loss 0.599351\n",
      "iteration 283 / 300: loss 0.602792\n",
      "iteration 283 / 300: loss 0.605028\n",
      "iteration 283 / 300: loss 0.603848\n",
      "iteration 283 / 300: loss 0.624144\n",
      "iteration 283 / 300: loss 0.587219\n",
      "iteration 283 / 300: loss 0.580754\n",
      "iteration 283 / 300: loss 0.625045\n",
      "iteration 283 / 300: loss 0.603310\n",
      "iteration 283 / 300: loss 0.604321\n",
      "iteration 283 / 300: loss 0.595476\n",
      "iteration 283 / 300: loss 0.597543\n",
      "iteration 283 / 300: loss 0.592740\n",
      "iteration 283 / 300: loss 0.589494\n",
      "iteration 283 / 300: loss 0.599264\n",
      "iteration 283 / 300: loss 0.611379\n",
      "iteration 283 / 300: loss 0.592463\n",
      "iteration 283 / 300: loss 0.599424\n",
      "iteration 283 / 300: loss 0.603100\n",
      "iteration 283 / 300: loss 0.602410\n",
      "iteration 283 / 300: loss 0.579811\n",
      "iteration 283 / 300: loss 0.601592\n",
      "iteration 284 / 300: loss 0.585528\n",
      "iteration 284 / 300: loss 0.588428\n",
      "iteration 284 / 300: loss 0.567516\n",
      "iteration 284 / 300: loss 0.592380\n",
      "iteration 284 / 300: loss 0.593618\n",
      "iteration 284 / 300: loss 0.595295\n",
      "iteration 284 / 300: loss 0.608784\n",
      "iteration 284 / 300: loss 0.592732\n",
      "iteration 284 / 300: loss 0.628060\n",
      "iteration 284 / 300: loss 0.580152\n",
      "iteration 284 / 300: loss 0.607923\n",
      "iteration 284 / 300: loss 0.587394\n",
      "iteration 284 / 300: loss 0.591686\n",
      "iteration 284 / 300: loss 0.571370\n",
      "iteration 284 / 300: loss 0.583025\n",
      "iteration 284 / 300: loss 0.608441\n",
      "iteration 284 / 300: loss 0.598359\n",
      "iteration 284 / 300: loss 0.583858\n",
      "iteration 284 / 300: loss 0.615253\n",
      "iteration 284 / 300: loss 0.591649\n",
      "iteration 284 / 300: loss 0.585499\n",
      "iteration 284 / 300: loss 0.591325\n",
      "iteration 284 / 300: loss 0.604341\n",
      "iteration 284 / 300: loss 0.595786\n",
      "iteration 284 / 300: loss 0.614949\n",
      "iteration 284 / 300: loss 0.608389\n",
      "iteration 284 / 300: loss 0.598222\n",
      "iteration 284 / 300: loss 0.588936\n",
      "iteration 284 / 300: loss 0.617757\n",
      "iteration 284 / 300: loss 0.594770\n",
      "iteration 284 / 300: loss 0.601684\n",
      "iteration 284 / 300: loss 0.631031\n",
      "iteration 284 / 300: loss 0.587513\n",
      "iteration 284 / 300: loss 0.606561\n",
      "iteration 284 / 300: loss 0.588034\n",
      "iteration 284 / 300: loss 0.600890\n",
      "iteration 284 / 300: loss 0.595958\n",
      "iteration 284 / 300: loss 0.589291\n",
      "iteration 284 / 300: loss 0.599526\n",
      "iteration 284 / 300: loss 0.604855\n",
      "iteration 284 / 300: loss 0.619414\n",
      "iteration 284 / 300: loss 0.588808\n",
      "iteration 284 / 300: loss 0.593645\n",
      "iteration 284 / 300: loss 0.585595\n",
      "iteration 284 / 300: loss 0.613212\n",
      "iteration 284 / 300: loss 0.587523\n",
      "iteration 284 / 300: loss 0.578328\n",
      "iteration 284 / 300: loss 0.567435\n",
      "iteration 284 / 300: loss 0.562235\n",
      "iteration 284 / 300: loss 0.594183\n",
      "iteration 284 / 300: loss 0.578821\n",
      "iteration 284 / 300: loss 0.586360\n",
      "iteration 284 / 300: loss 0.572890\n",
      "iteration 284 / 300: loss 0.596151\n",
      "iteration 284 / 300: loss 0.607951\n",
      "iteration 284 / 300: loss 0.610839\n",
      "iteration 284 / 300: loss 0.606265\n",
      "iteration 284 / 300: loss 0.583790\n",
      "iteration 284 / 300: loss 0.589627\n",
      "iteration 284 / 300: loss 0.595184\n",
      "iteration 284 / 300: loss 0.598955\n",
      "iteration 284 / 300: loss 0.596133\n",
      "iteration 284 / 300: loss 0.589769\n",
      "iteration 284 / 300: loss 0.591136\n",
      "iteration 284 / 300: loss 0.584854\n",
      "iteration 284 / 300: loss 0.599646\n",
      "iteration 284 / 300: loss 0.598902\n",
      "iteration 284 / 300: loss 0.614282\n",
      "iteration 284 / 300: loss 0.597796\n",
      "iteration 284 / 300: loss 0.599298\n",
      "iteration 284 / 300: loss 0.603317\n",
      "iteration 284 / 300: loss 0.592865\n",
      "iteration 284 / 300: loss 0.592391\n",
      "iteration 284 / 300: loss 0.589041\n",
      "iteration 284 / 300: loss 0.596446\n",
      "iteration 284 / 300: loss 0.605709\n",
      "iteration 284 / 300: loss 0.610562\n",
      "iteration 284 / 300: loss 0.587782\n",
      "iteration 284 / 300: loss 0.599351\n",
      "iteration 284 / 300: loss 0.602792\n",
      "iteration 284 / 300: loss 0.605028\n",
      "iteration 284 / 300: loss 0.603848\n",
      "iteration 284 / 300: loss 0.624144\n",
      "iteration 284 / 300: loss 0.587219\n",
      "iteration 284 / 300: loss 0.580754\n",
      "iteration 284 / 300: loss 0.625045\n",
      "iteration 284 / 300: loss 0.603310\n",
      "iteration 284 / 300: loss 0.604321\n",
      "iteration 284 / 300: loss 0.595476\n",
      "iteration 284 / 300: loss 0.597543\n",
      "iteration 284 / 300: loss 0.592740\n",
      "iteration 284 / 300: loss 0.589494\n",
      "iteration 284 / 300: loss 0.599264\n",
      "iteration 284 / 300: loss 0.611379\n",
      "iteration 284 / 300: loss 0.592463\n",
      "iteration 284 / 300: loss 0.599424\n",
      "iteration 284 / 300: loss 0.603100\n",
      "iteration 284 / 300: loss 0.602410\n",
      "iteration 284 / 300: loss 0.579811\n",
      "iteration 284 / 300: loss 0.601592\n",
      "iteration 285 / 300: loss 0.585528\n",
      "iteration 285 / 300: loss 0.588428\n",
      "iteration 285 / 300: loss 0.567516\n",
      "iteration 285 / 300: loss 0.592380\n",
      "iteration 285 / 300: loss 0.593618\n",
      "iteration 285 / 300: loss 0.595295\n",
      "iteration 285 / 300: loss 0.608784\n",
      "iteration 285 / 300: loss 0.592732\n",
      "iteration 285 / 300: loss 0.628060\n",
      "iteration 285 / 300: loss 0.580152\n",
      "iteration 285 / 300: loss 0.607923\n",
      "iteration 285 / 300: loss 0.587394\n",
      "iteration 285 / 300: loss 0.591686\n",
      "iteration 285 / 300: loss 0.571370\n",
      "iteration 285 / 300: loss 0.583025\n",
      "iteration 285 / 300: loss 0.608441\n",
      "iteration 285 / 300: loss 0.598359\n",
      "iteration 285 / 300: loss 0.583858\n",
      "iteration 285 / 300: loss 0.615253\n",
      "iteration 285 / 300: loss 0.591649\n",
      "iteration 285 / 300: loss 0.585499\n",
      "iteration 285 / 300: loss 0.591325\n",
      "iteration 285 / 300: loss 0.604341\n",
      "iteration 285 / 300: loss 0.595786\n",
      "iteration 285 / 300: loss 0.614949\n",
      "iteration 285 / 300: loss 0.608389\n",
      "iteration 285 / 300: loss 0.598222\n",
      "iteration 285 / 300: loss 0.588936\n",
      "iteration 285 / 300: loss 0.617757\n",
      "iteration 285 / 300: loss 0.594770\n",
      "iteration 285 / 300: loss 0.601684\n",
      "iteration 285 / 300: loss 0.631031\n",
      "iteration 285 / 300: loss 0.587513\n",
      "iteration 285 / 300: loss 0.606561\n",
      "iteration 285 / 300: loss 0.588034\n",
      "iteration 285 / 300: loss 0.600890\n",
      "iteration 285 / 300: loss 0.595958\n",
      "iteration 285 / 300: loss 0.589291\n",
      "iteration 285 / 300: loss 0.599526\n",
      "iteration 285 / 300: loss 0.604855\n",
      "iteration 285 / 300: loss 0.619414\n",
      "iteration 285 / 300: loss 0.588808\n",
      "iteration 285 / 300: loss 0.593645\n",
      "iteration 285 / 300: loss 0.585595\n",
      "iteration 285 / 300: loss 0.613212\n",
      "iteration 285 / 300: loss 0.587523\n",
      "iteration 285 / 300: loss 0.578328\n",
      "iteration 285 / 300: loss 0.567435\n",
      "iteration 285 / 300: loss 0.562235\n",
      "iteration 285 / 300: loss 0.594183\n",
      "iteration 285 / 300: loss 0.578821\n",
      "iteration 285 / 300: loss 0.586360\n",
      "iteration 285 / 300: loss 0.572890\n",
      "iteration 285 / 300: loss 0.596151\n",
      "iteration 285 / 300: loss 0.607951\n",
      "iteration 285 / 300: loss 0.610839\n",
      "iteration 285 / 300: loss 0.606265\n",
      "iteration 285 / 300: loss 0.583790\n",
      "iteration 285 / 300: loss 0.589627\n",
      "iteration 285 / 300: loss 0.595184\n",
      "iteration 285 / 300: loss 0.598955\n",
      "iteration 285 / 300: loss 0.596133\n",
      "iteration 285 / 300: loss 0.589769\n",
      "iteration 285 / 300: loss 0.591136\n",
      "iteration 285 / 300: loss 0.584854\n",
      "iteration 285 / 300: loss 0.599646\n",
      "iteration 285 / 300: loss 0.598902\n",
      "iteration 285 / 300: loss 0.614282\n",
      "iteration 285 / 300: loss 0.597796\n",
      "iteration 285 / 300: loss 0.599298\n",
      "iteration 285 / 300: loss 0.603317\n",
      "iteration 285 / 300: loss 0.592865\n",
      "iteration 285 / 300: loss 0.592391\n",
      "iteration 285 / 300: loss 0.589041\n",
      "iteration 285 / 300: loss 0.596446\n",
      "iteration 285 / 300: loss 0.605709\n",
      "iteration 285 / 300: loss 0.610562\n",
      "iteration 285 / 300: loss 0.587782\n",
      "iteration 285 / 300: loss 0.599351\n",
      "iteration 285 / 300: loss 0.602792\n",
      "iteration 285 / 300: loss 0.605028\n",
      "iteration 285 / 300: loss 0.603848\n",
      "iteration 285 / 300: loss 0.624144\n",
      "iteration 285 / 300: loss 0.587219\n",
      "iteration 285 / 300: loss 0.580754\n",
      "iteration 285 / 300: loss 0.625045\n",
      "iteration 285 / 300: loss 0.603310\n",
      "iteration 285 / 300: loss 0.604321\n",
      "iteration 285 / 300: loss 0.595476\n",
      "iteration 285 / 300: loss 0.597543\n",
      "iteration 285 / 300: loss 0.592740\n",
      "iteration 285 / 300: loss 0.589494\n",
      "iteration 285 / 300: loss 0.599264\n",
      "iteration 285 / 300: loss 0.611379\n",
      "iteration 285 / 300: loss 0.592463\n",
      "iteration 285 / 300: loss 0.599424\n",
      "iteration 285 / 300: loss 0.603100\n",
      "iteration 285 / 300: loss 0.602410\n",
      "iteration 285 / 300: loss 0.579811\n",
      "iteration 285 / 300: loss 0.601592\n",
      "iteration 286 / 300: loss 0.585528\n",
      "iteration 286 / 300: loss 0.588428\n",
      "iteration 286 / 300: loss 0.567516\n",
      "iteration 286 / 300: loss 0.592380\n",
      "iteration 286 / 300: loss 0.593618\n",
      "iteration 286 / 300: loss 0.595295\n",
      "iteration 286 / 300: loss 0.608784\n",
      "iteration 286 / 300: loss 0.592732\n",
      "iteration 286 / 300: loss 0.628060\n",
      "iteration 286 / 300: loss 0.580152\n",
      "iteration 286 / 300: loss 0.607923\n",
      "iteration 286 / 300: loss 0.587394\n",
      "iteration 286 / 300: loss 0.591686\n",
      "iteration 286 / 300: loss 0.571370\n",
      "iteration 286 / 300: loss 0.583025\n",
      "iteration 286 / 300: loss 0.608441\n",
      "iteration 286 / 300: loss 0.598359\n",
      "iteration 286 / 300: loss 0.583858\n",
      "iteration 286 / 300: loss 0.615253\n",
      "iteration 286 / 300: loss 0.591649\n",
      "iteration 286 / 300: loss 0.585499\n",
      "iteration 286 / 300: loss 0.591325\n",
      "iteration 286 / 300: loss 0.604341\n",
      "iteration 286 / 300: loss 0.595786\n",
      "iteration 286 / 300: loss 0.614949\n",
      "iteration 286 / 300: loss 0.608389\n",
      "iteration 286 / 300: loss 0.598222\n",
      "iteration 286 / 300: loss 0.588936\n",
      "iteration 286 / 300: loss 0.617757\n",
      "iteration 286 / 300: loss 0.594770\n",
      "iteration 286 / 300: loss 0.601684\n",
      "iteration 286 / 300: loss 0.631031\n",
      "iteration 286 / 300: loss 0.587513\n",
      "iteration 286 / 300: loss 0.606561\n",
      "iteration 286 / 300: loss 0.588034\n",
      "iteration 286 / 300: loss 0.600890\n",
      "iteration 286 / 300: loss 0.595958\n",
      "iteration 286 / 300: loss 0.589291\n",
      "iteration 286 / 300: loss 0.599526\n",
      "iteration 286 / 300: loss 0.604855\n",
      "iteration 286 / 300: loss 0.619414\n",
      "iteration 286 / 300: loss 0.588808\n",
      "iteration 286 / 300: loss 0.593645\n",
      "iteration 286 / 300: loss 0.585595\n",
      "iteration 286 / 300: loss 0.613212\n",
      "iteration 286 / 300: loss 0.587523\n",
      "iteration 286 / 300: loss 0.578328\n",
      "iteration 286 / 300: loss 0.567435\n",
      "iteration 286 / 300: loss 0.562235\n",
      "iteration 286 / 300: loss 0.594183\n",
      "iteration 286 / 300: loss 0.578821\n",
      "iteration 286 / 300: loss 0.586360\n",
      "iteration 286 / 300: loss 0.572890\n",
      "iteration 286 / 300: loss 0.596151\n",
      "iteration 286 / 300: loss 0.607951\n",
      "iteration 286 / 300: loss 0.610839\n",
      "iteration 286 / 300: loss 0.606265\n",
      "iteration 286 / 300: loss 0.583790\n",
      "iteration 286 / 300: loss 0.589627\n",
      "iteration 286 / 300: loss 0.595184\n",
      "iteration 286 / 300: loss 0.598955\n",
      "iteration 286 / 300: loss 0.596133\n",
      "iteration 286 / 300: loss 0.589769\n",
      "iteration 286 / 300: loss 0.591136\n",
      "iteration 286 / 300: loss 0.584854\n",
      "iteration 286 / 300: loss 0.599646\n",
      "iteration 286 / 300: loss 0.598902\n",
      "iteration 286 / 300: loss 0.614282\n",
      "iteration 286 / 300: loss 0.597796\n",
      "iteration 286 / 300: loss 0.599298\n",
      "iteration 286 / 300: loss 0.603317\n",
      "iteration 286 / 300: loss 0.592865\n",
      "iteration 286 / 300: loss 0.592391\n",
      "iteration 286 / 300: loss 0.589041\n",
      "iteration 286 / 300: loss 0.596446\n",
      "iteration 286 / 300: loss 0.605709\n",
      "iteration 286 / 300: loss 0.610562\n",
      "iteration 286 / 300: loss 0.587782\n",
      "iteration 286 / 300: loss 0.599351\n",
      "iteration 286 / 300: loss 0.602792\n",
      "iteration 286 / 300: loss 0.605028\n",
      "iteration 286 / 300: loss 0.603848\n",
      "iteration 286 / 300: loss 0.624144\n",
      "iteration 286 / 300: loss 0.587219\n",
      "iteration 286 / 300: loss 0.580754\n",
      "iteration 286 / 300: loss 0.625045\n",
      "iteration 286 / 300: loss 0.603310\n",
      "iteration 286 / 300: loss 0.604321\n",
      "iteration 286 / 300: loss 0.595476\n",
      "iteration 286 / 300: loss 0.597543\n",
      "iteration 286 / 300: loss 0.592740\n",
      "iteration 286 / 300: loss 0.589494\n",
      "iteration 286 / 300: loss 0.599264\n",
      "iteration 286 / 300: loss 0.611379\n",
      "iteration 286 / 300: loss 0.592463\n",
      "iteration 286 / 300: loss 0.599424\n",
      "iteration 286 / 300: loss 0.603100\n",
      "iteration 286 / 300: loss 0.602410\n",
      "iteration 286 / 300: loss 0.579811\n",
      "iteration 286 / 300: loss 0.601592\n",
      "iteration 287 / 300: loss 0.585528\n",
      "iteration 287 / 300: loss 0.588428\n",
      "iteration 287 / 300: loss 0.567516\n",
      "iteration 287 / 300: loss 0.592380\n",
      "iteration 287 / 300: loss 0.593618\n",
      "iteration 287 / 300: loss 0.595295\n",
      "iteration 287 / 300: loss 0.608784\n",
      "iteration 287 / 300: loss 0.592732\n",
      "iteration 287 / 300: loss 0.628060\n",
      "iteration 287 / 300: loss 0.580152\n",
      "iteration 287 / 300: loss 0.607923\n",
      "iteration 287 / 300: loss 0.587394\n",
      "iteration 287 / 300: loss 0.591686\n",
      "iteration 287 / 300: loss 0.571370\n",
      "iteration 287 / 300: loss 0.583025\n",
      "iteration 287 / 300: loss 0.608441\n",
      "iteration 287 / 300: loss 0.598359\n",
      "iteration 287 / 300: loss 0.583858\n",
      "iteration 287 / 300: loss 0.615253\n",
      "iteration 287 / 300: loss 0.591649\n",
      "iteration 287 / 300: loss 0.585499\n",
      "iteration 287 / 300: loss 0.591325\n",
      "iteration 287 / 300: loss 0.604341\n",
      "iteration 287 / 300: loss 0.595786\n",
      "iteration 287 / 300: loss 0.614949\n",
      "iteration 287 / 300: loss 0.608389\n",
      "iteration 287 / 300: loss 0.598222\n",
      "iteration 287 / 300: loss 0.588936\n",
      "iteration 287 / 300: loss 0.617757\n",
      "iteration 287 / 300: loss 0.594770\n",
      "iteration 287 / 300: loss 0.601684\n",
      "iteration 287 / 300: loss 0.631031\n",
      "iteration 287 / 300: loss 0.587513\n",
      "iteration 287 / 300: loss 0.606561\n",
      "iteration 287 / 300: loss 0.588034\n",
      "iteration 287 / 300: loss 0.600890\n",
      "iteration 287 / 300: loss 0.595958\n",
      "iteration 287 / 300: loss 0.589291\n",
      "iteration 287 / 300: loss 0.599526\n",
      "iteration 287 / 300: loss 0.604855\n",
      "iteration 287 / 300: loss 0.619414\n",
      "iteration 287 / 300: loss 0.588808\n",
      "iteration 287 / 300: loss 0.593645\n",
      "iteration 287 / 300: loss 0.585595\n",
      "iteration 287 / 300: loss 0.613212\n",
      "iteration 287 / 300: loss 0.587523\n",
      "iteration 287 / 300: loss 0.578328\n",
      "iteration 287 / 300: loss 0.567435\n",
      "iteration 287 / 300: loss 0.562235\n",
      "iteration 287 / 300: loss 0.594183\n",
      "iteration 287 / 300: loss 0.578821\n",
      "iteration 287 / 300: loss 0.586360\n",
      "iteration 287 / 300: loss 0.572890\n",
      "iteration 287 / 300: loss 0.596151\n",
      "iteration 287 / 300: loss 0.607951\n",
      "iteration 287 / 300: loss 0.610839\n",
      "iteration 287 / 300: loss 0.606265\n",
      "iteration 287 / 300: loss 0.583790\n",
      "iteration 287 / 300: loss 0.589627\n",
      "iteration 287 / 300: loss 0.595184\n",
      "iteration 287 / 300: loss 0.598955\n",
      "iteration 287 / 300: loss 0.596133\n",
      "iteration 287 / 300: loss 0.589769\n",
      "iteration 287 / 300: loss 0.591136\n",
      "iteration 287 / 300: loss 0.584854\n",
      "iteration 287 / 300: loss 0.599646\n",
      "iteration 287 / 300: loss 0.598902\n",
      "iteration 287 / 300: loss 0.614282\n",
      "iteration 287 / 300: loss 0.597796\n",
      "iteration 287 / 300: loss 0.599298\n",
      "iteration 287 / 300: loss 0.603317\n",
      "iteration 287 / 300: loss 0.592865\n",
      "iteration 287 / 300: loss 0.592391\n",
      "iteration 287 / 300: loss 0.589041\n",
      "iteration 287 / 300: loss 0.596446\n",
      "iteration 287 / 300: loss 0.605709\n",
      "iteration 287 / 300: loss 0.610562\n",
      "iteration 287 / 300: loss 0.587782\n",
      "iteration 287 / 300: loss 0.599351\n",
      "iteration 287 / 300: loss 0.602792\n",
      "iteration 287 / 300: loss 0.605028\n",
      "iteration 287 / 300: loss 0.603848\n",
      "iteration 287 / 300: loss 0.624144\n",
      "iteration 287 / 300: loss 0.587219\n",
      "iteration 287 / 300: loss 0.580754\n",
      "iteration 287 / 300: loss 0.625045\n",
      "iteration 287 / 300: loss 0.603310\n",
      "iteration 287 / 300: loss 0.604321\n",
      "iteration 287 / 300: loss 0.595476\n",
      "iteration 287 / 300: loss 0.597543\n",
      "iteration 287 / 300: loss 0.592740\n",
      "iteration 287 / 300: loss 0.589494\n",
      "iteration 287 / 300: loss 0.599264\n",
      "iteration 287 / 300: loss 0.611379\n",
      "iteration 287 / 300: loss 0.592463\n",
      "iteration 287 / 300: loss 0.599424\n",
      "iteration 287 / 300: loss 0.603100\n",
      "iteration 287 / 300: loss 0.602410\n",
      "iteration 287 / 300: loss 0.579811\n",
      "iteration 287 / 300: loss 0.601592\n",
      "iteration 288 / 300: loss 0.585528\n",
      "iteration 288 / 300: loss 0.588428\n",
      "iteration 288 / 300: loss 0.567516\n",
      "iteration 288 / 300: loss 0.592380\n",
      "iteration 288 / 300: loss 0.593618\n",
      "iteration 288 / 300: loss 0.595295\n",
      "iteration 288 / 300: loss 0.608784\n",
      "iteration 288 / 300: loss 0.592732\n",
      "iteration 288 / 300: loss 0.628060\n",
      "iteration 288 / 300: loss 0.580152\n",
      "iteration 288 / 300: loss 0.607923\n",
      "iteration 288 / 300: loss 0.587394\n",
      "iteration 288 / 300: loss 0.591686\n",
      "iteration 288 / 300: loss 0.571370\n",
      "iteration 288 / 300: loss 0.583025\n",
      "iteration 288 / 300: loss 0.608441\n",
      "iteration 288 / 300: loss 0.598359\n",
      "iteration 288 / 300: loss 0.583858\n",
      "iteration 288 / 300: loss 0.615253\n",
      "iteration 288 / 300: loss 0.591649\n",
      "iteration 288 / 300: loss 0.585499\n",
      "iteration 288 / 300: loss 0.591325\n",
      "iteration 288 / 300: loss 0.604341\n",
      "iteration 288 / 300: loss 0.595786\n",
      "iteration 288 / 300: loss 0.614949\n",
      "iteration 288 / 300: loss 0.608389\n",
      "iteration 288 / 300: loss 0.598222\n",
      "iteration 288 / 300: loss 0.588936\n",
      "iteration 288 / 300: loss 0.617757\n",
      "iteration 288 / 300: loss 0.594770\n",
      "iteration 288 / 300: loss 0.601684\n",
      "iteration 288 / 300: loss 0.631031\n",
      "iteration 288 / 300: loss 0.587513\n",
      "iteration 288 / 300: loss 0.606561\n",
      "iteration 288 / 300: loss 0.588034\n",
      "iteration 288 / 300: loss 0.600890\n",
      "iteration 288 / 300: loss 0.595958\n",
      "iteration 288 / 300: loss 0.589291\n",
      "iteration 288 / 300: loss 0.599526\n",
      "iteration 288 / 300: loss 0.604855\n",
      "iteration 288 / 300: loss 0.619414\n",
      "iteration 288 / 300: loss 0.588808\n",
      "iteration 288 / 300: loss 0.593645\n",
      "iteration 288 / 300: loss 0.585595\n",
      "iteration 288 / 300: loss 0.613212\n",
      "iteration 288 / 300: loss 0.587523\n",
      "iteration 288 / 300: loss 0.578328\n",
      "iteration 288 / 300: loss 0.567435\n",
      "iteration 288 / 300: loss 0.562235\n",
      "iteration 288 / 300: loss 0.594183\n",
      "iteration 288 / 300: loss 0.578821\n",
      "iteration 288 / 300: loss 0.586360\n",
      "iteration 288 / 300: loss 0.572890\n",
      "iteration 288 / 300: loss 0.596151\n",
      "iteration 288 / 300: loss 0.607951\n",
      "iteration 288 / 300: loss 0.610839\n",
      "iteration 288 / 300: loss 0.606265\n",
      "iteration 288 / 300: loss 0.583790\n",
      "iteration 288 / 300: loss 0.589627\n",
      "iteration 288 / 300: loss 0.595184\n",
      "iteration 288 / 300: loss 0.598955\n",
      "iteration 288 / 300: loss 0.596133\n",
      "iteration 288 / 300: loss 0.589769\n",
      "iteration 288 / 300: loss 0.591136\n",
      "iteration 288 / 300: loss 0.584854\n",
      "iteration 288 / 300: loss 0.599646\n",
      "iteration 288 / 300: loss 0.598902\n",
      "iteration 288 / 300: loss 0.614282\n",
      "iteration 288 / 300: loss 0.597796\n",
      "iteration 288 / 300: loss 0.599298\n",
      "iteration 288 / 300: loss 0.603317\n",
      "iteration 288 / 300: loss 0.592865\n",
      "iteration 288 / 300: loss 0.592391\n",
      "iteration 288 / 300: loss 0.589041\n",
      "iteration 288 / 300: loss 0.596446\n",
      "iteration 288 / 300: loss 0.605709\n",
      "iteration 288 / 300: loss 0.610562\n",
      "iteration 288 / 300: loss 0.587782\n",
      "iteration 288 / 300: loss 0.599351\n",
      "iteration 288 / 300: loss 0.602792\n",
      "iteration 288 / 300: loss 0.605028\n",
      "iteration 288 / 300: loss 0.603848\n",
      "iteration 288 / 300: loss 0.624144\n",
      "iteration 288 / 300: loss 0.587219\n",
      "iteration 288 / 300: loss 0.580754\n",
      "iteration 288 / 300: loss 0.625045\n",
      "iteration 288 / 300: loss 0.603310\n",
      "iteration 288 / 300: loss 0.604321\n",
      "iteration 288 / 300: loss 0.595476\n",
      "iteration 288 / 300: loss 0.597543\n",
      "iteration 288 / 300: loss 0.592740\n",
      "iteration 288 / 300: loss 0.589494\n",
      "iteration 288 / 300: loss 0.599264\n",
      "iteration 288 / 300: loss 0.611379\n",
      "iteration 288 / 300: loss 0.592463\n",
      "iteration 288 / 300: loss 0.599424\n",
      "iteration 288 / 300: loss 0.603100\n",
      "iteration 288 / 300: loss 0.602410\n",
      "iteration 288 / 300: loss 0.579811\n",
      "iteration 288 / 300: loss 0.601592\n",
      "iteration 289 / 300: loss 0.585528\n",
      "iteration 289 / 300: loss 0.588428\n",
      "iteration 289 / 300: loss 0.567516\n",
      "iteration 289 / 300: loss 0.592380\n",
      "iteration 289 / 300: loss 0.593618\n",
      "iteration 289 / 300: loss 0.595295\n",
      "iteration 289 / 300: loss 0.608784\n",
      "iteration 289 / 300: loss 0.592732\n",
      "iteration 289 / 300: loss 0.628060\n",
      "iteration 289 / 300: loss 0.580152\n",
      "iteration 289 / 300: loss 0.607923\n",
      "iteration 289 / 300: loss 0.587394\n",
      "iteration 289 / 300: loss 0.591686\n",
      "iteration 289 / 300: loss 0.571370\n",
      "iteration 289 / 300: loss 0.583025\n",
      "iteration 289 / 300: loss 0.608441\n",
      "iteration 289 / 300: loss 0.598359\n",
      "iteration 289 / 300: loss 0.583858\n",
      "iteration 289 / 300: loss 0.615253\n",
      "iteration 289 / 300: loss 0.591649\n",
      "iteration 289 / 300: loss 0.585499\n",
      "iteration 289 / 300: loss 0.591325\n",
      "iteration 289 / 300: loss 0.604341\n",
      "iteration 289 / 300: loss 0.595786\n",
      "iteration 289 / 300: loss 0.614949\n",
      "iteration 289 / 300: loss 0.608389\n",
      "iteration 289 / 300: loss 0.598222\n",
      "iteration 289 / 300: loss 0.588936\n",
      "iteration 289 / 300: loss 0.617757\n",
      "iteration 289 / 300: loss 0.594770\n",
      "iteration 289 / 300: loss 0.601684\n",
      "iteration 289 / 300: loss 0.631031\n",
      "iteration 289 / 300: loss 0.587513\n",
      "iteration 289 / 300: loss 0.606561\n",
      "iteration 289 / 300: loss 0.588034\n",
      "iteration 289 / 300: loss 0.600890\n",
      "iteration 289 / 300: loss 0.595958\n",
      "iteration 289 / 300: loss 0.589291\n",
      "iteration 289 / 300: loss 0.599526\n",
      "iteration 289 / 300: loss 0.604855\n",
      "iteration 289 / 300: loss 0.619414\n",
      "iteration 289 / 300: loss 0.588808\n",
      "iteration 289 / 300: loss 0.593645\n",
      "iteration 289 / 300: loss 0.585595\n",
      "iteration 289 / 300: loss 0.613212\n",
      "iteration 289 / 300: loss 0.587523\n",
      "iteration 289 / 300: loss 0.578328\n",
      "iteration 289 / 300: loss 0.567435\n",
      "iteration 289 / 300: loss 0.562235\n",
      "iteration 289 / 300: loss 0.594183\n",
      "iteration 289 / 300: loss 0.578821\n",
      "iteration 289 / 300: loss 0.586360\n",
      "iteration 289 / 300: loss 0.572890\n",
      "iteration 289 / 300: loss 0.596151\n",
      "iteration 289 / 300: loss 0.607951\n",
      "iteration 289 / 300: loss 0.610839\n",
      "iteration 289 / 300: loss 0.606265\n",
      "iteration 289 / 300: loss 0.583790\n",
      "iteration 289 / 300: loss 0.589627\n",
      "iteration 289 / 300: loss 0.595184\n",
      "iteration 289 / 300: loss 0.598955\n",
      "iteration 289 / 300: loss 0.596133\n",
      "iteration 289 / 300: loss 0.589769\n",
      "iteration 289 / 300: loss 0.591136\n",
      "iteration 289 / 300: loss 0.584854\n",
      "iteration 289 / 300: loss 0.599646\n",
      "iteration 289 / 300: loss 0.598902\n",
      "iteration 289 / 300: loss 0.614282\n",
      "iteration 289 / 300: loss 0.597796\n",
      "iteration 289 / 300: loss 0.599298\n",
      "iteration 289 / 300: loss 0.603317\n",
      "iteration 289 / 300: loss 0.592865\n",
      "iteration 289 / 300: loss 0.592391\n",
      "iteration 289 / 300: loss 0.589041\n",
      "iteration 289 / 300: loss 0.596446\n",
      "iteration 289 / 300: loss 0.605709\n",
      "iteration 289 / 300: loss 0.610562\n",
      "iteration 289 / 300: loss 0.587782\n",
      "iteration 289 / 300: loss 0.599351\n",
      "iteration 289 / 300: loss 0.602792\n",
      "iteration 289 / 300: loss 0.605028\n",
      "iteration 289 / 300: loss 0.603848\n",
      "iteration 289 / 300: loss 0.624144\n",
      "iteration 289 / 300: loss 0.587219\n",
      "iteration 289 / 300: loss 0.580754\n",
      "iteration 289 / 300: loss 0.625045\n",
      "iteration 289 / 300: loss 0.603310\n",
      "iteration 289 / 300: loss 0.604321\n",
      "iteration 289 / 300: loss 0.595476\n",
      "iteration 289 / 300: loss 0.597543\n",
      "iteration 289 / 300: loss 0.592740\n",
      "iteration 289 / 300: loss 0.589494\n",
      "iteration 289 / 300: loss 0.599264\n",
      "iteration 289 / 300: loss 0.611379\n",
      "iteration 289 / 300: loss 0.592463\n",
      "iteration 289 / 300: loss 0.599424\n",
      "iteration 289 / 300: loss 0.603100\n",
      "iteration 289 / 300: loss 0.602410\n",
      "iteration 289 / 300: loss 0.579811\n",
      "iteration 289 / 300: loss 0.601592\n",
      "iteration 290 / 300: loss 0.585528\n",
      "iteration 290 / 300: loss 0.588428\n",
      "iteration 290 / 300: loss 0.567516\n",
      "iteration 290 / 300: loss 0.592380\n",
      "iteration 290 / 300: loss 0.593618\n",
      "iteration 290 / 300: loss 0.595295\n",
      "iteration 290 / 300: loss 0.608784\n",
      "iteration 290 / 300: loss 0.592732\n",
      "iteration 290 / 300: loss 0.628060\n",
      "iteration 290 / 300: loss 0.580152\n",
      "iteration 290 / 300: loss 0.607923\n",
      "iteration 290 / 300: loss 0.587394\n",
      "iteration 290 / 300: loss 0.591686\n",
      "iteration 290 / 300: loss 0.571370\n",
      "iteration 290 / 300: loss 0.583025\n",
      "iteration 290 / 300: loss 0.608441\n",
      "iteration 290 / 300: loss 0.598359\n",
      "iteration 290 / 300: loss 0.583858\n",
      "iteration 290 / 300: loss 0.615253\n",
      "iteration 290 / 300: loss 0.591649\n",
      "iteration 290 / 300: loss 0.585499\n",
      "iteration 290 / 300: loss 0.591325\n",
      "iteration 290 / 300: loss 0.604341\n",
      "iteration 290 / 300: loss 0.595786\n",
      "iteration 290 / 300: loss 0.614949\n",
      "iteration 290 / 300: loss 0.608389\n",
      "iteration 290 / 300: loss 0.598222\n",
      "iteration 290 / 300: loss 0.588936\n",
      "iteration 290 / 300: loss 0.617757\n",
      "iteration 290 / 300: loss 0.594770\n",
      "iteration 290 / 300: loss 0.601684\n",
      "iteration 290 / 300: loss 0.631031\n",
      "iteration 290 / 300: loss 0.587513\n",
      "iteration 290 / 300: loss 0.606561\n",
      "iteration 290 / 300: loss 0.588034\n",
      "iteration 290 / 300: loss 0.600890\n",
      "iteration 290 / 300: loss 0.595958\n",
      "iteration 290 / 300: loss 0.589291\n",
      "iteration 290 / 300: loss 0.599526\n",
      "iteration 290 / 300: loss 0.604855\n",
      "iteration 290 / 300: loss 0.619414\n",
      "iteration 290 / 300: loss 0.588808\n",
      "iteration 290 / 300: loss 0.593645\n",
      "iteration 290 / 300: loss 0.585595\n",
      "iteration 290 / 300: loss 0.613212\n",
      "iteration 290 / 300: loss 0.587523\n",
      "iteration 290 / 300: loss 0.578328\n",
      "iteration 290 / 300: loss 0.567435\n",
      "iteration 290 / 300: loss 0.562235\n",
      "iteration 290 / 300: loss 0.594183\n",
      "iteration 290 / 300: loss 0.578821\n",
      "iteration 290 / 300: loss 0.586360\n",
      "iteration 290 / 300: loss 0.572890\n",
      "iteration 290 / 300: loss 0.596151\n",
      "iteration 290 / 300: loss 0.607951\n",
      "iteration 290 / 300: loss 0.610839\n",
      "iteration 290 / 300: loss 0.606265\n",
      "iteration 290 / 300: loss 0.583790\n",
      "iteration 290 / 300: loss 0.589627\n",
      "iteration 290 / 300: loss 0.595184\n",
      "iteration 290 / 300: loss 0.598955\n",
      "iteration 290 / 300: loss 0.596133\n",
      "iteration 290 / 300: loss 0.589769\n",
      "iteration 290 / 300: loss 0.591136\n",
      "iteration 290 / 300: loss 0.584854\n",
      "iteration 290 / 300: loss 0.599646\n",
      "iteration 290 / 300: loss 0.598902\n",
      "iteration 290 / 300: loss 0.614282\n",
      "iteration 290 / 300: loss 0.597796\n",
      "iteration 290 / 300: loss 0.599298\n",
      "iteration 290 / 300: loss 0.603317\n",
      "iteration 290 / 300: loss 0.592865\n",
      "iteration 290 / 300: loss 0.592391\n",
      "iteration 290 / 300: loss 0.589041\n",
      "iteration 290 / 300: loss 0.596446\n",
      "iteration 290 / 300: loss 0.605709\n",
      "iteration 290 / 300: loss 0.610562\n",
      "iteration 290 / 300: loss 0.587782\n",
      "iteration 290 / 300: loss 0.599351\n",
      "iteration 290 / 300: loss 0.602792\n",
      "iteration 290 / 300: loss 0.605028\n",
      "iteration 290 / 300: loss 0.603848\n",
      "iteration 290 / 300: loss 0.624144\n",
      "iteration 290 / 300: loss 0.587219\n",
      "iteration 290 / 300: loss 0.580754\n",
      "iteration 290 / 300: loss 0.625045\n",
      "iteration 290 / 300: loss 0.603310\n",
      "iteration 290 / 300: loss 0.604321\n",
      "iteration 290 / 300: loss 0.595476\n",
      "iteration 290 / 300: loss 0.597543\n",
      "iteration 290 / 300: loss 0.592740\n",
      "iteration 290 / 300: loss 0.589494\n",
      "iteration 290 / 300: loss 0.599264\n",
      "iteration 290 / 300: loss 0.611379\n",
      "iteration 290 / 300: loss 0.592463\n",
      "iteration 290 / 300: loss 0.599424\n",
      "iteration 290 / 300: loss 0.603100\n",
      "iteration 290 / 300: loss 0.602410\n",
      "iteration 290 / 300: loss 0.579811\n",
      "iteration 290 / 300: loss 0.601592\n",
      "iteration 291 / 300: loss 0.585528\n",
      "iteration 291 / 300: loss 0.588428\n",
      "iteration 291 / 300: loss 0.567516\n",
      "iteration 291 / 300: loss 0.592380\n",
      "iteration 291 / 300: loss 0.593618\n",
      "iteration 291 / 300: loss 0.595295\n",
      "iteration 291 / 300: loss 0.608784\n",
      "iteration 291 / 300: loss 0.592732\n",
      "iteration 291 / 300: loss 0.628060\n",
      "iteration 291 / 300: loss 0.580152\n",
      "iteration 291 / 300: loss 0.607923\n",
      "iteration 291 / 300: loss 0.587394\n",
      "iteration 291 / 300: loss 0.591686\n",
      "iteration 291 / 300: loss 0.571370\n",
      "iteration 291 / 300: loss 0.583025\n",
      "iteration 291 / 300: loss 0.608441\n",
      "iteration 291 / 300: loss 0.598359\n",
      "iteration 291 / 300: loss 0.583858\n",
      "iteration 291 / 300: loss 0.615253\n",
      "iteration 291 / 300: loss 0.591649\n",
      "iteration 291 / 300: loss 0.585499\n",
      "iteration 291 / 300: loss 0.591325\n",
      "iteration 291 / 300: loss 0.604341\n",
      "iteration 291 / 300: loss 0.595786\n",
      "iteration 291 / 300: loss 0.614949\n",
      "iteration 291 / 300: loss 0.608389\n",
      "iteration 291 / 300: loss 0.598222\n",
      "iteration 291 / 300: loss 0.588936\n",
      "iteration 291 / 300: loss 0.617757\n",
      "iteration 291 / 300: loss 0.594770\n",
      "iteration 291 / 300: loss 0.601684\n",
      "iteration 291 / 300: loss 0.631031\n",
      "iteration 291 / 300: loss 0.587513\n",
      "iteration 291 / 300: loss 0.606561\n",
      "iteration 291 / 300: loss 0.588034\n",
      "iteration 291 / 300: loss 0.600890\n",
      "iteration 291 / 300: loss 0.595958\n",
      "iteration 291 / 300: loss 0.589291\n",
      "iteration 291 / 300: loss 0.599526\n",
      "iteration 291 / 300: loss 0.604855\n",
      "iteration 291 / 300: loss 0.619414\n",
      "iteration 291 / 300: loss 0.588808\n",
      "iteration 291 / 300: loss 0.593645\n",
      "iteration 291 / 300: loss 0.585595\n",
      "iteration 291 / 300: loss 0.613212\n",
      "iteration 291 / 300: loss 0.587523\n",
      "iteration 291 / 300: loss 0.578328\n",
      "iteration 291 / 300: loss 0.567435\n",
      "iteration 291 / 300: loss 0.562235\n",
      "iteration 291 / 300: loss 0.594183\n",
      "iteration 291 / 300: loss 0.578821\n",
      "iteration 291 / 300: loss 0.586360\n",
      "iteration 291 / 300: loss 0.572890\n",
      "iteration 291 / 300: loss 0.596151\n",
      "iteration 291 / 300: loss 0.607951\n",
      "iteration 291 / 300: loss 0.610839\n",
      "iteration 291 / 300: loss 0.606265\n",
      "iteration 291 / 300: loss 0.583790\n",
      "iteration 291 / 300: loss 0.589627\n",
      "iteration 291 / 300: loss 0.595184\n",
      "iteration 291 / 300: loss 0.598955\n",
      "iteration 291 / 300: loss 0.596133\n",
      "iteration 291 / 300: loss 0.589769\n",
      "iteration 291 / 300: loss 0.591136\n",
      "iteration 291 / 300: loss 0.584854\n",
      "iteration 291 / 300: loss 0.599646\n",
      "iteration 291 / 300: loss 0.598902\n",
      "iteration 291 / 300: loss 0.614282\n",
      "iteration 291 / 300: loss 0.597796\n",
      "iteration 291 / 300: loss 0.599298\n",
      "iteration 291 / 300: loss 0.603317\n",
      "iteration 291 / 300: loss 0.592865\n",
      "iteration 291 / 300: loss 0.592391\n",
      "iteration 291 / 300: loss 0.589041\n",
      "iteration 291 / 300: loss 0.596446\n",
      "iteration 291 / 300: loss 0.605709\n",
      "iteration 291 / 300: loss 0.610562\n",
      "iteration 291 / 300: loss 0.587782\n",
      "iteration 291 / 300: loss 0.599351\n",
      "iteration 291 / 300: loss 0.602792\n",
      "iteration 291 / 300: loss 0.605028\n",
      "iteration 291 / 300: loss 0.603848\n",
      "iteration 291 / 300: loss 0.624144\n",
      "iteration 291 / 300: loss 0.587219\n",
      "iteration 291 / 300: loss 0.580754\n",
      "iteration 291 / 300: loss 0.625045\n",
      "iteration 291 / 300: loss 0.603310\n",
      "iteration 291 / 300: loss 0.604321\n",
      "iteration 291 / 300: loss 0.595476\n",
      "iteration 291 / 300: loss 0.597543\n",
      "iteration 291 / 300: loss 0.592740\n",
      "iteration 291 / 300: loss 0.589494\n",
      "iteration 291 / 300: loss 0.599264\n",
      "iteration 291 / 300: loss 0.611379\n",
      "iteration 291 / 300: loss 0.592463\n",
      "iteration 291 / 300: loss 0.599424\n",
      "iteration 291 / 300: loss 0.603100\n",
      "iteration 291 / 300: loss 0.602410\n",
      "iteration 291 / 300: loss 0.579811\n",
      "iteration 291 / 300: loss 0.601592\n",
      "iteration 292 / 300: loss 0.585528\n",
      "iteration 292 / 300: loss 0.588428\n",
      "iteration 292 / 300: loss 0.567516\n",
      "iteration 292 / 300: loss 0.592380\n",
      "iteration 292 / 300: loss 0.593618\n",
      "iteration 292 / 300: loss 0.595295\n",
      "iteration 292 / 300: loss 0.608784\n",
      "iteration 292 / 300: loss 0.592732\n",
      "iteration 292 / 300: loss 0.628060\n",
      "iteration 292 / 300: loss 0.580152\n",
      "iteration 292 / 300: loss 0.607923\n",
      "iteration 292 / 300: loss 0.587394\n",
      "iteration 292 / 300: loss 0.591686\n",
      "iteration 292 / 300: loss 0.571370\n",
      "iteration 292 / 300: loss 0.583025\n",
      "iteration 292 / 300: loss 0.608441\n",
      "iteration 292 / 300: loss 0.598359\n",
      "iteration 292 / 300: loss 0.583858\n",
      "iteration 292 / 300: loss 0.615253\n",
      "iteration 292 / 300: loss 0.591649\n",
      "iteration 292 / 300: loss 0.585499\n",
      "iteration 292 / 300: loss 0.591325\n",
      "iteration 292 / 300: loss 0.604341\n",
      "iteration 292 / 300: loss 0.595786\n",
      "iteration 292 / 300: loss 0.614949\n",
      "iteration 292 / 300: loss 0.608389\n",
      "iteration 292 / 300: loss 0.598222\n",
      "iteration 292 / 300: loss 0.588936\n",
      "iteration 292 / 300: loss 0.617757\n",
      "iteration 292 / 300: loss 0.594770\n",
      "iteration 292 / 300: loss 0.601684\n",
      "iteration 292 / 300: loss 0.631031\n",
      "iteration 292 / 300: loss 0.587513\n",
      "iteration 292 / 300: loss 0.606561\n",
      "iteration 292 / 300: loss 0.588034\n",
      "iteration 292 / 300: loss 0.600890\n",
      "iteration 292 / 300: loss 0.595958\n",
      "iteration 292 / 300: loss 0.589291\n",
      "iteration 292 / 300: loss 0.599526\n",
      "iteration 292 / 300: loss 0.604855\n",
      "iteration 292 / 300: loss 0.619414\n",
      "iteration 292 / 300: loss 0.588808\n",
      "iteration 292 / 300: loss 0.593645\n",
      "iteration 292 / 300: loss 0.585595\n",
      "iteration 292 / 300: loss 0.613212\n",
      "iteration 292 / 300: loss 0.587523\n",
      "iteration 292 / 300: loss 0.578328\n",
      "iteration 292 / 300: loss 0.567435\n",
      "iteration 292 / 300: loss 0.562235\n",
      "iteration 292 / 300: loss 0.594183\n",
      "iteration 292 / 300: loss 0.578821\n",
      "iteration 292 / 300: loss 0.586360\n",
      "iteration 292 / 300: loss 0.572890\n",
      "iteration 292 / 300: loss 0.596151\n",
      "iteration 292 / 300: loss 0.607951\n",
      "iteration 292 / 300: loss 0.610839\n",
      "iteration 292 / 300: loss 0.606265\n",
      "iteration 292 / 300: loss 0.583790\n",
      "iteration 292 / 300: loss 0.589627\n",
      "iteration 292 / 300: loss 0.595184\n",
      "iteration 292 / 300: loss 0.598955\n",
      "iteration 292 / 300: loss 0.596133\n",
      "iteration 292 / 300: loss 0.589769\n",
      "iteration 292 / 300: loss 0.591136\n",
      "iteration 292 / 300: loss 0.584854\n",
      "iteration 292 / 300: loss 0.599646\n",
      "iteration 292 / 300: loss 0.598902\n",
      "iteration 292 / 300: loss 0.614282\n",
      "iteration 292 / 300: loss 0.597796\n",
      "iteration 292 / 300: loss 0.599298\n",
      "iteration 292 / 300: loss 0.603317\n",
      "iteration 292 / 300: loss 0.592865\n",
      "iteration 292 / 300: loss 0.592391\n",
      "iteration 292 / 300: loss 0.589041\n",
      "iteration 292 / 300: loss 0.596446\n",
      "iteration 292 / 300: loss 0.605709\n",
      "iteration 292 / 300: loss 0.610562\n",
      "iteration 292 / 300: loss 0.587782\n",
      "iteration 292 / 300: loss 0.599351\n",
      "iteration 292 / 300: loss 0.602792\n",
      "iteration 292 / 300: loss 0.605028\n",
      "iteration 292 / 300: loss 0.603848\n",
      "iteration 292 / 300: loss 0.624144\n",
      "iteration 292 / 300: loss 0.587219\n",
      "iteration 292 / 300: loss 0.580754\n",
      "iteration 292 / 300: loss 0.625045\n",
      "iteration 292 / 300: loss 0.603310\n",
      "iteration 292 / 300: loss 0.604321\n",
      "iteration 292 / 300: loss 0.595476\n",
      "iteration 292 / 300: loss 0.597543\n",
      "iteration 292 / 300: loss 0.592740\n",
      "iteration 292 / 300: loss 0.589494\n",
      "iteration 292 / 300: loss 0.599264\n",
      "iteration 292 / 300: loss 0.611379\n",
      "iteration 292 / 300: loss 0.592463\n",
      "iteration 292 / 300: loss 0.599424\n",
      "iteration 292 / 300: loss 0.603100\n",
      "iteration 292 / 300: loss 0.602410\n",
      "iteration 292 / 300: loss 0.579811\n",
      "iteration 292 / 300: loss 0.601592\n",
      "iteration 293 / 300: loss 0.585528\n",
      "iteration 293 / 300: loss 0.588428\n",
      "iteration 293 / 300: loss 0.567516\n",
      "iteration 293 / 300: loss 0.592380\n",
      "iteration 293 / 300: loss 0.593618\n",
      "iteration 293 / 300: loss 0.595295\n",
      "iteration 293 / 300: loss 0.608784\n",
      "iteration 293 / 300: loss 0.592732\n",
      "iteration 293 / 300: loss 0.628060\n",
      "iteration 293 / 300: loss 0.580152\n",
      "iteration 293 / 300: loss 0.607923\n",
      "iteration 293 / 300: loss 0.587394\n",
      "iteration 293 / 300: loss 0.591686\n",
      "iteration 293 / 300: loss 0.571370\n",
      "iteration 293 / 300: loss 0.583025\n",
      "iteration 293 / 300: loss 0.608441\n",
      "iteration 293 / 300: loss 0.598359\n",
      "iteration 293 / 300: loss 0.583858\n",
      "iteration 293 / 300: loss 0.615253\n",
      "iteration 293 / 300: loss 0.591649\n",
      "iteration 293 / 300: loss 0.585499\n",
      "iteration 293 / 300: loss 0.591325\n",
      "iteration 293 / 300: loss 0.604341\n",
      "iteration 293 / 300: loss 0.595786\n",
      "iteration 293 / 300: loss 0.614949\n",
      "iteration 293 / 300: loss 0.608389\n",
      "iteration 293 / 300: loss 0.598222\n",
      "iteration 293 / 300: loss 0.588936\n",
      "iteration 293 / 300: loss 0.617757\n",
      "iteration 293 / 300: loss 0.594770\n",
      "iteration 293 / 300: loss 0.601684\n",
      "iteration 293 / 300: loss 0.631031\n",
      "iteration 293 / 300: loss 0.587513\n",
      "iteration 293 / 300: loss 0.606561\n",
      "iteration 293 / 300: loss 0.588034\n",
      "iteration 293 / 300: loss 0.600890\n",
      "iteration 293 / 300: loss 0.595958\n",
      "iteration 293 / 300: loss 0.589291\n",
      "iteration 293 / 300: loss 0.599526\n",
      "iteration 293 / 300: loss 0.604855\n",
      "iteration 293 / 300: loss 0.619414\n",
      "iteration 293 / 300: loss 0.588808\n",
      "iteration 293 / 300: loss 0.593645\n",
      "iteration 293 / 300: loss 0.585595\n",
      "iteration 293 / 300: loss 0.613212\n",
      "iteration 293 / 300: loss 0.587523\n",
      "iteration 293 / 300: loss 0.578328\n",
      "iteration 293 / 300: loss 0.567435\n",
      "iteration 293 / 300: loss 0.562235\n",
      "iteration 293 / 300: loss 0.594183\n",
      "iteration 293 / 300: loss 0.578821\n",
      "iteration 293 / 300: loss 0.586360\n",
      "iteration 293 / 300: loss 0.572890\n",
      "iteration 293 / 300: loss 0.596151\n",
      "iteration 293 / 300: loss 0.607951\n",
      "iteration 293 / 300: loss 0.610839\n",
      "iteration 293 / 300: loss 0.606265\n",
      "iteration 293 / 300: loss 0.583790\n",
      "iteration 293 / 300: loss 0.589627\n",
      "iteration 293 / 300: loss 0.595184\n",
      "iteration 293 / 300: loss 0.598955\n",
      "iteration 293 / 300: loss 0.596133\n",
      "iteration 293 / 300: loss 0.589769\n",
      "iteration 293 / 300: loss 0.591136\n",
      "iteration 293 / 300: loss 0.584854\n",
      "iteration 293 / 300: loss 0.599646\n",
      "iteration 293 / 300: loss 0.598902\n",
      "iteration 293 / 300: loss 0.614282\n",
      "iteration 293 / 300: loss 0.597796\n",
      "iteration 293 / 300: loss 0.599298\n",
      "iteration 293 / 300: loss 0.603317\n",
      "iteration 293 / 300: loss 0.592865\n",
      "iteration 293 / 300: loss 0.592391\n",
      "iteration 293 / 300: loss 0.589041\n",
      "iteration 293 / 300: loss 0.596446\n",
      "iteration 293 / 300: loss 0.605709\n",
      "iteration 293 / 300: loss 0.610562\n",
      "iteration 293 / 300: loss 0.587782\n",
      "iteration 293 / 300: loss 0.599351\n",
      "iteration 293 / 300: loss 0.602792\n",
      "iteration 293 / 300: loss 0.605028\n",
      "iteration 293 / 300: loss 0.603848\n",
      "iteration 293 / 300: loss 0.624144\n",
      "iteration 293 / 300: loss 0.587219\n",
      "iteration 293 / 300: loss 0.580754\n",
      "iteration 293 / 300: loss 0.625045\n",
      "iteration 293 / 300: loss 0.603310\n",
      "iteration 293 / 300: loss 0.604321\n",
      "iteration 293 / 300: loss 0.595476\n",
      "iteration 293 / 300: loss 0.597543\n",
      "iteration 293 / 300: loss 0.592740\n",
      "iteration 293 / 300: loss 0.589494\n",
      "iteration 293 / 300: loss 0.599264\n",
      "iteration 293 / 300: loss 0.611379\n",
      "iteration 293 / 300: loss 0.592463\n",
      "iteration 293 / 300: loss 0.599424\n",
      "iteration 293 / 300: loss 0.603100\n",
      "iteration 293 / 300: loss 0.602410\n",
      "iteration 293 / 300: loss 0.579811\n",
      "iteration 293 / 300: loss 0.601592\n",
      "iteration 294 / 300: loss 0.585528\n",
      "iteration 294 / 300: loss 0.588428\n",
      "iteration 294 / 300: loss 0.567516\n",
      "iteration 294 / 300: loss 0.592380\n",
      "iteration 294 / 300: loss 0.593618\n",
      "iteration 294 / 300: loss 0.595295\n",
      "iteration 294 / 300: loss 0.608784\n",
      "iteration 294 / 300: loss 0.592732\n",
      "iteration 294 / 300: loss 0.628060\n",
      "iteration 294 / 300: loss 0.580152\n",
      "iteration 294 / 300: loss 0.607923\n",
      "iteration 294 / 300: loss 0.587394\n",
      "iteration 294 / 300: loss 0.591686\n",
      "iteration 294 / 300: loss 0.571370\n",
      "iteration 294 / 300: loss 0.583025\n",
      "iteration 294 / 300: loss 0.608441\n",
      "iteration 294 / 300: loss 0.598359\n",
      "iteration 294 / 300: loss 0.583858\n",
      "iteration 294 / 300: loss 0.615253\n",
      "iteration 294 / 300: loss 0.591649\n",
      "iteration 294 / 300: loss 0.585499\n",
      "iteration 294 / 300: loss 0.591325\n",
      "iteration 294 / 300: loss 0.604341\n",
      "iteration 294 / 300: loss 0.595786\n",
      "iteration 294 / 300: loss 0.614949\n",
      "iteration 294 / 300: loss 0.608389\n",
      "iteration 294 / 300: loss 0.598222\n",
      "iteration 294 / 300: loss 0.588936\n",
      "iteration 294 / 300: loss 0.617757\n",
      "iteration 294 / 300: loss 0.594770\n",
      "iteration 294 / 300: loss 0.601684\n",
      "iteration 294 / 300: loss 0.631031\n",
      "iteration 294 / 300: loss 0.587513\n",
      "iteration 294 / 300: loss 0.606561\n",
      "iteration 294 / 300: loss 0.588034\n",
      "iteration 294 / 300: loss 0.600890\n",
      "iteration 294 / 300: loss 0.595958\n",
      "iteration 294 / 300: loss 0.589291\n",
      "iteration 294 / 300: loss 0.599526\n",
      "iteration 294 / 300: loss 0.604855\n",
      "iteration 294 / 300: loss 0.619414\n",
      "iteration 294 / 300: loss 0.588808\n",
      "iteration 294 / 300: loss 0.593645\n",
      "iteration 294 / 300: loss 0.585595\n",
      "iteration 294 / 300: loss 0.613212\n",
      "iteration 294 / 300: loss 0.587523\n",
      "iteration 294 / 300: loss 0.578328\n",
      "iteration 294 / 300: loss 0.567435\n",
      "iteration 294 / 300: loss 0.562235\n",
      "iteration 294 / 300: loss 0.594183\n",
      "iteration 294 / 300: loss 0.578821\n",
      "iteration 294 / 300: loss 0.586360\n",
      "iteration 294 / 300: loss 0.572890\n",
      "iteration 294 / 300: loss 0.596151\n",
      "iteration 294 / 300: loss 0.607951\n",
      "iteration 294 / 300: loss 0.610839\n",
      "iteration 294 / 300: loss 0.606265\n",
      "iteration 294 / 300: loss 0.583790\n",
      "iteration 294 / 300: loss 0.589627\n",
      "iteration 294 / 300: loss 0.595184\n",
      "iteration 294 / 300: loss 0.598955\n",
      "iteration 294 / 300: loss 0.596133\n",
      "iteration 294 / 300: loss 0.589769\n",
      "iteration 294 / 300: loss 0.591136\n",
      "iteration 294 / 300: loss 0.584854\n",
      "iteration 294 / 300: loss 0.599646\n",
      "iteration 294 / 300: loss 0.598902\n",
      "iteration 294 / 300: loss 0.614282\n",
      "iteration 294 / 300: loss 0.597796\n",
      "iteration 294 / 300: loss 0.599298\n",
      "iteration 294 / 300: loss 0.603317\n",
      "iteration 294 / 300: loss 0.592865\n",
      "iteration 294 / 300: loss 0.592391\n",
      "iteration 294 / 300: loss 0.589041\n",
      "iteration 294 / 300: loss 0.596446\n",
      "iteration 294 / 300: loss 0.605709\n",
      "iteration 294 / 300: loss 0.610562\n",
      "iteration 294 / 300: loss 0.587782\n",
      "iteration 294 / 300: loss 0.599351\n",
      "iteration 294 / 300: loss 0.602792\n",
      "iteration 294 / 300: loss 0.605028\n",
      "iteration 294 / 300: loss 0.603848\n",
      "iteration 294 / 300: loss 0.624144\n",
      "iteration 294 / 300: loss 0.587219\n",
      "iteration 294 / 300: loss 0.580754\n",
      "iteration 294 / 300: loss 0.625045\n",
      "iteration 294 / 300: loss 0.603310\n",
      "iteration 294 / 300: loss 0.604321\n",
      "iteration 294 / 300: loss 0.595476\n",
      "iteration 294 / 300: loss 0.597543\n",
      "iteration 294 / 300: loss 0.592740\n",
      "iteration 294 / 300: loss 0.589494\n",
      "iteration 294 / 300: loss 0.599264\n",
      "iteration 294 / 300: loss 0.611379\n",
      "iteration 294 / 300: loss 0.592463\n",
      "iteration 294 / 300: loss 0.599424\n",
      "iteration 294 / 300: loss 0.603100\n",
      "iteration 294 / 300: loss 0.602410\n",
      "iteration 294 / 300: loss 0.579811\n",
      "iteration 294 / 300: loss 0.601592\n",
      "iteration 295 / 300: loss 0.585528\n",
      "iteration 295 / 300: loss 0.588428\n",
      "iteration 295 / 300: loss 0.567516\n",
      "iteration 295 / 300: loss 0.592380\n",
      "iteration 295 / 300: loss 0.593618\n",
      "iteration 295 / 300: loss 0.595295\n",
      "iteration 295 / 300: loss 0.608784\n",
      "iteration 295 / 300: loss 0.592732\n",
      "iteration 295 / 300: loss 0.628060\n",
      "iteration 295 / 300: loss 0.580152\n",
      "iteration 295 / 300: loss 0.607923\n",
      "iteration 295 / 300: loss 0.587394\n",
      "iteration 295 / 300: loss 0.591686\n",
      "iteration 295 / 300: loss 0.571370\n",
      "iteration 295 / 300: loss 0.583025\n",
      "iteration 295 / 300: loss 0.608441\n",
      "iteration 295 / 300: loss 0.598359\n",
      "iteration 295 / 300: loss 0.583858\n",
      "iteration 295 / 300: loss 0.615253\n",
      "iteration 295 / 300: loss 0.591649\n",
      "iteration 295 / 300: loss 0.585499\n",
      "iteration 295 / 300: loss 0.591325\n",
      "iteration 295 / 300: loss 0.604341\n",
      "iteration 295 / 300: loss 0.595786\n",
      "iteration 295 / 300: loss 0.614949\n",
      "iteration 295 / 300: loss 0.608389\n",
      "iteration 295 / 300: loss 0.598222\n",
      "iteration 295 / 300: loss 0.588936\n",
      "iteration 295 / 300: loss 0.617757\n",
      "iteration 295 / 300: loss 0.594770\n",
      "iteration 295 / 300: loss 0.601684\n",
      "iteration 295 / 300: loss 0.631031\n",
      "iteration 295 / 300: loss 0.587513\n",
      "iteration 295 / 300: loss 0.606561\n",
      "iteration 295 / 300: loss 0.588034\n",
      "iteration 295 / 300: loss 0.600890\n",
      "iteration 295 / 300: loss 0.595958\n",
      "iteration 295 / 300: loss 0.589291\n",
      "iteration 295 / 300: loss 0.599526\n",
      "iteration 295 / 300: loss 0.604855\n",
      "iteration 295 / 300: loss 0.619414\n",
      "iteration 295 / 300: loss 0.588808\n",
      "iteration 295 / 300: loss 0.593645\n",
      "iteration 295 / 300: loss 0.585595\n",
      "iteration 295 / 300: loss 0.613212\n",
      "iteration 295 / 300: loss 0.587523\n",
      "iteration 295 / 300: loss 0.578328\n",
      "iteration 295 / 300: loss 0.567435\n",
      "iteration 295 / 300: loss 0.562235\n",
      "iteration 295 / 300: loss 0.594183\n",
      "iteration 295 / 300: loss 0.578821\n",
      "iteration 295 / 300: loss 0.586360\n",
      "iteration 295 / 300: loss 0.572890\n",
      "iteration 295 / 300: loss 0.596151\n",
      "iteration 295 / 300: loss 0.607951\n",
      "iteration 295 / 300: loss 0.610839\n",
      "iteration 295 / 300: loss 0.606265\n",
      "iteration 295 / 300: loss 0.583790\n",
      "iteration 295 / 300: loss 0.589627\n",
      "iteration 295 / 300: loss 0.595184\n",
      "iteration 295 / 300: loss 0.598955\n",
      "iteration 295 / 300: loss 0.596133\n",
      "iteration 295 / 300: loss 0.589769\n",
      "iteration 295 / 300: loss 0.591136\n",
      "iteration 295 / 300: loss 0.584854\n",
      "iteration 295 / 300: loss 0.599646\n",
      "iteration 295 / 300: loss 0.598902\n",
      "iteration 295 / 300: loss 0.614282\n",
      "iteration 295 / 300: loss 0.597796\n",
      "iteration 295 / 300: loss 0.599298\n",
      "iteration 295 / 300: loss 0.603317\n",
      "iteration 295 / 300: loss 0.592865\n",
      "iteration 295 / 300: loss 0.592391\n",
      "iteration 295 / 300: loss 0.589041\n",
      "iteration 295 / 300: loss 0.596446\n",
      "iteration 295 / 300: loss 0.605709\n",
      "iteration 295 / 300: loss 0.610562\n",
      "iteration 295 / 300: loss 0.587782\n",
      "iteration 295 / 300: loss 0.599351\n",
      "iteration 295 / 300: loss 0.602792\n",
      "iteration 295 / 300: loss 0.605028\n",
      "iteration 295 / 300: loss 0.603848\n",
      "iteration 295 / 300: loss 0.624144\n",
      "iteration 295 / 300: loss 0.587219\n",
      "iteration 295 / 300: loss 0.580754\n",
      "iteration 295 / 300: loss 0.625045\n",
      "iteration 295 / 300: loss 0.603310\n",
      "iteration 295 / 300: loss 0.604321\n",
      "iteration 295 / 300: loss 0.595476\n",
      "iteration 295 / 300: loss 0.597543\n",
      "iteration 295 / 300: loss 0.592740\n",
      "iteration 295 / 300: loss 0.589494\n",
      "iteration 295 / 300: loss 0.599264\n",
      "iteration 295 / 300: loss 0.611379\n",
      "iteration 295 / 300: loss 0.592463\n",
      "iteration 295 / 300: loss 0.599424\n",
      "iteration 295 / 300: loss 0.603100\n",
      "iteration 295 / 300: loss 0.602410\n",
      "iteration 295 / 300: loss 0.579811\n",
      "iteration 295 / 300: loss 0.601592\n",
      "iteration 296 / 300: loss 0.585528\n",
      "iteration 296 / 300: loss 0.588428\n",
      "iteration 296 / 300: loss 0.567516\n",
      "iteration 296 / 300: loss 0.592380\n",
      "iteration 296 / 300: loss 0.593618\n",
      "iteration 296 / 300: loss 0.595295\n",
      "iteration 296 / 300: loss 0.608784\n",
      "iteration 296 / 300: loss 0.592732\n",
      "iteration 296 / 300: loss 0.628060\n",
      "iteration 296 / 300: loss 0.580152\n",
      "iteration 296 / 300: loss 0.607923\n",
      "iteration 296 / 300: loss 0.587394\n",
      "iteration 296 / 300: loss 0.591686\n",
      "iteration 296 / 300: loss 0.571370\n",
      "iteration 296 / 300: loss 0.583025\n",
      "iteration 296 / 300: loss 0.608441\n",
      "iteration 296 / 300: loss 0.598359\n",
      "iteration 296 / 300: loss 0.583858\n",
      "iteration 296 / 300: loss 0.615253\n",
      "iteration 296 / 300: loss 0.591649\n",
      "iteration 296 / 300: loss 0.585499\n",
      "iteration 296 / 300: loss 0.591325\n",
      "iteration 296 / 300: loss 0.604341\n",
      "iteration 296 / 300: loss 0.595786\n",
      "iteration 296 / 300: loss 0.614949\n",
      "iteration 296 / 300: loss 0.608389\n",
      "iteration 296 / 300: loss 0.598222\n",
      "iteration 296 / 300: loss 0.588936\n",
      "iteration 296 / 300: loss 0.617757\n",
      "iteration 296 / 300: loss 0.594770\n",
      "iteration 296 / 300: loss 0.601684\n",
      "iteration 296 / 300: loss 0.631031\n",
      "iteration 296 / 300: loss 0.587513\n",
      "iteration 296 / 300: loss 0.606561\n",
      "iteration 296 / 300: loss 0.588034\n",
      "iteration 296 / 300: loss 0.600890\n",
      "iteration 296 / 300: loss 0.595958\n",
      "iteration 296 / 300: loss 0.589291\n",
      "iteration 296 / 300: loss 0.599526\n",
      "iteration 296 / 300: loss 0.604855\n",
      "iteration 296 / 300: loss 0.619414\n",
      "iteration 296 / 300: loss 0.588808\n",
      "iteration 296 / 300: loss 0.593645\n",
      "iteration 296 / 300: loss 0.585595\n",
      "iteration 296 / 300: loss 0.613212\n",
      "iteration 296 / 300: loss 0.587523\n",
      "iteration 296 / 300: loss 0.578328\n",
      "iteration 296 / 300: loss 0.567435\n",
      "iteration 296 / 300: loss 0.562235\n",
      "iteration 296 / 300: loss 0.594183\n",
      "iteration 296 / 300: loss 0.578821\n",
      "iteration 296 / 300: loss 0.586360\n",
      "iteration 296 / 300: loss 0.572890\n",
      "iteration 296 / 300: loss 0.596151\n",
      "iteration 296 / 300: loss 0.607951\n",
      "iteration 296 / 300: loss 0.610839\n",
      "iteration 296 / 300: loss 0.606265\n",
      "iteration 296 / 300: loss 0.583790\n",
      "iteration 296 / 300: loss 0.589627\n",
      "iteration 296 / 300: loss 0.595184\n",
      "iteration 296 / 300: loss 0.598955\n",
      "iteration 296 / 300: loss 0.596133\n",
      "iteration 296 / 300: loss 0.589769\n",
      "iteration 296 / 300: loss 0.591136\n",
      "iteration 296 / 300: loss 0.584854\n",
      "iteration 296 / 300: loss 0.599646\n",
      "iteration 296 / 300: loss 0.598902\n",
      "iteration 296 / 300: loss 0.614282\n",
      "iteration 296 / 300: loss 0.597796\n",
      "iteration 296 / 300: loss 0.599298\n",
      "iteration 296 / 300: loss 0.603317\n",
      "iteration 296 / 300: loss 0.592865\n",
      "iteration 296 / 300: loss 0.592391\n",
      "iteration 296 / 300: loss 0.589041\n",
      "iteration 296 / 300: loss 0.596446\n",
      "iteration 296 / 300: loss 0.605709\n",
      "iteration 296 / 300: loss 0.610562\n",
      "iteration 296 / 300: loss 0.587782\n",
      "iteration 296 / 300: loss 0.599351\n",
      "iteration 296 / 300: loss 0.602792\n",
      "iteration 296 / 300: loss 0.605028\n",
      "iteration 296 / 300: loss 0.603848\n",
      "iteration 296 / 300: loss 0.624144\n",
      "iteration 296 / 300: loss 0.587219\n",
      "iteration 296 / 300: loss 0.580754\n",
      "iteration 296 / 300: loss 0.625045\n",
      "iteration 296 / 300: loss 0.603310\n",
      "iteration 296 / 300: loss 0.604321\n",
      "iteration 296 / 300: loss 0.595476\n",
      "iteration 296 / 300: loss 0.597543\n",
      "iteration 296 / 300: loss 0.592740\n",
      "iteration 296 / 300: loss 0.589494\n",
      "iteration 296 / 300: loss 0.599264\n",
      "iteration 296 / 300: loss 0.611379\n",
      "iteration 296 / 300: loss 0.592463\n",
      "iteration 296 / 300: loss 0.599424\n",
      "iteration 296 / 300: loss 0.603100\n",
      "iteration 296 / 300: loss 0.602410\n",
      "iteration 296 / 300: loss 0.579811\n",
      "iteration 296 / 300: loss 0.601592\n",
      "iteration 297 / 300: loss 0.585528\n",
      "iteration 297 / 300: loss 0.588428\n",
      "iteration 297 / 300: loss 0.567516\n",
      "iteration 297 / 300: loss 0.592380\n",
      "iteration 297 / 300: loss 0.593618\n",
      "iteration 297 / 300: loss 0.595295\n",
      "iteration 297 / 300: loss 0.608784\n",
      "iteration 297 / 300: loss 0.592732\n",
      "iteration 297 / 300: loss 0.628060\n",
      "iteration 297 / 300: loss 0.580152\n",
      "iteration 297 / 300: loss 0.607923\n",
      "iteration 297 / 300: loss 0.587394\n",
      "iteration 297 / 300: loss 0.591686\n",
      "iteration 297 / 300: loss 0.571370\n",
      "iteration 297 / 300: loss 0.583025\n",
      "iteration 297 / 300: loss 0.608441\n",
      "iteration 297 / 300: loss 0.598359\n",
      "iteration 297 / 300: loss 0.583858\n",
      "iteration 297 / 300: loss 0.615253\n",
      "iteration 297 / 300: loss 0.591649\n",
      "iteration 297 / 300: loss 0.585499\n",
      "iteration 297 / 300: loss 0.591325\n",
      "iteration 297 / 300: loss 0.604341\n",
      "iteration 297 / 300: loss 0.595786\n",
      "iteration 297 / 300: loss 0.614949\n",
      "iteration 297 / 300: loss 0.608389\n",
      "iteration 297 / 300: loss 0.598222\n",
      "iteration 297 / 300: loss 0.588936\n",
      "iteration 297 / 300: loss 0.617757\n",
      "iteration 297 / 300: loss 0.594770\n",
      "iteration 297 / 300: loss 0.601684\n",
      "iteration 297 / 300: loss 0.631031\n",
      "iteration 297 / 300: loss 0.587513\n",
      "iteration 297 / 300: loss 0.606561\n",
      "iteration 297 / 300: loss 0.588034\n",
      "iteration 297 / 300: loss 0.600890\n",
      "iteration 297 / 300: loss 0.595958\n",
      "iteration 297 / 300: loss 0.589291\n",
      "iteration 297 / 300: loss 0.599526\n",
      "iteration 297 / 300: loss 0.604855\n",
      "iteration 297 / 300: loss 0.619414\n",
      "iteration 297 / 300: loss 0.588808\n",
      "iteration 297 / 300: loss 0.593645\n",
      "iteration 297 / 300: loss 0.585595\n",
      "iteration 297 / 300: loss 0.613212\n",
      "iteration 297 / 300: loss 0.587523\n",
      "iteration 297 / 300: loss 0.578328\n",
      "iteration 297 / 300: loss 0.567435\n",
      "iteration 297 / 300: loss 0.562235\n",
      "iteration 297 / 300: loss 0.594183\n",
      "iteration 297 / 300: loss 0.578821\n",
      "iteration 297 / 300: loss 0.586360\n",
      "iteration 297 / 300: loss 0.572890\n",
      "iteration 297 / 300: loss 0.596151\n",
      "iteration 297 / 300: loss 0.607951\n",
      "iteration 297 / 300: loss 0.610839\n",
      "iteration 297 / 300: loss 0.606265\n",
      "iteration 297 / 300: loss 0.583790\n",
      "iteration 297 / 300: loss 0.589627\n",
      "iteration 297 / 300: loss 0.595184\n",
      "iteration 297 / 300: loss 0.598955\n",
      "iteration 297 / 300: loss 0.596133\n",
      "iteration 297 / 300: loss 0.589769\n",
      "iteration 297 / 300: loss 0.591136\n",
      "iteration 297 / 300: loss 0.584854\n",
      "iteration 297 / 300: loss 0.599646\n",
      "iteration 297 / 300: loss 0.598902\n",
      "iteration 297 / 300: loss 0.614282\n",
      "iteration 297 / 300: loss 0.597796\n",
      "iteration 297 / 300: loss 0.599298\n",
      "iteration 297 / 300: loss 0.603317\n",
      "iteration 297 / 300: loss 0.592865\n",
      "iteration 297 / 300: loss 0.592391\n",
      "iteration 297 / 300: loss 0.589041\n",
      "iteration 297 / 300: loss 0.596446\n",
      "iteration 297 / 300: loss 0.605709\n",
      "iteration 297 / 300: loss 0.610562\n",
      "iteration 297 / 300: loss 0.587782\n",
      "iteration 297 / 300: loss 0.599351\n",
      "iteration 297 / 300: loss 0.602792\n",
      "iteration 297 / 300: loss 0.605028\n",
      "iteration 297 / 300: loss 0.603848\n",
      "iteration 297 / 300: loss 0.624144\n",
      "iteration 297 / 300: loss 0.587219\n",
      "iteration 297 / 300: loss 0.580754\n",
      "iteration 297 / 300: loss 0.625045\n",
      "iteration 297 / 300: loss 0.603310\n",
      "iteration 297 / 300: loss 0.604321\n",
      "iteration 297 / 300: loss 0.595476\n",
      "iteration 297 / 300: loss 0.597543\n",
      "iteration 297 / 300: loss 0.592740\n",
      "iteration 297 / 300: loss 0.589494\n",
      "iteration 297 / 300: loss 0.599264\n",
      "iteration 297 / 300: loss 0.611379\n",
      "iteration 297 / 300: loss 0.592463\n",
      "iteration 297 / 300: loss 0.599424\n",
      "iteration 297 / 300: loss 0.603100\n",
      "iteration 297 / 300: loss 0.602410\n",
      "iteration 297 / 300: loss 0.579811\n",
      "iteration 297 / 300: loss 0.601592\n",
      "iteration 298 / 300: loss 0.585528\n",
      "iteration 298 / 300: loss 0.588428\n",
      "iteration 298 / 300: loss 0.567516\n",
      "iteration 298 / 300: loss 0.592380\n",
      "iteration 298 / 300: loss 0.593618\n",
      "iteration 298 / 300: loss 0.595295\n",
      "iteration 298 / 300: loss 0.608784\n",
      "iteration 298 / 300: loss 0.592732\n",
      "iteration 298 / 300: loss 0.628060\n",
      "iteration 298 / 300: loss 0.580152\n",
      "iteration 298 / 300: loss 0.607923\n",
      "iteration 298 / 300: loss 0.587394\n",
      "iteration 298 / 300: loss 0.591686\n",
      "iteration 298 / 300: loss 0.571370\n",
      "iteration 298 / 300: loss 0.583025\n",
      "iteration 298 / 300: loss 0.608441\n",
      "iteration 298 / 300: loss 0.598359\n",
      "iteration 298 / 300: loss 0.583858\n",
      "iteration 298 / 300: loss 0.615253\n",
      "iteration 298 / 300: loss 0.591649\n",
      "iteration 298 / 300: loss 0.585499\n",
      "iteration 298 / 300: loss 0.591325\n",
      "iteration 298 / 300: loss 0.604341\n",
      "iteration 298 / 300: loss 0.595786\n",
      "iteration 298 / 300: loss 0.614949\n",
      "iteration 298 / 300: loss 0.608389\n",
      "iteration 298 / 300: loss 0.598222\n",
      "iteration 298 / 300: loss 0.588936\n",
      "iteration 298 / 300: loss 0.617757\n",
      "iteration 298 / 300: loss 0.594770\n",
      "iteration 298 / 300: loss 0.601684\n",
      "iteration 298 / 300: loss 0.631031\n",
      "iteration 298 / 300: loss 0.587513\n",
      "iteration 298 / 300: loss 0.606561\n",
      "iteration 298 / 300: loss 0.588034\n",
      "iteration 298 / 300: loss 0.600890\n",
      "iteration 298 / 300: loss 0.595958\n",
      "iteration 298 / 300: loss 0.589291\n",
      "iteration 298 / 300: loss 0.599526\n",
      "iteration 298 / 300: loss 0.604855\n",
      "iteration 298 / 300: loss 0.619414\n",
      "iteration 298 / 300: loss 0.588808\n",
      "iteration 298 / 300: loss 0.593645\n",
      "iteration 298 / 300: loss 0.585595\n",
      "iteration 298 / 300: loss 0.613212\n",
      "iteration 298 / 300: loss 0.587523\n",
      "iteration 298 / 300: loss 0.578328\n",
      "iteration 298 / 300: loss 0.567435\n",
      "iteration 298 / 300: loss 0.562235\n",
      "iteration 298 / 300: loss 0.594183\n",
      "iteration 298 / 300: loss 0.578821\n",
      "iteration 298 / 300: loss 0.586360\n",
      "iteration 298 / 300: loss 0.572890\n",
      "iteration 298 / 300: loss 0.596151\n",
      "iteration 298 / 300: loss 0.607951\n",
      "iteration 298 / 300: loss 0.610839\n",
      "iteration 298 / 300: loss 0.606265\n",
      "iteration 298 / 300: loss 0.583790\n",
      "iteration 298 / 300: loss 0.589627\n",
      "iteration 298 / 300: loss 0.595184\n",
      "iteration 298 / 300: loss 0.598955\n",
      "iteration 298 / 300: loss 0.596133\n",
      "iteration 298 / 300: loss 0.589769\n",
      "iteration 298 / 300: loss 0.591136\n",
      "iteration 298 / 300: loss 0.584854\n",
      "iteration 298 / 300: loss 0.599646\n",
      "iteration 298 / 300: loss 0.598902\n",
      "iteration 298 / 300: loss 0.614282\n",
      "iteration 298 / 300: loss 0.597796\n",
      "iteration 298 / 300: loss 0.599298\n",
      "iteration 298 / 300: loss 0.603317\n",
      "iteration 298 / 300: loss 0.592865\n",
      "iteration 298 / 300: loss 0.592391\n",
      "iteration 298 / 300: loss 0.589041\n",
      "iteration 298 / 300: loss 0.596446\n",
      "iteration 298 / 300: loss 0.605709\n",
      "iteration 298 / 300: loss 0.610562\n",
      "iteration 298 / 300: loss 0.587782\n",
      "iteration 298 / 300: loss 0.599351\n",
      "iteration 298 / 300: loss 0.602792\n",
      "iteration 298 / 300: loss 0.605028\n",
      "iteration 298 / 300: loss 0.603848\n",
      "iteration 298 / 300: loss 0.624144\n",
      "iteration 298 / 300: loss 0.587219\n",
      "iteration 298 / 300: loss 0.580754\n",
      "iteration 298 / 300: loss 0.625045\n",
      "iteration 298 / 300: loss 0.603310\n",
      "iteration 298 / 300: loss 0.604321\n",
      "iteration 298 / 300: loss 0.595476\n",
      "iteration 298 / 300: loss 0.597543\n",
      "iteration 298 / 300: loss 0.592740\n",
      "iteration 298 / 300: loss 0.589494\n",
      "iteration 298 / 300: loss 0.599264\n",
      "iteration 298 / 300: loss 0.611379\n",
      "iteration 298 / 300: loss 0.592463\n",
      "iteration 298 / 300: loss 0.599424\n",
      "iteration 298 / 300: loss 0.603100\n",
      "iteration 298 / 300: loss 0.602410\n",
      "iteration 298 / 300: loss 0.579811\n",
      "iteration 298 / 300: loss 0.601592\n",
      "iteration 299 / 300: loss 0.585528\n",
      "iteration 299 / 300: loss 0.588428\n",
      "iteration 299 / 300: loss 0.567516\n",
      "iteration 299 / 300: loss 0.592380\n",
      "iteration 299 / 300: loss 0.593618\n",
      "iteration 299 / 300: loss 0.595295\n",
      "iteration 299 / 300: loss 0.608784\n",
      "iteration 299 / 300: loss 0.592732\n",
      "iteration 299 / 300: loss 0.628060\n",
      "iteration 299 / 300: loss 0.580152\n",
      "iteration 299 / 300: loss 0.607923\n",
      "iteration 299 / 300: loss 0.587394\n",
      "iteration 299 / 300: loss 0.591686\n",
      "iteration 299 / 300: loss 0.571370\n",
      "iteration 299 / 300: loss 0.583025\n",
      "iteration 299 / 300: loss 0.608441\n",
      "iteration 299 / 300: loss 0.598359\n",
      "iteration 299 / 300: loss 0.583858\n",
      "iteration 299 / 300: loss 0.615253\n",
      "iteration 299 / 300: loss 0.591649\n",
      "iteration 299 / 300: loss 0.585499\n",
      "iteration 299 / 300: loss 0.591325\n",
      "iteration 299 / 300: loss 0.604341\n",
      "iteration 299 / 300: loss 0.595786\n",
      "iteration 299 / 300: loss 0.614949\n",
      "iteration 299 / 300: loss 0.608389\n",
      "iteration 299 / 300: loss 0.598222\n",
      "iteration 299 / 300: loss 0.588936\n",
      "iteration 299 / 300: loss 0.617757\n",
      "iteration 299 / 300: loss 0.594770\n",
      "iteration 299 / 300: loss 0.601684\n",
      "iteration 299 / 300: loss 0.631031\n",
      "iteration 299 / 300: loss 0.587513\n",
      "iteration 299 / 300: loss 0.606561\n",
      "iteration 299 / 300: loss 0.588034\n",
      "iteration 299 / 300: loss 0.600890\n",
      "iteration 299 / 300: loss 0.595958\n",
      "iteration 299 / 300: loss 0.589291\n",
      "iteration 299 / 300: loss 0.599526\n",
      "iteration 299 / 300: loss 0.604855\n",
      "iteration 299 / 300: loss 0.619414\n",
      "iteration 299 / 300: loss 0.588808\n",
      "iteration 299 / 300: loss 0.593645\n",
      "iteration 299 / 300: loss 0.585595\n",
      "iteration 299 / 300: loss 0.613212\n",
      "iteration 299 / 300: loss 0.587523\n",
      "iteration 299 / 300: loss 0.578328\n",
      "iteration 299 / 300: loss 0.567435\n",
      "iteration 299 / 300: loss 0.562235\n",
      "iteration 299 / 300: loss 0.594183\n",
      "iteration 299 / 300: loss 0.578821\n",
      "iteration 299 / 300: loss 0.586360\n",
      "iteration 299 / 300: loss 0.572890\n",
      "iteration 299 / 300: loss 0.596151\n",
      "iteration 299 / 300: loss 0.607951\n",
      "iteration 299 / 300: loss 0.610839\n",
      "iteration 299 / 300: loss 0.606265\n",
      "iteration 299 / 300: loss 0.583790\n",
      "iteration 299 / 300: loss 0.589627\n",
      "iteration 299 / 300: loss 0.595184\n",
      "iteration 299 / 300: loss 0.598955\n",
      "iteration 299 / 300: loss 0.596133\n",
      "iteration 299 / 300: loss 0.589769\n",
      "iteration 299 / 300: loss 0.591136\n",
      "iteration 299 / 300: loss 0.584854\n",
      "iteration 299 / 300: loss 0.599646\n",
      "iteration 299 / 300: loss 0.598902\n",
      "iteration 299 / 300: loss 0.614282\n",
      "iteration 299 / 300: loss 0.597796\n",
      "iteration 299 / 300: loss 0.599298\n",
      "iteration 299 / 300: loss 0.603317\n",
      "iteration 299 / 300: loss 0.592865\n",
      "iteration 299 / 300: loss 0.592391\n",
      "iteration 299 / 300: loss 0.589041\n",
      "iteration 299 / 300: loss 0.596446\n",
      "iteration 299 / 300: loss 0.605709\n",
      "iteration 299 / 300: loss 0.610562\n",
      "iteration 299 / 300: loss 0.587782\n",
      "iteration 299 / 300: loss 0.599351\n",
      "iteration 299 / 300: loss 0.602792\n",
      "iteration 299 / 300: loss 0.605028\n",
      "iteration 299 / 300: loss 0.603848\n",
      "iteration 299 / 300: loss 0.624144\n",
      "iteration 299 / 300: loss 0.587219\n",
      "iteration 299 / 300: loss 0.580754\n",
      "iteration 299 / 300: loss 0.625045\n",
      "iteration 299 / 300: loss 0.603310\n",
      "iteration 299 / 300: loss 0.604321\n",
      "iteration 299 / 300: loss 0.595476\n",
      "iteration 299 / 300: loss 0.597543\n",
      "iteration 299 / 300: loss 0.592740\n",
      "iteration 299 / 300: loss 0.589494\n",
      "iteration 299 / 300: loss 0.599264\n",
      "iteration 299 / 300: loss 0.611379\n",
      "iteration 299 / 300: loss 0.592463\n",
      "iteration 299 / 300: loss 0.599424\n",
      "iteration 299 / 300: loss 0.603100\n",
      "iteration 299 / 300: loss 0.602410\n",
      "iteration 299 / 300: loss 0.579811\n",
      "iteration 299 / 300: loss 0.601592\n"
     ]
    }
   ],
   "source": [
    "iterations = 300\n",
    "lr = 0.015\n",
    "lr_decay=0.999\n",
    "reg = 5e-6\n",
    "loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "for t in range(iterations):\n",
    "    indices = np.arange(Ntr)\n",
    "    indices = np.split(indices,100) \n",
    "    for i in indices:\n",
    "        rng.shuffle(i)\n",
    "        x = x_train[i]\t\n",
    "        y = y_train[i]\n",
    "        h = 1.0/(1.0 + np.exp(-(x.dot(w1) + b1)))\n",
    "        y_pred = h.dot(w2) +b2\n",
    "        loss = 1./batch_size*np.square(y_pred - y).sum() + reg * (np.sum(w2 * w2) + np.sum(w1 * w1))\n",
    "        loss_history.append(loss)\n",
    "        #if t%10 ==0:\n",
    "        print('iteration %d / %d: loss %f' %(t, iterations, loss))\n",
    "        dy_pred = 1./batch_size*2.0*(y_pred -y) # partial derivative of L w.r.t y_hat backward\n",
    "        dw2 = h.T.dot(dy_pred) + reg*w2\n",
    "        db2 = dy_pred.sum(axis=0)\n",
    "        dh = dy_pred.dot(w2.T)\n",
    "        dw1 = x.T.dot(dh*h*(1-h)) + reg*w1\n",
    "        db1 = (dh*h*(1-h)).sum(axis=0)\n",
    "        w1 -= lr*dw1\n",
    "        w2 -= lr*dw2\n",
    "        b1 -= lr*db1\n",
    "        b2 -= lr*db2\n",
    "        lr *= lr_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "greater-martin",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAV8ElEQVR4nO3de5RV5XnH8d/DDDOjXERgJC5AQYsaTCKhU6LEpSbRBNAlaV0rxV5M0yxdiZoVTaPF2iSG2ubW2taUmmpiE9NGQoixdKlVoyZqouKgiMAIjihyE0a5eeMyM0//OHvIOYc9M2eGfc4+7z7fz1qzZt9m7+edffjNy7v32cfcXQCA8A1JuwAAQDIIdADICAIdADKCQAeAjCDQASAj6tM68NixY33SpElpHR4AgrR8+fLX3b05bl1qgT5p0iS1tramdXgACJKZbehtHUMuAJARBDoAZASBDgAZQaADQEYQ6ACQEf0GupndbmbbzWxVL+vNzG42s3YzW2lm05MvEwDQn1J66D+UNKuP9bMlTYm+LpN0y+GXBQAYqH4D3d0flbSjj03mSrrDc56UNMrMjk2qwGJPv7JDNz2wVvs7u8t1CAAIUhJj6OMlbcyb3xQtO4SZXWZmrWbW2tHRMaiDPbNhp25+uF2d3QQ6AOSr6EVRd7/V3VvcvaW5OfadqwPYV0JFAUBGJBHomyVNzJufEC0rC7Ny7RkAwpZEoC+VdEl0t8vpkna7+9YE9tsnOugAUKjfh3OZ2Z2SzpE01sw2SfqapKGS5O7fk3SvpDmS2iW9I+kz5SpWkkx00QEgTr+B7u4X97PeJV2RWEUl4sOtAaBQcO8UZQwdAOIFF+g96J8DQKFgAx0AUCjYQGcIHQAKBRfoxiA6AMQKLtAPoocOAAWCC3T65wAQL7hA7+F00QGgQHCBzhA6AMQLLtB7cJcLABQKLtDpoANAvOACvQcddAAoFFygcx86AMQLLtABAPGCDXQenwsAhYILdEZcACBecIHeg/45ABQKLtDpoANAvOACvQdD6ABQKLxAZxAdAGKFF+gRHs4FAIWCC3T65wAQL7hAP4gOOgAUCC7QGUIHgHjBBXoPOugAUCi4QDdG0QEgVnCB3oP70AGgUHCBzhg6AMQLLtB7cB86ABQKLtDpoANAvOACvQdj6ABQKLhAZwwdAOIFF+g96KADQKHgAp370AEgXnCB3oPPFAWAQuEFOh10AIhVUqCb2SwzW2tm7WY2P2b98Wb2kJmtNLNfmdmE5EstRAcdAAr1G+hmVidpoaTZkqZKutjMphZt9o+S7nD3D0haIOkbSRd6sJ5y7RgAAldKD32GpHZ3X+/u+yUtkjS3aJupkh6Oph+JWQ8AKLNSAn28pI1585uiZfmek/RH0fQfShphZmOKd2Rml5lZq5m1dnR0DKZeGTeiA0CspC6KflnS2Wb2rKSzJW2W1FW8kbvf6u4t7t7S3Nx8WAdkDB0ACtWXsM1mSRPz5idEyw5y9y2KeuhmNlzSRe6+K6EaC9A/B4B4pfTQn5Y0xcwmm1mDpHmSluZvYGZjzaxnX9dJuj3ZMg/F0xYBoFC/ge7unZKulHS/pDZJi919tZktMLMLo83OkbTWzNZJGifp78tUL89yAYBelDLkIne/V9K9Rcu+mje9RNKSZEvrr6ZKHg0Aql9w7xSlhw4A8YIL9B500AGgUHCBztMWASBecIHeg6ctAkCh4AKdMXQAiBdcoPegfw4AhYINdABAoWADnSF0ACgUXKDztEUAiBdcoAMA4gUX6O/u75TEbYsAUCy4QP/rnz8vSbr+7lUpVwIA1SW4QO/RPKIx7RIAoKoEF+gTjj5CktRYF1zpAFBWwaViY32u5H2d3SlXAgDVJcBAr5Mk7es85CNLAaCmhRfoQ+mhA0Cc4AK9IRo730+gA0CB8AI9GkPf30WgA0C+4AJ9aNRDP0CgA0CBAAM99yyXA528UxQA8gUX6A3RXS700AGgUHCBPi56h+jwpvqUKwGA6hJcoF9yxiRJ0p/MOC7dQgCgygQX6PV1PA8dAOIEF+h1Q3KBPv+u51OuBACqS3CBPoRPLAKAWMEFek8PHQBQKLxAp4cOALGCC/QhwVUMAJURXDwy5AIA8YILdC6KAkC84AI9v4fe3c3zXACgR3iBntdD7yTQAeCg4AJ9CGPoABAruEDP56KHDgA9Sgp0M5tlZmvNrN3M5sesP87MHjGzZ81spZnNSb7UQ7VtfbMShwGAIPQb6GZWJ2mhpNmSpkq62MymFm32t5IWu/sHJc2T9O9JFxpnwxtvV+IwABCEUnroMyS1u/t6d98vaZGkuUXbuKSR0fRRkrYkV2LvvrhoRSUOAwBBKOVTIsZL2pg3v0nSh4q2uUHSA2b2BUnDJJ2bSHUAgJIldVH0Ykk/dPcJkuZI+rGZHbJvM7vMzFrNrLWjoyOhQwMApNICfbOkiXnzE6Jl+T4rabEkufsTkpokjS3ekbvf6u4t7t7S3Nw8uIoBALFKCfSnJU0xs8lm1qDcRc+lRdu8KuljkmRm71Uu0OmCA0AF9Rvo7t4p6UpJ90tqU+5ultVmtsDMLow2+ytJl5rZc5LulPQX7l6Rm8T3dXZV4jAAUPVKuSgqd79X0r1Fy76aN71G0oeTLa00j657XedNHZfGoQGgqgT9TlFJeuxFRnYAQMpAoN/xxIa0SwCAqhB8oAMAcgh0AMiIIAN9zLCGgnk+6AIAAg30a2edXDD/0AvbU6oEAKpHkIH+qZaJBfO3/Ko9pUoAoHoEGehW9EHRz7y6K51CAKCKBBnoAIBDZSbQl2/YmXYJAJCqzAT6Rbf8Vis27kq7DABITWYCXZJe2Lon7RIAIDWZCnQAqGWZCvS39nWmXQIApCZTgX7jPW1plwAAqQk20B+4+qy0SwCAqhJsoJ80bkTs8s6u7gpXAgDVIdhA781/Pcnz0QHUpswF+g3/uybtEgAgFZkLdACoVQQ6AGREJgN9zRbeMQqg9mQy0Ofc/BifYgSg5mQy0AGgFgUd6Ku+/ole1z3Ytq2ClQBA+oIO9OGN9b2ua31lRwUrAYD0BR3ofbntsZfTLgEAKiqzgQ4AtYZAB4CMyHSg8zmjAGpJpgP9olt+q7f50AsANSL4QG9bMKvP9Z1dvMEIQG0IPtCPaKjrc72LQAdQG4IP9P7c8QTPRwdQGzIf6Dc9uE4db+5LuwwAKLvMB7oktW3l6YsAsi8Tgf709ef2uf6S25fpjbfopQPItpIC3cxmmdlaM2s3s/kx6//ZzFZEX+vMbFfilfaheURjv9u8s7+rApUAQHp6f7pVxMzqJC2UdJ6kTZKeNrOl7n7wwzvd/eq87b8g6YNlqBUA0IdSeugzJLW7+3p33y9pkaS5fWx/saQ7kyguSWd/5xHtPUAvHUB2lRLo4yVtzJvfFC07hJkdL2mypId7WX+ZmbWaWWtHR8dAaz0s3S5t2vlORY8JAJWU9EXReZKWuHtsV9jdb3X3FndvaW5uTvTA500d1+82W3fvTfSYAFBNSgn0zZIm5s1PiJbFmaeUhltuu6Sl323+/AfLtG0PoQ4gm0oJ9KclTTGzyWbWoFxoLy3eyMxOkXS0pCeSLTFZO97en3YJAFAW/Qa6u3dKulLS/ZLaJC1299VmtsDMLszbdJ6kRe5e1Q9PuW/Va2mXAABlYWnlb0tLi7e2tia6z2/c16b/+PX6fre7/6qzdPJ7RiR6bACoBDNb7u6xY8yZeKdoj+tmv7ek7d7ZzzPSAWRPpgK9VNcsWakqHxkCgAGryUBv3/6WnnmVj6cDkC01GeiSdO/zXBwFkC01G+g/ePxlrdq8O+0yACAxNRvoknTBdx9PuwQASEzmAv37JbxjtGD7x/q/zREAQpC5QD+3hGe65Lvxnjbt7+wuUzUAUDmZC/TB+OTC36RdAgActkwG+kdOHtiTHNds3cPQC4DgZTLQ//MzMwb8Mzfe08ZdLwCClslAH6wLvvu4tux6N+0yAGBQCPQiM7/5MKEOIEgEeoyZ33xY7dvfTLsMABiQzAb6xwd4+2Kxc296VI+uq+znngLA4chsoN86wDcYxbnk9mW6+qcr9PY+HrcLoPplNtCT8otnN+vUr92v1Vu4AwZAdSPQS3T+zY9r7sLfaDsfMg2gSmU60P913rRE9/fcxl2a8Q8P6Vv/94J2v3Mg0X0DwOHKdKDPnTa+LPu95Vcv6bQFD+j7j63X7ncJdgDVIdOBXm433tOm077+gK5a9Cz3rgNIXX3aBZTb6SeM1pPrd5T1GHev2KK7V2w5OH/R9AmadtwoTRpzpMaPOkLHjGzS8MbM/6oBpMzS+rDklpYWb21trcixJs2/pyLHKcXJ40Zo+vGjdMLY4Zo4+gi956gj1DyiUaOPbNARDXVplwegypnZcnePvS+bbmOFrd32ptZu6/9dqCc0D9NJx4zQuJGNGjO8UaOOHKqRTUM1oqlewxrrdWRDnY5sqFNjfZ0a64eooX6I6uuGaGidqX7IEA0xycwq0CIA1YJAr1LrO97W+o630y4DQMI+e+ZkfeWCqWXZd01cFH3s2o+kXQIASMp9QH251ESgTxx9ZNolAEDZ1USgA0A1eahtW1n2WzOB/rPPnZF2CQAgSWrdsLMs+62ZQP+DSaPTLgEAJEnlulu8ZgJdksYMa0i7BAAom5oK9OVfOS/tEgBArvJ00Wsq0AGgGmzfs68s+625QP/ll85KuwQANe4Xz24uy35rLtB/75gRaZcAAGVRc4EuSU/9zcfSLgEAEldSoJvZLDNba2btZja/l20+ZWZrzGy1mf0k2TKTNW5kU9olAEDi+g10M6uTtFDSbElTJV1sZlOLtpki6TpJH3b3UyVdlXypyfrJpR9KuwQASFQpPfQZktrdfb2775e0SNLcom0ulbTQ3XdKkrtvT7bM5M08cWzaJQBAokoJ9PGSNubNb4qW5TtJ0klm9hsze9LMZsXtyMwuM7NWM2vt6OgYXMUJ+vU156RdAgAkJqmLovWSpkg6R9LFkm4zs1HFG7n7re7e4u4tzc3NCR168I4fM0ynTRyVdhkAkIhSAn2zpIl58xOiZfk2SVrq7gfc/WVJ65QL+Kr3P1d8OO0SACARpQT605KmmNlkM2uQNE/S0qJt7laudy4zG6vcEMz65Mosr2XXcxsjgPD1G+ju3inpSkn3S2qTtNjdV5vZAjO7MNrsfklvmNkaSY9Iusbd3yhX0Uk7ZkST7rp8ZtplAMBhMS/Xcxz70dLS4q2trakcuzeLWzfq2iUr0y4DQA145ZvnD+rnzGy5u7fEravJd4r25lMtE3X++49NuwwAGBQCvcjCP52u948/Ku0yAGDACPQYP//8TJ3yHh7iBSAsBHqMhvohWnrlmfqz049LuxQAGfToNR8py34J9F401A/RjZ98P/epA0jccWOOLMt+CfR+nDZxlJ6/4eP63Nknpl0KAPSJQC/BiKahmj/7FD37lfN0+TkEO4DqRKAPwNHDGnTtrFP0wt/N0k8u/ZCmHDM87ZIA4KD6tAsIUdPQOs08cawe/NLZ2nugS8+8ulNLWjfprjJ9TiAAlIJAP0w94T7zxLG66Y+nqbOrWy+89qaeeXWnnnjpDd236rW0SwRQIwj0hNXXDdH7xh+l940/SpecMengcndXx5v7tHX3Xm3dvVfb9uyNpt/VK6+/rVVb9qirO53HMADIBgK9QsxMx4xs0jEjm3TaxP63l6S9B7q070C39nbmvu/r7NLeA93a3xXNd3XrQGe3DnS5DnR160BXtzq7XZ3R966eL3d1deW+d3vuj0t3NN3tLnepu9vlktyl3FRuOve9Z8nv1hc/AijuT9HAHxOU7B80d8ms9/mB/OxA9ps/P5BjVtpA6j6cNlbr72cgbTycfRfvZ1oZP4OBQK9iTUPr1DS0TkdpaNqlAAgAd7kAQEYQ6ACQEQQ6AGQEgQ4AGUGgA0BGEOgAkBEEOgBkBIEOABlhPvC38yVzYLMOSRsG+eNjJb2eYDlpoi3VJyvtkGhLtTqcthzv7s1xK1IL9MNhZq3u3pJ2HUmgLdUnK+2QaEu1KldbGHIBgIwg0AEgI0IN9FvTLiBBtKX6ZKUdEm2pVmVpS5Bj6ACAQ4XaQwcAFCHQASAjggt0M5tlZmvNrN3M5qddTxwze8XMnjezFWbWGi0bbWYPmtmL0fejo+VmZjdH7VlpZtPz9vPpaPsXzezTFar9djPbbmar8pYlVruZ/X70u2mPfrZsn1fTS1tuMLPN0blZYWZz8tZdF9W11sw+kbc89jVnZpPN7Klo+U/NrKFM7ZhoZo+Y2RozW21mX4yWB3de+mhLiOelycyWmdlzUVu+3tfxzawxmm+P1k8abBt75e7BfEmqk/SSpBMkNUh6TtLUtOuKqfMVSWOLln1b0vxoer6kb0XTcyTdJ8kknS7pqWj5aEnro+9HR9NHV6D2syRNl7SqHLVLWhZta9HPzq5wW26Q9OWYbadGr6dGSZOj11ldX685SYslzYumvyfp82Vqx7GSpkfTIySti+oN7rz00ZYQz4tJGh5ND5X0VPQ7jD2+pMslfS+anifpp4NtY29fofXQZ0hqd/f17r5f0iJJc1OuqVRzJf0omv6RpE/mLb/Dc56UNMrMjpX0CUkPuvsOd98p6UFJs8pdpLs/KmlHOWqP1o109yc990q+I29flWpLb+ZKWuTu+9z9ZUntyr3eYl9zUQ/2o5KWRD+f/3tJlLtvdfdnouk3JbVJGq8Az0sfbelNNZ8Xd/e3otmh0Zf3cfz887VE0seiegfUxr5qCi3Qx0vamDe/SX2/GNLikh4ws+Vmdlm0bJy7b42mX5M0LprurU3V1Nakah8fTRcvr7Qro6GI23uGKTTwtoyRtMvdO4uWl1X03/QPKtcbDPq8FLVFCvC8mFmdma2QtF25P5Av9XH8gzVH63dH9SaWAaEFeijOdPfpkmZLusLMzspfGfWCgrxfNOTaI7dIOlHSNElbJf1TqtUMgJkNl/RzSVe5+578daGdl5i2BHle3L3L3adJmqBcj/qUNOsJLdA3S5qYNz8hWlZV3H1z9H27pF8od6K3Rf+1VfR9e7R5b22qprYmVfvmaLp4ecW4+7boH2G3pNuUOzfSwNvyhnJDGfVFy8vCzIYqF4D/7e53RYuDPC9xbQn1vPRw912SHpF0Rh/HP1hztP6oqN7kMqAcFwvK9SWpXrkLOZP1u4sEp6ZdV1GNwySNyJv+rXJj399R4QWsb0fT56vwAtayaPloSS8rd/Hq6Gh6dIXaMEmFFxITq12HXnybU+G2HJs3fbVyY5eSdKoKL0ytV+6iVK+vOUk/U+HFr8vL1AZTblz7X4qWB3de+mhLiOelWdKoaPoISY9JuqC340u6QoUXRRcPto291lTOf0xl+iXOUe7K+EuSrk+7npj6Toh+8c9JWt1To3JjZQ9JelHSL/P+IZmkhVF7npfUkrevv1TuAkm7pM9UqP47lfsv7wHlxuw+m2TtklokrYp+5t8UvVu5gm35cVTrSklLi4Lk+qiutcq7y6O311x0rpdFbfyZpMYyteNM5YZTVkpaEX3NCfG89NGWEM/LByQ9G9W8StJX+zq+pKZovj1af8Jg29jbF2/9B4CMCG0MHQDQCwIdADKCQAeAjCDQASAjCHQAyAgCHQAygkAHgIz4f5NGRKFyvNgNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train -> (50000, 3072)\n",
      "train_acc =  0.8623377777777778\n",
      "train_loss =  0.5964346652836968\n",
      "x_test -> (10000, 3072)\n",
      "test_acc =  0.7772555555555556\n",
      "test_loss =  0.7433258738073459\n"
     ]
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "f, axarr = plt.subplots(1,10)\n",
    "f.set_size_inches(16, 6)\n",
    "\n",
    "for i in range(10):\n",
    "    img = w1[:, i].reshape(32, 32, 3) # CIFAR10\n",
    "    #img = w1[:, i].reshape(28, 28) # MNIST\n",
    "    axarr[i].imshow(img*100000)\n",
    "plt.show()\n",
    "\n",
    "x_t = x_train\n",
    "print(\"x_train ->\", x_t.shape)\n",
    "h = 1.0/(1.0 + np.exp(-(x_t.dot(w1) + b1))) #sigmoid\n",
    "y_pred = h.dot(w2) + b2\n",
    "train_acc = 1.0 -1/(9*Ntr)*(np.abs(np.argmax(y_train,axis=1) - np.argmax(y_pred, axis=1))).sum()\n",
    "train_loss = 1/(Ntr)*np.square(y_train - y_pred).sum()\n",
    "print(\"train_acc = \", train_acc)\n",
    "print(\"train_loss = \", train_loss)\n",
    "\n",
    "x_t = x_test\n",
    "print(\"x_test ->\", x_t.shape)\n",
    "h = 1.0/(1.0 + np.exp(-(x_t.dot(w1) + b1))) #sigmoid\n",
    "y_pred= h.dot(w2) + b2\n",
    "test_acc = 1.0 - 1/(9*Nte)*(np.abs(np.argmax(y_test,axis=1) - np.argmax(y_pred, axis=1))).sum()\n",
    "test_loss = 1/(Nte)*np.square(y_test - y_pred).sum()\n",
    "print(\"test_acc = \", test_acc)\n",
    "print(\"test_loss = \", test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
