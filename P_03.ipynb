{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distinguished-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "republican-lover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (50000, 32, 32, 3)\n",
      "w1: (3072, 200)\n",
      "b1: (200,)\n",
      "w2: (200, 10)\n",
      "b2: (10,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "print(\"x_train:\", x_train.shape)\n",
    "\n",
    "H = 200\n",
    "K = len(np.unique(y_train)) # Classes\n",
    "Ntr = x_train.shape[0]\n",
    "Nte = x_test.shape[0]\n",
    "Din = 3072 # CIFAR10\n",
    "# Din = 784 # MINIST\n",
    "\n",
    "# Normalize pixel values\n",
    "#x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "x_train = x_train - mean_image\n",
    "x_test = x_test - mean_image\n",
    "\n",
    "#Get the y value\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=K)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=K)\n",
    "\n",
    "# Transform images from (width, width, 3) to 3072-dimensional vectors (width*width*3)\n",
    "x_train = np.reshape(x_train,(Ntr,Din))\n",
    "x_test = np.reshape(x_test,(Nte,Din))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "std=1e-5\n",
    "w1 = std*np.random.randn(Din, H)\n",
    "w2 = std*np.random.randn(H, K)\n",
    "b1 = np.zeros(H)\n",
    "b2 = np.zeros(K)\n",
    "print(\"w1:\", w1.shape)\n",
    "print(\"b1:\", b1.shape)\n",
    "print(\"w2:\", w2.shape)\n",
    "print(\"b2:\", b2.shape)\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "integrated-jewel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 300: loss 0.999989\n",
      "iteration 0 / 300: loss 0.932921\n",
      "iteration 0 / 300: loss 0.914993\n",
      "iteration 0 / 300: loss 0.949184\n",
      "iteration 0 / 300: loss 0.973047\n",
      "iteration 0 / 300: loss 0.937630\n",
      "iteration 0 / 300: loss 0.914309\n",
      "iteration 0 / 300: loss 0.890677\n",
      "iteration 0 / 300: loss 0.886672\n",
      "iteration 0 / 300: loss 0.880934\n",
      "iteration 0 / 300: loss 0.870579\n",
      "iteration 0 / 300: loss 0.864933\n",
      "iteration 0 / 300: loss 0.865688\n",
      "iteration 0 / 300: loss 0.868945\n",
      "iteration 0 / 300: loss 0.854517\n",
      "iteration 0 / 300: loss 0.860942\n",
      "iteration 0 / 300: loss 0.858009\n",
      "iteration 0 / 300: loss 0.859767\n",
      "iteration 0 / 300: loss 0.859406\n",
      "iteration 0 / 300: loss 0.843421\n",
      "iteration 0 / 300: loss 0.852855\n",
      "iteration 0 / 300: loss 0.837301\n",
      "iteration 0 / 300: loss 0.850377\n",
      "iteration 0 / 300: loss 0.849026\n",
      "iteration 0 / 300: loss 0.845369\n",
      "iteration 0 / 300: loss 0.853037\n",
      "iteration 0 / 300: loss 0.847383\n",
      "iteration 0 / 300: loss 0.835382\n",
      "iteration 0 / 300: loss 0.838365\n",
      "iteration 0 / 300: loss 0.837468\n",
      "iteration 0 / 300: loss 0.851567\n",
      "iteration 0 / 300: loss 0.849104\n",
      "iteration 0 / 300: loss 0.833405\n",
      "iteration 0 / 300: loss 0.831561\n",
      "iteration 0 / 300: loss 0.834166\n",
      "iteration 0 / 300: loss 0.828879\n",
      "iteration 0 / 300: loss 0.824959\n",
      "iteration 0 / 300: loss 0.824565\n",
      "iteration 0 / 300: loss 0.823488\n",
      "iteration 0 / 300: loss 0.827097\n",
      "iteration 0 / 300: loss 0.826584\n",
      "iteration 0 / 300: loss 0.820623\n",
      "iteration 0 / 300: loss 0.828101\n",
      "iteration 0 / 300: loss 0.823409\n",
      "iteration 0 / 300: loss 0.826350\n",
      "iteration 0 / 300: loss 0.831067\n",
      "iteration 0 / 300: loss 0.822373\n",
      "iteration 0 / 300: loss 0.817982\n",
      "iteration 0 / 300: loss 0.809686\n",
      "iteration 0 / 300: loss 0.824441\n",
      "iteration 0 / 300: loss 0.809411\n",
      "iteration 0 / 300: loss 0.815895\n",
      "iteration 0 / 300: loss 0.803022\n",
      "iteration 0 / 300: loss 0.817033\n",
      "iteration 0 / 300: loss 0.825471\n",
      "iteration 0 / 300: loss 0.821454\n",
      "iteration 0 / 300: loss 0.832249\n",
      "iteration 0 / 300: loss 0.806067\n",
      "iteration 0 / 300: loss 0.820963\n",
      "iteration 0 / 300: loss 0.807381\n",
      "iteration 0 / 300: loss 0.806915\n",
      "iteration 0 / 300: loss 0.811069\n",
      "iteration 0 / 300: loss 0.812944\n",
      "iteration 0 / 300: loss 0.814733\n",
      "iteration 0 / 300: loss 0.812962\n",
      "iteration 0 / 300: loss 0.821712\n",
      "iteration 0 / 300: loss 0.821252\n",
      "iteration 0 / 300: loss 0.818754\n",
      "iteration 0 / 300: loss 0.799100\n",
      "iteration 0 / 300: loss 0.798427\n",
      "iteration 0 / 300: loss 0.804959\n",
      "iteration 0 / 300: loss 0.804303\n",
      "iteration 0 / 300: loss 0.803732\n",
      "iteration 0 / 300: loss 0.803928\n",
      "iteration 0 / 300: loss 0.808310\n",
      "iteration 0 / 300: loss 0.811238\n",
      "iteration 0 / 300: loss 0.804701\n",
      "iteration 0 / 300: loss 0.789345\n",
      "iteration 0 / 300: loss 0.799513\n",
      "iteration 0 / 300: loss 0.811460\n",
      "iteration 0 / 300: loss 0.807701\n",
      "iteration 0 / 300: loss 0.806186\n",
      "iteration 0 / 300: loss 0.810503\n",
      "iteration 0 / 300: loss 0.786440\n",
      "iteration 0 / 300: loss 0.790747\n",
      "iteration 0 / 300: loss 0.817955\n",
      "iteration 0 / 300: loss 0.799499\n",
      "iteration 0 / 300: loss 0.800337\n",
      "iteration 0 / 300: loss 0.817107\n",
      "iteration 0 / 300: loss 0.805619\n",
      "iteration 0 / 300: loss 0.802770\n",
      "iteration 0 / 300: loss 0.795338\n",
      "iteration 0 / 300: loss 0.801870\n",
      "iteration 0 / 300: loss 0.804600\n",
      "iteration 0 / 300: loss 0.799752\n",
      "iteration 0 / 300: loss 0.795851\n",
      "iteration 0 / 300: loss 0.812000\n",
      "iteration 0 / 300: loss 0.795478\n",
      "iteration 0 / 300: loss 0.786314\n",
      "iteration 0 / 300: loss 0.791927\n",
      "iteration 1 / 300: loss 0.786254\n",
      "iteration 1 / 300: loss 0.794264\n",
      "iteration 1 / 300: loss 0.776884\n",
      "iteration 1 / 300: loss 0.787936\n",
      "iteration 1 / 300: loss 0.789814\n",
      "iteration 1 / 300: loss 0.790554\n",
      "iteration 1 / 300: loss 0.800555\n",
      "iteration 1 / 300: loss 0.788072\n",
      "iteration 1 / 300: loss 0.804948\n",
      "iteration 1 / 300: loss 0.788475\n",
      "iteration 1 / 300: loss 0.805336\n",
      "iteration 1 / 300: loss 0.776177\n",
      "iteration 1 / 300: loss 0.784998\n",
      "iteration 1 / 300: loss 0.786616\n",
      "iteration 1 / 300: loss 0.776145\n",
      "iteration 1 / 300: loss 0.798240\n",
      "iteration 1 / 300: loss 0.790562\n",
      "iteration 1 / 300: loss 0.792309\n",
      "iteration 1 / 300: loss 0.800558\n",
      "iteration 1 / 300: loss 0.783461\n",
      "iteration 1 / 300: loss 0.797648\n",
      "iteration 1 / 300: loss 0.786648\n",
      "iteration 1 / 300: loss 0.803228\n",
      "iteration 1 / 300: loss 0.794169\n",
      "iteration 1 / 300: loss 0.794032\n",
      "iteration 1 / 300: loss 0.783346\n",
      "iteration 1 / 300: loss 0.796024\n",
      "iteration 1 / 300: loss 0.777724\n",
      "iteration 1 / 300: loss 0.792870\n",
      "iteration 1 / 300: loss 0.780647\n",
      "iteration 1 / 300: loss 0.795783\n",
      "iteration 1 / 300: loss 0.797122\n",
      "iteration 1 / 300: loss 0.778539\n",
      "iteration 1 / 300: loss 0.780367\n",
      "iteration 1 / 300: loss 0.788453\n",
      "iteration 1 / 300: loss 0.784720\n",
      "iteration 1 / 300: loss 0.782545\n",
      "iteration 1 / 300: loss 0.789076\n",
      "iteration 1 / 300: loss 0.782776\n",
      "iteration 1 / 300: loss 0.789970\n",
      "iteration 1 / 300: loss 0.795062\n",
      "iteration 1 / 300: loss 0.778049\n",
      "iteration 1 / 300: loss 0.779856\n",
      "iteration 1 / 300: loss 0.774834\n",
      "iteration 1 / 300: loss 0.779775\n",
      "iteration 1 / 300: loss 0.774854\n",
      "iteration 1 / 300: loss 0.762550\n",
      "iteration 1 / 300: loss 0.772855\n",
      "iteration 1 / 300: loss 0.761065\n",
      "iteration 1 / 300: loss 0.779103\n",
      "iteration 1 / 300: loss 0.778630\n",
      "iteration 1 / 300: loss 0.789731\n",
      "iteration 1 / 300: loss 0.767380\n",
      "iteration 1 / 300: loss 0.790022\n",
      "iteration 1 / 300: loss 0.801779\n",
      "iteration 1 / 300: loss 0.794118\n",
      "iteration 1 / 300: loss 0.794356\n",
      "iteration 1 / 300: loss 0.768582\n",
      "iteration 1 / 300: loss 0.776562\n",
      "iteration 1 / 300: loss 0.774443\n",
      "iteration 1 / 300: loss 0.773106\n",
      "iteration 1 / 300: loss 0.777168\n",
      "iteration 1 / 300: loss 0.775724\n",
      "iteration 1 / 300: loss 0.776434\n",
      "iteration 1 / 300: loss 0.774385\n",
      "iteration 1 / 300: loss 0.797286\n",
      "iteration 1 / 300: loss 0.793481\n",
      "iteration 1 / 300: loss 0.795834\n",
      "iteration 1 / 300: loss 0.772318\n",
      "iteration 1 / 300: loss 0.767414\n",
      "iteration 1 / 300: loss 0.777714\n",
      "iteration 1 / 300: loss 0.772196\n",
      "iteration 1 / 300: loss 0.772107\n",
      "iteration 1 / 300: loss 0.767705\n",
      "iteration 1 / 300: loss 0.772760\n",
      "iteration 1 / 300: loss 0.781009\n",
      "iteration 1 / 300: loss 0.784311\n",
      "iteration 1 / 300: loss 0.760192\n",
      "iteration 1 / 300: loss 0.772429\n",
      "iteration 1 / 300: loss 0.788659\n",
      "iteration 1 / 300: loss 0.778527\n",
      "iteration 1 / 300: loss 0.776162\n",
      "iteration 1 / 300: loss 0.794579\n",
      "iteration 1 / 300: loss 0.759482\n",
      "iteration 1 / 300: loss 0.760814\n",
      "iteration 1 / 300: loss 0.792383\n",
      "iteration 1 / 300: loss 0.773005\n",
      "iteration 1 / 300: loss 0.771907\n",
      "iteration 1 / 300: loss 0.793181\n",
      "iteration 1 / 300: loss 0.783605\n",
      "iteration 1 / 300: loss 0.780613\n",
      "iteration 1 / 300: loss 0.766487\n",
      "iteration 1 / 300: loss 0.778413\n",
      "iteration 1 / 300: loss 0.777648\n",
      "iteration 1 / 300: loss 0.772933\n",
      "iteration 1 / 300: loss 0.768267\n",
      "iteration 1 / 300: loss 0.788574\n",
      "iteration 1 / 300: loss 0.767095\n",
      "iteration 1 / 300: loss 0.759900\n",
      "iteration 1 / 300: loss 0.766248\n",
      "iteration 2 / 300: loss 0.761768\n",
      "iteration 2 / 300: loss 0.774009\n",
      "iteration 2 / 300: loss 0.751659\n",
      "iteration 2 / 300: loss 0.761824\n",
      "iteration 2 / 300: loss 0.769360\n",
      "iteration 2 / 300: loss 0.772553\n",
      "iteration 2 / 300: loss 0.782145\n",
      "iteration 2 / 300: loss 0.766017\n",
      "iteration 2 / 300: loss 0.792725\n",
      "iteration 2 / 300: loss 0.768147\n",
      "iteration 2 / 300: loss 0.785578\n",
      "iteration 2 / 300: loss 0.759564\n",
      "iteration 2 / 300: loss 0.763627\n",
      "iteration 2 / 300: loss 0.760786\n",
      "iteration 2 / 300: loss 0.752220\n",
      "iteration 2 / 300: loss 0.774983\n",
      "iteration 2 / 300: loss 0.764920\n",
      "iteration 2 / 300: loss 0.768013\n",
      "iteration 2 / 300: loss 0.783523\n",
      "iteration 2 / 300: loss 0.761805\n",
      "iteration 2 / 300: loss 0.774353\n",
      "iteration 2 / 300: loss 0.761596\n",
      "iteration 2 / 300: loss 0.774855\n",
      "iteration 2 / 300: loss 0.772734\n",
      "iteration 2 / 300: loss 0.771343\n",
      "iteration 2 / 300: loss 0.769184\n",
      "iteration 2 / 300: loss 0.777007\n",
      "iteration 2 / 300: loss 0.756994\n",
      "iteration 2 / 300: loss 0.777121\n",
      "iteration 2 / 300: loss 0.763773\n",
      "iteration 2 / 300: loss 0.777093\n",
      "iteration 2 / 300: loss 0.783295\n",
      "iteration 2 / 300: loss 0.759380\n",
      "iteration 2 / 300: loss 0.761358\n",
      "iteration 2 / 300: loss 0.767684\n",
      "iteration 2 / 300: loss 0.765599\n",
      "iteration 2 / 300: loss 0.759914\n",
      "iteration 2 / 300: loss 0.769204\n",
      "iteration 2 / 300: loss 0.764514\n",
      "iteration 2 / 300: loss 0.772088\n",
      "iteration 2 / 300: loss 0.778806\n",
      "iteration 2 / 300: loss 0.759348\n",
      "iteration 2 / 300: loss 0.759786\n",
      "iteration 2 / 300: loss 0.755461\n",
      "iteration 2 / 300: loss 0.765723\n",
      "iteration 2 / 300: loss 0.755595\n",
      "iteration 2 / 300: loss 0.742368\n",
      "iteration 2 / 300: loss 0.752149\n",
      "iteration 2 / 300: loss 0.737879\n",
      "iteration 2 / 300: loss 0.755217\n",
      "iteration 2 / 300: loss 0.758082\n",
      "iteration 2 / 300: loss 0.761102\n",
      "iteration 2 / 300: loss 0.738455\n",
      "iteration 2 / 300: loss 0.764571\n",
      "iteration 2 / 300: loss 0.778682\n",
      "iteration 2 / 300: loss 0.768872\n",
      "iteration 2 / 300: loss 0.774408\n",
      "iteration 2 / 300: loss 0.753030\n",
      "iteration 2 / 300: loss 0.762851\n",
      "iteration 2 / 300: loss 0.759015\n",
      "iteration 2 / 300: loss 0.757406\n",
      "iteration 2 / 300: loss 0.758802\n",
      "iteration 2 / 300: loss 0.757452\n",
      "iteration 2 / 300: loss 0.756506\n",
      "iteration 2 / 300: loss 0.757006\n",
      "iteration 2 / 300: loss 0.777540\n",
      "iteration 2 / 300: loss 0.771027\n",
      "iteration 2 / 300: loss 0.783545\n",
      "iteration 2 / 300: loss 0.758087\n",
      "iteration 2 / 300: loss 0.754789\n",
      "iteration 2 / 300: loss 0.764578\n",
      "iteration 2 / 300: loss 0.756617\n",
      "iteration 2 / 300: loss 0.758070\n",
      "iteration 2 / 300: loss 0.751295\n",
      "iteration 2 / 300: loss 0.756131\n",
      "iteration 2 / 300: loss 0.760831\n",
      "iteration 2 / 300: loss 0.764463\n",
      "iteration 2 / 300: loss 0.743419\n",
      "iteration 2 / 300: loss 0.757862\n",
      "iteration 2 / 300: loss 0.774973\n",
      "iteration 2 / 300: loss 0.760461\n",
      "iteration 2 / 300: loss 0.763080\n",
      "iteration 2 / 300: loss 0.783690\n",
      "iteration 2 / 300: loss 0.749770\n",
      "iteration 2 / 300: loss 0.752683\n",
      "iteration 2 / 300: loss 0.781289\n",
      "iteration 2 / 300: loss 0.761154\n",
      "iteration 2 / 300: loss 0.762392\n",
      "iteration 2 / 300: loss 0.774862\n",
      "iteration 2 / 300: loss 0.773004\n",
      "iteration 2 / 300: loss 0.759878\n",
      "iteration 2 / 300: loss 0.754040\n",
      "iteration 2 / 300: loss 0.763851\n",
      "iteration 2 / 300: loss 0.763709\n",
      "iteration 2 / 300: loss 0.761665\n",
      "iteration 2 / 300: loss 0.754964\n",
      "iteration 2 / 300: loss 0.770500\n",
      "iteration 2 / 300: loss 0.751520\n",
      "iteration 2 / 300: loss 0.741365\n",
      "iteration 2 / 300: loss 0.753687\n",
      "iteration 3 / 300: loss 0.742021\n",
      "iteration 3 / 300: loss 0.758206\n",
      "iteration 3 / 300: loss 0.732824\n",
      "iteration 3 / 300: loss 0.748716\n",
      "iteration 3 / 300: loss 0.750254\n",
      "iteration 3 / 300: loss 0.754079\n",
      "iteration 3 / 300: loss 0.767059\n",
      "iteration 3 / 300: loss 0.750531\n",
      "iteration 3 / 300: loss 0.779233\n",
      "iteration 3 / 300: loss 0.756137\n",
      "iteration 3 / 300: loss 0.768143\n",
      "iteration 3 / 300: loss 0.744391\n",
      "iteration 3 / 300: loss 0.748007\n",
      "iteration 3 / 300: loss 0.742206\n",
      "iteration 3 / 300: loss 0.737293\n",
      "iteration 3 / 300: loss 0.761649\n",
      "iteration 3 / 300: loss 0.749679\n",
      "iteration 3 / 300: loss 0.752098\n",
      "iteration 3 / 300: loss 0.772154\n",
      "iteration 3 / 300: loss 0.746579\n",
      "iteration 3 / 300: loss 0.757204\n",
      "iteration 3 / 300: loss 0.745080\n",
      "iteration 3 / 300: loss 0.765413\n",
      "iteration 3 / 300: loss 0.754304\n",
      "iteration 3 / 300: loss 0.761424\n",
      "iteration 3 / 300: loss 0.756127\n",
      "iteration 3 / 300: loss 0.763489\n",
      "iteration 3 / 300: loss 0.742519\n",
      "iteration 3 / 300: loss 0.765420\n",
      "iteration 3 / 300: loss 0.751165\n",
      "iteration 3 / 300: loss 0.757239\n",
      "iteration 3 / 300: loss 0.769555\n",
      "iteration 3 / 300: loss 0.739053\n",
      "iteration 3 / 300: loss 0.745598\n",
      "iteration 3 / 300: loss 0.759364\n",
      "iteration 3 / 300: loss 0.752749\n",
      "iteration 3 / 300: loss 0.747906\n",
      "iteration 3 / 300: loss 0.756092\n",
      "iteration 3 / 300: loss 0.752311\n",
      "iteration 3 / 300: loss 0.759506\n",
      "iteration 3 / 300: loss 0.769861\n",
      "iteration 3 / 300: loss 0.750043\n",
      "iteration 3 / 300: loss 0.751465\n",
      "iteration 3 / 300: loss 0.743051\n",
      "iteration 3 / 300: loss 0.752007\n",
      "iteration 3 / 300: loss 0.738640\n",
      "iteration 3 / 300: loss 0.732422\n",
      "iteration 3 / 300: loss 0.741089\n",
      "iteration 3 / 300: loss 0.723149\n",
      "iteration 3 / 300: loss 0.735161\n",
      "iteration 3 / 300: loss 0.742315\n",
      "iteration 3 / 300: loss 0.743390\n",
      "iteration 3 / 300: loss 0.725017\n",
      "iteration 3 / 300: loss 0.747013\n",
      "iteration 3 / 300: loss 0.765277\n",
      "iteration 3 / 300: loss 0.756552\n",
      "iteration 3 / 300: loss 0.762069\n",
      "iteration 3 / 300: loss 0.739227\n",
      "iteration 3 / 300: loss 0.749358\n",
      "iteration 3 / 300: loss 0.749648\n",
      "iteration 3 / 300: loss 0.743350\n",
      "iteration 3 / 300: loss 0.749862\n",
      "iteration 3 / 300: loss 0.747009\n",
      "iteration 3 / 300: loss 0.748222\n",
      "iteration 3 / 300: loss 0.744054\n",
      "iteration 3 / 300: loss 0.771192\n",
      "iteration 3 / 300: loss 0.758966\n",
      "iteration 3 / 300: loss 0.771413\n",
      "iteration 3 / 300: loss 0.746758\n",
      "iteration 3 / 300: loss 0.739360\n",
      "iteration 3 / 300: loss 0.753020\n",
      "iteration 3 / 300: loss 0.741066\n",
      "iteration 3 / 300: loss 0.747589\n",
      "iteration 3 / 300: loss 0.740630\n",
      "iteration 3 / 300: loss 0.746232\n",
      "iteration 3 / 300: loss 0.753380\n",
      "iteration 3 / 300: loss 0.753993\n",
      "iteration 3 / 300: loss 0.731330\n",
      "iteration 3 / 300: loss 0.747508\n",
      "iteration 3 / 300: loss 0.760234\n",
      "iteration 3 / 300: loss 0.747529\n",
      "iteration 3 / 300: loss 0.750245\n",
      "iteration 3 / 300: loss 0.768602\n",
      "iteration 3 / 300: loss 0.728963\n",
      "iteration 3 / 300: loss 0.732818\n",
      "iteration 3 / 300: loss 0.768357\n",
      "iteration 3 / 300: loss 0.751911\n",
      "iteration 3 / 300: loss 0.748982\n",
      "iteration 3 / 300: loss 0.762958\n",
      "iteration 3 / 300: loss 0.757837\n",
      "iteration 3 / 300: loss 0.743703\n",
      "iteration 3 / 300: loss 0.739208\n",
      "iteration 3 / 300: loss 0.750905\n",
      "iteration 3 / 300: loss 0.750353\n",
      "iteration 3 / 300: loss 0.746623\n",
      "iteration 3 / 300: loss 0.738222\n",
      "iteration 3 / 300: loss 0.758926\n",
      "iteration 3 / 300: loss 0.739056\n",
      "iteration 3 / 300: loss 0.729510\n",
      "iteration 3 / 300: loss 0.741724\n",
      "iteration 4 / 300: loss 0.728648\n",
      "iteration 4 / 300: loss 0.744597\n",
      "iteration 4 / 300: loss 0.718863\n",
      "iteration 4 / 300: loss 0.738888\n",
      "iteration 4 / 300: loss 0.741996\n",
      "iteration 4 / 300: loss 0.742871\n",
      "iteration 4 / 300: loss 0.752652\n",
      "iteration 4 / 300: loss 0.733283\n",
      "iteration 4 / 300: loss 0.761498\n",
      "iteration 4 / 300: loss 0.739922\n",
      "iteration 4 / 300: loss 0.764113\n",
      "iteration 4 / 300: loss 0.744399\n",
      "iteration 4 / 300: loss 0.744741\n",
      "iteration 4 / 300: loss 0.733156\n",
      "iteration 4 / 300: loss 0.726778\n",
      "iteration 4 / 300: loss 0.747289\n",
      "iteration 4 / 300: loss 0.742404\n",
      "iteration 4 / 300: loss 0.737699\n",
      "iteration 4 / 300: loss 0.756678\n",
      "iteration 4 / 300: loss 0.732188\n",
      "iteration 4 / 300: loss 0.740485\n",
      "iteration 4 / 300: loss 0.734065\n",
      "iteration 4 / 300: loss 0.753982\n",
      "iteration 4 / 300: loss 0.746468\n",
      "iteration 4 / 300: loss 0.746637\n",
      "iteration 4 / 300: loss 0.747693\n",
      "iteration 4 / 300: loss 0.752623\n",
      "iteration 4 / 300: loss 0.730371\n",
      "iteration 4 / 300: loss 0.756816\n",
      "iteration 4 / 300: loss 0.740948\n",
      "iteration 4 / 300: loss 0.744957\n",
      "iteration 4 / 300: loss 0.763592\n",
      "iteration 4 / 300: loss 0.727323\n",
      "iteration 4 / 300: loss 0.735108\n",
      "iteration 4 / 300: loss 0.746202\n",
      "iteration 4 / 300: loss 0.743998\n",
      "iteration 4 / 300: loss 0.738301\n",
      "iteration 4 / 300: loss 0.744526\n",
      "iteration 4 / 300: loss 0.738993\n",
      "iteration 4 / 300: loss 0.745241\n",
      "iteration 4 / 300: loss 0.760270\n",
      "iteration 4 / 300: loss 0.730594\n",
      "iteration 4 / 300: loss 0.737746\n",
      "iteration 4 / 300: loss 0.727063\n",
      "iteration 4 / 300: loss 0.740551\n",
      "iteration 4 / 300: loss 0.725220\n",
      "iteration 4 / 300: loss 0.714674\n",
      "iteration 4 / 300: loss 0.729030\n",
      "iteration 4 / 300: loss 0.707518\n",
      "iteration 4 / 300: loss 0.729987\n",
      "iteration 4 / 300: loss 0.731256\n",
      "iteration 4 / 300: loss 0.732658\n",
      "iteration 4 / 300: loss 0.712369\n",
      "iteration 4 / 300: loss 0.734473\n",
      "iteration 4 / 300: loss 0.756367\n",
      "iteration 4 / 300: loss 0.747444\n",
      "iteration 4 / 300: loss 0.751573\n",
      "iteration 4 / 300: loss 0.727018\n",
      "iteration 4 / 300: loss 0.735511\n",
      "iteration 4 / 300: loss 0.737620\n",
      "iteration 4 / 300: loss 0.732500\n",
      "iteration 4 / 300: loss 0.735527\n",
      "iteration 4 / 300: loss 0.728521\n",
      "iteration 4 / 300: loss 0.733461\n",
      "iteration 4 / 300: loss 0.732625\n",
      "iteration 4 / 300: loss 0.753564\n",
      "iteration 4 / 300: loss 0.745788\n",
      "iteration 4 / 300: loss 0.757553\n",
      "iteration 4 / 300: loss 0.733636\n",
      "iteration 4 / 300: loss 0.725336\n",
      "iteration 4 / 300: loss 0.743552\n",
      "iteration 4 / 300: loss 0.736404\n",
      "iteration 4 / 300: loss 0.736638\n",
      "iteration 4 / 300: loss 0.729410\n",
      "iteration 4 / 300: loss 0.733641\n",
      "iteration 4 / 300: loss 0.739617\n",
      "iteration 4 / 300: loss 0.745176\n",
      "iteration 4 / 300: loss 0.718556\n",
      "iteration 4 / 300: loss 0.734514\n",
      "iteration 4 / 300: loss 0.748740\n",
      "iteration 4 / 300: loss 0.737193\n",
      "iteration 4 / 300: loss 0.739126\n",
      "iteration 4 / 300: loss 0.758123\n",
      "iteration 4 / 300: loss 0.716531\n",
      "iteration 4 / 300: loss 0.719535\n",
      "iteration 4 / 300: loss 0.760372\n",
      "iteration 4 / 300: loss 0.743750\n",
      "iteration 4 / 300: loss 0.735806\n",
      "iteration 4 / 300: loss 0.746360\n",
      "iteration 4 / 300: loss 0.746206\n",
      "iteration 4 / 300: loss 0.731962\n",
      "iteration 4 / 300: loss 0.727617\n",
      "iteration 4 / 300: loss 0.738819\n",
      "iteration 4 / 300: loss 0.741166\n",
      "iteration 4 / 300: loss 0.735968\n",
      "iteration 4 / 300: loss 0.726714\n",
      "iteration 4 / 300: loss 0.750642\n",
      "iteration 4 / 300: loss 0.733715\n",
      "iteration 4 / 300: loss 0.720266\n",
      "iteration 4 / 300: loss 0.731571\n",
      "iteration 5 / 300: loss 0.722882\n",
      "iteration 5 / 300: loss 0.737137\n",
      "iteration 5 / 300: loss 0.708946\n",
      "iteration 5 / 300: loss 0.727752\n",
      "iteration 5 / 300: loss 0.730908\n",
      "iteration 5 / 300: loss 0.734107\n",
      "iteration 5 / 300: loss 0.742050\n",
      "iteration 5 / 300: loss 0.725337\n",
      "iteration 5 / 300: loss 0.757579\n",
      "iteration 5 / 300: loss 0.730953\n",
      "iteration 5 / 300: loss 0.746704\n",
      "iteration 5 / 300: loss 0.724010\n",
      "iteration 5 / 300: loss 0.727702\n",
      "iteration 5 / 300: loss 0.715411\n",
      "iteration 5 / 300: loss 0.712998\n",
      "iteration 5 / 300: loss 0.732027\n",
      "iteration 5 / 300: loss 0.727930\n",
      "iteration 5 / 300: loss 0.726982\n",
      "iteration 5 / 300: loss 0.745206\n",
      "iteration 5 / 300: loss 0.718615\n",
      "iteration 5 / 300: loss 0.728079\n",
      "iteration 5 / 300: loss 0.720426\n",
      "iteration 5 / 300: loss 0.736954\n",
      "iteration 5 / 300: loss 0.732553\n",
      "iteration 5 / 300: loss 0.735973\n",
      "iteration 5 / 300: loss 0.738756\n",
      "iteration 5 / 300: loss 0.738881\n",
      "iteration 5 / 300: loss 0.720386\n",
      "iteration 5 / 300: loss 0.747889\n",
      "iteration 5 / 300: loss 0.731778\n",
      "iteration 5 / 300: loss 0.731892\n",
      "iteration 5 / 300: loss 0.754540\n",
      "iteration 5 / 300: loss 0.717846\n",
      "iteration 5 / 300: loss 0.723922\n",
      "iteration 5 / 300: loss 0.733167\n",
      "iteration 5 / 300: loss 0.734392\n",
      "iteration 5 / 300: loss 0.727330\n",
      "iteration 5 / 300: loss 0.730649\n",
      "iteration 5 / 300: loss 0.729144\n",
      "iteration 5 / 300: loss 0.736501\n",
      "iteration 5 / 300: loss 0.744658\n",
      "iteration 5 / 300: loss 0.715370\n",
      "iteration 5 / 300: loss 0.722486\n",
      "iteration 5 / 300: loss 0.712136\n",
      "iteration 5 / 300: loss 0.729485\n",
      "iteration 5 / 300: loss 0.714800\n",
      "iteration 5 / 300: loss 0.704735\n",
      "iteration 5 / 300: loss 0.716483\n",
      "iteration 5 / 300: loss 0.700981\n",
      "iteration 5 / 300: loss 0.721172\n",
      "iteration 5 / 300: loss 0.718645\n",
      "iteration 5 / 300: loss 0.720858\n",
      "iteration 5 / 300: loss 0.699678\n",
      "iteration 5 / 300: loss 0.724458\n",
      "iteration 5 / 300: loss 0.748461\n",
      "iteration 5 / 300: loss 0.737416\n",
      "iteration 5 / 300: loss 0.743934\n",
      "iteration 5 / 300: loss 0.717873\n",
      "iteration 5 / 300: loss 0.727648\n",
      "iteration 5 / 300: loss 0.727046\n",
      "iteration 5 / 300: loss 0.719991\n",
      "iteration 5 / 300: loss 0.727944\n",
      "iteration 5 / 300: loss 0.721599\n",
      "iteration 5 / 300: loss 0.720766\n",
      "iteration 5 / 300: loss 0.725070\n",
      "iteration 5 / 300: loss 0.745633\n",
      "iteration 5 / 300: loss 0.734713\n",
      "iteration 5 / 300: loss 0.749566\n",
      "iteration 5 / 300: loss 0.727801\n",
      "iteration 5 / 300: loss 0.717122\n",
      "iteration 5 / 300: loss 0.734121\n",
      "iteration 5 / 300: loss 0.724462\n",
      "iteration 5 / 300: loss 0.724937\n",
      "iteration 5 / 300: loss 0.717404\n",
      "iteration 5 / 300: loss 0.722653\n",
      "iteration 5 / 300: loss 0.730620\n",
      "iteration 5 / 300: loss 0.733090\n",
      "iteration 5 / 300: loss 0.711710\n",
      "iteration 5 / 300: loss 0.724699\n",
      "iteration 5 / 300: loss 0.738028\n",
      "iteration 5 / 300: loss 0.727253\n",
      "iteration 5 / 300: loss 0.727141\n",
      "iteration 5 / 300: loss 0.750774\n",
      "iteration 5 / 300: loss 0.708179\n",
      "iteration 5 / 300: loss 0.713049\n",
      "iteration 5 / 300: loss 0.752291\n",
      "iteration 5 / 300: loss 0.733290\n",
      "iteration 5 / 300: loss 0.728241\n",
      "iteration 5 / 300: loss 0.733607\n",
      "iteration 5 / 300: loss 0.733957\n",
      "iteration 5 / 300: loss 0.721474\n",
      "iteration 5 / 300: loss 0.713580\n",
      "iteration 5 / 300: loss 0.730682\n",
      "iteration 5 / 300: loss 0.733151\n",
      "iteration 5 / 300: loss 0.724075\n",
      "iteration 5 / 300: loss 0.713056\n",
      "iteration 5 / 300: loss 0.735825\n",
      "iteration 5 / 300: loss 0.720772\n",
      "iteration 5 / 300: loss 0.707281\n",
      "iteration 5 / 300: loss 0.723343\n",
      "iteration 6 / 300: loss 0.707606\n",
      "iteration 6 / 300: loss 0.720640\n",
      "iteration 6 / 300: loss 0.699731\n",
      "iteration 6 / 300: loss 0.716935\n",
      "iteration 6 / 300: loss 0.721373\n",
      "iteration 6 / 300: loss 0.719559\n",
      "iteration 6 / 300: loss 0.731717\n",
      "iteration 6 / 300: loss 0.721800\n",
      "iteration 6 / 300: loss 0.749937\n",
      "iteration 6 / 300: loss 0.721155\n",
      "iteration 6 / 300: loss 0.741415\n",
      "iteration 6 / 300: loss 0.716864\n",
      "iteration 6 / 300: loss 0.719037\n",
      "iteration 6 / 300: loss 0.705931\n",
      "iteration 6 / 300: loss 0.704759\n",
      "iteration 6 / 300: loss 0.724033\n",
      "iteration 6 / 300: loss 0.719064\n",
      "iteration 6 / 300: loss 0.715827\n",
      "iteration 6 / 300: loss 0.737381\n",
      "iteration 6 / 300: loss 0.706933\n",
      "iteration 6 / 300: loss 0.714509\n",
      "iteration 6 / 300: loss 0.714610\n",
      "iteration 6 / 300: loss 0.725886\n",
      "iteration 6 / 300: loss 0.725654\n",
      "iteration 6 / 300: loss 0.728850\n",
      "iteration 6 / 300: loss 0.726894\n",
      "iteration 6 / 300: loss 0.731496\n",
      "iteration 6 / 300: loss 0.710897\n",
      "iteration 6 / 300: loss 0.740368\n",
      "iteration 6 / 300: loss 0.721774\n",
      "iteration 6 / 300: loss 0.722216\n",
      "iteration 6 / 300: loss 0.742774\n",
      "iteration 6 / 300: loss 0.708549\n",
      "iteration 6 / 300: loss 0.713085\n",
      "iteration 6 / 300: loss 0.721224\n",
      "iteration 6 / 300: loss 0.727247\n",
      "iteration 6 / 300: loss 0.722061\n",
      "iteration 6 / 300: loss 0.723002\n",
      "iteration 6 / 300: loss 0.722100\n",
      "iteration 6 / 300: loss 0.728953\n",
      "iteration 6 / 300: loss 0.740780\n",
      "iteration 6 / 300: loss 0.709356\n",
      "iteration 6 / 300: loss 0.718578\n",
      "iteration 6 / 300: loss 0.704345\n",
      "iteration 6 / 300: loss 0.721105\n",
      "iteration 6 / 300: loss 0.702561\n",
      "iteration 6 / 300: loss 0.699133\n",
      "iteration 6 / 300: loss 0.706299\n",
      "iteration 6 / 300: loss 0.691912\n",
      "iteration 6 / 300: loss 0.709376\n",
      "iteration 6 / 300: loss 0.706731\n",
      "iteration 6 / 300: loss 0.706467\n",
      "iteration 6 / 300: loss 0.688811\n",
      "iteration 6 / 300: loss 0.714621\n",
      "iteration 6 / 300: loss 0.736659\n",
      "iteration 6 / 300: loss 0.725406\n",
      "iteration 6 / 300: loss 0.735975\n",
      "iteration 6 / 300: loss 0.711620\n",
      "iteration 6 / 300: loss 0.719183\n",
      "iteration 6 / 300: loss 0.718444\n",
      "iteration 6 / 300: loss 0.713390\n",
      "iteration 6 / 300: loss 0.716094\n",
      "iteration 6 / 300: loss 0.710012\n",
      "iteration 6 / 300: loss 0.714255\n",
      "iteration 6 / 300: loss 0.710577\n",
      "iteration 6 / 300: loss 0.734603\n",
      "iteration 6 / 300: loss 0.722214\n",
      "iteration 6 / 300: loss 0.738951\n",
      "iteration 6 / 300: loss 0.716312\n",
      "iteration 6 / 300: loss 0.708645\n",
      "iteration 6 / 300: loss 0.726169\n",
      "iteration 6 / 300: loss 0.716793\n",
      "iteration 6 / 300: loss 0.716184\n",
      "iteration 6 / 300: loss 0.702931\n",
      "iteration 6 / 300: loss 0.711204\n",
      "iteration 6 / 300: loss 0.722691\n",
      "iteration 6 / 300: loss 0.727848\n",
      "iteration 6 / 300: loss 0.702868\n",
      "iteration 6 / 300: loss 0.712794\n",
      "iteration 6 / 300: loss 0.726950\n",
      "iteration 6 / 300: loss 0.715739\n",
      "iteration 6 / 300: loss 0.719712\n",
      "iteration 6 / 300: loss 0.738184\n",
      "iteration 6 / 300: loss 0.696627\n",
      "iteration 6 / 300: loss 0.700192\n",
      "iteration 6 / 300: loss 0.741956\n",
      "iteration 6 / 300: loss 0.720635\n",
      "iteration 6 / 300: loss 0.719217\n",
      "iteration 6 / 300: loss 0.725223\n",
      "iteration 6 / 300: loss 0.724415\n",
      "iteration 6 / 300: loss 0.709823\n",
      "iteration 6 / 300: loss 0.701512\n",
      "iteration 6 / 300: loss 0.720712\n",
      "iteration 6 / 300: loss 0.722009\n",
      "iteration 6 / 300: loss 0.716577\n",
      "iteration 6 / 300: loss 0.705774\n",
      "iteration 6 / 300: loss 0.726405\n",
      "iteration 6 / 300: loss 0.712229\n",
      "iteration 6 / 300: loss 0.696244\n",
      "iteration 6 / 300: loss 0.713233\n",
      "iteration 7 / 300: loss 0.698346\n",
      "iteration 7 / 300: loss 0.710734\n",
      "iteration 7 / 300: loss 0.685365\n",
      "iteration 7 / 300: loss 0.706053\n",
      "iteration 7 / 300: loss 0.712546\n",
      "iteration 7 / 300: loss 0.711304\n",
      "iteration 7 / 300: loss 0.722206\n",
      "iteration 7 / 300: loss 0.706566\n",
      "iteration 7 / 300: loss 0.735636\n",
      "iteration 7 / 300: loss 0.710537\n",
      "iteration 7 / 300: loss 0.734883\n",
      "iteration 7 / 300: loss 0.708670\n",
      "iteration 7 / 300: loss 0.709786\n",
      "iteration 7 / 300: loss 0.695115\n",
      "iteration 7 / 300: loss 0.695424\n",
      "iteration 7 / 300: loss 0.716441\n",
      "iteration 7 / 300: loss 0.707873\n",
      "iteration 7 / 300: loss 0.703502\n",
      "iteration 7 / 300: loss 0.729430\n",
      "iteration 7 / 300: loss 0.696635\n",
      "iteration 7 / 300: loss 0.704667\n",
      "iteration 7 / 300: loss 0.698009\n",
      "iteration 7 / 300: loss 0.719842\n",
      "iteration 7 / 300: loss 0.716252\n",
      "iteration 7 / 300: loss 0.719868\n",
      "iteration 7 / 300: loss 0.720279\n",
      "iteration 7 / 300: loss 0.721021\n",
      "iteration 7 / 300: loss 0.703611\n",
      "iteration 7 / 300: loss 0.733310\n",
      "iteration 7 / 300: loss 0.712646\n",
      "iteration 7 / 300: loss 0.714889\n",
      "iteration 7 / 300: loss 0.737329\n",
      "iteration 7 / 300: loss 0.699041\n",
      "iteration 7 / 300: loss 0.707425\n",
      "iteration 7 / 300: loss 0.715980\n",
      "iteration 7 / 300: loss 0.713338\n",
      "iteration 7 / 300: loss 0.707853\n",
      "iteration 7 / 300: loss 0.709897\n",
      "iteration 7 / 300: loss 0.710111\n",
      "iteration 7 / 300: loss 0.719090\n",
      "iteration 7 / 300: loss 0.731353\n",
      "iteration 7 / 300: loss 0.697090\n",
      "iteration 7 / 300: loss 0.702366\n",
      "iteration 7 / 300: loss 0.694209\n",
      "iteration 7 / 300: loss 0.711496\n",
      "iteration 7 / 300: loss 0.695706\n",
      "iteration 7 / 300: loss 0.687322\n",
      "iteration 7 / 300: loss 0.699362\n",
      "iteration 7 / 300: loss 0.684902\n",
      "iteration 7 / 300: loss 0.702087\n",
      "iteration 7 / 300: loss 0.698110\n",
      "iteration 7 / 300: loss 0.700669\n",
      "iteration 7 / 300: loss 0.681457\n",
      "iteration 7 / 300: loss 0.707607\n",
      "iteration 7 / 300: loss 0.725690\n",
      "iteration 7 / 300: loss 0.718352\n",
      "iteration 7 / 300: loss 0.725509\n",
      "iteration 7 / 300: loss 0.700284\n",
      "iteration 7 / 300: loss 0.710099\n",
      "iteration 7 / 300: loss 0.709521\n",
      "iteration 7 / 300: loss 0.702122\n",
      "iteration 7 / 300: loss 0.704864\n",
      "iteration 7 / 300: loss 0.703027\n",
      "iteration 7 / 300: loss 0.705223\n",
      "iteration 7 / 300: loss 0.700152\n",
      "iteration 7 / 300: loss 0.727585\n",
      "iteration 7 / 300: loss 0.712148\n",
      "iteration 7 / 300: loss 0.726682\n",
      "iteration 7 / 300: loss 0.703369\n",
      "iteration 7 / 300: loss 0.700328\n",
      "iteration 7 / 300: loss 0.715303\n",
      "iteration 7 / 300: loss 0.708007\n",
      "iteration 7 / 300: loss 0.707058\n",
      "iteration 7 / 300: loss 0.694458\n",
      "iteration 7 / 300: loss 0.704324\n",
      "iteration 7 / 300: loss 0.714587\n",
      "iteration 7 / 300: loss 0.720019\n",
      "iteration 7 / 300: loss 0.694437\n",
      "iteration 7 / 300: loss 0.705713\n",
      "iteration 7 / 300: loss 0.719224\n",
      "iteration 7 / 300: loss 0.708114\n",
      "iteration 7 / 300: loss 0.707737\n",
      "iteration 7 / 300: loss 0.729524\n",
      "iteration 7 / 300: loss 0.684671\n",
      "iteration 7 / 300: loss 0.690038\n",
      "iteration 7 / 300: loss 0.732794\n",
      "iteration 7 / 300: loss 0.714717\n",
      "iteration 7 / 300: loss 0.710635\n",
      "iteration 7 / 300: loss 0.712739\n",
      "iteration 7 / 300: loss 0.718256\n",
      "iteration 7 / 300: loss 0.705642\n",
      "iteration 7 / 300: loss 0.694786\n",
      "iteration 7 / 300: loss 0.711049\n",
      "iteration 7 / 300: loss 0.714377\n",
      "iteration 7 / 300: loss 0.708451\n",
      "iteration 7 / 300: loss 0.694469\n",
      "iteration 7 / 300: loss 0.716011\n",
      "iteration 7 / 300: loss 0.704062\n",
      "iteration 7 / 300: loss 0.687442\n",
      "iteration 7 / 300: loss 0.703594\n",
      "iteration 8 / 300: loss 0.686370\n",
      "iteration 8 / 300: loss 0.699589\n",
      "iteration 8 / 300: loss 0.674452\n",
      "iteration 8 / 300: loss 0.696682\n",
      "iteration 8 / 300: loss 0.703358\n",
      "iteration 8 / 300: loss 0.701019\n",
      "iteration 8 / 300: loss 0.711922\n",
      "iteration 8 / 300: loss 0.695066\n",
      "iteration 8 / 300: loss 0.723028\n",
      "iteration 8 / 300: loss 0.696662\n",
      "iteration 8 / 300: loss 0.728131\n",
      "iteration 8 / 300: loss 0.711775\n",
      "iteration 8 / 300: loss 0.709251\n",
      "iteration 8 / 300: loss 0.687970\n",
      "iteration 8 / 300: loss 0.688859\n",
      "iteration 8 / 300: loss 0.709762\n",
      "iteration 8 / 300: loss 0.701189\n",
      "iteration 8 / 300: loss 0.699794\n",
      "iteration 8 / 300: loss 0.720720\n",
      "iteration 8 / 300: loss 0.688253\n",
      "iteration 8 / 300: loss 0.694932\n",
      "iteration 8 / 300: loss 0.688851\n",
      "iteration 8 / 300: loss 0.704512\n",
      "iteration 8 / 300: loss 0.705454\n",
      "iteration 8 / 300: loss 0.709670\n",
      "iteration 8 / 300: loss 0.710299\n",
      "iteration 8 / 300: loss 0.709303\n",
      "iteration 8 / 300: loss 0.694524\n",
      "iteration 8 / 300: loss 0.724711\n",
      "iteration 8 / 300: loss 0.704997\n",
      "iteration 8 / 300: loss 0.702834\n",
      "iteration 8 / 300: loss 0.723262\n",
      "iteration 8 / 300: loss 0.687673\n",
      "iteration 8 / 300: loss 0.700409\n",
      "iteration 8 / 300: loss 0.706659\n",
      "iteration 8 / 300: loss 0.705311\n",
      "iteration 8 / 300: loss 0.699016\n",
      "iteration 8 / 300: loss 0.699699\n",
      "iteration 8 / 300: loss 0.697620\n",
      "iteration 8 / 300: loss 0.712370\n",
      "iteration 8 / 300: loss 0.721827\n",
      "iteration 8 / 300: loss 0.692240\n",
      "iteration 8 / 300: loss 0.696573\n",
      "iteration 8 / 300: loss 0.683019\n",
      "iteration 8 / 300: loss 0.703090\n",
      "iteration 8 / 300: loss 0.687568\n",
      "iteration 8 / 300: loss 0.678068\n",
      "iteration 8 / 300: loss 0.688293\n",
      "iteration 8 / 300: loss 0.674745\n",
      "iteration 8 / 300: loss 0.694214\n",
      "iteration 8 / 300: loss 0.691028\n",
      "iteration 8 / 300: loss 0.693983\n",
      "iteration 8 / 300: loss 0.676330\n",
      "iteration 8 / 300: loss 0.701352\n",
      "iteration 8 / 300: loss 0.717490\n",
      "iteration 8 / 300: loss 0.713320\n",
      "iteration 8 / 300: loss 0.717646\n",
      "iteration 8 / 300: loss 0.694149\n",
      "iteration 8 / 300: loss 0.701059\n",
      "iteration 8 / 300: loss 0.699885\n",
      "iteration 8 / 300: loss 0.697765\n",
      "iteration 8 / 300: loss 0.696050\n",
      "iteration 8 / 300: loss 0.693863\n",
      "iteration 8 / 300: loss 0.693989\n",
      "iteration 8 / 300: loss 0.693338\n",
      "iteration 8 / 300: loss 0.719274\n",
      "iteration 8 / 300: loss 0.701019\n",
      "iteration 8 / 300: loss 0.718585\n",
      "iteration 8 / 300: loss 0.696671\n",
      "iteration 8 / 300: loss 0.693086\n",
      "iteration 8 / 300: loss 0.709926\n",
      "iteration 8 / 300: loss 0.699954\n",
      "iteration 8 / 300: loss 0.697101\n",
      "iteration 8 / 300: loss 0.686485\n",
      "iteration 8 / 300: loss 0.692313\n",
      "iteration 8 / 300: loss 0.706813\n",
      "iteration 8 / 300: loss 0.709607\n",
      "iteration 8 / 300: loss 0.687662\n",
      "iteration 8 / 300: loss 0.696997\n",
      "iteration 8 / 300: loss 0.706431\n",
      "iteration 8 / 300: loss 0.699430\n",
      "iteration 8 / 300: loss 0.699832\n",
      "iteration 8 / 300: loss 0.720465\n",
      "iteration 8 / 300: loss 0.678202\n",
      "iteration 8 / 300: loss 0.681330\n",
      "iteration 8 / 300: loss 0.726131\n",
      "iteration 8 / 300: loss 0.707454\n",
      "iteration 8 / 300: loss 0.698453\n",
      "iteration 8 / 300: loss 0.707440\n",
      "iteration 8 / 300: loss 0.709871\n",
      "iteration 8 / 300: loss 0.694113\n",
      "iteration 8 / 300: loss 0.684920\n",
      "iteration 8 / 300: loss 0.705843\n",
      "iteration 8 / 300: loss 0.704668\n",
      "iteration 8 / 300: loss 0.695385\n",
      "iteration 8 / 300: loss 0.688303\n",
      "iteration 8 / 300: loss 0.706846\n",
      "iteration 8 / 300: loss 0.695624\n",
      "iteration 8 / 300: loss 0.683225\n",
      "iteration 8 / 300: loss 0.699418\n",
      "iteration 9 / 300: loss 0.682539\n",
      "iteration 9 / 300: loss 0.694539\n",
      "iteration 9 / 300: loss 0.669264\n",
      "iteration 9 / 300: loss 0.687811\n",
      "iteration 9 / 300: loss 0.693170\n",
      "iteration 9 / 300: loss 0.693626\n",
      "iteration 9 / 300: loss 0.708135\n",
      "iteration 9 / 300: loss 0.688122\n",
      "iteration 9 / 300: loss 0.718895\n",
      "iteration 9 / 300: loss 0.690319\n",
      "iteration 9 / 300: loss 0.715934\n",
      "iteration 9 / 300: loss 0.691729\n",
      "iteration 9 / 300: loss 0.694473\n",
      "iteration 9 / 300: loss 0.677202\n",
      "iteration 9 / 300: loss 0.680854\n",
      "iteration 9 / 300: loss 0.698915\n",
      "iteration 9 / 300: loss 0.690799\n",
      "iteration 9 / 300: loss 0.686080\n",
      "iteration 9 / 300: loss 0.710152\n",
      "iteration 9 / 300: loss 0.677111\n",
      "iteration 9 / 300: loss 0.686383\n",
      "iteration 9 / 300: loss 0.683810\n",
      "iteration 9 / 300: loss 0.698408\n",
      "iteration 9 / 300: loss 0.700235\n",
      "iteration 9 / 300: loss 0.702022\n",
      "iteration 9 / 300: loss 0.701577\n",
      "iteration 9 / 300: loss 0.702035\n",
      "iteration 9 / 300: loss 0.684313\n",
      "iteration 9 / 300: loss 0.713796\n",
      "iteration 9 / 300: loss 0.691833\n",
      "iteration 9 / 300: loss 0.692810\n",
      "iteration 9 / 300: loss 0.716416\n",
      "iteration 9 / 300: loss 0.680582\n",
      "iteration 9 / 300: loss 0.691659\n",
      "iteration 9 / 300: loss 0.697900\n",
      "iteration 9 / 300: loss 0.696863\n",
      "iteration 9 / 300: loss 0.692128\n",
      "iteration 9 / 300: loss 0.690093\n",
      "iteration 9 / 300: loss 0.691269\n",
      "iteration 9 / 300: loss 0.706885\n",
      "iteration 9 / 300: loss 0.713958\n",
      "iteration 9 / 300: loss 0.685225\n",
      "iteration 9 / 300: loss 0.686200\n",
      "iteration 9 / 300: loss 0.674590\n",
      "iteration 9 / 300: loss 0.693031\n",
      "iteration 9 / 300: loss 0.679719\n",
      "iteration 9 / 300: loss 0.669310\n",
      "iteration 9 / 300: loss 0.676824\n",
      "iteration 9 / 300: loss 0.662839\n",
      "iteration 9 / 300: loss 0.688011\n",
      "iteration 9 / 300: loss 0.681528\n",
      "iteration 9 / 300: loss 0.681888\n",
      "iteration 9 / 300: loss 0.663422\n",
      "iteration 9 / 300: loss 0.688859\n",
      "iteration 9 / 300: loss 0.709447\n",
      "iteration 9 / 300: loss 0.700953\n",
      "iteration 9 / 300: loss 0.707088\n",
      "iteration 9 / 300: loss 0.687130\n",
      "iteration 9 / 300: loss 0.694739\n",
      "iteration 9 / 300: loss 0.693457\n",
      "iteration 9 / 300: loss 0.687690\n",
      "iteration 9 / 300: loss 0.690098\n",
      "iteration 9 / 300: loss 0.686837\n",
      "iteration 9 / 300: loss 0.687649\n",
      "iteration 9 / 300: loss 0.682128\n",
      "iteration 9 / 300: loss 0.704493\n",
      "iteration 9 / 300: loss 0.691402\n",
      "iteration 9 / 300: loss 0.712722\n",
      "iteration 9 / 300: loss 0.690031\n",
      "iteration 9 / 300: loss 0.687368\n",
      "iteration 9 / 300: loss 0.698752\n",
      "iteration 9 / 300: loss 0.689236\n",
      "iteration 9 / 300: loss 0.683099\n",
      "iteration 9 / 300: loss 0.675319\n",
      "iteration 9 / 300: loss 0.684281\n",
      "iteration 9 / 300: loss 0.697322\n",
      "iteration 9 / 300: loss 0.701181\n",
      "iteration 9 / 300: loss 0.676429\n",
      "iteration 9 / 300: loss 0.688247\n",
      "iteration 9 / 300: loss 0.698939\n",
      "iteration 9 / 300: loss 0.689154\n",
      "iteration 9 / 300: loss 0.691765\n",
      "iteration 9 / 300: loss 0.711071\n",
      "iteration 9 / 300: loss 0.672195\n",
      "iteration 9 / 300: loss 0.672827\n",
      "iteration 9 / 300: loss 0.714648\n",
      "iteration 9 / 300: loss 0.695190\n",
      "iteration 9 / 300: loss 0.688101\n",
      "iteration 9 / 300: loss 0.692115\n",
      "iteration 9 / 300: loss 0.696687\n",
      "iteration 9 / 300: loss 0.687283\n",
      "iteration 9 / 300: loss 0.677445\n",
      "iteration 9 / 300: loss 0.695609\n",
      "iteration 9 / 300: loss 0.697465\n",
      "iteration 9 / 300: loss 0.686645\n",
      "iteration 9 / 300: loss 0.678602\n",
      "iteration 9 / 300: loss 0.698702\n",
      "iteration 9 / 300: loss 0.686938\n",
      "iteration 9 / 300: loss 0.673916\n",
      "iteration 9 / 300: loss 0.692089\n",
      "iteration 10 / 300: loss 0.671130\n",
      "iteration 10 / 300: loss 0.684094\n",
      "iteration 10 / 300: loss 0.662759\n",
      "iteration 10 / 300: loss 0.678386\n",
      "iteration 10 / 300: loss 0.686585\n",
      "iteration 10 / 300: loss 0.687780\n",
      "iteration 10 / 300: loss 0.700396\n",
      "iteration 10 / 300: loss 0.682513\n",
      "iteration 10 / 300: loss 0.712747\n",
      "iteration 10 / 300: loss 0.679202\n",
      "iteration 10 / 300: loss 0.710101\n",
      "iteration 10 / 300: loss 0.684898\n",
      "iteration 10 / 300: loss 0.686174\n",
      "iteration 10 / 300: loss 0.669139\n",
      "iteration 10 / 300: loss 0.675618\n",
      "iteration 10 / 300: loss 0.691879\n",
      "iteration 10 / 300: loss 0.683186\n",
      "iteration 10 / 300: loss 0.680990\n",
      "iteration 10 / 300: loss 0.704095\n",
      "iteration 10 / 300: loss 0.668801\n",
      "iteration 10 / 300: loss 0.676429\n",
      "iteration 10 / 300: loss 0.673073\n",
      "iteration 10 / 300: loss 0.692596\n",
      "iteration 10 / 300: loss 0.693153\n",
      "iteration 10 / 300: loss 0.695043\n",
      "iteration 10 / 300: loss 0.693707\n",
      "iteration 10 / 300: loss 0.691951\n",
      "iteration 10 / 300: loss 0.677925\n",
      "iteration 10 / 300: loss 0.706297\n",
      "iteration 10 / 300: loss 0.683669\n",
      "iteration 10 / 300: loss 0.689276\n",
      "iteration 10 / 300: loss 0.708296\n",
      "iteration 10 / 300: loss 0.667883\n",
      "iteration 10 / 300: loss 0.684637\n",
      "iteration 10 / 300: loss 0.689431\n",
      "iteration 10 / 300: loss 0.686730\n",
      "iteration 10 / 300: loss 0.681432\n",
      "iteration 10 / 300: loss 0.680264\n",
      "iteration 10 / 300: loss 0.675678\n",
      "iteration 10 / 300: loss 0.694446\n",
      "iteration 10 / 300: loss 0.706239\n",
      "iteration 10 / 300: loss 0.675787\n",
      "iteration 10 / 300: loss 0.677083\n",
      "iteration 10 / 300: loss 0.669499\n",
      "iteration 10 / 300: loss 0.686147\n",
      "iteration 10 / 300: loss 0.669332\n",
      "iteration 10 / 300: loss 0.663318\n",
      "iteration 10 / 300: loss 0.667275\n",
      "iteration 10 / 300: loss 0.655227\n",
      "iteration 10 / 300: loss 0.679420\n",
      "iteration 10 / 300: loss 0.668734\n",
      "iteration 10 / 300: loss 0.675189\n",
      "iteration 10 / 300: loss 0.653852\n",
      "iteration 10 / 300: loss 0.679415\n",
      "iteration 10 / 300: loss 0.701453\n",
      "iteration 10 / 300: loss 0.690296\n",
      "iteration 10 / 300: loss 0.699057\n",
      "iteration 10 / 300: loss 0.679064\n",
      "iteration 10 / 300: loss 0.684510\n",
      "iteration 10 / 300: loss 0.681549\n",
      "iteration 10 / 300: loss 0.679389\n",
      "iteration 10 / 300: loss 0.681953\n",
      "iteration 10 / 300: loss 0.680008\n",
      "iteration 10 / 300: loss 0.678080\n",
      "iteration 10 / 300: loss 0.674256\n",
      "iteration 10 / 300: loss 0.697067\n",
      "iteration 10 / 300: loss 0.683746\n",
      "iteration 10 / 300: loss 0.705264\n",
      "iteration 10 / 300: loss 0.680970\n",
      "iteration 10 / 300: loss 0.678317\n",
      "iteration 10 / 300: loss 0.688924\n",
      "iteration 10 / 300: loss 0.683161\n",
      "iteration 10 / 300: loss 0.678283\n",
      "iteration 10 / 300: loss 0.669537\n",
      "iteration 10 / 300: loss 0.677241\n",
      "iteration 10 / 300: loss 0.690270\n",
      "iteration 10 / 300: loss 0.692134\n",
      "iteration 10 / 300: loss 0.666087\n",
      "iteration 10 / 300: loss 0.682405\n",
      "iteration 10 / 300: loss 0.691647\n",
      "iteration 10 / 300: loss 0.681711\n",
      "iteration 10 / 300: loss 0.683543\n",
      "iteration 10 / 300: loss 0.705811\n",
      "iteration 10 / 300: loss 0.660532\n",
      "iteration 10 / 300: loss 0.668826\n",
      "iteration 10 / 300: loss 0.710170\n",
      "iteration 10 / 300: loss 0.690528\n",
      "iteration 10 / 300: loss 0.682524\n",
      "iteration 10 / 300: loss 0.683170\n",
      "iteration 10 / 300: loss 0.692556\n",
      "iteration 10 / 300: loss 0.678345\n",
      "iteration 10 / 300: loss 0.668803\n",
      "iteration 10 / 300: loss 0.687513\n",
      "iteration 10 / 300: loss 0.692663\n",
      "iteration 10 / 300: loss 0.681179\n",
      "iteration 10 / 300: loss 0.668652\n",
      "iteration 10 / 300: loss 0.692331\n",
      "iteration 10 / 300: loss 0.678477\n",
      "iteration 10 / 300: loss 0.664569\n",
      "iteration 10 / 300: loss 0.686157\n",
      "iteration 11 / 300: loss 0.661209\n",
      "iteration 11 / 300: loss 0.676866\n",
      "iteration 11 / 300: loss 0.652936\n",
      "iteration 11 / 300: loss 0.672994\n",
      "iteration 11 / 300: loss 0.678037\n",
      "iteration 11 / 300: loss 0.677553\n",
      "iteration 11 / 300: loss 0.689666\n",
      "iteration 11 / 300: loss 0.671584\n",
      "iteration 11 / 300: loss 0.706348\n",
      "iteration 11 / 300: loss 0.671736\n",
      "iteration 11 / 300: loss 0.704425\n",
      "iteration 11 / 300: loss 0.678385\n",
      "iteration 11 / 300: loss 0.678814\n",
      "iteration 11 / 300: loss 0.660502\n",
      "iteration 11 / 300: loss 0.669021\n",
      "iteration 11 / 300: loss 0.684141\n",
      "iteration 11 / 300: loss 0.678254\n",
      "iteration 11 / 300: loss 0.673695\n",
      "iteration 11 / 300: loss 0.697632\n",
      "iteration 11 / 300: loss 0.663489\n",
      "iteration 11 / 300: loss 0.670289\n",
      "iteration 11 / 300: loss 0.671232\n",
      "iteration 11 / 300: loss 0.687067\n",
      "iteration 11 / 300: loss 0.687616\n",
      "iteration 11 / 300: loss 0.684639\n",
      "iteration 11 / 300: loss 0.686114\n",
      "iteration 11 / 300: loss 0.682486\n",
      "iteration 11 / 300: loss 0.669733\n",
      "iteration 11 / 300: loss 0.700871\n",
      "iteration 11 / 300: loss 0.676092\n",
      "iteration 11 / 300: loss 0.677891\n",
      "iteration 11 / 300: loss 0.701509\n",
      "iteration 11 / 300: loss 0.660934\n",
      "iteration 11 / 300: loss 0.676201\n",
      "iteration 11 / 300: loss 0.683431\n",
      "iteration 11 / 300: loss 0.680432\n",
      "iteration 11 / 300: loss 0.677189\n",
      "iteration 11 / 300: loss 0.674728\n",
      "iteration 11 / 300: loss 0.668795\n",
      "iteration 11 / 300: loss 0.686972\n",
      "iteration 11 / 300: loss 0.698104\n",
      "iteration 11 / 300: loss 0.668561\n",
      "iteration 11 / 300: loss 0.668910\n",
      "iteration 11 / 300: loss 0.661000\n",
      "iteration 11 / 300: loss 0.677097\n",
      "iteration 11 / 300: loss 0.659694\n",
      "iteration 11 / 300: loss 0.656191\n",
      "iteration 11 / 300: loss 0.660082\n",
      "iteration 11 / 300: loss 0.648877\n",
      "iteration 11 / 300: loss 0.673402\n",
      "iteration 11 / 300: loss 0.662065\n",
      "iteration 11 / 300: loss 0.665529\n",
      "iteration 11 / 300: loss 0.647212\n",
      "iteration 11 / 300: loss 0.671462\n",
      "iteration 11 / 300: loss 0.693797\n",
      "iteration 11 / 300: loss 0.681341\n",
      "iteration 11 / 300: loss 0.692378\n",
      "iteration 11 / 300: loss 0.671549\n",
      "iteration 11 / 300: loss 0.679153\n",
      "iteration 11 / 300: loss 0.677024\n",
      "iteration 11 / 300: loss 0.675211\n",
      "iteration 11 / 300: loss 0.676500\n",
      "iteration 11 / 300: loss 0.673640\n",
      "iteration 11 / 300: loss 0.668307\n",
      "iteration 11 / 300: loss 0.665700\n",
      "iteration 11 / 300: loss 0.689300\n",
      "iteration 11 / 300: loss 0.677393\n",
      "iteration 11 / 300: loss 0.698801\n",
      "iteration 11 / 300: loss 0.670986\n",
      "iteration 11 / 300: loss 0.672028\n",
      "iteration 11 / 300: loss 0.684412\n",
      "iteration 11 / 300: loss 0.677136\n",
      "iteration 11 / 300: loss 0.667393\n",
      "iteration 11 / 300: loss 0.660238\n",
      "iteration 11 / 300: loss 0.671538\n",
      "iteration 11 / 300: loss 0.685080\n",
      "iteration 11 / 300: loss 0.686413\n",
      "iteration 11 / 300: loss 0.661645\n",
      "iteration 11 / 300: loss 0.673789\n",
      "iteration 11 / 300: loss 0.683270\n",
      "iteration 11 / 300: loss 0.671075\n",
      "iteration 11 / 300: loss 0.677247\n",
      "iteration 11 / 300: loss 0.697468\n",
      "iteration 11 / 300: loss 0.653185\n",
      "iteration 11 / 300: loss 0.660301\n",
      "iteration 11 / 300: loss 0.698886\n",
      "iteration 11 / 300: loss 0.683809\n",
      "iteration 11 / 300: loss 0.674623\n",
      "iteration 11 / 300: loss 0.674473\n",
      "iteration 11 / 300: loss 0.686034\n",
      "iteration 11 / 300: loss 0.671191\n",
      "iteration 11 / 300: loss 0.664672\n",
      "iteration 11 / 300: loss 0.680120\n",
      "iteration 11 / 300: loss 0.684622\n",
      "iteration 11 / 300: loss 0.674240\n",
      "iteration 11 / 300: loss 0.662496\n",
      "iteration 11 / 300: loss 0.682131\n",
      "iteration 11 / 300: loss 0.674046\n",
      "iteration 11 / 300: loss 0.658467\n",
      "iteration 11 / 300: loss 0.679312\n",
      "iteration 12 / 300: loss 0.653466\n",
      "iteration 12 / 300: loss 0.669206\n",
      "iteration 12 / 300: loss 0.644284\n",
      "iteration 12 / 300: loss 0.665052\n",
      "iteration 12 / 300: loss 0.671943\n",
      "iteration 12 / 300: loss 0.672487\n",
      "iteration 12 / 300: loss 0.684789\n",
      "iteration 12 / 300: loss 0.662441\n",
      "iteration 12 / 300: loss 0.699967\n",
      "iteration 12 / 300: loss 0.664356\n",
      "iteration 12 / 300: loss 0.698921\n",
      "iteration 12 / 300: loss 0.671312\n",
      "iteration 12 / 300: loss 0.671975\n",
      "iteration 12 / 300: loss 0.653660\n",
      "iteration 12 / 300: loss 0.663034\n",
      "iteration 12 / 300: loss 0.675602\n",
      "iteration 12 / 300: loss 0.671937\n",
      "iteration 12 / 300: loss 0.665461\n",
      "iteration 12 / 300: loss 0.690785\n",
      "iteration 12 / 300: loss 0.655541\n",
      "iteration 12 / 300: loss 0.662699\n",
      "iteration 12 / 300: loss 0.659884\n",
      "iteration 12 / 300: loss 0.674643\n",
      "iteration 12 / 300: loss 0.676111\n",
      "iteration 12 / 300: loss 0.678189\n",
      "iteration 12 / 300: loss 0.681390\n",
      "iteration 12 / 300: loss 0.674532\n",
      "iteration 12 / 300: loss 0.661975\n",
      "iteration 12 / 300: loss 0.691573\n",
      "iteration 12 / 300: loss 0.669594\n",
      "iteration 12 / 300: loss 0.672372\n",
      "iteration 12 / 300: loss 0.694314\n",
      "iteration 12 / 300: loss 0.652190\n",
      "iteration 12 / 300: loss 0.667082\n",
      "iteration 12 / 300: loss 0.676721\n",
      "iteration 12 / 300: loss 0.672332\n",
      "iteration 12 / 300: loss 0.668438\n",
      "iteration 12 / 300: loss 0.666357\n",
      "iteration 12 / 300: loss 0.660854\n",
      "iteration 12 / 300: loss 0.681503\n",
      "iteration 12 / 300: loss 0.689289\n",
      "iteration 12 / 300: loss 0.663505\n",
      "iteration 12 / 300: loss 0.661048\n",
      "iteration 12 / 300: loss 0.653357\n",
      "iteration 12 / 300: loss 0.668564\n",
      "iteration 12 / 300: loss 0.654849\n",
      "iteration 12 / 300: loss 0.651550\n",
      "iteration 12 / 300: loss 0.652344\n",
      "iteration 12 / 300: loss 0.640850\n",
      "iteration 12 / 300: loss 0.666433\n",
      "iteration 12 / 300: loss 0.655094\n",
      "iteration 12 / 300: loss 0.659532\n",
      "iteration 12 / 300: loss 0.638643\n",
      "iteration 12 / 300: loss 0.666570\n",
      "iteration 12 / 300: loss 0.685366\n",
      "iteration 12 / 300: loss 0.674363\n",
      "iteration 12 / 300: loss 0.684973\n",
      "iteration 12 / 300: loss 0.662138\n",
      "iteration 12 / 300: loss 0.671087\n",
      "iteration 12 / 300: loss 0.670860\n",
      "iteration 12 / 300: loss 0.667327\n",
      "iteration 12 / 300: loss 0.670001\n",
      "iteration 12 / 300: loss 0.666282\n",
      "iteration 12 / 300: loss 0.661760\n",
      "iteration 12 / 300: loss 0.660663\n",
      "iteration 12 / 300: loss 0.680565\n",
      "iteration 12 / 300: loss 0.669623\n",
      "iteration 12 / 300: loss 0.689746\n",
      "iteration 12 / 300: loss 0.665400\n",
      "iteration 12 / 300: loss 0.666588\n",
      "iteration 12 / 300: loss 0.677835\n",
      "iteration 12 / 300: loss 0.672156\n",
      "iteration 12 / 300: loss 0.661110\n",
      "iteration 12 / 300: loss 0.653586\n",
      "iteration 12 / 300: loss 0.664166\n",
      "iteration 12 / 300: loss 0.678426\n",
      "iteration 12 / 300: loss 0.678512\n",
      "iteration 12 / 300: loss 0.653093\n",
      "iteration 12 / 300: loss 0.667666\n",
      "iteration 12 / 300: loss 0.676298\n",
      "iteration 12 / 300: loss 0.665435\n",
      "iteration 12 / 300: loss 0.670615\n",
      "iteration 12 / 300: loss 0.692094\n",
      "iteration 12 / 300: loss 0.647130\n",
      "iteration 12 / 300: loss 0.652514\n",
      "iteration 12 / 300: loss 0.692449\n",
      "iteration 12 / 300: loss 0.678283\n",
      "iteration 12 / 300: loss 0.669746\n",
      "iteration 12 / 300: loss 0.668748\n",
      "iteration 12 / 300: loss 0.680376\n",
      "iteration 12 / 300: loss 0.663054\n",
      "iteration 12 / 300: loss 0.654744\n",
      "iteration 12 / 300: loss 0.673419\n",
      "iteration 12 / 300: loss 0.677995\n",
      "iteration 12 / 300: loss 0.665185\n",
      "iteration 12 / 300: loss 0.657306\n",
      "iteration 12 / 300: loss 0.674667\n",
      "iteration 12 / 300: loss 0.666575\n",
      "iteration 12 / 300: loss 0.650814\n",
      "iteration 12 / 300: loss 0.677181\n",
      "iteration 13 / 300: loss 0.646768\n",
      "iteration 13 / 300: loss 0.661883\n",
      "iteration 13 / 300: loss 0.637525\n",
      "iteration 13 / 300: loss 0.661546\n",
      "iteration 13 / 300: loss 0.664000\n",
      "iteration 13 / 300: loss 0.665713\n",
      "iteration 13 / 300: loss 0.678562\n",
      "iteration 13 / 300: loss 0.654712\n",
      "iteration 13 / 300: loss 0.692420\n",
      "iteration 13 / 300: loss 0.662443\n",
      "iteration 13 / 300: loss 0.693176\n",
      "iteration 13 / 300: loss 0.666160\n",
      "iteration 13 / 300: loss 0.667007\n",
      "iteration 13 / 300: loss 0.644266\n",
      "iteration 13 / 300: loss 0.659840\n",
      "iteration 13 / 300: loss 0.669269\n",
      "iteration 13 / 300: loss 0.663606\n",
      "iteration 13 / 300: loss 0.659143\n",
      "iteration 13 / 300: loss 0.682890\n",
      "iteration 13 / 300: loss 0.649046\n",
      "iteration 13 / 300: loss 0.655469\n",
      "iteration 13 / 300: loss 0.655232\n",
      "iteration 13 / 300: loss 0.666093\n",
      "iteration 13 / 300: loss 0.669691\n",
      "iteration 13 / 300: loss 0.672058\n",
      "iteration 13 / 300: loss 0.674942\n",
      "iteration 13 / 300: loss 0.667727\n",
      "iteration 13 / 300: loss 0.655069\n",
      "iteration 13 / 300: loss 0.685043\n",
      "iteration 13 / 300: loss 0.663378\n",
      "iteration 13 / 300: loss 0.662882\n",
      "iteration 13 / 300: loss 0.685515\n",
      "iteration 13 / 300: loss 0.645637\n",
      "iteration 13 / 300: loss 0.659574\n",
      "iteration 13 / 300: loss 0.670697\n",
      "iteration 13 / 300: loss 0.665208\n",
      "iteration 13 / 300: loss 0.664400\n",
      "iteration 13 / 300: loss 0.659887\n",
      "iteration 13 / 300: loss 0.655037\n",
      "iteration 13 / 300: loss 0.676754\n",
      "iteration 13 / 300: loss 0.683458\n",
      "iteration 13 / 300: loss 0.657705\n",
      "iteration 13 / 300: loss 0.652580\n",
      "iteration 13 / 300: loss 0.646742\n",
      "iteration 13 / 300: loss 0.660636\n",
      "iteration 13 / 300: loss 0.647370\n",
      "iteration 13 / 300: loss 0.644251\n",
      "iteration 13 / 300: loss 0.645832\n",
      "iteration 13 / 300: loss 0.634983\n",
      "iteration 13 / 300: loss 0.660239\n",
      "iteration 13 / 300: loss 0.648302\n",
      "iteration 13 / 300: loss 0.651677\n",
      "iteration 13 / 300: loss 0.632556\n",
      "iteration 13 / 300: loss 0.658730\n",
      "iteration 13 / 300: loss 0.678946\n",
      "iteration 13 / 300: loss 0.668881\n",
      "iteration 13 / 300: loss 0.678533\n",
      "iteration 13 / 300: loss 0.655359\n",
      "iteration 13 / 300: loss 0.665356\n",
      "iteration 13 / 300: loss 0.663715\n",
      "iteration 13 / 300: loss 0.660453\n",
      "iteration 13 / 300: loss 0.663347\n",
      "iteration 13 / 300: loss 0.659775\n",
      "iteration 13 / 300: loss 0.655953\n",
      "iteration 13 / 300: loss 0.651650\n",
      "iteration 13 / 300: loss 0.671309\n",
      "iteration 13 / 300: loss 0.663630\n",
      "iteration 13 / 300: loss 0.684068\n",
      "iteration 13 / 300: loss 0.658152\n",
      "iteration 13 / 300: loss 0.659602\n",
      "iteration 13 / 300: loss 0.670775\n",
      "iteration 13 / 300: loss 0.664205\n",
      "iteration 13 / 300: loss 0.652284\n",
      "iteration 13 / 300: loss 0.647098\n",
      "iteration 13 / 300: loss 0.658325\n",
      "iteration 13 / 300: loss 0.672042\n",
      "iteration 13 / 300: loss 0.671358\n",
      "iteration 13 / 300: loss 0.647299\n",
      "iteration 13 / 300: loss 0.660036\n",
      "iteration 13 / 300: loss 0.668732\n",
      "iteration 13 / 300: loss 0.659108\n",
      "iteration 13 / 300: loss 0.665466\n",
      "iteration 13 / 300: loss 0.685477\n",
      "iteration 13 / 300: loss 0.641758\n",
      "iteration 13 / 300: loss 0.646550\n",
      "iteration 13 / 300: loss 0.687315\n",
      "iteration 13 / 300: loss 0.672950\n",
      "iteration 13 / 300: loss 0.662574\n",
      "iteration 13 / 300: loss 0.662252\n",
      "iteration 13 / 300: loss 0.675362\n",
      "iteration 13 / 300: loss 0.655856\n",
      "iteration 13 / 300: loss 0.648894\n",
      "iteration 13 / 300: loss 0.666362\n",
      "iteration 13 / 300: loss 0.671291\n",
      "iteration 13 / 300: loss 0.658598\n",
      "iteration 13 / 300: loss 0.651513\n",
      "iteration 13 / 300: loss 0.668542\n",
      "iteration 13 / 300: loss 0.661085\n",
      "iteration 13 / 300: loss 0.643340\n",
      "iteration 13 / 300: loss 0.670622\n",
      "iteration 14 / 300: loss 0.640230\n",
      "iteration 14 / 300: loss 0.654591\n",
      "iteration 14 / 300: loss 0.629606\n",
      "iteration 14 / 300: loss 0.655423\n",
      "iteration 14 / 300: loss 0.656397\n",
      "iteration 14 / 300: loss 0.661272\n",
      "iteration 14 / 300: loss 0.674879\n",
      "iteration 14 / 300: loss 0.648606\n",
      "iteration 14 / 300: loss 0.687107\n",
      "iteration 14 / 300: loss 0.655403\n",
      "iteration 14 / 300: loss 0.685607\n",
      "iteration 14 / 300: loss 0.657967\n",
      "iteration 14 / 300: loss 0.661483\n",
      "iteration 14 / 300: loss 0.636263\n",
      "iteration 14 / 300: loss 0.653687\n",
      "iteration 14 / 300: loss 0.665592\n",
      "iteration 14 / 300: loss 0.657628\n",
      "iteration 14 / 300: loss 0.651241\n",
      "iteration 14 / 300: loss 0.679452\n",
      "iteration 14 / 300: loss 0.644447\n",
      "iteration 14 / 300: loss 0.650849\n",
      "iteration 14 / 300: loss 0.649144\n",
      "iteration 14 / 300: loss 0.660882\n",
      "iteration 14 / 300: loss 0.663663\n",
      "iteration 14 / 300: loss 0.666450\n",
      "iteration 14 / 300: loss 0.667001\n",
      "iteration 14 / 300: loss 0.659907\n",
      "iteration 14 / 300: loss 0.650562\n",
      "iteration 14 / 300: loss 0.680541\n",
      "iteration 14 / 300: loss 0.658858\n",
      "iteration 14 / 300: loss 0.655117\n",
      "iteration 14 / 300: loss 0.680597\n",
      "iteration 14 / 300: loss 0.641219\n",
      "iteration 14 / 300: loss 0.654438\n",
      "iteration 14 / 300: loss 0.662879\n",
      "iteration 14 / 300: loss 0.658952\n",
      "iteration 14 / 300: loss 0.657915\n",
      "iteration 14 / 300: loss 0.653586\n",
      "iteration 14 / 300: loss 0.648816\n",
      "iteration 14 / 300: loss 0.671062\n",
      "iteration 14 / 300: loss 0.677586\n",
      "iteration 14 / 300: loss 0.650475\n",
      "iteration 14 / 300: loss 0.646235\n",
      "iteration 14 / 300: loss 0.641451\n",
      "iteration 14 / 300: loss 0.655731\n",
      "iteration 14 / 300: loss 0.640161\n",
      "iteration 14 / 300: loss 0.638811\n",
      "iteration 14 / 300: loss 0.638690\n",
      "iteration 14 / 300: loss 0.630122\n",
      "iteration 14 / 300: loss 0.654091\n",
      "iteration 14 / 300: loss 0.643105\n",
      "iteration 14 / 300: loss 0.645096\n",
      "iteration 14 / 300: loss 0.627088\n",
      "iteration 14 / 300: loss 0.653160\n",
      "iteration 14 / 300: loss 0.673469\n",
      "iteration 14 / 300: loss 0.663119\n",
      "iteration 14 / 300: loss 0.673183\n",
      "iteration 14 / 300: loss 0.649826\n",
      "iteration 14 / 300: loss 0.659825\n",
      "iteration 14 / 300: loss 0.659041\n",
      "iteration 14 / 300: loss 0.656544\n",
      "iteration 14 / 300: loss 0.659254\n",
      "iteration 14 / 300: loss 0.654819\n",
      "iteration 14 / 300: loss 0.650617\n",
      "iteration 14 / 300: loss 0.645295\n",
      "iteration 14 / 300: loss 0.665596\n",
      "iteration 14 / 300: loss 0.658937\n",
      "iteration 14 / 300: loss 0.676330\n",
      "iteration 14 / 300: loss 0.653216\n",
      "iteration 14 / 300: loss 0.653054\n",
      "iteration 14 / 300: loss 0.663971\n",
      "iteration 14 / 300: loss 0.659237\n",
      "iteration 14 / 300: loss 0.646243\n",
      "iteration 14 / 300: loss 0.642631\n",
      "iteration 14 / 300: loss 0.653907\n",
      "iteration 14 / 300: loss 0.667357\n",
      "iteration 14 / 300: loss 0.666113\n",
      "iteration 14 / 300: loss 0.640697\n",
      "iteration 14 / 300: loss 0.653457\n",
      "iteration 14 / 300: loss 0.663137\n",
      "iteration 14 / 300: loss 0.654009\n",
      "iteration 14 / 300: loss 0.661211\n",
      "iteration 14 / 300: loss 0.682265\n",
      "iteration 14 / 300: loss 0.635531\n",
      "iteration 14 / 300: loss 0.639940\n",
      "iteration 14 / 300: loss 0.681939\n",
      "iteration 14 / 300: loss 0.667427\n",
      "iteration 14 / 300: loss 0.658014\n",
      "iteration 14 / 300: loss 0.656099\n",
      "iteration 14 / 300: loss 0.670902\n",
      "iteration 14 / 300: loss 0.650032\n",
      "iteration 14 / 300: loss 0.643365\n",
      "iteration 14 / 300: loss 0.662077\n",
      "iteration 14 / 300: loss 0.664832\n",
      "iteration 14 / 300: loss 0.652124\n",
      "iteration 14 / 300: loss 0.645363\n",
      "iteration 14 / 300: loss 0.662662\n",
      "iteration 14 / 300: loss 0.654564\n",
      "iteration 14 / 300: loss 0.636811\n",
      "iteration 14 / 300: loss 0.665257\n",
      "iteration 15 / 300: loss 0.634171\n",
      "iteration 15 / 300: loss 0.648729\n",
      "iteration 15 / 300: loss 0.624724\n",
      "iteration 15 / 300: loss 0.650009\n",
      "iteration 15 / 300: loss 0.651493\n",
      "iteration 15 / 300: loss 0.655690\n",
      "iteration 15 / 300: loss 0.667441\n",
      "iteration 15 / 300: loss 0.640421\n",
      "iteration 15 / 300: loss 0.681460\n",
      "iteration 15 / 300: loss 0.650913\n",
      "iteration 15 / 300: loss 0.680572\n",
      "iteration 15 / 300: loss 0.651896\n",
      "iteration 15 / 300: loss 0.658281\n",
      "iteration 15 / 300: loss 0.630497\n",
      "iteration 15 / 300: loss 0.649974\n",
      "iteration 15 / 300: loss 0.660765\n",
      "iteration 15 / 300: loss 0.652820\n",
      "iteration 15 / 300: loss 0.644825\n",
      "iteration 15 / 300: loss 0.675213\n",
      "iteration 15 / 300: loss 0.640005\n",
      "iteration 15 / 300: loss 0.645434\n",
      "iteration 15 / 300: loss 0.645464\n",
      "iteration 15 / 300: loss 0.656592\n",
      "iteration 15 / 300: loss 0.657930\n",
      "iteration 15 / 300: loss 0.663126\n",
      "iteration 15 / 300: loss 0.661382\n",
      "iteration 15 / 300: loss 0.653459\n",
      "iteration 15 / 300: loss 0.645006\n",
      "iteration 15 / 300: loss 0.674348\n",
      "iteration 15 / 300: loss 0.654690\n",
      "iteration 15 / 300: loss 0.650359\n",
      "iteration 15 / 300: loss 0.674658\n",
      "iteration 15 / 300: loss 0.634427\n",
      "iteration 15 / 300: loss 0.649450\n",
      "iteration 15 / 300: loss 0.657606\n",
      "iteration 15 / 300: loss 0.654223\n",
      "iteration 15 / 300: loss 0.653949\n",
      "iteration 15 / 300: loss 0.648059\n",
      "iteration 15 / 300: loss 0.641574\n",
      "iteration 15 / 300: loss 0.665369\n",
      "iteration 15 / 300: loss 0.673336\n",
      "iteration 15 / 300: loss 0.645538\n",
      "iteration 15 / 300: loss 0.638995\n",
      "iteration 15 / 300: loss 0.636545\n",
      "iteration 15 / 300: loss 0.650272\n",
      "iteration 15 / 300: loss 0.635024\n",
      "iteration 15 / 300: loss 0.632649\n",
      "iteration 15 / 300: loss 0.631933\n",
      "iteration 15 / 300: loss 0.624369\n",
      "iteration 15 / 300: loss 0.649415\n",
      "iteration 15 / 300: loss 0.636696\n",
      "iteration 15 / 300: loss 0.639165\n",
      "iteration 15 / 300: loss 0.621217\n",
      "iteration 15 / 300: loss 0.648510\n",
      "iteration 15 / 300: loss 0.668755\n",
      "iteration 15 / 300: loss 0.657724\n",
      "iteration 15 / 300: loss 0.666056\n",
      "iteration 15 / 300: loss 0.643900\n",
      "iteration 15 / 300: loss 0.653093\n",
      "iteration 15 / 300: loss 0.654090\n",
      "iteration 15 / 300: loss 0.650012\n",
      "iteration 15 / 300: loss 0.653361\n",
      "iteration 15 / 300: loss 0.649096\n",
      "iteration 15 / 300: loss 0.645969\n",
      "iteration 15 / 300: loss 0.639091\n",
      "iteration 15 / 300: loss 0.659002\n",
      "iteration 15 / 300: loss 0.653571\n",
      "iteration 15 / 300: loss 0.671637\n",
      "iteration 15 / 300: loss 0.648797\n",
      "iteration 15 / 300: loss 0.648688\n",
      "iteration 15 / 300: loss 0.658216\n",
      "iteration 15 / 300: loss 0.653210\n",
      "iteration 15 / 300: loss 0.641798\n",
      "iteration 15 / 300: loss 0.635881\n",
      "iteration 15 / 300: loss 0.649138\n",
      "iteration 15 / 300: loss 0.662668\n",
      "iteration 15 / 300: loss 0.662126\n",
      "iteration 15 / 300: loss 0.635564\n",
      "iteration 15 / 300: loss 0.646747\n",
      "iteration 15 / 300: loss 0.657877\n",
      "iteration 15 / 300: loss 0.650602\n",
      "iteration 15 / 300: loss 0.656088\n",
      "iteration 15 / 300: loss 0.676458\n",
      "iteration 15 / 300: loss 0.632379\n",
      "iteration 15 / 300: loss 0.634440\n",
      "iteration 15 / 300: loss 0.678177\n",
      "iteration 15 / 300: loss 0.661925\n",
      "iteration 15 / 300: loss 0.654835\n",
      "iteration 15 / 300: loss 0.650520\n",
      "iteration 15 / 300: loss 0.663143\n",
      "iteration 15 / 300: loss 0.644331\n",
      "iteration 15 / 300: loss 0.638558\n",
      "iteration 15 / 300: loss 0.657608\n",
      "iteration 15 / 300: loss 0.661053\n",
      "iteration 15 / 300: loss 0.646491\n",
      "iteration 15 / 300: loss 0.641798\n",
      "iteration 15 / 300: loss 0.658179\n",
      "iteration 15 / 300: loss 0.650938\n",
      "iteration 15 / 300: loss 0.632714\n",
      "iteration 15 / 300: loss 0.660640\n",
      "iteration 16 / 300: loss 0.627317\n",
      "iteration 16 / 300: loss 0.643559\n",
      "iteration 16 / 300: loss 0.618346\n",
      "iteration 16 / 300: loss 0.643403\n",
      "iteration 16 / 300: loss 0.646382\n",
      "iteration 16 / 300: loss 0.651255\n",
      "iteration 16 / 300: loss 0.663530\n",
      "iteration 16 / 300: loss 0.634617\n",
      "iteration 16 / 300: loss 0.675699\n",
      "iteration 16 / 300: loss 0.646078\n",
      "iteration 16 / 300: loss 0.675354\n",
      "iteration 16 / 300: loss 0.646344\n",
      "iteration 16 / 300: loss 0.652801\n",
      "iteration 16 / 300: loss 0.625054\n",
      "iteration 16 / 300: loss 0.645766\n",
      "iteration 16 / 300: loss 0.656422\n",
      "iteration 16 / 300: loss 0.647571\n",
      "iteration 16 / 300: loss 0.639490\n",
      "iteration 16 / 300: loss 0.669835\n",
      "iteration 16 / 300: loss 0.635252\n",
      "iteration 16 / 300: loss 0.640568\n",
      "iteration 16 / 300: loss 0.641095\n",
      "iteration 16 / 300: loss 0.652245\n",
      "iteration 16 / 300: loss 0.652890\n",
      "iteration 16 / 300: loss 0.660262\n",
      "iteration 16 / 300: loss 0.656632\n",
      "iteration 16 / 300: loss 0.648700\n",
      "iteration 16 / 300: loss 0.641418\n",
      "iteration 16 / 300: loss 0.668683\n",
      "iteration 16 / 300: loss 0.649582\n",
      "iteration 16 / 300: loss 0.645097\n",
      "iteration 16 / 300: loss 0.670423\n",
      "iteration 16 / 300: loss 0.628775\n",
      "iteration 16 / 300: loss 0.644772\n",
      "iteration 16 / 300: loss 0.651394\n",
      "iteration 16 / 300: loss 0.648475\n",
      "iteration 16 / 300: loss 0.648680\n",
      "iteration 16 / 300: loss 0.642195\n",
      "iteration 16 / 300: loss 0.637772\n",
      "iteration 16 / 300: loss 0.660929\n",
      "iteration 16 / 300: loss 0.667289\n",
      "iteration 16 / 300: loss 0.639875\n",
      "iteration 16 / 300: loss 0.634068\n",
      "iteration 16 / 300: loss 0.632714\n",
      "iteration 16 / 300: loss 0.644690\n",
      "iteration 16 / 300: loss 0.630514\n",
      "iteration 16 / 300: loss 0.628671\n",
      "iteration 16 / 300: loss 0.626583\n",
      "iteration 16 / 300: loss 0.618603\n",
      "iteration 16 / 300: loss 0.645110\n",
      "iteration 16 / 300: loss 0.631037\n",
      "iteration 16 / 300: loss 0.634314\n",
      "iteration 16 / 300: loss 0.616679\n",
      "iteration 16 / 300: loss 0.642912\n",
      "iteration 16 / 300: loss 0.664103\n",
      "iteration 16 / 300: loss 0.653751\n",
      "iteration 16 / 300: loss 0.661473\n",
      "iteration 16 / 300: loss 0.639059\n",
      "iteration 16 / 300: loss 0.647175\n",
      "iteration 16 / 300: loss 0.648548\n",
      "iteration 16 / 300: loss 0.644831\n",
      "iteration 16 / 300: loss 0.648964\n",
      "iteration 16 / 300: loss 0.643605\n",
      "iteration 16 / 300: loss 0.641979\n",
      "iteration 16 / 300: loss 0.633723\n",
      "iteration 16 / 300: loss 0.653262\n",
      "iteration 16 / 300: loss 0.649055\n",
      "iteration 16 / 300: loss 0.666470\n",
      "iteration 16 / 300: loss 0.643888\n",
      "iteration 16 / 300: loss 0.644057\n",
      "iteration 16 / 300: loss 0.651632\n",
      "iteration 16 / 300: loss 0.648272\n",
      "iteration 16 / 300: loss 0.637455\n",
      "iteration 16 / 300: loss 0.630921\n",
      "iteration 16 / 300: loss 0.645087\n",
      "iteration 16 / 300: loss 0.659709\n",
      "iteration 16 / 300: loss 0.658556\n",
      "iteration 16 / 300: loss 0.631617\n",
      "iteration 16 / 300: loss 0.642830\n",
      "iteration 16 / 300: loss 0.653016\n",
      "iteration 16 / 300: loss 0.645968\n",
      "iteration 16 / 300: loss 0.652187\n",
      "iteration 16 / 300: loss 0.670819\n",
      "iteration 16 / 300: loss 0.627763\n",
      "iteration 16 / 300: loss 0.628314\n",
      "iteration 16 / 300: loss 0.673905\n",
      "iteration 16 / 300: loss 0.656865\n",
      "iteration 16 / 300: loss 0.650320\n",
      "iteration 16 / 300: loss 0.646523\n",
      "iteration 16 / 300: loss 0.659593\n",
      "iteration 16 / 300: loss 0.640013\n",
      "iteration 16 / 300: loss 0.633404\n",
      "iteration 16 / 300: loss 0.653397\n",
      "iteration 16 / 300: loss 0.656481\n",
      "iteration 16 / 300: loss 0.641047\n",
      "iteration 16 / 300: loss 0.636528\n",
      "iteration 16 / 300: loss 0.653098\n",
      "iteration 16 / 300: loss 0.645549\n",
      "iteration 16 / 300: loss 0.628847\n",
      "iteration 16 / 300: loss 0.655589\n",
      "iteration 17 / 300: loss 0.622629\n",
      "iteration 17 / 300: loss 0.638440\n",
      "iteration 17 / 300: loss 0.612644\n",
      "iteration 17 / 300: loss 0.638820\n",
      "iteration 17 / 300: loss 0.641599\n",
      "iteration 17 / 300: loss 0.648004\n",
      "iteration 17 / 300: loss 0.659882\n",
      "iteration 17 / 300: loss 0.630473\n",
      "iteration 17 / 300: loss 0.670952\n",
      "iteration 17 / 300: loss 0.642130\n",
      "iteration 17 / 300: loss 0.670677\n",
      "iteration 17 / 300: loss 0.642172\n",
      "iteration 17 / 300: loss 0.648104\n",
      "iteration 17 / 300: loss 0.619963\n",
      "iteration 17 / 300: loss 0.640358\n",
      "iteration 17 / 300: loss 0.652560\n",
      "iteration 17 / 300: loss 0.643516\n",
      "iteration 17 / 300: loss 0.634451\n",
      "iteration 17 / 300: loss 0.665729\n",
      "iteration 17 / 300: loss 0.630776\n",
      "iteration 17 / 300: loss 0.636511\n",
      "iteration 17 / 300: loss 0.637355\n",
      "iteration 17 / 300: loss 0.647433\n",
      "iteration 17 / 300: loss 0.647414\n",
      "iteration 17 / 300: loss 0.656938\n",
      "iteration 17 / 300: loss 0.652398\n",
      "iteration 17 / 300: loss 0.644317\n",
      "iteration 17 / 300: loss 0.637618\n",
      "iteration 17 / 300: loss 0.664937\n",
      "iteration 17 / 300: loss 0.645553\n",
      "iteration 17 / 300: loss 0.640178\n",
      "iteration 17 / 300: loss 0.666455\n",
      "iteration 17 / 300: loss 0.623411\n",
      "iteration 17 / 300: loss 0.640139\n",
      "iteration 17 / 300: loss 0.646306\n",
      "iteration 17 / 300: loss 0.643017\n",
      "iteration 17 / 300: loss 0.643282\n",
      "iteration 17 / 300: loss 0.636934\n",
      "iteration 17 / 300: loss 0.633305\n",
      "iteration 17 / 300: loss 0.657030\n",
      "iteration 17 / 300: loss 0.661802\n",
      "iteration 17 / 300: loss 0.635160\n",
      "iteration 17 / 300: loss 0.628681\n",
      "iteration 17 / 300: loss 0.629177\n",
      "iteration 17 / 300: loss 0.640919\n",
      "iteration 17 / 300: loss 0.626318\n",
      "iteration 17 / 300: loss 0.624818\n",
      "iteration 17 / 300: loss 0.622659\n",
      "iteration 17 / 300: loss 0.614025\n",
      "iteration 17 / 300: loss 0.641796\n",
      "iteration 17 / 300: loss 0.626257\n",
      "iteration 17 / 300: loss 0.629944\n",
      "iteration 17 / 300: loss 0.612304\n",
      "iteration 17 / 300: loss 0.638030\n",
      "iteration 17 / 300: loss 0.659236\n",
      "iteration 17 / 300: loss 0.650027\n",
      "iteration 17 / 300: loss 0.657070\n",
      "iteration 17 / 300: loss 0.634967\n",
      "iteration 17 / 300: loss 0.642094\n",
      "iteration 17 / 300: loss 0.644237\n",
      "iteration 17 / 300: loss 0.641104\n",
      "iteration 17 / 300: loss 0.644117\n",
      "iteration 17 / 300: loss 0.639203\n",
      "iteration 17 / 300: loss 0.638142\n",
      "iteration 17 / 300: loss 0.628890\n",
      "iteration 17 / 300: loss 0.648351\n",
      "iteration 17 / 300: loss 0.645233\n",
      "iteration 17 / 300: loss 0.662153\n",
      "iteration 17 / 300: loss 0.639762\n",
      "iteration 17 / 300: loss 0.639936\n",
      "iteration 17 / 300: loss 0.647153\n",
      "iteration 17 / 300: loss 0.643212\n",
      "iteration 17 / 300: loss 0.633248\n",
      "iteration 17 / 300: loss 0.626297\n",
      "iteration 17 / 300: loss 0.641104\n",
      "iteration 17 / 300: loss 0.656283\n",
      "iteration 17 / 300: loss 0.654234\n",
      "iteration 17 / 300: loss 0.626879\n",
      "iteration 17 / 300: loss 0.639722\n",
      "iteration 17 / 300: loss 0.649217\n",
      "iteration 17 / 300: loss 0.641020\n",
      "iteration 17 / 300: loss 0.648345\n",
      "iteration 17 / 300: loss 0.666964\n",
      "iteration 17 / 300: loss 0.623671\n",
      "iteration 17 / 300: loss 0.623346\n",
      "iteration 17 / 300: loss 0.670032\n",
      "iteration 17 / 300: loss 0.652316\n",
      "iteration 17 / 300: loss 0.647883\n",
      "iteration 17 / 300: loss 0.642656\n",
      "iteration 17 / 300: loss 0.655125\n",
      "iteration 17 / 300: loss 0.635980\n",
      "iteration 17 / 300: loss 0.629108\n",
      "iteration 17 / 300: loss 0.650052\n",
      "iteration 17 / 300: loss 0.651774\n",
      "iteration 17 / 300: loss 0.636257\n",
      "iteration 17 / 300: loss 0.632372\n",
      "iteration 17 / 300: loss 0.649577\n",
      "iteration 17 / 300: loss 0.641308\n",
      "iteration 17 / 300: loss 0.624582\n",
      "iteration 17 / 300: loss 0.650795\n",
      "iteration 18 / 300: loss 0.618251\n",
      "iteration 18 / 300: loss 0.633835\n",
      "iteration 18 / 300: loss 0.607831\n",
      "iteration 18 / 300: loss 0.634849\n",
      "iteration 18 / 300: loss 0.637808\n",
      "iteration 18 / 300: loss 0.643788\n",
      "iteration 18 / 300: loss 0.655684\n",
      "iteration 18 / 300: loss 0.626535\n",
      "iteration 18 / 300: loss 0.666408\n",
      "iteration 18 / 300: loss 0.637876\n",
      "iteration 18 / 300: loss 0.666216\n",
      "iteration 18 / 300: loss 0.637783\n",
      "iteration 18 / 300: loss 0.643917\n",
      "iteration 18 / 300: loss 0.615045\n",
      "iteration 18 / 300: loss 0.636121\n",
      "iteration 18 / 300: loss 0.648130\n",
      "iteration 18 / 300: loss 0.639358\n",
      "iteration 18 / 300: loss 0.630001\n",
      "iteration 18 / 300: loss 0.660991\n",
      "iteration 18 / 300: loss 0.627143\n",
      "iteration 18 / 300: loss 0.632271\n",
      "iteration 18 / 300: loss 0.633872\n",
      "iteration 18 / 300: loss 0.642648\n",
      "iteration 18 / 300: loss 0.642422\n",
      "iteration 18 / 300: loss 0.653401\n",
      "iteration 18 / 300: loss 0.648012\n",
      "iteration 18 / 300: loss 0.639696\n",
      "iteration 18 / 300: loss 0.633907\n",
      "iteration 18 / 300: loss 0.661977\n",
      "iteration 18 / 300: loss 0.641543\n",
      "iteration 18 / 300: loss 0.636579\n",
      "iteration 18 / 300: loss 0.662815\n",
      "iteration 18 / 300: loss 0.619965\n",
      "iteration 18 / 300: loss 0.636173\n",
      "iteration 18 / 300: loss 0.641810\n",
      "iteration 18 / 300: loss 0.638968\n",
      "iteration 18 / 300: loss 0.638936\n",
      "iteration 18 / 300: loss 0.632481\n",
      "iteration 18 / 300: loss 0.629156\n",
      "iteration 18 / 300: loss 0.652975\n",
      "iteration 18 / 300: loss 0.656933\n",
      "iteration 18 / 300: loss 0.631334\n",
      "iteration 18 / 300: loss 0.624250\n",
      "iteration 18 / 300: loss 0.625859\n",
      "iteration 18 / 300: loss 0.637079\n",
      "iteration 18 / 300: loss 0.622140\n",
      "iteration 18 / 300: loss 0.620567\n",
      "iteration 18 / 300: loss 0.618323\n",
      "iteration 18 / 300: loss 0.610266\n",
      "iteration 18 / 300: loss 0.638031\n",
      "iteration 18 / 300: loss 0.622549\n",
      "iteration 18 / 300: loss 0.625719\n",
      "iteration 18 / 300: loss 0.608272\n",
      "iteration 18 / 300: loss 0.633682\n",
      "iteration 18 / 300: loss 0.654857\n",
      "iteration 18 / 300: loss 0.646582\n",
      "iteration 18 / 300: loss 0.652453\n",
      "iteration 18 / 300: loss 0.631477\n",
      "iteration 18 / 300: loss 0.637626\n",
      "iteration 18 / 300: loss 0.640597\n",
      "iteration 18 / 300: loss 0.636839\n",
      "iteration 18 / 300: loss 0.640143\n",
      "iteration 18 / 300: loss 0.635981\n",
      "iteration 18 / 300: loss 0.634601\n",
      "iteration 18 / 300: loss 0.625425\n",
      "iteration 18 / 300: loss 0.644335\n",
      "iteration 18 / 300: loss 0.641861\n",
      "iteration 18 / 300: loss 0.658121\n",
      "iteration 18 / 300: loss 0.635865\n",
      "iteration 18 / 300: loss 0.636302\n",
      "iteration 18 / 300: loss 0.643212\n",
      "iteration 18 / 300: loss 0.639175\n",
      "iteration 18 / 300: loss 0.629641\n",
      "iteration 18 / 300: loss 0.622562\n",
      "iteration 18 / 300: loss 0.637338\n",
      "iteration 18 / 300: loss 0.652636\n",
      "iteration 18 / 300: loss 0.649957\n",
      "iteration 18 / 300: loss 0.623301\n",
      "iteration 18 / 300: loss 0.636563\n",
      "iteration 18 / 300: loss 0.645768\n",
      "iteration 18 / 300: loss 0.637197\n",
      "iteration 18 / 300: loss 0.645256\n",
      "iteration 18 / 300: loss 0.663259\n",
      "iteration 18 / 300: loss 0.620532\n",
      "iteration 18 / 300: loss 0.619166\n",
      "iteration 18 / 300: loss 0.666258\n",
      "iteration 18 / 300: loss 0.648524\n",
      "iteration 18 / 300: loss 0.644709\n",
      "iteration 18 / 300: loss 0.637758\n",
      "iteration 18 / 300: loss 0.651009\n",
      "iteration 18 / 300: loss 0.632246\n",
      "iteration 18 / 300: loss 0.625518\n",
      "iteration 18 / 300: loss 0.647306\n",
      "iteration 18 / 300: loss 0.647835\n",
      "iteration 18 / 300: loss 0.632922\n",
      "iteration 18 / 300: loss 0.628950\n",
      "iteration 18 / 300: loss 0.645984\n",
      "iteration 18 / 300: loss 0.637501\n",
      "iteration 18 / 300: loss 0.620923\n",
      "iteration 18 / 300: loss 0.646881\n",
      "iteration 19 / 300: loss 0.614843\n",
      "iteration 19 / 300: loss 0.629924\n",
      "iteration 19 / 300: loss 0.603905\n",
      "iteration 19 / 300: loss 0.631296\n",
      "iteration 19 / 300: loss 0.634590\n",
      "iteration 19 / 300: loss 0.640205\n",
      "iteration 19 / 300: loss 0.651661\n",
      "iteration 19 / 300: loss 0.623101\n",
      "iteration 19 / 300: loss 0.661978\n",
      "iteration 19 / 300: loss 0.634163\n",
      "iteration 19 / 300: loss 0.661580\n",
      "iteration 19 / 300: loss 0.633671\n",
      "iteration 19 / 300: loss 0.639547\n",
      "iteration 19 / 300: loss 0.610289\n",
      "iteration 19 / 300: loss 0.632781\n",
      "iteration 19 / 300: loss 0.644246\n",
      "iteration 19 / 300: loss 0.635450\n",
      "iteration 19 / 300: loss 0.626086\n",
      "iteration 19 / 300: loss 0.657590\n",
      "iteration 19 / 300: loss 0.624425\n",
      "iteration 19 / 300: loss 0.627734\n",
      "iteration 19 / 300: loss 0.631048\n",
      "iteration 19 / 300: loss 0.638523\n",
      "iteration 19 / 300: loss 0.637208\n",
      "iteration 19 / 300: loss 0.650906\n",
      "iteration 19 / 300: loss 0.644232\n",
      "iteration 19 / 300: loss 0.635933\n",
      "iteration 19 / 300: loss 0.630725\n",
      "iteration 19 / 300: loss 0.659075\n",
      "iteration 19 / 300: loss 0.637585\n",
      "iteration 19 / 300: loss 0.631986\n",
      "iteration 19 / 300: loss 0.658933\n",
      "iteration 19 / 300: loss 0.616092\n",
      "iteration 19 / 300: loss 0.632796\n",
      "iteration 19 / 300: loss 0.637797\n",
      "iteration 19 / 300: loss 0.635492\n",
      "iteration 19 / 300: loss 0.635303\n",
      "iteration 19 / 300: loss 0.628215\n",
      "iteration 19 / 300: loss 0.625896\n",
      "iteration 19 / 300: loss 0.648747\n",
      "iteration 19 / 300: loss 0.652822\n",
      "iteration 19 / 300: loss 0.627772\n",
      "iteration 19 / 300: loss 0.621150\n",
      "iteration 19 / 300: loss 0.622491\n",
      "iteration 19 / 300: loss 0.633531\n",
      "iteration 19 / 300: loss 0.618112\n",
      "iteration 19 / 300: loss 0.616609\n",
      "iteration 19 / 300: loss 0.614270\n",
      "iteration 19 / 300: loss 0.606939\n",
      "iteration 19 / 300: loss 0.634687\n",
      "iteration 19 / 300: loss 0.619270\n",
      "iteration 19 / 300: loss 0.621438\n",
      "iteration 19 / 300: loss 0.604748\n",
      "iteration 19 / 300: loss 0.629934\n",
      "iteration 19 / 300: loss 0.651441\n",
      "iteration 19 / 300: loss 0.643297\n",
      "iteration 19 / 300: loss 0.647993\n",
      "iteration 19 / 300: loss 0.628041\n",
      "iteration 19 / 300: loss 0.633554\n",
      "iteration 19 / 300: loss 0.637169\n",
      "iteration 19 / 300: loss 0.633118\n",
      "iteration 19 / 300: loss 0.636383\n",
      "iteration 19 / 300: loss 0.633250\n",
      "iteration 19 / 300: loss 0.631661\n",
      "iteration 19 / 300: loss 0.621301\n",
      "iteration 19 / 300: loss 0.640393\n",
      "iteration 19 / 300: loss 0.638607\n",
      "iteration 19 / 300: loss 0.654423\n",
      "iteration 19 / 300: loss 0.631689\n",
      "iteration 19 / 300: loss 0.633212\n",
      "iteration 19 / 300: loss 0.639584\n",
      "iteration 19 / 300: loss 0.636043\n",
      "iteration 19 / 300: loss 0.626226\n",
      "iteration 19 / 300: loss 0.618809\n",
      "iteration 19 / 300: loss 0.633514\n",
      "iteration 19 / 300: loss 0.649526\n",
      "iteration 19 / 300: loss 0.646731\n",
      "iteration 19 / 300: loss 0.620365\n",
      "iteration 19 / 300: loss 0.633785\n",
      "iteration 19 / 300: loss 0.642781\n",
      "iteration 19 / 300: loss 0.633729\n",
      "iteration 19 / 300: loss 0.641708\n",
      "iteration 19 / 300: loss 0.659444\n",
      "iteration 19 / 300: loss 0.617988\n",
      "iteration 19 / 300: loss 0.615543\n",
      "iteration 19 / 300: loss 0.663328\n",
      "iteration 19 / 300: loss 0.645146\n",
      "iteration 19 / 300: loss 0.641573\n",
      "iteration 19 / 300: loss 0.633635\n",
      "iteration 19 / 300: loss 0.647055\n",
      "iteration 19 / 300: loss 0.628876\n",
      "iteration 19 / 300: loss 0.622022\n",
      "iteration 19 / 300: loss 0.645125\n",
      "iteration 19 / 300: loss 0.644641\n",
      "iteration 19 / 300: loss 0.630439\n",
      "iteration 19 / 300: loss 0.625766\n",
      "iteration 19 / 300: loss 0.642922\n",
      "iteration 19 / 300: loss 0.633690\n",
      "iteration 19 / 300: loss 0.617503\n",
      "iteration 19 / 300: loss 0.643777\n",
      "iteration 20 / 300: loss 0.611760\n",
      "iteration 20 / 300: loss 0.626639\n",
      "iteration 20 / 300: loss 0.600632\n",
      "iteration 20 / 300: loss 0.627997\n",
      "iteration 20 / 300: loss 0.631623\n",
      "iteration 20 / 300: loss 0.636726\n",
      "iteration 20 / 300: loss 0.647945\n",
      "iteration 20 / 300: loss 0.619845\n",
      "iteration 20 / 300: loss 0.658057\n",
      "iteration 20 / 300: loss 0.630618\n",
      "iteration 20 / 300: loss 0.657863\n",
      "iteration 20 / 300: loss 0.630308\n",
      "iteration 20 / 300: loss 0.635880\n",
      "iteration 20 / 300: loss 0.606370\n",
      "iteration 20 / 300: loss 0.629830\n",
      "iteration 20 / 300: loss 0.640396\n",
      "iteration 20 / 300: loss 0.632066\n",
      "iteration 20 / 300: loss 0.622705\n",
      "iteration 20 / 300: loss 0.654283\n",
      "iteration 20 / 300: loss 0.621574\n",
      "iteration 20 / 300: loss 0.623941\n",
      "iteration 20 / 300: loss 0.627472\n",
      "iteration 20 / 300: loss 0.634895\n",
      "iteration 20 / 300: loss 0.632906\n",
      "iteration 20 / 300: loss 0.648309\n",
      "iteration 20 / 300: loss 0.641096\n",
      "iteration 20 / 300: loss 0.632681\n",
      "iteration 20 / 300: loss 0.627647\n",
      "iteration 20 / 300: loss 0.656024\n",
      "iteration 20 / 300: loss 0.634284\n",
      "iteration 20 / 300: loss 0.628464\n",
      "iteration 20 / 300: loss 0.655352\n",
      "iteration 20 / 300: loss 0.612433\n",
      "iteration 20 / 300: loss 0.629589\n",
      "iteration 20 / 300: loss 0.633736\n",
      "iteration 20 / 300: loss 0.632371\n",
      "iteration 20 / 300: loss 0.631795\n",
      "iteration 20 / 300: loss 0.624547\n",
      "iteration 20 / 300: loss 0.623032\n",
      "iteration 20 / 300: loss 0.645326\n",
      "iteration 20 / 300: loss 0.649481\n",
      "iteration 20 / 300: loss 0.624292\n",
      "iteration 20 / 300: loss 0.617424\n",
      "iteration 20 / 300: loss 0.619270\n",
      "iteration 20 / 300: loss 0.630198\n",
      "iteration 20 / 300: loss 0.614729\n",
      "iteration 20 / 300: loss 0.613258\n",
      "iteration 20 / 300: loss 0.610448\n",
      "iteration 20 / 300: loss 0.603793\n",
      "iteration 20 / 300: loss 0.631900\n",
      "iteration 20 / 300: loss 0.615844\n",
      "iteration 20 / 300: loss 0.617783\n",
      "iteration 20 / 300: loss 0.601391\n",
      "iteration 20 / 300: loss 0.626731\n",
      "iteration 20 / 300: loss 0.648804\n",
      "iteration 20 / 300: loss 0.640075\n",
      "iteration 20 / 300: loss 0.644080\n",
      "iteration 20 / 300: loss 0.625014\n",
      "iteration 20 / 300: loss 0.630105\n",
      "iteration 20 / 300: loss 0.634347\n",
      "iteration 20 / 300: loss 0.630020\n",
      "iteration 20 / 300: loss 0.632965\n",
      "iteration 20 / 300: loss 0.630686\n",
      "iteration 20 / 300: loss 0.628982\n",
      "iteration 20 / 300: loss 0.617910\n",
      "iteration 20 / 300: loss 0.636810\n",
      "iteration 20 / 300: loss 0.635587\n",
      "iteration 20 / 300: loss 0.650941\n",
      "iteration 20 / 300: loss 0.628631\n",
      "iteration 20 / 300: loss 0.630602\n",
      "iteration 20 / 300: loss 0.636443\n",
      "iteration 20 / 300: loss 0.632948\n",
      "iteration 20 / 300: loss 0.622789\n",
      "iteration 20 / 300: loss 0.615131\n",
      "iteration 20 / 300: loss 0.629947\n",
      "iteration 20 / 300: loss 0.646413\n",
      "iteration 20 / 300: loss 0.644081\n",
      "iteration 20 / 300: loss 0.617399\n",
      "iteration 20 / 300: loss 0.630992\n",
      "iteration 20 / 300: loss 0.639531\n",
      "iteration 20 / 300: loss 0.630545\n",
      "iteration 20 / 300: loss 0.638852\n",
      "iteration 20 / 300: loss 0.655843\n",
      "iteration 20 / 300: loss 0.615358\n",
      "iteration 20 / 300: loss 0.612314\n",
      "iteration 20 / 300: loss 0.660862\n",
      "iteration 20 / 300: loss 0.641737\n",
      "iteration 20 / 300: loss 0.638794\n",
      "iteration 20 / 300: loss 0.630305\n",
      "iteration 20 / 300: loss 0.643823\n",
      "iteration 20 / 300: loss 0.626149\n",
      "iteration 20 / 300: loss 0.618668\n",
      "iteration 20 / 300: loss 0.642914\n",
      "iteration 20 / 300: loss 0.641697\n",
      "iteration 20 / 300: loss 0.627535\n",
      "iteration 20 / 300: loss 0.623198\n",
      "iteration 20 / 300: loss 0.640122\n",
      "iteration 20 / 300: loss 0.630094\n",
      "iteration 20 / 300: loss 0.614448\n",
      "iteration 20 / 300: loss 0.640782\n",
      "iteration 21 / 300: loss 0.608988\n",
      "iteration 21 / 300: loss 0.623742\n",
      "iteration 21 / 300: loss 0.597937\n",
      "iteration 21 / 300: loss 0.624992\n",
      "iteration 21 / 300: loss 0.628637\n",
      "iteration 21 / 300: loss 0.633706\n",
      "iteration 21 / 300: loss 0.645231\n",
      "iteration 21 / 300: loss 0.616646\n",
      "iteration 21 / 300: loss 0.654816\n",
      "iteration 21 / 300: loss 0.627803\n",
      "iteration 21 / 300: loss 0.655414\n",
      "iteration 21 / 300: loss 0.627259\n",
      "iteration 21 / 300: loss 0.633052\n",
      "iteration 21 / 300: loss 0.603235\n",
      "iteration 21 / 300: loss 0.627425\n",
      "iteration 21 / 300: loss 0.636770\n",
      "iteration 21 / 300: loss 0.628827\n",
      "iteration 21 / 300: loss 0.619372\n",
      "iteration 21 / 300: loss 0.650667\n",
      "iteration 21 / 300: loss 0.619043\n",
      "iteration 21 / 300: loss 0.621010\n",
      "iteration 21 / 300: loss 0.624047\n",
      "iteration 21 / 300: loss 0.631805\n",
      "iteration 21 / 300: loss 0.629187\n",
      "iteration 21 / 300: loss 0.645789\n",
      "iteration 21 / 300: loss 0.638210\n",
      "iteration 21 / 300: loss 0.629937\n",
      "iteration 21 / 300: loss 0.625153\n",
      "iteration 21 / 300: loss 0.653126\n",
      "iteration 21 / 300: loss 0.631431\n",
      "iteration 21 / 300: loss 0.625426\n",
      "iteration 21 / 300: loss 0.652258\n",
      "iteration 21 / 300: loss 0.609088\n",
      "iteration 21 / 300: loss 0.626439\n",
      "iteration 21 / 300: loss 0.630116\n",
      "iteration 21 / 300: loss 0.629706\n",
      "iteration 21 / 300: loss 0.628586\n",
      "iteration 21 / 300: loss 0.621150\n",
      "iteration 21 / 300: loss 0.620466\n",
      "iteration 21 / 300: loss 0.642357\n",
      "iteration 21 / 300: loss 0.646237\n",
      "iteration 21 / 300: loss 0.620910\n",
      "iteration 21 / 300: loss 0.614001\n",
      "iteration 21 / 300: loss 0.616064\n",
      "iteration 21 / 300: loss 0.627174\n",
      "iteration 21 / 300: loss 0.611823\n",
      "iteration 21 / 300: loss 0.610161\n",
      "iteration 21 / 300: loss 0.606859\n",
      "iteration 21 / 300: loss 0.601035\n",
      "iteration 21 / 300: loss 0.629143\n",
      "iteration 21 / 300: loss 0.612890\n",
      "iteration 21 / 300: loss 0.614763\n",
      "iteration 21 / 300: loss 0.598306\n",
      "iteration 21 / 300: loss 0.623803\n",
      "iteration 21 / 300: loss 0.646299\n",
      "iteration 21 / 300: loss 0.637248\n",
      "iteration 21 / 300: loss 0.640686\n",
      "iteration 21 / 300: loss 0.622331\n",
      "iteration 21 / 300: loss 0.626879\n",
      "iteration 21 / 300: loss 0.631869\n",
      "iteration 21 / 300: loss 0.627374\n",
      "iteration 21 / 300: loss 0.629972\n",
      "iteration 21 / 300: loss 0.628250\n",
      "iteration 21 / 300: loss 0.626481\n",
      "iteration 21 / 300: loss 0.615225\n",
      "iteration 21 / 300: loss 0.633705\n",
      "iteration 21 / 300: loss 0.632701\n",
      "iteration 21 / 300: loss 0.647927\n",
      "iteration 21 / 300: loss 0.625779\n",
      "iteration 21 / 300: loss 0.628199\n",
      "iteration 21 / 300: loss 0.633691\n",
      "iteration 21 / 300: loss 0.630511\n",
      "iteration 21 / 300: loss 0.619977\n",
      "iteration 21 / 300: loss 0.611865\n",
      "iteration 21 / 300: loss 0.626900\n",
      "iteration 21 / 300: loss 0.643324\n",
      "iteration 21 / 300: loss 0.641613\n",
      "iteration 21 / 300: loss 0.614537\n",
      "iteration 21 / 300: loss 0.628266\n",
      "iteration 21 / 300: loss 0.636406\n",
      "iteration 21 / 300: loss 0.627770\n",
      "iteration 21 / 300: loss 0.636564\n",
      "iteration 21 / 300: loss 0.652464\n",
      "iteration 21 / 300: loss 0.612859\n",
      "iteration 21 / 300: loss 0.609518\n",
      "iteration 21 / 300: loss 0.657936\n",
      "iteration 21 / 300: loss 0.638902\n",
      "iteration 21 / 300: loss 0.635978\n",
      "iteration 21 / 300: loss 0.627377\n",
      "iteration 21 / 300: loss 0.640794\n",
      "iteration 21 / 300: loss 0.623637\n",
      "iteration 21 / 300: loss 0.615802\n",
      "iteration 21 / 300: loss 0.640800\n",
      "iteration 21 / 300: loss 0.638967\n",
      "iteration 21 / 300: loss 0.624629\n",
      "iteration 21 / 300: loss 0.620726\n",
      "iteration 21 / 300: loss 0.637621\n",
      "iteration 21 / 300: loss 0.626801\n",
      "iteration 21 / 300: loss 0.611652\n",
      "iteration 21 / 300: loss 0.638061\n",
      "iteration 22 / 300: loss 0.606459\n",
      "iteration 22 / 300: loss 0.621166\n",
      "iteration 22 / 300: loss 0.595489\n",
      "iteration 22 / 300: loss 0.622721\n",
      "iteration 22 / 300: loss 0.625984\n",
      "iteration 22 / 300: loss 0.631051\n",
      "iteration 22 / 300: loss 0.642602\n",
      "iteration 22 / 300: loss 0.613860\n",
      "iteration 22 / 300: loss 0.652374\n",
      "iteration 22 / 300: loss 0.625345\n",
      "iteration 22 / 300: loss 0.652559\n",
      "iteration 22 / 300: loss 0.624383\n",
      "iteration 22 / 300: loss 0.630523\n",
      "iteration 22 / 300: loss 0.600842\n",
      "iteration 22 / 300: loss 0.624727\n",
      "iteration 22 / 300: loss 0.634318\n",
      "iteration 22 / 300: loss 0.625909\n",
      "iteration 22 / 300: loss 0.616369\n",
      "iteration 22 / 300: loss 0.647643\n",
      "iteration 22 / 300: loss 0.616857\n",
      "iteration 22 / 300: loss 0.618713\n",
      "iteration 22 / 300: loss 0.621367\n",
      "iteration 22 / 300: loss 0.628950\n",
      "iteration 22 / 300: loss 0.625925\n",
      "iteration 22 / 300: loss 0.643393\n",
      "iteration 22 / 300: loss 0.635555\n",
      "iteration 22 / 300: loss 0.626904\n",
      "iteration 22 / 300: loss 0.622688\n",
      "iteration 22 / 300: loss 0.650650\n",
      "iteration 22 / 300: loss 0.629009\n",
      "iteration 22 / 300: loss 0.622928\n",
      "iteration 22 / 300: loss 0.649694\n",
      "iteration 22 / 300: loss 0.606356\n",
      "iteration 22 / 300: loss 0.623583\n",
      "iteration 22 / 300: loss 0.626901\n",
      "iteration 22 / 300: loss 0.627282\n",
      "iteration 22 / 300: loss 0.625790\n",
      "iteration 22 / 300: loss 0.618337\n",
      "iteration 22 / 300: loss 0.618073\n",
      "iteration 22 / 300: loss 0.639828\n",
      "iteration 22 / 300: loss 0.643028\n",
      "iteration 22 / 300: loss 0.617937\n",
      "iteration 22 / 300: loss 0.611036\n",
      "iteration 22 / 300: loss 0.613172\n",
      "iteration 22 / 300: loss 0.624954\n",
      "iteration 22 / 300: loss 0.609291\n",
      "iteration 22 / 300: loss 0.607199\n",
      "iteration 22 / 300: loss 0.603961\n",
      "iteration 22 / 300: loss 0.598537\n",
      "iteration 22 / 300: loss 0.626281\n",
      "iteration 22 / 300: loss 0.610299\n",
      "iteration 22 / 300: loss 0.612133\n",
      "iteration 22 / 300: loss 0.595974\n",
      "iteration 22 / 300: loss 0.621190\n",
      "iteration 22 / 300: loss 0.643936\n",
      "iteration 22 / 300: loss 0.634779\n",
      "iteration 22 / 300: loss 0.637785\n",
      "iteration 22 / 300: loss 0.619924\n",
      "iteration 22 / 300: loss 0.623786\n",
      "iteration 22 / 300: loss 0.629478\n",
      "iteration 22 / 300: loss 0.625038\n",
      "iteration 22 / 300: loss 0.627214\n",
      "iteration 22 / 300: loss 0.625939\n",
      "iteration 22 / 300: loss 0.624005\n",
      "iteration 22 / 300: loss 0.613018\n",
      "iteration 22 / 300: loss 0.631025\n",
      "iteration 22 / 300: loss 0.629795\n",
      "iteration 22 / 300: loss 0.645302\n",
      "iteration 22 / 300: loss 0.623004\n",
      "iteration 22 / 300: loss 0.625948\n",
      "iteration 22 / 300: loss 0.631143\n",
      "iteration 22 / 300: loss 0.628173\n",
      "iteration 22 / 300: loss 0.617549\n",
      "iteration 22 / 300: loss 0.608840\n",
      "iteration 22 / 300: loss 0.624147\n",
      "iteration 22 / 300: loss 0.640453\n",
      "iteration 22 / 300: loss 0.639613\n",
      "iteration 22 / 300: loss 0.611682\n",
      "iteration 22 / 300: loss 0.625717\n",
      "iteration 22 / 300: loss 0.633843\n",
      "iteration 22 / 300: loss 0.625333\n",
      "iteration 22 / 300: loss 0.634255\n",
      "iteration 22 / 300: loss 0.649207\n",
      "iteration 22 / 300: loss 0.610230\n",
      "iteration 22 / 300: loss 0.607137\n",
      "iteration 22 / 300: loss 0.655207\n",
      "iteration 22 / 300: loss 0.636233\n",
      "iteration 22 / 300: loss 0.633622\n",
      "iteration 22 / 300: loss 0.624810\n",
      "iteration 22 / 300: loss 0.638221\n",
      "iteration 22 / 300: loss 0.620989\n",
      "iteration 22 / 300: loss 0.613148\n",
      "iteration 22 / 300: loss 0.638673\n",
      "iteration 22 / 300: loss 0.636400\n",
      "iteration 22 / 300: loss 0.622054\n",
      "iteration 22 / 300: loss 0.618284\n",
      "iteration 22 / 300: loss 0.635335\n",
      "iteration 22 / 300: loss 0.623839\n",
      "iteration 22 / 300: loss 0.609053\n",
      "iteration 22 / 300: loss 0.635692\n",
      "iteration 23 / 300: loss 0.604278\n",
      "iteration 23 / 300: loss 0.618735\n",
      "iteration 23 / 300: loss 0.593203\n",
      "iteration 23 / 300: loss 0.620739\n",
      "iteration 23 / 300: loss 0.623807\n",
      "iteration 23 / 300: loss 0.628814\n",
      "iteration 23 / 300: loss 0.640245\n",
      "iteration 23 / 300: loss 0.611333\n",
      "iteration 23 / 300: loss 0.650162\n",
      "iteration 23 / 300: loss 0.622994\n",
      "iteration 23 / 300: loss 0.649893\n",
      "iteration 23 / 300: loss 0.621587\n",
      "iteration 23 / 300: loss 0.628087\n",
      "iteration 23 / 300: loss 0.598666\n",
      "iteration 23 / 300: loss 0.622517\n",
      "iteration 23 / 300: loss 0.631928\n",
      "iteration 23 / 300: loss 0.622941\n",
      "iteration 23 / 300: loss 0.613902\n",
      "iteration 23 / 300: loss 0.645158\n",
      "iteration 23 / 300: loss 0.615160\n",
      "iteration 23 / 300: loss 0.616257\n",
      "iteration 23 / 300: loss 0.619093\n",
      "iteration 23 / 300: loss 0.626361\n",
      "iteration 23 / 300: loss 0.623081\n",
      "iteration 23 / 300: loss 0.640958\n",
      "iteration 23 / 300: loss 0.633052\n",
      "iteration 23 / 300: loss 0.624020\n",
      "iteration 23 / 300: loss 0.620254\n",
      "iteration 23 / 300: loss 0.648328\n",
      "iteration 23 / 300: loss 0.626780\n",
      "iteration 23 / 300: loss 0.620664\n",
      "iteration 23 / 300: loss 0.647099\n",
      "iteration 23 / 300: loss 0.604037\n",
      "iteration 23 / 300: loss 0.620744\n",
      "iteration 23 / 300: loss 0.624017\n",
      "iteration 23 / 300: loss 0.625192\n",
      "iteration 23 / 300: loss 0.623185\n",
      "iteration 23 / 300: loss 0.615978\n",
      "iteration 23 / 300: loss 0.615946\n",
      "iteration 23 / 300: loss 0.638078\n",
      "iteration 23 / 300: loss 0.640482\n",
      "iteration 23 / 300: loss 0.615302\n",
      "iteration 23 / 300: loss 0.608360\n",
      "iteration 23 / 300: loss 0.610712\n",
      "iteration 23 / 300: loss 0.622775\n",
      "iteration 23 / 300: loss 0.606955\n",
      "iteration 23 / 300: loss 0.604616\n",
      "iteration 23 / 300: loss 0.601458\n",
      "iteration 23 / 300: loss 0.596398\n",
      "iteration 23 / 300: loss 0.623579\n",
      "iteration 23 / 300: loss 0.608079\n",
      "iteration 23 / 300: loss 0.609708\n",
      "iteration 23 / 300: loss 0.593778\n",
      "iteration 23 / 300: loss 0.618791\n",
      "iteration 23 / 300: loss 0.641754\n",
      "iteration 23 / 300: loss 0.632494\n",
      "iteration 23 / 300: loss 0.635399\n",
      "iteration 23 / 300: loss 0.617867\n",
      "iteration 23 / 300: loss 0.621045\n",
      "iteration 23 / 300: loss 0.627029\n",
      "iteration 23 / 300: loss 0.622802\n",
      "iteration 23 / 300: loss 0.624776\n",
      "iteration 23 / 300: loss 0.623728\n",
      "iteration 23 / 300: loss 0.621730\n",
      "iteration 23 / 300: loss 0.610819\n",
      "iteration 23 / 300: loss 0.628654\n",
      "iteration 23 / 300: loss 0.627049\n",
      "iteration 23 / 300: loss 0.642664\n",
      "iteration 23 / 300: loss 0.620790\n",
      "iteration 23 / 300: loss 0.623754\n",
      "iteration 23 / 300: loss 0.628857\n",
      "iteration 23 / 300: loss 0.625754\n",
      "iteration 23 / 300: loss 0.615340\n",
      "iteration 23 / 300: loss 0.606161\n",
      "iteration 23 / 300: loss 0.621660\n",
      "iteration 23 / 300: loss 0.637857\n",
      "iteration 23 / 300: loss 0.637868\n",
      "iteration 23 / 300: loss 0.608770\n",
      "iteration 23 / 300: loss 0.623540\n",
      "iteration 23 / 300: loss 0.631777\n",
      "iteration 23 / 300: loss 0.623183\n",
      "iteration 23 / 300: loss 0.632035\n",
      "iteration 23 / 300: loss 0.646433\n",
      "iteration 23 / 300: loss 0.607864\n",
      "iteration 23 / 300: loss 0.605096\n",
      "iteration 23 / 300: loss 0.652713\n",
      "iteration 23 / 300: loss 0.633786\n",
      "iteration 23 / 300: loss 0.631705\n",
      "iteration 23 / 300: loss 0.622511\n",
      "iteration 23 / 300: loss 0.635925\n",
      "iteration 23 / 300: loss 0.618659\n",
      "iteration 23 / 300: loss 0.610758\n",
      "iteration 23 / 300: loss 0.636698\n",
      "iteration 23 / 300: loss 0.634187\n",
      "iteration 23 / 300: loss 0.619898\n",
      "iteration 23 / 300: loss 0.615939\n",
      "iteration 23 / 300: loss 0.633157\n",
      "iteration 23 / 300: loss 0.621111\n",
      "iteration 23 / 300: loss 0.606455\n",
      "iteration 23 / 300: loss 0.633972\n",
      "iteration 24 / 300: loss 0.602485\n",
      "iteration 24 / 300: loss 0.616455\n",
      "iteration 24 / 300: loss 0.591043\n",
      "iteration 24 / 300: loss 0.618964\n",
      "iteration 24 / 300: loss 0.622046\n",
      "iteration 24 / 300: loss 0.626961\n",
      "iteration 24 / 300: loss 0.638169\n",
      "iteration 24 / 300: loss 0.609180\n",
      "iteration 24 / 300: loss 0.648292\n",
      "iteration 24 / 300: loss 0.620682\n",
      "iteration 24 / 300: loss 0.647516\n",
      "iteration 24 / 300: loss 0.619405\n",
      "iteration 24 / 300: loss 0.625657\n",
      "iteration 24 / 300: loss 0.596499\n",
      "iteration 24 / 300: loss 0.620452\n",
      "iteration 24 / 300: loss 0.629936\n",
      "iteration 24 / 300: loss 0.620082\n",
      "iteration 24 / 300: loss 0.611583\n",
      "iteration 24 / 300: loss 0.642972\n",
      "iteration 24 / 300: loss 0.613815\n",
      "iteration 24 / 300: loss 0.614217\n",
      "iteration 24 / 300: loss 0.617247\n",
      "iteration 24 / 300: loss 0.624019\n",
      "iteration 24 / 300: loss 0.620816\n",
      "iteration 24 / 300: loss 0.638493\n",
      "iteration 24 / 300: loss 0.630985\n",
      "iteration 24 / 300: loss 0.621361\n",
      "iteration 24 / 300: loss 0.618096\n",
      "iteration 24 / 300: loss 0.646275\n",
      "iteration 24 / 300: loss 0.624867\n",
      "iteration 24 / 300: loss 0.618645\n",
      "iteration 24 / 300: loss 0.644778\n",
      "iteration 24 / 300: loss 0.601796\n",
      "iteration 24 / 300: loss 0.618253\n",
      "iteration 24 / 300: loss 0.621438\n",
      "iteration 24 / 300: loss 0.623340\n",
      "iteration 24 / 300: loss 0.620686\n",
      "iteration 24 / 300: loss 0.613810\n",
      "iteration 24 / 300: loss 0.614028\n",
      "iteration 24 / 300: loss 0.636551\n",
      "iteration 24 / 300: loss 0.638279\n",
      "iteration 24 / 300: loss 0.613013\n",
      "iteration 24 / 300: loss 0.606130\n",
      "iteration 24 / 300: loss 0.608657\n",
      "iteration 24 / 300: loss 0.620794\n",
      "iteration 24 / 300: loss 0.604808\n",
      "iteration 24 / 300: loss 0.602250\n",
      "iteration 24 / 300: loss 0.599234\n",
      "iteration 24 / 300: loss 0.594333\n",
      "iteration 24 / 300: loss 0.621188\n",
      "iteration 24 / 300: loss 0.605916\n",
      "iteration 24 / 300: loss 0.607486\n",
      "iteration 24 / 300: loss 0.591556\n",
      "iteration 24 / 300: loss 0.616555\n",
      "iteration 24 / 300: loss 0.639471\n",
      "iteration 24 / 300: loss 0.630362\n",
      "iteration 24 / 300: loss 0.633312\n",
      "iteration 24 / 300: loss 0.616066\n",
      "iteration 24 / 300: loss 0.618521\n",
      "iteration 24 / 300: loss 0.624581\n",
      "iteration 24 / 300: loss 0.620588\n",
      "iteration 24 / 300: loss 0.622782\n",
      "iteration 24 / 300: loss 0.621629\n",
      "iteration 24 / 300: loss 0.619609\n",
      "iteration 24 / 300: loss 0.608766\n",
      "iteration 24 / 300: loss 0.626481\n",
      "iteration 24 / 300: loss 0.624547\n",
      "iteration 24 / 300: loss 0.640144\n",
      "iteration 24 / 300: loss 0.618969\n",
      "iteration 24 / 300: loss 0.621676\n",
      "iteration 24 / 300: loss 0.626895\n",
      "iteration 24 / 300: loss 0.623459\n",
      "iteration 24 / 300: loss 0.613467\n",
      "iteration 24 / 300: loss 0.603815\n",
      "iteration 24 / 300: loss 0.619350\n",
      "iteration 24 / 300: loss 0.635532\n",
      "iteration 24 / 300: loss 0.636032\n",
      "iteration 24 / 300: loss 0.606192\n",
      "iteration 24 / 300: loss 0.621574\n",
      "iteration 24 / 300: loss 0.630002\n",
      "iteration 24 / 300: loss 0.621076\n",
      "iteration 24 / 300: loss 0.630013\n",
      "iteration 24 / 300: loss 0.644014\n",
      "iteration 24 / 300: loss 0.605805\n",
      "iteration 24 / 300: loss 0.603225\n",
      "iteration 24 / 300: loss 0.650448\n",
      "iteration 24 / 300: loss 0.631475\n",
      "iteration 24 / 300: loss 0.629945\n",
      "iteration 24 / 300: loss 0.620421\n",
      "iteration 24 / 300: loss 0.633977\n",
      "iteration 24 / 300: loss 0.616572\n",
      "iteration 24 / 300: loss 0.608517\n",
      "iteration 24 / 300: loss 0.634828\n",
      "iteration 24 / 300: loss 0.632154\n",
      "iteration 24 / 300: loss 0.618304\n",
      "iteration 24 / 300: loss 0.613805\n",
      "iteration 24 / 300: loss 0.631611\n",
      "iteration 24 / 300: loss 0.618576\n",
      "iteration 24 / 300: loss 0.604037\n",
      "iteration 24 / 300: loss 0.632450\n",
      "iteration 25 / 300: loss 0.601154\n",
      "iteration 25 / 300: loss 0.614734\n",
      "iteration 25 / 300: loss 0.589238\n",
      "iteration 25 / 300: loss 0.617369\n",
      "iteration 25 / 300: loss 0.620304\n",
      "iteration 25 / 300: loss 0.625439\n",
      "iteration 25 / 300: loss 0.636353\n",
      "iteration 25 / 300: loss 0.607419\n",
      "iteration 25 / 300: loss 0.646812\n",
      "iteration 25 / 300: loss 0.618379\n",
      "iteration 25 / 300: loss 0.645396\n",
      "iteration 25 / 300: loss 0.617407\n",
      "iteration 25 / 300: loss 0.623444\n",
      "iteration 25 / 300: loss 0.594351\n",
      "iteration 25 / 300: loss 0.618309\n",
      "iteration 25 / 300: loss 0.628139\n",
      "iteration 25 / 300: loss 0.617665\n",
      "iteration 25 / 300: loss 0.609374\n",
      "iteration 25 / 300: loss 0.640908\n",
      "iteration 25 / 300: loss 0.612294\n",
      "iteration 25 / 300: loss 0.612422\n",
      "iteration 25 / 300: loss 0.615609\n",
      "iteration 25 / 300: loss 0.621868\n",
      "iteration 25 / 300: loss 0.618763\n",
      "iteration 25 / 300: loss 0.636103\n",
      "iteration 25 / 300: loss 0.629398\n",
      "iteration 25 / 300: loss 0.619098\n",
      "iteration 25 / 300: loss 0.616206\n",
      "iteration 25 / 300: loss 0.644598\n",
      "iteration 25 / 300: loss 0.623116\n",
      "iteration 25 / 300: loss 0.616932\n",
      "iteration 25 / 300: loss 0.642767\n",
      "iteration 25 / 300: loss 0.599750\n",
      "iteration 25 / 300: loss 0.616273\n",
      "iteration 25 / 300: loss 0.619098\n",
      "iteration 25 / 300: loss 0.621648\n",
      "iteration 25 / 300: loss 0.618399\n",
      "iteration 25 / 300: loss 0.611716\n",
      "iteration 25 / 300: loss 0.612279\n",
      "iteration 25 / 300: loss 0.635143\n",
      "iteration 25 / 300: loss 0.636303\n",
      "iteration 25 / 300: loss 0.611184\n",
      "iteration 25 / 300: loss 0.604292\n",
      "iteration 25 / 300: loss 0.606886\n",
      "iteration 25 / 300: loss 0.619163\n",
      "iteration 25 / 300: loss 0.602765\n",
      "iteration 25 / 300: loss 0.600183\n",
      "iteration 25 / 300: loss 0.597087\n",
      "iteration 25 / 300: loss 0.592255\n",
      "iteration 25 / 300: loss 0.619079\n",
      "iteration 25 / 300: loss 0.603686\n",
      "iteration 25 / 300: loss 0.605372\n",
      "iteration 25 / 300: loss 0.589665\n",
      "iteration 25 / 300: loss 0.614659\n",
      "iteration 25 / 300: loss 0.637365\n",
      "iteration 25 / 300: loss 0.628495\n",
      "iteration 25 / 300: loss 0.631480\n",
      "iteration 25 / 300: loss 0.614474\n",
      "iteration 25 / 300: loss 0.616255\n",
      "iteration 25 / 300: loss 0.622394\n",
      "iteration 25 / 300: loss 0.618681\n",
      "iteration 25 / 300: loss 0.620974\n",
      "iteration 25 / 300: loss 0.619857\n",
      "iteration 25 / 300: loss 0.617733\n",
      "iteration 25 / 300: loss 0.607079\n",
      "iteration 25 / 300: loss 0.624425\n",
      "iteration 25 / 300: loss 0.622312\n",
      "iteration 25 / 300: loss 0.637926\n",
      "iteration 25 / 300: loss 0.617447\n",
      "iteration 25 / 300: loss 0.619832\n",
      "iteration 25 / 300: loss 0.625368\n",
      "iteration 25 / 300: loss 0.621302\n",
      "iteration 25 / 300: loss 0.611826\n",
      "iteration 25 / 300: loss 0.601505\n",
      "iteration 25 / 300: loss 0.617311\n",
      "iteration 25 / 300: loss 0.633591\n",
      "iteration 25 / 300: loss 0.633923\n",
      "iteration 25 / 300: loss 0.603837\n",
      "iteration 25 / 300: loss 0.619682\n",
      "iteration 25 / 300: loss 0.628416\n",
      "iteration 25 / 300: loss 0.619102\n",
      "iteration 25 / 300: loss 0.628138\n",
      "iteration 25 / 300: loss 0.641881\n",
      "iteration 25 / 300: loss 0.604048\n",
      "iteration 25 / 300: loss 0.601488\n",
      "iteration 25 / 300: loss 0.648386\n",
      "iteration 25 / 300: loss 0.629307\n",
      "iteration 25 / 300: loss 0.628194\n",
      "iteration 25 / 300: loss 0.618520\n",
      "iteration 25 / 300: loss 0.632335\n",
      "iteration 25 / 300: loss 0.614610\n",
      "iteration 25 / 300: loss 0.606392\n",
      "iteration 25 / 300: loss 0.632941\n",
      "iteration 25 / 300: loss 0.630079\n",
      "iteration 25 / 300: loss 0.616654\n",
      "iteration 25 / 300: loss 0.611784\n",
      "iteration 25 / 300: loss 0.630084\n",
      "iteration 25 / 300: loss 0.616580\n",
      "iteration 25 / 300: loss 0.601960\n",
      "iteration 25 / 300: loss 0.630806\n",
      "iteration 26 / 300: loss 0.599787\n",
      "iteration 26 / 300: loss 0.612959\n",
      "iteration 26 / 300: loss 0.587652\n",
      "iteration 26 / 300: loss 0.615975\n",
      "iteration 26 / 300: loss 0.618589\n",
      "iteration 26 / 300: loss 0.624006\n",
      "iteration 26 / 300: loss 0.634690\n",
      "iteration 26 / 300: loss 0.605636\n",
      "iteration 26 / 300: loss 0.645364\n",
      "iteration 26 / 300: loss 0.616449\n",
      "iteration 26 / 300: loss 0.643551\n",
      "iteration 26 / 300: loss 0.615598\n",
      "iteration 26 / 300: loss 0.621242\n",
      "iteration 26 / 300: loss 0.592490\n",
      "iteration 26 / 300: loss 0.616335\n",
      "iteration 26 / 300: loss 0.626114\n",
      "iteration 26 / 300: loss 0.615658\n",
      "iteration 26 / 300: loss 0.607475\n",
      "iteration 26 / 300: loss 0.639173\n",
      "iteration 26 / 300: loss 0.610696\n",
      "iteration 26 / 300: loss 0.610707\n",
      "iteration 26 / 300: loss 0.614216\n",
      "iteration 26 / 300: loss 0.619917\n",
      "iteration 26 / 300: loss 0.617088\n",
      "iteration 26 / 300: loss 0.634042\n",
      "iteration 26 / 300: loss 0.628001\n",
      "iteration 26 / 300: loss 0.617204\n",
      "iteration 26 / 300: loss 0.614451\n",
      "iteration 26 / 300: loss 0.643028\n",
      "iteration 26 / 300: loss 0.621551\n",
      "iteration 26 / 300: loss 0.615404\n",
      "iteration 26 / 300: loss 0.640901\n",
      "iteration 26 / 300: loss 0.597862\n",
      "iteration 26 / 300: loss 0.614448\n",
      "iteration 26 / 300: loss 0.616926\n",
      "iteration 26 / 300: loss 0.620057\n",
      "iteration 26 / 300: loss 0.616229\n",
      "iteration 26 / 300: loss 0.609760\n",
      "iteration 26 / 300: loss 0.610682\n",
      "iteration 26 / 300: loss 0.633865\n",
      "iteration 26 / 300: loss 0.634775\n",
      "iteration 26 / 300: loss 0.609444\n",
      "iteration 26 / 300: loss 0.602696\n",
      "iteration 26 / 300: loss 0.605355\n",
      "iteration 26 / 300: loss 0.617848\n",
      "iteration 26 / 300: loss 0.600971\n",
      "iteration 26 / 300: loss 0.598484\n",
      "iteration 26 / 300: loss 0.595150\n",
      "iteration 26 / 300: loss 0.590376\n",
      "iteration 26 / 300: loss 0.617222\n",
      "iteration 26 / 300: loss 0.601600\n",
      "iteration 26 / 300: loss 0.603383\n",
      "iteration 26 / 300: loss 0.587925\n",
      "iteration 26 / 300: loss 0.612946\n",
      "iteration 26 / 300: loss 0.635466\n",
      "iteration 26 / 300: loss 0.626804\n",
      "iteration 26 / 300: loss 0.629739\n",
      "iteration 26 / 300: loss 0.612990\n",
      "iteration 26 / 300: loss 0.614227\n",
      "iteration 26 / 300: loss 0.620340\n",
      "iteration 26 / 300: loss 0.617090\n",
      "iteration 26 / 300: loss 0.619213\n",
      "iteration 26 / 300: loss 0.618237\n",
      "iteration 26 / 300: loss 0.616152\n",
      "iteration 26 / 300: loss 0.605695\n",
      "iteration 26 / 300: loss 0.622564\n",
      "iteration 26 / 300: loss 0.620289\n",
      "iteration 26 / 300: loss 0.636023\n",
      "iteration 26 / 300: loss 0.615989\n",
      "iteration 26 / 300: loss 0.618118\n",
      "iteration 26 / 300: loss 0.623807\n",
      "iteration 26 / 300: loss 0.619513\n",
      "iteration 26 / 300: loss 0.610100\n",
      "iteration 26 / 300: loss 0.599521\n",
      "iteration 26 / 300: loss 0.615469\n",
      "iteration 26 / 300: loss 0.631809\n",
      "iteration 26 / 300: loss 0.631946\n",
      "iteration 26 / 300: loss 0.601776\n",
      "iteration 26 / 300: loss 0.617926\n",
      "iteration 26 / 300: loss 0.626984\n",
      "iteration 26 / 300: loss 0.617413\n",
      "iteration 26 / 300: loss 0.626507\n",
      "iteration 26 / 300: loss 0.640015\n",
      "iteration 26 / 300: loss 0.602523\n",
      "iteration 26 / 300: loss 0.599916\n",
      "iteration 26 / 300: loss 0.646524\n",
      "iteration 26 / 300: loss 0.627426\n",
      "iteration 26 / 300: loss 0.626499\n",
      "iteration 26 / 300: loss 0.616705\n",
      "iteration 26 / 300: loss 0.630825\n",
      "iteration 26 / 300: loss 0.612838\n",
      "iteration 26 / 300: loss 0.604451\n",
      "iteration 26 / 300: loss 0.631212\n",
      "iteration 26 / 300: loss 0.628147\n",
      "iteration 26 / 300: loss 0.615252\n",
      "iteration 26 / 300: loss 0.610011\n",
      "iteration 26 / 300: loss 0.628793\n",
      "iteration 26 / 300: loss 0.614845\n",
      "iteration 26 / 300: loss 0.599990\n",
      "iteration 26 / 300: loss 0.629190\n",
      "iteration 27 / 300: loss 0.598446\n",
      "iteration 27 / 300: loss 0.611397\n",
      "iteration 27 / 300: loss 0.586220\n",
      "iteration 27 / 300: loss 0.614783\n",
      "iteration 27 / 300: loss 0.616985\n",
      "iteration 27 / 300: loss 0.622622\n",
      "iteration 27 / 300: loss 0.633145\n",
      "iteration 27 / 300: loss 0.604110\n",
      "iteration 27 / 300: loss 0.644016\n",
      "iteration 27 / 300: loss 0.614643\n",
      "iteration 27 / 300: loss 0.641886\n",
      "iteration 27 / 300: loss 0.613976\n",
      "iteration 27 / 300: loss 0.619264\n",
      "iteration 27 / 300: loss 0.590763\n",
      "iteration 27 / 300: loss 0.614563\n",
      "iteration 27 / 300: loss 0.624149\n",
      "iteration 27 / 300: loss 0.613915\n",
      "iteration 27 / 300: loss 0.605602\n",
      "iteration 27 / 300: loss 0.637652\n",
      "iteration 27 / 300: loss 0.609313\n",
      "iteration 27 / 300: loss 0.609095\n",
      "iteration 27 / 300: loss 0.612924\n",
      "iteration 27 / 300: loss 0.618369\n",
      "iteration 27 / 300: loss 0.615756\n",
      "iteration 27 / 300: loss 0.632284\n",
      "iteration 27 / 300: loss 0.626725\n",
      "iteration 27 / 300: loss 0.615497\n",
      "iteration 27 / 300: loss 0.612805\n",
      "iteration 27 / 300: loss 0.641428\n",
      "iteration 27 / 300: loss 0.620120\n",
      "iteration 27 / 300: loss 0.614061\n",
      "iteration 27 / 300: loss 0.639160\n",
      "iteration 27 / 300: loss 0.596268\n",
      "iteration 27 / 300: loss 0.612946\n",
      "iteration 27 / 300: loss 0.614913\n",
      "iteration 27 / 300: loss 0.618535\n",
      "iteration 27 / 300: loss 0.614257\n",
      "iteration 27 / 300: loss 0.608032\n",
      "iteration 27 / 300: loss 0.609192\n",
      "iteration 27 / 300: loss 0.632677\n",
      "iteration 27 / 300: loss 0.633499\n",
      "iteration 27 / 300: loss 0.607586\n",
      "iteration 27 / 300: loss 0.601316\n",
      "iteration 27 / 300: loss 0.603939\n",
      "iteration 27 / 300: loss 0.616654\n",
      "iteration 27 / 300: loss 0.599402\n",
      "iteration 27 / 300: loss 0.596986\n",
      "iteration 27 / 300: loss 0.593404\n",
      "iteration 27 / 300: loss 0.588715\n",
      "iteration 27 / 300: loss 0.615532\n",
      "iteration 27 / 300: loss 0.599806\n",
      "iteration 27 / 300: loss 0.601551\n",
      "iteration 27 / 300: loss 0.586221\n",
      "iteration 27 / 300: loss 0.611447\n",
      "iteration 27 / 300: loss 0.633709\n",
      "iteration 27 / 300: loss 0.625264\n",
      "iteration 27 / 300: loss 0.628049\n",
      "iteration 27 / 300: loss 0.611607\n",
      "iteration 27 / 300: loss 0.612469\n",
      "iteration 27 / 300: loss 0.618446\n",
      "iteration 27 / 300: loss 0.615732\n",
      "iteration 27 / 300: loss 0.617557\n",
      "iteration 27 / 300: loss 0.616731\n",
      "iteration 27 / 300: loss 0.614769\n",
      "iteration 27 / 300: loss 0.604476\n",
      "iteration 27 / 300: loss 0.620876\n",
      "iteration 27 / 300: loss 0.618433\n",
      "iteration 27 / 300: loss 0.634369\n",
      "iteration 27 / 300: loss 0.614655\n",
      "iteration 27 / 300: loss 0.616532\n",
      "iteration 27 / 300: loss 0.622313\n",
      "iteration 27 / 300: loss 0.617832\n",
      "iteration 27 / 300: loss 0.608708\n",
      "iteration 27 / 300: loss 0.597879\n",
      "iteration 27 / 300: loss 0.613867\n",
      "iteration 27 / 300: loss 0.630193\n",
      "iteration 27 / 300: loss 0.630321\n",
      "iteration 27 / 300: loss 0.599880\n",
      "iteration 27 / 300: loss 0.616361\n",
      "iteration 27 / 300: loss 0.625738\n",
      "iteration 27 / 300: loss 0.615978\n",
      "iteration 27 / 300: loss 0.625158\n",
      "iteration 27 / 300: loss 0.638341\n",
      "iteration 27 / 300: loss 0.601151\n",
      "iteration 27 / 300: loss 0.598534\n",
      "iteration 27 / 300: loss 0.644848\n",
      "iteration 27 / 300: loss 0.625919\n",
      "iteration 27 / 300: loss 0.624939\n",
      "iteration 27 / 300: loss 0.615097\n",
      "iteration 27 / 300: loss 0.629333\n",
      "iteration 27 / 300: loss 0.611362\n",
      "iteration 27 / 300: loss 0.602700\n",
      "iteration 27 / 300: loss 0.629724\n",
      "iteration 27 / 300: loss 0.626385\n",
      "iteration 27 / 300: loss 0.613980\n",
      "iteration 27 / 300: loss 0.608362\n",
      "iteration 27 / 300: loss 0.627737\n",
      "iteration 27 / 300: loss 0.613267\n",
      "iteration 27 / 300: loss 0.598207\n",
      "iteration 27 / 300: loss 0.627725\n",
      "iteration 28 / 300: loss 0.597140\n",
      "iteration 28 / 300: loss 0.610092\n",
      "iteration 28 / 300: loss 0.584927\n",
      "iteration 28 / 300: loss 0.613663\n",
      "iteration 28 / 300: loss 0.615503\n",
      "iteration 28 / 300: loss 0.621358\n",
      "iteration 28 / 300: loss 0.631642\n",
      "iteration 28 / 300: loss 0.602838\n",
      "iteration 28 / 300: loss 0.642712\n",
      "iteration 28 / 300: loss 0.612889\n",
      "iteration 28 / 300: loss 0.640425\n",
      "iteration 28 / 300: loss 0.612465\n",
      "iteration 28 / 300: loss 0.617534\n",
      "iteration 28 / 300: loss 0.589213\n",
      "iteration 28 / 300: loss 0.613026\n",
      "iteration 28 / 300: loss 0.622430\n",
      "iteration 28 / 300: loss 0.612580\n",
      "iteration 28 / 300: loss 0.603644\n",
      "iteration 28 / 300: loss 0.636151\n",
      "iteration 28 / 300: loss 0.608028\n",
      "iteration 28 / 300: loss 0.607615\n",
      "iteration 28 / 300: loss 0.611760\n",
      "iteration 28 / 300: loss 0.616853\n",
      "iteration 28 / 300: loss 0.614623\n",
      "iteration 28 / 300: loss 0.630688\n",
      "iteration 28 / 300: loss 0.625603\n",
      "iteration 28 / 300: loss 0.613983\n",
      "iteration 28 / 300: loss 0.611178\n",
      "iteration 28 / 300: loss 0.639956\n",
      "iteration 28 / 300: loss 0.618913\n",
      "iteration 28 / 300: loss 0.612963\n",
      "iteration 28 / 300: loss 0.637605\n",
      "iteration 28 / 300: loss 0.594902\n",
      "iteration 28 / 300: loss 0.611752\n",
      "iteration 28 / 300: loss 0.613117\n",
      "iteration 28 / 300: loss 0.617103\n",
      "iteration 28 / 300: loss 0.612528\n",
      "iteration 28 / 300: loss 0.606583\n",
      "iteration 28 / 300: loss 0.607857\n",
      "iteration 28 / 300: loss 0.631687\n",
      "iteration 28 / 300: loss 0.632447\n",
      "iteration 28 / 300: loss 0.605792\n",
      "iteration 28 / 300: loss 0.600028\n",
      "iteration 28 / 300: loss 0.602655\n",
      "iteration 28 / 300: loss 0.615547\n",
      "iteration 28 / 300: loss 0.598051\n",
      "iteration 28 / 300: loss 0.595595\n",
      "iteration 28 / 300: loss 0.591787\n",
      "iteration 28 / 300: loss 0.587229\n",
      "iteration 28 / 300: loss 0.614014\n",
      "iteration 28 / 300: loss 0.598140\n",
      "iteration 28 / 300: loss 0.599825\n",
      "iteration 28 / 300: loss 0.584540\n",
      "iteration 28 / 300: loss 0.610109\n",
      "iteration 28 / 300: loss 0.632090\n",
      "iteration 28 / 300: loss 0.623787\n",
      "iteration 28 / 300: loss 0.626480\n",
      "iteration 28 / 300: loss 0.610326\n",
      "iteration 28 / 300: loss 0.610900\n",
      "iteration 28 / 300: loss 0.616732\n",
      "iteration 28 / 300: loss 0.614570\n",
      "iteration 28 / 300: loss 0.616013\n",
      "iteration 28 / 300: loss 0.615356\n",
      "iteration 28 / 300: loss 0.613575\n",
      "iteration 28 / 300: loss 0.603355\n",
      "iteration 28 / 300: loss 0.619381\n",
      "iteration 28 / 300: loss 0.616798\n",
      "iteration 28 / 300: loss 0.632942\n",
      "iteration 28 / 300: loss 0.613496\n",
      "iteration 28 / 300: loss 0.615131\n",
      "iteration 28 / 300: loss 0.620970\n",
      "iteration 28 / 300: loss 0.616299\n",
      "iteration 28 / 300: loss 0.607451\n",
      "iteration 28 / 300: loss 0.596462\n",
      "iteration 28 / 300: loss 0.612433\n",
      "iteration 28 / 300: loss 0.628794\n",
      "iteration 28 / 300: loss 0.628961\n",
      "iteration 28 / 300: loss 0.598220\n",
      "iteration 28 / 300: loss 0.615009\n",
      "iteration 28 / 300: loss 0.624624\n",
      "iteration 28 / 300: loss 0.614727\n",
      "iteration 28 / 300: loss 0.623885\n",
      "iteration 28 / 300: loss 0.636865\n",
      "iteration 28 / 300: loss 0.599854\n",
      "iteration 28 / 300: loss 0.597327\n",
      "iteration 28 / 300: loss 0.643450\n",
      "iteration 28 / 300: loss 0.624601\n",
      "iteration 28 / 300: loss 0.623394\n",
      "iteration 28 / 300: loss 0.613834\n",
      "iteration 28 / 300: loss 0.627965\n",
      "iteration 28 / 300: loss 0.610111\n",
      "iteration 28 / 300: loss 0.601106\n",
      "iteration 28 / 300: loss 0.628376\n",
      "iteration 28 / 300: loss 0.624814\n",
      "iteration 28 / 300: loss 0.612808\n",
      "iteration 28 / 300: loss 0.606840\n",
      "iteration 28 / 300: loss 0.626828\n",
      "iteration 28 / 300: loss 0.611863\n",
      "iteration 28 / 300: loss 0.596631\n",
      "iteration 28 / 300: loss 0.626356\n",
      "iteration 29 / 300: loss 0.595842\n",
      "iteration 29 / 300: loss 0.608929\n",
      "iteration 29 / 300: loss 0.583779\n",
      "iteration 29 / 300: loss 0.612560\n",
      "iteration 29 / 300: loss 0.614221\n",
      "iteration 29 / 300: loss 0.620139\n",
      "iteration 29 / 300: loss 0.630253\n",
      "iteration 29 / 300: loss 0.601653\n",
      "iteration 29 / 300: loss 0.641499\n",
      "iteration 29 / 300: loss 0.611202\n",
      "iteration 29 / 300: loss 0.639061\n",
      "iteration 29 / 300: loss 0.610932\n",
      "iteration 29 / 300: loss 0.616169\n",
      "iteration 29 / 300: loss 0.587642\n",
      "iteration 29 / 300: loss 0.611601\n",
      "iteration 29 / 300: loss 0.621048\n",
      "iteration 29 / 300: loss 0.611682\n",
      "iteration 29 / 300: loss 0.601683\n",
      "iteration 29 / 300: loss 0.634811\n",
      "iteration 29 / 300: loss 0.606714\n",
      "iteration 29 / 300: loss 0.606199\n",
      "iteration 29 / 300: loss 0.610552\n",
      "iteration 29 / 300: loss 0.615234\n",
      "iteration 29 / 300: loss 0.613411\n",
      "iteration 29 / 300: loss 0.629173\n",
      "iteration 29 / 300: loss 0.624482\n",
      "iteration 29 / 300: loss 0.612749\n",
      "iteration 29 / 300: loss 0.609689\n",
      "iteration 29 / 300: loss 0.638718\n",
      "iteration 29 / 300: loss 0.617778\n",
      "iteration 29 / 300: loss 0.612043\n",
      "iteration 29 / 300: loss 0.636197\n",
      "iteration 29 / 300: loss 0.593724\n",
      "iteration 29 / 300: loss 0.610795\n",
      "iteration 29 / 300: loss 0.611352\n",
      "iteration 29 / 300: loss 0.615937\n",
      "iteration 29 / 300: loss 0.611006\n",
      "iteration 29 / 300: loss 0.605491\n",
      "iteration 29 / 300: loss 0.606739\n",
      "iteration 29 / 300: loss 0.630866\n",
      "iteration 29 / 300: loss 0.631510\n",
      "iteration 29 / 300: loss 0.604104\n",
      "iteration 29 / 300: loss 0.598940\n",
      "iteration 29 / 300: loss 0.601648\n",
      "iteration 29 / 300: loss 0.614585\n",
      "iteration 29 / 300: loss 0.596820\n",
      "iteration 29 / 300: loss 0.594287\n",
      "iteration 29 / 300: loss 0.590281\n",
      "iteration 29 / 300: loss 0.585911\n",
      "iteration 29 / 300: loss 0.612650\n",
      "iteration 29 / 300: loss 0.596670\n",
      "iteration 29 / 300: loss 0.598152\n",
      "iteration 29 / 300: loss 0.583084\n",
      "iteration 29 / 300: loss 0.608827\n",
      "iteration 29 / 300: loss 0.630577\n",
      "iteration 29 / 300: loss 0.622470\n",
      "iteration 29 / 300: loss 0.625026\n",
      "iteration 29 / 300: loss 0.609155\n",
      "iteration 29 / 300: loss 0.609499\n",
      "iteration 29 / 300: loss 0.615194\n",
      "iteration 29 / 300: loss 0.613559\n",
      "iteration 29 / 300: loss 0.614686\n",
      "iteration 29 / 300: loss 0.614109\n",
      "iteration 29 / 300: loss 0.612522\n",
      "iteration 29 / 300: loss 0.602270\n",
      "iteration 29 / 300: loss 0.618046\n",
      "iteration 29 / 300: loss 0.615376\n",
      "iteration 29 / 300: loss 0.631676\n",
      "iteration 29 / 300: loss 0.612553\n",
      "iteration 29 / 300: loss 0.613902\n",
      "iteration 29 / 300: loss 0.619775\n",
      "iteration 29 / 300: loss 0.614943\n",
      "iteration 29 / 300: loss 0.606344\n",
      "iteration 29 / 300: loss 0.595170\n",
      "iteration 29 / 300: loss 0.611186\n",
      "iteration 29 / 300: loss 0.627583\n",
      "iteration 29 / 300: loss 0.627673\n",
      "iteration 29 / 300: loss 0.596787\n",
      "iteration 29 / 300: loss 0.613976\n",
      "iteration 29 / 300: loss 0.623683\n",
      "iteration 29 / 300: loss 0.613633\n",
      "iteration 29 / 300: loss 0.622661\n",
      "iteration 29 / 300: loss 0.635543\n",
      "iteration 29 / 300: loss 0.598634\n",
      "iteration 29 / 300: loss 0.596263\n",
      "iteration 29 / 300: loss 0.642245\n",
      "iteration 29 / 300: loss 0.623331\n",
      "iteration 29 / 300: loss 0.621800\n",
      "iteration 29 / 300: loss 0.612780\n",
      "iteration 29 / 300: loss 0.626697\n",
      "iteration 29 / 300: loss 0.608999\n",
      "iteration 29 / 300: loss 0.599570\n",
      "iteration 29 / 300: loss 0.627078\n",
      "iteration 29 / 300: loss 0.623386\n",
      "iteration 29 / 300: loss 0.611716\n",
      "iteration 29 / 300: loss 0.605515\n",
      "iteration 29 / 300: loss 0.625934\n",
      "iteration 29 / 300: loss 0.610706\n",
      "iteration 29 / 300: loss 0.595210\n",
      "iteration 29 / 300: loss 0.625023\n",
      "iteration 30 / 300: loss 0.594591\n",
      "iteration 30 / 300: loss 0.607909\n",
      "iteration 30 / 300: loss 0.582714\n",
      "iteration 30 / 300: loss 0.611473\n",
      "iteration 30 / 300: loss 0.613140\n",
      "iteration 30 / 300: loss 0.618992\n",
      "iteration 30 / 300: loss 0.629000\n",
      "iteration 30 / 300: loss 0.600487\n",
      "iteration 30 / 300: loss 0.640329\n",
      "iteration 30 / 300: loss 0.609663\n",
      "iteration 30 / 300: loss 0.637780\n",
      "iteration 30 / 300: loss 0.609467\n",
      "iteration 30 / 300: loss 0.614925\n",
      "iteration 30 / 300: loss 0.586267\n",
      "iteration 30 / 300: loss 0.610128\n",
      "iteration 30 / 300: loss 0.619746\n",
      "iteration 30 / 300: loss 0.610931\n",
      "iteration 30 / 300: loss 0.599838\n",
      "iteration 30 / 300: loss 0.633583\n",
      "iteration 30 / 300: loss 0.605552\n",
      "iteration 30 / 300: loss 0.604998\n",
      "iteration 30 / 300: loss 0.609297\n",
      "iteration 30 / 300: loss 0.613747\n",
      "iteration 30 / 300: loss 0.612193\n",
      "iteration 30 / 300: loss 0.627728\n",
      "iteration 30 / 300: loss 0.623404\n",
      "iteration 30 / 300: loss 0.611600\n",
      "iteration 30 / 300: loss 0.608366\n",
      "iteration 30 / 300: loss 0.637611\n",
      "iteration 30 / 300: loss 0.616653\n",
      "iteration 30 / 300: loss 0.611250\n",
      "iteration 30 / 300: loss 0.634943\n",
      "iteration 30 / 300: loss 0.592703\n",
      "iteration 30 / 300: loss 0.609976\n",
      "iteration 30 / 300: loss 0.609607\n",
      "iteration 30 / 300: loss 0.614844\n",
      "iteration 30 / 300: loss 0.609676\n",
      "iteration 30 / 300: loss 0.604574\n",
      "iteration 30 / 300: loss 0.605755\n",
      "iteration 30 / 300: loss 0.629953\n",
      "iteration 30 / 300: loss 0.630505\n",
      "iteration 30 / 300: loss 0.602412\n",
      "iteration 30 / 300: loss 0.597694\n",
      "iteration 30 / 300: loss 0.600992\n",
      "iteration 30 / 300: loss 0.614218\n",
      "iteration 30 / 300: loss 0.595932\n",
      "iteration 30 / 300: loss 0.593141\n",
      "iteration 30 / 300: loss 0.588874\n",
      "iteration 30 / 300: loss 0.584627\n",
      "iteration 30 / 300: loss 0.611360\n",
      "iteration 30 / 300: loss 0.595401\n",
      "iteration 30 / 300: loss 0.596664\n",
      "iteration 30 / 300: loss 0.581830\n",
      "iteration 30 / 300: loss 0.607658\n",
      "iteration 30 / 300: loss 0.629132\n",
      "iteration 30 / 300: loss 0.621306\n",
      "iteration 30 / 300: loss 0.623653\n",
      "iteration 30 / 300: loss 0.608107\n",
      "iteration 30 / 300: loss 0.608209\n",
      "iteration 30 / 300: loss 0.613878\n",
      "iteration 30 / 300: loss 0.612603\n",
      "iteration 30 / 300: loss 0.613585\n",
      "iteration 30 / 300: loss 0.613039\n",
      "iteration 30 / 300: loss 0.611541\n",
      "iteration 30 / 300: loss 0.601216\n",
      "iteration 30 / 300: loss 0.616888\n",
      "iteration 30 / 300: loss 0.614158\n",
      "iteration 30 / 300: loss 0.630550\n",
      "iteration 30 / 300: loss 0.611845\n",
      "iteration 30 / 300: loss 0.612810\n",
      "iteration 30 / 300: loss 0.618685\n",
      "iteration 30 / 300: loss 0.613709\n",
      "iteration 30 / 300: loss 0.605339\n",
      "iteration 30 / 300: loss 0.593925\n",
      "iteration 30 / 300: loss 0.610183\n",
      "iteration 30 / 300: loss 0.626526\n",
      "iteration 30 / 300: loss 0.626375\n",
      "iteration 30 / 300: loss 0.595494\n",
      "iteration 30 / 300: loss 0.613213\n",
      "iteration 30 / 300: loss 0.622876\n",
      "iteration 30 / 300: loss 0.612757\n",
      "iteration 30 / 300: loss 0.621518\n",
      "iteration 30 / 300: loss 0.634406\n",
      "iteration 30 / 300: loss 0.597471\n",
      "iteration 30 / 300: loss 0.595365\n",
      "iteration 30 / 300: loss 0.641141\n",
      "iteration 30 / 300: loss 0.622156\n",
      "iteration 30 / 300: loss 0.620242\n",
      "iteration 30 / 300: loss 0.611865\n",
      "iteration 30 / 300: loss 0.625553\n",
      "iteration 30 / 300: loss 0.608026\n",
      "iteration 30 / 300: loss 0.598070\n",
      "iteration 30 / 300: loss 0.625811\n",
      "iteration 30 / 300: loss 0.621993\n",
      "iteration 30 / 300: loss 0.610655\n",
      "iteration 30 / 300: loss 0.604382\n",
      "iteration 30 / 300: loss 0.624933\n",
      "iteration 30 / 300: loss 0.609724\n",
      "iteration 30 / 300: loss 0.593884\n",
      "iteration 30 / 300: loss 0.623763\n",
      "iteration 31 / 300: loss 0.593368\n",
      "iteration 31 / 300: loss 0.607050\n",
      "iteration 31 / 300: loss 0.581755\n",
      "iteration 31 / 300: loss 0.610436\n",
      "iteration 31 / 300: loss 0.612196\n",
      "iteration 31 / 300: loss 0.617919\n",
      "iteration 31 / 300: loss 0.627866\n",
      "iteration 31 / 300: loss 0.599399\n",
      "iteration 31 / 300: loss 0.639198\n",
      "iteration 31 / 300: loss 0.608320\n",
      "iteration 31 / 300: loss 0.636632\n",
      "iteration 31 / 300: loss 0.608057\n",
      "iteration 31 / 300: loss 0.613879\n",
      "iteration 31 / 300: loss 0.585043\n",
      "iteration 31 / 300: loss 0.608753\n",
      "iteration 31 / 300: loss 0.618508\n",
      "iteration 31 / 300: loss 0.610185\n",
      "iteration 31 / 300: loss 0.598145\n",
      "iteration 31 / 300: loss 0.632368\n",
      "iteration 31 / 300: loss 0.604497\n",
      "iteration 31 / 300: loss 0.603951\n",
      "iteration 31 / 300: loss 0.608076\n",
      "iteration 31 / 300: loss 0.612431\n",
      "iteration 31 / 300: loss 0.611065\n",
      "iteration 31 / 300: loss 0.626298\n",
      "iteration 31 / 300: loss 0.622348\n",
      "iteration 31 / 300: loss 0.610514\n",
      "iteration 31 / 300: loss 0.607179\n",
      "iteration 31 / 300: loss 0.636642\n",
      "iteration 31 / 300: loss 0.615610\n",
      "iteration 31 / 300: loss 0.610545\n",
      "iteration 31 / 300: loss 0.633806\n",
      "iteration 31 / 300: loss 0.591889\n",
      "iteration 31 / 300: loss 0.609330\n",
      "iteration 31 / 300: loss 0.607918\n",
      "iteration 31 / 300: loss 0.613835\n",
      "iteration 31 / 300: loss 0.608505\n",
      "iteration 31 / 300: loss 0.603727\n",
      "iteration 31 / 300: loss 0.604726\n",
      "iteration 31 / 300: loss 0.629083\n",
      "iteration 31 / 300: loss 0.629719\n",
      "iteration 31 / 300: loss 0.600962\n",
      "iteration 31 / 300: loss 0.596456\n",
      "iteration 31 / 300: loss 0.599924\n",
      "iteration 31 / 300: loss 0.613584\n",
      "iteration 31 / 300: loss 0.595124\n",
      "iteration 31 / 300: loss 0.592257\n",
      "iteration 31 / 300: loss 0.587725\n",
      "iteration 31 / 300: loss 0.583618\n",
      "iteration 31 / 300: loss 0.610238\n",
      "iteration 31 / 300: loss 0.594350\n",
      "iteration 31 / 300: loss 0.595235\n",
      "iteration 31 / 300: loss 0.580714\n",
      "iteration 31 / 300: loss 0.606637\n",
      "iteration 31 / 300: loss 0.627692\n",
      "iteration 31 / 300: loss 0.620288\n",
      "iteration 31 / 300: loss 0.622437\n",
      "iteration 31 / 300: loss 0.607081\n",
      "iteration 31 / 300: loss 0.606988\n",
      "iteration 31 / 300: loss 0.612725\n",
      "iteration 31 / 300: loss 0.611649\n",
      "iteration 31 / 300: loss 0.612622\n",
      "iteration 31 / 300: loss 0.612122\n",
      "iteration 31 / 300: loss 0.610618\n",
      "iteration 31 / 300: loss 0.600199\n",
      "iteration 31 / 300: loss 0.615881\n",
      "iteration 31 / 300: loss 0.613063\n",
      "iteration 31 / 300: loss 0.629561\n",
      "iteration 31 / 300: loss 0.611234\n",
      "iteration 31 / 300: loss 0.611816\n",
      "iteration 31 / 300: loss 0.617679\n",
      "iteration 31 / 300: loss 0.612594\n",
      "iteration 31 / 300: loss 0.604437\n",
      "iteration 31 / 300: loss 0.592763\n",
      "iteration 31 / 300: loss 0.609427\n",
      "iteration 31 / 300: loss 0.625586\n",
      "iteration 31 / 300: loss 0.625159\n",
      "iteration 31 / 300: loss 0.594291\n",
      "iteration 31 / 300: loss 0.612591\n",
      "iteration 31 / 300: loss 0.622144\n",
      "iteration 31 / 300: loss 0.612057\n",
      "iteration 31 / 300: loss 0.620458\n",
      "iteration 31 / 300: loss 0.633444\n",
      "iteration 31 / 300: loss 0.596398\n",
      "iteration 31 / 300: loss 0.594596\n",
      "iteration 31 / 300: loss 0.640133\n",
      "iteration 31 / 300: loss 0.621102\n",
      "iteration 31 / 300: loss 0.618870\n",
      "iteration 31 / 300: loss 0.611019\n",
      "iteration 31 / 300: loss 0.624595\n",
      "iteration 31 / 300: loss 0.607153\n",
      "iteration 31 / 300: loss 0.596662\n",
      "iteration 31 / 300: loss 0.624619\n",
      "iteration 31 / 300: loss 0.620635\n",
      "iteration 31 / 300: loss 0.609638\n",
      "iteration 31 / 300: loss 0.603361\n",
      "iteration 31 / 300: loss 0.623936\n",
      "iteration 31 / 300: loss 0.608812\n",
      "iteration 31 / 300: loss 0.592692\n",
      "iteration 31 / 300: loss 0.622606\n",
      "iteration 32 / 300: loss 0.592214\n",
      "iteration 32 / 300: loss 0.606324\n",
      "iteration 32 / 300: loss 0.580879\n",
      "iteration 32 / 300: loss 0.609505\n",
      "iteration 32 / 300: loss 0.611316\n",
      "iteration 32 / 300: loss 0.616919\n",
      "iteration 32 / 300: loss 0.626855\n",
      "iteration 32 / 300: loss 0.598424\n",
      "iteration 32 / 300: loss 0.638061\n",
      "iteration 32 / 300: loss 0.607170\n",
      "iteration 32 / 300: loss 0.635587\n",
      "iteration 32 / 300: loss 0.606682\n",
      "iteration 32 / 300: loss 0.612953\n",
      "iteration 32 / 300: loss 0.583923\n",
      "iteration 32 / 300: loss 0.607511\n",
      "iteration 32 / 300: loss 0.617285\n",
      "iteration 32 / 300: loss 0.609440\n",
      "iteration 32 / 300: loss 0.596604\n",
      "iteration 32 / 300: loss 0.631129\n",
      "iteration 32 / 300: loss 0.603536\n",
      "iteration 32 / 300: loss 0.602940\n",
      "iteration 32 / 300: loss 0.606932\n",
      "iteration 32 / 300: loss 0.611289\n",
      "iteration 32 / 300: loss 0.610000\n",
      "iteration 32 / 300: loss 0.625009\n",
      "iteration 32 / 300: loss 0.621306\n",
      "iteration 32 / 300: loss 0.609542\n",
      "iteration 32 / 300: loss 0.606187\n",
      "iteration 32 / 300: loss 0.635797\n",
      "iteration 32 / 300: loss 0.614598\n",
      "iteration 32 / 300: loss 0.609845\n",
      "iteration 32 / 300: loss 0.632676\n",
      "iteration 32 / 300: loss 0.591035\n",
      "iteration 32 / 300: loss 0.608712\n",
      "iteration 32 / 300: loss 0.606531\n",
      "iteration 32 / 300: loss 0.612772\n",
      "iteration 32 / 300: loss 0.607462\n",
      "iteration 32 / 300: loss 0.602889\n",
      "iteration 32 / 300: loss 0.603781\n",
      "iteration 32 / 300: loss 0.628264\n",
      "iteration 32 / 300: loss 0.629126\n",
      "iteration 32 / 300: loss 0.599809\n",
      "iteration 32 / 300: loss 0.595292\n",
      "iteration 32 / 300: loss 0.598871\n",
      "iteration 32 / 300: loss 0.612930\n",
      "iteration 32 / 300: loss 0.594299\n",
      "iteration 32 / 300: loss 0.591409\n",
      "iteration 32 / 300: loss 0.586761\n",
      "iteration 32 / 300: loss 0.582727\n",
      "iteration 32 / 300: loss 0.609261\n",
      "iteration 32 / 300: loss 0.593475\n",
      "iteration 32 / 300: loss 0.593949\n",
      "iteration 32 / 300: loss 0.579725\n",
      "iteration 32 / 300: loss 0.605689\n",
      "iteration 32 / 300: loss 0.626289\n",
      "iteration 32 / 300: loss 0.619384\n",
      "iteration 32 / 300: loss 0.621294\n",
      "iteration 32 / 300: loss 0.606107\n",
      "iteration 32 / 300: loss 0.605830\n",
      "iteration 32 / 300: loss 0.611662\n",
      "iteration 32 / 300: loss 0.610710\n",
      "iteration 32 / 300: loss 0.611754\n",
      "iteration 32 / 300: loss 0.611264\n",
      "iteration 32 / 300: loss 0.609740\n",
      "iteration 32 / 300: loss 0.599262\n",
      "iteration 32 / 300: loss 0.614981\n",
      "iteration 32 / 300: loss 0.612073\n",
      "iteration 32 / 300: loss 0.628735\n",
      "iteration 32 / 300: loss 0.610662\n",
      "iteration 32 / 300: loss 0.610927\n",
      "iteration 32 / 300: loss 0.616746\n",
      "iteration 32 / 300: loss 0.611584\n",
      "iteration 32 / 300: loss 0.603651\n",
      "iteration 32 / 300: loss 0.591702\n",
      "iteration 32 / 300: loss 0.608797\n",
      "iteration 32 / 300: loss 0.624703\n",
      "iteration 32 / 300: loss 0.624111\n",
      "iteration 32 / 300: loss 0.593148\n",
      "iteration 32 / 300: loss 0.612064\n",
      "iteration 32 / 300: loss 0.621435\n",
      "iteration 32 / 300: loss 0.611465\n",
      "iteration 32 / 300: loss 0.619502\n",
      "iteration 32 / 300: loss 0.632581\n",
      "iteration 32 / 300: loss 0.595440\n",
      "iteration 32 / 300: loss 0.593915\n",
      "iteration 32 / 300: loss 0.639230\n",
      "iteration 32 / 300: loss 0.620116\n",
      "iteration 32 / 300: loss 0.617726\n",
      "iteration 32 / 300: loss 0.610208\n",
      "iteration 32 / 300: loss 0.623812\n",
      "iteration 32 / 300: loss 0.606368\n",
      "iteration 32 / 300: loss 0.595385\n",
      "iteration 32 / 300: loss 0.623512\n",
      "iteration 32 / 300: loss 0.619393\n",
      "iteration 32 / 300: loss 0.608693\n",
      "iteration 32 / 300: loss 0.602420\n",
      "iteration 32 / 300: loss 0.623050\n",
      "iteration 32 / 300: loss 0.607983\n",
      "iteration 32 / 300: loss 0.591614\n",
      "iteration 32 / 300: loss 0.621507\n",
      "iteration 33 / 300: loss 0.591169\n",
      "iteration 33 / 300: loss 0.605654\n",
      "iteration 33 / 300: loss 0.580064\n",
      "iteration 33 / 300: loss 0.608646\n",
      "iteration 33 / 300: loss 0.610469\n",
      "iteration 33 / 300: loss 0.615925\n",
      "iteration 33 / 300: loss 0.625947\n",
      "iteration 33 / 300: loss 0.597552\n",
      "iteration 33 / 300: loss 0.636984\n",
      "iteration 33 / 300: loss 0.606135\n",
      "iteration 33 / 300: loss 0.634652\n",
      "iteration 33 / 300: loss 0.605379\n",
      "iteration 33 / 300: loss 0.612087\n",
      "iteration 33 / 300: loss 0.582830\n",
      "iteration 33 / 300: loss 0.606393\n",
      "iteration 33 / 300: loss 0.616017\n",
      "iteration 33 / 300: loss 0.608762\n",
      "iteration 33 / 300: loss 0.595307\n",
      "iteration 33 / 300: loss 0.629832\n",
      "iteration 33 / 300: loss 0.602617\n",
      "iteration 33 / 300: loss 0.602055\n",
      "iteration 33 / 300: loss 0.605922\n",
      "iteration 33 / 300: loss 0.610309\n",
      "iteration 33 / 300: loss 0.608984\n",
      "iteration 33 / 300: loss 0.623927\n",
      "iteration 33 / 300: loss 0.620361\n",
      "iteration 33 / 300: loss 0.608660\n",
      "iteration 33 / 300: loss 0.605405\n",
      "iteration 33 / 300: loss 0.635095\n",
      "iteration 33 / 300: loss 0.613591\n",
      "iteration 33 / 300: loss 0.609159\n",
      "iteration 33 / 300: loss 0.631640\n",
      "iteration 33 / 300: loss 0.590229\n",
      "iteration 33 / 300: loss 0.608095\n",
      "iteration 33 / 300: loss 0.605341\n",
      "iteration 33 / 300: loss 0.611724\n",
      "iteration 33 / 300: loss 0.606520\n",
      "iteration 33 / 300: loss 0.602075\n",
      "iteration 33 / 300: loss 0.602926\n",
      "iteration 33 / 300: loss 0.627453\n",
      "iteration 33 / 300: loss 0.628684\n",
      "iteration 33 / 300: loss 0.598834\n",
      "iteration 33 / 300: loss 0.594229\n",
      "iteration 33 / 300: loss 0.597920\n",
      "iteration 33 / 300: loss 0.612374\n",
      "iteration 33 / 300: loss 0.593654\n",
      "iteration 33 / 300: loss 0.590656\n",
      "iteration 33 / 300: loss 0.585939\n",
      "iteration 33 / 300: loss 0.581979\n",
      "iteration 33 / 300: loss 0.608398\n",
      "iteration 33 / 300: loss 0.592716\n",
      "iteration 33 / 300: loss 0.592856\n",
      "iteration 33 / 300: loss 0.578785\n",
      "iteration 33 / 300: loss 0.604789\n",
      "iteration 33 / 300: loss 0.624982\n",
      "iteration 33 / 300: loss 0.618588\n",
      "iteration 33 / 300: loss 0.620213\n",
      "iteration 33 / 300: loss 0.605184\n",
      "iteration 33 / 300: loss 0.604735\n",
      "iteration 33 / 300: loss 0.610653\n",
      "iteration 33 / 300: loss 0.609782\n",
      "iteration 33 / 300: loss 0.610944\n",
      "iteration 33 / 300: loss 0.610422\n",
      "iteration 33 / 300: loss 0.608907\n",
      "iteration 33 / 300: loss 0.598397\n",
      "iteration 33 / 300: loss 0.614118\n",
      "iteration 33 / 300: loss 0.611170\n",
      "iteration 33 / 300: loss 0.628027\n",
      "iteration 33 / 300: loss 0.610127\n",
      "iteration 33 / 300: loss 0.610144\n",
      "iteration 33 / 300: loss 0.615878\n",
      "iteration 33 / 300: loss 0.610704\n",
      "iteration 33 / 300: loss 0.602975\n",
      "iteration 33 / 300: loss 0.590746\n",
      "iteration 33 / 300: loss 0.608212\n",
      "iteration 33 / 300: loss 0.623856\n",
      "iteration 33 / 300: loss 0.623236\n",
      "iteration 33 / 300: loss 0.592083\n",
      "iteration 33 / 300: loss 0.611621\n",
      "iteration 33 / 300: loss 0.620685\n",
      "iteration 33 / 300: loss 0.610929\n",
      "iteration 33 / 300: loss 0.618658\n",
      "iteration 33 / 300: loss 0.631813\n",
      "iteration 33 / 300: loss 0.594635\n",
      "iteration 33 / 300: loss 0.593266\n",
      "iteration 33 / 300: loss 0.638432\n",
      "iteration 33 / 300: loss 0.619136\n",
      "iteration 33 / 300: loss 0.616791\n",
      "iteration 33 / 300: loss 0.609437\n",
      "iteration 33 / 300: loss 0.623145\n",
      "iteration 33 / 300: loss 0.605640\n",
      "iteration 33 / 300: loss 0.594222\n",
      "iteration 33 / 300: loss 0.622441\n",
      "iteration 33 / 300: loss 0.618345\n",
      "iteration 33 / 300: loss 0.607813\n",
      "iteration 33 / 300: loss 0.601592\n",
      "iteration 33 / 300: loss 0.622245\n",
      "iteration 33 / 300: loss 0.607247\n",
      "iteration 33 / 300: loss 0.590632\n",
      "iteration 33 / 300: loss 0.620467\n",
      "iteration 34 / 300: loss 0.590202\n",
      "iteration 34 / 300: loss 0.605010\n",
      "iteration 34 / 300: loss 0.579295\n",
      "iteration 34 / 300: loss 0.607833\n",
      "iteration 34 / 300: loss 0.609654\n",
      "iteration 34 / 300: loss 0.614962\n",
      "iteration 34 / 300: loss 0.625081\n",
      "iteration 34 / 300: loss 0.596774\n",
      "iteration 34 / 300: loss 0.636030\n",
      "iteration 34 / 300: loss 0.605209\n",
      "iteration 34 / 300: loss 0.633792\n",
      "iteration 34 / 300: loss 0.604201\n",
      "iteration 34 / 300: loss 0.611270\n",
      "iteration 34 / 300: loss 0.581771\n",
      "iteration 34 / 300: loss 0.605368\n",
      "iteration 34 / 300: loss 0.614792\n",
      "iteration 34 / 300: loss 0.608125\n",
      "iteration 34 / 300: loss 0.594193\n",
      "iteration 34 / 300: loss 0.628579\n",
      "iteration 34 / 300: loss 0.601765\n",
      "iteration 34 / 300: loss 0.601234\n",
      "iteration 34 / 300: loss 0.605028\n",
      "iteration 34 / 300: loss 0.609410\n",
      "iteration 34 / 300: loss 0.608053\n",
      "iteration 34 / 300: loss 0.622981\n",
      "iteration 34 / 300: loss 0.619505\n",
      "iteration 34 / 300: loss 0.607888\n",
      "iteration 34 / 300: loss 0.604760\n",
      "iteration 34 / 300: loss 0.634520\n",
      "iteration 34 / 300: loss 0.612623\n",
      "iteration 34 / 300: loss 0.608519\n",
      "iteration 34 / 300: loss 0.630724\n",
      "iteration 34 / 300: loss 0.589513\n",
      "iteration 34 / 300: loss 0.607509\n",
      "iteration 34 / 300: loss 0.604279\n",
      "iteration 34 / 300: loss 0.610748\n",
      "iteration 34 / 300: loss 0.605678\n",
      "iteration 34 / 300: loss 0.601301\n",
      "iteration 34 / 300: loss 0.602130\n",
      "iteration 34 / 300: loss 0.626684\n",
      "iteration 34 / 300: loss 0.628333\n",
      "iteration 34 / 300: loss 0.597996\n",
      "iteration 34 / 300: loss 0.593295\n",
      "iteration 34 / 300: loss 0.597064\n",
      "iteration 34 / 300: loss 0.611903\n",
      "iteration 34 / 300: loss 0.593153\n",
      "iteration 34 / 300: loss 0.589972\n",
      "iteration 34 / 300: loss 0.585238\n",
      "iteration 34 / 300: loss 0.581370\n",
      "iteration 34 / 300: loss 0.607629\n",
      "iteration 34 / 300: loss 0.592057\n",
      "iteration 34 / 300: loss 0.591948\n",
      "iteration 34 / 300: loss 0.577895\n",
      "iteration 34 / 300: loss 0.603905\n",
      "iteration 34 / 300: loss 0.623805\n",
      "iteration 34 / 300: loss 0.617899\n",
      "iteration 34 / 300: loss 0.619214\n",
      "iteration 34 / 300: loss 0.604326\n",
      "iteration 34 / 300: loss 0.603712\n",
      "iteration 34 / 300: loss 0.609677\n",
      "iteration 34 / 300: loss 0.608881\n",
      "iteration 34 / 300: loss 0.610175\n",
      "iteration 34 / 300: loss 0.609582\n",
      "iteration 34 / 300: loss 0.608117\n",
      "iteration 34 / 300: loss 0.597596\n",
      "iteration 34 / 300: loss 0.613249\n",
      "iteration 34 / 300: loss 0.610324\n",
      "iteration 34 / 300: loss 0.627380\n",
      "iteration 34 / 300: loss 0.609612\n",
      "iteration 34 / 300: loss 0.609441\n",
      "iteration 34 / 300: loss 0.615069\n",
      "iteration 34 / 300: loss 0.609945\n",
      "iteration 34 / 300: loss 0.602384\n",
      "iteration 34 / 300: loss 0.589898\n",
      "iteration 34 / 300: loss 0.607660\n",
      "iteration 34 / 300: loss 0.623070\n",
      "iteration 34 / 300: loss 0.622479\n",
      "iteration 34 / 300: loss 0.591120\n",
      "iteration 34 / 300: loss 0.611234\n",
      "iteration 34 / 300: loss 0.619912\n",
      "iteration 34 / 300: loss 0.610439\n",
      "iteration 34 / 300: loss 0.617912\n",
      "iteration 34 / 300: loss 0.631128\n",
      "iteration 34 / 300: loss 0.593960\n",
      "iteration 34 / 300: loss 0.592629\n",
      "iteration 34 / 300: loss 0.637732\n",
      "iteration 34 / 300: loss 0.618191\n",
      "iteration 34 / 300: loss 0.616007\n",
      "iteration 34 / 300: loss 0.608692\n",
      "iteration 34 / 300: loss 0.622563\n",
      "iteration 34 / 300: loss 0.604931\n",
      "iteration 34 / 300: loss 0.593146\n",
      "iteration 34 / 300: loss 0.621388\n",
      "iteration 34 / 300: loss 0.617454\n",
      "iteration 34 / 300: loss 0.607021\n",
      "iteration 34 / 300: loss 0.600865\n",
      "iteration 34 / 300: loss 0.621500\n",
      "iteration 34 / 300: loss 0.606591\n",
      "iteration 34 / 300: loss 0.589729\n",
      "iteration 34 / 300: loss 0.619508\n",
      "iteration 35 / 300: loss 0.589288\n",
      "iteration 35 / 300: loss 0.604391\n",
      "iteration 35 / 300: loss 0.578579\n",
      "iteration 35 / 300: loss 0.607058\n",
      "iteration 35 / 300: loss 0.608878\n",
      "iteration 35 / 300: loss 0.614061\n",
      "iteration 35 / 300: loss 0.624251\n",
      "iteration 35 / 300: loss 0.596076\n",
      "iteration 35 / 300: loss 0.635180\n",
      "iteration 35 / 300: loss 0.604382\n",
      "iteration 35 / 300: loss 0.632970\n",
      "iteration 35 / 300: loss 0.603169\n",
      "iteration 35 / 300: loss 0.610487\n",
      "iteration 35 / 300: loss 0.580778\n",
      "iteration 35 / 300: loss 0.604395\n",
      "iteration 35 / 300: loss 0.613654\n",
      "iteration 35 / 300: loss 0.607491\n",
      "iteration 35 / 300: loss 0.593192\n",
      "iteration 35 / 300: loss 0.627433\n",
      "iteration 35 / 300: loss 0.601004\n",
      "iteration 35 / 300: loss 0.600461\n",
      "iteration 35 / 300: loss 0.604186\n",
      "iteration 35 / 300: loss 0.608562\n",
      "iteration 35 / 300: loss 0.607211\n",
      "iteration 35 / 300: loss 0.622116\n",
      "iteration 35 / 300: loss 0.618712\n",
      "iteration 35 / 300: loss 0.607200\n",
      "iteration 35 / 300: loss 0.604193\n",
      "iteration 35 / 300: loss 0.634047\n",
      "iteration 35 / 300: loss 0.611704\n",
      "iteration 35 / 300: loss 0.607946\n",
      "iteration 35 / 300: loss 0.629925\n",
      "iteration 35 / 300: loss 0.588911\n",
      "iteration 35 / 300: loss 0.606971\n",
      "iteration 35 / 300: loss 0.603307\n",
      "iteration 35 / 300: loss 0.609872\n",
      "iteration 35 / 300: loss 0.604914\n",
      "iteration 35 / 300: loss 0.600561\n",
      "iteration 35 / 300: loss 0.601392\n",
      "iteration 35 / 300: loss 0.625969\n",
      "iteration 35 / 300: loss 0.628021\n",
      "iteration 35 / 300: loss 0.597274\n",
      "iteration 35 / 300: loss 0.592462\n",
      "iteration 35 / 300: loss 0.596284\n",
      "iteration 35 / 300: loss 0.611490\n",
      "iteration 35 / 300: loss 0.592743\n",
      "iteration 35 / 300: loss 0.589322\n",
      "iteration 35 / 300: loss 0.584621\n",
      "iteration 35 / 300: loss 0.580865\n",
      "iteration 35 / 300: loss 0.606945\n",
      "iteration 35 / 300: loss 0.591512\n",
      "iteration 35 / 300: loss 0.591206\n",
      "iteration 35 / 300: loss 0.577098\n",
      "iteration 35 / 300: loss 0.603026\n",
      "iteration 35 / 300: loss 0.622772\n",
      "iteration 35 / 300: loss 0.617305\n",
      "iteration 35 / 300: loss 0.618290\n",
      "iteration 35 / 300: loss 0.603558\n",
      "iteration 35 / 300: loss 0.602768\n",
      "iteration 35 / 300: loss 0.608734\n",
      "iteration 35 / 300: loss 0.608029\n",
      "iteration 35 / 300: loss 0.609457\n",
      "iteration 35 / 300: loss 0.608752\n",
      "iteration 35 / 300: loss 0.607367\n",
      "iteration 35 / 300: loss 0.596855\n",
      "iteration 35 / 300: loss 0.612383\n",
      "iteration 35 / 300: loss 0.609530\n",
      "iteration 35 / 300: loss 0.626756\n",
      "iteration 35 / 300: loss 0.609077\n",
      "iteration 35 / 300: loss 0.608798\n",
      "iteration 35 / 300: loss 0.614342\n",
      "iteration 35 / 300: loss 0.609252\n",
      "iteration 35 / 300: loss 0.601825\n",
      "iteration 35 / 300: loss 0.589165\n",
      "iteration 35 / 300: loss 0.607156\n",
      "iteration 35 / 300: loss 0.622359\n",
      "iteration 35 / 300: loss 0.621836\n",
      "iteration 35 / 300: loss 0.590282\n",
      "iteration 35 / 300: loss 0.610886\n",
      "iteration 35 / 300: loss 0.619154\n",
      "iteration 35 / 300: loss 0.609996\n",
      "iteration 35 / 300: loss 0.617244\n",
      "iteration 35 / 300: loss 0.630498\n",
      "iteration 35 / 300: loss 0.593372\n",
      "iteration 35 / 300: loss 0.592003\n",
      "iteration 35 / 300: loss 0.637120\n",
      "iteration 35 / 300: loss 0.617327\n",
      "iteration 35 / 300: loss 0.615324\n",
      "iteration 35 / 300: loss 0.607960\n",
      "iteration 35 / 300: loss 0.622063\n",
      "iteration 35 / 300: loss 0.604243\n",
      "iteration 35 / 300: loss 0.592140\n",
      "iteration 35 / 300: loss 0.620365\n",
      "iteration 35 / 300: loss 0.616670\n",
      "iteration 35 / 300: loss 0.606316\n",
      "iteration 35 / 300: loss 0.600207\n",
      "iteration 35 / 300: loss 0.620810\n",
      "iteration 35 / 300: loss 0.606010\n",
      "iteration 35 / 300: loss 0.588915\n",
      "iteration 35 / 300: loss 0.618640\n",
      "iteration 36 / 300: loss 0.588413\n",
      "iteration 36 / 300: loss 0.603797\n",
      "iteration 36 / 300: loss 0.577919\n",
      "iteration 36 / 300: loss 0.606336\n",
      "iteration 36 / 300: loss 0.608168\n",
      "iteration 36 / 300: loss 0.613233\n",
      "iteration 36 / 300: loss 0.623465\n",
      "iteration 36 / 300: loss 0.595456\n",
      "iteration 36 / 300: loss 0.634415\n",
      "iteration 36 / 300: loss 0.603623\n",
      "iteration 36 / 300: loss 0.632185\n",
      "iteration 36 / 300: loss 0.602268\n",
      "iteration 36 / 300: loss 0.609743\n",
      "iteration 36 / 300: loss 0.579871\n",
      "iteration 36 / 300: loss 0.603481\n",
      "iteration 36 / 300: loss 0.612595\n",
      "iteration 36 / 300: loss 0.606850\n",
      "iteration 36 / 300: loss 0.592297\n",
      "iteration 36 / 300: loss 0.626383\n",
      "iteration 36 / 300: loss 0.600315\n",
      "iteration 36 / 300: loss 0.599760\n",
      "iteration 36 / 300: loss 0.603399\n",
      "iteration 36 / 300: loss 0.607751\n",
      "iteration 36 / 300: loss 0.606428\n",
      "iteration 36 / 300: loss 0.621308\n",
      "iteration 36 / 300: loss 0.617983\n",
      "iteration 36 / 300: loss 0.606562\n",
      "iteration 36 / 300: loss 0.603638\n",
      "iteration 36 / 300: loss 0.633629\n",
      "iteration 36 / 300: loss 0.610880\n",
      "iteration 36 / 300: loss 0.607410\n",
      "iteration 36 / 300: loss 0.629229\n",
      "iteration 36 / 300: loss 0.588405\n",
      "iteration 36 / 300: loss 0.606480\n",
      "iteration 36 / 300: loss 0.602409\n",
      "iteration 36 / 300: loss 0.609082\n",
      "iteration 36 / 300: loss 0.604221\n",
      "iteration 36 / 300: loss 0.599857\n",
      "iteration 36 / 300: loss 0.600707\n",
      "iteration 36 / 300: loss 0.625293\n",
      "iteration 36 / 300: loss 0.627721\n",
      "iteration 36 / 300: loss 0.596627\n",
      "iteration 36 / 300: loss 0.591700\n",
      "iteration 36 / 300: loss 0.595556\n",
      "iteration 36 / 300: loss 0.611124\n",
      "iteration 36 / 300: loss 0.592380\n",
      "iteration 36 / 300: loss 0.588698\n",
      "iteration 36 / 300: loss 0.584068\n",
      "iteration 36 / 300: loss 0.580414\n",
      "iteration 36 / 300: loss 0.606345\n",
      "iteration 36 / 300: loss 0.591064\n",
      "iteration 36 / 300: loss 0.590602\n",
      "iteration 36 / 300: loss 0.576412\n",
      "iteration 36 / 300: loss 0.602158\n",
      "iteration 36 / 300: loss 0.621864\n",
      "iteration 36 / 300: loss 0.616775\n",
      "iteration 36 / 300: loss 0.617441\n",
      "iteration 36 / 300: loss 0.602882\n",
      "iteration 36 / 300: loss 0.601893\n",
      "iteration 36 / 300: loss 0.607840\n",
      "iteration 36 / 300: loss 0.607231\n",
      "iteration 36 / 300: loss 0.608792\n",
      "iteration 36 / 300: loss 0.607935\n",
      "iteration 36 / 300: loss 0.606643\n",
      "iteration 36 / 300: loss 0.596163\n",
      "iteration 36 / 300: loss 0.611529\n",
      "iteration 36 / 300: loss 0.608791\n",
      "iteration 36 / 300: loss 0.626134\n",
      "iteration 36 / 300: loss 0.608489\n",
      "iteration 36 / 300: loss 0.608203\n",
      "iteration 36 / 300: loss 0.613691\n",
      "iteration 36 / 300: loss 0.608561\n",
      "iteration 36 / 300: loss 0.601244\n",
      "iteration 36 / 300: loss 0.588527\n",
      "iteration 36 / 300: loss 0.606701\n",
      "iteration 36 / 300: loss 0.621709\n",
      "iteration 36 / 300: loss 0.621298\n",
      "iteration 36 / 300: loss 0.589580\n",
      "iteration 36 / 300: loss 0.610545\n",
      "iteration 36 / 300: loss 0.618440\n",
      "iteration 36 / 300: loss 0.609597\n",
      "iteration 36 / 300: loss 0.616645\n",
      "iteration 36 / 300: loss 0.629921\n",
      "iteration 36 / 300: loss 0.592849\n",
      "iteration 36 / 300: loss 0.591371\n",
      "iteration 36 / 300: loss 0.636583\n",
      "iteration 36 / 300: loss 0.616544\n",
      "iteration 36 / 300: loss 0.614729\n",
      "iteration 36 / 300: loss 0.607263\n",
      "iteration 36 / 300: loss 0.621690\n",
      "iteration 36 / 300: loss 0.603597\n",
      "iteration 36 / 300: loss 0.591203\n",
      "iteration 36 / 300: loss 0.619403\n",
      "iteration 36 / 300: loss 0.615984\n",
      "iteration 36 / 300: loss 0.605685\n",
      "iteration 36 / 300: loss 0.599592\n",
      "iteration 36 / 300: loss 0.620170\n",
      "iteration 36 / 300: loss 0.605498\n",
      "iteration 36 / 300: loss 0.588195\n",
      "iteration 36 / 300: loss 0.617852\n",
      "iteration 37 / 300: loss 0.587571\n",
      "iteration 37 / 300: loss 0.603232\n",
      "iteration 37 / 300: loss 0.577307\n",
      "iteration 37 / 300: loss 0.605677\n",
      "iteration 37 / 300: loss 0.607520\n",
      "iteration 37 / 300: loss 0.612474\n",
      "iteration 37 / 300: loss 0.622736\n",
      "iteration 37 / 300: loss 0.594908\n",
      "iteration 37 / 300: loss 0.633721\n",
      "iteration 37 / 300: loss 0.602904\n",
      "iteration 37 / 300: loss 0.631451\n",
      "iteration 37 / 300: loss 0.601464\n",
      "iteration 37 / 300: loss 0.609046\n",
      "iteration 37 / 300: loss 0.579047\n",
      "iteration 37 / 300: loss 0.602640\n",
      "iteration 37 / 300: loss 0.611614\n",
      "iteration 37 / 300: loss 0.606204\n",
      "iteration 37 / 300: loss 0.591510\n",
      "iteration 37 / 300: loss 0.625402\n",
      "iteration 37 / 300: loss 0.599678\n",
      "iteration 37 / 300: loss 0.599128\n",
      "iteration 37 / 300: loss 0.602662\n",
      "iteration 37 / 300: loss 0.606971\n",
      "iteration 37 / 300: loss 0.605691\n",
      "iteration 37 / 300: loss 0.620558\n",
      "iteration 37 / 300: loss 0.617311\n",
      "iteration 37 / 300: loss 0.605960\n",
      "iteration 37 / 300: loss 0.603070\n",
      "iteration 37 / 300: loss 0.633245\n",
      "iteration 37 / 300: loss 0.610153\n",
      "iteration 37 / 300: loss 0.606893\n",
      "iteration 37 / 300: loss 0.628612\n",
      "iteration 37 / 300: loss 0.587965\n",
      "iteration 37 / 300: loss 0.606028\n",
      "iteration 37 / 300: loss 0.601583\n",
      "iteration 37 / 300: loss 0.608370\n",
      "iteration 37 / 300: loss 0.603601\n",
      "iteration 37 / 300: loss 0.599194\n",
      "iteration 37 / 300: loss 0.600064\n",
      "iteration 37 / 300: loss 0.624643\n",
      "iteration 37 / 300: loss 0.627420\n",
      "iteration 37 / 300: loss 0.596021\n",
      "iteration 37 / 300: loss 0.590992\n",
      "iteration 37 / 300: loss 0.594861\n",
      "iteration 37 / 300: loss 0.610785\n",
      "iteration 37 / 300: loss 0.592030\n",
      "iteration 37 / 300: loss 0.588097\n",
      "iteration 37 / 300: loss 0.583577\n",
      "iteration 37 / 300: loss 0.579995\n",
      "iteration 37 / 300: loss 0.605823\n",
      "iteration 37 / 300: loss 0.590674\n",
      "iteration 37 / 300: loss 0.590098\n",
      "iteration 37 / 300: loss 0.575821\n",
      "iteration 37 / 300: loss 0.601323\n",
      "iteration 37 / 300: loss 0.621053\n",
      "iteration 37 / 300: loss 0.616288\n",
      "iteration 37 / 300: loss 0.616664\n",
      "iteration 37 / 300: loss 0.602281\n",
      "iteration 37 / 300: loss 0.601089\n",
      "iteration 37 / 300: loss 0.607006\n",
      "iteration 37 / 300: loss 0.606481\n",
      "iteration 37 / 300: loss 0.608175\n",
      "iteration 37 / 300: loss 0.607135\n",
      "iteration 37 / 300: loss 0.605935\n",
      "iteration 37 / 300: loss 0.595511\n",
      "iteration 37 / 300: loss 0.610692\n",
      "iteration 37 / 300: loss 0.608109\n",
      "iteration 37 / 300: loss 0.625506\n",
      "iteration 37 / 300: loss 0.607850\n",
      "iteration 37 / 300: loss 0.607644\n",
      "iteration 37 / 300: loss 0.613085\n",
      "iteration 37 / 300: loss 0.607857\n",
      "iteration 37 / 300: loss 0.600637\n",
      "iteration 37 / 300: loss 0.587919\n",
      "iteration 37 / 300: loss 0.606236\n",
      "iteration 37 / 300: loss 0.621081\n",
      "iteration 37 / 300: loss 0.620809\n",
      "iteration 37 / 300: loss 0.588997\n",
      "iteration 37 / 300: loss 0.610191\n",
      "iteration 37 / 300: loss 0.617785\n",
      "iteration 37 / 300: loss 0.609216\n",
      "iteration 37 / 300: loss 0.616098\n",
      "iteration 37 / 300: loss 0.629390\n",
      "iteration 37 / 300: loss 0.592380\n",
      "iteration 37 / 300: loss 0.590768\n",
      "iteration 37 / 300: loss 0.636122\n",
      "iteration 37 / 300: loss 0.615864\n",
      "iteration 37 / 300: loss 0.614182\n",
      "iteration 37 / 300: loss 0.606671\n",
      "iteration 37 / 300: loss 0.621411\n",
      "iteration 37 / 300: loss 0.603019\n",
      "iteration 37 / 300: loss 0.590356\n",
      "iteration 37 / 300: loss 0.618516\n",
      "iteration 37 / 300: loss 0.615379\n",
      "iteration 37 / 300: loss 0.605113\n",
      "iteration 37 / 300: loss 0.599019\n",
      "iteration 37 / 300: loss 0.619570\n",
      "iteration 37 / 300: loss 0.605047\n",
      "iteration 37 / 300: loss 0.587567\n",
      "iteration 37 / 300: loss 0.617144\n",
      "iteration 38 / 300: loss 0.586772\n",
      "iteration 38 / 300: loss 0.602712\n",
      "iteration 38 / 300: loss 0.576734\n",
      "iteration 38 / 300: loss 0.605081\n",
      "iteration 38 / 300: loss 0.606925\n",
      "iteration 38 / 300: loss 0.611770\n",
      "iteration 38 / 300: loss 0.622058\n",
      "iteration 38 / 300: loss 0.594411\n",
      "iteration 38 / 300: loss 0.633083\n",
      "iteration 38 / 300: loss 0.602217\n",
      "iteration 38 / 300: loss 0.630757\n",
      "iteration 38 / 300: loss 0.600734\n",
      "iteration 38 / 300: loss 0.608397\n",
      "iteration 38 / 300: loss 0.578290\n",
      "iteration 38 / 300: loss 0.601868\n",
      "iteration 38 / 300: loss 0.610703\n",
      "iteration 38 / 300: loss 0.605564\n",
      "iteration 38 / 300: loss 0.590821\n",
      "iteration 38 / 300: loss 0.624480\n",
      "iteration 38 / 300: loss 0.599083\n",
      "iteration 38 / 300: loss 0.598541\n",
      "iteration 38 / 300: loss 0.601953\n",
      "iteration 38 / 300: loss 0.606240\n",
      "iteration 38 / 300: loss 0.604999\n",
      "iteration 38 / 300: loss 0.619876\n",
      "iteration 38 / 300: loss 0.616676\n",
      "iteration 38 / 300: loss 0.605390\n",
      "iteration 38 / 300: loss 0.602507\n",
      "iteration 38 / 300: loss 0.632886\n",
      "iteration 38 / 300: loss 0.609494\n",
      "iteration 38 / 300: loss 0.606386\n",
      "iteration 38 / 300: loss 0.628062\n",
      "iteration 38 / 300: loss 0.587579\n",
      "iteration 38 / 300: loss 0.605606\n",
      "iteration 38 / 300: loss 0.600834\n",
      "iteration 38 / 300: loss 0.607733\n",
      "iteration 38 / 300: loss 0.603064\n",
      "iteration 38 / 300: loss 0.598570\n",
      "iteration 38 / 300: loss 0.599470\n",
      "iteration 38 / 300: loss 0.624020\n",
      "iteration 38 / 300: loss 0.627119\n",
      "iteration 38 / 300: loss 0.595440\n",
      "iteration 38 / 300: loss 0.590331\n",
      "iteration 38 / 300: loss 0.594188\n",
      "iteration 38 / 300: loss 0.610453\n",
      "iteration 38 / 300: loss 0.591677\n",
      "iteration 38 / 300: loss 0.587511\n",
      "iteration 38 / 300: loss 0.583132\n",
      "iteration 38 / 300: loss 0.579620\n",
      "iteration 38 / 300: loss 0.605370\n",
      "iteration 38 / 300: loss 0.590320\n",
      "iteration 38 / 300: loss 0.589679\n",
      "iteration 38 / 300: loss 0.575294\n",
      "iteration 38 / 300: loss 0.600542\n",
      "iteration 38 / 300: loss 0.620321\n",
      "iteration 38 / 300: loss 0.615835\n",
      "iteration 38 / 300: loss 0.615949\n",
      "iteration 38 / 300: loss 0.601741\n",
      "iteration 38 / 300: loss 0.600356\n",
      "iteration 38 / 300: loss 0.606241\n",
      "iteration 38 / 300: loss 0.605776\n",
      "iteration 38 / 300: loss 0.607606\n",
      "iteration 38 / 300: loss 0.606360\n",
      "iteration 38 / 300: loss 0.605259\n",
      "iteration 38 / 300: loss 0.594907\n",
      "iteration 38 / 300: loss 0.609882\n",
      "iteration 38 / 300: loss 0.607475\n",
      "iteration 38 / 300: loss 0.624883\n",
      "iteration 38 / 300: loss 0.607180\n",
      "iteration 38 / 300: loss 0.607111\n",
      "iteration 38 / 300: loss 0.612519\n",
      "iteration 38 / 300: loss 0.607160\n",
      "iteration 38 / 300: loss 0.600021\n",
      "iteration 38 / 300: loss 0.587331\n",
      "iteration 38 / 300: loss 0.605748\n",
      "iteration 38 / 300: loss 0.620461\n",
      "iteration 38 / 300: loss 0.620324\n",
      "iteration 38 / 300: loss 0.588489\n",
      "iteration 38 / 300: loss 0.609843\n",
      "iteration 38 / 300: loss 0.617184\n",
      "iteration 38 / 300: loss 0.608831\n",
      "iteration 38 / 300: loss 0.615577\n",
      "iteration 38 / 300: loss 0.628881\n",
      "iteration 38 / 300: loss 0.591943\n",
      "iteration 38 / 300: loss 0.590225\n",
      "iteration 38 / 300: loss 0.635723\n",
      "iteration 38 / 300: loss 0.615290\n",
      "iteration 38 / 300: loss 0.613672\n",
      "iteration 38 / 300: loss 0.606160\n",
      "iteration 38 / 300: loss 0.621183\n",
      "iteration 38 / 300: loss 0.602506\n",
      "iteration 38 / 300: loss 0.589602\n",
      "iteration 38 / 300: loss 0.617711\n",
      "iteration 38 / 300: loss 0.614829\n",
      "iteration 38 / 300: loss 0.604590\n",
      "iteration 38 / 300: loss 0.598483\n",
      "iteration 38 / 300: loss 0.619007\n",
      "iteration 38 / 300: loss 0.604640\n",
      "iteration 38 / 300: loss 0.587023\n",
      "iteration 38 / 300: loss 0.616511\n",
      "iteration 39 / 300: loss 0.586034\n",
      "iteration 39 / 300: loss 0.602251\n",
      "iteration 39 / 300: loss 0.576192\n",
      "iteration 39 / 300: loss 0.604539\n",
      "iteration 39 / 300: loss 0.606372\n",
      "iteration 39 / 300: loss 0.611115\n",
      "iteration 39 / 300: loss 0.621431\n",
      "iteration 39 / 300: loss 0.593962\n",
      "iteration 39 / 300: loss 0.632501\n",
      "iteration 39 / 300: loss 0.601554\n",
      "iteration 39 / 300: loss 0.630093\n",
      "iteration 39 / 300: loss 0.600052\n",
      "iteration 39 / 300: loss 0.607789\n",
      "iteration 39 / 300: loss 0.577594\n",
      "iteration 39 / 300: loss 0.601148\n",
      "iteration 39 / 300: loss 0.609853\n",
      "iteration 39 / 300: loss 0.604944\n",
      "iteration 39 / 300: loss 0.590204\n",
      "iteration 39 / 300: loss 0.623622\n",
      "iteration 39 / 300: loss 0.598531\n",
      "iteration 39 / 300: loss 0.597983\n",
      "iteration 39 / 300: loss 0.601269\n",
      "iteration 39 / 300: loss 0.605572\n",
      "iteration 39 / 300: loss 0.604350\n",
      "iteration 39 / 300: loss 0.619260\n",
      "iteration 39 / 300: loss 0.616075\n",
      "iteration 39 / 300: loss 0.604846\n",
      "iteration 39 / 300: loss 0.601967\n",
      "iteration 39 / 300: loss 0.632549\n",
      "iteration 39 / 300: loss 0.608896\n",
      "iteration 39 / 300: loss 0.605901\n",
      "iteration 39 / 300: loss 0.627574\n",
      "iteration 39 / 300: loss 0.587235\n",
      "iteration 39 / 300: loss 0.605211\n",
      "iteration 39 / 300: loss 0.600147\n",
      "iteration 39 / 300: loss 0.607156\n",
      "iteration 39 / 300: loss 0.602610\n",
      "iteration 39 / 300: loss 0.597980\n",
      "iteration 39 / 300: loss 0.598921\n",
      "iteration 39 / 300: loss 0.623428\n",
      "iteration 39 / 300: loss 0.626816\n",
      "iteration 39 / 300: loss 0.594889\n",
      "iteration 39 / 300: loss 0.589716\n",
      "iteration 39 / 300: loss 0.593529\n",
      "iteration 39 / 300: loss 0.610119\n",
      "iteration 39 / 300: loss 0.591324\n",
      "iteration 39 / 300: loss 0.586941\n",
      "iteration 39 / 300: loss 0.582711\n",
      "iteration 39 / 300: loss 0.579293\n",
      "iteration 39 / 300: loss 0.604972\n",
      "iteration 39 / 300: loss 0.589986\n",
      "iteration 39 / 300: loss 0.589332\n",
      "iteration 39 / 300: loss 0.574801\n",
      "iteration 39 / 300: loss 0.599824\n",
      "iteration 39 / 300: loss 0.619657\n",
      "iteration 39 / 300: loss 0.615410\n",
      "iteration 39 / 300: loss 0.615289\n",
      "iteration 39 / 300: loss 0.601246\n",
      "iteration 39 / 300: loss 0.599697\n",
      "iteration 39 / 300: loss 0.605548\n",
      "iteration 39 / 300: loss 0.605115\n",
      "iteration 39 / 300: loss 0.607083\n",
      "iteration 39 / 300: loss 0.605621\n",
      "iteration 39 / 300: loss 0.604639\n",
      "iteration 39 / 300: loss 0.594357\n",
      "iteration 39 / 300: loss 0.609109\n",
      "iteration 39 / 300: loss 0.606884\n",
      "iteration 39 / 300: loss 0.624278\n",
      "iteration 39 / 300: loss 0.606499\n",
      "iteration 39 / 300: loss 0.606605\n",
      "iteration 39 / 300: loss 0.611990\n",
      "iteration 39 / 300: loss 0.606488\n",
      "iteration 39 / 300: loss 0.599408\n",
      "iteration 39 / 300: loss 0.586775\n",
      "iteration 39 / 300: loss 0.605254\n",
      "iteration 39 / 300: loss 0.619854\n",
      "iteration 39 / 300: loss 0.619848\n",
      "iteration 39 / 300: loss 0.588015\n",
      "iteration 39 / 300: loss 0.609502\n",
      "iteration 39 / 300: loss 0.616628\n",
      "iteration 39 / 300: loss 0.608437\n",
      "iteration 39 / 300: loss 0.615077\n",
      "iteration 39 / 300: loss 0.628385\n",
      "iteration 39 / 300: loss 0.591532\n",
      "iteration 39 / 300: loss 0.589723\n",
      "iteration 39 / 300: loss 0.635372\n",
      "iteration 39 / 300: loss 0.614812\n",
      "iteration 39 / 300: loss 0.613192\n",
      "iteration 39 / 300: loss 0.605694\n",
      "iteration 39 / 300: loss 0.621000\n",
      "iteration 39 / 300: loss 0.602054\n",
      "iteration 39 / 300: loss 0.588930\n",
      "iteration 39 / 300: loss 0.616982\n",
      "iteration 39 / 300: loss 0.614317\n",
      "iteration 39 / 300: loss 0.604115\n",
      "iteration 39 / 300: loss 0.597983\n",
      "iteration 39 / 300: loss 0.618477\n",
      "iteration 39 / 300: loss 0.604262\n",
      "iteration 39 / 300: loss 0.586547\n",
      "iteration 39 / 300: loss 0.615941\n",
      "iteration 40 / 300: loss 0.585369\n",
      "iteration 40 / 300: loss 0.601841\n",
      "iteration 40 / 300: loss 0.575674\n",
      "iteration 40 / 300: loss 0.604043\n",
      "iteration 40 / 300: loss 0.605851\n",
      "iteration 40 / 300: loss 0.610508\n",
      "iteration 40 / 300: loss 0.620858\n",
      "iteration 40 / 300: loss 0.593563\n",
      "iteration 40 / 300: loss 0.631985\n",
      "iteration 40 / 300: loss 0.600912\n",
      "iteration 40 / 300: loss 0.629459\n",
      "iteration 40 / 300: loss 0.599413\n",
      "iteration 40 / 300: loss 0.607215\n",
      "iteration 40 / 300: loss 0.576953\n",
      "iteration 40 / 300: loss 0.600472\n",
      "iteration 40 / 300: loss 0.609051\n",
      "iteration 40 / 300: loss 0.604358\n",
      "iteration 40 / 300: loss 0.589633\n",
      "iteration 40 / 300: loss 0.622823\n",
      "iteration 40 / 300: loss 0.598018\n",
      "iteration 40 / 300: loss 0.597459\n",
      "iteration 40 / 300: loss 0.600619\n",
      "iteration 40 / 300: loss 0.604970\n",
      "iteration 40 / 300: loss 0.603744\n",
      "iteration 40 / 300: loss 0.618699\n",
      "iteration 40 / 300: loss 0.615515\n",
      "iteration 40 / 300: loss 0.604317\n",
      "iteration 40 / 300: loss 0.601464\n",
      "iteration 40 / 300: loss 0.632234\n",
      "iteration 40 / 300: loss 0.608355\n",
      "iteration 40 / 300: loss 0.605448\n",
      "iteration 40 / 300: loss 0.627145\n",
      "iteration 40 / 300: loss 0.586926\n",
      "iteration 40 / 300: loss 0.604845\n",
      "iteration 40 / 300: loss 0.599504\n",
      "iteration 40 / 300: loss 0.606619\n",
      "iteration 40 / 300: loss 0.602218\n",
      "iteration 40 / 300: loss 0.597425\n",
      "iteration 40 / 300: loss 0.598403\n",
      "iteration 40 / 300: loss 0.622865\n",
      "iteration 40 / 300: loss 0.626505\n",
      "iteration 40 / 300: loss 0.594371\n",
      "iteration 40 / 300: loss 0.589149\n",
      "iteration 40 / 300: loss 0.592890\n",
      "iteration 40 / 300: loss 0.609791\n",
      "iteration 40 / 300: loss 0.590985\n",
      "iteration 40 / 300: loss 0.586391\n",
      "iteration 40 / 300: loss 0.582306\n",
      "iteration 40 / 300: loss 0.579000\n",
      "iteration 40 / 300: loss 0.604622\n",
      "iteration 40 / 300: loss 0.589664\n",
      "iteration 40 / 300: loss 0.589045\n",
      "iteration 40 / 300: loss 0.574330\n",
      "iteration 40 / 300: loss 0.599173\n",
      "iteration 40 / 300: loss 0.619050\n",
      "iteration 40 / 300: loss 0.615003\n",
      "iteration 40 / 300: loss 0.614682\n",
      "iteration 40 / 300: loss 0.600795\n",
      "iteration 40 / 300: loss 0.599107\n",
      "iteration 40 / 300: loss 0.604924\n",
      "iteration 40 / 300: loss 0.604496\n",
      "iteration 40 / 300: loss 0.606599\n",
      "iteration 40 / 300: loss 0.604928\n",
      "iteration 40 / 300: loss 0.604096\n",
      "iteration 40 / 300: loss 0.593867\n",
      "iteration 40 / 300: loss 0.608381\n",
      "iteration 40 / 300: loss 0.606334\n",
      "iteration 40 / 300: loss 0.623705\n",
      "iteration 40 / 300: loss 0.605831\n",
      "iteration 40 / 300: loss 0.606130\n",
      "iteration 40 / 300: loss 0.611502\n",
      "iteration 40 / 300: loss 0.605852\n",
      "iteration 40 / 300: loss 0.598810\n",
      "iteration 40 / 300: loss 0.586261\n",
      "iteration 40 / 300: loss 0.604766\n",
      "iteration 40 / 300: loss 0.619264\n",
      "iteration 40 / 300: loss 0.619392\n",
      "iteration 40 / 300: loss 0.587573\n",
      "iteration 40 / 300: loss 0.609154\n",
      "iteration 40 / 300: loss 0.616104\n",
      "iteration 40 / 300: loss 0.608038\n",
      "iteration 40 / 300: loss 0.614601\n",
      "iteration 40 / 300: loss 0.627896\n",
      "iteration 40 / 300: loss 0.591137\n",
      "iteration 40 / 300: loss 0.589252\n",
      "iteration 40 / 300: loss 0.635042\n",
      "iteration 40 / 300: loss 0.614399\n",
      "iteration 40 / 300: loss 0.612731\n",
      "iteration 40 / 300: loss 0.605248\n",
      "iteration 40 / 300: loss 0.620845\n",
      "iteration 40 / 300: loss 0.601659\n",
      "iteration 40 / 300: loss 0.588328\n",
      "iteration 40 / 300: loss 0.616321\n",
      "iteration 40 / 300: loss 0.613836\n",
      "iteration 40 / 300: loss 0.603687\n",
      "iteration 40 / 300: loss 0.597518\n",
      "iteration 40 / 300: loss 0.617970\n",
      "iteration 40 / 300: loss 0.603904\n",
      "iteration 40 / 300: loss 0.586124\n",
      "iteration 40 / 300: loss 0.615427\n",
      "iteration 41 / 300: loss 0.584773\n",
      "iteration 41 / 300: loss 0.601467\n",
      "iteration 41 / 300: loss 0.575183\n",
      "iteration 41 / 300: loss 0.603586\n",
      "iteration 41 / 300: loss 0.605362\n",
      "iteration 41 / 300: loss 0.609950\n",
      "iteration 41 / 300: loss 0.620333\n",
      "iteration 41 / 300: loss 0.593211\n",
      "iteration 41 / 300: loss 0.631539\n",
      "iteration 41 / 300: loss 0.600292\n",
      "iteration 41 / 300: loss 0.628854\n",
      "iteration 41 / 300: loss 0.598820\n",
      "iteration 41 / 300: loss 0.606675\n",
      "iteration 41 / 300: loss 0.576366\n",
      "iteration 41 / 300: loss 0.599834\n",
      "iteration 41 / 300: loss 0.608293\n",
      "iteration 41 / 300: loss 0.603816\n",
      "iteration 41 / 300: loss 0.589099\n",
      "iteration 41 / 300: loss 0.622075\n",
      "iteration 41 / 300: loss 0.597531\n",
      "iteration 41 / 300: loss 0.596975\n",
      "iteration 41 / 300: loss 0.600013\n",
      "iteration 41 / 300: loss 0.604421\n",
      "iteration 41 / 300: loss 0.603181\n",
      "iteration 41 / 300: loss 0.618177\n",
      "iteration 41 / 300: loss 0.614992\n",
      "iteration 41 / 300: loss 0.603800\n",
      "iteration 41 / 300: loss 0.601009\n",
      "iteration 41 / 300: loss 0.631938\n",
      "iteration 41 / 300: loss 0.607858\n",
      "iteration 41 / 300: loss 0.605033\n",
      "iteration 41 / 300: loss 0.626766\n",
      "iteration 41 / 300: loss 0.586651\n",
      "iteration 41 / 300: loss 0.604509\n",
      "iteration 41 / 300: loss 0.598899\n",
      "iteration 41 / 300: loss 0.606117\n",
      "iteration 41 / 300: loss 0.601863\n",
      "iteration 41 / 300: loss 0.596913\n",
      "iteration 41 / 300: loss 0.597911\n",
      "iteration 41 / 300: loss 0.622325\n",
      "iteration 41 / 300: loss 0.626184\n",
      "iteration 41 / 300: loss 0.593880\n",
      "iteration 41 / 300: loss 0.588628\n",
      "iteration 41 / 300: loss 0.592278\n",
      "iteration 41 / 300: loss 0.609474\n",
      "iteration 41 / 300: loss 0.590665\n",
      "iteration 41 / 300: loss 0.585865\n",
      "iteration 41 / 300: loss 0.581918\n",
      "iteration 41 / 300: loss 0.578723\n",
      "iteration 41 / 300: loss 0.604316\n",
      "iteration 41 / 300: loss 0.589351\n",
      "iteration 41 / 300: loss 0.588800\n",
      "iteration 41 / 300: loss 0.573880\n",
      "iteration 41 / 300: loss 0.598587\n",
      "iteration 41 / 300: loss 0.618495\n",
      "iteration 41 / 300: loss 0.614606\n",
      "iteration 41 / 300: loss 0.614127\n",
      "iteration 41 / 300: loss 0.600389\n",
      "iteration 41 / 300: loss 0.598580\n",
      "iteration 41 / 300: loss 0.604356\n",
      "iteration 41 / 300: loss 0.603921\n",
      "iteration 41 / 300: loss 0.606148\n",
      "iteration 41 / 300: loss 0.604286\n",
      "iteration 41 / 300: loss 0.603626\n",
      "iteration 41 / 300: loss 0.593431\n",
      "iteration 41 / 300: loss 0.607701\n",
      "iteration 41 / 300: loss 0.605825\n",
      "iteration 41 / 300: loss 0.623174\n",
      "iteration 41 / 300: loss 0.605201\n",
      "iteration 41 / 300: loss 0.605691\n",
      "iteration 41 / 300: loss 0.611055\n",
      "iteration 41 / 300: loss 0.605260\n",
      "iteration 41 / 300: loss 0.598236\n",
      "iteration 41 / 300: loss 0.585790\n",
      "iteration 41 / 300: loss 0.604290\n",
      "iteration 41 / 300: loss 0.618692\n",
      "iteration 41 / 300: loss 0.618958\n",
      "iteration 41 / 300: loss 0.587162\n",
      "iteration 41 / 300: loss 0.608795\n",
      "iteration 41 / 300: loss 0.615605\n",
      "iteration 41 / 300: loss 0.607640\n",
      "iteration 41 / 300: loss 0.614151\n",
      "iteration 41 / 300: loss 0.627416\n",
      "iteration 41 / 300: loss 0.590751\n",
      "iteration 41 / 300: loss 0.588811\n",
      "iteration 41 / 300: loss 0.634716\n",
      "iteration 41 / 300: loss 0.614028\n",
      "iteration 41 / 300: loss 0.612285\n",
      "iteration 41 / 300: loss 0.604813\n",
      "iteration 41 / 300: loss 0.620698\n",
      "iteration 41 / 300: loss 0.601310\n",
      "iteration 41 / 300: loss 0.587785\n",
      "iteration 41 / 300: loss 0.615721\n",
      "iteration 41 / 300: loss 0.613388\n",
      "iteration 41 / 300: loss 0.603303\n",
      "iteration 41 / 300: loss 0.597090\n",
      "iteration 41 / 300: loss 0.617480\n",
      "iteration 41 / 300: loss 0.603561\n",
      "iteration 41 / 300: loss 0.585741\n",
      "iteration 41 / 300: loss 0.614962\n",
      "iteration 42 / 300: loss 0.584239\n",
      "iteration 42 / 300: loss 0.601119\n",
      "iteration 42 / 300: loss 0.574727\n",
      "iteration 42 / 300: loss 0.603164\n",
      "iteration 42 / 300: loss 0.604903\n",
      "iteration 42 / 300: loss 0.609439\n",
      "iteration 42 / 300: loss 0.619854\n",
      "iteration 42 / 300: loss 0.592894\n",
      "iteration 42 / 300: loss 0.631156\n",
      "iteration 42 / 300: loss 0.599695\n",
      "iteration 42 / 300: loss 0.628285\n",
      "iteration 42 / 300: loss 0.598277\n",
      "iteration 42 / 300: loss 0.606172\n",
      "iteration 42 / 300: loss 0.575831\n",
      "iteration 42 / 300: loss 0.599235\n",
      "iteration 42 / 300: loss 0.607578\n",
      "iteration 42 / 300: loss 0.603319\n",
      "iteration 42 / 300: loss 0.588605\n",
      "iteration 42 / 300: loss 0.621378\n",
      "iteration 42 / 300: loss 0.597064\n",
      "iteration 42 / 300: loss 0.596527\n",
      "iteration 42 / 300: loss 0.599453\n",
      "iteration 42 / 300: loss 0.603907\n",
      "iteration 42 / 300: loss 0.602659\n",
      "iteration 42 / 300: loss 0.617686\n",
      "iteration 42 / 300: loss 0.614494\n",
      "iteration 42 / 300: loss 0.603300\n",
      "iteration 42 / 300: loss 0.600603\n",
      "iteration 42 / 300: loss 0.631654\n",
      "iteration 42 / 300: loss 0.607395\n",
      "iteration 42 / 300: loss 0.604650\n",
      "iteration 42 / 300: loss 0.626425\n",
      "iteration 42 / 300: loss 0.586403\n",
      "iteration 42 / 300: loss 0.604204\n",
      "iteration 42 / 300: loss 0.598330\n",
      "iteration 42 / 300: loss 0.605648\n",
      "iteration 42 / 300: loss 0.601525\n",
      "iteration 42 / 300: loss 0.596442\n",
      "iteration 42 / 300: loss 0.597453\n",
      "iteration 42 / 300: loss 0.621812\n",
      "iteration 42 / 300: loss 0.625863\n",
      "iteration 42 / 300: loss 0.593410\n",
      "iteration 42 / 300: loss 0.588146\n",
      "iteration 42 / 300: loss 0.591701\n",
      "iteration 42 / 300: loss 0.609165\n",
      "iteration 42 / 300: loss 0.590359\n",
      "iteration 42 / 300: loss 0.585357\n",
      "iteration 42 / 300: loss 0.581543\n",
      "iteration 42 / 300: loss 0.578453\n",
      "iteration 42 / 300: loss 0.604048\n",
      "iteration 42 / 300: loss 0.589043\n",
      "iteration 42 / 300: loss 0.588580\n",
      "iteration 42 / 300: loss 0.573453\n",
      "iteration 42 / 300: loss 0.598053\n",
      "iteration 42 / 300: loss 0.617985\n",
      "iteration 42 / 300: loss 0.614218\n",
      "iteration 42 / 300: loss 0.613619\n",
      "iteration 42 / 300: loss 0.600020\n",
      "iteration 42 / 300: loss 0.598106\n",
      "iteration 42 / 300: loss 0.603832\n",
      "iteration 42 / 300: loss 0.603393\n",
      "iteration 42 / 300: loss 0.605730\n",
      "iteration 42 / 300: loss 0.603693\n",
      "iteration 42 / 300: loss 0.603211\n",
      "iteration 42 / 300: loss 0.593037\n",
      "iteration 42 / 300: loss 0.607067\n",
      "iteration 42 / 300: loss 0.605349\n",
      "iteration 42 / 300: loss 0.622691\n",
      "iteration 42 / 300: loss 0.604617\n",
      "iteration 42 / 300: loss 0.605290\n",
      "iteration 42 / 300: loss 0.610646\n",
      "iteration 42 / 300: loss 0.604712\n",
      "iteration 42 / 300: loss 0.597696\n",
      "iteration 42 / 300: loss 0.585357\n",
      "iteration 42 / 300: loss 0.603829\n",
      "iteration 42 / 300: loss 0.618140\n",
      "iteration 42 / 300: loss 0.618545\n",
      "iteration 42 / 300: loss 0.586776\n",
      "iteration 42 / 300: loss 0.608427\n",
      "iteration 42 / 300: loss 0.615124\n",
      "iteration 42 / 300: loss 0.607249\n",
      "iteration 42 / 300: loss 0.613730\n",
      "iteration 42 / 300: loss 0.626947\n",
      "iteration 42 / 300: loss 0.590373\n",
      "iteration 42 / 300: loss 0.588401\n",
      "iteration 42 / 300: loss 0.634388\n",
      "iteration 42 / 300: loss 0.613690\n",
      "iteration 42 / 300: loss 0.611855\n",
      "iteration 42 / 300: loss 0.604391\n",
      "iteration 42 / 300: loss 0.620544\n",
      "iteration 42 / 300: loss 0.600992\n",
      "iteration 42 / 300: loss 0.587293\n",
      "iteration 42 / 300: loss 0.615179\n",
      "iteration 42 / 300: loss 0.612975\n",
      "iteration 42 / 300: loss 0.602956\n",
      "iteration 42 / 300: loss 0.596700\n",
      "iteration 42 / 300: loss 0.617006\n",
      "iteration 42 / 300: loss 0.603231\n",
      "iteration 42 / 300: loss 0.585393\n",
      "iteration 42 / 300: loss 0.614539\n",
      "iteration 43 / 300: loss 0.583761\n",
      "iteration 43 / 300: loss 0.600792\n",
      "iteration 43 / 300: loss 0.574305\n",
      "iteration 43 / 300: loss 0.602775\n",
      "iteration 43 / 300: loss 0.604470\n",
      "iteration 43 / 300: loss 0.608974\n",
      "iteration 43 / 300: loss 0.619420\n",
      "iteration 43 / 300: loss 0.592601\n",
      "iteration 43 / 300: loss 0.630820\n",
      "iteration 43 / 300: loss 0.599122\n",
      "iteration 43 / 300: loss 0.627753\n",
      "iteration 43 / 300: loss 0.597784\n",
      "iteration 43 / 300: loss 0.605704\n",
      "iteration 43 / 300: loss 0.575346\n",
      "iteration 43 / 300: loss 0.598675\n",
      "iteration 43 / 300: loss 0.606909\n",
      "iteration 43 / 300: loss 0.602861\n",
      "iteration 43 / 300: loss 0.588151\n",
      "iteration 43 / 300: loss 0.620730\n",
      "iteration 43 / 300: loss 0.596616\n",
      "iteration 43 / 300: loss 0.596113\n",
      "iteration 43 / 300: loss 0.598942\n",
      "iteration 43 / 300: loss 0.603420\n",
      "iteration 43 / 300: loss 0.602175\n",
      "iteration 43 / 300: loss 0.617221\n",
      "iteration 43 / 300: loss 0.614016\n",
      "iteration 43 / 300: loss 0.602826\n",
      "iteration 43 / 300: loss 0.600244\n",
      "iteration 43 / 300: loss 0.631379\n",
      "iteration 43 / 300: loss 0.606960\n",
      "iteration 43 / 300: loss 0.604297\n",
      "iteration 43 / 300: loss 0.626112\n",
      "iteration 43 / 300: loss 0.586171\n",
      "iteration 43 / 300: loss 0.603926\n",
      "iteration 43 / 300: loss 0.597795\n",
      "iteration 43 / 300: loss 0.605212\n",
      "iteration 43 / 300: loss 0.601196\n",
      "iteration 43 / 300: loss 0.596008\n",
      "iteration 43 / 300: loss 0.597034\n",
      "iteration 43 / 300: loss 0.621328\n",
      "iteration 43 / 300: loss 0.625552\n",
      "iteration 43 / 300: loss 0.592960\n",
      "iteration 43 / 300: loss 0.587698\n",
      "iteration 43 / 300: loss 0.591164\n",
      "iteration 43 / 300: loss 0.608861\n",
      "iteration 43 / 300: loss 0.590061\n",
      "iteration 43 / 300: loss 0.584868\n",
      "iteration 43 / 300: loss 0.581183\n",
      "iteration 43 / 300: loss 0.578187\n",
      "iteration 43 / 300: loss 0.603809\n",
      "iteration 43 / 300: loss 0.588738\n",
      "iteration 43 / 300: loss 0.588372\n",
      "iteration 43 / 300: loss 0.573051\n",
      "iteration 43 / 300: loss 0.597560\n",
      "iteration 43 / 300: loss 0.617516\n",
      "iteration 43 / 300: loss 0.613836\n",
      "iteration 43 / 300: loss 0.613150\n",
      "iteration 43 / 300: loss 0.599684\n",
      "iteration 43 / 300: loss 0.597675\n",
      "iteration 43 / 300: loss 0.603345\n",
      "iteration 43 / 300: loss 0.602913\n",
      "iteration 43 / 300: loss 0.605349\n",
      "iteration 43 / 300: loss 0.603146\n",
      "iteration 43 / 300: loss 0.602837\n",
      "iteration 43 / 300: loss 0.592671\n",
      "iteration 43 / 300: loss 0.606481\n",
      "iteration 43 / 300: loss 0.604903\n",
      "iteration 43 / 300: loss 0.622259\n",
      "iteration 43 / 300: loss 0.604081\n",
      "iteration 43 / 300: loss 0.604926\n",
      "iteration 43 / 300: loss 0.610269\n",
      "iteration 43 / 300: loss 0.604204\n",
      "iteration 43 / 300: loss 0.597189\n",
      "iteration 43 / 300: loss 0.584958\n",
      "iteration 43 / 300: loss 0.603387\n",
      "iteration 43 / 300: loss 0.617613\n",
      "iteration 43 / 300: loss 0.618150\n",
      "iteration 43 / 300: loss 0.586414\n",
      "iteration 43 / 300: loss 0.608055\n",
      "iteration 43 / 300: loss 0.614660\n",
      "iteration 43 / 300: loss 0.606870\n",
      "iteration 43 / 300: loss 0.613337\n",
      "iteration 43 / 300: loss 0.626492\n",
      "iteration 43 / 300: loss 0.590001\n",
      "iteration 43 / 300: loss 0.588020\n",
      "iteration 43 / 300: loss 0.634064\n",
      "iteration 43 / 300: loss 0.613376\n",
      "iteration 43 / 300: loss 0.611443\n",
      "iteration 43 / 300: loss 0.603985\n",
      "iteration 43 / 300: loss 0.620374\n",
      "iteration 43 / 300: loss 0.600692\n",
      "iteration 43 / 300: loss 0.586846\n",
      "iteration 43 / 300: loss 0.614694\n",
      "iteration 43 / 300: loss 0.612597\n",
      "iteration 43 / 300: loss 0.602641\n",
      "iteration 43 / 300: loss 0.596348\n",
      "iteration 43 / 300: loss 0.616554\n",
      "iteration 43 / 300: loss 0.602915\n",
      "iteration 43 / 300: loss 0.585075\n",
      "iteration 43 / 300: loss 0.614153\n",
      "iteration 44 / 300: loss 0.583332\n",
      "iteration 44 / 300: loss 0.600483\n",
      "iteration 44 / 300: loss 0.573916\n",
      "iteration 44 / 300: loss 0.602418\n",
      "iteration 44 / 300: loss 0.604060\n",
      "iteration 44 / 300: loss 0.608551\n",
      "iteration 44 / 300: loss 0.619029\n",
      "iteration 44 / 300: loss 0.592324\n",
      "iteration 44 / 300: loss 0.630522\n",
      "iteration 44 / 300: loss 0.598576\n",
      "iteration 44 / 300: loss 0.627260\n",
      "iteration 44 / 300: loss 0.597336\n",
      "iteration 44 / 300: loss 0.605270\n",
      "iteration 44 / 300: loss 0.574910\n",
      "iteration 44 / 300: loss 0.598156\n",
      "iteration 44 / 300: loss 0.606287\n",
      "iteration 44 / 300: loss 0.602441\n",
      "iteration 44 / 300: loss 0.587737\n",
      "iteration 44 / 300: loss 0.620132\n",
      "iteration 44 / 300: loss 0.596189\n",
      "iteration 44 / 300: loss 0.595730\n",
      "iteration 44 / 300: loss 0.598476\n",
      "iteration 44 / 300: loss 0.602958\n",
      "iteration 44 / 300: loss 0.601728\n",
      "iteration 44 / 300: loss 0.616781\n",
      "iteration 44 / 300: loss 0.613556\n",
      "iteration 44 / 300: loss 0.602378\n",
      "iteration 44 / 300: loss 0.599925\n",
      "iteration 44 / 300: loss 0.631111\n",
      "iteration 44 / 300: loss 0.606550\n",
      "iteration 44 / 300: loss 0.603972\n",
      "iteration 44 / 300: loss 0.625820\n",
      "iteration 44 / 300: loss 0.585946\n",
      "iteration 44 / 300: loss 0.603668\n",
      "iteration 44 / 300: loss 0.597293\n",
      "iteration 44 / 300: loss 0.604807\n",
      "iteration 44 / 300: loss 0.600870\n",
      "iteration 44 / 300: loss 0.595609\n",
      "iteration 44 / 300: loss 0.596655\n",
      "iteration 44 / 300: loss 0.620875\n",
      "iteration 44 / 300: loss 0.625254\n",
      "iteration 44 / 300: loss 0.592529\n",
      "iteration 44 / 300: loss 0.587281\n",
      "iteration 44 / 300: loss 0.590670\n",
      "iteration 44 / 300: loss 0.608560\n",
      "iteration 44 / 300: loss 0.589769\n",
      "iteration 44 / 300: loss 0.584397\n",
      "iteration 44 / 300: loss 0.580840\n",
      "iteration 44 / 300: loss 0.577923\n",
      "iteration 44 / 300: loss 0.603589\n",
      "iteration 44 / 300: loss 0.588439\n",
      "iteration 44 / 300: loss 0.588170\n",
      "iteration 44 / 300: loss 0.572675\n",
      "iteration 44 / 300: loss 0.597101\n",
      "iteration 44 / 300: loss 0.617082\n",
      "iteration 44 / 300: loss 0.613463\n",
      "iteration 44 / 300: loss 0.612713\n",
      "iteration 44 / 300: loss 0.599373\n",
      "iteration 44 / 300: loss 0.597279\n",
      "iteration 44 / 300: loss 0.602892\n",
      "iteration 44 / 300: loss 0.602478\n",
      "iteration 44 / 300: loss 0.605003\n",
      "iteration 44 / 300: loss 0.602644\n",
      "iteration 44 / 300: loss 0.602495\n",
      "iteration 44 / 300: loss 0.592326\n",
      "iteration 44 / 300: loss 0.605941\n",
      "iteration 44 / 300: loss 0.604483\n",
      "iteration 44 / 300: loss 0.621870\n",
      "iteration 44 / 300: loss 0.603589\n",
      "iteration 44 / 300: loss 0.604592\n",
      "iteration 44 / 300: loss 0.609917\n",
      "iteration 44 / 300: loss 0.603734\n",
      "iteration 44 / 300: loss 0.596714\n",
      "iteration 44 / 300: loss 0.584588\n",
      "iteration 44 / 300: loss 0.602968\n",
      "iteration 44 / 300: loss 0.617116\n",
      "iteration 44 / 300: loss 0.617773\n",
      "iteration 44 / 300: loss 0.586075\n",
      "iteration 44 / 300: loss 0.607681\n",
      "iteration 44 / 300: loss 0.614216\n",
      "iteration 44 / 300: loss 0.606507\n",
      "iteration 44 / 300: loss 0.612970\n",
      "iteration 44 / 300: loss 0.626053\n",
      "iteration 44 / 300: loss 0.589637\n",
      "iteration 44 / 300: loss 0.587665\n",
      "iteration 44 / 300: loss 0.633743\n",
      "iteration 44 / 300: loss 0.613082\n",
      "iteration 44 / 300: loss 0.611050\n",
      "iteration 44 / 300: loss 0.603598\n",
      "iteration 44 / 300: loss 0.620186\n",
      "iteration 44 / 300: loss 0.600406\n",
      "iteration 44 / 300: loss 0.586434\n",
      "iteration 44 / 300: loss 0.614261\n",
      "iteration 44 / 300: loss 0.612252\n",
      "iteration 44 / 300: loss 0.602352\n",
      "iteration 44 / 300: loss 0.596031\n",
      "iteration 44 / 300: loss 0.616129\n",
      "iteration 44 / 300: loss 0.602613\n",
      "iteration 44 / 300: loss 0.584784\n",
      "iteration 44 / 300: loss 0.613799\n",
      "iteration 45 / 300: loss 0.582945\n",
      "iteration 45 / 300: loss 0.600190\n",
      "iteration 45 / 300: loss 0.573557\n",
      "iteration 45 / 300: loss 0.602087\n",
      "iteration 45 / 300: loss 0.603670\n",
      "iteration 45 / 300: loss 0.608164\n",
      "iteration 45 / 300: loss 0.618679\n",
      "iteration 45 / 300: loss 0.592059\n",
      "iteration 45 / 300: loss 0.630253\n",
      "iteration 45 / 300: loss 0.598062\n",
      "iteration 45 / 300: loss 0.626803\n",
      "iteration 45 / 300: loss 0.596932\n",
      "iteration 45 / 300: loss 0.604867\n",
      "iteration 45 / 300: loss 0.574521\n",
      "iteration 45 / 300: loss 0.597678\n",
      "iteration 45 / 300: loss 0.605712\n",
      "iteration 45 / 300: loss 0.602053\n",
      "iteration 45 / 300: loss 0.587359\n",
      "iteration 45 / 300: loss 0.619585\n",
      "iteration 45 / 300: loss 0.595785\n",
      "iteration 45 / 300: loss 0.595375\n",
      "iteration 45 / 300: loss 0.598051\n",
      "iteration 45 / 300: loss 0.602518\n",
      "iteration 45 / 300: loss 0.601314\n",
      "iteration 45 / 300: loss 0.616367\n",
      "iteration 45 / 300: loss 0.613114\n",
      "iteration 45 / 300: loss 0.601958\n",
      "iteration 45 / 300: loss 0.599639\n",
      "iteration 45 / 300: loss 0.630851\n",
      "iteration 45 / 300: loss 0.606164\n",
      "iteration 45 / 300: loss 0.603669\n",
      "iteration 45 / 300: loss 0.625543\n",
      "iteration 45 / 300: loss 0.585724\n",
      "iteration 45 / 300: loss 0.603424\n",
      "iteration 45 / 300: loss 0.596821\n",
      "iteration 45 / 300: loss 0.604430\n",
      "iteration 45 / 300: loss 0.600548\n",
      "iteration 45 / 300: loss 0.595241\n",
      "iteration 45 / 300: loss 0.596310\n",
      "iteration 45 / 300: loss 0.620453\n",
      "iteration 45 / 300: loss 0.624973\n",
      "iteration 45 / 300: loss 0.592118\n",
      "iteration 45 / 300: loss 0.586895\n",
      "iteration 45 / 300: loss 0.590218\n",
      "iteration 45 / 300: loss 0.608262\n",
      "iteration 45 / 300: loss 0.589484\n",
      "iteration 45 / 300: loss 0.583947\n",
      "iteration 45 / 300: loss 0.580514\n",
      "iteration 45 / 300: loss 0.577662\n",
      "iteration 45 / 300: loss 0.603384\n",
      "iteration 45 / 300: loss 0.588150\n",
      "iteration 45 / 300: loss 0.587969\n",
      "iteration 45 / 300: loss 0.572325\n",
      "iteration 45 / 300: loss 0.596672\n",
      "iteration 45 / 300: loss 0.616681\n",
      "iteration 45 / 300: loss 0.613103\n",
      "iteration 45 / 300: loss 0.612304\n",
      "iteration 45 / 300: loss 0.599083\n",
      "iteration 45 / 300: loss 0.596913\n",
      "iteration 45 / 300: loss 0.602474\n",
      "iteration 45 / 300: loss 0.602080\n",
      "iteration 45 / 300: loss 0.604690\n",
      "iteration 45 / 300: loss 0.602187\n",
      "iteration 45 / 300: loss 0.602183\n",
      "iteration 45 / 300: loss 0.592000\n",
      "iteration 45 / 300: loss 0.605445\n",
      "iteration 45 / 300: loss 0.604088\n",
      "iteration 45 / 300: loss 0.621517\n",
      "iteration 45 / 300: loss 0.603139\n",
      "iteration 45 / 300: loss 0.604286\n",
      "iteration 45 / 300: loss 0.609587\n",
      "iteration 45 / 300: loss 0.603298\n",
      "iteration 45 / 300: loss 0.596267\n",
      "iteration 45 / 300: loss 0.584246\n",
      "iteration 45 / 300: loss 0.602573\n",
      "iteration 45 / 300: loss 0.616649\n",
      "iteration 45 / 300: loss 0.617416\n",
      "iteration 45 / 300: loss 0.585759\n",
      "iteration 45 / 300: loss 0.607310\n",
      "iteration 45 / 300: loss 0.613792\n",
      "iteration 45 / 300: loss 0.606159\n",
      "iteration 45 / 300: loss 0.612625\n",
      "iteration 45 / 300: loss 0.625634\n",
      "iteration 45 / 300: loss 0.589283\n",
      "iteration 45 / 300: loss 0.587330\n",
      "iteration 45 / 300: loss 0.633426\n",
      "iteration 45 / 300: loss 0.612806\n",
      "iteration 45 / 300: loss 0.610675\n",
      "iteration 45 / 300: loss 0.603231\n",
      "iteration 45 / 300: loss 0.619979\n",
      "iteration 45 / 300: loss 0.600134\n",
      "iteration 45 / 300: loss 0.586049\n",
      "iteration 45 / 300: loss 0.613870\n",
      "iteration 45 / 300: loss 0.611935\n",
      "iteration 45 / 300: loss 0.602082\n",
      "iteration 45 / 300: loss 0.595743\n",
      "iteration 45 / 300: loss 0.615735\n",
      "iteration 45 / 300: loss 0.602328\n",
      "iteration 45 / 300: loss 0.584517\n",
      "iteration 45 / 300: loss 0.613474\n",
      "iteration 46 / 300: loss 0.582593\n",
      "iteration 46 / 300: loss 0.599914\n",
      "iteration 46 / 300: loss 0.573225\n",
      "iteration 46 / 300: loss 0.601780\n",
      "iteration 46 / 300: loss 0.603300\n",
      "iteration 46 / 300: loss 0.607812\n",
      "iteration 46 / 300: loss 0.618365\n",
      "iteration 46 / 300: loss 0.591805\n",
      "iteration 46 / 300: loss 0.630009\n",
      "iteration 46 / 300: loss 0.597582\n",
      "iteration 46 / 300: loss 0.626380\n",
      "iteration 46 / 300: loss 0.596569\n",
      "iteration 46 / 300: loss 0.604494\n",
      "iteration 46 / 300: loss 0.574176\n",
      "iteration 46 / 300: loss 0.597239\n",
      "iteration 46 / 300: loss 0.605184\n",
      "iteration 46 / 300: loss 0.601696\n",
      "iteration 46 / 300: loss 0.587015\n",
      "iteration 46 / 300: loss 0.619084\n",
      "iteration 46 / 300: loss 0.595406\n",
      "iteration 46 / 300: loss 0.595045\n",
      "iteration 46 / 300: loss 0.597665\n",
      "iteration 46 / 300: loss 0.602101\n",
      "iteration 46 / 300: loss 0.600931\n",
      "iteration 46 / 300: loss 0.615977\n",
      "iteration 46 / 300: loss 0.612690\n",
      "iteration 46 / 300: loss 0.601564\n",
      "iteration 46 / 300: loss 0.599380\n",
      "iteration 46 / 300: loss 0.630601\n",
      "iteration 46 / 300: loss 0.605801\n",
      "iteration 46 / 300: loss 0.603385\n",
      "iteration 46 / 300: loss 0.625278\n",
      "iteration 46 / 300: loss 0.585499\n",
      "iteration 46 / 300: loss 0.603189\n",
      "iteration 46 / 300: loss 0.596378\n",
      "iteration 46 / 300: loss 0.604079\n",
      "iteration 46 / 300: loss 0.600230\n",
      "iteration 46 / 300: loss 0.594902\n",
      "iteration 46 / 300: loss 0.595993\n",
      "iteration 46 / 300: loss 0.620059\n",
      "iteration 46 / 300: loss 0.624709\n",
      "iteration 46 / 300: loss 0.591728\n",
      "iteration 46 / 300: loss 0.586537\n",
      "iteration 46 / 300: loss 0.589806\n",
      "iteration 46 / 300: loss 0.607967\n",
      "iteration 46 / 300: loss 0.589206\n",
      "iteration 46 / 300: loss 0.583519\n",
      "iteration 46 / 300: loss 0.580203\n",
      "iteration 46 / 300: loss 0.577409\n",
      "iteration 46 / 300: loss 0.603190\n",
      "iteration 46 / 300: loss 0.587873\n",
      "iteration 46 / 300: loss 0.587770\n",
      "iteration 46 / 300: loss 0.572001\n",
      "iteration 46 / 300: loss 0.596274\n",
      "iteration 46 / 300: loss 0.616309\n",
      "iteration 46 / 300: loss 0.612758\n",
      "iteration 46 / 300: loss 0.611920\n",
      "iteration 46 / 300: loss 0.598812\n",
      "iteration 46 / 300: loss 0.596576\n",
      "iteration 46 / 300: loss 0.602089\n",
      "iteration 46 / 300: loss 0.601717\n",
      "iteration 46 / 300: loss 0.604405\n",
      "iteration 46 / 300: loss 0.601770\n",
      "iteration 46 / 300: loss 0.601896\n",
      "iteration 46 / 300: loss 0.591691\n",
      "iteration 46 / 300: loss 0.604991\n",
      "iteration 46 / 300: loss 0.603718\n",
      "iteration 46 / 300: loss 0.621193\n",
      "iteration 46 / 300: loss 0.602729\n",
      "iteration 46 / 300: loss 0.604004\n",
      "iteration 46 / 300: loss 0.609278\n",
      "iteration 46 / 300: loss 0.602895\n",
      "iteration 46 / 300: loss 0.595849\n",
      "iteration 46 / 300: loss 0.583929\n",
      "iteration 46 / 300: loss 0.602202\n",
      "iteration 46 / 300: loss 0.616213\n",
      "iteration 46 / 300: loss 0.617079\n",
      "iteration 46 / 300: loss 0.585465\n",
      "iteration 46 / 300: loss 0.606943\n",
      "iteration 46 / 300: loss 0.613391\n",
      "iteration 46 / 300: loss 0.605827\n",
      "iteration 46 / 300: loss 0.612299\n",
      "iteration 46 / 300: loss 0.625233\n",
      "iteration 46 / 300: loss 0.588942\n",
      "iteration 46 / 300: loss 0.587017\n",
      "iteration 46 / 300: loss 0.633115\n",
      "iteration 46 / 300: loss 0.612546\n",
      "iteration 46 / 300: loss 0.610321\n",
      "iteration 46 / 300: loss 0.602887\n",
      "iteration 46 / 300: loss 0.619756\n",
      "iteration 46 / 300: loss 0.599877\n",
      "iteration 46 / 300: loss 0.585686\n",
      "iteration 46 / 300: loss 0.613516\n",
      "iteration 46 / 300: loss 0.611640\n",
      "iteration 46 / 300: loss 0.601828\n",
      "iteration 46 / 300: loss 0.595480\n",
      "iteration 46 / 300: loss 0.615367\n",
      "iteration 46 / 300: loss 0.602060\n",
      "iteration 46 / 300: loss 0.584271\n",
      "iteration 46 / 300: loss 0.613175\n",
      "iteration 47 / 300: loss 0.582272\n",
      "iteration 47 / 300: loss 0.599655\n",
      "iteration 47 / 300: loss 0.572920\n",
      "iteration 47 / 300: loss 0.601494\n",
      "iteration 47 / 300: loss 0.602951\n",
      "iteration 47 / 300: loss 0.607488\n",
      "iteration 47 / 300: loss 0.618082\n",
      "iteration 47 / 300: loss 0.591560\n",
      "iteration 47 / 300: loss 0.629788\n",
      "iteration 47 / 300: loss 0.597139\n",
      "iteration 47 / 300: loss 0.625987\n",
      "iteration 47 / 300: loss 0.596245\n",
      "iteration 47 / 300: loss 0.604149\n",
      "iteration 47 / 300: loss 0.573869\n",
      "iteration 47 / 300: loss 0.596839\n",
      "iteration 47 / 300: loss 0.604699\n",
      "iteration 47 / 300: loss 0.601367\n",
      "iteration 47 / 300: loss 0.586701\n",
      "iteration 47 / 300: loss 0.618628\n",
      "iteration 47 / 300: loss 0.595052\n",
      "iteration 47 / 300: loss 0.594739\n",
      "iteration 47 / 300: loss 0.597314\n",
      "iteration 47 / 300: loss 0.601703\n",
      "iteration 47 / 300: loss 0.600577\n",
      "iteration 47 / 300: loss 0.615613\n",
      "iteration 47 / 300: loss 0.612284\n",
      "iteration 47 / 300: loss 0.601196\n",
      "iteration 47 / 300: loss 0.599144\n",
      "iteration 47 / 300: loss 0.630362\n",
      "iteration 47 / 300: loss 0.605459\n",
      "iteration 47 / 300: loss 0.603116\n",
      "iteration 47 / 300: loss 0.625025\n",
      "iteration 47 / 300: loss 0.585273\n",
      "iteration 47 / 300: loss 0.602962\n",
      "iteration 47 / 300: loss 0.595964\n",
      "iteration 47 / 300: loss 0.603751\n",
      "iteration 47 / 300: loss 0.599919\n",
      "iteration 47 / 300: loss 0.594588\n",
      "iteration 47 / 300: loss 0.595700\n",
      "iteration 47 / 300: loss 0.619691\n",
      "iteration 47 / 300: loss 0.624463\n",
      "iteration 47 / 300: loss 0.591359\n",
      "iteration 47 / 300: loss 0.586207\n",
      "iteration 47 / 300: loss 0.589430\n",
      "iteration 47 / 300: loss 0.607677\n",
      "iteration 47 / 300: loss 0.588937\n",
      "iteration 47 / 300: loss 0.583118\n",
      "iteration 47 / 300: loss 0.579908\n",
      "iteration 47 / 300: loss 0.577166\n",
      "iteration 47 / 300: loss 0.603003\n",
      "iteration 47 / 300: loss 0.587610\n",
      "iteration 47 / 300: loss 0.587574\n",
      "iteration 47 / 300: loss 0.571700\n",
      "iteration 47 / 300: loss 0.595906\n",
      "iteration 47 / 300: loss 0.615964\n",
      "iteration 47 / 300: loss 0.612433\n",
      "iteration 47 / 300: loss 0.611560\n",
      "iteration 47 / 300: loss 0.598558\n",
      "iteration 47 / 300: loss 0.596265\n",
      "iteration 47 / 300: loss 0.601736\n",
      "iteration 47 / 300: loss 0.601383\n",
      "iteration 47 / 300: loss 0.604144\n",
      "iteration 47 / 300: loss 0.601393\n",
      "iteration 47 / 300: loss 0.601632\n",
      "iteration 47 / 300: loss 0.591398\n",
      "iteration 47 / 300: loss 0.604577\n",
      "iteration 47 / 300: loss 0.603372\n",
      "iteration 47 / 300: loss 0.620895\n",
      "iteration 47 / 300: loss 0.602357\n",
      "iteration 47 / 300: loss 0.603746\n",
      "iteration 47 / 300: loss 0.608986\n",
      "iteration 47 / 300: loss 0.602523\n",
      "iteration 47 / 300: loss 0.595458\n",
      "iteration 47 / 300: loss 0.583635\n",
      "iteration 47 / 300: loss 0.601857\n",
      "iteration 47 / 300: loss 0.615808\n",
      "iteration 47 / 300: loss 0.616763\n",
      "iteration 47 / 300: loss 0.585194\n",
      "iteration 47 / 300: loss 0.606586\n",
      "iteration 47 / 300: loss 0.613015\n",
      "iteration 47 / 300: loss 0.605513\n",
      "iteration 47 / 300: loss 0.611990\n",
      "iteration 47 / 300: loss 0.624854\n",
      "iteration 47 / 300: loss 0.588616\n",
      "iteration 47 / 300: loss 0.586724\n",
      "iteration 47 / 300: loss 0.632810\n",
      "iteration 47 / 300: loss 0.612301\n",
      "iteration 47 / 300: loss 0.609986\n",
      "iteration 47 / 300: loss 0.602564\n",
      "iteration 47 / 300: loss 0.619525\n",
      "iteration 47 / 300: loss 0.599634\n",
      "iteration 47 / 300: loss 0.585345\n",
      "iteration 47 / 300: loss 0.613193\n",
      "iteration 47 / 300: loss 0.611364\n",
      "iteration 47 / 300: loss 0.601586\n",
      "iteration 47 / 300: loss 0.595236\n",
      "iteration 47 / 300: loss 0.615023\n",
      "iteration 47 / 300: loss 0.601807\n",
      "iteration 47 / 300: loss 0.584044\n",
      "iteration 47 / 300: loss 0.612900\n",
      "iteration 48 / 300: loss 0.581977\n",
      "iteration 48 / 300: loss 0.599411\n",
      "iteration 48 / 300: loss 0.572638\n",
      "iteration 48 / 300: loss 0.601226\n",
      "iteration 48 / 300: loss 0.602623\n",
      "iteration 48 / 300: loss 0.607191\n",
      "iteration 48 / 300: loss 0.617827\n",
      "iteration 48 / 300: loss 0.591324\n",
      "iteration 48 / 300: loss 0.629586\n",
      "iteration 48 / 300: loss 0.596733\n",
      "iteration 48 / 300: loss 0.625622\n",
      "iteration 48 / 300: loss 0.595956\n",
      "iteration 48 / 300: loss 0.603832\n",
      "iteration 48 / 300: loss 0.573598\n",
      "iteration 48 / 300: loss 0.596474\n",
      "iteration 48 / 300: loss 0.604255\n",
      "iteration 48 / 300: loss 0.601066\n",
      "iteration 48 / 300: loss 0.586416\n",
      "iteration 48 / 300: loss 0.618213\n",
      "iteration 48 / 300: loss 0.594725\n",
      "iteration 48 / 300: loss 0.594455\n",
      "iteration 48 / 300: loss 0.596995\n",
      "iteration 48 / 300: loss 0.601326\n",
      "iteration 48 / 300: loss 0.600250\n",
      "iteration 48 / 300: loss 0.615274\n",
      "iteration 48 / 300: loss 0.611897\n",
      "iteration 48 / 300: loss 0.600854\n",
      "iteration 48 / 300: loss 0.598927\n",
      "iteration 48 / 300: loss 0.630135\n",
      "iteration 48 / 300: loss 0.605139\n",
      "iteration 48 / 300: loss 0.602863\n",
      "iteration 48 / 300: loss 0.624784\n",
      "iteration 48 / 300: loss 0.585046\n",
      "iteration 48 / 300: loss 0.602741\n",
      "iteration 48 / 300: loss 0.595578\n",
      "iteration 48 / 300: loss 0.603444\n",
      "iteration 48 / 300: loss 0.599618\n",
      "iteration 48 / 300: loss 0.594294\n",
      "iteration 48 / 300: loss 0.595428\n",
      "iteration 48 / 300: loss 0.619348\n",
      "iteration 48 / 300: loss 0.624232\n",
      "iteration 48 / 300: loss 0.591012\n",
      "iteration 48 / 300: loss 0.585901\n",
      "iteration 48 / 300: loss 0.589086\n",
      "iteration 48 / 300: loss 0.607394\n",
      "iteration 48 / 300: loss 0.588677\n",
      "iteration 48 / 300: loss 0.582744\n",
      "iteration 48 / 300: loss 0.579627\n",
      "iteration 48 / 300: loss 0.576935\n",
      "iteration 48 / 300: loss 0.602825\n",
      "iteration 48 / 300: loss 0.587361\n",
      "iteration 48 / 300: loss 0.587383\n",
      "iteration 48 / 300: loss 0.571421\n",
      "iteration 48 / 300: loss 0.595567\n",
      "iteration 48 / 300: loss 0.615643\n",
      "iteration 48 / 300: loss 0.612129\n",
      "iteration 48 / 300: loss 0.611224\n",
      "iteration 48 / 300: loss 0.598319\n",
      "iteration 48 / 300: loss 0.595979\n",
      "iteration 48 / 300: loss 0.601413\n",
      "iteration 48 / 300: loss 0.601075\n",
      "iteration 48 / 300: loss 0.603902\n",
      "iteration 48 / 300: loss 0.601049\n",
      "iteration 48 / 300: loss 0.601389\n",
      "iteration 48 / 300: loss 0.591121\n",
      "iteration 48 / 300: loss 0.604200\n",
      "iteration 48 / 300: loss 0.603052\n",
      "iteration 48 / 300: loss 0.620621\n",
      "iteration 48 / 300: loss 0.602022\n",
      "iteration 48 / 300: loss 0.603507\n",
      "iteration 48 / 300: loss 0.608711\n",
      "iteration 48 / 300: loss 0.602181\n",
      "iteration 48 / 300: loss 0.595095\n",
      "iteration 48 / 300: loss 0.583364\n",
      "iteration 48 / 300: loss 0.601539\n",
      "iteration 48 / 300: loss 0.615433\n",
      "iteration 48 / 300: loss 0.616467\n",
      "iteration 48 / 300: loss 0.584944\n",
      "iteration 48 / 300: loss 0.606240\n",
      "iteration 48 / 300: loss 0.612665\n",
      "iteration 48 / 300: loss 0.605217\n",
      "iteration 48 / 300: loss 0.611696\n",
      "iteration 48 / 300: loss 0.624494\n",
      "iteration 48 / 300: loss 0.588306\n",
      "iteration 48 / 300: loss 0.586453\n",
      "iteration 48 / 300: loss 0.632515\n",
      "iteration 48 / 300: loss 0.612072\n",
      "iteration 48 / 300: loss 0.609674\n",
      "iteration 48 / 300: loss 0.602264\n",
      "iteration 48 / 300: loss 0.619291\n",
      "iteration 48 / 300: loss 0.599405\n",
      "iteration 48 / 300: loss 0.585025\n",
      "iteration 48 / 300: loss 0.612897\n",
      "iteration 48 / 300: loss 0.611105\n",
      "iteration 48 / 300: loss 0.601356\n",
      "iteration 48 / 300: loss 0.595007\n",
      "iteration 48 / 300: loss 0.614701\n",
      "iteration 48 / 300: loss 0.601568\n",
      "iteration 48 / 300: loss 0.583835\n",
      "iteration 48 / 300: loss 0.612644\n",
      "iteration 49 / 300: loss 0.581703\n",
      "iteration 49 / 300: loss 0.599182\n",
      "iteration 49 / 300: loss 0.572377\n",
      "iteration 49 / 300: loss 0.600975\n",
      "iteration 49 / 300: loss 0.602316\n",
      "iteration 49 / 300: loss 0.606918\n",
      "iteration 49 / 300: loss 0.617597\n",
      "iteration 49 / 300: loss 0.591098\n",
      "iteration 49 / 300: loss 0.629401\n",
      "iteration 49 / 300: loss 0.596363\n",
      "iteration 49 / 300: loss 0.625283\n",
      "iteration 49 / 300: loss 0.595697\n",
      "iteration 49 / 300: loss 0.603541\n",
      "iteration 49 / 300: loss 0.573357\n",
      "iteration 49 / 300: loss 0.596143\n",
      "iteration 49 / 300: loss 0.603851\n",
      "iteration 49 / 300: loss 0.600791\n",
      "iteration 49 / 300: loss 0.586157\n",
      "iteration 49 / 300: loss 0.617837\n",
      "iteration 49 / 300: loss 0.594422\n",
      "iteration 49 / 300: loss 0.594191\n",
      "iteration 49 / 300: loss 0.596708\n",
      "iteration 49 / 300: loss 0.600969\n",
      "iteration 49 / 300: loss 0.599949\n",
      "iteration 49 / 300: loss 0.614960\n",
      "iteration 49 / 300: loss 0.611529\n",
      "iteration 49 / 300: loss 0.600536\n",
      "iteration 49 / 300: loss 0.598726\n",
      "iteration 49 / 300: loss 0.629921\n",
      "iteration 49 / 300: loss 0.604840\n",
      "iteration 49 / 300: loss 0.602624\n",
      "iteration 49 / 300: loss 0.624555\n",
      "iteration 49 / 300: loss 0.584819\n",
      "iteration 49 / 300: loss 0.602528\n",
      "iteration 49 / 300: loss 0.595218\n",
      "iteration 49 / 300: loss 0.603158\n",
      "iteration 49 / 300: loss 0.599329\n",
      "iteration 49 / 300: loss 0.594020\n",
      "iteration 49 / 300: loss 0.595172\n",
      "iteration 49 / 300: loss 0.619029\n",
      "iteration 49 / 300: loss 0.624017\n",
      "iteration 49 / 300: loss 0.590687\n",
      "iteration 49 / 300: loss 0.585619\n",
      "iteration 49 / 300: loss 0.588773\n",
      "iteration 49 / 300: loss 0.607121\n",
      "iteration 49 / 300: loss 0.588428\n",
      "iteration 49 / 300: loss 0.582398\n",
      "iteration 49 / 300: loss 0.579361\n",
      "iteration 49 / 300: loss 0.576717\n",
      "iteration 49 / 300: loss 0.602656\n",
      "iteration 49 / 300: loss 0.587128\n",
      "iteration 49 / 300: loss 0.587199\n",
      "iteration 49 / 300: loss 0.571161\n",
      "iteration 49 / 300: loss 0.595255\n",
      "iteration 49 / 300: loss 0.615345\n",
      "iteration 49 / 300: loss 0.611847\n",
      "iteration 49 / 300: loss 0.610912\n",
      "iteration 49 / 300: loss 0.598097\n",
      "iteration 49 / 300: loss 0.595716\n",
      "iteration 49 / 300: loss 0.601118\n",
      "iteration 49 / 300: loss 0.600793\n",
      "iteration 49 / 300: loss 0.603677\n",
      "iteration 49 / 300: loss 0.600737\n",
      "iteration 49 / 300: loss 0.601165\n",
      "iteration 49 / 300: loss 0.590860\n",
      "iteration 49 / 300: loss 0.603857\n",
      "iteration 49 / 300: loss 0.602755\n",
      "iteration 49 / 300: loss 0.620367\n",
      "iteration 49 / 300: loss 0.601722\n",
      "iteration 49 / 300: loss 0.603287\n",
      "iteration 49 / 300: loss 0.608450\n",
      "iteration 49 / 300: loss 0.601867\n",
      "iteration 49 / 300: loss 0.594759\n",
      "iteration 49 / 300: loss 0.583114\n",
      "iteration 49 / 300: loss 0.601247\n",
      "iteration 49 / 300: loss 0.615088\n",
      "iteration 49 / 300: loss 0.616192\n",
      "iteration 49 / 300: loss 0.584713\n",
      "iteration 49 / 300: loss 0.605908\n",
      "iteration 49 / 300: loss 0.612342\n",
      "iteration 49 / 300: loss 0.604938\n",
      "iteration 49 / 300: loss 0.611418\n",
      "iteration 49 / 300: loss 0.624156\n",
      "iteration 49 / 300: loss 0.588013\n",
      "iteration 49 / 300: loss 0.586202\n",
      "iteration 49 / 300: loss 0.632230\n",
      "iteration 49 / 300: loss 0.611857\n",
      "iteration 49 / 300: loss 0.609384\n",
      "iteration 49 / 300: loss 0.601986\n",
      "iteration 49 / 300: loss 0.619059\n",
      "iteration 49 / 300: loss 0.599189\n",
      "iteration 49 / 300: loss 0.584726\n",
      "iteration 49 / 300: loss 0.612626\n",
      "iteration 49 / 300: loss 0.610862\n",
      "iteration 49 / 300: loss 0.601137\n",
      "iteration 49 / 300: loss 0.594791\n",
      "iteration 49 / 300: loss 0.614400\n",
      "iteration 49 / 300: loss 0.601343\n",
      "iteration 49 / 300: loss 0.583640\n",
      "iteration 49 / 300: loss 0.612406\n",
      "iteration 50 / 300: loss 0.581448\n",
      "iteration 50 / 300: loss 0.598967\n",
      "iteration 50 / 300: loss 0.572137\n",
      "iteration 50 / 300: loss 0.600738\n",
      "iteration 50 / 300: loss 0.602029\n",
      "iteration 50 / 300: loss 0.606666\n",
      "iteration 50 / 300: loss 0.617388\n",
      "iteration 50 / 300: loss 0.590884\n",
      "iteration 50 / 300: loss 0.629232\n",
      "iteration 50 / 300: loss 0.596027\n",
      "iteration 50 / 300: loss 0.624967\n",
      "iteration 50 / 300: loss 0.595466\n",
      "iteration 50 / 300: loss 0.603274\n",
      "iteration 50 / 300: loss 0.573143\n",
      "iteration 50 / 300: loss 0.595842\n",
      "iteration 50 / 300: loss 0.603483\n",
      "iteration 50 / 300: loss 0.600541\n",
      "iteration 50 / 300: loss 0.585924\n",
      "iteration 50 / 300: loss 0.617496\n",
      "iteration 50 / 300: loss 0.594143\n",
      "iteration 50 / 300: loss 0.593947\n",
      "iteration 50 / 300: loss 0.596448\n",
      "iteration 50 / 300: loss 0.600631\n",
      "iteration 50 / 300: loss 0.599671\n",
      "iteration 50 / 300: loss 0.614671\n",
      "iteration 50 / 300: loss 0.611181\n",
      "iteration 50 / 300: loss 0.600241\n",
      "iteration 50 / 300: loss 0.598539\n",
      "iteration 50 / 300: loss 0.629721\n",
      "iteration 50 / 300: loss 0.604562\n",
      "iteration 50 / 300: loss 0.602398\n",
      "iteration 50 / 300: loss 0.624340\n",
      "iteration 50 / 300: loss 0.584595\n",
      "iteration 50 / 300: loss 0.602322\n",
      "iteration 50 / 300: loss 0.594883\n",
      "iteration 50 / 300: loss 0.602891\n",
      "iteration 50 / 300: loss 0.599056\n",
      "iteration 50 / 300: loss 0.593762\n",
      "iteration 50 / 300: loss 0.594932\n",
      "iteration 50 / 300: loss 0.618730\n",
      "iteration 50 / 300: loss 0.623816\n",
      "iteration 50 / 300: loss 0.590385\n",
      "iteration 50 / 300: loss 0.585358\n",
      "iteration 50 / 300: loss 0.588487\n",
      "iteration 50 / 300: loss 0.606860\n",
      "iteration 50 / 300: loss 0.588189\n",
      "iteration 50 / 300: loss 0.582079\n",
      "iteration 50 / 300: loss 0.579111\n",
      "iteration 50 / 300: loss 0.576511\n",
      "iteration 50 / 300: loss 0.602494\n",
      "iteration 50 / 300: loss 0.586911\n",
      "iteration 50 / 300: loss 0.587022\n",
      "iteration 50 / 300: loss 0.570920\n",
      "iteration 50 / 300: loss 0.594969\n",
      "iteration 50 / 300: loss 0.615070\n",
      "iteration 50 / 300: loss 0.611588\n",
      "iteration 50 / 300: loss 0.610624\n",
      "iteration 50 / 300: loss 0.597890\n",
      "iteration 50 / 300: loss 0.595473\n",
      "iteration 50 / 300: loss 0.600848\n",
      "iteration 50 / 300: loss 0.600532\n",
      "iteration 50 / 300: loss 0.603468\n",
      "iteration 50 / 300: loss 0.600452\n",
      "iteration 50 / 300: loss 0.600959\n",
      "iteration 50 / 300: loss 0.590614\n",
      "iteration 50 / 300: loss 0.603546\n",
      "iteration 50 / 300: loss 0.602482\n",
      "iteration 50 / 300: loss 0.620134\n",
      "iteration 50 / 300: loss 0.601452\n",
      "iteration 50 / 300: loss 0.603083\n",
      "iteration 50 / 300: loss 0.608205\n",
      "iteration 50 / 300: loss 0.601578\n",
      "iteration 50 / 300: loss 0.594451\n",
      "iteration 50 / 300: loss 0.582882\n",
      "iteration 50 / 300: loss 0.600982\n",
      "iteration 50 / 300: loss 0.614771\n",
      "iteration 50 / 300: loss 0.615935\n",
      "iteration 50 / 300: loss 0.584500\n",
      "iteration 50 / 300: loss 0.605591\n",
      "iteration 50 / 300: loss 0.612044\n",
      "iteration 50 / 300: loss 0.604678\n",
      "iteration 50 / 300: loss 0.611153\n",
      "iteration 50 / 300: loss 0.623838\n",
      "iteration 50 / 300: loss 0.587740\n",
      "iteration 50 / 300: loss 0.585971\n",
      "iteration 50 / 300: loss 0.631957\n",
      "iteration 50 / 300: loss 0.611656\n",
      "iteration 50 / 300: loss 0.609115\n",
      "iteration 50 / 300: loss 0.601728\n",
      "iteration 50 / 300: loss 0.618831\n",
      "iteration 50 / 300: loss 0.598984\n",
      "iteration 50 / 300: loss 0.584448\n",
      "iteration 50 / 300: loss 0.612376\n",
      "iteration 50 / 300: loss 0.610634\n",
      "iteration 50 / 300: loss 0.600927\n",
      "iteration 50 / 300: loss 0.594588\n",
      "iteration 50 / 300: loss 0.614119\n",
      "iteration 50 / 300: loss 0.601131\n",
      "iteration 50 / 300: loss 0.583459\n",
      "iteration 50 / 300: loss 0.612183\n",
      "iteration 51 / 300: loss 0.581211\n",
      "iteration 51 / 300: loss 0.598764\n",
      "iteration 51 / 300: loss 0.571916\n",
      "iteration 51 / 300: loss 0.600515\n",
      "iteration 51 / 300: loss 0.601763\n",
      "iteration 51 / 300: loss 0.606434\n",
      "iteration 51 / 300: loss 0.617199\n",
      "iteration 51 / 300: loss 0.590680\n",
      "iteration 51 / 300: loss 0.629076\n",
      "iteration 51 / 300: loss 0.595722\n",
      "iteration 51 / 300: loss 0.624675\n",
      "iteration 51 / 300: loss 0.595258\n",
      "iteration 51 / 300: loss 0.603031\n",
      "iteration 51 / 300: loss 0.572953\n",
      "iteration 51 / 300: loss 0.595569\n",
      "iteration 51 / 300: loss 0.603149\n",
      "iteration 51 / 300: loss 0.600314\n",
      "iteration 51 / 300: loss 0.585713\n",
      "iteration 51 / 300: loss 0.617188\n",
      "iteration 51 / 300: loss 0.593887\n",
      "iteration 51 / 300: loss 0.593722\n",
      "iteration 51 / 300: loss 0.596214\n",
      "iteration 51 / 300: loss 0.600312\n",
      "iteration 51 / 300: loss 0.599414\n",
      "iteration 51 / 300: loss 0.614405\n",
      "iteration 51 / 300: loss 0.610854\n",
      "iteration 51 / 300: loss 0.599968\n",
      "iteration 51 / 300: loss 0.598365\n",
      "iteration 51 / 300: loss 0.629534\n",
      "iteration 51 / 300: loss 0.604305\n",
      "iteration 51 / 300: loss 0.602187\n",
      "iteration 51 / 300: loss 0.624139\n",
      "iteration 51 / 300: loss 0.584376\n",
      "iteration 51 / 300: loss 0.602125\n",
      "iteration 51 / 300: loss 0.594571\n",
      "iteration 51 / 300: loss 0.602642\n",
      "iteration 51 / 300: loss 0.598799\n",
      "iteration 51 / 300: loss 0.593519\n",
      "iteration 51 / 300: loss 0.594706\n",
      "iteration 51 / 300: loss 0.618453\n",
      "iteration 51 / 300: loss 0.623628\n",
      "iteration 51 / 300: loss 0.590104\n",
      "iteration 51 / 300: loss 0.585118\n",
      "iteration 51 / 300: loss 0.588226\n",
      "iteration 51 / 300: loss 0.606612\n",
      "iteration 51 / 300: loss 0.587962\n",
      "iteration 51 / 300: loss 0.581787\n",
      "iteration 51 / 300: loss 0.578876\n",
      "iteration 51 / 300: loss 0.576317\n",
      "iteration 51 / 300: loss 0.602341\n",
      "iteration 51 / 300: loss 0.586709\n",
      "iteration 51 / 300: loss 0.586854\n",
      "iteration 51 / 300: loss 0.570697\n",
      "iteration 51 / 300: loss 0.594707\n",
      "iteration 51 / 300: loss 0.614815\n",
      "iteration 51 / 300: loss 0.611349\n",
      "iteration 51 / 300: loss 0.610358\n",
      "iteration 51 / 300: loss 0.597697\n",
      "iteration 51 / 300: loss 0.595250\n",
      "iteration 51 / 300: loss 0.600602\n",
      "iteration 51 / 300: loss 0.600292\n",
      "iteration 51 / 300: loss 0.603272\n",
      "iteration 51 / 300: loss 0.600191\n",
      "iteration 51 / 300: loss 0.600769\n",
      "iteration 51 / 300: loss 0.590384\n",
      "iteration 51 / 300: loss 0.603263\n",
      "iteration 51 / 300: loss 0.602231\n",
      "iteration 51 / 300: loss 0.619919\n",
      "iteration 51 / 300: loss 0.601211\n",
      "iteration 51 / 300: loss 0.602894\n",
      "iteration 51 / 300: loss 0.607974\n",
      "iteration 51 / 300: loss 0.601314\n",
      "iteration 51 / 300: loss 0.594169\n",
      "iteration 51 / 300: loss 0.582669\n",
      "iteration 51 / 300: loss 0.600740\n",
      "iteration 51 / 300: loss 0.614480\n",
      "iteration 51 / 300: loss 0.615697\n",
      "iteration 51 / 300: loss 0.584303\n",
      "iteration 51 / 300: loss 0.605291\n",
      "iteration 51 / 300: loss 0.611770\n",
      "iteration 51 / 300: loss 0.604435\n",
      "iteration 51 / 300: loss 0.610903\n",
      "iteration 51 / 300: loss 0.623540\n",
      "iteration 51 / 300: loss 0.587487\n",
      "iteration 51 / 300: loss 0.585760\n",
      "iteration 51 / 300: loss 0.631698\n",
      "iteration 51 / 300: loss 0.611469\n",
      "iteration 51 / 300: loss 0.608868\n",
      "iteration 51 / 300: loss 0.601491\n",
      "iteration 51 / 300: loss 0.618610\n",
      "iteration 51 / 300: loss 0.598791\n",
      "iteration 51 / 300: loss 0.584189\n",
      "iteration 51 / 300: loss 0.612147\n",
      "iteration 51 / 300: loss 0.610421\n",
      "iteration 51 / 300: loss 0.600727\n",
      "iteration 51 / 300: loss 0.594396\n",
      "iteration 51 / 300: loss 0.613857\n",
      "iteration 51 / 300: loss 0.600930\n",
      "iteration 51 / 300: loss 0.583291\n",
      "iteration 51 / 300: loss 0.611974\n",
      "iteration 52 / 300: loss 0.580989\n",
      "iteration 52 / 300: loss 0.598573\n",
      "iteration 52 / 300: loss 0.571711\n",
      "iteration 52 / 300: loss 0.600306\n",
      "iteration 52 / 300: loss 0.601516\n",
      "iteration 52 / 300: loss 0.606220\n",
      "iteration 52 / 300: loss 0.617027\n",
      "iteration 52 / 300: loss 0.590488\n",
      "iteration 52 / 300: loss 0.628933\n",
      "iteration 52 / 300: loss 0.595445\n",
      "iteration 52 / 300: loss 0.624404\n",
      "iteration 52 / 300: loss 0.595070\n",
      "iteration 52 / 300: loss 0.602810\n",
      "iteration 52 / 300: loss 0.572782\n",
      "iteration 52 / 300: loss 0.595323\n",
      "iteration 52 / 300: loss 0.602846\n",
      "iteration 52 / 300: loss 0.600108\n",
      "iteration 52 / 300: loss 0.585524\n",
      "iteration 52 / 300: loss 0.616910\n",
      "iteration 52 / 300: loss 0.593653\n",
      "iteration 52 / 300: loss 0.593514\n",
      "iteration 52 / 300: loss 0.596003\n",
      "iteration 52 / 300: loss 0.600013\n",
      "iteration 52 / 300: loss 0.599177\n",
      "iteration 52 / 300: loss 0.614162\n",
      "iteration 52 / 300: loss 0.610548\n",
      "iteration 52 / 300: loss 0.599716\n",
      "iteration 52 / 300: loss 0.598204\n",
      "iteration 52 / 300: loss 0.629360\n",
      "iteration 52 / 300: loss 0.604067\n",
      "iteration 52 / 300: loss 0.601991\n",
      "iteration 52 / 300: loss 0.623952\n",
      "iteration 52 / 300: loss 0.584162\n",
      "iteration 52 / 300: loss 0.601937\n",
      "iteration 52 / 300: loss 0.594282\n",
      "iteration 52 / 300: loss 0.602410\n",
      "iteration 52 / 300: loss 0.598559\n",
      "iteration 52 / 300: loss 0.593291\n",
      "iteration 52 / 300: loss 0.594493\n",
      "iteration 52 / 300: loss 0.618196\n",
      "iteration 52 / 300: loss 0.623452\n",
      "iteration 52 / 300: loss 0.589845\n",
      "iteration 52 / 300: loss 0.584896\n",
      "iteration 52 / 300: loss 0.587988\n",
      "iteration 52 / 300: loss 0.606379\n",
      "iteration 52 / 300: loss 0.587747\n",
      "iteration 52 / 300: loss 0.581519\n",
      "iteration 52 / 300: loss 0.578658\n",
      "iteration 52 / 300: loss 0.576137\n",
      "iteration 52 / 300: loss 0.602197\n",
      "iteration 52 / 300: loss 0.586521\n",
      "iteration 52 / 300: loss 0.586696\n",
      "iteration 52 / 300: loss 0.570491\n",
      "iteration 52 / 300: loss 0.594468\n",
      "iteration 52 / 300: loss 0.614580\n",
      "iteration 52 / 300: loss 0.611130\n",
      "iteration 52 / 300: loss 0.610114\n",
      "iteration 52 / 300: loss 0.597519\n",
      "iteration 52 / 300: loss 0.595045\n",
      "iteration 52 / 300: loss 0.600376\n",
      "iteration 52 / 300: loss 0.600070\n",
      "iteration 52 / 300: loss 0.603089\n",
      "iteration 52 / 300: loss 0.599952\n",
      "iteration 52 / 300: loss 0.600596\n",
      "iteration 52 / 300: loss 0.590169\n",
      "iteration 52 / 300: loss 0.603005\n",
      "iteration 52 / 300: loss 0.602001\n",
      "iteration 52 / 300: loss 0.619723\n",
      "iteration 52 / 300: loss 0.600994\n",
      "iteration 52 / 300: loss 0.602719\n",
      "iteration 52 / 300: loss 0.607757\n",
      "iteration 52 / 300: loss 0.601073\n",
      "iteration 52 / 300: loss 0.593912\n",
      "iteration 52 / 300: loss 0.582472\n",
      "iteration 52 / 300: loss 0.600520\n",
      "iteration 52 / 300: loss 0.614215\n",
      "iteration 52 / 300: loss 0.615477\n",
      "iteration 52 / 300: loss 0.584122\n",
      "iteration 52 / 300: loss 0.605009\n",
      "iteration 52 / 300: loss 0.611519\n",
      "iteration 52 / 300: loss 0.604210\n",
      "iteration 52 / 300: loss 0.610667\n",
      "iteration 52 / 300: loss 0.623263\n",
      "iteration 52 / 300: loss 0.587253\n",
      "iteration 52 / 300: loss 0.585568\n",
      "iteration 52 / 300: loss 0.631453\n",
      "iteration 52 / 300: loss 0.611295\n",
      "iteration 52 / 300: loss 0.608641\n",
      "iteration 52 / 300: loss 0.601272\n",
      "iteration 52 / 300: loss 0.618398\n",
      "iteration 52 / 300: loss 0.598610\n",
      "iteration 52 / 300: loss 0.583950\n",
      "iteration 52 / 300: loss 0.611937\n",
      "iteration 52 / 300: loss 0.610223\n",
      "iteration 52 / 300: loss 0.600536\n",
      "iteration 52 / 300: loss 0.594215\n",
      "iteration 52 / 300: loss 0.613613\n",
      "iteration 52 / 300: loss 0.600742\n",
      "iteration 52 / 300: loss 0.583135\n",
      "iteration 52 / 300: loss 0.611780\n",
      "iteration 53 / 300: loss 0.580781\n",
      "iteration 53 / 300: loss 0.598392\n",
      "iteration 53 / 300: loss 0.571522\n",
      "iteration 53 / 300: loss 0.600110\n",
      "iteration 53 / 300: loss 0.601288\n",
      "iteration 53 / 300: loss 0.606023\n",
      "iteration 53 / 300: loss 0.616870\n",
      "iteration 53 / 300: loss 0.590308\n",
      "iteration 53 / 300: loss 0.628799\n",
      "iteration 53 / 300: loss 0.595193\n",
      "iteration 53 / 300: loss 0.624153\n",
      "iteration 53 / 300: loss 0.594900\n",
      "iteration 53 / 300: loss 0.602608\n",
      "iteration 53 / 300: loss 0.572628\n",
      "iteration 53 / 300: loss 0.595100\n",
      "iteration 53 / 300: loss 0.602573\n",
      "iteration 53 / 300: loss 0.599922\n",
      "iteration 53 / 300: loss 0.585353\n",
      "iteration 53 / 300: loss 0.616659\n",
      "iteration 53 / 300: loss 0.593438\n",
      "iteration 53 / 300: loss 0.593323\n",
      "iteration 53 / 300: loss 0.595814\n",
      "iteration 53 / 300: loss 0.599733\n",
      "iteration 53 / 300: loss 0.598959\n",
      "iteration 53 / 300: loss 0.613940\n",
      "iteration 53 / 300: loss 0.610262\n",
      "iteration 53 / 300: loss 0.599484\n",
      "iteration 53 / 300: loss 0.598053\n",
      "iteration 53 / 300: loss 0.629199\n",
      "iteration 53 / 300: loss 0.603849\n",
      "iteration 53 / 300: loss 0.601808\n",
      "iteration 53 / 300: loss 0.623778\n",
      "iteration 53 / 300: loss 0.583956\n",
      "iteration 53 / 300: loss 0.601758\n",
      "iteration 53 / 300: loss 0.594013\n",
      "iteration 53 / 300: loss 0.602195\n",
      "iteration 53 / 300: loss 0.598335\n",
      "iteration 53 / 300: loss 0.593078\n",
      "iteration 53 / 300: loss 0.594293\n",
      "iteration 53 / 300: loss 0.617958\n",
      "iteration 53 / 300: loss 0.623286\n",
      "iteration 53 / 300: loss 0.589606\n",
      "iteration 53 / 300: loss 0.584691\n",
      "iteration 53 / 300: loss 0.587771\n",
      "iteration 53 / 300: loss 0.606159\n",
      "iteration 53 / 300: loss 0.587544\n",
      "iteration 53 / 300: loss 0.581275\n",
      "iteration 53 / 300: loss 0.578456\n",
      "iteration 53 / 300: loss 0.575968\n",
      "iteration 53 / 300: loss 0.602062\n",
      "iteration 53 / 300: loss 0.586348\n",
      "iteration 53 / 300: loss 0.586547\n",
      "iteration 53 / 300: loss 0.570300\n",
      "iteration 53 / 300: loss 0.594249\n",
      "iteration 53 / 300: loss 0.614363\n",
      "iteration 53 / 300: loss 0.610930\n",
      "iteration 53 / 300: loss 0.609890\n",
      "iteration 53 / 300: loss 0.597354\n",
      "iteration 53 / 300: loss 0.594856\n",
      "iteration 53 / 300: loss 0.600169\n",
      "iteration 53 / 300: loss 0.599866\n",
      "iteration 53 / 300: loss 0.602917\n",
      "iteration 53 / 300: loss 0.599734\n",
      "iteration 53 / 300: loss 0.600437\n",
      "iteration 53 / 300: loss 0.589969\n",
      "iteration 53 / 300: loss 0.602772\n",
      "iteration 53 / 300: loss 0.601790\n",
      "iteration 53 / 300: loss 0.619542\n",
      "iteration 53 / 300: loss 0.600799\n",
      "iteration 53 / 300: loss 0.602557\n",
      "iteration 53 / 300: loss 0.607555\n",
      "iteration 53 / 300: loss 0.600853\n",
      "iteration 53 / 300: loss 0.593678\n",
      "iteration 53 / 300: loss 0.582291\n",
      "iteration 53 / 300: loss 0.600320\n",
      "iteration 53 / 300: loss 0.613974\n",
      "iteration 53 / 300: loss 0.615273\n",
      "iteration 53 / 300: loss 0.583955\n",
      "iteration 53 / 300: loss 0.604746\n",
      "iteration 53 / 300: loss 0.611290\n",
      "iteration 53 / 300: loss 0.604001\n",
      "iteration 53 / 300: loss 0.610446\n",
      "iteration 53 / 300: loss 0.623004\n",
      "iteration 53 / 300: loss 0.587038\n",
      "iteration 53 / 300: loss 0.585393\n",
      "iteration 53 / 300: loss 0.631223\n",
      "iteration 53 / 300: loss 0.611134\n",
      "iteration 53 / 300: loss 0.608433\n",
      "iteration 53 / 300: loss 0.601072\n",
      "iteration 53 / 300: loss 0.618196\n",
      "iteration 53 / 300: loss 0.598440\n",
      "iteration 53 / 300: loss 0.583730\n",
      "iteration 53 / 300: loss 0.611745\n",
      "iteration 53 / 300: loss 0.610039\n",
      "iteration 53 / 300: loss 0.600356\n",
      "iteration 53 / 300: loss 0.594044\n",
      "iteration 53 / 300: loss 0.613388\n",
      "iteration 53 / 300: loss 0.600565\n",
      "iteration 53 / 300: loss 0.582990\n",
      "iteration 53 / 300: loss 0.611599\n",
      "iteration 54 / 300: loss 0.580587\n",
      "iteration 54 / 300: loss 0.598222\n",
      "iteration 54 / 300: loss 0.571347\n",
      "iteration 54 / 300: loss 0.599926\n",
      "iteration 54 / 300: loss 0.601078\n",
      "iteration 54 / 300: loss 0.605841\n",
      "iteration 54 / 300: loss 0.616728\n",
      "iteration 54 / 300: loss 0.590139\n",
      "iteration 54 / 300: loss 0.628675\n",
      "iteration 54 / 300: loss 0.594964\n",
      "iteration 54 / 300: loss 0.623922\n",
      "iteration 54 / 300: loss 0.594745\n",
      "iteration 54 / 300: loss 0.602424\n",
      "iteration 54 / 300: loss 0.572489\n",
      "iteration 54 / 300: loss 0.594898\n",
      "iteration 54 / 300: loss 0.602326\n",
      "iteration 54 / 300: loss 0.599753\n",
      "iteration 54 / 300: loss 0.585200\n",
      "iteration 54 / 300: loss 0.616433\n",
      "iteration 54 / 300: loss 0.593242\n",
      "iteration 54 / 300: loss 0.593148\n",
      "iteration 54 / 300: loss 0.595644\n",
      "iteration 54 / 300: loss 0.599472\n",
      "iteration 54 / 300: loss 0.598758\n",
      "iteration 54 / 300: loss 0.613737\n",
      "iteration 54 / 300: loss 0.609997\n",
      "iteration 54 / 300: loss 0.599270\n",
      "iteration 54 / 300: loss 0.597912\n",
      "iteration 54 / 300: loss 0.629050\n",
      "iteration 54 / 300: loss 0.603649\n",
      "iteration 54 / 300: loss 0.601640\n",
      "iteration 54 / 300: loss 0.623618\n",
      "iteration 54 / 300: loss 0.583759\n",
      "iteration 54 / 300: loss 0.601589\n",
      "iteration 54 / 300: loss 0.593765\n",
      "iteration 54 / 300: loss 0.601996\n",
      "iteration 54 / 300: loss 0.598129\n",
      "iteration 54 / 300: loss 0.592878\n",
      "iteration 54 / 300: loss 0.594104\n",
      "iteration 54 / 300: loss 0.617738\n",
      "iteration 54 / 300: loss 0.623132\n",
      "iteration 54 / 300: loss 0.589387\n",
      "iteration 54 / 300: loss 0.584502\n",
      "iteration 54 / 300: loss 0.587573\n",
      "iteration 54 / 300: loss 0.605953\n",
      "iteration 54 / 300: loss 0.587354\n",
      "iteration 54 / 300: loss 0.581052\n",
      "iteration 54 / 300: loss 0.578271\n",
      "iteration 54 / 300: loss 0.575811\n",
      "iteration 54 / 300: loss 0.601936\n",
      "iteration 54 / 300: loss 0.586188\n",
      "iteration 54 / 300: loss 0.586407\n",
      "iteration 54 / 300: loss 0.570124\n",
      "iteration 54 / 300: loss 0.594049\n",
      "iteration 54 / 300: loss 0.614164\n",
      "iteration 54 / 300: loss 0.610747\n",
      "iteration 54 / 300: loss 0.609684\n",
      "iteration 54 / 300: loss 0.597202\n",
      "iteration 54 / 300: loss 0.594683\n",
      "iteration 54 / 300: loss 0.599980\n",
      "iteration 54 / 300: loss 0.599677\n",
      "iteration 54 / 300: loss 0.602757\n",
      "iteration 54 / 300: loss 0.599533\n",
      "iteration 54 / 300: loss 0.600291\n",
      "iteration 54 / 300: loss 0.589784\n",
      "iteration 54 / 300: loss 0.602560\n",
      "iteration 54 / 300: loss 0.601598\n",
      "iteration 54 / 300: loss 0.619376\n",
      "iteration 54 / 300: loss 0.600622\n",
      "iteration 54 / 300: loss 0.602407\n",
      "iteration 54 / 300: loss 0.607367\n",
      "iteration 54 / 300: loss 0.600651\n",
      "iteration 54 / 300: loss 0.593467\n",
      "iteration 54 / 300: loss 0.582125\n",
      "iteration 54 / 300: loss 0.600138\n",
      "iteration 54 / 300: loss 0.613755\n",
      "iteration 54 / 300: loss 0.615086\n",
      "iteration 54 / 300: loss 0.583801\n",
      "iteration 54 / 300: loss 0.604500\n",
      "iteration 54 / 300: loss 0.611080\n",
      "iteration 54 / 300: loss 0.603807\n",
      "iteration 54 / 300: loss 0.610239\n",
      "iteration 54 / 300: loss 0.622764\n",
      "iteration 54 / 300: loss 0.586841\n",
      "iteration 54 / 300: loss 0.585235\n",
      "iteration 54 / 300: loss 0.631009\n",
      "iteration 54 / 300: loss 0.610985\n",
      "iteration 54 / 300: loss 0.608242\n",
      "iteration 54 / 300: loss 0.600888\n",
      "iteration 54 / 300: loss 0.618006\n",
      "iteration 54 / 300: loss 0.598281\n",
      "iteration 54 / 300: loss 0.583527\n",
      "iteration 54 / 300: loss 0.611569\n",
      "iteration 54 / 300: loss 0.609870\n",
      "iteration 54 / 300: loss 0.600185\n",
      "iteration 54 / 300: loss 0.593884\n",
      "iteration 54 / 300: loss 0.613180\n",
      "iteration 54 / 300: loss 0.600399\n",
      "iteration 54 / 300: loss 0.582856\n",
      "iteration 54 / 300: loss 0.611431\n",
      "iteration 55 / 300: loss 0.580407\n",
      "iteration 55 / 300: loss 0.598062\n",
      "iteration 55 / 300: loss 0.571186\n",
      "iteration 55 / 300: loss 0.599754\n",
      "iteration 55 / 300: loss 0.600884\n",
      "iteration 55 / 300: loss 0.605673\n",
      "iteration 55 / 300: loss 0.616597\n",
      "iteration 55 / 300: loss 0.589981\n",
      "iteration 55 / 300: loss 0.628559\n",
      "iteration 55 / 300: loss 0.594755\n",
      "iteration 55 / 300: loss 0.623709\n",
      "iteration 55 / 300: loss 0.594603\n",
      "iteration 55 / 300: loss 0.602257\n",
      "iteration 55 / 300: loss 0.572363\n",
      "iteration 55 / 300: loss 0.594715\n",
      "iteration 55 / 300: loss 0.602104\n",
      "iteration 55 / 300: loss 0.599600\n",
      "iteration 55 / 300: loss 0.585062\n",
      "iteration 55 / 300: loss 0.616229\n",
      "iteration 55 / 300: loss 0.593063\n",
      "iteration 55 / 300: loss 0.592987\n",
      "iteration 55 / 300: loss 0.595491\n",
      "iteration 55 / 300: loss 0.599229\n",
      "iteration 55 / 300: loss 0.598574\n",
      "iteration 55 / 300: loss 0.613553\n",
      "iteration 55 / 300: loss 0.609752\n",
      "iteration 55 / 300: loss 0.599073\n",
      "iteration 55 / 300: loss 0.597781\n",
      "iteration 55 / 300: loss 0.628912\n",
      "iteration 55 / 300: loss 0.603465\n",
      "iteration 55 / 300: loss 0.601486\n",
      "iteration 55 / 300: loss 0.623470\n",
      "iteration 55 / 300: loss 0.583572\n",
      "iteration 55 / 300: loss 0.601429\n",
      "iteration 55 / 300: loss 0.593536\n",
      "iteration 55 / 300: loss 0.601812\n",
      "iteration 55 / 300: loss 0.597938\n",
      "iteration 55 / 300: loss 0.592692\n",
      "iteration 55 / 300: loss 0.593928\n",
      "iteration 55 / 300: loss 0.617536\n",
      "iteration 55 / 300: loss 0.622987\n",
      "iteration 55 / 300: loss 0.589187\n",
      "iteration 55 / 300: loss 0.584328\n",
      "iteration 55 / 300: loss 0.587392\n",
      "iteration 55 / 300: loss 0.605762\n",
      "iteration 55 / 300: loss 0.587176\n",
      "iteration 55 / 300: loss 0.580849\n",
      "iteration 55 / 300: loss 0.578101\n",
      "iteration 55 / 300: loss 0.575666\n",
      "iteration 55 / 300: loss 0.601818\n",
      "iteration 55 / 300: loss 0.586041\n",
      "iteration 55 / 300: loss 0.586278\n",
      "iteration 55 / 300: loss 0.569963\n",
      "iteration 55 / 300: loss 0.593866\n",
      "iteration 55 / 300: loss 0.613981\n",
      "iteration 55 / 300: loss 0.610580\n",
      "iteration 55 / 300: loss 0.609497\n",
      "iteration 55 / 300: loss 0.597062\n",
      "iteration 55 / 300: loss 0.594523\n",
      "iteration 55 / 300: loss 0.599806\n",
      "iteration 55 / 300: loss 0.599504\n",
      "iteration 55 / 300: loss 0.602608\n",
      "iteration 55 / 300: loss 0.599349\n",
      "iteration 55 / 300: loss 0.600158\n",
      "iteration 55 / 300: loss 0.589613\n",
      "iteration 55 / 300: loss 0.602368\n",
      "iteration 55 / 300: loss 0.601422\n",
      "iteration 55 / 300: loss 0.619224\n",
      "iteration 55 / 300: loss 0.600463\n",
      "iteration 55 / 300: loss 0.602268\n",
      "iteration 55 / 300: loss 0.607193\n",
      "iteration 55 / 300: loss 0.600467\n",
      "iteration 55 / 300: loss 0.593276\n",
      "iteration 55 / 300: loss 0.581972\n",
      "iteration 55 / 300: loss 0.599972\n",
      "iteration 55 / 300: loss 0.613556\n",
      "iteration 55 / 300: loss 0.614915\n",
      "iteration 55 / 300: loss 0.583660\n",
      "iteration 55 / 300: loss 0.604273\n",
      "iteration 55 / 300: loss 0.610890\n",
      "iteration 55 / 300: loss 0.603629\n",
      "iteration 55 / 300: loss 0.610046\n",
      "iteration 55 / 300: loss 0.622542\n",
      "iteration 55 / 300: loss 0.586661\n",
      "iteration 55 / 300: loss 0.585091\n",
      "iteration 55 / 300: loss 0.630810\n",
      "iteration 55 / 300: loss 0.610847\n",
      "iteration 55 / 300: loss 0.608068\n",
      "iteration 55 / 300: loss 0.600721\n",
      "iteration 55 / 300: loss 0.617828\n",
      "iteration 55 / 300: loss 0.598133\n",
      "iteration 55 / 300: loss 0.583341\n",
      "iteration 55 / 300: loss 0.611409\n",
      "iteration 55 / 300: loss 0.609714\n",
      "iteration 55 / 300: loss 0.600023\n",
      "iteration 55 / 300: loss 0.593733\n",
      "iteration 55 / 300: loss 0.612989\n",
      "iteration 55 / 300: loss 0.600243\n",
      "iteration 55 / 300: loss 0.582732\n",
      "iteration 55 / 300: loss 0.611275\n",
      "iteration 56 / 300: loss 0.580238\n",
      "iteration 56 / 300: loss 0.597911\n",
      "iteration 56 / 300: loss 0.571037\n",
      "iteration 56 / 300: loss 0.599594\n",
      "iteration 56 / 300: loss 0.600707\n",
      "iteration 56 / 300: loss 0.605519\n",
      "iteration 56 / 300: loss 0.616478\n",
      "iteration 56 / 300: loss 0.589834\n",
      "iteration 56 / 300: loss 0.628451\n",
      "iteration 56 / 300: loss 0.594565\n",
      "iteration 56 / 300: loss 0.623513\n",
      "iteration 56 / 300: loss 0.594474\n",
      "iteration 56 / 300: loss 0.602104\n",
      "iteration 56 / 300: loss 0.572248\n",
      "iteration 56 / 300: loss 0.594550\n",
      "iteration 56 / 300: loss 0.601903\n",
      "iteration 56 / 300: loss 0.599461\n",
      "iteration 56 / 300: loss 0.584938\n",
      "iteration 56 / 300: loss 0.616045\n",
      "iteration 56 / 300: loss 0.592900\n",
      "iteration 56 / 300: loss 0.592841\n",
      "iteration 56 / 300: loss 0.595353\n",
      "iteration 56 / 300: loss 0.599004\n",
      "iteration 56 / 300: loss 0.598405\n",
      "iteration 56 / 300: loss 0.613386\n",
      "iteration 56 / 300: loss 0.609527\n",
      "iteration 56 / 300: loss 0.598892\n",
      "iteration 56 / 300: loss 0.597660\n",
      "iteration 56 / 300: loss 0.628784\n",
      "iteration 56 / 300: loss 0.603297\n",
      "iteration 56 / 300: loss 0.601345\n",
      "iteration 56 / 300: loss 0.623335\n",
      "iteration 56 / 300: loss 0.583396\n",
      "iteration 56 / 300: loss 0.601280\n",
      "iteration 56 / 300: loss 0.593325\n",
      "iteration 56 / 300: loss 0.601642\n",
      "iteration 56 / 300: loss 0.597763\n",
      "iteration 56 / 300: loss 0.592520\n",
      "iteration 56 / 300: loss 0.593763\n",
      "iteration 56 / 300: loss 0.617350\n",
      "iteration 56 / 300: loss 0.622852\n",
      "iteration 56 / 300: loss 0.589005\n",
      "iteration 56 / 300: loss 0.584168\n",
      "iteration 56 / 300: loss 0.587227\n",
      "iteration 56 / 300: loss 0.605584\n",
      "iteration 56 / 300: loss 0.587010\n",
      "iteration 56 / 300: loss 0.580664\n",
      "iteration 56 / 300: loss 0.577945\n",
      "iteration 56 / 300: loss 0.575532\n",
      "iteration 56 / 300: loss 0.601708\n",
      "iteration 56 / 300: loss 0.585906\n",
      "iteration 56 / 300: loss 0.586158\n",
      "iteration 56 / 300: loss 0.569815\n",
      "iteration 56 / 300: loss 0.593698\n",
      "iteration 56 / 300: loss 0.613813\n",
      "iteration 56 / 300: loss 0.610428\n",
      "iteration 56 / 300: loss 0.609325\n",
      "iteration 56 / 300: loss 0.596932\n",
      "iteration 56 / 300: loss 0.594376\n",
      "iteration 56 / 300: loss 0.599647\n",
      "iteration 56 / 300: loss 0.599345\n",
      "iteration 56 / 300: loss 0.602469\n",
      "iteration 56 / 300: loss 0.599180\n",
      "iteration 56 / 300: loss 0.600035\n",
      "iteration 56 / 300: loss 0.589455\n",
      "iteration 56 / 300: loss 0.602193\n",
      "iteration 56 / 300: loss 0.601261\n",
      "iteration 56 / 300: loss 0.619083\n",
      "iteration 56 / 300: loss 0.600318\n",
      "iteration 56 / 300: loss 0.602140\n",
      "iteration 56 / 300: loss 0.607031\n",
      "iteration 56 / 300: loss 0.600299\n",
      "iteration 56 / 300: loss 0.593103\n",
      "iteration 56 / 300: loss 0.581832\n",
      "iteration 56 / 300: loss 0.599820\n",
      "iteration 56 / 300: loss 0.613376\n",
      "iteration 56 / 300: loss 0.614758\n",
      "iteration 56 / 300: loss 0.583530\n",
      "iteration 56 / 300: loss 0.604064\n",
      "iteration 56 / 300: loss 0.610716\n",
      "iteration 56 / 300: loss 0.603466\n",
      "iteration 56 / 300: loss 0.609867\n",
      "iteration 56 / 300: loss 0.622337\n",
      "iteration 56 / 300: loss 0.586497\n",
      "iteration 56 / 300: loss 0.584962\n",
      "iteration 56 / 300: loss 0.630626\n",
      "iteration 56 / 300: loss 0.610721\n",
      "iteration 56 / 300: loss 0.607909\n",
      "iteration 56 / 300: loss 0.600568\n",
      "iteration 56 / 300: loss 0.617662\n",
      "iteration 56 / 300: loss 0.597996\n",
      "iteration 56 / 300: loss 0.583171\n",
      "iteration 56 / 300: loss 0.611263\n",
      "iteration 56 / 300: loss 0.609570\n",
      "iteration 56 / 300: loss 0.599872\n",
      "iteration 56 / 300: loss 0.593593\n",
      "iteration 56 / 300: loss 0.612813\n",
      "iteration 56 / 300: loss 0.600099\n",
      "iteration 56 / 300: loss 0.582618\n",
      "iteration 56 / 300: loss 0.611130\n",
      "iteration 57 / 300: loss 0.580081\n",
      "iteration 57 / 300: loss 0.597770\n",
      "iteration 57 / 300: loss 0.570900\n",
      "iteration 57 / 300: loss 0.599446\n",
      "iteration 57 / 300: loss 0.600544\n",
      "iteration 57 / 300: loss 0.605377\n",
      "iteration 57 / 300: loss 0.616369\n",
      "iteration 57 / 300: loss 0.589697\n",
      "iteration 57 / 300: loss 0.628349\n",
      "iteration 57 / 300: loss 0.594391\n",
      "iteration 57 / 300: loss 0.623334\n",
      "iteration 57 / 300: loss 0.594355\n",
      "iteration 57 / 300: loss 0.601965\n",
      "iteration 57 / 300: loss 0.572142\n",
      "iteration 57 / 300: loss 0.594400\n",
      "iteration 57 / 300: loss 0.601723\n",
      "iteration 57 / 300: loss 0.599334\n",
      "iteration 57 / 300: loss 0.584826\n",
      "iteration 57 / 300: loss 0.615879\n",
      "iteration 57 / 300: loss 0.592752\n",
      "iteration 57 / 300: loss 0.592707\n",
      "iteration 57 / 300: loss 0.595229\n",
      "iteration 57 / 300: loss 0.598797\n",
      "iteration 57 / 300: loss 0.598251\n",
      "iteration 57 / 300: loss 0.613234\n",
      "iteration 57 / 300: loss 0.609319\n",
      "iteration 57 / 300: loss 0.598726\n",
      "iteration 57 / 300: loss 0.597546\n",
      "iteration 57 / 300: loss 0.628666\n",
      "iteration 57 / 300: loss 0.603144\n",
      "iteration 57 / 300: loss 0.601215\n",
      "iteration 57 / 300: loss 0.623211\n",
      "iteration 57 / 300: loss 0.583231\n",
      "iteration 57 / 300: loss 0.601140\n",
      "iteration 57 / 300: loss 0.593131\n",
      "iteration 57 / 300: loss 0.601486\n",
      "iteration 57 / 300: loss 0.597603\n",
      "iteration 57 / 300: loss 0.592360\n",
      "iteration 57 / 300: loss 0.593610\n",
      "iteration 57 / 300: loss 0.617180\n",
      "iteration 57 / 300: loss 0.622727\n",
      "iteration 57 / 300: loss 0.588839\n",
      "iteration 57 / 300: loss 0.584020\n",
      "iteration 57 / 300: loss 0.587077\n",
      "iteration 57 / 300: loss 0.605420\n",
      "iteration 57 / 300: loss 0.586855\n",
      "iteration 57 / 300: loss 0.580496\n",
      "iteration 57 / 300: loss 0.577804\n",
      "iteration 57 / 300: loss 0.575408\n",
      "iteration 57 / 300: loss 0.601606\n",
      "iteration 57 / 300: loss 0.585782\n",
      "iteration 57 / 300: loss 0.586046\n",
      "iteration 57 / 300: loss 0.569680\n",
      "iteration 57 / 300: loss 0.593546\n",
      "iteration 57 / 300: loss 0.613660\n",
      "iteration 57 / 300: loss 0.610290\n",
      "iteration 57 / 300: loss 0.609168\n",
      "iteration 57 / 300: loss 0.596813\n",
      "iteration 57 / 300: loss 0.594240\n",
      "iteration 57 / 300: loss 0.599501\n",
      "iteration 57 / 300: loss 0.599198\n",
      "iteration 57 / 300: loss 0.602340\n",
      "iteration 57 / 300: loss 0.599025\n",
      "iteration 57 / 300: loss 0.599924\n",
      "iteration 57 / 300: loss 0.589310\n",
      "iteration 57 / 300: loss 0.602034\n",
      "iteration 57 / 300: loss 0.601115\n",
      "iteration 57 / 300: loss 0.618954\n",
      "iteration 57 / 300: loss 0.600186\n",
      "iteration 57 / 300: loss 0.602022\n",
      "iteration 57 / 300: loss 0.606881\n",
      "iteration 57 / 300: loss 0.600145\n",
      "iteration 57 / 300: loss 0.592947\n",
      "iteration 57 / 300: loss 0.581703\n",
      "iteration 57 / 300: loss 0.599682\n",
      "iteration 57 / 300: loss 0.613213\n",
      "iteration 57 / 300: loss 0.614615\n",
      "iteration 57 / 300: loss 0.583411\n",
      "iteration 57 / 300: loss 0.603872\n",
      "iteration 57 / 300: loss 0.610558\n",
      "iteration 57 / 300: loss 0.603316\n",
      "iteration 57 / 300: loss 0.609701\n",
      "iteration 57 / 300: loss 0.622149\n",
      "iteration 57 / 300: loss 0.586347\n",
      "iteration 57 / 300: loss 0.584845\n",
      "iteration 57 / 300: loss 0.630458\n",
      "iteration 57 / 300: loss 0.610604\n",
      "iteration 57 / 300: loss 0.607764\n",
      "iteration 57 / 300: loss 0.600429\n",
      "iteration 57 / 300: loss 0.617507\n",
      "iteration 57 / 300: loss 0.597868\n",
      "iteration 57 / 300: loss 0.583014\n",
      "iteration 57 / 300: loss 0.611129\n",
      "iteration 57 / 300: loss 0.609438\n",
      "iteration 57 / 300: loss 0.599731\n",
      "iteration 57 / 300: loss 0.593462\n",
      "iteration 57 / 300: loss 0.612652\n",
      "iteration 57 / 300: loss 0.599965\n",
      "iteration 57 / 300: loss 0.582513\n",
      "iteration 57 / 300: loss 0.610997\n",
      "iteration 58 / 300: loss 0.579936\n",
      "iteration 58 / 300: loss 0.597639\n",
      "iteration 58 / 300: loss 0.570774\n",
      "iteration 58 / 300: loss 0.599308\n",
      "iteration 58 / 300: loss 0.600395\n",
      "iteration 58 / 300: loss 0.605247\n",
      "iteration 58 / 300: loss 0.616270\n",
      "iteration 58 / 300: loss 0.589570\n",
      "iteration 58 / 300: loss 0.628254\n",
      "iteration 58 / 300: loss 0.594232\n",
      "iteration 58 / 300: loss 0.623169\n",
      "iteration 58 / 300: loss 0.594246\n",
      "iteration 58 / 300: loss 0.601838\n",
      "iteration 58 / 300: loss 0.572045\n",
      "iteration 58 / 300: loss 0.594265\n",
      "iteration 58 / 300: loss 0.601561\n",
      "iteration 58 / 300: loss 0.599219\n",
      "iteration 58 / 300: loss 0.584724\n",
      "iteration 58 / 300: loss 0.615730\n",
      "iteration 58 / 300: loss 0.592617\n",
      "iteration 58 / 300: loss 0.592585\n",
      "iteration 58 / 300: loss 0.595117\n",
      "iteration 58 / 300: loss 0.598606\n",
      "iteration 58 / 300: loss 0.598109\n",
      "iteration 58 / 300: loss 0.613096\n",
      "iteration 58 / 300: loss 0.609129\n",
      "iteration 58 / 300: loss 0.598574\n",
      "iteration 58 / 300: loss 0.597441\n",
      "iteration 58 / 300: loss 0.628558\n",
      "iteration 58 / 300: loss 0.603004\n",
      "iteration 58 / 300: loss 0.601097\n",
      "iteration 58 / 300: loss 0.623097\n",
      "iteration 58 / 300: loss 0.583077\n",
      "iteration 58 / 300: loss 0.601010\n",
      "iteration 58 / 300: loss 0.592954\n",
      "iteration 58 / 300: loss 0.601343\n",
      "iteration 58 / 300: loss 0.597456\n",
      "iteration 58 / 300: loss 0.592214\n",
      "iteration 58 / 300: loss 0.593468\n",
      "iteration 58 / 300: loss 0.617024\n",
      "iteration 58 / 300: loss 0.622610\n",
      "iteration 58 / 300: loss 0.588688\n",
      "iteration 58 / 300: loss 0.583885\n",
      "iteration 58 / 300: loss 0.586941\n",
      "iteration 58 / 300: loss 0.605268\n",
      "iteration 58 / 300: loss 0.586713\n",
      "iteration 58 / 300: loss 0.580344\n",
      "iteration 58 / 300: loss 0.577676\n",
      "iteration 58 / 300: loss 0.575293\n",
      "iteration 58 / 300: loss 0.601512\n",
      "iteration 58 / 300: loss 0.585669\n",
      "iteration 58 / 300: loss 0.585943\n",
      "iteration 58 / 300: loss 0.569556\n",
      "iteration 58 / 300: loss 0.593406\n",
      "iteration 58 / 300: loss 0.613520\n",
      "iteration 58 / 300: loss 0.610164\n",
      "iteration 58 / 300: loss 0.609026\n",
      "iteration 58 / 300: loss 0.596703\n",
      "iteration 58 / 300: loss 0.594116\n",
      "iteration 58 / 300: loss 0.599367\n",
      "iteration 58 / 300: loss 0.599064\n",
      "iteration 58 / 300: loss 0.602221\n",
      "iteration 58 / 300: loss 0.598883\n",
      "iteration 58 / 300: loss 0.599821\n",
      "iteration 58 / 300: loss 0.589176\n",
      "iteration 58 / 300: loss 0.601890\n",
      "iteration 58 / 300: loss 0.600981\n",
      "iteration 58 / 300: loss 0.618835\n",
      "iteration 58 / 300: loss 0.600067\n",
      "iteration 58 / 300: loss 0.601913\n",
      "iteration 58 / 300: loss 0.606742\n",
      "iteration 58 / 300: loss 0.600004\n",
      "iteration 58 / 300: loss 0.592806\n",
      "iteration 58 / 300: loss 0.581586\n",
      "iteration 58 / 300: loss 0.599555\n",
      "iteration 58 / 300: loss 0.613067\n",
      "iteration 58 / 300: loss 0.614485\n",
      "iteration 58 / 300: loss 0.583302\n",
      "iteration 58 / 300: loss 0.603695\n",
      "iteration 58 / 300: loss 0.610413\n",
      "iteration 58 / 300: loss 0.603179\n",
      "iteration 58 / 300: loss 0.609548\n",
      "iteration 58 / 300: loss 0.621976\n",
      "iteration 58 / 300: loss 0.586210\n",
      "iteration 58 / 300: loss 0.584739\n",
      "iteration 58 / 300: loss 0.630304\n",
      "iteration 58 / 300: loss 0.610497\n",
      "iteration 58 / 300: loss 0.607631\n",
      "iteration 58 / 300: loss 0.600302\n",
      "iteration 58 / 300: loss 0.617364\n",
      "iteration 58 / 300: loss 0.597750\n",
      "iteration 58 / 300: loss 0.582872\n",
      "iteration 58 / 300: loss 0.611008\n",
      "iteration 58 / 300: loss 0.609318\n",
      "iteration 58 / 300: loss 0.599599\n",
      "iteration 58 / 300: loss 0.593340\n",
      "iteration 58 / 300: loss 0.612505\n",
      "iteration 58 / 300: loss 0.599841\n",
      "iteration 58 / 300: loss 0.582416\n",
      "iteration 58 / 300: loss 0.610874\n",
      "iteration 59 / 300: loss 0.579801\n",
      "iteration 59 / 300: loss 0.597516\n",
      "iteration 59 / 300: loss 0.570658\n",
      "iteration 59 / 300: loss 0.599180\n",
      "iteration 59 / 300: loss 0.600260\n",
      "iteration 59 / 300: loss 0.605127\n",
      "iteration 59 / 300: loss 0.616179\n",
      "iteration 59 / 300: loss 0.589453\n",
      "iteration 59 / 300: loss 0.628166\n",
      "iteration 59 / 300: loss 0.594087\n",
      "iteration 59 / 300: loss 0.623018\n",
      "iteration 59 / 300: loss 0.594146\n",
      "iteration 59 / 300: loss 0.601721\n",
      "iteration 59 / 300: loss 0.571955\n",
      "iteration 59 / 300: loss 0.594141\n",
      "iteration 59 / 300: loss 0.601414\n",
      "iteration 59 / 300: loss 0.599114\n",
      "iteration 59 / 300: loss 0.584632\n",
      "iteration 59 / 300: loss 0.615596\n",
      "iteration 59 / 300: loss 0.592495\n",
      "iteration 59 / 300: loss 0.592474\n",
      "iteration 59 / 300: loss 0.595015\n",
      "iteration 59 / 300: loss 0.598431\n",
      "iteration 59 / 300: loss 0.597980\n",
      "iteration 59 / 300: loss 0.612971\n",
      "iteration 59 / 300: loss 0.608956\n",
      "iteration 59 / 300: loss 0.598435\n",
      "iteration 59 / 300: loss 0.597344\n",
      "iteration 59 / 300: loss 0.628458\n",
      "iteration 59 / 300: loss 0.602877\n",
      "iteration 59 / 300: loss 0.600990\n",
      "iteration 59 / 300: loss 0.622993\n",
      "iteration 59 / 300: loss 0.582934\n",
      "iteration 59 / 300: loss 0.600889\n",
      "iteration 59 / 300: loss 0.592791\n",
      "iteration 59 / 300: loss 0.601212\n",
      "iteration 59 / 300: loss 0.597322\n",
      "iteration 59 / 300: loss 0.592079\n",
      "iteration 59 / 300: loss 0.593336\n",
      "iteration 59 / 300: loss 0.616881\n",
      "iteration 59 / 300: loss 0.622502\n",
      "iteration 59 / 300: loss 0.588552\n",
      "iteration 59 / 300: loss 0.583760\n",
      "iteration 59 / 300: loss 0.586816\n",
      "iteration 59 / 300: loss 0.605128\n",
      "iteration 59 / 300: loss 0.586580\n",
      "iteration 59 / 300: loss 0.580205\n",
      "iteration 59 / 300: loss 0.577559\n",
      "iteration 59 / 300: loss 0.575188\n",
      "iteration 59 / 300: loss 0.601425\n",
      "iteration 59 / 300: loss 0.585565\n",
      "iteration 59 / 300: loss 0.585848\n",
      "iteration 59 / 300: loss 0.569442\n",
      "iteration 59 / 300: loss 0.593279\n",
      "iteration 59 / 300: loss 0.613392\n",
      "iteration 59 / 300: loss 0.610049\n",
      "iteration 59 / 300: loss 0.608896\n",
      "iteration 59 / 300: loss 0.596602\n",
      "iteration 59 / 300: loss 0.594002\n",
      "iteration 59 / 300: loss 0.599244\n",
      "iteration 59 / 300: loss 0.598941\n",
      "iteration 59 / 300: loss 0.602111\n",
      "iteration 59 / 300: loss 0.598752\n",
      "iteration 59 / 300: loss 0.599728\n",
      "iteration 59 / 300: loss 0.589054\n",
      "iteration 59 / 300: loss 0.601759\n",
      "iteration 59 / 300: loss 0.600859\n",
      "iteration 59 / 300: loss 0.618724\n",
      "iteration 59 / 300: loss 0.599958\n",
      "iteration 59 / 300: loss 0.601813\n",
      "iteration 59 / 300: loss 0.606615\n",
      "iteration 59 / 300: loss 0.599876\n",
      "iteration 59 / 300: loss 0.592680\n",
      "iteration 59 / 300: loss 0.581478\n",
      "iteration 59 / 300: loss 0.599438\n",
      "iteration 59 / 300: loss 0.612934\n",
      "iteration 59 / 300: loss 0.614367\n",
      "iteration 59 / 300: loss 0.583203\n",
      "iteration 59 / 300: loss 0.603534\n",
      "iteration 59 / 300: loss 0.610282\n",
      "iteration 59 / 300: loss 0.603053\n",
      "iteration 59 / 300: loss 0.609407\n",
      "iteration 59 / 300: loss 0.621818\n",
      "iteration 59 / 300: loss 0.586084\n",
      "iteration 59 / 300: loss 0.584644\n",
      "iteration 59 / 300: loss 0.630163\n",
      "iteration 59 / 300: loss 0.610398\n",
      "iteration 59 / 300: loss 0.607510\n",
      "iteration 59 / 300: loss 0.600187\n",
      "iteration 59 / 300: loss 0.617232\n",
      "iteration 59 / 300: loss 0.597642\n",
      "iteration 59 / 300: loss 0.582741\n",
      "iteration 59 / 300: loss 0.610898\n",
      "iteration 59 / 300: loss 0.609208\n",
      "iteration 59 / 300: loss 0.599478\n",
      "iteration 59 / 300: loss 0.593227\n",
      "iteration 59 / 300: loss 0.612370\n",
      "iteration 59 / 300: loss 0.599726\n",
      "iteration 59 / 300: loss 0.582326\n",
      "iteration 59 / 300: loss 0.610761\n",
      "iteration 60 / 300: loss 0.579677\n",
      "iteration 60 / 300: loss 0.597402\n",
      "iteration 60 / 300: loss 0.570552\n",
      "iteration 60 / 300: loss 0.599063\n",
      "iteration 60 / 300: loss 0.600137\n",
      "iteration 60 / 300: loss 0.605017\n",
      "iteration 60 / 300: loss 0.616095\n",
      "iteration 60 / 300: loss 0.589345\n",
      "iteration 60 / 300: loss 0.628084\n",
      "iteration 60 / 300: loss 0.593953\n",
      "iteration 60 / 300: loss 0.622880\n",
      "iteration 60 / 300: loss 0.594054\n",
      "iteration 60 / 300: loss 0.601616\n",
      "iteration 60 / 300: loss 0.571873\n",
      "iteration 60 / 300: loss 0.594029\n",
      "iteration 60 / 300: loss 0.601283\n",
      "iteration 60 / 300: loss 0.599018\n",
      "iteration 60 / 300: loss 0.584549\n",
      "iteration 60 / 300: loss 0.615475\n",
      "iteration 60 / 300: loss 0.592384\n",
      "iteration 60 / 300: loss 0.592373\n",
      "iteration 60 / 300: loss 0.594923\n",
      "iteration 60 / 300: loss 0.598271\n",
      "iteration 60 / 300: loss 0.597862\n",
      "iteration 60 / 300: loss 0.612857\n",
      "iteration 60 / 300: loss 0.608797\n",
      "iteration 60 / 300: loss 0.598307\n",
      "iteration 60 / 300: loss 0.597254\n",
      "iteration 60 / 300: loss 0.628365\n",
      "iteration 60 / 300: loss 0.602760\n",
      "iteration 60 / 300: loss 0.600892\n",
      "iteration 60 / 300: loss 0.622899\n",
      "iteration 60 / 300: loss 0.582801\n",
      "iteration 60 / 300: loss 0.600777\n",
      "iteration 60 / 300: loss 0.592643\n",
      "iteration 60 / 300: loss 0.601093\n",
      "iteration 60 / 300: loss 0.597200\n",
      "iteration 60 / 300: loss 0.591956\n",
      "iteration 60 / 300: loss 0.593215\n",
      "iteration 60 / 300: loss 0.616751\n",
      "iteration 60 / 300: loss 0.622403\n",
      "iteration 60 / 300: loss 0.588428\n",
      "iteration 60 / 300: loss 0.583646\n",
      "iteration 60 / 300: loss 0.586702\n",
      "iteration 60 / 300: loss 0.604998\n",
      "iteration 60 / 300: loss 0.586459\n",
      "iteration 60 / 300: loss 0.580080\n",
      "iteration 60 / 300: loss 0.577453\n",
      "iteration 60 / 300: loss 0.575092\n",
      "iteration 60 / 300: loss 0.601345\n",
      "iteration 60 / 300: loss 0.585470\n",
      "iteration 60 / 300: loss 0.585761\n",
      "iteration 60 / 300: loss 0.569339\n",
      "iteration 60 / 300: loss 0.593163\n",
      "iteration 60 / 300: loss 0.613276\n",
      "iteration 60 / 300: loss 0.609945\n",
      "iteration 60 / 300: loss 0.608777\n",
      "iteration 60 / 300: loss 0.596508\n",
      "iteration 60 / 300: loss 0.593897\n",
      "iteration 60 / 300: loss 0.599132\n",
      "iteration 60 / 300: loss 0.598828\n",
      "iteration 60 / 300: loss 0.602009\n",
      "iteration 60 / 300: loss 0.598632\n",
      "iteration 60 / 300: loss 0.599642\n",
      "iteration 60 / 300: loss 0.588941\n",
      "iteration 60 / 300: loss 0.601641\n",
      "iteration 60 / 300: loss 0.600748\n",
      "iteration 60 / 300: loss 0.618623\n",
      "iteration 60 / 300: loss 0.599859\n",
      "iteration 60 / 300: loss 0.601721\n",
      "iteration 60 / 300: loss 0.606498\n",
      "iteration 60 / 300: loss 0.599759\n",
      "iteration 60 / 300: loss 0.592565\n",
      "iteration 60 / 300: loss 0.581379\n",
      "iteration 60 / 300: loss 0.599331\n",
      "iteration 60 / 300: loss 0.612814\n",
      "iteration 60 / 300: loss 0.614260\n",
      "iteration 60 / 300: loss 0.583112\n",
      "iteration 60 / 300: loss 0.603388\n",
      "iteration 60 / 300: loss 0.610162\n",
      "iteration 60 / 300: loss 0.602938\n",
      "iteration 60 / 300: loss 0.609277\n",
      "iteration 60 / 300: loss 0.621673\n",
      "iteration 60 / 300: loss 0.585970\n",
      "iteration 60 / 300: loss 0.584557\n",
      "iteration 60 / 300: loss 0.630036\n",
      "iteration 60 / 300: loss 0.610308\n",
      "iteration 60 / 300: loss 0.607399\n",
      "iteration 60 / 300: loss 0.600082\n",
      "iteration 60 / 300: loss 0.617111\n",
      "iteration 60 / 300: loss 0.597541\n",
      "iteration 60 / 300: loss 0.582622\n",
      "iteration 60 / 300: loss 0.610797\n",
      "iteration 60 / 300: loss 0.609108\n",
      "iteration 60 / 300: loss 0.599365\n",
      "iteration 60 / 300: loss 0.593123\n",
      "iteration 60 / 300: loss 0.612247\n",
      "iteration 60 / 300: loss 0.599621\n",
      "iteration 60 / 300: loss 0.582244\n",
      "iteration 60 / 300: loss 0.610657\n",
      "iteration 61 / 300: loss 0.579563\n",
      "iteration 61 / 300: loss 0.597297\n",
      "iteration 61 / 300: loss 0.570454\n",
      "iteration 61 / 300: loss 0.598955\n",
      "iteration 61 / 300: loss 0.600024\n",
      "iteration 61 / 300: loss 0.604916\n",
      "iteration 61 / 300: loss 0.616019\n",
      "iteration 61 / 300: loss 0.589245\n",
      "iteration 61 / 300: loss 0.628007\n",
      "iteration 61 / 300: loss 0.593832\n",
      "iteration 61 / 300: loss 0.622754\n",
      "iteration 61 / 300: loss 0.593969\n",
      "iteration 61 / 300: loss 0.601519\n",
      "iteration 61 / 300: loss 0.571797\n",
      "iteration 61 / 300: loss 0.593927\n",
      "iteration 61 / 300: loss 0.601164\n",
      "iteration 61 / 300: loss 0.598930\n",
      "iteration 61 / 300: loss 0.584473\n",
      "iteration 61 / 300: loss 0.615366\n",
      "iteration 61 / 300: loss 0.592282\n",
      "iteration 61 / 300: loss 0.592281\n",
      "iteration 61 / 300: loss 0.594840\n",
      "iteration 61 / 300: loss 0.598126\n",
      "iteration 61 / 300: loss 0.597755\n",
      "iteration 61 / 300: loss 0.612754\n",
      "iteration 61 / 300: loss 0.608653\n",
      "iteration 61 / 300: loss 0.598191\n",
      "iteration 61 / 300: loss 0.597171\n",
      "iteration 61 / 300: loss 0.628280\n",
      "iteration 61 / 300: loss 0.602654\n",
      "iteration 61 / 300: loss 0.600802\n",
      "iteration 61 / 300: loss 0.622812\n",
      "iteration 61 / 300: loss 0.582679\n",
      "iteration 61 / 300: loss 0.600674\n",
      "iteration 61 / 300: loss 0.592507\n",
      "iteration 61 / 300: loss 0.600984\n",
      "iteration 61 / 300: loss 0.597089\n",
      "iteration 61 / 300: loss 0.591844\n",
      "iteration 61 / 300: loss 0.593103\n",
      "iteration 61 / 300: loss 0.616633\n",
      "iteration 61 / 300: loss 0.622311\n",
      "iteration 61 / 300: loss 0.588316\n",
      "iteration 61 / 300: loss 0.583542\n",
      "iteration 61 / 300: loss 0.586599\n",
      "iteration 61 / 300: loss 0.604880\n",
      "iteration 61 / 300: loss 0.586347\n",
      "iteration 61 / 300: loss 0.579966\n",
      "iteration 61 / 300: loss 0.577357\n",
      "iteration 61 / 300: loss 0.575004\n",
      "iteration 61 / 300: loss 0.601271\n",
      "iteration 61 / 300: loss 0.585383\n",
      "iteration 61 / 300: loss 0.585680\n",
      "iteration 61 / 300: loss 0.569245\n",
      "iteration 61 / 300: loss 0.593057\n",
      "iteration 61 / 300: loss 0.613169\n",
      "iteration 61 / 300: loss 0.609851\n",
      "iteration 61 / 300: loss 0.608669\n",
      "iteration 61 / 300: loss 0.596423\n",
      "iteration 61 / 300: loss 0.593802\n",
      "iteration 61 / 300: loss 0.599029\n",
      "iteration 61 / 300: loss 0.598724\n",
      "iteration 61 / 300: loss 0.601915\n",
      "iteration 61 / 300: loss 0.598522\n",
      "iteration 61 / 300: loss 0.599564\n",
      "iteration 61 / 300: loss 0.588839\n",
      "iteration 61 / 300: loss 0.601533\n",
      "iteration 61 / 300: loss 0.600647\n",
      "iteration 61 / 300: loss 0.618529\n",
      "iteration 61 / 300: loss 0.599769\n",
      "iteration 61 / 300: loss 0.601637\n",
      "iteration 61 / 300: loss 0.606390\n",
      "iteration 61 / 300: loss 0.599651\n",
      "iteration 61 / 300: loss 0.592461\n",
      "iteration 61 / 300: loss 0.581289\n",
      "iteration 61 / 300: loss 0.599233\n",
      "iteration 61 / 300: loss 0.612706\n",
      "iteration 61 / 300: loss 0.614162\n",
      "iteration 61 / 300: loss 0.583030\n",
      "iteration 61 / 300: loss 0.603254\n",
      "iteration 61 / 300: loss 0.610053\n",
      "iteration 61 / 300: loss 0.602834\n",
      "iteration 61 / 300: loss 0.609157\n",
      "iteration 61 / 300: loss 0.621541\n",
      "iteration 61 / 300: loss 0.585866\n",
      "iteration 61 / 300: loss 0.584480\n",
      "iteration 61 / 300: loss 0.629921\n",
      "iteration 61 / 300: loss 0.610225\n",
      "iteration 61 / 300: loss 0.607298\n",
      "iteration 61 / 300: loss 0.599986\n",
      "iteration 61 / 300: loss 0.616999\n",
      "iteration 61 / 300: loss 0.597449\n",
      "iteration 61 / 300: loss 0.582513\n",
      "iteration 61 / 300: loss 0.610706\n",
      "iteration 61 / 300: loss 0.609016\n",
      "iteration 61 / 300: loss 0.599262\n",
      "iteration 61 / 300: loss 0.593026\n",
      "iteration 61 / 300: loss 0.612135\n",
      "iteration 61 / 300: loss 0.599524\n",
      "iteration 61 / 300: loss 0.582169\n",
      "iteration 61 / 300: loss 0.610562\n",
      "iteration 62 / 300: loss 0.579457\n",
      "iteration 62 / 300: loss 0.597200\n",
      "iteration 62 / 300: loss 0.570364\n",
      "iteration 62 / 300: loss 0.598856\n",
      "iteration 62 / 300: loss 0.599922\n",
      "iteration 62 / 300: loss 0.604824\n",
      "iteration 62 / 300: loss 0.615950\n",
      "iteration 62 / 300: loss 0.589153\n",
      "iteration 62 / 300: loss 0.627936\n",
      "iteration 62 / 300: loss 0.593720\n",
      "iteration 62 / 300: loss 0.622640\n",
      "iteration 62 / 300: loss 0.593892\n",
      "iteration 62 / 300: loss 0.601430\n",
      "iteration 62 / 300: loss 0.571727\n",
      "iteration 62 / 300: loss 0.593834\n",
      "iteration 62 / 300: loss 0.601057\n",
      "iteration 62 / 300: loss 0.598851\n",
      "iteration 62 / 300: loss 0.584404\n",
      "iteration 62 / 300: loss 0.615268\n",
      "iteration 62 / 300: loss 0.592190\n",
      "iteration 62 / 300: loss 0.592198\n",
      "iteration 62 / 300: loss 0.594764\n",
      "iteration 62 / 300: loss 0.597993\n",
      "iteration 62 / 300: loss 0.597658\n",
      "iteration 62 / 300: loss 0.612660\n",
      "iteration 62 / 300: loss 0.608522\n",
      "iteration 62 / 300: loss 0.598084\n",
      "iteration 62 / 300: loss 0.597094\n",
      "iteration 62 / 300: loss 0.628202\n",
      "iteration 62 / 300: loss 0.602557\n",
      "iteration 62 / 300: loss 0.600721\n",
      "iteration 62 / 300: loss 0.622733\n",
      "iteration 62 / 300: loss 0.582567\n",
      "iteration 62 / 300: loss 0.600579\n",
      "iteration 62 / 300: loss 0.592384\n",
      "iteration 62 / 300: loss 0.600885\n",
      "iteration 62 / 300: loss 0.596988\n",
      "iteration 62 / 300: loss 0.591742\n",
      "iteration 62 / 300: loss 0.593000\n",
      "iteration 62 / 300: loss 0.616525\n",
      "iteration 62 / 300: loss 0.622226\n",
      "iteration 62 / 300: loss 0.588215\n",
      "iteration 62 / 300: loss 0.583446\n",
      "iteration 62 / 300: loss 0.586504\n",
      "iteration 62 / 300: loss 0.604771\n",
      "iteration 62 / 300: loss 0.586244\n",
      "iteration 62 / 300: loss 0.579863\n",
      "iteration 62 / 300: loss 0.577270\n",
      "iteration 62 / 300: loss 0.574923\n",
      "iteration 62 / 300: loss 0.601202\n",
      "iteration 62 / 300: loss 0.585303\n",
      "iteration 62 / 300: loss 0.585606\n",
      "iteration 62 / 300: loss 0.569159\n",
      "iteration 62 / 300: loss 0.592961\n",
      "iteration 62 / 300: loss 0.613072\n",
      "iteration 62 / 300: loss 0.609765\n",
      "iteration 62 / 300: loss 0.608571\n",
      "iteration 62 / 300: loss 0.596344\n",
      "iteration 62 / 300: loss 0.593714\n",
      "iteration 62 / 300: loss 0.598935\n",
      "iteration 62 / 300: loss 0.598630\n",
      "iteration 62 / 300: loss 0.601829\n",
      "iteration 62 / 300: loss 0.598422\n",
      "iteration 62 / 300: loss 0.599493\n",
      "iteration 62 / 300: loss 0.588745\n",
      "iteration 62 / 300: loss 0.601436\n",
      "iteration 62 / 300: loss 0.600554\n",
      "iteration 62 / 300: loss 0.618443\n",
      "iteration 62 / 300: loss 0.599686\n",
      "iteration 62 / 300: loss 0.601560\n",
      "iteration 62 / 300: loss 0.606291\n",
      "iteration 62 / 300: loss 0.599554\n",
      "iteration 62 / 300: loss 0.592368\n",
      "iteration 62 / 300: loss 0.581207\n",
      "iteration 62 / 300: loss 0.599144\n",
      "iteration 62 / 300: loss 0.612608\n",
      "iteration 62 / 300: loss 0.614074\n",
      "iteration 62 / 300: loss 0.582954\n",
      "iteration 62 / 300: loss 0.603132\n",
      "iteration 62 / 300: loss 0.609953\n",
      "iteration 62 / 300: loss 0.602738\n",
      "iteration 62 / 300: loss 0.609048\n",
      "iteration 62 / 300: loss 0.621421\n",
      "iteration 62 / 300: loss 0.585771\n",
      "iteration 62 / 300: loss 0.584409\n",
      "iteration 62 / 300: loss 0.629816\n",
      "iteration 62 / 300: loss 0.610150\n",
      "iteration 62 / 300: loss 0.607205\n",
      "iteration 62 / 300: loss 0.599899\n",
      "iteration 62 / 300: loss 0.616897\n",
      "iteration 62 / 300: loss 0.597364\n",
      "iteration 62 / 300: loss 0.582414\n",
      "iteration 62 / 300: loss 0.610622\n",
      "iteration 62 / 300: loss 0.608933\n",
      "iteration 62 / 300: loss 0.599167\n",
      "iteration 62 / 300: loss 0.592937\n",
      "iteration 62 / 300: loss 0.612033\n",
      "iteration 62 / 300: loss 0.599435\n",
      "iteration 62 / 300: loss 0.582100\n",
      "iteration 62 / 300: loss 0.610474\n",
      "iteration 63 / 300: loss 0.579361\n",
      "iteration 63 / 300: loss 0.597111\n",
      "iteration 63 / 300: loss 0.570283\n",
      "iteration 63 / 300: loss 0.598765\n",
      "iteration 63 / 300: loss 0.599830\n",
      "iteration 63 / 300: loss 0.604739\n",
      "iteration 63 / 300: loss 0.615886\n",
      "iteration 63 / 300: loss 0.589070\n",
      "iteration 63 / 300: loss 0.627870\n",
      "iteration 63 / 300: loss 0.593618\n",
      "iteration 63 / 300: loss 0.622535\n",
      "iteration 63 / 300: loss 0.593820\n",
      "iteration 63 / 300: loss 0.601350\n",
      "iteration 63 / 300: loss 0.571663\n",
      "iteration 63 / 300: loss 0.593750\n",
      "iteration 63 / 300: loss 0.600960\n",
      "iteration 63 / 300: loss 0.598778\n",
      "iteration 63 / 300: loss 0.584342\n",
      "iteration 63 / 300: loss 0.615180\n",
      "iteration 63 / 300: loss 0.592107\n",
      "iteration 63 / 300: loss 0.592123\n",
      "iteration 63 / 300: loss 0.594695\n",
      "iteration 63 / 300: loss 0.597873\n",
      "iteration 63 / 300: loss 0.597569\n",
      "iteration 63 / 300: loss 0.612574\n",
      "iteration 63 / 300: loss 0.608402\n",
      "iteration 63 / 300: loss 0.597987\n",
      "iteration 63 / 300: loss 0.597023\n",
      "iteration 63 / 300: loss 0.628130\n",
      "iteration 63 / 300: loss 0.602469\n",
      "iteration 63 / 300: loss 0.600647\n",
      "iteration 63 / 300: loss 0.622662\n",
      "iteration 63 / 300: loss 0.582464\n",
      "iteration 63 / 300: loss 0.600492\n",
      "iteration 63 / 300: loss 0.592271\n",
      "iteration 63 / 300: loss 0.600794\n",
      "iteration 63 / 300: loss 0.596896\n",
      "iteration 63 / 300: loss 0.591649\n",
      "iteration 63 / 300: loss 0.592906\n",
      "iteration 63 / 300: loss 0.616426\n",
      "iteration 63 / 300: loss 0.622148\n",
      "iteration 63 / 300: loss 0.588124\n",
      "iteration 63 / 300: loss 0.583359\n",
      "iteration 63 / 300: loss 0.586419\n",
      "iteration 63 / 300: loss 0.604671\n",
      "iteration 63 / 300: loss 0.586149\n",
      "iteration 63 / 300: loss 0.579769\n",
      "iteration 63 / 300: loss 0.577191\n",
      "iteration 63 / 300: loss 0.574848\n",
      "iteration 63 / 300: loss 0.601140\n",
      "iteration 63 / 300: loss 0.585231\n",
      "iteration 63 / 300: loss 0.585538\n",
      "iteration 63 / 300: loss 0.569082\n",
      "iteration 63 / 300: loss 0.592874\n",
      "iteration 63 / 300: loss 0.612984\n",
      "iteration 63 / 300: loss 0.609687\n",
      "iteration 63 / 300: loss 0.608482\n",
      "iteration 63 / 300: loss 0.596272\n",
      "iteration 63 / 300: loss 0.593634\n",
      "iteration 63 / 300: loss 0.598849\n",
      "iteration 63 / 300: loss 0.598543\n",
      "iteration 63 / 300: loss 0.601750\n",
      "iteration 63 / 300: loss 0.598331\n",
      "iteration 63 / 300: loss 0.599427\n",
      "iteration 63 / 300: loss 0.588659\n",
      "iteration 63 / 300: loss 0.601347\n",
      "iteration 63 / 300: loss 0.600470\n",
      "iteration 63 / 300: loss 0.618363\n",
      "iteration 63 / 300: loss 0.599611\n",
      "iteration 63 / 300: loss 0.601490\n",
      "iteration 63 / 300: loss 0.606201\n",
      "iteration 63 / 300: loss 0.599465\n",
      "iteration 63 / 300: loss 0.592283\n",
      "iteration 63 / 300: loss 0.581131\n",
      "iteration 63 / 300: loss 0.599061\n",
      "iteration 63 / 300: loss 0.612520\n",
      "iteration 63 / 300: loss 0.613993\n",
      "iteration 63 / 300: loss 0.582885\n",
      "iteration 63 / 300: loss 0.603022\n",
      "iteration 63 / 300: loss 0.609863\n",
      "iteration 63 / 300: loss 0.602651\n",
      "iteration 63 / 300: loss 0.608948\n",
      "iteration 63 / 300: loss 0.621311\n",
      "iteration 63 / 300: loss 0.585684\n",
      "iteration 63 / 300: loss 0.584345\n",
      "iteration 63 / 300: loss 0.629722\n",
      "iteration 63 / 300: loss 0.610081\n",
      "iteration 63 / 300: loss 0.607121\n",
      "iteration 63 / 300: loss 0.599820\n",
      "iteration 63 / 300: loss 0.616804\n",
      "iteration 63 / 300: loss 0.597286\n",
      "iteration 63 / 300: loss 0.582323\n",
      "iteration 63 / 300: loss 0.610547\n",
      "iteration 63 / 300: loss 0.608857\n",
      "iteration 63 / 300: loss 0.599080\n",
      "iteration 63 / 300: loss 0.592855\n",
      "iteration 63 / 300: loss 0.611940\n",
      "iteration 63 / 300: loss 0.599354\n",
      "iteration 63 / 300: loss 0.582036\n",
      "iteration 63 / 300: loss 0.610394\n",
      "iteration 64 / 300: loss 0.579272\n",
      "iteration 64 / 300: loss 0.597030\n",
      "iteration 64 / 300: loss 0.570208\n",
      "iteration 64 / 300: loss 0.598681\n",
      "iteration 64 / 300: loss 0.599746\n",
      "iteration 64 / 300: loss 0.604661\n",
      "iteration 64 / 300: loss 0.615829\n",
      "iteration 64 / 300: loss 0.588993\n",
      "iteration 64 / 300: loss 0.627809\n",
      "iteration 64 / 300: loss 0.593525\n",
      "iteration 64 / 300: loss 0.622440\n",
      "iteration 64 / 300: loss 0.593755\n",
      "iteration 64 / 300: loss 0.601276\n",
      "iteration 64 / 300: loss 0.571604\n",
      "iteration 64 / 300: loss 0.593673\n",
      "iteration 64 / 300: loss 0.600873\n",
      "iteration 64 / 300: loss 0.598711\n",
      "iteration 64 / 300: loss 0.584285\n",
      "iteration 64 / 300: loss 0.615100\n",
      "iteration 64 / 300: loss 0.592031\n",
      "iteration 64 / 300: loss 0.592054\n",
      "iteration 64 / 300: loss 0.594632\n",
      "iteration 64 / 300: loss 0.597763\n",
      "iteration 64 / 300: loss 0.597488\n",
      "iteration 64 / 300: loss 0.612496\n",
      "iteration 64 / 300: loss 0.608294\n",
      "iteration 64 / 300: loss 0.597899\n",
      "iteration 64 / 300: loss 0.596958\n",
      "iteration 64 / 300: loss 0.628064\n",
      "iteration 64 / 300: loss 0.602388\n",
      "iteration 64 / 300: loss 0.600580\n",
      "iteration 64 / 300: loss 0.622596\n",
      "iteration 64 / 300: loss 0.582370\n",
      "iteration 64 / 300: loss 0.600412\n",
      "iteration 64 / 300: loss 0.592169\n",
      "iteration 64 / 300: loss 0.600712\n",
      "iteration 64 / 300: loss 0.596813\n",
      "iteration 64 / 300: loss 0.591565\n",
      "iteration 64 / 300: loss 0.592820\n",
      "iteration 64 / 300: loss 0.616337\n",
      "iteration 64 / 300: loss 0.622077\n",
      "iteration 64 / 300: loss 0.588041\n",
      "iteration 64 / 300: loss 0.583279\n",
      "iteration 64 / 300: loss 0.586340\n",
      "iteration 64 / 300: loss 0.604580\n",
      "iteration 64 / 300: loss 0.586063\n",
      "iteration 64 / 300: loss 0.579685\n",
      "iteration 64 / 300: loss 0.577120\n",
      "iteration 64 / 300: loss 0.574781\n",
      "iteration 64 / 300: loss 0.601082\n",
      "iteration 64 / 300: loss 0.585164\n",
      "iteration 64 / 300: loss 0.585475\n",
      "iteration 64 / 300: loss 0.569011\n",
      "iteration 64 / 300: loss 0.592794\n",
      "iteration 64 / 300: loss 0.612904\n",
      "iteration 64 / 300: loss 0.609616\n",
      "iteration 64 / 300: loss 0.608401\n",
      "iteration 64 / 300: loss 0.596206\n",
      "iteration 64 / 300: loss 0.593561\n",
      "iteration 64 / 300: loss 0.598771\n",
      "iteration 64 / 300: loss 0.598465\n",
      "iteration 64 / 300: loss 0.601678\n",
      "iteration 64 / 300: loss 0.598247\n",
      "iteration 64 / 300: loss 0.599368\n",
      "iteration 64 / 300: loss 0.588580\n",
      "iteration 64 / 300: loss 0.601267\n",
      "iteration 64 / 300: loss 0.600394\n",
      "iteration 64 / 300: loss 0.618290\n",
      "iteration 64 / 300: loss 0.599543\n",
      "iteration 64 / 300: loss 0.601426\n",
      "iteration 64 / 300: loss 0.606118\n",
      "iteration 64 / 300: loss 0.599383\n",
      "iteration 64 / 300: loss 0.592207\n",
      "iteration 64 / 300: loss 0.581062\n",
      "iteration 64 / 300: loss 0.598986\n",
      "iteration 64 / 300: loss 0.612440\n",
      "iteration 64 / 300: loss 0.613921\n",
      "iteration 64 / 300: loss 0.582823\n",
      "iteration 64 / 300: loss 0.602921\n",
      "iteration 64 / 300: loss 0.609780\n",
      "iteration 64 / 300: loss 0.602572\n",
      "iteration 64 / 300: loss 0.608856\n",
      "iteration 64 / 300: loss 0.621211\n",
      "iteration 64 / 300: loss 0.585605\n",
      "iteration 64 / 300: loss 0.584287\n",
      "iteration 64 / 300: loss 0.629637\n",
      "iteration 64 / 300: loss 0.610018\n",
      "iteration 64 / 300: loss 0.607043\n",
      "iteration 64 / 300: loss 0.599747\n",
      "iteration 64 / 300: loss 0.616718\n",
      "iteration 64 / 300: loss 0.597214\n",
      "iteration 64 / 300: loss 0.582241\n",
      "iteration 64 / 300: loss 0.610478\n",
      "iteration 64 / 300: loss 0.608789\n",
      "iteration 64 / 300: loss 0.599001\n",
      "iteration 64 / 300: loss 0.592781\n",
      "iteration 64 / 300: loss 0.611855\n",
      "iteration 64 / 300: loss 0.599280\n",
      "iteration 64 / 300: loss 0.581978\n",
      "iteration 64 / 300: loss 0.610321\n",
      "iteration 65 / 300: loss 0.579191\n",
      "iteration 65 / 300: loss 0.596955\n",
      "iteration 65 / 300: loss 0.570139\n",
      "iteration 65 / 300: loss 0.598605\n",
      "iteration 65 / 300: loss 0.599669\n",
      "iteration 65 / 300: loss 0.604591\n",
      "iteration 65 / 300: loss 0.615776\n",
      "iteration 65 / 300: loss 0.588923\n",
      "iteration 65 / 300: loss 0.627753\n",
      "iteration 65 / 300: loss 0.593440\n",
      "iteration 65 / 300: loss 0.622353\n",
      "iteration 65 / 300: loss 0.593695\n",
      "iteration 65 / 300: loss 0.601209\n",
      "iteration 65 / 300: loss 0.571550\n",
      "iteration 65 / 300: loss 0.593603\n",
      "iteration 65 / 300: loss 0.600794\n",
      "iteration 65 / 300: loss 0.598651\n",
      "iteration 65 / 300: loss 0.584233\n",
      "iteration 65 / 300: loss 0.615028\n",
      "iteration 65 / 300: loss 0.591962\n",
      "iteration 65 / 300: loss 0.591992\n",
      "iteration 65 / 300: loss 0.594575\n",
      "iteration 65 / 300: loss 0.597664\n",
      "iteration 65 / 300: loss 0.597415\n",
      "iteration 65 / 300: loss 0.612425\n",
      "iteration 65 / 300: loss 0.608196\n",
      "iteration 65 / 300: loss 0.597818\n",
      "iteration 65 / 300: loss 0.596899\n",
      "iteration 65 / 300: loss 0.628003\n",
      "iteration 65 / 300: loss 0.602314\n",
      "iteration 65 / 300: loss 0.600519\n",
      "iteration 65 / 300: loss 0.622537\n",
      "iteration 65 / 300: loss 0.582284\n",
      "iteration 65 / 300: loss 0.600338\n",
      "iteration 65 / 300: loss 0.592077\n",
      "iteration 65 / 300: loss 0.600638\n",
      "iteration 65 / 300: loss 0.596738\n",
      "iteration 65 / 300: loss 0.591489\n",
      "iteration 65 / 300: loss 0.592741\n",
      "iteration 65 / 300: loss 0.616256\n",
      "iteration 65 / 300: loss 0.622012\n",
      "iteration 65 / 300: loss 0.587967\n",
      "iteration 65 / 300: loss 0.583206\n",
      "iteration 65 / 300: loss 0.586269\n",
      "iteration 65 / 300: loss 0.604497\n",
      "iteration 65 / 300: loss 0.585984\n",
      "iteration 65 / 300: loss 0.579608\n",
      "iteration 65 / 300: loss 0.577055\n",
      "iteration 65 / 300: loss 0.574719\n",
      "iteration 65 / 300: loss 0.601030\n",
      "iteration 65 / 300: loss 0.585103\n",
      "iteration 65 / 300: loss 0.585418\n",
      "iteration 65 / 300: loss 0.568947\n",
      "iteration 65 / 300: loss 0.592722\n",
      "iteration 65 / 300: loss 0.612831\n",
      "iteration 65 / 300: loss 0.609552\n",
      "iteration 65 / 300: loss 0.608328\n",
      "iteration 65 / 300: loss 0.596145\n",
      "iteration 65 / 300: loss 0.593494\n",
      "iteration 65 / 300: loss 0.598699\n",
      "iteration 65 / 300: loss 0.598393\n",
      "iteration 65 / 300: loss 0.601611\n",
      "iteration 65 / 300: loss 0.598171\n",
      "iteration 65 / 300: loss 0.599314\n",
      "iteration 65 / 300: loss 0.588509\n",
      "iteration 65 / 300: loss 0.601194\n",
      "iteration 65 / 300: loss 0.600325\n",
      "iteration 65 / 300: loss 0.618223\n",
      "iteration 65 / 300: loss 0.599481\n",
      "iteration 65 / 300: loss 0.601368\n",
      "iteration 65 / 300: loss 0.606043\n",
      "iteration 65 / 300: loss 0.599310\n",
      "iteration 65 / 300: loss 0.592137\n",
      "iteration 65 / 300: loss 0.581000\n",
      "iteration 65 / 300: loss 0.598917\n",
      "iteration 65 / 300: loss 0.612368\n",
      "iteration 65 / 300: loss 0.613855\n",
      "iteration 65 / 300: loss 0.582766\n",
      "iteration 65 / 300: loss 0.602830\n",
      "iteration 65 / 300: loss 0.609704\n",
      "iteration 65 / 300: loss 0.602500\n",
      "iteration 65 / 300: loss 0.608773\n",
      "iteration 65 / 300: loss 0.621120\n",
      "iteration 65 / 300: loss 0.585533\n",
      "iteration 65 / 300: loss 0.584235\n",
      "iteration 65 / 300: loss 0.629561\n",
      "iteration 65 / 300: loss 0.609961\n",
      "iteration 65 / 300: loss 0.606973\n",
      "iteration 65 / 300: loss 0.599682\n",
      "iteration 65 / 300: loss 0.616640\n",
      "iteration 65 / 300: loss 0.597149\n",
      "iteration 65 / 300: loss 0.582166\n",
      "iteration 65 / 300: loss 0.610415\n",
      "iteration 65 / 300: loss 0.608726\n",
      "iteration 65 / 300: loss 0.598929\n",
      "iteration 65 / 300: loss 0.592712\n",
      "iteration 65 / 300: loss 0.611779\n",
      "iteration 65 / 300: loss 0.599213\n",
      "iteration 65 / 300: loss 0.581924\n",
      "iteration 65 / 300: loss 0.610254\n",
      "iteration 66 / 300: loss 0.579118\n",
      "iteration 66 / 300: loss 0.596887\n",
      "iteration 66 / 300: loss 0.570077\n",
      "iteration 66 / 300: loss 0.598536\n",
      "iteration 66 / 300: loss 0.599600\n",
      "iteration 66 / 300: loss 0.604526\n",
      "iteration 66 / 300: loss 0.615728\n",
      "iteration 66 / 300: loss 0.588859\n",
      "iteration 66 / 300: loss 0.627702\n",
      "iteration 66 / 300: loss 0.593363\n",
      "iteration 66 / 300: loss 0.622274\n",
      "iteration 66 / 300: loss 0.593641\n",
      "iteration 66 / 300: loss 0.601148\n",
      "iteration 66 / 300: loss 0.571500\n",
      "iteration 66 / 300: loss 0.593539\n",
      "iteration 66 / 300: loss 0.600723\n",
      "iteration 66 / 300: loss 0.598595\n",
      "iteration 66 / 300: loss 0.584185\n",
      "iteration 66 / 300: loss 0.614964\n",
      "iteration 66 / 300: loss 0.591899\n",
      "iteration 66 / 300: loss 0.591935\n",
      "iteration 66 / 300: loss 0.594522\n",
      "iteration 66 / 300: loss 0.597575\n",
      "iteration 66 / 300: loss 0.597349\n",
      "iteration 66 / 300: loss 0.612361\n",
      "iteration 66 / 300: loss 0.608107\n",
      "iteration 66 / 300: loss 0.597745\n",
      "iteration 66 / 300: loss 0.596844\n",
      "iteration 66 / 300: loss 0.627948\n",
      "iteration 66 / 300: loss 0.602247\n",
      "iteration 66 / 300: loss 0.600464\n",
      "iteration 66 / 300: loss 0.622482\n",
      "iteration 66 / 300: loss 0.582206\n",
      "iteration 66 / 300: loss 0.600271\n",
      "iteration 66 / 300: loss 0.591992\n",
      "iteration 66 / 300: loss 0.600570\n",
      "iteration 66 / 300: loss 0.596669\n",
      "iteration 66 / 300: loss 0.591419\n",
      "iteration 66 / 300: loss 0.592669\n",
      "iteration 66 / 300: loss 0.616182\n",
      "iteration 66 / 300: loss 0.621953\n",
      "iteration 66 / 300: loss 0.587900\n",
      "iteration 66 / 300: loss 0.583140\n",
      "iteration 66 / 300: loss 0.586204\n",
      "iteration 66 / 300: loss 0.604421\n",
      "iteration 66 / 300: loss 0.585912\n",
      "iteration 66 / 300: loss 0.579539\n",
      "iteration 66 / 300: loss 0.576995\n",
      "iteration 66 / 300: loss 0.574662\n",
      "iteration 66 / 300: loss 0.600982\n",
      "iteration 66 / 300: loss 0.585048\n",
      "iteration 66 / 300: loss 0.585366\n",
      "iteration 66 / 300: loss 0.568888\n",
      "iteration 66 / 300: loss 0.592657\n",
      "iteration 66 / 300: loss 0.612765\n",
      "iteration 66 / 300: loss 0.609493\n",
      "iteration 66 / 300: loss 0.608261\n",
      "iteration 66 / 300: loss 0.596090\n",
      "iteration 66 / 300: loss 0.593434\n",
      "iteration 66 / 300: loss 0.598634\n",
      "iteration 66 / 300: loss 0.598327\n",
      "iteration 66 / 300: loss 0.601551\n",
      "iteration 66 / 300: loss 0.598101\n",
      "iteration 66 / 300: loss 0.599264\n",
      "iteration 66 / 300: loss 0.588444\n",
      "iteration 66 / 300: loss 0.601128\n",
      "iteration 66 / 300: loss 0.600262\n",
      "iteration 66 / 300: loss 0.618162\n",
      "iteration 66 / 300: loss 0.599425\n",
      "iteration 66 / 300: loss 0.601315\n",
      "iteration 66 / 300: loss 0.605975\n",
      "iteration 66 / 300: loss 0.599242\n",
      "iteration 66 / 300: loss 0.592075\n",
      "iteration 66 / 300: loss 0.580942\n",
      "iteration 66 / 300: loss 0.598854\n",
      "iteration 66 / 300: loss 0.612303\n",
      "iteration 66 / 300: loss 0.613795\n",
      "iteration 66 / 300: loss 0.582714\n",
      "iteration 66 / 300: loss 0.602748\n",
      "iteration 66 / 300: loss 0.609636\n",
      "iteration 66 / 300: loss 0.602434\n",
      "iteration 66 / 300: loss 0.608696\n",
      "iteration 66 / 300: loss 0.621038\n",
      "iteration 66 / 300: loss 0.585467\n",
      "iteration 66 / 300: loss 0.584187\n",
      "iteration 66 / 300: loss 0.629492\n",
      "iteration 66 / 300: loss 0.609909\n",
      "iteration 66 / 300: loss 0.606908\n",
      "iteration 66 / 300: loss 0.599622\n",
      "iteration 66 / 300: loss 0.616569\n",
      "iteration 66 / 300: loss 0.597089\n",
      "iteration 66 / 300: loss 0.582098\n",
      "iteration 66 / 300: loss 0.610359\n",
      "iteration 66 / 300: loss 0.608670\n",
      "iteration 66 / 300: loss 0.598863\n",
      "iteration 66 / 300: loss 0.592649\n",
      "iteration 66 / 300: loss 0.611709\n",
      "iteration 66 / 300: loss 0.599151\n",
      "iteration 66 / 300: loss 0.581876\n",
      "iteration 66 / 300: loss 0.610192\n",
      "iteration 67 / 300: loss 0.579050\n",
      "iteration 67 / 300: loss 0.596824\n",
      "iteration 67 / 300: loss 0.570020\n",
      "iteration 67 / 300: loss 0.598472\n",
      "iteration 67 / 300: loss 0.599538\n",
      "iteration 67 / 300: loss 0.604467\n",
      "iteration 67 / 300: loss 0.615685\n",
      "iteration 67 / 300: loss 0.588800\n",
      "iteration 67 / 300: loss 0.627654\n",
      "iteration 67 / 300: loss 0.593292\n",
      "iteration 67 / 300: loss 0.622202\n",
      "iteration 67 / 300: loss 0.593591\n",
      "iteration 67 / 300: loss 0.601092\n",
      "iteration 67 / 300: loss 0.571455\n",
      "iteration 67 / 300: loss 0.593481\n",
      "iteration 67 / 300: loss 0.600658\n",
      "iteration 67 / 300: loss 0.598545\n",
      "iteration 67 / 300: loss 0.584142\n",
      "iteration 67 / 300: loss 0.614905\n",
      "iteration 67 / 300: loss 0.591842\n",
      "iteration 67 / 300: loss 0.591884\n",
      "iteration 67 / 300: loss 0.594475\n",
      "iteration 67 / 300: loss 0.597494\n",
      "iteration 67 / 300: loss 0.597289\n",
      "iteration 67 / 300: loss 0.612303\n",
      "iteration 67 / 300: loss 0.608026\n",
      "iteration 67 / 300: loss 0.597678\n",
      "iteration 67 / 300: loss 0.596795\n",
      "iteration 67 / 300: loss 0.627897\n",
      "iteration 67 / 300: loss 0.602186\n",
      "iteration 67 / 300: loss 0.600413\n",
      "iteration 67 / 300: loss 0.622433\n",
      "iteration 67 / 300: loss 0.582134\n",
      "iteration 67 / 300: loss 0.600210\n",
      "iteration 67 / 300: loss 0.591916\n",
      "iteration 67 / 300: loss 0.600509\n",
      "iteration 67 / 300: loss 0.596607\n",
      "iteration 67 / 300: loss 0.591357\n",
      "iteration 67 / 300: loss 0.592604\n",
      "iteration 67 / 300: loss 0.616115\n",
      "iteration 67 / 300: loss 0.621898\n",
      "iteration 67 / 300: loss 0.587839\n",
      "iteration 67 / 300: loss 0.583079\n",
      "iteration 67 / 300: loss 0.586146\n",
      "iteration 67 / 300: loss 0.604351\n",
      "iteration 67 / 300: loss 0.585846\n",
      "iteration 67 / 300: loss 0.579476\n",
      "iteration 67 / 300: loss 0.576942\n",
      "iteration 67 / 300: loss 0.574610\n",
      "iteration 67 / 300: loss 0.600938\n",
      "iteration 67 / 300: loss 0.584997\n",
      "iteration 67 / 300: loss 0.585318\n",
      "iteration 67 / 300: loss 0.568835\n",
      "iteration 67 / 300: loss 0.592597\n",
      "iteration 67 / 300: loss 0.612704\n",
      "iteration 67 / 300: loss 0.609440\n",
      "iteration 67 / 300: loss 0.608200\n",
      "iteration 67 / 300: loss 0.596039\n",
      "iteration 67 / 300: loss 0.593378\n",
      "iteration 67 / 300: loss 0.598575\n",
      "iteration 67 / 300: loss 0.598267\n",
      "iteration 67 / 300: loss 0.601496\n",
      "iteration 67 / 300: loss 0.598038\n",
      "iteration 67 / 300: loss 0.599219\n",
      "iteration 67 / 300: loss 0.588385\n",
      "iteration 67 / 300: loss 0.601069\n",
      "iteration 67 / 300: loss 0.600205\n",
      "iteration 67 / 300: loss 0.618106\n",
      "iteration 67 / 300: loss 0.599374\n",
      "iteration 67 / 300: loss 0.601266\n",
      "iteration 67 / 300: loss 0.605912\n",
      "iteration 67 / 300: loss 0.599181\n",
      "iteration 67 / 300: loss 0.592018\n",
      "iteration 67 / 300: loss 0.580890\n",
      "iteration 67 / 300: loss 0.598796\n",
      "iteration 67 / 300: loss 0.612244\n",
      "iteration 67 / 300: loss 0.613741\n",
      "iteration 67 / 300: loss 0.582668\n",
      "iteration 67 / 300: loss 0.602673\n",
      "iteration 67 / 300: loss 0.609573\n",
      "iteration 67 / 300: loss 0.602374\n",
      "iteration 67 / 300: loss 0.608627\n",
      "iteration 67 / 300: loss 0.620963\n",
      "iteration 67 / 300: loss 0.585407\n",
      "iteration 67 / 300: loss 0.584144\n",
      "iteration 67 / 300: loss 0.629429\n",
      "iteration 67 / 300: loss 0.609861\n",
      "iteration 67 / 300: loss 0.606849\n",
      "iteration 67 / 300: loss 0.599568\n",
      "iteration 67 / 300: loss 0.616505\n",
      "iteration 67 / 300: loss 0.597034\n",
      "iteration 67 / 300: loss 0.582035\n",
      "iteration 67 / 300: loss 0.610307\n",
      "iteration 67 / 300: loss 0.608619\n",
      "iteration 67 / 300: loss 0.598803\n",
      "iteration 67 / 300: loss 0.592592\n",
      "iteration 67 / 300: loss 0.611645\n",
      "iteration 67 / 300: loss 0.599095\n",
      "iteration 67 / 300: loss 0.581831\n",
      "iteration 67 / 300: loss 0.610136\n",
      "iteration 68 / 300: loss 0.578988\n",
      "iteration 68 / 300: loss 0.596768\n",
      "iteration 68 / 300: loss 0.569968\n",
      "iteration 68 / 300: loss 0.598415\n",
      "iteration 68 / 300: loss 0.599481\n",
      "iteration 68 / 300: loss 0.604413\n",
      "iteration 68 / 300: loss 0.615645\n",
      "iteration 68 / 300: loss 0.588747\n",
      "iteration 68 / 300: loss 0.627611\n",
      "iteration 68 / 300: loss 0.593228\n",
      "iteration 68 / 300: loss 0.622136\n",
      "iteration 68 / 300: loss 0.593545\n",
      "iteration 68 / 300: loss 0.601041\n",
      "iteration 68 / 300: loss 0.571414\n",
      "iteration 68 / 300: loss 0.593429\n",
      "iteration 68 / 300: loss 0.600600\n",
      "iteration 68 / 300: loss 0.598499\n",
      "iteration 68 / 300: loss 0.584102\n",
      "iteration 68 / 300: loss 0.614852\n",
      "iteration 68 / 300: loss 0.591790\n",
      "iteration 68 / 300: loss 0.591838\n",
      "iteration 68 / 300: loss 0.594432\n",
      "iteration 68 / 300: loss 0.597421\n",
      "iteration 68 / 300: loss 0.597234\n",
      "iteration 68 / 300: loss 0.612250\n",
      "iteration 68 / 300: loss 0.607953\n",
      "iteration 68 / 300: loss 0.597618\n",
      "iteration 68 / 300: loss 0.596749\n",
      "iteration 68 / 300: loss 0.627851\n",
      "iteration 68 / 300: loss 0.602131\n",
      "iteration 68 / 300: loss 0.600367\n",
      "iteration 68 / 300: loss 0.622388\n",
      "iteration 68 / 300: loss 0.582069\n",
      "iteration 68 / 300: loss 0.600154\n",
      "iteration 68 / 300: loss 0.591847\n",
      "iteration 68 / 300: loss 0.600454\n",
      "iteration 68 / 300: loss 0.596551\n",
      "iteration 68 / 300: loss 0.591300\n",
      "iteration 68 / 300: loss 0.592544\n",
      "iteration 68 / 300: loss 0.616054\n",
      "iteration 68 / 300: loss 0.621849\n",
      "iteration 68 / 300: loss 0.587784\n",
      "iteration 68 / 300: loss 0.583024\n",
      "iteration 68 / 300: loss 0.586092\n",
      "iteration 68 / 300: loss 0.604288\n",
      "iteration 68 / 300: loss 0.585785\n",
      "iteration 68 / 300: loss 0.579419\n",
      "iteration 68 / 300: loss 0.576893\n",
      "iteration 68 / 300: loss 0.574563\n",
      "iteration 68 / 300: loss 0.600898\n",
      "iteration 68 / 300: loss 0.584951\n",
      "iteration 68 / 300: loss 0.585274\n",
      "iteration 68 / 300: loss 0.568787\n",
      "iteration 68 / 300: loss 0.592543\n",
      "iteration 68 / 300: loss 0.612649\n",
      "iteration 68 / 300: loss 0.609392\n",
      "iteration 68 / 300: loss 0.608145\n",
      "iteration 68 / 300: loss 0.595993\n",
      "iteration 68 / 300: loss 0.593328\n",
      "iteration 68 / 300: loss 0.598520\n",
      "iteration 68 / 300: loss 0.598213\n",
      "iteration 68 / 300: loss 0.601446\n",
      "iteration 68 / 300: loss 0.597981\n",
      "iteration 68 / 300: loss 0.599179\n",
      "iteration 68 / 300: loss 0.588331\n",
      "iteration 68 / 300: loss 0.601015\n",
      "iteration 68 / 300: loss 0.600153\n",
      "iteration 68 / 300: loss 0.618054\n",
      "iteration 68 / 300: loss 0.599327\n",
      "iteration 68 / 300: loss 0.601223\n",
      "iteration 68 / 300: loss 0.605855\n",
      "iteration 68 / 300: loss 0.599126\n",
      "iteration 68 / 300: loss 0.591966\n",
      "iteration 68 / 300: loss 0.580843\n",
      "iteration 68 / 300: loss 0.598743\n",
      "iteration 68 / 300: loss 0.612191\n",
      "iteration 68 / 300: loss 0.613692\n",
      "iteration 68 / 300: loss 0.582625\n",
      "iteration 68 / 300: loss 0.602605\n",
      "iteration 68 / 300: loss 0.609516\n",
      "iteration 68 / 300: loss 0.602320\n",
      "iteration 68 / 300: loss 0.608564\n",
      "iteration 68 / 300: loss 0.620894\n",
      "iteration 68 / 300: loss 0.585352\n",
      "iteration 68 / 300: loss 0.584105\n",
      "iteration 68 / 300: loss 0.629373\n",
      "iteration 68 / 300: loss 0.609818\n",
      "iteration 68 / 300: loss 0.606796\n",
      "iteration 68 / 300: loss 0.599518\n",
      "iteration 68 / 300: loss 0.616446\n",
      "iteration 68 / 300: loss 0.596984\n",
      "iteration 68 / 300: loss 0.581979\n",
      "iteration 68 / 300: loss 0.610260\n",
      "iteration 68 / 300: loss 0.608572\n",
      "iteration 68 / 300: loss 0.598749\n",
      "iteration 68 / 300: loss 0.592539\n",
      "iteration 68 / 300: loss 0.611588\n",
      "iteration 68 / 300: loss 0.599044\n",
      "iteration 68 / 300: loss 0.581790\n",
      "iteration 68 / 300: loss 0.610085\n",
      "iteration 69 / 300: loss 0.578932\n",
      "iteration 69 / 300: loss 0.596716\n",
      "iteration 69 / 300: loss 0.569920\n",
      "iteration 69 / 300: loss 0.598362\n",
      "iteration 69 / 300: loss 0.599430\n",
      "iteration 69 / 300: loss 0.604363\n",
      "iteration 69 / 300: loss 0.615609\n",
      "iteration 69 / 300: loss 0.588699\n",
      "iteration 69 / 300: loss 0.627571\n",
      "iteration 69 / 300: loss 0.593170\n",
      "iteration 69 / 300: loss 0.622077\n",
      "iteration 69 / 300: loss 0.593503\n",
      "iteration 69 / 300: loss 0.600995\n",
      "iteration 69 / 300: loss 0.571376\n",
      "iteration 69 / 300: loss 0.593381\n",
      "iteration 69 / 300: loss 0.600547\n",
      "iteration 69 / 300: loss 0.598458\n",
      "iteration 69 / 300: loss 0.584067\n",
      "iteration 69 / 300: loss 0.614805\n",
      "iteration 69 / 300: loss 0.591743\n",
      "iteration 69 / 300: loss 0.591795\n",
      "iteration 69 / 300: loss 0.594392\n",
      "iteration 69 / 300: loss 0.597354\n",
      "iteration 69 / 300: loss 0.597185\n",
      "iteration 69 / 300: loss 0.612202\n",
      "iteration 69 / 300: loss 0.607887\n",
      "iteration 69 / 300: loss 0.597563\n",
      "iteration 69 / 300: loss 0.596708\n",
      "iteration 69 / 300: loss 0.627809\n",
      "iteration 69 / 300: loss 0.602080\n",
      "iteration 69 / 300: loss 0.600326\n",
      "iteration 69 / 300: loss 0.622348\n",
      "iteration 69 / 300: loss 0.582010\n",
      "iteration 69 / 300: loss 0.600103\n",
      "iteration 69 / 300: loss 0.591784\n",
      "iteration 69 / 300: loss 0.600403\n",
      "iteration 69 / 300: loss 0.596500\n",
      "iteration 69 / 300: loss 0.591248\n",
      "iteration 69 / 300: loss 0.592490\n",
      "iteration 69 / 300: loss 0.615999\n",
      "iteration 69 / 300: loss 0.621803\n",
      "iteration 69 / 300: loss 0.587735\n",
      "iteration 69 / 300: loss 0.582974\n",
      "iteration 69 / 300: loss 0.586044\n",
      "iteration 69 / 300: loss 0.604230\n",
      "iteration 69 / 300: loss 0.585731\n",
      "iteration 69 / 300: loss 0.579368\n",
      "iteration 69 / 300: loss 0.576849\n",
      "iteration 69 / 300: loss 0.574520\n",
      "iteration 69 / 300: loss 0.600861\n",
      "iteration 69 / 300: loss 0.584909\n",
      "iteration 69 / 300: loss 0.585234\n",
      "iteration 69 / 300: loss 0.568743\n",
      "iteration 69 / 300: loss 0.592494\n",
      "iteration 69 / 300: loss 0.612600\n",
      "iteration 69 / 300: loss 0.609348\n",
      "iteration 69 / 300: loss 0.608095\n",
      "iteration 69 / 300: loss 0.595951\n",
      "iteration 69 / 300: loss 0.593282\n",
      "iteration 69 / 300: loss 0.598471\n",
      "iteration 69 / 300: loss 0.598163\n",
      "iteration 69 / 300: loss 0.601400\n",
      "iteration 69 / 300: loss 0.597928\n",
      "iteration 69 / 300: loss 0.599141\n",
      "iteration 69 / 300: loss 0.588282\n",
      "iteration 69 / 300: loss 0.600966\n",
      "iteration 69 / 300: loss 0.600105\n",
      "iteration 69 / 300: loss 0.618007\n",
      "iteration 69 / 300: loss 0.599285\n",
      "iteration 69 / 300: loss 0.601183\n",
      "iteration 69 / 300: loss 0.605804\n",
      "iteration 69 / 300: loss 0.599076\n",
      "iteration 69 / 300: loss 0.591920\n",
      "iteration 69 / 300: loss 0.580800\n",
      "iteration 69 / 300: loss 0.598695\n",
      "iteration 69 / 300: loss 0.612142\n",
      "iteration 69 / 300: loss 0.613647\n",
      "iteration 69 / 300: loss 0.582586\n",
      "iteration 69 / 300: loss 0.602543\n",
      "iteration 69 / 300: loss 0.609464\n",
      "iteration 69 / 300: loss 0.602271\n",
      "iteration 69 / 300: loss 0.608506\n",
      "iteration 69 / 300: loss 0.620833\n",
      "iteration 69 / 300: loss 0.585303\n",
      "iteration 69 / 300: loss 0.584069\n",
      "iteration 69 / 300: loss 0.629322\n",
      "iteration 69 / 300: loss 0.609779\n",
      "iteration 69 / 300: loss 0.606747\n",
      "iteration 69 / 300: loss 0.599473\n",
      "iteration 69 / 300: loss 0.616393\n",
      "iteration 69 / 300: loss 0.596938\n",
      "iteration 69 / 300: loss 0.581928\n",
      "iteration 69 / 300: loss 0.610218\n",
      "iteration 69 / 300: loss 0.608530\n",
      "iteration 69 / 300: loss 0.598700\n",
      "iteration 69 / 300: loss 0.592492\n",
      "iteration 69 / 300: loss 0.611536\n",
      "iteration 69 / 300: loss 0.598998\n",
      "iteration 69 / 300: loss 0.581753\n",
      "iteration 69 / 300: loss 0.610039\n",
      "iteration 70 / 300: loss 0.578881\n",
      "iteration 70 / 300: loss 0.596669\n",
      "iteration 70 / 300: loss 0.569877\n",
      "iteration 70 / 300: loss 0.598314\n",
      "iteration 70 / 300: loss 0.599383\n",
      "iteration 70 / 300: loss 0.604319\n",
      "iteration 70 / 300: loss 0.615577\n",
      "iteration 70 / 300: loss 0.588655\n",
      "iteration 70 / 300: loss 0.627535\n",
      "iteration 70 / 300: loss 0.593117\n",
      "iteration 70 / 300: loss 0.622023\n",
      "iteration 70 / 300: loss 0.593466\n",
      "iteration 70 / 300: loss 0.600953\n",
      "iteration 70 / 300: loss 0.571341\n",
      "iteration 70 / 300: loss 0.593337\n",
      "iteration 70 / 300: loss 0.600500\n",
      "iteration 70 / 300: loss 0.598420\n",
      "iteration 70 / 300: loss 0.584034\n",
      "iteration 70 / 300: loss 0.614761\n",
      "iteration 70 / 300: loss 0.591700\n",
      "iteration 70 / 300: loss 0.591757\n",
      "iteration 70 / 300: loss 0.594357\n",
      "iteration 70 / 300: loss 0.597295\n",
      "iteration 70 / 300: loss 0.597140\n",
      "iteration 70 / 300: loss 0.612158\n",
      "iteration 70 / 300: loss 0.607827\n",
      "iteration 70 / 300: loss 0.597513\n",
      "iteration 70 / 300: loss 0.596670\n",
      "iteration 70 / 300: loss 0.627770\n",
      "iteration 70 / 300: loss 0.602034\n",
      "iteration 70 / 300: loss 0.600288\n",
      "iteration 70 / 300: loss 0.622311\n",
      "iteration 70 / 300: loss 0.581956\n",
      "iteration 70 / 300: loss 0.600057\n",
      "iteration 70 / 300: loss 0.591727\n",
      "iteration 70 / 300: loss 0.600358\n",
      "iteration 70 / 300: loss 0.596454\n",
      "iteration 70 / 300: loss 0.591202\n",
      "iteration 70 / 300: loss 0.592440\n",
      "iteration 70 / 300: loss 0.615949\n",
      "iteration 70 / 300: loss 0.621762\n",
      "iteration 70 / 300: loss 0.587690\n",
      "iteration 70 / 300: loss 0.582928\n",
      "iteration 70 / 300: loss 0.585999\n",
      "iteration 70 / 300: loss 0.604178\n",
      "iteration 70 / 300: loss 0.585681\n",
      "iteration 70 / 300: loss 0.579321\n",
      "iteration 70 / 300: loss 0.576809\n",
      "iteration 70 / 300: loss 0.574481\n",
      "iteration 70 / 300: loss 0.600828\n",
      "iteration 70 / 300: loss 0.584870\n",
      "iteration 70 / 300: loss 0.585197\n",
      "iteration 70 / 300: loss 0.568704\n",
      "iteration 70 / 300: loss 0.592450\n",
      "iteration 70 / 300: loss 0.612554\n",
      "iteration 70 / 300: loss 0.609309\n",
      "iteration 70 / 300: loss 0.608050\n",
      "iteration 70 / 300: loss 0.595912\n",
      "iteration 70 / 300: loss 0.593241\n",
      "iteration 70 / 300: loss 0.598426\n",
      "iteration 70 / 300: loss 0.598118\n",
      "iteration 70 / 300: loss 0.601358\n",
      "iteration 70 / 300: loss 0.597881\n",
      "iteration 70 / 300: loss 0.599107\n",
      "iteration 70 / 300: loss 0.588238\n",
      "iteration 70 / 300: loss 0.600922\n",
      "iteration 70 / 300: loss 0.600063\n",
      "iteration 70 / 300: loss 0.617965\n",
      "iteration 70 / 300: loss 0.599246\n",
      "iteration 70 / 300: loss 0.601147\n",
      "iteration 70 / 300: loss 0.605757\n",
      "iteration 70 / 300: loss 0.599030\n",
      "iteration 70 / 300: loss 0.591878\n",
      "iteration 70 / 300: loss 0.580761\n",
      "iteration 70 / 300: loss 0.598651\n",
      "iteration 70 / 300: loss 0.612099\n",
      "iteration 70 / 300: loss 0.613607\n",
      "iteration 70 / 300: loss 0.582551\n",
      "iteration 70 / 300: loss 0.602488\n",
      "iteration 70 / 300: loss 0.609417\n",
      "iteration 70 / 300: loss 0.602226\n",
      "iteration 70 / 300: loss 0.608454\n",
      "iteration 70 / 300: loss 0.620777\n",
      "iteration 70 / 300: loss 0.585258\n",
      "iteration 70 / 300: loss 0.584037\n",
      "iteration 70 / 300: loss 0.629277\n",
      "iteration 70 / 300: loss 0.609743\n",
      "iteration 70 / 300: loss 0.606702\n",
      "iteration 70 / 300: loss 0.599432\n",
      "iteration 70 / 300: loss 0.616344\n",
      "iteration 70 / 300: loss 0.596897\n",
      "iteration 70 / 300: loss 0.581881\n",
      "iteration 70 / 300: loss 0.610179\n",
      "iteration 70 / 300: loss 0.608491\n",
      "iteration 70 / 300: loss 0.598655\n",
      "iteration 70 / 300: loss 0.592448\n",
      "iteration 70 / 300: loss 0.611488\n",
      "iteration 70 / 300: loss 0.598956\n",
      "iteration 70 / 300: loss 0.581719\n",
      "iteration 70 / 300: loss 0.609996\n",
      "iteration 71 / 300: loss 0.578835\n",
      "iteration 71 / 300: loss 0.596627\n",
      "iteration 71 / 300: loss 0.569838\n",
      "iteration 71 / 300: loss 0.598271\n",
      "iteration 71 / 300: loss 0.599341\n",
      "iteration 71 / 300: loss 0.604278\n",
      "iteration 71 / 300: loss 0.615547\n",
      "iteration 71 / 300: loss 0.588615\n",
      "iteration 71 / 300: loss 0.627502\n",
      "iteration 71 / 300: loss 0.593068\n",
      "iteration 71 / 300: loss 0.621974\n",
      "iteration 71 / 300: loss 0.593431\n",
      "iteration 71 / 300: loss 0.600915\n",
      "iteration 71 / 300: loss 0.571310\n",
      "iteration 71 / 300: loss 0.593297\n",
      "iteration 71 / 300: loss 0.600456\n",
      "iteration 71 / 300: loss 0.598386\n",
      "iteration 71 / 300: loss 0.584004\n",
      "iteration 71 / 300: loss 0.614723\n",
      "iteration 71 / 300: loss 0.591661\n",
      "iteration 71 / 300: loss 0.591723\n",
      "iteration 71 / 300: loss 0.594324\n",
      "iteration 71 / 300: loss 0.597241\n",
      "iteration 71 / 300: loss 0.597099\n",
      "iteration 71 / 300: loss 0.612118\n",
      "iteration 71 / 300: loss 0.607773\n",
      "iteration 71 / 300: loss 0.597468\n",
      "iteration 71 / 300: loss 0.596636\n",
      "iteration 71 / 300: loss 0.627735\n",
      "iteration 71 / 300: loss 0.601992\n",
      "iteration 71 / 300: loss 0.600254\n",
      "iteration 71 / 300: loss 0.622277\n",
      "iteration 71 / 300: loss 0.581907\n",
      "iteration 71 / 300: loss 0.600015\n",
      "iteration 71 / 300: loss 0.591675\n",
      "iteration 71 / 300: loss 0.600316\n",
      "iteration 71 / 300: loss 0.596412\n",
      "iteration 71 / 300: loss 0.591160\n",
      "iteration 71 / 300: loss 0.592396\n",
      "iteration 71 / 300: loss 0.615904\n",
      "iteration 71 / 300: loss 0.621725\n",
      "iteration 71 / 300: loss 0.587649\n",
      "iteration 71 / 300: loss 0.582886\n",
      "iteration 71 / 300: loss 0.585959\n",
      "iteration 71 / 300: loss 0.604130\n",
      "iteration 71 / 300: loss 0.585635\n",
      "iteration 71 / 300: loss 0.579279\n",
      "iteration 71 / 300: loss 0.576772\n",
      "iteration 71 / 300: loss 0.574446\n",
      "iteration 71 / 300: loss 0.600797\n",
      "iteration 71 / 300: loss 0.584835\n",
      "iteration 71 / 300: loss 0.585164\n",
      "iteration 71 / 300: loss 0.568668\n",
      "iteration 71 / 300: loss 0.592410\n",
      "iteration 71 / 300: loss 0.612513\n",
      "iteration 71 / 300: loss 0.609272\n",
      "iteration 71 / 300: loss 0.608009\n",
      "iteration 71 / 300: loss 0.595877\n",
      "iteration 71 / 300: loss 0.593203\n",
      "iteration 71 / 300: loss 0.598385\n",
      "iteration 71 / 300: loss 0.598077\n",
      "iteration 71 / 300: loss 0.601321\n",
      "iteration 71 / 300: loss 0.597838\n",
      "iteration 71 / 300: loss 0.599077\n",
      "iteration 71 / 300: loss 0.588197\n",
      "iteration 71 / 300: loss 0.600881\n",
      "iteration 71 / 300: loss 0.600024\n",
      "iteration 71 / 300: loss 0.617925\n",
      "iteration 71 / 300: loss 0.599212\n",
      "iteration 71 / 300: loss 0.601114\n",
      "iteration 71 / 300: loss 0.605714\n",
      "iteration 71 / 300: loss 0.598989\n",
      "iteration 71 / 300: loss 0.591840\n",
      "iteration 71 / 300: loss 0.580725\n",
      "iteration 71 / 300: loss 0.598612\n",
      "iteration 71 / 300: loss 0.612059\n",
      "iteration 71 / 300: loss 0.613570\n",
      "iteration 71 / 300: loss 0.582519\n",
      "iteration 71 / 300: loss 0.602437\n",
      "iteration 71 / 300: loss 0.609374\n",
      "iteration 71 / 300: loss 0.602186\n",
      "iteration 71 / 300: loss 0.608406\n",
      "iteration 71 / 300: loss 0.620726\n",
      "iteration 71 / 300: loss 0.585216\n",
      "iteration 71 / 300: loss 0.584007\n",
      "iteration 71 / 300: loss 0.629235\n",
      "iteration 71 / 300: loss 0.609711\n",
      "iteration 71 / 300: loss 0.606662\n",
      "iteration 71 / 300: loss 0.599395\n",
      "iteration 71 / 300: loss 0.616300\n",
      "iteration 71 / 300: loss 0.596859\n",
      "iteration 71 / 300: loss 0.581839\n",
      "iteration 71 / 300: loss 0.610144\n",
      "iteration 71 / 300: loss 0.608457\n",
      "iteration 71 / 300: loss 0.598614\n",
      "iteration 71 / 300: loss 0.592408\n",
      "iteration 71 / 300: loss 0.611445\n",
      "iteration 71 / 300: loss 0.598918\n",
      "iteration 71 / 300: loss 0.581688\n",
      "iteration 71 / 300: loss 0.609958\n",
      "iteration 72 / 300: loss 0.578793\n",
      "iteration 72 / 300: loss 0.596588\n",
      "iteration 72 / 300: loss 0.569803\n",
      "iteration 72 / 300: loss 0.598232\n",
      "iteration 72 / 300: loss 0.599303\n",
      "iteration 72 / 300: loss 0.604241\n",
      "iteration 72 / 300: loss 0.615520\n",
      "iteration 72 / 300: loss 0.588578\n",
      "iteration 72 / 300: loss 0.627471\n",
      "iteration 72 / 300: loss 0.593024\n",
      "iteration 72 / 300: loss 0.621930\n",
      "iteration 72 / 300: loss 0.593400\n",
      "iteration 72 / 300: loss 0.600880\n",
      "iteration 72 / 300: loss 0.571281\n",
      "iteration 72 / 300: loss 0.593261\n",
      "iteration 72 / 300: loss 0.600417\n",
      "iteration 72 / 300: loss 0.598355\n",
      "iteration 72 / 300: loss 0.583977\n",
      "iteration 72 / 300: loss 0.614687\n",
      "iteration 72 / 300: loss 0.591626\n",
      "iteration 72 / 300: loss 0.591691\n",
      "iteration 72 / 300: loss 0.594294\n",
      "iteration 72 / 300: loss 0.597192\n",
      "iteration 72 / 300: loss 0.597063\n",
      "iteration 72 / 300: loss 0.612082\n",
      "iteration 72 / 300: loss 0.607724\n",
      "iteration 72 / 300: loss 0.597426\n",
      "iteration 72 / 300: loss 0.596604\n",
      "iteration 72 / 300: loss 0.627703\n",
      "iteration 72 / 300: loss 0.601954\n",
      "iteration 72 / 300: loss 0.600223\n",
      "iteration 72 / 300: loss 0.622247\n",
      "iteration 72 / 300: loss 0.581863\n",
      "iteration 72 / 300: loss 0.599976\n",
      "iteration 72 / 300: loss 0.591628\n",
      "iteration 72 / 300: loss 0.600279\n",
      "iteration 72 / 300: loss 0.596375\n",
      "iteration 72 / 300: loss 0.591122\n",
      "iteration 72 / 300: loss 0.592355\n",
      "iteration 72 / 300: loss 0.615863\n",
      "iteration 72 / 300: loss 0.621691\n",
      "iteration 72 / 300: loss 0.587613\n",
      "iteration 72 / 300: loss 0.582849\n",
      "iteration 72 / 300: loss 0.585923\n",
      "iteration 72 / 300: loss 0.604087\n",
      "iteration 72 / 300: loss 0.585594\n",
      "iteration 72 / 300: loss 0.579241\n",
      "iteration 72 / 300: loss 0.576739\n",
      "iteration 72 / 300: loss 0.574414\n",
      "iteration 72 / 300: loss 0.600770\n",
      "iteration 72 / 300: loss 0.584803\n",
      "iteration 72 / 300: loss 0.585133\n",
      "iteration 72 / 300: loss 0.568635\n",
      "iteration 72 / 300: loss 0.592373\n",
      "iteration 72 / 300: loss 0.612476\n",
      "iteration 72 / 300: loss 0.609240\n",
      "iteration 72 / 300: loss 0.607972\n",
      "iteration 72 / 300: loss 0.595845\n",
      "iteration 72 / 300: loss 0.593169\n",
      "iteration 72 / 300: loss 0.598348\n",
      "iteration 72 / 300: loss 0.598040\n",
      "iteration 72 / 300: loss 0.601286\n",
      "iteration 72 / 300: loss 0.597799\n",
      "iteration 72 / 300: loss 0.599049\n",
      "iteration 72 / 300: loss 0.588161\n",
      "iteration 72 / 300: loss 0.600845\n",
      "iteration 72 / 300: loss 0.599989\n",
      "iteration 72 / 300: loss 0.617890\n",
      "iteration 72 / 300: loss 0.599180\n",
      "iteration 72 / 300: loss 0.601084\n",
      "iteration 72 / 300: loss 0.605676\n",
      "iteration 72 / 300: loss 0.598951\n",
      "iteration 72 / 300: loss 0.591805\n",
      "iteration 72 / 300: loss 0.580693\n",
      "iteration 72 / 300: loss 0.598575\n",
      "iteration 72 / 300: loss 0.612024\n",
      "iteration 72 / 300: loss 0.613537\n",
      "iteration 72 / 300: loss 0.582491\n",
      "iteration 72 / 300: loss 0.602391\n",
      "iteration 72 / 300: loss 0.609335\n",
      "iteration 72 / 300: loss 0.602149\n",
      "iteration 72 / 300: loss 0.608363\n",
      "iteration 72 / 300: loss 0.620680\n",
      "iteration 72 / 300: loss 0.585179\n",
      "iteration 72 / 300: loss 0.583981\n",
      "iteration 72 / 300: loss 0.629198\n",
      "iteration 72 / 300: loss 0.609682\n",
      "iteration 72 / 300: loss 0.606625\n",
      "iteration 72 / 300: loss 0.599361\n",
      "iteration 72 / 300: loss 0.616260\n",
      "iteration 72 / 300: loss 0.596825\n",
      "iteration 72 / 300: loss 0.581800\n",
      "iteration 72 / 300: loss 0.610112\n",
      "iteration 72 / 300: loss 0.608425\n",
      "iteration 72 / 300: loss 0.598577\n",
      "iteration 72 / 300: loss 0.592372\n",
      "iteration 72 / 300: loss 0.611406\n",
      "iteration 72 / 300: loss 0.598883\n",
      "iteration 72 / 300: loss 0.581660\n",
      "iteration 72 / 300: loss 0.609923\n",
      "iteration 73 / 300: loss 0.578755\n",
      "iteration 73 / 300: loss 0.596553\n",
      "iteration 73 / 300: loss 0.569770\n",
      "iteration 73 / 300: loss 0.598196\n",
      "iteration 73 / 300: loss 0.599269\n",
      "iteration 73 / 300: loss 0.604207\n",
      "iteration 73 / 300: loss 0.615496\n",
      "iteration 73 / 300: loss 0.588545\n",
      "iteration 73 / 300: loss 0.627444\n",
      "iteration 73 / 300: loss 0.592984\n",
      "iteration 73 / 300: loss 0.621889\n",
      "iteration 73 / 300: loss 0.593371\n",
      "iteration 73 / 300: loss 0.600848\n",
      "iteration 73 / 300: loss 0.571255\n",
      "iteration 73 / 300: loss 0.593229\n",
      "iteration 73 / 300: loss 0.600382\n",
      "iteration 73 / 300: loss 0.598326\n",
      "iteration 73 / 300: loss 0.583953\n",
      "iteration 73 / 300: loss 0.614656\n",
      "iteration 73 / 300: loss 0.591594\n",
      "iteration 73 / 300: loss 0.591663\n",
      "iteration 73 / 300: loss 0.594268\n",
      "iteration 73 / 300: loss 0.597148\n",
      "iteration 73 / 300: loss 0.597029\n",
      "iteration 73 / 300: loss 0.612050\n",
      "iteration 73 / 300: loss 0.607679\n",
      "iteration 73 / 300: loss 0.597389\n",
      "iteration 73 / 300: loss 0.596576\n",
      "iteration 73 / 300: loss 0.627674\n",
      "iteration 73 / 300: loss 0.601920\n",
      "iteration 73 / 300: loss 0.600195\n",
      "iteration 73 / 300: loss 0.622219\n",
      "iteration 73 / 300: loss 0.581822\n",
      "iteration 73 / 300: loss 0.599942\n",
      "iteration 73 / 300: loss 0.591586\n",
      "iteration 73 / 300: loss 0.600245\n",
      "iteration 73 / 300: loss 0.596340\n",
      "iteration 73 / 300: loss 0.591087\n",
      "iteration 73 / 300: loss 0.592318\n",
      "iteration 73 / 300: loss 0.615825\n",
      "iteration 73 / 300: loss 0.621660\n",
      "iteration 73 / 300: loss 0.587580\n",
      "iteration 73 / 300: loss 0.582814\n",
      "iteration 73 / 300: loss 0.585890\n",
      "iteration 73 / 300: loss 0.604047\n",
      "iteration 73 / 300: loss 0.585557\n",
      "iteration 73 / 300: loss 0.579207\n",
      "iteration 73 / 300: loss 0.576709\n",
      "iteration 73 / 300: loss 0.574384\n",
      "iteration 73 / 300: loss 0.600745\n",
      "iteration 73 / 300: loss 0.584774\n",
      "iteration 73 / 300: loss 0.585106\n",
      "iteration 73 / 300: loss 0.568606\n",
      "iteration 73 / 300: loss 0.592340\n",
      "iteration 73 / 300: loss 0.612442\n",
      "iteration 73 / 300: loss 0.609210\n",
      "iteration 73 / 300: loss 0.607938\n",
      "iteration 73 / 300: loss 0.595816\n",
      "iteration 73 / 300: loss 0.593137\n",
      "iteration 73 / 300: loss 0.598315\n",
      "iteration 73 / 300: loss 0.598006\n",
      "iteration 73 / 300: loss 0.601255\n",
      "iteration 73 / 300: loss 0.597763\n",
      "iteration 73 / 300: loss 0.599023\n",
      "iteration 73 / 300: loss 0.588127\n",
      "iteration 73 / 300: loss 0.600812\n",
      "iteration 73 / 300: loss 0.599957\n",
      "iteration 73 / 300: loss 0.617857\n",
      "iteration 73 / 300: loss 0.599151\n",
      "iteration 73 / 300: loss 0.601058\n",
      "iteration 73 / 300: loss 0.605641\n",
      "iteration 73 / 300: loss 0.598917\n",
      "iteration 73 / 300: loss 0.591774\n",
      "iteration 73 / 300: loss 0.580664\n",
      "iteration 73 / 300: loss 0.598542\n",
      "iteration 73 / 300: loss 0.611991\n",
      "iteration 73 / 300: loss 0.613507\n",
      "iteration 73 / 300: loss 0.582464\n",
      "iteration 73 / 300: loss 0.602350\n",
      "iteration 73 / 300: loss 0.609300\n",
      "iteration 73 / 300: loss 0.602116\n",
      "iteration 73 / 300: loss 0.608323\n",
      "iteration 73 / 300: loss 0.620638\n",
      "iteration 73 / 300: loss 0.585145\n",
      "iteration 73 / 300: loss 0.583956\n",
      "iteration 73 / 300: loss 0.629165\n",
      "iteration 73 / 300: loss 0.609655\n",
      "iteration 73 / 300: loss 0.606591\n",
      "iteration 73 / 300: loss 0.599331\n",
      "iteration 73 / 300: loss 0.616224\n",
      "iteration 73 / 300: loss 0.596793\n",
      "iteration 73 / 300: loss 0.581765\n",
      "iteration 73 / 300: loss 0.610083\n",
      "iteration 73 / 300: loss 0.608397\n",
      "iteration 73 / 300: loss 0.598544\n",
      "iteration 73 / 300: loss 0.592340\n",
      "iteration 73 / 300: loss 0.611371\n",
      "iteration 73 / 300: loss 0.598852\n",
      "iteration 73 / 300: loss 0.581634\n",
      "iteration 73 / 300: loss 0.609891\n",
      "iteration 74 / 300: loss 0.578720\n",
      "iteration 74 / 300: loss 0.596521\n",
      "iteration 74 / 300: loss 0.569741\n",
      "iteration 74 / 300: loss 0.598163\n",
      "iteration 74 / 300: loss 0.599237\n",
      "iteration 74 / 300: loss 0.604176\n",
      "iteration 74 / 300: loss 0.615474\n",
      "iteration 74 / 300: loss 0.588515\n",
      "iteration 74 / 300: loss 0.627419\n",
      "iteration 74 / 300: loss 0.592948\n",
      "iteration 74 / 300: loss 0.621853\n",
      "iteration 74 / 300: loss 0.593345\n",
      "iteration 74 / 300: loss 0.600819\n",
      "iteration 74 / 300: loss 0.571231\n",
      "iteration 74 / 300: loss 0.593199\n",
      "iteration 74 / 300: loss 0.600350\n",
      "iteration 74 / 300: loss 0.598301\n",
      "iteration 74 / 300: loss 0.583930\n",
      "iteration 74 / 300: loss 0.614627\n",
      "iteration 74 / 300: loss 0.591565\n",
      "iteration 74 / 300: loss 0.591637\n",
      "iteration 74 / 300: loss 0.594243\n",
      "iteration 74 / 300: loss 0.597108\n",
      "iteration 74 / 300: loss 0.596999\n",
      "iteration 74 / 300: loss 0.612020\n",
      "iteration 74 / 300: loss 0.607639\n",
      "iteration 74 / 300: loss 0.597355\n",
      "iteration 74 / 300: loss 0.596550\n",
      "iteration 74 / 300: loss 0.627648\n",
      "iteration 74 / 300: loss 0.601888\n",
      "iteration 74 / 300: loss 0.600169\n",
      "iteration 74 / 300: loss 0.622194\n",
      "iteration 74 / 300: loss 0.581786\n",
      "iteration 74 / 300: loss 0.599910\n",
      "iteration 74 / 300: loss 0.591548\n",
      "iteration 74 / 300: loss 0.600214\n",
      "iteration 74 / 300: loss 0.596309\n",
      "iteration 74 / 300: loss 0.591056\n",
      "iteration 74 / 300: loss 0.592284\n",
      "iteration 74 / 300: loss 0.615792\n",
      "iteration 74 / 300: loss 0.621632\n",
      "iteration 74 / 300: loss 0.587550\n",
      "iteration 74 / 300: loss 0.582783\n",
      "iteration 74 / 300: loss 0.585860\n",
      "iteration 74 / 300: loss 0.604011\n",
      "iteration 74 / 300: loss 0.585522\n",
      "iteration 74 / 300: loss 0.579176\n",
      "iteration 74 / 300: loss 0.576682\n",
      "iteration 74 / 300: loss 0.574357\n",
      "iteration 74 / 300: loss 0.600722\n",
      "iteration 74 / 300: loss 0.584748\n",
      "iteration 74 / 300: loss 0.585080\n",
      "iteration 74 / 300: loss 0.568579\n",
      "iteration 74 / 300: loss 0.592311\n",
      "iteration 74 / 300: loss 0.612412\n",
      "iteration 74 / 300: loss 0.609183\n",
      "iteration 74 / 300: loss 0.607907\n",
      "iteration 74 / 300: loss 0.595790\n",
      "iteration 74 / 300: loss 0.593109\n",
      "iteration 74 / 300: loss 0.598284\n",
      "iteration 74 / 300: loss 0.597975\n",
      "iteration 74 / 300: loss 0.601227\n",
      "iteration 74 / 300: loss 0.597731\n",
      "iteration 74 / 300: loss 0.599000\n",
      "iteration 74 / 300: loss 0.588097\n",
      "iteration 74 / 300: loss 0.600783\n",
      "iteration 74 / 300: loss 0.599928\n",
      "iteration 74 / 300: loss 0.617828\n",
      "iteration 74 / 300: loss 0.599125\n",
      "iteration 74 / 300: loss 0.601033\n",
      "iteration 74 / 300: loss 0.605609\n",
      "iteration 74 / 300: loss 0.598886\n",
      "iteration 74 / 300: loss 0.591745\n",
      "iteration 74 / 300: loss 0.580637\n",
      "iteration 74 / 300: loss 0.598512\n",
      "iteration 74 / 300: loss 0.611962\n",
      "iteration 74 / 300: loss 0.613480\n",
      "iteration 74 / 300: loss 0.582441\n",
      "iteration 74 / 300: loss 0.602313\n",
      "iteration 74 / 300: loss 0.609268\n",
      "iteration 74 / 300: loss 0.602085\n",
      "iteration 74 / 300: loss 0.608288\n",
      "iteration 74 / 300: loss 0.620600\n",
      "iteration 74 / 300: loss 0.585114\n",
      "iteration 74 / 300: loss 0.583934\n",
      "iteration 74 / 300: loss 0.629134\n",
      "iteration 74 / 300: loss 0.609631\n",
      "iteration 74 / 300: loss 0.606561\n",
      "iteration 74 / 300: loss 0.599303\n",
      "iteration 74 / 300: loss 0.616191\n",
      "iteration 74 / 300: loss 0.596765\n",
      "iteration 74 / 300: loss 0.581734\n",
      "iteration 74 / 300: loss 0.610057\n",
      "iteration 74 / 300: loss 0.608371\n",
      "iteration 74 / 300: loss 0.598514\n",
      "iteration 74 / 300: loss 0.592310\n",
      "iteration 74 / 300: loss 0.611339\n",
      "iteration 74 / 300: loss 0.598823\n",
      "iteration 74 / 300: loss 0.581611\n",
      "iteration 74 / 300: loss 0.609862\n",
      "iteration 75 / 300: loss 0.578688\n",
      "iteration 75 / 300: loss 0.596492\n",
      "iteration 75 / 300: loss 0.569714\n",
      "iteration 75 / 300: loss 0.598134\n",
      "iteration 75 / 300: loss 0.599209\n",
      "iteration 75 / 300: loss 0.604148\n",
      "iteration 75 / 300: loss 0.615454\n",
      "iteration 75 / 300: loss 0.588488\n",
      "iteration 75 / 300: loss 0.627396\n",
      "iteration 75 / 300: loss 0.592916\n",
      "iteration 75 / 300: loss 0.621819\n",
      "iteration 75 / 300: loss 0.593322\n",
      "iteration 75 / 300: loss 0.600793\n",
      "iteration 75 / 300: loss 0.571209\n",
      "iteration 75 / 300: loss 0.593172\n",
      "iteration 75 / 300: loss 0.600321\n",
      "iteration 75 / 300: loss 0.598277\n",
      "iteration 75 / 300: loss 0.583910\n",
      "iteration 75 / 300: loss 0.614601\n",
      "iteration 75 / 300: loss 0.591539\n",
      "iteration 75 / 300: loss 0.591614\n",
      "iteration 75 / 300: loss 0.594221\n",
      "iteration 75 / 300: loss 0.597072\n",
      "iteration 75 / 300: loss 0.596972\n",
      "iteration 75 / 300: loss 0.611993\n",
      "iteration 75 / 300: loss 0.607603\n",
      "iteration 75 / 300: loss 0.597325\n",
      "iteration 75 / 300: loss 0.596527\n",
      "iteration 75 / 300: loss 0.627624\n",
      "iteration 75 / 300: loss 0.601860\n",
      "iteration 75 / 300: loss 0.600146\n",
      "iteration 75 / 300: loss 0.622171\n",
      "iteration 75 / 300: loss 0.581753\n",
      "iteration 75 / 300: loss 0.599881\n",
      "iteration 75 / 300: loss 0.591513\n",
      "iteration 75 / 300: loss 0.600186\n",
      "iteration 75 / 300: loss 0.596281\n",
      "iteration 75 / 300: loss 0.591028\n",
      "iteration 75 / 300: loss 0.592254\n",
      "iteration 75 / 300: loss 0.615761\n",
      "iteration 75 / 300: loss 0.621606\n",
      "iteration 75 / 300: loss 0.587523\n",
      "iteration 75 / 300: loss 0.582755\n",
      "iteration 75 / 300: loss 0.585833\n",
      "iteration 75 / 300: loss 0.603979\n",
      "iteration 75 / 300: loss 0.585492\n",
      "iteration 75 / 300: loss 0.579148\n",
      "iteration 75 / 300: loss 0.576657\n",
      "iteration 75 / 300: loss 0.574333\n",
      "iteration 75 / 300: loss 0.600701\n",
      "iteration 75 / 300: loss 0.584724\n",
      "iteration 75 / 300: loss 0.585058\n",
      "iteration 75 / 300: loss 0.568555\n",
      "iteration 75 / 300: loss 0.592283\n",
      "iteration 75 / 300: loss 0.612384\n",
      "iteration 75 / 300: loss 0.609158\n",
      "iteration 75 / 300: loss 0.607879\n",
      "iteration 75 / 300: loss 0.595766\n",
      "iteration 75 / 300: loss 0.593083\n",
      "iteration 75 / 300: loss 0.598256\n",
      "iteration 75 / 300: loss 0.597947\n",
      "iteration 75 / 300: loss 0.601201\n",
      "iteration 75 / 300: loss 0.597702\n",
      "iteration 75 / 300: loss 0.598979\n",
      "iteration 75 / 300: loss 0.588070\n",
      "iteration 75 / 300: loss 0.600756\n",
      "iteration 75 / 300: loss 0.599902\n",
      "iteration 75 / 300: loss 0.617801\n",
      "iteration 75 / 300: loss 0.599101\n",
      "iteration 75 / 300: loss 0.601011\n",
      "iteration 75 / 300: loss 0.605580\n",
      "iteration 75 / 300: loss 0.598858\n",
      "iteration 75 / 300: loss 0.591720\n",
      "iteration 75 / 300: loss 0.580613\n",
      "iteration 75 / 300: loss 0.598485\n",
      "iteration 75 / 300: loss 0.611936\n",
      "iteration 75 / 300: loss 0.613455\n",
      "iteration 75 / 300: loss 0.582419\n",
      "iteration 75 / 300: loss 0.602279\n",
      "iteration 75 / 300: loss 0.609238\n",
      "iteration 75 / 300: loss 0.602058\n",
      "iteration 75 / 300: loss 0.608255\n",
      "iteration 75 / 300: loss 0.620565\n",
      "iteration 75 / 300: loss 0.585086\n",
      "iteration 75 / 300: loss 0.583914\n",
      "iteration 75 / 300: loss 0.629107\n",
      "iteration 75 / 300: loss 0.609609\n",
      "iteration 75 / 300: loss 0.606533\n",
      "iteration 75 / 300: loss 0.599278\n",
      "iteration 75 / 300: loss 0.616161\n",
      "iteration 75 / 300: loss 0.596739\n",
      "iteration 75 / 300: loss 0.581705\n",
      "iteration 75 / 300: loss 0.610034\n",
      "iteration 75 / 300: loss 0.608348\n",
      "iteration 75 / 300: loss 0.598486\n",
      "iteration 75 / 300: loss 0.592283\n",
      "iteration 75 / 300: loss 0.611310\n",
      "iteration 75 / 300: loss 0.598797\n",
      "iteration 75 / 300: loss 0.581589\n",
      "iteration 75 / 300: loss 0.609835\n",
      "iteration 76 / 300: loss 0.578660\n",
      "iteration 76 / 300: loss 0.596466\n",
      "iteration 76 / 300: loss 0.569690\n",
      "iteration 76 / 300: loss 0.598107\n",
      "iteration 76 / 300: loss 0.599183\n",
      "iteration 76 / 300: loss 0.604123\n",
      "iteration 76 / 300: loss 0.615436\n",
      "iteration 76 / 300: loss 0.588463\n",
      "iteration 76 / 300: loss 0.627375\n",
      "iteration 76 / 300: loss 0.592886\n",
      "iteration 76 / 300: loss 0.621789\n",
      "iteration 76 / 300: loss 0.593300\n",
      "iteration 76 / 300: loss 0.600770\n",
      "iteration 76 / 300: loss 0.571190\n",
      "iteration 76 / 300: loss 0.593147\n",
      "iteration 76 / 300: loss 0.600294\n",
      "iteration 76 / 300: loss 0.598256\n",
      "iteration 76 / 300: loss 0.583891\n",
      "iteration 76 / 300: loss 0.614577\n",
      "iteration 76 / 300: loss 0.591515\n",
      "iteration 76 / 300: loss 0.591593\n",
      "iteration 76 / 300: loss 0.594201\n",
      "iteration 76 / 300: loss 0.597040\n",
      "iteration 76 / 300: loss 0.596947\n",
      "iteration 76 / 300: loss 0.611969\n",
      "iteration 76 / 300: loss 0.607570\n",
      "iteration 76 / 300: loss 0.597297\n",
      "iteration 76 / 300: loss 0.596506\n",
      "iteration 76 / 300: loss 0.627602\n",
      "iteration 76 / 300: loss 0.601834\n",
      "iteration 76 / 300: loss 0.600125\n",
      "iteration 76 / 300: loss 0.622150\n",
      "iteration 76 / 300: loss 0.581723\n",
      "iteration 76 / 300: loss 0.599855\n",
      "iteration 76 / 300: loss 0.591481\n",
      "iteration 76 / 300: loss 0.600161\n",
      "iteration 76 / 300: loss 0.596256\n",
      "iteration 76 / 300: loss 0.591002\n",
      "iteration 76 / 300: loss 0.592226\n",
      "iteration 76 / 300: loss 0.615733\n",
      "iteration 76 / 300: loss 0.621583\n",
      "iteration 76 / 300: loss 0.587498\n",
      "iteration 76 / 300: loss 0.582729\n",
      "iteration 76 / 300: loss 0.585808\n",
      "iteration 76 / 300: loss 0.603950\n",
      "iteration 76 / 300: loss 0.585463\n",
      "iteration 76 / 300: loss 0.579122\n",
      "iteration 76 / 300: loss 0.576635\n",
      "iteration 76 / 300: loss 0.574311\n",
      "iteration 76 / 300: loss 0.600682\n",
      "iteration 76 / 300: loss 0.584702\n",
      "iteration 76 / 300: loss 0.585037\n",
      "iteration 76 / 300: loss 0.568533\n",
      "iteration 76 / 300: loss 0.592259\n",
      "iteration 76 / 300: loss 0.612358\n",
      "iteration 76 / 300: loss 0.609136\n",
      "iteration 76 / 300: loss 0.607854\n",
      "iteration 76 / 300: loss 0.595744\n",
      "iteration 76 / 300: loss 0.593060\n",
      "iteration 76 / 300: loss 0.598231\n",
      "iteration 76 / 300: loss 0.597922\n",
      "iteration 76 / 300: loss 0.601177\n",
      "iteration 76 / 300: loss 0.597676\n",
      "iteration 76 / 300: loss 0.598960\n",
      "iteration 76 / 300: loss 0.588045\n",
      "iteration 76 / 300: loss 0.600731\n",
      "iteration 76 / 300: loss 0.599878\n",
      "iteration 76 / 300: loss 0.617777\n",
      "iteration 76 / 300: loss 0.599080\n",
      "iteration 76 / 300: loss 0.600991\n",
      "iteration 76 / 300: loss 0.605554\n",
      "iteration 76 / 300: loss 0.598833\n",
      "iteration 76 / 300: loss 0.591696\n",
      "iteration 76 / 300: loss 0.580592\n",
      "iteration 76 / 300: loss 0.598460\n",
      "iteration 76 / 300: loss 0.611912\n",
      "iteration 76 / 300: loss 0.613433\n",
      "iteration 76 / 300: loss 0.582400\n",
      "iteration 76 / 300: loss 0.602248\n",
      "iteration 76 / 300: loss 0.609212\n",
      "iteration 76 / 300: loss 0.602033\n",
      "iteration 76 / 300: loss 0.608226\n",
      "iteration 76 / 300: loss 0.620534\n",
      "iteration 76 / 300: loss 0.585061\n",
      "iteration 76 / 300: loss 0.583896\n",
      "iteration 76 / 300: loss 0.629082\n",
      "iteration 76 / 300: loss 0.609589\n",
      "iteration 76 / 300: loss 0.606508\n",
      "iteration 76 / 300: loss 0.599255\n",
      "iteration 76 / 300: loss 0.616135\n",
      "iteration 76 / 300: loss 0.596716\n",
      "iteration 76 / 300: loss 0.581679\n",
      "iteration 76 / 300: loss 0.610012\n",
      "iteration 76 / 300: loss 0.608327\n",
      "iteration 76 / 300: loss 0.598461\n",
      "iteration 76 / 300: loss 0.592258\n",
      "iteration 76 / 300: loss 0.611283\n",
      "iteration 76 / 300: loss 0.598774\n",
      "iteration 76 / 300: loss 0.581570\n",
      "iteration 76 / 300: loss 0.609811\n",
      "iteration 77 / 300: loss 0.578634\n",
      "iteration 77 / 300: loss 0.596442\n",
      "iteration 77 / 300: loss 0.569668\n",
      "iteration 77 / 300: loss 0.598083\n",
      "iteration 77 / 300: loss 0.599160\n",
      "iteration 77 / 300: loss 0.604099\n",
      "iteration 77 / 300: loss 0.615419\n",
      "iteration 77 / 300: loss 0.588441\n",
      "iteration 77 / 300: loss 0.627356\n",
      "iteration 77 / 300: loss 0.592859\n",
      "iteration 77 / 300: loss 0.621762\n",
      "iteration 77 / 300: loss 0.593281\n",
      "iteration 77 / 300: loss 0.600748\n",
      "iteration 77 / 300: loss 0.571172\n",
      "iteration 77 / 300: loss 0.593125\n",
      "iteration 77 / 300: loss 0.600270\n",
      "iteration 77 / 300: loss 0.598237\n",
      "iteration 77 / 300: loss 0.583875\n",
      "iteration 77 / 300: loss 0.614556\n",
      "iteration 77 / 300: loss 0.591493\n",
      "iteration 77 / 300: loss 0.591574\n",
      "iteration 77 / 300: loss 0.594182\n",
      "iteration 77 / 300: loss 0.597010\n",
      "iteration 77 / 300: loss 0.596925\n",
      "iteration 77 / 300: loss 0.611947\n",
      "iteration 77 / 300: loss 0.607540\n",
      "iteration 77 / 300: loss 0.597272\n",
      "iteration 77 / 300: loss 0.596486\n",
      "iteration 77 / 300: loss 0.627582\n",
      "iteration 77 / 300: loss 0.601810\n",
      "iteration 77 / 300: loss 0.600106\n",
      "iteration 77 / 300: loss 0.622132\n",
      "iteration 77 / 300: loss 0.581695\n",
      "iteration 77 / 300: loss 0.599832\n",
      "iteration 77 / 300: loss 0.591453\n",
      "iteration 77 / 300: loss 0.600138\n",
      "iteration 77 / 300: loss 0.596233\n",
      "iteration 77 / 300: loss 0.590979\n",
      "iteration 77 / 300: loss 0.592201\n",
      "iteration 77 / 300: loss 0.615708\n",
      "iteration 77 / 300: loss 0.621562\n",
      "iteration 77 / 300: loss 0.587476\n",
      "iteration 77 / 300: loss 0.582706\n",
      "iteration 77 / 300: loss 0.585786\n",
      "iteration 77 / 300: loss 0.603923\n",
      "iteration 77 / 300: loss 0.585438\n",
      "iteration 77 / 300: loss 0.579099\n",
      "iteration 77 / 300: loss 0.576614\n",
      "iteration 77 / 300: loss 0.574291\n",
      "iteration 77 / 300: loss 0.600665\n",
      "iteration 77 / 300: loss 0.584682\n",
      "iteration 77 / 300: loss 0.585018\n",
      "iteration 77 / 300: loss 0.568513\n",
      "iteration 77 / 300: loss 0.592237\n",
      "iteration 77 / 300: loss 0.612336\n",
      "iteration 77 / 300: loss 0.609116\n",
      "iteration 77 / 300: loss 0.607831\n",
      "iteration 77 / 300: loss 0.595725\n",
      "iteration 77 / 300: loss 0.593039\n",
      "iteration 77 / 300: loss 0.598208\n",
      "iteration 77 / 300: loss 0.597899\n",
      "iteration 77 / 300: loss 0.601156\n",
      "iteration 77 / 300: loss 0.597652\n",
      "iteration 77 / 300: loss 0.598943\n",
      "iteration 77 / 300: loss 0.588022\n",
      "iteration 77 / 300: loss 0.600709\n",
      "iteration 77 / 300: loss 0.599856\n",
      "iteration 77 / 300: loss 0.617755\n",
      "iteration 77 / 300: loss 0.599061\n",
      "iteration 77 / 300: loss 0.600973\n",
      "iteration 77 / 300: loss 0.605531\n",
      "iteration 77 / 300: loss 0.598810\n",
      "iteration 77 / 300: loss 0.591675\n",
      "iteration 77 / 300: loss 0.580572\n",
      "iteration 77 / 300: loss 0.598438\n",
      "iteration 77 / 300: loss 0.611890\n",
      "iteration 77 / 300: loss 0.613413\n",
      "iteration 77 / 300: loss 0.582382\n",
      "iteration 77 / 300: loss 0.602220\n",
      "iteration 77 / 300: loss 0.609188\n",
      "iteration 77 / 300: loss 0.602010\n",
      "iteration 77 / 300: loss 0.608200\n",
      "iteration 77 / 300: loss 0.620506\n",
      "iteration 77 / 300: loss 0.585038\n",
      "iteration 77 / 300: loss 0.583880\n",
      "iteration 77 / 300: loss 0.629060\n",
      "iteration 77 / 300: loss 0.609571\n",
      "iteration 77 / 300: loss 0.606485\n",
      "iteration 77 / 300: loss 0.599234\n",
      "iteration 77 / 300: loss 0.616110\n",
      "iteration 77 / 300: loss 0.596694\n",
      "iteration 77 / 300: loss 0.581656\n",
      "iteration 77 / 300: loss 0.609993\n",
      "iteration 77 / 300: loss 0.608308\n",
      "iteration 77 / 300: loss 0.598439\n",
      "iteration 77 / 300: loss 0.592236\n",
      "iteration 77 / 300: loss 0.611259\n",
      "iteration 77 / 300: loss 0.598753\n",
      "iteration 77 / 300: loss 0.581553\n",
      "iteration 77 / 300: loss 0.609790\n",
      "iteration 78 / 300: loss 0.578610\n",
      "iteration 78 / 300: loss 0.596420\n",
      "iteration 78 / 300: loss 0.569648\n",
      "iteration 78 / 300: loss 0.598061\n",
      "iteration 78 / 300: loss 0.599139\n",
      "iteration 78 / 300: loss 0.604079\n",
      "iteration 78 / 300: loss 0.615404\n",
      "iteration 78 / 300: loss 0.588421\n",
      "iteration 78 / 300: loss 0.627339\n",
      "iteration 78 / 300: loss 0.592834\n",
      "iteration 78 / 300: loss 0.621737\n",
      "iteration 78 / 300: loss 0.593263\n",
      "iteration 78 / 300: loss 0.600729\n",
      "iteration 78 / 300: loss 0.571156\n",
      "iteration 78 / 300: loss 0.593105\n",
      "iteration 78 / 300: loss 0.600249\n",
      "iteration 78 / 300: loss 0.598219\n",
      "iteration 78 / 300: loss 0.583859\n",
      "iteration 78 / 300: loss 0.614537\n",
      "iteration 78 / 300: loss 0.591474\n",
      "iteration 78 / 300: loss 0.591556\n",
      "iteration 78 / 300: loss 0.594166\n",
      "iteration 78 / 300: loss 0.596984\n",
      "iteration 78 / 300: loss 0.596905\n",
      "iteration 78 / 300: loss 0.611927\n",
      "iteration 78 / 300: loss 0.607513\n",
      "iteration 78 / 300: loss 0.597249\n",
      "iteration 78 / 300: loss 0.596469\n",
      "iteration 78 / 300: loss 0.627564\n",
      "iteration 78 / 300: loss 0.601789\n",
      "iteration 78 / 300: loss 0.600089\n",
      "iteration 78 / 300: loss 0.622115\n",
      "iteration 78 / 300: loss 0.581671\n",
      "iteration 78 / 300: loss 0.599810\n",
      "iteration 78 / 300: loss 0.591427\n",
      "iteration 78 / 300: loss 0.600117\n",
      "iteration 78 / 300: loss 0.596212\n",
      "iteration 78 / 300: loss 0.590958\n",
      "iteration 78 / 300: loss 0.592179\n",
      "iteration 78 / 300: loss 0.615685\n",
      "iteration 78 / 300: loss 0.621543\n",
      "iteration 78 / 300: loss 0.587456\n",
      "iteration 78 / 300: loss 0.582685\n",
      "iteration 78 / 300: loss 0.585766\n",
      "iteration 78 / 300: loss 0.603899\n",
      "iteration 78 / 300: loss 0.585415\n",
      "iteration 78 / 300: loss 0.579078\n",
      "iteration 78 / 300: loss 0.576596\n",
      "iteration 78 / 300: loss 0.574273\n",
      "iteration 78 / 300: loss 0.600650\n",
      "iteration 78 / 300: loss 0.584664\n",
      "iteration 78 / 300: loss 0.585001\n",
      "iteration 78 / 300: loss 0.568495\n",
      "iteration 78 / 300: loss 0.592217\n",
      "iteration 78 / 300: loss 0.612315\n",
      "iteration 78 / 300: loss 0.609098\n",
      "iteration 78 / 300: loss 0.607811\n",
      "iteration 78 / 300: loss 0.595707\n",
      "iteration 78 / 300: loss 0.593020\n",
      "iteration 78 / 300: loss 0.598188\n",
      "iteration 78 / 300: loss 0.597878\n",
      "iteration 78 / 300: loss 0.601137\n",
      "iteration 78 / 300: loss 0.597630\n",
      "iteration 78 / 300: loss 0.598927\n",
      "iteration 78 / 300: loss 0.588002\n",
      "iteration 78 / 300: loss 0.600689\n",
      "iteration 78 / 300: loss 0.599837\n",
      "iteration 78 / 300: loss 0.617735\n",
      "iteration 78 / 300: loss 0.599043\n",
      "iteration 78 / 300: loss 0.600957\n",
      "iteration 78 / 300: loss 0.605509\n",
      "iteration 78 / 300: loss 0.598789\n",
      "iteration 78 / 300: loss 0.591656\n",
      "iteration 78 / 300: loss 0.580554\n",
      "iteration 78 / 300: loss 0.598417\n",
      "iteration 78 / 300: loss 0.611871\n",
      "iteration 78 / 300: loss 0.613394\n",
      "iteration 78 / 300: loss 0.582366\n",
      "iteration 78 / 300: loss 0.602195\n",
      "iteration 78 / 300: loss 0.609166\n",
      "iteration 78 / 300: loss 0.601990\n",
      "iteration 78 / 300: loss 0.608175\n",
      "iteration 78 / 300: loss 0.620481\n",
      "iteration 78 / 300: loss 0.585017\n",
      "iteration 78 / 300: loss 0.583865\n",
      "iteration 78 / 300: loss 0.629040\n",
      "iteration 78 / 300: loss 0.609555\n",
      "iteration 78 / 300: loss 0.606465\n",
      "iteration 78 / 300: loss 0.599215\n",
      "iteration 78 / 300: loss 0.616088\n",
      "iteration 78 / 300: loss 0.596675\n",
      "iteration 78 / 300: loss 0.581634\n",
      "iteration 78 / 300: loss 0.609975\n",
      "iteration 78 / 300: loss 0.608290\n",
      "iteration 78 / 300: loss 0.598419\n",
      "iteration 78 / 300: loss 0.592216\n",
      "iteration 78 / 300: loss 0.611238\n",
      "iteration 78 / 300: loss 0.598733\n",
      "iteration 78 / 300: loss 0.581537\n",
      "iteration 78 / 300: loss 0.609770\n",
      "iteration 79 / 300: loss 0.578589\n",
      "iteration 79 / 300: loss 0.596401\n",
      "iteration 79 / 300: loss 0.569629\n",
      "iteration 79 / 300: loss 0.598041\n",
      "iteration 79 / 300: loss 0.599120\n",
      "iteration 79 / 300: loss 0.604060\n",
      "iteration 79 / 300: loss 0.615391\n",
      "iteration 79 / 300: loss 0.588403\n",
      "iteration 79 / 300: loss 0.627323\n",
      "iteration 79 / 300: loss 0.592812\n",
      "iteration 79 / 300: loss 0.621715\n",
      "iteration 79 / 300: loss 0.593247\n",
      "iteration 79 / 300: loss 0.600711\n",
      "iteration 79 / 300: loss 0.571141\n",
      "iteration 79 / 300: loss 0.593087\n",
      "iteration 79 / 300: loss 0.600229\n",
      "iteration 79 / 300: loss 0.598204\n",
      "iteration 79 / 300: loss 0.583846\n",
      "iteration 79 / 300: loss 0.614520\n",
      "iteration 79 / 300: loss 0.591456\n",
      "iteration 79 / 300: loss 0.591541\n",
      "iteration 79 / 300: loss 0.594151\n",
      "iteration 79 / 300: loss 0.596960\n",
      "iteration 79 / 300: loss 0.596886\n",
      "iteration 79 / 300: loss 0.611908\n",
      "iteration 79 / 300: loss 0.607489\n",
      "iteration 79 / 300: loss 0.597228\n",
      "iteration 79 / 300: loss 0.596453\n",
      "iteration 79 / 300: loss 0.627548\n",
      "iteration 79 / 300: loss 0.601770\n",
      "iteration 79 / 300: loss 0.600073\n",
      "iteration 79 / 300: loss 0.622099\n",
      "iteration 79 / 300: loss 0.581648\n",
      "iteration 79 / 300: loss 0.599791\n",
      "iteration 79 / 300: loss 0.591404\n",
      "iteration 79 / 300: loss 0.600098\n",
      "iteration 79 / 300: loss 0.596194\n",
      "iteration 79 / 300: loss 0.590940\n",
      "iteration 79 / 300: loss 0.592158\n",
      "iteration 79 / 300: loss 0.615665\n",
      "iteration 79 / 300: loss 0.621526\n",
      "iteration 79 / 300: loss 0.587438\n",
      "iteration 79 / 300: loss 0.582666\n",
      "iteration 79 / 300: loss 0.585748\n",
      "iteration 79 / 300: loss 0.603877\n",
      "iteration 79 / 300: loss 0.585394\n",
      "iteration 79 / 300: loss 0.579059\n",
      "iteration 79 / 300: loss 0.576579\n",
      "iteration 79 / 300: loss 0.574256\n",
      "iteration 79 / 300: loss 0.600635\n",
      "iteration 79 / 300: loss 0.584648\n",
      "iteration 79 / 300: loss 0.584985\n",
      "iteration 79 / 300: loss 0.568479\n",
      "iteration 79 / 300: loss 0.592199\n",
      "iteration 79 / 300: loss 0.612296\n",
      "iteration 79 / 300: loss 0.609081\n",
      "iteration 79 / 300: loss 0.607792\n",
      "iteration 79 / 300: loss 0.595690\n",
      "iteration 79 / 300: loss 0.593003\n",
      "iteration 79 / 300: loss 0.598169\n",
      "iteration 79 / 300: loss 0.597859\n",
      "iteration 79 / 300: loss 0.601120\n",
      "iteration 79 / 300: loss 0.597610\n",
      "iteration 79 / 300: loss 0.598913\n",
      "iteration 79 / 300: loss 0.587984\n",
      "iteration 79 / 300: loss 0.600671\n",
      "iteration 79 / 300: loss 0.599819\n",
      "iteration 79 / 300: loss 0.617716\n",
      "iteration 79 / 300: loss 0.599027\n",
      "iteration 79 / 300: loss 0.600942\n",
      "iteration 79 / 300: loss 0.605490\n",
      "iteration 79 / 300: loss 0.598771\n",
      "iteration 79 / 300: loss 0.591639\n",
      "iteration 79 / 300: loss 0.580538\n",
      "iteration 79 / 300: loss 0.598399\n",
      "iteration 79 / 300: loss 0.611853\n",
      "iteration 79 / 300: loss 0.613378\n",
      "iteration 79 / 300: loss 0.582352\n",
      "iteration 79 / 300: loss 0.602172\n",
      "iteration 79 / 300: loss 0.609146\n",
      "iteration 79 / 300: loss 0.601971\n",
      "iteration 79 / 300: loss 0.608154\n",
      "iteration 79 / 300: loss 0.620457\n",
      "iteration 79 / 300: loss 0.584998\n",
      "iteration 79 / 300: loss 0.583851\n",
      "iteration 79 / 300: loss 0.629021\n",
      "iteration 79 / 300: loss 0.609540\n",
      "iteration 79 / 300: loss 0.606446\n",
      "iteration 79 / 300: loss 0.599198\n",
      "iteration 79 / 300: loss 0.616068\n",
      "iteration 79 / 300: loss 0.596657\n",
      "iteration 79 / 300: loss 0.581615\n",
      "iteration 79 / 300: loss 0.609959\n",
      "iteration 79 / 300: loss 0.608275\n",
      "iteration 79 / 300: loss 0.598400\n",
      "iteration 79 / 300: loss 0.592198\n",
      "iteration 79 / 300: loss 0.611218\n",
      "iteration 79 / 300: loss 0.598716\n",
      "iteration 79 / 300: loss 0.581522\n",
      "iteration 79 / 300: loss 0.609752\n",
      "iteration 80 / 300: loss 0.578569\n",
      "iteration 80 / 300: loss 0.596383\n",
      "iteration 80 / 300: loss 0.569613\n",
      "iteration 80 / 300: loss 0.598023\n",
      "iteration 80 / 300: loss 0.599103\n",
      "iteration 80 / 300: loss 0.604042\n",
      "iteration 80 / 300: loss 0.615379\n",
      "iteration 80 / 300: loss 0.588386\n",
      "iteration 80 / 300: loss 0.627309\n",
      "iteration 80 / 300: loss 0.592792\n",
      "iteration 80 / 300: loss 0.621694\n",
      "iteration 80 / 300: loss 0.593233\n",
      "iteration 80 / 300: loss 0.600695\n",
      "iteration 80 / 300: loss 0.571128\n",
      "iteration 80 / 300: loss 0.593070\n",
      "iteration 80 / 300: loss 0.600212\n",
      "iteration 80 / 300: loss 0.598189\n",
      "iteration 80 / 300: loss 0.583833\n",
      "iteration 80 / 300: loss 0.614504\n",
      "iteration 80 / 300: loss 0.591440\n",
      "iteration 80 / 300: loss 0.591526\n",
      "iteration 80 / 300: loss 0.594137\n",
      "iteration 80 / 300: loss 0.596938\n",
      "iteration 80 / 300: loss 0.596870\n",
      "iteration 80 / 300: loss 0.611892\n",
      "iteration 80 / 300: loss 0.607467\n",
      "iteration 80 / 300: loss 0.597210\n",
      "iteration 80 / 300: loss 0.596439\n",
      "iteration 80 / 300: loss 0.627533\n",
      "iteration 80 / 300: loss 0.601752\n",
      "iteration 80 / 300: loss 0.600059\n",
      "iteration 80 / 300: loss 0.622085\n",
      "iteration 80 / 300: loss 0.581628\n",
      "iteration 80 / 300: loss 0.599773\n",
      "iteration 80 / 300: loss 0.591383\n",
      "iteration 80 / 300: loss 0.600081\n",
      "iteration 80 / 300: loss 0.596177\n",
      "iteration 80 / 300: loss 0.590923\n",
      "iteration 80 / 300: loss 0.592139\n",
      "iteration 80 / 300: loss 0.615646\n",
      "iteration 80 / 300: loss 0.621510\n",
      "iteration 80 / 300: loss 0.587422\n",
      "iteration 80 / 300: loss 0.582649\n",
      "iteration 80 / 300: loss 0.585731\n",
      "iteration 80 / 300: loss 0.603857\n",
      "iteration 80 / 300: loss 0.585375\n",
      "iteration 80 / 300: loss 0.579042\n",
      "iteration 80 / 300: loss 0.576564\n",
      "iteration 80 / 300: loss 0.574241\n",
      "iteration 80 / 300: loss 0.600623\n",
      "iteration 80 / 300: loss 0.584633\n",
      "iteration 80 / 300: loss 0.584971\n",
      "iteration 80 / 300: loss 0.568464\n",
      "iteration 80 / 300: loss 0.592182\n",
      "iteration 80 / 300: loss 0.612279\n",
      "iteration 80 / 300: loss 0.609066\n",
      "iteration 80 / 300: loss 0.607775\n",
      "iteration 80 / 300: loss 0.595676\n",
      "iteration 80 / 300: loss 0.592987\n",
      "iteration 80 / 300: loss 0.598152\n",
      "iteration 80 / 300: loss 0.597842\n",
      "iteration 80 / 300: loss 0.601104\n",
      "iteration 80 / 300: loss 0.597592\n",
      "iteration 80 / 300: loss 0.598900\n",
      "iteration 80 / 300: loss 0.587967\n",
      "iteration 80 / 300: loss 0.600655\n",
      "iteration 80 / 300: loss 0.599803\n",
      "iteration 80 / 300: loss 0.617700\n",
      "iteration 80 / 300: loss 0.599013\n",
      "iteration 80 / 300: loss 0.600929\n",
      "iteration 80 / 300: loss 0.605472\n",
      "iteration 80 / 300: loss 0.598754\n",
      "iteration 80 / 300: loss 0.591623\n",
      "iteration 80 / 300: loss 0.580523\n",
      "iteration 80 / 300: loss 0.598382\n",
      "iteration 80 / 300: loss 0.611837\n",
      "iteration 80 / 300: loss 0.613363\n",
      "iteration 80 / 300: loss 0.582339\n",
      "iteration 80 / 300: loss 0.602152\n",
      "iteration 80 / 300: loss 0.609128\n",
      "iteration 80 / 300: loss 0.601954\n",
      "iteration 80 / 300: loss 0.608134\n",
      "iteration 80 / 300: loss 0.620436\n",
      "iteration 80 / 300: loss 0.584981\n",
      "iteration 80 / 300: loss 0.583839\n",
      "iteration 80 / 300: loss 0.629005\n",
      "iteration 80 / 300: loss 0.609527\n",
      "iteration 80 / 300: loss 0.606429\n",
      "iteration 80 / 300: loss 0.599183\n",
      "iteration 80 / 300: loss 0.616050\n",
      "iteration 80 / 300: loss 0.596641\n",
      "iteration 80 / 300: loss 0.581597\n",
      "iteration 80 / 300: loss 0.609945\n",
      "iteration 80 / 300: loss 0.608260\n",
      "iteration 80 / 300: loss 0.598383\n",
      "iteration 80 / 300: loss 0.592181\n",
      "iteration 80 / 300: loss 0.611200\n",
      "iteration 80 / 300: loss 0.598700\n",
      "iteration 80 / 300: loss 0.581509\n",
      "iteration 80 / 300: loss 0.609736\n",
      "iteration 81 / 300: loss 0.578552\n",
      "iteration 81 / 300: loss 0.596367\n",
      "iteration 81 / 300: loss 0.569598\n",
      "iteration 81 / 300: loss 0.598006\n",
      "iteration 81 / 300: loss 0.599088\n",
      "iteration 81 / 300: loss 0.604027\n",
      "iteration 81 / 300: loss 0.615367\n",
      "iteration 81 / 300: loss 0.588371\n",
      "iteration 81 / 300: loss 0.627296\n",
      "iteration 81 / 300: loss 0.592774\n",
      "iteration 81 / 300: loss 0.621676\n",
      "iteration 81 / 300: loss 0.593220\n",
      "iteration 81 / 300: loss 0.600680\n",
      "iteration 81 / 300: loss 0.571116\n",
      "iteration 81 / 300: loss 0.593055\n",
      "iteration 81 / 300: loss 0.600195\n",
      "iteration 81 / 300: loss 0.598176\n",
      "iteration 81 / 300: loss 0.583822\n",
      "iteration 81 / 300: loss 0.614490\n",
      "iteration 81 / 300: loss 0.591425\n",
      "iteration 81 / 300: loss 0.591514\n",
      "iteration 81 / 300: loss 0.594124\n",
      "iteration 81 / 300: loss 0.596919\n",
      "iteration 81 / 300: loss 0.596855\n",
      "iteration 81 / 300: loss 0.611877\n",
      "iteration 81 / 300: loss 0.607447\n",
      "iteration 81 / 300: loss 0.597193\n",
      "iteration 81 / 300: loss 0.596426\n",
      "iteration 81 / 300: loss 0.627520\n",
      "iteration 81 / 300: loss 0.601736\n",
      "iteration 81 / 300: loss 0.600046\n",
      "iteration 81 / 300: loss 0.622073\n",
      "iteration 81 / 300: loss 0.581610\n",
      "iteration 81 / 300: loss 0.599757\n",
      "iteration 81 / 300: loss 0.591364\n",
      "iteration 81 / 300: loss 0.600066\n",
      "iteration 81 / 300: loss 0.596161\n",
      "iteration 81 / 300: loss 0.590907\n",
      "iteration 81 / 300: loss 0.592123\n",
      "iteration 81 / 300: loss 0.615629\n",
      "iteration 81 / 300: loss 0.621496\n",
      "iteration 81 / 300: loss 0.587407\n",
      "iteration 81 / 300: loss 0.582633\n",
      "iteration 81 / 300: loss 0.585716\n",
      "iteration 81 / 300: loss 0.603839\n",
      "iteration 81 / 300: loss 0.585358\n",
      "iteration 81 / 300: loss 0.579027\n",
      "iteration 81 / 300: loss 0.576550\n",
      "iteration 81 / 300: loss 0.574228\n",
      "iteration 81 / 300: loss 0.600611\n",
      "iteration 81 / 300: loss 0.584620\n",
      "iteration 81 / 300: loss 0.584958\n",
      "iteration 81 / 300: loss 0.568451\n",
      "iteration 81 / 300: loss 0.592167\n",
      "iteration 81 / 300: loss 0.612264\n",
      "iteration 81 / 300: loss 0.609053\n",
      "iteration 81 / 300: loss 0.607760\n",
      "iteration 81 / 300: loss 0.595662\n",
      "iteration 81 / 300: loss 0.592973\n",
      "iteration 81 / 300: loss 0.598136\n",
      "iteration 81 / 300: loss 0.597826\n",
      "iteration 81 / 300: loss 0.601090\n",
      "iteration 81 / 300: loss 0.597576\n",
      "iteration 81 / 300: loss 0.598888\n",
      "iteration 81 / 300: loss 0.587952\n",
      "iteration 81 / 300: loss 0.600640\n",
      "iteration 81 / 300: loss 0.599789\n",
      "iteration 81 / 300: loss 0.617685\n",
      "iteration 81 / 300: loss 0.599000\n",
      "iteration 81 / 300: loss 0.600916\n",
      "iteration 81 / 300: loss 0.605457\n",
      "iteration 81 / 300: loss 0.598738\n",
      "iteration 81 / 300: loss 0.591609\n",
      "iteration 81 / 300: loss 0.580510\n",
      "iteration 81 / 300: loss 0.598367\n",
      "iteration 81 / 300: loss 0.611823\n",
      "iteration 81 / 300: loss 0.613349\n",
      "iteration 81 / 300: loss 0.582327\n",
      "iteration 81 / 300: loss 0.602133\n",
      "iteration 81 / 300: loss 0.609112\n",
      "iteration 81 / 300: loss 0.601939\n",
      "iteration 81 / 300: loss 0.608116\n",
      "iteration 81 / 300: loss 0.620417\n",
      "iteration 81 / 300: loss 0.584966\n",
      "iteration 81 / 300: loss 0.583828\n",
      "iteration 81 / 300: loss 0.628990\n",
      "iteration 81 / 300: loss 0.609515\n",
      "iteration 81 / 300: loss 0.606413\n",
      "iteration 81 / 300: loss 0.599169\n",
      "iteration 81 / 300: loss 0.616033\n",
      "iteration 81 / 300: loss 0.596627\n",
      "iteration 81 / 300: loss 0.581582\n",
      "iteration 81 / 300: loss 0.609932\n",
      "iteration 81 / 300: loss 0.608248\n",
      "iteration 81 / 300: loss 0.598368\n",
      "iteration 81 / 300: loss 0.592166\n",
      "iteration 81 / 300: loss 0.611184\n",
      "iteration 81 / 300: loss 0.598686\n",
      "iteration 81 / 300: loss 0.581497\n",
      "iteration 81 / 300: loss 0.609721\n",
      "iteration 82 / 300: loss 0.578536\n",
      "iteration 82 / 300: loss 0.596352\n",
      "iteration 82 / 300: loss 0.569585\n",
      "iteration 82 / 300: loss 0.597991\n",
      "iteration 82 / 300: loss 0.599074\n",
      "iteration 82 / 300: loss 0.604012\n",
      "iteration 82 / 300: loss 0.615357\n",
      "iteration 82 / 300: loss 0.588357\n",
      "iteration 82 / 300: loss 0.627284\n",
      "iteration 82 / 300: loss 0.592757\n",
      "iteration 82 / 300: loss 0.621659\n",
      "iteration 82 / 300: loss 0.593208\n",
      "iteration 82 / 300: loss 0.600667\n",
      "iteration 82 / 300: loss 0.571105\n",
      "iteration 82 / 300: loss 0.593042\n",
      "iteration 82 / 300: loss 0.600181\n",
      "iteration 82 / 300: loss 0.598165\n",
      "iteration 82 / 300: loss 0.583811\n",
      "iteration 82 / 300: loss 0.614477\n",
      "iteration 82 / 300: loss 0.591412\n",
      "iteration 82 / 300: loss 0.591502\n",
      "iteration 82 / 300: loss 0.594113\n",
      "iteration 82 / 300: loss 0.596901\n",
      "iteration 82 / 300: loss 0.596841\n",
      "iteration 82 / 300: loss 0.611864\n",
      "iteration 82 / 300: loss 0.607429\n",
      "iteration 82 / 300: loss 0.597178\n",
      "iteration 82 / 300: loss 0.596414\n",
      "iteration 82 / 300: loss 0.627508\n",
      "iteration 82 / 300: loss 0.601722\n",
      "iteration 82 / 300: loss 0.600034\n",
      "iteration 82 / 300: loss 0.622061\n",
      "iteration 82 / 300: loss 0.581593\n",
      "iteration 82 / 300: loss 0.599743\n",
      "iteration 82 / 300: loss 0.591346\n",
      "iteration 82 / 300: loss 0.600052\n",
      "iteration 82 / 300: loss 0.596147\n",
      "iteration 82 / 300: loss 0.590893\n",
      "iteration 82 / 300: loss 0.592107\n",
      "iteration 82 / 300: loss 0.615614\n",
      "iteration 82 / 300: loss 0.621483\n",
      "iteration 82 / 300: loss 0.587394\n",
      "iteration 82 / 300: loss 0.582619\n",
      "iteration 82 / 300: loss 0.585702\n",
      "iteration 82 / 300: loss 0.603822\n",
      "iteration 82 / 300: loss 0.585342\n",
      "iteration 82 / 300: loss 0.579013\n",
      "iteration 82 / 300: loss 0.576538\n",
      "iteration 82 / 300: loss 0.574215\n",
      "iteration 82 / 300: loss 0.600601\n",
      "iteration 82 / 300: loss 0.584608\n",
      "iteration 82 / 300: loss 0.584946\n",
      "iteration 82 / 300: loss 0.568439\n",
      "iteration 82 / 300: loss 0.592154\n",
      "iteration 82 / 300: loss 0.612250\n",
      "iteration 82 / 300: loss 0.609040\n",
      "iteration 82 / 300: loss 0.607746\n",
      "iteration 82 / 300: loss 0.595650\n",
      "iteration 82 / 300: loss 0.592960\n",
      "iteration 82 / 300: loss 0.598122\n",
      "iteration 82 / 300: loss 0.597812\n",
      "iteration 82 / 300: loss 0.601077\n",
      "iteration 82 / 300: loss 0.597561\n",
      "iteration 82 / 300: loss 0.598878\n",
      "iteration 82 / 300: loss 0.587938\n",
      "iteration 82 / 300: loss 0.600627\n",
      "iteration 82 / 300: loss 0.599776\n",
      "iteration 82 / 300: loss 0.617671\n",
      "iteration 82 / 300: loss 0.598988\n",
      "iteration 82 / 300: loss 0.600905\n",
      "iteration 82 / 300: loss 0.605442\n",
      "iteration 82 / 300: loss 0.598724\n",
      "iteration 82 / 300: loss 0.591596\n",
      "iteration 82 / 300: loss 0.580497\n",
      "iteration 82 / 300: loss 0.598353\n",
      "iteration 82 / 300: loss 0.611809\n",
      "iteration 82 / 300: loss 0.613337\n",
      "iteration 82 / 300: loss 0.582316\n",
      "iteration 82 / 300: loss 0.602116\n",
      "iteration 82 / 300: loss 0.609097\n",
      "iteration 82 / 300: loss 0.601925\n",
      "iteration 82 / 300: loss 0.608100\n",
      "iteration 82 / 300: loss 0.620400\n",
      "iteration 82 / 300: loss 0.584952\n",
      "iteration 82 / 300: loss 0.583818\n",
      "iteration 82 / 300: loss 0.628976\n",
      "iteration 82 / 300: loss 0.609504\n",
      "iteration 82 / 300: loss 0.606399\n",
      "iteration 82 / 300: loss 0.599156\n",
      "iteration 82 / 300: loss 0.616018\n",
      "iteration 82 / 300: loss 0.596614\n",
      "iteration 82 / 300: loss 0.581567\n",
      "iteration 82 / 300: loss 0.609920\n",
      "iteration 82 / 300: loss 0.608236\n",
      "iteration 82 / 300: loss 0.598355\n",
      "iteration 82 / 300: loss 0.592153\n",
      "iteration 82 / 300: loss 0.611170\n",
      "iteration 82 / 300: loss 0.598673\n",
      "iteration 82 / 300: loss 0.581486\n",
      "iteration 82 / 300: loss 0.609708\n",
      "iteration 83 / 300: loss 0.578522\n",
      "iteration 83 / 300: loss 0.596339\n",
      "iteration 83 / 300: loss 0.569572\n",
      "iteration 83 / 300: loss 0.597978\n",
      "iteration 83 / 300: loss 0.599061\n",
      "iteration 83 / 300: loss 0.604000\n",
      "iteration 83 / 300: loss 0.615348\n",
      "iteration 83 / 300: loss 0.588345\n",
      "iteration 83 / 300: loss 0.627274\n",
      "iteration 83 / 300: loss 0.592742\n",
      "iteration 83 / 300: loss 0.621644\n",
      "iteration 83 / 300: loss 0.593197\n",
      "iteration 83 / 300: loss 0.600655\n",
      "iteration 83 / 300: loss 0.571095\n",
      "iteration 83 / 300: loss 0.593029\n",
      "iteration 83 / 300: loss 0.600168\n",
      "iteration 83 / 300: loss 0.598154\n",
      "iteration 83 / 300: loss 0.583802\n",
      "iteration 83 / 300: loss 0.614465\n",
      "iteration 83 / 300: loss 0.591400\n",
      "iteration 83 / 300: loss 0.591491\n",
      "iteration 83 / 300: loss 0.594103\n",
      "iteration 83 / 300: loss 0.596885\n",
      "iteration 83 / 300: loss 0.596829\n",
      "iteration 83 / 300: loss 0.611851\n",
      "iteration 83 / 300: loss 0.607413\n",
      "iteration 83 / 300: loss 0.597164\n",
      "iteration 83 / 300: loss 0.596403\n",
      "iteration 83 / 300: loss 0.627497\n",
      "iteration 83 / 300: loss 0.601709\n",
      "iteration 83 / 300: loss 0.600024\n",
      "iteration 83 / 300: loss 0.622051\n",
      "iteration 83 / 300: loss 0.581578\n",
      "iteration 83 / 300: loss 0.599730\n",
      "iteration 83 / 300: loss 0.591331\n",
      "iteration 83 / 300: loss 0.600040\n",
      "iteration 83 / 300: loss 0.596135\n",
      "iteration 83 / 300: loss 0.590880\n",
      "iteration 83 / 300: loss 0.592093\n",
      "iteration 83 / 300: loss 0.615600\n",
      "iteration 83 / 300: loss 0.621471\n",
      "iteration 83 / 300: loss 0.587382\n",
      "iteration 83 / 300: loss 0.582606\n",
      "iteration 83 / 300: loss 0.585690\n",
      "iteration 83 / 300: loss 0.603807\n",
      "iteration 83 / 300: loss 0.585328\n",
      "iteration 83 / 300: loss 0.579000\n",
      "iteration 83 / 300: loss 0.576526\n",
      "iteration 83 / 300: loss 0.574204\n",
      "iteration 83 / 300: loss 0.600591\n",
      "iteration 83 / 300: loss 0.584596\n",
      "iteration 83 / 300: loss 0.584936\n",
      "iteration 83 / 300: loss 0.568428\n",
      "iteration 83 / 300: loss 0.592142\n",
      "iteration 83 / 300: loss 0.612237\n",
      "iteration 83 / 300: loss 0.609029\n",
      "iteration 83 / 300: loss 0.607733\n",
      "iteration 83 / 300: loss 0.595639\n",
      "iteration 83 / 300: loss 0.592948\n",
      "iteration 83 / 300: loss 0.598110\n",
      "iteration 83 / 300: loss 0.597799\n",
      "iteration 83 / 300: loss 0.601065\n",
      "iteration 83 / 300: loss 0.597548\n",
      "iteration 83 / 300: loss 0.598868\n",
      "iteration 83 / 300: loss 0.587925\n",
      "iteration 83 / 300: loss 0.600615\n",
      "iteration 83 / 300: loss 0.599764\n",
      "iteration 83 / 300: loss 0.617659\n",
      "iteration 83 / 300: loss 0.598977\n",
      "iteration 83 / 300: loss 0.600896\n",
      "iteration 83 / 300: loss 0.605429\n",
      "iteration 83 / 300: loss 0.598712\n",
      "iteration 83 / 300: loss 0.591584\n",
      "iteration 83 / 300: loss 0.580487\n",
      "iteration 83 / 300: loss 0.598341\n",
      "iteration 83 / 300: loss 0.611798\n",
      "iteration 83 / 300: loss 0.613326\n",
      "iteration 83 / 300: loss 0.582306\n",
      "iteration 83 / 300: loss 0.602101\n",
      "iteration 83 / 300: loss 0.609084\n",
      "iteration 83 / 300: loss 0.601913\n",
      "iteration 83 / 300: loss 0.608085\n",
      "iteration 83 / 300: loss 0.620385\n",
      "iteration 83 / 300: loss 0.584939\n",
      "iteration 83 / 300: loss 0.583809\n",
      "iteration 83 / 300: loss 0.628964\n",
      "iteration 83 / 300: loss 0.609494\n",
      "iteration 83 / 300: loss 0.606387\n",
      "iteration 83 / 300: loss 0.599145\n",
      "iteration 83 / 300: loss 0.616005\n",
      "iteration 83 / 300: loss 0.596602\n",
      "iteration 83 / 300: loss 0.581554\n",
      "iteration 83 / 300: loss 0.609909\n",
      "iteration 83 / 300: loss 0.608226\n",
      "iteration 83 / 300: loss 0.598342\n",
      "iteration 83 / 300: loss 0.592140\n",
      "iteration 83 / 300: loss 0.611157\n",
      "iteration 83 / 300: loss 0.598661\n",
      "iteration 83 / 300: loss 0.581476\n",
      "iteration 83 / 300: loss 0.609696\n",
      "iteration 84 / 300: loss 0.578509\n",
      "iteration 84 / 300: loss 0.596327\n",
      "iteration 84 / 300: loss 0.569561\n",
      "iteration 84 / 300: loss 0.597966\n",
      "iteration 84 / 300: loss 0.599049\n",
      "iteration 84 / 300: loss 0.603988\n",
      "iteration 84 / 300: loss 0.615340\n",
      "iteration 84 / 300: loss 0.588334\n",
      "iteration 84 / 300: loss 0.627264\n",
      "iteration 84 / 300: loss 0.592729\n",
      "iteration 84 / 300: loss 0.621630\n",
      "iteration 84 / 300: loss 0.593187\n",
      "iteration 84 / 300: loss 0.600645\n",
      "iteration 84 / 300: loss 0.571086\n",
      "iteration 84 / 300: loss 0.593018\n",
      "iteration 84 / 300: loss 0.600156\n",
      "iteration 84 / 300: loss 0.598145\n",
      "iteration 84 / 300: loss 0.583793\n",
      "iteration 84 / 300: loss 0.614455\n",
      "iteration 84 / 300: loss 0.591389\n",
      "iteration 84 / 300: loss 0.591482\n",
      "iteration 84 / 300: loss 0.594094\n",
      "iteration 84 / 300: loss 0.596871\n",
      "iteration 84 / 300: loss 0.596818\n",
      "iteration 84 / 300: loss 0.611840\n",
      "iteration 84 / 300: loss 0.607398\n",
      "iteration 84 / 300: loss 0.597151\n",
      "iteration 84 / 300: loss 0.596393\n",
      "iteration 84 / 300: loss 0.627487\n",
      "iteration 84 / 300: loss 0.601697\n",
      "iteration 84 / 300: loss 0.600014\n",
      "iteration 84 / 300: loss 0.622042\n",
      "iteration 84 / 300: loss 0.581564\n",
      "iteration 84 / 300: loss 0.599718\n",
      "iteration 84 / 300: loss 0.591317\n",
      "iteration 84 / 300: loss 0.600028\n",
      "iteration 84 / 300: loss 0.596123\n",
      "iteration 84 / 300: loss 0.590869\n",
      "iteration 84 / 300: loss 0.592081\n",
      "iteration 84 / 300: loss 0.615587\n",
      "iteration 84 / 300: loss 0.621461\n",
      "iteration 84 / 300: loss 0.587371\n",
      "iteration 84 / 300: loss 0.582594\n",
      "iteration 84 / 300: loss 0.585679\n",
      "iteration 84 / 300: loss 0.603794\n",
      "iteration 84 / 300: loss 0.585315\n",
      "iteration 84 / 300: loss 0.578989\n",
      "iteration 84 / 300: loss 0.576516\n",
      "iteration 84 / 300: loss 0.574194\n",
      "iteration 84 / 300: loss 0.600583\n",
      "iteration 84 / 300: loss 0.584586\n",
      "iteration 84 / 300: loss 0.584926\n",
      "iteration 84 / 300: loss 0.568418\n",
      "iteration 84 / 300: loss 0.592130\n",
      "iteration 84 / 300: loss 0.612226\n",
      "iteration 84 / 300: loss 0.609019\n",
      "iteration 84 / 300: loss 0.607722\n",
      "iteration 84 / 300: loss 0.595629\n",
      "iteration 84 / 300: loss 0.592938\n",
      "iteration 84 / 300: loss 0.598098\n",
      "iteration 84 / 300: loss 0.597788\n",
      "iteration 84 / 300: loss 0.601054\n",
      "iteration 84 / 300: loss 0.597536\n",
      "iteration 84 / 300: loss 0.598859\n",
      "iteration 84 / 300: loss 0.587914\n",
      "iteration 84 / 300: loss 0.600604\n",
      "iteration 84 / 300: loss 0.599753\n",
      "iteration 84 / 300: loss 0.617648\n",
      "iteration 84 / 300: loss 0.598967\n",
      "iteration 84 / 300: loss 0.600887\n",
      "iteration 84 / 300: loss 0.605417\n",
      "iteration 84 / 300: loss 0.598700\n",
      "iteration 84 / 300: loss 0.591574\n",
      "iteration 84 / 300: loss 0.580477\n",
      "iteration 84 / 300: loss 0.598329\n",
      "iteration 84 / 300: loss 0.611787\n",
      "iteration 84 / 300: loss 0.613315\n",
      "iteration 84 / 300: loss 0.582298\n",
      "iteration 84 / 300: loss 0.602087\n",
      "iteration 84 / 300: loss 0.609072\n",
      "iteration 84 / 300: loss 0.601902\n",
      "iteration 84 / 300: loss 0.608072\n",
      "iteration 84 / 300: loss 0.620371\n",
      "iteration 84 / 300: loss 0.584927\n",
      "iteration 84 / 300: loss 0.583800\n",
      "iteration 84 / 300: loss 0.628953\n",
      "iteration 84 / 300: loss 0.609485\n",
      "iteration 84 / 300: loss 0.606375\n",
      "iteration 84 / 300: loss 0.599134\n",
      "iteration 84 / 300: loss 0.615993\n",
      "iteration 84 / 300: loss 0.596591\n",
      "iteration 84 / 300: loss 0.581542\n",
      "iteration 84 / 300: loss 0.609899\n",
      "iteration 84 / 300: loss 0.608216\n",
      "iteration 84 / 300: loss 0.598331\n",
      "iteration 84 / 300: loss 0.592129\n",
      "iteration 84 / 300: loss 0.611145\n",
      "iteration 84 / 300: loss 0.598651\n",
      "iteration 84 / 300: loss 0.581467\n",
      "iteration 84 / 300: loss 0.609685\n",
      "iteration 85 / 300: loss 0.578497\n",
      "iteration 85 / 300: loss 0.596317\n",
      "iteration 85 / 300: loss 0.569551\n",
      "iteration 85 / 300: loss 0.597955\n",
      "iteration 85 / 300: loss 0.599039\n",
      "iteration 85 / 300: loss 0.603977\n",
      "iteration 85 / 300: loss 0.615333\n",
      "iteration 85 / 300: loss 0.588323\n",
      "iteration 85 / 300: loss 0.627255\n",
      "iteration 85 / 300: loss 0.592717\n",
      "iteration 85 / 300: loss 0.621618\n",
      "iteration 85 / 300: loss 0.593178\n",
      "iteration 85 / 300: loss 0.600635\n",
      "iteration 85 / 300: loss 0.571078\n",
      "iteration 85 / 300: loss 0.593008\n",
      "iteration 85 / 300: loss 0.600145\n",
      "iteration 85 / 300: loss 0.598136\n",
      "iteration 85 / 300: loss 0.583786\n",
      "iteration 85 / 300: loss 0.614445\n",
      "iteration 85 / 300: loss 0.591379\n",
      "iteration 85 / 300: loss 0.591473\n",
      "iteration 85 / 300: loss 0.594085\n",
      "iteration 85 / 300: loss 0.596858\n",
      "iteration 85 / 300: loss 0.596808\n",
      "iteration 85 / 300: loss 0.611830\n",
      "iteration 85 / 300: loss 0.607385\n",
      "iteration 85 / 300: loss 0.597140\n",
      "iteration 85 / 300: loss 0.596385\n",
      "iteration 85 / 300: loss 0.627478\n",
      "iteration 85 / 300: loss 0.601686\n",
      "iteration 85 / 300: loss 0.600006\n",
      "iteration 85 / 300: loss 0.622033\n",
      "iteration 85 / 300: loss 0.581552\n",
      "iteration 85 / 300: loss 0.599707\n",
      "iteration 85 / 300: loss 0.591304\n",
      "iteration 85 / 300: loss 0.600018\n",
      "iteration 85 / 300: loss 0.596113\n",
      "iteration 85 / 300: loss 0.590859\n",
      "iteration 85 / 300: loss 0.592070\n",
      "iteration 85 / 300: loss 0.615576\n",
      "iteration 85 / 300: loss 0.621451\n",
      "iteration 85 / 300: loss 0.587361\n",
      "iteration 85 / 300: loss 0.582584\n",
      "iteration 85 / 300: loss 0.585669\n",
      "iteration 85 / 300: loss 0.603782\n",
      "iteration 85 / 300: loss 0.585303\n",
      "iteration 85 / 300: loss 0.578979\n",
      "iteration 85 / 300: loss 0.576507\n",
      "iteration 85 / 300: loss 0.574185\n",
      "iteration 85 / 300: loss 0.600575\n",
      "iteration 85 / 300: loss 0.584577\n",
      "iteration 85 / 300: loss 0.584917\n",
      "iteration 85 / 300: loss 0.568409\n",
      "iteration 85 / 300: loss 0.592120\n",
      "iteration 85 / 300: loss 0.612215\n",
      "iteration 85 / 300: loss 0.609010\n",
      "iteration 85 / 300: loss 0.607711\n",
      "iteration 85 / 300: loss 0.595620\n",
      "iteration 85 / 300: loss 0.592928\n",
      "iteration 85 / 300: loss 0.598088\n",
      "iteration 85 / 300: loss 0.597777\n",
      "iteration 85 / 300: loss 0.601045\n",
      "iteration 85 / 300: loss 0.597525\n",
      "iteration 85 / 300: loss 0.598852\n",
      "iteration 85 / 300: loss 0.587904\n",
      "iteration 85 / 300: loss 0.600594\n",
      "iteration 85 / 300: loss 0.599743\n",
      "iteration 85 / 300: loss 0.617637\n",
      "iteration 85 / 300: loss 0.598959\n",
      "iteration 85 / 300: loss 0.600878\n",
      "iteration 85 / 300: loss 0.605407\n",
      "iteration 85 / 300: loss 0.598690\n",
      "iteration 85 / 300: loss 0.591564\n",
      "iteration 85 / 300: loss 0.580468\n",
      "iteration 85 / 300: loss 0.598319\n",
      "iteration 85 / 300: loss 0.611777\n",
      "iteration 85 / 300: loss 0.613306\n",
      "iteration 85 / 300: loss 0.582290\n",
      "iteration 85 / 300: loss 0.602074\n",
      "iteration 85 / 300: loss 0.609061\n",
      "iteration 85 / 300: loss 0.601891\n",
      "iteration 85 / 300: loss 0.608060\n",
      "iteration 85 / 300: loss 0.620358\n",
      "iteration 85 / 300: loss 0.584917\n",
      "iteration 85 / 300: loss 0.583793\n",
      "iteration 85 / 300: loss 0.628943\n",
      "iteration 85 / 300: loss 0.609476\n",
      "iteration 85 / 300: loss 0.606365\n",
      "iteration 85 / 300: loss 0.599125\n",
      "iteration 85 / 300: loss 0.615982\n",
      "iteration 85 / 300: loss 0.596582\n",
      "iteration 85 / 300: loss 0.581532\n",
      "iteration 85 / 300: loss 0.609891\n",
      "iteration 85 / 300: loss 0.608207\n",
      "iteration 85 / 300: loss 0.598321\n",
      "iteration 85 / 300: loss 0.592119\n",
      "iteration 85 / 300: loss 0.611134\n",
      "iteration 85 / 300: loss 0.598641\n",
      "iteration 85 / 300: loss 0.581459\n",
      "iteration 85 / 300: loss 0.609675\n",
      "iteration 86 / 300: loss 0.578486\n",
      "iteration 86 / 300: loss 0.596307\n",
      "iteration 86 / 300: loss 0.569542\n",
      "iteration 86 / 300: loss 0.597945\n",
      "iteration 86 / 300: loss 0.599029\n",
      "iteration 86 / 300: loss 0.603968\n",
      "iteration 86 / 300: loss 0.615326\n",
      "iteration 86 / 300: loss 0.588314\n",
      "iteration 86 / 300: loss 0.627247\n",
      "iteration 86 / 300: loss 0.592706\n",
      "iteration 86 / 300: loss 0.621607\n",
      "iteration 86 / 300: loss 0.593170\n",
      "iteration 86 / 300: loss 0.600626\n",
      "iteration 86 / 300: loss 0.571070\n",
      "iteration 86 / 300: loss 0.592999\n",
      "iteration 86 / 300: loss 0.600135\n",
      "iteration 86 / 300: loss 0.598128\n",
      "iteration 86 / 300: loss 0.583779\n",
      "iteration 86 / 300: loss 0.614437\n",
      "iteration 86 / 300: loss 0.591370\n",
      "iteration 86 / 300: loss 0.591465\n",
      "iteration 86 / 300: loss 0.594078\n",
      "iteration 86 / 300: loss 0.596846\n",
      "iteration 86 / 300: loss 0.596799\n",
      "iteration 86 / 300: loss 0.611821\n",
      "iteration 86 / 300: loss 0.607373\n",
      "iteration 86 / 300: loss 0.597129\n",
      "iteration 86 / 300: loss 0.596377\n",
      "iteration 86 / 300: loss 0.627470\n",
      "iteration 86 / 300: loss 0.601677\n",
      "iteration 86 / 300: loss 0.599998\n",
      "iteration 86 / 300: loss 0.622025\n",
      "iteration 86 / 300: loss 0.581541\n",
      "iteration 86 / 300: loss 0.599697\n",
      "iteration 86 / 300: loss 0.591292\n",
      "iteration 86 / 300: loss 0.600008\n",
      "iteration 86 / 300: loss 0.596104\n",
      "iteration 86 / 300: loss 0.590849\n",
      "iteration 86 / 300: loss 0.592059\n",
      "iteration 86 / 300: loss 0.615566\n",
      "iteration 86 / 300: loss 0.621443\n",
      "iteration 86 / 300: loss 0.587352\n",
      "iteration 86 / 300: loss 0.582574\n",
      "iteration 86 / 300: loss 0.585660\n",
      "iteration 86 / 300: loss 0.603771\n",
      "iteration 86 / 300: loss 0.585293\n",
      "iteration 86 / 300: loss 0.578969\n",
      "iteration 86 / 300: loss 0.576498\n",
      "iteration 86 / 300: loss 0.574177\n",
      "iteration 86 / 300: loss 0.600568\n",
      "iteration 86 / 300: loss 0.584569\n",
      "iteration 86 / 300: loss 0.584909\n",
      "iteration 86 / 300: loss 0.568401\n",
      "iteration 86 / 300: loss 0.592111\n",
      "iteration 86 / 300: loss 0.612206\n",
      "iteration 86 / 300: loss 0.609002\n",
      "iteration 86 / 300: loss 0.607702\n",
      "iteration 86 / 300: loss 0.595612\n",
      "iteration 86 / 300: loss 0.592919\n",
      "iteration 86 / 300: loss 0.598078\n",
      "iteration 86 / 300: loss 0.597768\n",
      "iteration 86 / 300: loss 0.601036\n",
      "iteration 86 / 300: loss 0.597516\n",
      "iteration 86 / 300: loss 0.598844\n",
      "iteration 86 / 300: loss 0.587895\n",
      "iteration 86 / 300: loss 0.600585\n",
      "iteration 86 / 300: loss 0.599734\n",
      "iteration 86 / 300: loss 0.617628\n",
      "iteration 86 / 300: loss 0.598951\n",
      "iteration 86 / 300: loss 0.600871\n",
      "iteration 86 / 300: loss 0.605397\n",
      "iteration 86 / 300: loss 0.598681\n",
      "iteration 86 / 300: loss 0.591556\n",
      "iteration 86 / 300: loss 0.580460\n",
      "iteration 86 / 300: loss 0.598310\n",
      "iteration 86 / 300: loss 0.611768\n",
      "iteration 86 / 300: loss 0.613298\n",
      "iteration 86 / 300: loss 0.582283\n",
      "iteration 86 / 300: loss 0.602063\n",
      "iteration 86 / 300: loss 0.609051\n",
      "iteration 86 / 300: loss 0.601882\n",
      "iteration 86 / 300: loss 0.608049\n",
      "iteration 86 / 300: loss 0.620346\n",
      "iteration 86 / 300: loss 0.584907\n",
      "iteration 86 / 300: loss 0.583786\n",
      "iteration 86 / 300: loss 0.628934\n",
      "iteration 86 / 300: loss 0.609469\n",
      "iteration 86 / 300: loss 0.606355\n",
      "iteration 86 / 300: loss 0.599116\n",
      "iteration 86 / 300: loss 0.615972\n",
      "iteration 86 / 300: loss 0.596573\n",
      "iteration 86 / 300: loss 0.581522\n",
      "iteration 86 / 300: loss 0.609883\n",
      "iteration 86 / 300: loss 0.608200\n",
      "iteration 86 / 300: loss 0.598312\n",
      "iteration 86 / 300: loss 0.592110\n",
      "iteration 86 / 300: loss 0.611124\n",
      "iteration 86 / 300: loss 0.598632\n",
      "iteration 86 / 300: loss 0.581452\n",
      "iteration 86 / 300: loss 0.609666\n",
      "iteration 87 / 300: loss 0.578476\n",
      "iteration 87 / 300: loss 0.596298\n",
      "iteration 87 / 300: loss 0.569534\n",
      "iteration 87 / 300: loss 0.597936\n",
      "iteration 87 / 300: loss 0.599021\n",
      "iteration 87 / 300: loss 0.603959\n",
      "iteration 87 / 300: loss 0.615320\n",
      "iteration 87 / 300: loss 0.588306\n",
      "iteration 87 / 300: loss 0.627240\n",
      "iteration 87 / 300: loss 0.592696\n",
      "iteration 87 / 300: loss 0.621597\n",
      "iteration 87 / 300: loss 0.593163\n",
      "iteration 87 / 300: loss 0.600618\n",
      "iteration 87 / 300: loss 0.571064\n",
      "iteration 87 / 300: loss 0.592991\n",
      "iteration 87 / 300: loss 0.600127\n",
      "iteration 87 / 300: loss 0.598121\n",
      "iteration 87 / 300: loss 0.583773\n",
      "iteration 87 / 300: loss 0.614429\n",
      "iteration 87 / 300: loss 0.591362\n",
      "iteration 87 / 300: loss 0.591458\n",
      "iteration 87 / 300: loss 0.594071\n",
      "iteration 87 / 300: loss 0.596835\n",
      "iteration 87 / 300: loss 0.596790\n",
      "iteration 87 / 300: loss 0.611813\n",
      "iteration 87 / 300: loss 0.607362\n",
      "iteration 87 / 300: loss 0.597120\n",
      "iteration 87 / 300: loss 0.596369\n",
      "iteration 87 / 300: loss 0.627462\n",
      "iteration 87 / 300: loss 0.601668\n",
      "iteration 87 / 300: loss 0.599991\n",
      "iteration 87 / 300: loss 0.622018\n",
      "iteration 87 / 300: loss 0.581531\n",
      "iteration 87 / 300: loss 0.599688\n",
      "iteration 87 / 300: loss 0.591282\n",
      "iteration 87 / 300: loss 0.600000\n",
      "iteration 87 / 300: loss 0.596095\n",
      "iteration 87 / 300: loss 0.590841\n",
      "iteration 87 / 300: loss 0.592050\n",
      "iteration 87 / 300: loss 0.615556\n",
      "iteration 87 / 300: loss 0.621435\n",
      "iteration 87 / 300: loss 0.587344\n",
      "iteration 87 / 300: loss 0.582565\n",
      "iteration 87 / 300: loss 0.585651\n",
      "iteration 87 / 300: loss 0.603761\n",
      "iteration 87 / 300: loss 0.585283\n",
      "iteration 87 / 300: loss 0.578961\n",
      "iteration 87 / 300: loss 0.576491\n",
      "iteration 87 / 300: loss 0.574169\n",
      "iteration 87 / 300: loss 0.600561\n",
      "iteration 87 / 300: loss 0.584562\n",
      "iteration 87 / 300: loss 0.584902\n",
      "iteration 87 / 300: loss 0.568393\n",
      "iteration 87 / 300: loss 0.592103\n",
      "iteration 87 / 300: loss 0.612197\n",
      "iteration 87 / 300: loss 0.608994\n",
      "iteration 87 / 300: loss 0.607694\n",
      "iteration 87 / 300: loss 0.595604\n",
      "iteration 87 / 300: loss 0.592912\n",
      "iteration 87 / 300: loss 0.598070\n",
      "iteration 87 / 300: loss 0.597759\n",
      "iteration 87 / 300: loss 0.601028\n",
      "iteration 87 / 300: loss 0.597507\n",
      "iteration 87 / 300: loss 0.598838\n",
      "iteration 87 / 300: loss 0.587886\n",
      "iteration 87 / 300: loss 0.600577\n",
      "iteration 87 / 300: loss 0.599726\n",
      "iteration 87 / 300: loss 0.617620\n",
      "iteration 87 / 300: loss 0.598943\n",
      "iteration 87 / 300: loss 0.600864\n",
      "iteration 87 / 300: loss 0.605388\n",
      "iteration 87 / 300: loss 0.598672\n",
      "iteration 87 / 300: loss 0.591548\n",
      "iteration 87 / 300: loss 0.580452\n",
      "iteration 87 / 300: loss 0.598301\n",
      "iteration 87 / 300: loss 0.611760\n",
      "iteration 87 / 300: loss 0.613290\n",
      "iteration 87 / 300: loss 0.582276\n",
      "iteration 87 / 300: loss 0.602053\n",
      "iteration 87 / 300: loss 0.609042\n",
      "iteration 87 / 300: loss 0.601874\n",
      "iteration 87 / 300: loss 0.608039\n",
      "iteration 87 / 300: loss 0.620336\n",
      "iteration 87 / 300: loss 0.584899\n",
      "iteration 87 / 300: loss 0.583780\n",
      "iteration 87 / 300: loss 0.628926\n",
      "iteration 87 / 300: loss 0.609462\n",
      "iteration 87 / 300: loss 0.606347\n",
      "iteration 87 / 300: loss 0.599108\n",
      "iteration 87 / 300: loss 0.615963\n",
      "iteration 87 / 300: loss 0.596565\n",
      "iteration 87 / 300: loss 0.581513\n",
      "iteration 87 / 300: loss 0.609875\n",
      "iteration 87 / 300: loss 0.608193\n",
      "iteration 87 / 300: loss 0.598303\n",
      "iteration 87 / 300: loss 0.592101\n",
      "iteration 87 / 300: loss 0.611115\n",
      "iteration 87 / 300: loss 0.598625\n",
      "iteration 87 / 300: loss 0.581445\n",
      "iteration 87 / 300: loss 0.609658\n",
      "iteration 88 / 300: loss 0.578468\n",
      "iteration 88 / 300: loss 0.596290\n",
      "iteration 88 / 300: loss 0.569526\n",
      "iteration 88 / 300: loss 0.597927\n",
      "iteration 88 / 300: loss 0.599013\n",
      "iteration 88 / 300: loss 0.603951\n",
      "iteration 88 / 300: loss 0.615314\n",
      "iteration 88 / 300: loss 0.588298\n",
      "iteration 88 / 300: loss 0.627234\n",
      "iteration 88 / 300: loss 0.592686\n",
      "iteration 88 / 300: loss 0.621587\n",
      "iteration 88 / 300: loss 0.593156\n",
      "iteration 88 / 300: loss 0.600610\n",
      "iteration 88 / 300: loss 0.571058\n",
      "iteration 88 / 300: loss 0.592983\n",
      "iteration 88 / 300: loss 0.600119\n",
      "iteration 88 / 300: loss 0.598114\n",
      "iteration 88 / 300: loss 0.583767\n",
      "iteration 88 / 300: loss 0.614422\n",
      "iteration 88 / 300: loss 0.591355\n",
      "iteration 88 / 300: loss 0.591452\n",
      "iteration 88 / 300: loss 0.594064\n",
      "iteration 88 / 300: loss 0.596826\n",
      "iteration 88 / 300: loss 0.596783\n",
      "iteration 88 / 300: loss 0.611806\n",
      "iteration 88 / 300: loss 0.607352\n",
      "iteration 88 / 300: loss 0.597112\n",
      "iteration 88 / 300: loss 0.596363\n",
      "iteration 88 / 300: loss 0.627455\n",
      "iteration 88 / 300: loss 0.601660\n",
      "iteration 88 / 300: loss 0.599984\n",
      "iteration 88 / 300: loss 0.622012\n",
      "iteration 88 / 300: loss 0.581522\n",
      "iteration 88 / 300: loss 0.599680\n",
      "iteration 88 / 300: loss 0.591272\n",
      "iteration 88 / 300: loss 0.599992\n",
      "iteration 88 / 300: loss 0.596088\n",
      "iteration 88 / 300: loss 0.590833\n",
      "iteration 88 / 300: loss 0.592042\n",
      "iteration 88 / 300: loss 0.615548\n",
      "iteration 88 / 300: loss 0.621428\n",
      "iteration 88 / 300: loss 0.587336\n",
      "iteration 88 / 300: loss 0.582558\n",
      "iteration 88 / 300: loss 0.585644\n",
      "iteration 88 / 300: loss 0.603752\n",
      "iteration 88 / 300: loss 0.585275\n",
      "iteration 88 / 300: loss 0.578953\n",
      "iteration 88 / 300: loss 0.576484\n",
      "iteration 88 / 300: loss 0.574162\n",
      "iteration 88 / 300: loss 0.600555\n",
      "iteration 88 / 300: loss 0.584555\n",
      "iteration 88 / 300: loss 0.584896\n",
      "iteration 88 / 300: loss 0.568387\n",
      "iteration 88 / 300: loss 0.592096\n",
      "iteration 88 / 300: loss 0.612190\n",
      "iteration 88 / 300: loss 0.608987\n",
      "iteration 88 / 300: loss 0.607686\n",
      "iteration 88 / 300: loss 0.595598\n",
      "iteration 88 / 300: loss 0.592904\n",
      "iteration 88 / 300: loss 0.598062\n",
      "iteration 88 / 300: loss 0.597751\n",
      "iteration 88 / 300: loss 0.601021\n",
      "iteration 88 / 300: loss 0.597499\n",
      "iteration 88 / 300: loss 0.598832\n",
      "iteration 88 / 300: loss 0.587879\n",
      "iteration 88 / 300: loss 0.600569\n",
      "iteration 88 / 300: loss 0.599719\n",
      "iteration 88 / 300: loss 0.617612\n",
      "iteration 88 / 300: loss 0.598937\n",
      "iteration 88 / 300: loss 0.600858\n",
      "iteration 88 / 300: loss 0.605380\n",
      "iteration 88 / 300: loss 0.598665\n",
      "iteration 88 / 300: loss 0.591541\n",
      "iteration 88 / 300: loss 0.580446\n",
      "iteration 88 / 300: loss 0.598294\n",
      "iteration 88 / 300: loss 0.611753\n",
      "iteration 88 / 300: loss 0.613284\n",
      "iteration 88 / 300: loss 0.582270\n",
      "iteration 88 / 300: loss 0.602044\n",
      "iteration 88 / 300: loss 0.609034\n",
      "iteration 88 / 300: loss 0.601866\n",
      "iteration 88 / 300: loss 0.608030\n",
      "iteration 88 / 300: loss 0.620326\n",
      "iteration 88 / 300: loss 0.584891\n",
      "iteration 88 / 300: loss 0.583774\n",
      "iteration 88 / 300: loss 0.628919\n",
      "iteration 88 / 300: loss 0.609456\n",
      "iteration 88 / 300: loss 0.606339\n",
      "iteration 88 / 300: loss 0.599101\n",
      "iteration 88 / 300: loss 0.615954\n",
      "iteration 88 / 300: loss 0.596558\n",
      "iteration 88 / 300: loss 0.581505\n",
      "iteration 88 / 300: loss 0.609869\n",
      "iteration 88 / 300: loss 0.608186\n",
      "iteration 88 / 300: loss 0.598296\n",
      "iteration 88 / 300: loss 0.592094\n",
      "iteration 88 / 300: loss 0.611107\n",
      "iteration 88 / 300: loss 0.598617\n",
      "iteration 88 / 300: loss 0.581439\n",
      "iteration 88 / 300: loss 0.609650\n",
      "iteration 89 / 300: loss 0.578460\n",
      "iteration 89 / 300: loss 0.596283\n",
      "iteration 89 / 300: loss 0.569519\n",
      "iteration 89 / 300: loss 0.597920\n",
      "iteration 89 / 300: loss 0.599006\n",
      "iteration 89 / 300: loss 0.603944\n",
      "iteration 89 / 300: loss 0.615309\n",
      "iteration 89 / 300: loss 0.588292\n",
      "iteration 89 / 300: loss 0.627228\n",
      "iteration 89 / 300: loss 0.592678\n",
      "iteration 89 / 300: loss 0.621579\n",
      "iteration 89 / 300: loss 0.593150\n",
      "iteration 89 / 300: loss 0.600604\n",
      "iteration 89 / 300: loss 0.571052\n",
      "iteration 89 / 300: loss 0.592976\n",
      "iteration 89 / 300: loss 0.600111\n",
      "iteration 89 / 300: loss 0.598108\n",
      "iteration 89 / 300: loss 0.583762\n",
      "iteration 89 / 300: loss 0.614415\n",
      "iteration 89 / 300: loss 0.591348\n",
      "iteration 89 / 300: loss 0.591446\n",
      "iteration 89 / 300: loss 0.594059\n",
      "iteration 89 / 300: loss 0.596817\n",
      "iteration 89 / 300: loss 0.596776\n",
      "iteration 89 / 300: loss 0.611799\n",
      "iteration 89 / 300: loss 0.607343\n",
      "iteration 89 / 300: loss 0.597104\n",
      "iteration 89 / 300: loss 0.596357\n",
      "iteration 89 / 300: loss 0.627449\n",
      "iteration 89 / 300: loss 0.601653\n",
      "iteration 89 / 300: loss 0.599979\n",
      "iteration 89 / 300: loss 0.622006\n",
      "iteration 89 / 300: loss 0.581513\n",
      "iteration 89 / 300: loss 0.599673\n",
      "iteration 89 / 300: loss 0.591264\n",
      "iteration 89 / 300: loss 0.599985\n",
      "iteration 89 / 300: loss 0.596081\n",
      "iteration 89 / 300: loss 0.590826\n",
      "iteration 89 / 300: loss 0.592034\n",
      "iteration 89 / 300: loss 0.615540\n",
      "iteration 89 / 300: loss 0.621421\n",
      "iteration 89 / 300: loss 0.587330\n",
      "iteration 89 / 300: loss 0.582550\n",
      "iteration 89 / 300: loss 0.585637\n",
      "iteration 89 / 300: loss 0.603744\n",
      "iteration 89 / 300: loss 0.585267\n",
      "iteration 89 / 300: loss 0.578946\n",
      "iteration 89 / 300: loss 0.576478\n",
      "iteration 89 / 300: loss 0.574156\n",
      "iteration 89 / 300: loss 0.600550\n",
      "iteration 89 / 300: loss 0.584549\n",
      "iteration 89 / 300: loss 0.584890\n",
      "iteration 89 / 300: loss 0.568381\n",
      "iteration 89 / 300: loss 0.592089\n",
      "iteration 89 / 300: loss 0.612183\n",
      "iteration 89 / 300: loss 0.608981\n",
      "iteration 89 / 300: loss 0.607679\n",
      "iteration 89 / 300: loss 0.595592\n",
      "iteration 89 / 300: loss 0.592898\n",
      "iteration 89 / 300: loss 0.598055\n",
      "iteration 89 / 300: loss 0.597744\n",
      "iteration 89 / 300: loss 0.601014\n",
      "iteration 89 / 300: loss 0.597491\n",
      "iteration 89 / 300: loss 0.598827\n",
      "iteration 89 / 300: loss 0.587872\n",
      "iteration 89 / 300: loss 0.600563\n",
      "iteration 89 / 300: loss 0.599713\n",
      "iteration 89 / 300: loss 0.617605\n",
      "iteration 89 / 300: loss 0.598931\n",
      "iteration 89 / 300: loss 0.600853\n",
      "iteration 89 / 300: loss 0.605373\n",
      "iteration 89 / 300: loss 0.598658\n",
      "iteration 89 / 300: loss 0.591534\n",
      "iteration 89 / 300: loss 0.580440\n",
      "iteration 89 / 300: loss 0.598287\n",
      "iteration 89 / 300: loss 0.611747\n",
      "iteration 89 / 300: loss 0.613278\n",
      "iteration 89 / 300: loss 0.582265\n",
      "iteration 89 / 300: loss 0.602035\n",
      "iteration 89 / 300: loss 0.609027\n",
      "iteration 89 / 300: loss 0.601859\n",
      "iteration 89 / 300: loss 0.608022\n",
      "iteration 89 / 300: loss 0.620318\n",
      "iteration 89 / 300: loss 0.584884\n",
      "iteration 89 / 300: loss 0.583769\n",
      "iteration 89 / 300: loss 0.628912\n",
      "iteration 89 / 300: loss 0.609451\n",
      "iteration 89 / 300: loss 0.606332\n",
      "iteration 89 / 300: loss 0.599095\n",
      "iteration 89 / 300: loss 0.615947\n",
      "iteration 89 / 300: loss 0.596551\n",
      "iteration 89 / 300: loss 0.581498\n",
      "iteration 89 / 300: loss 0.609863\n",
      "iteration 89 / 300: loss 0.608180\n",
      "iteration 89 / 300: loss 0.598289\n",
      "iteration 89 / 300: loss 0.592087\n",
      "iteration 89 / 300: loss 0.611100\n",
      "iteration 89 / 300: loss 0.598611\n",
      "iteration 89 / 300: loss 0.581434\n",
      "iteration 89 / 300: loss 0.609644\n",
      "iteration 90 / 300: loss 0.578452\n",
      "iteration 90 / 300: loss 0.596276\n",
      "iteration 90 / 300: loss 0.569513\n",
      "iteration 90 / 300: loss 0.597913\n",
      "iteration 90 / 300: loss 0.599000\n",
      "iteration 90 / 300: loss 0.603938\n",
      "iteration 90 / 300: loss 0.615305\n",
      "iteration 90 / 300: loss 0.588285\n",
      "iteration 90 / 300: loss 0.627222\n",
      "iteration 90 / 300: loss 0.592671\n",
      "iteration 90 / 300: loss 0.621571\n",
      "iteration 90 / 300: loss 0.593145\n",
      "iteration 90 / 300: loss 0.600598\n",
      "iteration 90 / 300: loss 0.571047\n",
      "iteration 90 / 300: loss 0.592970\n",
      "iteration 90 / 300: loss 0.600105\n",
      "iteration 90 / 300: loss 0.598103\n",
      "iteration 90 / 300: loss 0.583757\n",
      "iteration 90 / 300: loss 0.614410\n",
      "iteration 90 / 300: loss 0.591342\n",
      "iteration 90 / 300: loss 0.591441\n",
      "iteration 90 / 300: loss 0.594054\n",
      "iteration 90 / 300: loss 0.596809\n",
      "iteration 90 / 300: loss 0.596770\n",
      "iteration 90 / 300: loss 0.611793\n",
      "iteration 90 / 300: loss 0.607335\n",
      "iteration 90 / 300: loss 0.597097\n",
      "iteration 90 / 300: loss 0.596352\n",
      "iteration 90 / 300: loss 0.627444\n",
      "iteration 90 / 300: loss 0.601646\n",
      "iteration 90 / 300: loss 0.599973\n",
      "iteration 90 / 300: loss 0.622001\n",
      "iteration 90 / 300: loss 0.581506\n",
      "iteration 90 / 300: loss 0.599667\n",
      "iteration 90 / 300: loss 0.591256\n",
      "iteration 90 / 300: loss 0.599979\n",
      "iteration 90 / 300: loss 0.596075\n",
      "iteration 90 / 300: loss 0.590820\n",
      "iteration 90 / 300: loss 0.592027\n",
      "iteration 90 / 300: loss 0.615533\n",
      "iteration 90 / 300: loss 0.621416\n",
      "iteration 90 / 300: loss 0.587324\n",
      "iteration 90 / 300: loss 0.582544\n",
      "iteration 90 / 300: loss 0.585631\n",
      "iteration 90 / 300: loss 0.603736\n",
      "iteration 90 / 300: loss 0.585260\n",
      "iteration 90 / 300: loss 0.578940\n",
      "iteration 90 / 300: loss 0.576472\n",
      "iteration 90 / 300: loss 0.574151\n",
      "iteration 90 / 300: loss 0.600545\n",
      "iteration 90 / 300: loss 0.584543\n",
      "iteration 90 / 300: loss 0.584885\n",
      "iteration 90 / 300: loss 0.568375\n",
      "iteration 90 / 300: loss 0.592083\n",
      "iteration 90 / 300: loss 0.612176\n",
      "iteration 90 / 300: loss 0.608976\n",
      "iteration 90 / 300: loss 0.607673\n",
      "iteration 90 / 300: loss 0.595586\n",
      "iteration 90 / 300: loss 0.592892\n",
      "iteration 90 / 300: loss 0.598049\n",
      "iteration 90 / 300: loss 0.597738\n",
      "iteration 90 / 300: loss 0.601009\n",
      "iteration 90 / 300: loss 0.597485\n",
      "iteration 90 / 300: loss 0.598822\n",
      "iteration 90 / 300: loss 0.587866\n",
      "iteration 90 / 300: loss 0.600557\n",
      "iteration 90 / 300: loss 0.599707\n",
      "iteration 90 / 300: loss 0.617599\n",
      "iteration 90 / 300: loss 0.598926\n",
      "iteration 90 / 300: loss 0.600848\n",
      "iteration 90 / 300: loss 0.605367\n",
      "iteration 90 / 300: loss 0.598652\n",
      "iteration 90 / 300: loss 0.591529\n",
      "iteration 90 / 300: loss 0.580434\n",
      "iteration 90 / 300: loss 0.598281\n",
      "iteration 90 / 300: loss 0.611741\n",
      "iteration 90 / 300: loss 0.613272\n",
      "iteration 90 / 300: loss 0.582260\n",
      "iteration 90 / 300: loss 0.602028\n",
      "iteration 90 / 300: loss 0.609020\n",
      "iteration 90 / 300: loss 0.601853\n",
      "iteration 90 / 300: loss 0.608014\n",
      "iteration 90 / 300: loss 0.620310\n",
      "iteration 90 / 300: loss 0.584877\n",
      "iteration 90 / 300: loss 0.583765\n",
      "iteration 90 / 300: loss 0.628906\n",
      "iteration 90 / 300: loss 0.609446\n",
      "iteration 90 / 300: loss 0.606326\n",
      "iteration 90 / 300: loss 0.599089\n",
      "iteration 90 / 300: loss 0.615940\n",
      "iteration 90 / 300: loss 0.596545\n",
      "iteration 90 / 300: loss 0.581492\n",
      "iteration 90 / 300: loss 0.609858\n",
      "iteration 90 / 300: loss 0.608175\n",
      "iteration 90 / 300: loss 0.598283\n",
      "iteration 90 / 300: loss 0.592081\n",
      "iteration 90 / 300: loss 0.611094\n",
      "iteration 90 / 300: loss 0.598605\n",
      "iteration 90 / 300: loss 0.581429\n",
      "iteration 90 / 300: loss 0.609638\n",
      "iteration 91 / 300: loss 0.578446\n",
      "iteration 91 / 300: loss 0.596270\n",
      "iteration 91 / 300: loss 0.569508\n",
      "iteration 91 / 300: loss 0.597907\n",
      "iteration 91 / 300: loss 0.598994\n",
      "iteration 91 / 300: loss 0.603932\n",
      "iteration 91 / 300: loss 0.615300\n",
      "iteration 91 / 300: loss 0.588280\n",
      "iteration 91 / 300: loss 0.627218\n",
      "iteration 91 / 300: loss 0.592664\n",
      "iteration 91 / 300: loss 0.621565\n",
      "iteration 91 / 300: loss 0.593140\n",
      "iteration 91 / 300: loss 0.600592\n",
      "iteration 91 / 300: loss 0.571043\n",
      "iteration 91 / 300: loss 0.592964\n",
      "iteration 91 / 300: loss 0.600099\n",
      "iteration 91 / 300: loss 0.598098\n",
      "iteration 91 / 300: loss 0.583753\n",
      "iteration 91 / 300: loss 0.614404\n",
      "iteration 91 / 300: loss 0.591337\n",
      "iteration 91 / 300: loss 0.591436\n",
      "iteration 91 / 300: loss 0.594049\n",
      "iteration 91 / 300: loss 0.596802\n",
      "iteration 91 / 300: loss 0.596765\n",
      "iteration 91 / 300: loss 0.611787\n",
      "iteration 91 / 300: loss 0.607328\n",
      "iteration 91 / 300: loss 0.597091\n",
      "iteration 91 / 300: loss 0.596347\n",
      "iteration 91 / 300: loss 0.627439\n",
      "iteration 91 / 300: loss 0.601640\n",
      "iteration 91 / 300: loss 0.599969\n",
      "iteration 91 / 300: loss 0.621996\n",
      "iteration 91 / 300: loss 0.581499\n",
      "iteration 91 / 300: loss 0.599661\n",
      "iteration 91 / 300: loss 0.591249\n",
      "iteration 91 / 300: loss 0.599973\n",
      "iteration 91 / 300: loss 0.596069\n",
      "iteration 91 / 300: loss 0.590814\n",
      "iteration 91 / 300: loss 0.592021\n",
      "iteration 91 / 300: loss 0.615527\n",
      "iteration 91 / 300: loss 0.621410\n",
      "iteration 91 / 300: loss 0.587318\n",
      "iteration 91 / 300: loss 0.582538\n",
      "iteration 91 / 300: loss 0.585625\n",
      "iteration 91 / 300: loss 0.603730\n",
      "iteration 91 / 300: loss 0.585253\n",
      "iteration 91 / 300: loss 0.578934\n",
      "iteration 91 / 300: loss 0.576467\n",
      "iteration 91 / 300: loss 0.574146\n",
      "iteration 91 / 300: loss 0.600541\n",
      "iteration 91 / 300: loss 0.584538\n",
      "iteration 91 / 300: loss 0.584880\n",
      "iteration 91 / 300: loss 0.568370\n",
      "iteration 91 / 300: loss 0.592078\n",
      "iteration 91 / 300: loss 0.612171\n",
      "iteration 91 / 300: loss 0.608971\n",
      "iteration 91 / 300: loss 0.607667\n",
      "iteration 91 / 300: loss 0.595581\n",
      "iteration 91 / 300: loss 0.592887\n",
      "iteration 91 / 300: loss 0.598043\n",
      "iteration 91 / 300: loss 0.597732\n",
      "iteration 91 / 300: loss 0.601003\n",
      "iteration 91 / 300: loss 0.597479\n",
      "iteration 91 / 300: loss 0.598818\n",
      "iteration 91 / 300: loss 0.587860\n",
      "iteration 91 / 300: loss 0.600551\n",
      "iteration 91 / 300: loss 0.599701\n",
      "iteration 91 / 300: loss 0.617594\n",
      "iteration 91 / 300: loss 0.598921\n",
      "iteration 91 / 300: loss 0.600844\n",
      "iteration 91 / 300: loss 0.605361\n",
      "iteration 91 / 300: loss 0.598646\n",
      "iteration 91 / 300: loss 0.591523\n",
      "iteration 91 / 300: loss 0.580429\n",
      "iteration 91 / 300: loss 0.598275\n",
      "iteration 91 / 300: loss 0.611735\n",
      "iteration 91 / 300: loss 0.613267\n",
      "iteration 91 / 300: loss 0.582256\n",
      "iteration 91 / 300: loss 0.602021\n",
      "iteration 91 / 300: loss 0.609014\n",
      "iteration 91 / 300: loss 0.601847\n",
      "iteration 91 / 300: loss 0.608008\n",
      "iteration 91 / 300: loss 0.620303\n",
      "iteration 91 / 300: loss 0.584872\n",
      "iteration 91 / 300: loss 0.583761\n",
      "iteration 91 / 300: loss 0.628901\n",
      "iteration 91 / 300: loss 0.609441\n",
      "iteration 91 / 300: loss 0.606320\n",
      "iteration 91 / 300: loss 0.599084\n",
      "iteration 91 / 300: loss 0.615934\n",
      "iteration 91 / 300: loss 0.596540\n",
      "iteration 91 / 300: loss 0.581486\n",
      "iteration 91 / 300: loss 0.609853\n",
      "iteration 91 / 300: loss 0.608170\n",
      "iteration 91 / 300: loss 0.598277\n",
      "iteration 91 / 300: loss 0.592075\n",
      "iteration 91 / 300: loss 0.611088\n",
      "iteration 91 / 300: loss 0.598600\n",
      "iteration 91 / 300: loss 0.581425\n",
      "iteration 91 / 300: loss 0.609632\n",
      "iteration 92 / 300: loss 0.578440\n",
      "iteration 92 / 300: loss 0.596265\n",
      "iteration 92 / 300: loss 0.569503\n",
      "iteration 92 / 300: loss 0.597902\n",
      "iteration 92 / 300: loss 0.598989\n",
      "iteration 92 / 300: loss 0.603927\n",
      "iteration 92 / 300: loss 0.615297\n",
      "iteration 92 / 300: loss 0.588275\n",
      "iteration 92 / 300: loss 0.627213\n",
      "iteration 92 / 300: loss 0.592658\n",
      "iteration 92 / 300: loss 0.621558\n",
      "iteration 92 / 300: loss 0.593136\n",
      "iteration 92 / 300: loss 0.600588\n",
      "iteration 92 / 300: loss 0.571039\n",
      "iteration 92 / 300: loss 0.592959\n",
      "iteration 92 / 300: loss 0.600094\n",
      "iteration 92 / 300: loss 0.598094\n",
      "iteration 92 / 300: loss 0.583749\n",
      "iteration 92 / 300: loss 0.614400\n",
      "iteration 92 / 300: loss 0.591332\n",
      "iteration 92 / 300: loss 0.591432\n",
      "iteration 92 / 300: loss 0.594045\n",
      "iteration 92 / 300: loss 0.596796\n",
      "iteration 92 / 300: loss 0.596760\n",
      "iteration 92 / 300: loss 0.611782\n",
      "iteration 92 / 300: loss 0.607321\n",
      "iteration 92 / 300: loss 0.597085\n",
      "iteration 92 / 300: loss 0.596342\n",
      "iteration 92 / 300: loss 0.627434\n",
      "iteration 92 / 300: loss 0.601635\n",
      "iteration 92 / 300: loss 0.599964\n",
      "iteration 92 / 300: loss 0.621992\n",
      "iteration 92 / 300: loss 0.581493\n",
      "iteration 92 / 300: loss 0.599655\n",
      "iteration 92 / 300: loss 0.591242\n",
      "iteration 92 / 300: loss 0.599968\n",
      "iteration 92 / 300: loss 0.596064\n",
      "iteration 92 / 300: loss 0.590809\n",
      "iteration 92 / 300: loss 0.592015\n",
      "iteration 92 / 300: loss 0.615521\n",
      "iteration 92 / 300: loss 0.621406\n",
      "iteration 92 / 300: loss 0.587313\n",
      "iteration 92 / 300: loss 0.582533\n",
      "iteration 92 / 300: loss 0.585620\n",
      "iteration 92 / 300: loss 0.603723\n",
      "iteration 92 / 300: loss 0.585248\n",
      "iteration 92 / 300: loss 0.578929\n",
      "iteration 92 / 300: loss 0.576462\n",
      "iteration 92 / 300: loss 0.574141\n",
      "iteration 92 / 300: loss 0.600537\n",
      "iteration 92 / 300: loss 0.584534\n",
      "iteration 92 / 300: loss 0.584875\n",
      "iteration 92 / 300: loss 0.568366\n",
      "iteration 92 / 300: loss 0.592073\n",
      "iteration 92 / 300: loss 0.612165\n",
      "iteration 92 / 300: loss 0.608966\n",
      "iteration 92 / 300: loss 0.607662\n",
      "iteration 92 / 300: loss 0.595577\n",
      "iteration 92 / 300: loss 0.592882\n",
      "iteration 92 / 300: loss 0.598038\n",
      "iteration 92 / 300: loss 0.597727\n",
      "iteration 92 / 300: loss 0.600999\n",
      "iteration 92 / 300: loss 0.597473\n",
      "iteration 92 / 300: loss 0.598814\n",
      "iteration 92 / 300: loss 0.587855\n",
      "iteration 92 / 300: loss 0.600546\n",
      "iteration 92 / 300: loss 0.599696\n",
      "iteration 92 / 300: loss 0.617589\n",
      "iteration 92 / 300: loss 0.598916\n",
      "iteration 92 / 300: loss 0.600839\n",
      "iteration 92 / 300: loss 0.605356\n",
      "iteration 92 / 300: loss 0.598641\n",
      "iteration 92 / 300: loss 0.591519\n",
      "iteration 92 / 300: loss 0.580425\n",
      "iteration 92 / 300: loss 0.598270\n",
      "iteration 92 / 300: loss 0.611731\n",
      "iteration 92 / 300: loss 0.613262\n",
      "iteration 92 / 300: loss 0.582252\n",
      "iteration 92 / 300: loss 0.602014\n",
      "iteration 92 / 300: loss 0.609008\n",
      "iteration 92 / 300: loss 0.601842\n",
      "iteration 92 / 300: loss 0.608002\n",
      "iteration 92 / 300: loss 0.620297\n",
      "iteration 92 / 300: loss 0.584866\n",
      "iteration 92 / 300: loss 0.583757\n",
      "iteration 92 / 300: loss 0.628896\n",
      "iteration 92 / 300: loss 0.609437\n",
      "iteration 92 / 300: loss 0.606315\n",
      "iteration 92 / 300: loss 0.599079\n",
      "iteration 92 / 300: loss 0.615929\n",
      "iteration 92 / 300: loss 0.596535\n",
      "iteration 92 / 300: loss 0.581481\n",
      "iteration 92 / 300: loss 0.609849\n",
      "iteration 92 / 300: loss 0.608166\n",
      "iteration 92 / 300: loss 0.598272\n",
      "iteration 92 / 300: loss 0.592070\n",
      "iteration 92 / 300: loss 0.611082\n",
      "iteration 92 / 300: loss 0.598595\n",
      "iteration 92 / 300: loss 0.581421\n",
      "iteration 92 / 300: loss 0.609627\n",
      "iteration 93 / 300: loss 0.578435\n",
      "iteration 93 / 300: loss 0.596260\n",
      "iteration 93 / 300: loss 0.569498\n",
      "iteration 93 / 300: loss 0.597897\n",
      "iteration 93 / 300: loss 0.598984\n",
      "iteration 93 / 300: loss 0.603922\n",
      "iteration 93 / 300: loss 0.615293\n",
      "iteration 93 / 300: loss 0.588270\n",
      "iteration 93 / 300: loss 0.627209\n",
      "iteration 93 / 300: loss 0.592652\n",
      "iteration 93 / 300: loss 0.621553\n",
      "iteration 93 / 300: loss 0.593132\n",
      "iteration 93 / 300: loss 0.600583\n",
      "iteration 93 / 300: loss 0.571035\n",
      "iteration 93 / 300: loss 0.592955\n",
      "iteration 93 / 300: loss 0.600089\n",
      "iteration 93 / 300: loss 0.598090\n",
      "iteration 93 / 300: loss 0.583745\n",
      "iteration 93 / 300: loss 0.614395\n",
      "iteration 93 / 300: loss 0.591328\n",
      "iteration 93 / 300: loss 0.591428\n",
      "iteration 93 / 300: loss 0.594041\n",
      "iteration 93 / 300: loss 0.596790\n",
      "iteration 93 / 300: loss 0.596755\n",
      "iteration 93 / 300: loss 0.611778\n",
      "iteration 93 / 300: loss 0.607315\n",
      "iteration 93 / 300: loss 0.597080\n",
      "iteration 93 / 300: loss 0.596338\n",
      "iteration 93 / 300: loss 0.627430\n",
      "iteration 93 / 300: loss 0.601630\n",
      "iteration 93 / 300: loss 0.599960\n",
      "iteration 93 / 300: loss 0.621988\n",
      "iteration 93 / 300: loss 0.581488\n",
      "iteration 93 / 300: loss 0.599650\n",
      "iteration 93 / 300: loss 0.591237\n",
      "iteration 93 / 300: loss 0.599964\n",
      "iteration 93 / 300: loss 0.596059\n",
      "iteration 93 / 300: loss 0.590804\n",
      "iteration 93 / 300: loss 0.592010\n",
      "iteration 93 / 300: loss 0.615516\n",
      "iteration 93 / 300: loss 0.621401\n",
      "iteration 93 / 300: loss 0.587309\n",
      "iteration 93 / 300: loss 0.582528\n",
      "iteration 93 / 300: loss 0.585616\n",
      "iteration 93 / 300: loss 0.603718\n",
      "iteration 93 / 300: loss 0.585242\n",
      "iteration 93 / 300: loss 0.578924\n",
      "iteration 93 / 300: loss 0.576458\n",
      "iteration 93 / 300: loss 0.574137\n",
      "iteration 93 / 300: loss 0.600534\n",
      "iteration 93 / 300: loss 0.584529\n",
      "iteration 93 / 300: loss 0.584871\n",
      "iteration 93 / 300: loss 0.568362\n",
      "iteration 93 / 300: loss 0.592068\n",
      "iteration 93 / 300: loss 0.612161\n",
      "iteration 93 / 300: loss 0.608962\n",
      "iteration 93 / 300: loss 0.607657\n",
      "iteration 93 / 300: loss 0.595572\n",
      "iteration 93 / 300: loss 0.592878\n",
      "iteration 93 / 300: loss 0.598033\n",
      "iteration 93 / 300: loss 0.597722\n",
      "iteration 93 / 300: loss 0.600994\n",
      "iteration 93 / 300: loss 0.597468\n",
      "iteration 93 / 300: loss 0.598810\n",
      "iteration 93 / 300: loss 0.587850\n",
      "iteration 93 / 300: loss 0.600542\n",
      "iteration 93 / 300: loss 0.599692\n",
      "iteration 93 / 300: loss 0.617584\n",
      "iteration 93 / 300: loss 0.598912\n",
      "iteration 93 / 300: loss 0.600836\n",
      "iteration 93 / 300: loss 0.605351\n",
      "iteration 93 / 300: loss 0.598636\n",
      "iteration 93 / 300: loss 0.591514\n",
      "iteration 93 / 300: loss 0.580421\n",
      "iteration 93 / 300: loss 0.598265\n",
      "iteration 93 / 300: loss 0.611726\n",
      "iteration 93 / 300: loss 0.613258\n",
      "iteration 93 / 300: loss 0.582248\n",
      "iteration 93 / 300: loss 0.602009\n",
      "iteration 93 / 300: loss 0.609003\n",
      "iteration 93 / 300: loss 0.601838\n",
      "iteration 93 / 300: loss 0.607996\n",
      "iteration 93 / 300: loss 0.620291\n",
      "iteration 93 / 300: loss 0.584862\n",
      "iteration 93 / 300: loss 0.583753\n",
      "iteration 93 / 300: loss 0.628891\n",
      "iteration 93 / 300: loss 0.609434\n",
      "iteration 93 / 300: loss 0.606310\n",
      "iteration 93 / 300: loss 0.599075\n",
      "iteration 93 / 300: loss 0.615924\n",
      "iteration 93 / 300: loss 0.596531\n",
      "iteration 93 / 300: loss 0.581476\n",
      "iteration 93 / 300: loss 0.609845\n",
      "iteration 93 / 300: loss 0.608162\n",
      "iteration 93 / 300: loss 0.598268\n",
      "iteration 93 / 300: loss 0.592066\n",
      "iteration 93 / 300: loss 0.611077\n",
      "iteration 93 / 300: loss 0.598591\n",
      "iteration 93 / 300: loss 0.581417\n",
      "iteration 93 / 300: loss 0.609623\n",
      "iteration 94 / 300: loss 0.578430\n",
      "iteration 94 / 300: loss 0.596256\n",
      "iteration 94 / 300: loss 0.569494\n",
      "iteration 94 / 300: loss 0.597892\n",
      "iteration 94 / 300: loss 0.598980\n",
      "iteration 94 / 300: loss 0.603918\n",
      "iteration 94 / 300: loss 0.615290\n",
      "iteration 94 / 300: loss 0.588266\n",
      "iteration 94 / 300: loss 0.627206\n",
      "iteration 94 / 300: loss 0.592647\n",
      "iteration 94 / 300: loss 0.621548\n",
      "iteration 94 / 300: loss 0.593128\n",
      "iteration 94 / 300: loss 0.600579\n",
      "iteration 94 / 300: loss 0.571032\n",
      "iteration 94 / 300: loss 0.592951\n",
      "iteration 94 / 300: loss 0.600084\n",
      "iteration 94 / 300: loss 0.598086\n",
      "iteration 94 / 300: loss 0.583742\n",
      "iteration 94 / 300: loss 0.614392\n",
      "iteration 94 / 300: loss 0.591324\n",
      "iteration 94 / 300: loss 0.591424\n",
      "iteration 94 / 300: loss 0.594038\n",
      "iteration 94 / 300: loss 0.596785\n",
      "iteration 94 / 300: loss 0.596751\n",
      "iteration 94 / 300: loss 0.611774\n",
      "iteration 94 / 300: loss 0.607310\n",
      "iteration 94 / 300: loss 0.597076\n",
      "iteration 94 / 300: loss 0.596335\n",
      "iteration 94 / 300: loss 0.627427\n",
      "iteration 94 / 300: loss 0.601626\n",
      "iteration 94 / 300: loss 0.599957\n",
      "iteration 94 / 300: loss 0.621985\n",
      "iteration 94 / 300: loss 0.581482\n",
      "iteration 94 / 300: loss 0.599646\n",
      "iteration 94 / 300: loss 0.591231\n",
      "iteration 94 / 300: loss 0.599959\n",
      "iteration 94 / 300: loss 0.596055\n",
      "iteration 94 / 300: loss 0.590800\n",
      "iteration 94 / 300: loss 0.592005\n",
      "iteration 94 / 300: loss 0.615512\n",
      "iteration 94 / 300: loss 0.621397\n",
      "iteration 94 / 300: loss 0.587305\n",
      "iteration 94 / 300: loss 0.582524\n",
      "iteration 94 / 300: loss 0.585612\n",
      "iteration 94 / 300: loss 0.603713\n",
      "iteration 94 / 300: loss 0.585238\n",
      "iteration 94 / 300: loss 0.578920\n",
      "iteration 94 / 300: loss 0.576454\n",
      "iteration 94 / 300: loss 0.574133\n",
      "iteration 94 / 300: loss 0.600531\n",
      "iteration 94 / 300: loss 0.584526\n",
      "iteration 94 / 300: loss 0.584868\n",
      "iteration 94 / 300: loss 0.568358\n",
      "iteration 94 / 300: loss 0.592064\n",
      "iteration 94 / 300: loss 0.612157\n",
      "iteration 94 / 300: loss 0.608958\n",
      "iteration 94 / 300: loss 0.607653\n",
      "iteration 94 / 300: loss 0.595569\n",
      "iteration 94 / 300: loss 0.592874\n",
      "iteration 94 / 300: loss 0.598029\n",
      "iteration 94 / 300: loss 0.597718\n",
      "iteration 94 / 300: loss 0.600990\n",
      "iteration 94 / 300: loss 0.597464\n",
      "iteration 94 / 300: loss 0.598807\n",
      "iteration 94 / 300: loss 0.587846\n",
      "iteration 94 / 300: loss 0.600538\n",
      "iteration 94 / 300: loss 0.599688\n",
      "iteration 94 / 300: loss 0.617580\n",
      "iteration 94 / 300: loss 0.598909\n",
      "iteration 94 / 300: loss 0.600833\n",
      "iteration 94 / 300: loss 0.605346\n",
      "iteration 94 / 300: loss 0.598632\n",
      "iteration 94 / 300: loss 0.591511\n",
      "iteration 94 / 300: loss 0.580417\n",
      "iteration 94 / 300: loss 0.598261\n",
      "iteration 94 / 300: loss 0.611722\n",
      "iteration 94 / 300: loss 0.613255\n",
      "iteration 94 / 300: loss 0.582245\n",
      "iteration 94 / 300: loss 0.602004\n",
      "iteration 94 / 300: loss 0.608999\n",
      "iteration 94 / 300: loss 0.601833\n",
      "iteration 94 / 300: loss 0.607991\n",
      "iteration 94 / 300: loss 0.620286\n",
      "iteration 94 / 300: loss 0.584857\n",
      "iteration 94 / 300: loss 0.583750\n",
      "iteration 94 / 300: loss 0.628887\n",
      "iteration 94 / 300: loss 0.609430\n",
      "iteration 94 / 300: loss 0.606306\n",
      "iteration 94 / 300: loss 0.599071\n",
      "iteration 94 / 300: loss 0.615919\n",
      "iteration 94 / 300: loss 0.596527\n",
      "iteration 94 / 300: loss 0.581471\n",
      "iteration 94 / 300: loss 0.609841\n",
      "iteration 94 / 300: loss 0.608159\n",
      "iteration 94 / 300: loss 0.598264\n",
      "iteration 94 / 300: loss 0.592062\n",
      "iteration 94 / 300: loss 0.611073\n",
      "iteration 94 / 300: loss 0.598587\n",
      "iteration 94 / 300: loss 0.581414\n",
      "iteration 94 / 300: loss 0.609618\n",
      "iteration 95 / 300: loss 0.578426\n",
      "iteration 95 / 300: loss 0.596252\n",
      "iteration 95 / 300: loss 0.569490\n",
      "iteration 95 / 300: loss 0.597888\n",
      "iteration 95 / 300: loss 0.598976\n",
      "iteration 95 / 300: loss 0.603914\n",
      "iteration 95 / 300: loss 0.615288\n",
      "iteration 95 / 300: loss 0.588262\n",
      "iteration 95 / 300: loss 0.627202\n",
      "iteration 95 / 300: loss 0.592643\n",
      "iteration 95 / 300: loss 0.621543\n",
      "iteration 95 / 300: loss 0.593125\n",
      "iteration 95 / 300: loss 0.600575\n",
      "iteration 95 / 300: loss 0.571029\n",
      "iteration 95 / 300: loss 0.592947\n",
      "iteration 95 / 300: loss 0.600080\n",
      "iteration 95 / 300: loss 0.598083\n",
      "iteration 95 / 300: loss 0.583739\n",
      "iteration 95 / 300: loss 0.614388\n",
      "iteration 95 / 300: loss 0.591320\n",
      "iteration 95 / 300: loss 0.591421\n",
      "iteration 95 / 300: loss 0.594035\n",
      "iteration 95 / 300: loss 0.596780\n",
      "iteration 95 / 300: loss 0.596747\n",
      "iteration 95 / 300: loss 0.611770\n",
      "iteration 95 / 300: loss 0.607305\n",
      "iteration 95 / 300: loss 0.597071\n",
      "iteration 95 / 300: loss 0.596332\n",
      "iteration 95 / 300: loss 0.627423\n",
      "iteration 95 / 300: loss 0.601622\n",
      "iteration 95 / 300: loss 0.599954\n",
      "iteration 95 / 300: loss 0.621982\n",
      "iteration 95 / 300: loss 0.581478\n",
      "iteration 95 / 300: loss 0.599642\n",
      "iteration 95 / 300: loss 0.591227\n",
      "iteration 95 / 300: loss 0.599956\n",
      "iteration 95 / 300: loss 0.596051\n",
      "iteration 95 / 300: loss 0.590796\n",
      "iteration 95 / 300: loss 0.592001\n",
      "iteration 95 / 300: loss 0.615507\n",
      "iteration 95 / 300: loss 0.621394\n",
      "iteration 95 / 300: loss 0.587301\n",
      "iteration 95 / 300: loss 0.582520\n",
      "iteration 95 / 300: loss 0.585608\n",
      "iteration 95 / 300: loss 0.603708\n",
      "iteration 95 / 300: loss 0.585233\n",
      "iteration 95 / 300: loss 0.578916\n",
      "iteration 95 / 300: loss 0.576451\n",
      "iteration 95 / 300: loss 0.574130\n",
      "iteration 95 / 300: loss 0.600528\n",
      "iteration 95 / 300: loss 0.584522\n",
      "iteration 95 / 300: loss 0.584865\n",
      "iteration 95 / 300: loss 0.568355\n",
      "iteration 95 / 300: loss 0.592060\n",
      "iteration 95 / 300: loss 0.612153\n",
      "iteration 95 / 300: loss 0.608955\n",
      "iteration 95 / 300: loss 0.607649\n",
      "iteration 95 / 300: loss 0.595565\n",
      "iteration 95 / 300: loss 0.592870\n",
      "iteration 95 / 300: loss 0.598025\n",
      "iteration 95 / 300: loss 0.597714\n",
      "iteration 95 / 300: loss 0.600987\n",
      "iteration 95 / 300: loss 0.597460\n",
      "iteration 95 / 300: loss 0.598804\n",
      "iteration 95 / 300: loss 0.587842\n",
      "iteration 95 / 300: loss 0.600534\n",
      "iteration 95 / 300: loss 0.599685\n",
      "iteration 95 / 300: loss 0.617576\n",
      "iteration 95 / 300: loss 0.598906\n",
      "iteration 95 / 300: loss 0.600830\n",
      "iteration 95 / 300: loss 0.605342\n",
      "iteration 95 / 300: loss 0.598628\n",
      "iteration 95 / 300: loss 0.591507\n",
      "iteration 95 / 300: loss 0.580414\n",
      "iteration 95 / 300: loss 0.598257\n",
      "iteration 95 / 300: loss 0.611719\n",
      "iteration 95 / 300: loss 0.613251\n",
      "iteration 95 / 300: loss 0.582242\n",
      "iteration 95 / 300: loss 0.601999\n",
      "iteration 95 / 300: loss 0.608995\n",
      "iteration 95 / 300: loss 0.601830\n",
      "iteration 95 / 300: loss 0.607987\n",
      "iteration 95 / 300: loss 0.620281\n",
      "iteration 95 / 300: loss 0.584854\n",
      "iteration 95 / 300: loss 0.583748\n",
      "iteration 95 / 300: loss 0.628884\n",
      "iteration 95 / 300: loss 0.609427\n",
      "iteration 95 / 300: loss 0.606302\n",
      "iteration 95 / 300: loss 0.599068\n",
      "iteration 95 / 300: loss 0.615915\n",
      "iteration 95 / 300: loss 0.596523\n",
      "iteration 95 / 300: loss 0.581467\n",
      "iteration 95 / 300: loss 0.609838\n",
      "iteration 95 / 300: loss 0.608156\n",
      "iteration 95 / 300: loss 0.598260\n",
      "iteration 95 / 300: loss 0.592058\n",
      "iteration 95 / 300: loss 0.611069\n",
      "iteration 95 / 300: loss 0.598583\n",
      "iteration 95 / 300: loss 0.581411\n",
      "iteration 95 / 300: loss 0.609615\n",
      "iteration 96 / 300: loss 0.578422\n",
      "iteration 96 / 300: loss 0.596248\n",
      "iteration 96 / 300: loss 0.569487\n",
      "iteration 96 / 300: loss 0.597884\n",
      "iteration 96 / 300: loss 0.598973\n",
      "iteration 96 / 300: loss 0.603910\n",
      "iteration 96 / 300: loss 0.615285\n",
      "iteration 96 / 300: loss 0.588259\n",
      "iteration 96 / 300: loss 0.627199\n",
      "iteration 96 / 300: loss 0.592639\n",
      "iteration 96 / 300: loss 0.621539\n",
      "iteration 96 / 300: loss 0.593122\n",
      "iteration 96 / 300: loss 0.600572\n",
      "iteration 96 / 300: loss 0.571026\n",
      "iteration 96 / 300: loss 0.592944\n",
      "iteration 96 / 300: loss 0.600077\n",
      "iteration 96 / 300: loss 0.598080\n",
      "iteration 96 / 300: loss 0.583737\n",
      "iteration 96 / 300: loss 0.614385\n",
      "iteration 96 / 300: loss 0.591317\n",
      "iteration 96 / 300: loss 0.591418\n",
      "iteration 96 / 300: loss 0.594032\n",
      "iteration 96 / 300: loss 0.596775\n",
      "iteration 96 / 300: loss 0.596744\n",
      "iteration 96 / 300: loss 0.611767\n",
      "iteration 96 / 300: loss 0.607300\n",
      "iteration 96 / 300: loss 0.597068\n",
      "iteration 96 / 300: loss 0.596329\n",
      "iteration 96 / 300: loss 0.627420\n",
      "iteration 96 / 300: loss 0.601618\n",
      "iteration 96 / 300: loss 0.599951\n",
      "iteration 96 / 300: loss 0.621979\n",
      "iteration 96 / 300: loss 0.581474\n",
      "iteration 96 / 300: loss 0.599638\n",
      "iteration 96 / 300: loss 0.591223\n",
      "iteration 96 / 300: loss 0.599952\n",
      "iteration 96 / 300: loss 0.596048\n",
      "iteration 96 / 300: loss 0.590793\n",
      "iteration 96 / 300: loss 0.591997\n",
      "iteration 96 / 300: loss 0.615504\n",
      "iteration 96 / 300: loss 0.621391\n",
      "iteration 96 / 300: loss 0.587298\n",
      "iteration 96 / 300: loss 0.582516\n",
      "iteration 96 / 300: loss 0.585604\n",
      "iteration 96 / 300: loss 0.603704\n",
      "iteration 96 / 300: loss 0.585229\n",
      "iteration 96 / 300: loss 0.578913\n",
      "iteration 96 / 300: loss 0.576448\n",
      "iteration 96 / 300: loss 0.574127\n",
      "iteration 96 / 300: loss 0.600525\n",
      "iteration 96 / 300: loss 0.584519\n",
      "iteration 96 / 300: loss 0.584862\n",
      "iteration 96 / 300: loss 0.568352\n",
      "iteration 96 / 300: loss 0.592057\n",
      "iteration 96 / 300: loss 0.612149\n",
      "iteration 96 / 300: loss 0.608952\n",
      "iteration 96 / 300: loss 0.607646\n",
      "iteration 96 / 300: loss 0.595562\n",
      "iteration 96 / 300: loss 0.592867\n",
      "iteration 96 / 300: loss 0.598022\n",
      "iteration 96 / 300: loss 0.597710\n",
      "iteration 96 / 300: loss 0.600983\n",
      "iteration 96 / 300: loss 0.597456\n",
      "iteration 96 / 300: loss 0.598801\n",
      "iteration 96 / 300: loss 0.587839\n",
      "iteration 96 / 300: loss 0.600531\n",
      "iteration 96 / 300: loss 0.599681\n",
      "iteration 96 / 300: loss 0.617573\n",
      "iteration 96 / 300: loss 0.598903\n",
      "iteration 96 / 300: loss 0.600827\n",
      "iteration 96 / 300: loss 0.605339\n",
      "iteration 96 / 300: loss 0.598625\n",
      "iteration 96 / 300: loss 0.591504\n",
      "iteration 96 / 300: loss 0.580411\n",
      "iteration 96 / 300: loss 0.598254\n",
      "iteration 96 / 300: loss 0.611715\n",
      "iteration 96 / 300: loss 0.613248\n",
      "iteration 96 / 300: loss 0.582239\n",
      "iteration 96 / 300: loss 0.601995\n",
      "iteration 96 / 300: loss 0.608991\n",
      "iteration 96 / 300: loss 0.601826\n",
      "iteration 96 / 300: loss 0.607983\n",
      "iteration 96 / 300: loss 0.620277\n",
      "iteration 96 / 300: loss 0.584850\n",
      "iteration 96 / 300: loss 0.583745\n",
      "iteration 96 / 300: loss 0.628880\n",
      "iteration 96 / 300: loss 0.609425\n",
      "iteration 96 / 300: loss 0.606298\n",
      "iteration 96 / 300: loss 0.599065\n",
      "iteration 96 / 300: loss 0.615912\n",
      "iteration 96 / 300: loss 0.596520\n",
      "iteration 96 / 300: loss 0.581464\n",
      "iteration 96 / 300: loss 0.609835\n",
      "iteration 96 / 300: loss 0.608153\n",
      "iteration 96 / 300: loss 0.598256\n",
      "iteration 96 / 300: loss 0.592054\n",
      "iteration 96 / 300: loss 0.611065\n",
      "iteration 96 / 300: loss 0.598580\n",
      "iteration 96 / 300: loss 0.581408\n",
      "iteration 96 / 300: loss 0.609611\n",
      "iteration 97 / 300: loss 0.578418\n",
      "iteration 97 / 300: loss 0.596245\n",
      "iteration 97 / 300: loss 0.569484\n",
      "iteration 97 / 300: loss 0.597881\n",
      "iteration 97 / 300: loss 0.598970\n",
      "iteration 97 / 300: loss 0.603907\n",
      "iteration 97 / 300: loss 0.615283\n",
      "iteration 97 / 300: loss 0.588256\n",
      "iteration 97 / 300: loss 0.627197\n",
      "iteration 97 / 300: loss 0.592635\n",
      "iteration 97 / 300: loss 0.621535\n",
      "iteration 97 / 300: loss 0.593119\n",
      "iteration 97 / 300: loss 0.600569\n",
      "iteration 97 / 300: loss 0.571023\n",
      "iteration 97 / 300: loss 0.592940\n",
      "iteration 97 / 300: loss 0.600073\n",
      "iteration 97 / 300: loss 0.598078\n",
      "iteration 97 / 300: loss 0.583734\n",
      "iteration 97 / 300: loss 0.614382\n",
      "iteration 97 / 300: loss 0.591314\n",
      "iteration 97 / 300: loss 0.591415\n",
      "iteration 97 / 300: loss 0.594029\n",
      "iteration 97 / 300: loss 0.596772\n",
      "iteration 97 / 300: loss 0.596741\n",
      "iteration 97 / 300: loss 0.611764\n",
      "iteration 97 / 300: loss 0.607296\n",
      "iteration 97 / 300: loss 0.597064\n",
      "iteration 97 / 300: loss 0.596326\n",
      "iteration 97 / 300: loss 0.627417\n",
      "iteration 97 / 300: loss 0.601615\n",
      "iteration 97 / 300: loss 0.599948\n",
      "iteration 97 / 300: loss 0.621976\n",
      "iteration 97 / 300: loss 0.581470\n",
      "iteration 97 / 300: loss 0.599635\n",
      "iteration 97 / 300: loss 0.591219\n",
      "iteration 97 / 300: loss 0.599949\n",
      "iteration 97 / 300: loss 0.596045\n",
      "iteration 97 / 300: loss 0.590790\n",
      "iteration 97 / 300: loss 0.591994\n",
      "iteration 97 / 300: loss 0.615500\n",
      "iteration 97 / 300: loss 0.621388\n",
      "iteration 97 / 300: loss 0.587295\n",
      "iteration 97 / 300: loss 0.582513\n",
      "iteration 97 / 300: loss 0.585601\n",
      "iteration 97 / 300: loss 0.603701\n",
      "iteration 97 / 300: loss 0.585226\n",
      "iteration 97 / 300: loss 0.578910\n",
      "iteration 97 / 300: loss 0.576445\n",
      "iteration 97 / 300: loss 0.574124\n",
      "iteration 97 / 300: loss 0.600523\n",
      "iteration 97 / 300: loss 0.584516\n",
      "iteration 97 / 300: loss 0.584859\n",
      "iteration 97 / 300: loss 0.568349\n",
      "iteration 97 / 300: loss 0.592054\n",
      "iteration 97 / 300: loss 0.612146\n",
      "iteration 97 / 300: loss 0.608949\n",
      "iteration 97 / 300: loss 0.607643\n",
      "iteration 97 / 300: loss 0.595560\n",
      "iteration 97 / 300: loss 0.592864\n",
      "iteration 97 / 300: loss 0.598018\n",
      "iteration 97 / 300: loss 0.597707\n",
      "iteration 97 / 300: loss 0.600981\n",
      "iteration 97 / 300: loss 0.597453\n",
      "iteration 97 / 300: loss 0.598799\n",
      "iteration 97 / 300: loss 0.587836\n",
      "iteration 97 / 300: loss 0.600528\n",
      "iteration 97 / 300: loss 0.599678\n",
      "iteration 97 / 300: loss 0.617570\n",
      "iteration 97 / 300: loss 0.598900\n",
      "iteration 97 / 300: loss 0.600824\n",
      "iteration 97 / 300: loss 0.605336\n",
      "iteration 97 / 300: loss 0.598622\n",
      "iteration 97 / 300: loss 0.591501\n",
      "iteration 97 / 300: loss 0.580408\n",
      "iteration 97 / 300: loss 0.598251\n",
      "iteration 97 / 300: loss 0.611712\n",
      "iteration 97 / 300: loss 0.613245\n",
      "iteration 97 / 300: loss 0.582237\n",
      "iteration 97 / 300: loss 0.601991\n",
      "iteration 97 / 300: loss 0.608988\n",
      "iteration 97 / 300: loss 0.601823\n",
      "iteration 97 / 300: loss 0.607979\n",
      "iteration 97 / 300: loss 0.620273\n",
      "iteration 97 / 300: loss 0.584847\n",
      "iteration 97 / 300: loss 0.583743\n",
      "iteration 97 / 300: loss 0.628877\n",
      "iteration 97 / 300: loss 0.609422\n",
      "iteration 97 / 300: loss 0.606295\n",
      "iteration 97 / 300: loss 0.599062\n",
      "iteration 97 / 300: loss 0.615908\n",
      "iteration 97 / 300: loss 0.596517\n",
      "iteration 97 / 300: loss 0.581461\n",
      "iteration 97 / 300: loss 0.609832\n",
      "iteration 97 / 300: loss 0.608150\n",
      "iteration 97 / 300: loss 0.598253\n",
      "iteration 97 / 300: loss 0.592051\n",
      "iteration 97 / 300: loss 0.611062\n",
      "iteration 97 / 300: loss 0.598577\n",
      "iteration 97 / 300: loss 0.581405\n",
      "iteration 97 / 300: loss 0.609608\n",
      "iteration 98 / 300: loss 0.578415\n",
      "iteration 98 / 300: loss 0.596242\n",
      "iteration 98 / 300: loss 0.569481\n",
      "iteration 98 / 300: loss 0.597878\n",
      "iteration 98 / 300: loss 0.598967\n",
      "iteration 98 / 300: loss 0.603904\n",
      "iteration 98 / 300: loss 0.615281\n",
      "iteration 98 / 300: loss 0.588253\n",
      "iteration 98 / 300: loss 0.627194\n",
      "iteration 98 / 300: loss 0.592632\n",
      "iteration 98 / 300: loss 0.621532\n",
      "iteration 98 / 300: loss 0.593117\n",
      "iteration 98 / 300: loss 0.600567\n",
      "iteration 98 / 300: loss 0.571021\n",
      "iteration 98 / 300: loss 0.592938\n",
      "iteration 98 / 300: loss 0.600071\n",
      "iteration 98 / 300: loss 0.598075\n",
      "iteration 98 / 300: loss 0.583732\n",
      "iteration 98 / 300: loss 0.614379\n",
      "iteration 98 / 300: loss 0.591311\n",
      "iteration 98 / 300: loss 0.591413\n",
      "iteration 98 / 300: loss 0.594027\n",
      "iteration 98 / 300: loss 0.596768\n",
      "iteration 98 / 300: loss 0.596738\n",
      "iteration 98 / 300: loss 0.611761\n",
      "iteration 98 / 300: loss 0.607293\n",
      "iteration 98 / 300: loss 0.597061\n",
      "iteration 98 / 300: loss 0.596324\n",
      "iteration 98 / 300: loss 0.627415\n",
      "iteration 98 / 300: loss 0.601612\n",
      "iteration 98 / 300: loss 0.599946\n",
      "iteration 98 / 300: loss 0.621974\n",
      "iteration 98 / 300: loss 0.581467\n",
      "iteration 98 / 300: loss 0.599632\n",
      "iteration 98 / 300: loss 0.591215\n",
      "iteration 98 / 300: loss 0.599946\n",
      "iteration 98 / 300: loss 0.596042\n",
      "iteration 98 / 300: loss 0.590787\n",
      "iteration 98 / 300: loss 0.591991\n",
      "iteration 98 / 300: loss 0.615497\n",
      "iteration 98 / 300: loss 0.621385\n",
      "iteration 98 / 300: loss 0.587292\n",
      "iteration 98 / 300: loss 0.582510\n",
      "iteration 98 / 300: loss 0.585599\n",
      "iteration 98 / 300: loss 0.603697\n",
      "iteration 98 / 300: loss 0.585223\n",
      "iteration 98 / 300: loss 0.578907\n",
      "iteration 98 / 300: loss 0.576442\n",
      "iteration 98 / 300: loss 0.574121\n",
      "iteration 98 / 300: loss 0.600521\n",
      "iteration 98 / 300: loss 0.584514\n",
      "iteration 98 / 300: loss 0.584857\n",
      "iteration 98 / 300: loss 0.568347\n",
      "iteration 98 / 300: loss 0.592051\n",
      "iteration 98 / 300: loss 0.612143\n",
      "iteration 98 / 300: loss 0.608947\n",
      "iteration 98 / 300: loss 0.607640\n",
      "iteration 98 / 300: loss 0.595557\n",
      "iteration 98 / 300: loss 0.592862\n",
      "iteration 98 / 300: loss 0.598016\n",
      "iteration 98 / 300: loss 0.597704\n",
      "iteration 98 / 300: loss 0.600978\n",
      "iteration 98 / 300: loss 0.597450\n",
      "iteration 98 / 300: loss 0.598797\n",
      "iteration 98 / 300: loss 0.587833\n",
      "iteration 98 / 300: loss 0.600525\n",
      "iteration 98 / 300: loss 0.599676\n",
      "iteration 98 / 300: loss 0.617567\n",
      "iteration 98 / 300: loss 0.598898\n",
      "iteration 98 / 300: loss 0.600822\n",
      "iteration 98 / 300: loss 0.605333\n",
      "iteration 98 / 300: loss 0.598619\n",
      "iteration 98 / 300: loss 0.591498\n",
      "iteration 98 / 300: loss 0.580406\n",
      "iteration 98 / 300: loss 0.598248\n",
      "iteration 98 / 300: loss 0.611710\n",
      "iteration 98 / 300: loss 0.613243\n",
      "iteration 98 / 300: loss 0.582235\n",
      "iteration 98 / 300: loss 0.601988\n",
      "iteration 98 / 300: loss 0.608985\n",
      "iteration 98 / 300: loss 0.601820\n",
      "iteration 98 / 300: loss 0.607976\n",
      "iteration 98 / 300: loss 0.620269\n",
      "iteration 98 / 300: loss 0.584844\n",
      "iteration 98 / 300: loss 0.583741\n",
      "iteration 98 / 300: loss 0.628875\n",
      "iteration 98 / 300: loss 0.609420\n",
      "iteration 98 / 300: loss 0.606292\n",
      "iteration 98 / 300: loss 0.599059\n",
      "iteration 98 / 300: loss 0.615905\n",
      "iteration 98 / 300: loss 0.596514\n",
      "iteration 98 / 300: loss 0.581458\n",
      "iteration 98 / 300: loss 0.609830\n",
      "iteration 98 / 300: loss 0.608148\n",
      "iteration 98 / 300: loss 0.598251\n",
      "iteration 98 / 300: loss 0.592049\n",
      "iteration 98 / 300: loss 0.611059\n",
      "iteration 98 / 300: loss 0.598575\n",
      "iteration 98 / 300: loss 0.581403\n",
      "iteration 98 / 300: loss 0.609606\n",
      "iteration 99 / 300: loss 0.578412\n",
      "iteration 99 / 300: loss 0.596239\n",
      "iteration 99 / 300: loss 0.569479\n",
      "iteration 99 / 300: loss 0.597875\n",
      "iteration 99 / 300: loss 0.598964\n",
      "iteration 99 / 300: loss 0.603901\n",
      "iteration 99 / 300: loss 0.615279\n",
      "iteration 99 / 300: loss 0.588251\n",
      "iteration 99 / 300: loss 0.627192\n",
      "iteration 99 / 300: loss 0.592629\n",
      "iteration 99 / 300: loss 0.621529\n",
      "iteration 99 / 300: loss 0.593114\n",
      "iteration 99 / 300: loss 0.600564\n",
      "iteration 99 / 300: loss 0.571019\n",
      "iteration 99 / 300: loss 0.592935\n",
      "iteration 99 / 300: loss 0.600068\n",
      "iteration 99 / 300: loss 0.598073\n",
      "iteration 99 / 300: loss 0.583730\n",
      "iteration 99 / 300: loss 0.614377\n",
      "iteration 99 / 300: loss 0.591309\n",
      "iteration 99 / 300: loss 0.591411\n",
      "iteration 99 / 300: loss 0.594025\n",
      "iteration 99 / 300: loss 0.596765\n",
      "iteration 99 / 300: loss 0.596736\n",
      "iteration 99 / 300: loss 0.611758\n",
      "iteration 99 / 300: loss 0.607289\n",
      "iteration 99 / 300: loss 0.597058\n",
      "iteration 99 / 300: loss 0.596321\n",
      "iteration 99 / 300: loss 0.627413\n",
      "iteration 99 / 300: loss 0.601609\n",
      "iteration 99 / 300: loss 0.599944\n",
      "iteration 99 / 300: loss 0.621972\n",
      "iteration 99 / 300: loss 0.581464\n",
      "iteration 99 / 300: loss 0.599630\n",
      "iteration 99 / 300: loss 0.591212\n",
      "iteration 99 / 300: loss 0.599944\n",
      "iteration 99 / 300: loss 0.596039\n",
      "iteration 99 / 300: loss 0.590784\n",
      "iteration 99 / 300: loss 0.591988\n",
      "iteration 99 / 300: loss 0.615494\n",
      "iteration 99 / 300: loss 0.621383\n",
      "iteration 99 / 300: loss 0.587290\n",
      "iteration 99 / 300: loss 0.582508\n",
      "iteration 99 / 300: loss 0.585596\n",
      "iteration 99 / 300: loss 0.603694\n",
      "iteration 99 / 300: loss 0.585220\n",
      "iteration 99 / 300: loss 0.578904\n",
      "iteration 99 / 300: loss 0.576440\n",
      "iteration 99 / 300: loss 0.574119\n",
      "iteration 99 / 300: loss 0.600519\n",
      "iteration 99 / 300: loss 0.584512\n",
      "iteration 99 / 300: loss 0.584854\n",
      "iteration 99 / 300: loss 0.568344\n",
      "iteration 99 / 300: loss 0.592049\n",
      "iteration 99 / 300: loss 0.612141\n",
      "iteration 99 / 300: loss 0.608944\n",
      "iteration 99 / 300: loss 0.607637\n",
      "iteration 99 / 300: loss 0.595555\n",
      "iteration 99 / 300: loss 0.592859\n",
      "iteration 99 / 300: loss 0.598013\n",
      "iteration 99 / 300: loss 0.597701\n",
      "iteration 99 / 300: loss 0.600976\n",
      "iteration 99 / 300: loss 0.597447\n",
      "iteration 99 / 300: loss 0.598795\n",
      "iteration 99 / 300: loss 0.587830\n",
      "iteration 99 / 300: loss 0.600523\n",
      "iteration 99 / 300: loss 0.599673\n",
      "iteration 99 / 300: loss 0.617564\n",
      "iteration 99 / 300: loss 0.598895\n",
      "iteration 99 / 300: loss 0.600820\n",
      "iteration 99 / 300: loss 0.605330\n",
      "iteration 99 / 300: loss 0.598616\n",
      "iteration 99 / 300: loss 0.591496\n",
      "iteration 99 / 300: loss 0.580403\n",
      "iteration 99 / 300: loss 0.598245\n",
      "iteration 99 / 300: loss 0.611707\n",
      "iteration 99 / 300: loss 0.613241\n",
      "iteration 99 / 300: loss 0.582233\n",
      "iteration 99 / 300: loss 0.601985\n",
      "iteration 99 / 300: loss 0.608982\n",
      "iteration 99 / 300: loss 0.601818\n",
      "iteration 99 / 300: loss 0.607973\n",
      "iteration 99 / 300: loss 0.620266\n",
      "iteration 99 / 300: loss 0.584841\n",
      "iteration 99 / 300: loss 0.583739\n",
      "iteration 99 / 300: loss 0.628872\n",
      "iteration 99 / 300: loss 0.609418\n",
      "iteration 99 / 300: loss 0.606290\n",
      "iteration 99 / 300: loss 0.599057\n",
      "iteration 99 / 300: loss 0.615902\n",
      "iteration 99 / 300: loss 0.596512\n",
      "iteration 99 / 300: loss 0.581455\n",
      "iteration 99 / 300: loss 0.609828\n",
      "iteration 99 / 300: loss 0.608146\n",
      "iteration 99 / 300: loss 0.598248\n",
      "iteration 99 / 300: loss 0.592046\n",
      "iteration 99 / 300: loss 0.611056\n",
      "iteration 99 / 300: loss 0.598572\n",
      "iteration 99 / 300: loss 0.581401\n",
      "iteration 99 / 300: loss 0.609603\n",
      "iteration 100 / 300: loss 0.578409\n",
      "iteration 100 / 300: loss 0.596237\n",
      "iteration 100 / 300: loss 0.569476\n",
      "iteration 100 / 300: loss 0.597873\n",
      "iteration 100 / 300: loss 0.598962\n",
      "iteration 100 / 300: loss 0.603899\n",
      "iteration 100 / 300: loss 0.615277\n",
      "iteration 100 / 300: loss 0.588248\n",
      "iteration 100 / 300: loss 0.627190\n",
      "iteration 100 / 300: loss 0.592626\n",
      "iteration 100 / 300: loss 0.621526\n",
      "iteration 100 / 300: loss 0.593112\n",
      "iteration 100 / 300: loss 0.600562\n",
      "iteration 100 / 300: loss 0.571017\n",
      "iteration 100 / 300: loss 0.592933\n",
      "iteration 100 / 300: loss 0.600065\n",
      "iteration 100 / 300: loss 0.598071\n",
      "iteration 100 / 300: loss 0.583729\n",
      "iteration 100 / 300: loss 0.614375\n",
      "iteration 100 / 300: loss 0.591306\n",
      "iteration 100 / 300: loss 0.591409\n",
      "iteration 100 / 300: loss 0.594023\n",
      "iteration 100 / 300: loss 0.596762\n",
      "iteration 100 / 300: loss 0.596733\n",
      "iteration 100 / 300: loss 0.611756\n",
      "iteration 100 / 300: loss 0.607286\n",
      "iteration 100 / 300: loss 0.597056\n",
      "iteration 100 / 300: loss 0.596319\n",
      "iteration 100 / 300: loss 0.627411\n",
      "iteration 100 / 300: loss 0.601607\n",
      "iteration 100 / 300: loss 0.599942\n",
      "iteration 100 / 300: loss 0.621970\n",
      "iteration 100 / 300: loss 0.581461\n",
      "iteration 100 / 300: loss 0.599627\n",
      "iteration 100 / 300: loss 0.591209\n",
      "iteration 100 / 300: loss 0.599941\n",
      "iteration 100 / 300: loss 0.596037\n",
      "iteration 100 / 300: loss 0.590782\n",
      "iteration 100 / 300: loss 0.591986\n",
      "iteration 100 / 300: loss 0.615492\n",
      "iteration 100 / 300: loss 0.621380\n",
      "iteration 100 / 300: loss 0.587288\n",
      "iteration 100 / 300: loss 0.582505\n",
      "iteration 100 / 300: loss 0.585594\n",
      "iteration 100 / 300: loss 0.603692\n",
      "iteration 100 / 300: loss 0.585217\n",
      "iteration 100 / 300: loss 0.578902\n",
      "iteration 100 / 300: loss 0.576438\n",
      "iteration 100 / 300: loss 0.574117\n",
      "iteration 100 / 300: loss 0.600517\n",
      "iteration 100 / 300: loss 0.584510\n",
      "iteration 100 / 300: loss 0.584852\n",
      "iteration 100 / 300: loss 0.568342\n",
      "iteration 100 / 300: loss 0.592047\n",
      "iteration 100 / 300: loss 0.612138\n",
      "iteration 100 / 300: loss 0.608942\n",
      "iteration 100 / 300: loss 0.607635\n",
      "iteration 100 / 300: loss 0.595553\n",
      "iteration 100 / 300: loss 0.592857\n",
      "iteration 100 / 300: loss 0.598011\n",
      "iteration 100 / 300: loss 0.597699\n",
      "iteration 100 / 300: loss 0.600973\n",
      "iteration 100 / 300: loss 0.597445\n",
      "iteration 100 / 300: loss 0.598793\n",
      "iteration 100 / 300: loss 0.587828\n",
      "iteration 100 / 300: loss 0.600520\n",
      "iteration 100 / 300: loss 0.599671\n",
      "iteration 100 / 300: loss 0.617562\n",
      "iteration 100 / 300: loss 0.598893\n",
      "iteration 100 / 300: loss 0.600818\n",
      "iteration 100 / 300: loss 0.605328\n",
      "iteration 100 / 300: loss 0.598614\n",
      "iteration 100 / 300: loss 0.591494\n",
      "iteration 100 / 300: loss 0.580401\n",
      "iteration 100 / 300: loss 0.598243\n",
      "iteration 100 / 300: loss 0.611705\n",
      "iteration 100 / 300: loss 0.613238\n",
      "iteration 100 / 300: loss 0.582231\n",
      "iteration 100 / 300: loss 0.601982\n",
      "iteration 100 / 300: loss 0.608980\n",
      "iteration 100 / 300: loss 0.601815\n",
      "iteration 100 / 300: loss 0.607970\n",
      "iteration 100 / 300: loss 0.620263\n",
      "iteration 100 / 300: loss 0.584839\n",
      "iteration 100 / 300: loss 0.583737\n",
      "iteration 100 / 300: loss 0.628870\n",
      "iteration 100 / 300: loss 0.609416\n",
      "iteration 100 / 300: loss 0.606287\n",
      "iteration 100 / 300: loss 0.599055\n",
      "iteration 100 / 300: loss 0.615900\n",
      "iteration 100 / 300: loss 0.596509\n",
      "iteration 100 / 300: loss 0.581453\n",
      "iteration 100 / 300: loss 0.609826\n",
      "iteration 100 / 300: loss 0.608144\n",
      "iteration 100 / 300: loss 0.598246\n",
      "iteration 100 / 300: loss 0.592044\n",
      "iteration 100 / 300: loss 0.611054\n",
      "iteration 100 / 300: loss 0.598570\n",
      "iteration 100 / 300: loss 0.581399\n",
      "iteration 100 / 300: loss 0.609601\n",
      "iteration 101 / 300: loss 0.578407\n",
      "iteration 101 / 300: loss 0.596235\n",
      "iteration 101 / 300: loss 0.569474\n",
      "iteration 101 / 300: loss 0.597871\n",
      "iteration 101 / 300: loss 0.598960\n",
      "iteration 101 / 300: loss 0.603897\n",
      "iteration 101 / 300: loss 0.615276\n",
      "iteration 101 / 300: loss 0.588246\n",
      "iteration 101 / 300: loss 0.627188\n",
      "iteration 101 / 300: loss 0.592623\n",
      "iteration 101 / 300: loss 0.621524\n",
      "iteration 101 / 300: loss 0.593111\n",
      "iteration 101 / 300: loss 0.600560\n",
      "iteration 101 / 300: loss 0.571016\n",
      "iteration 101 / 300: loss 0.592931\n",
      "iteration 101 / 300: loss 0.600063\n",
      "iteration 101 / 300: loss 0.598069\n",
      "iteration 101 / 300: loss 0.583727\n",
      "iteration 101 / 300: loss 0.614373\n",
      "iteration 101 / 300: loss 0.591304\n",
      "iteration 101 / 300: loss 0.591407\n",
      "iteration 101 / 300: loss 0.594021\n",
      "iteration 101 / 300: loss 0.596759\n",
      "iteration 101 / 300: loss 0.596731\n",
      "iteration 101 / 300: loss 0.611754\n",
      "iteration 101 / 300: loss 0.607284\n",
      "iteration 101 / 300: loss 0.597053\n",
      "iteration 101 / 300: loss 0.596318\n",
      "iteration 101 / 300: loss 0.627409\n",
      "iteration 101 / 300: loss 0.601605\n",
      "iteration 101 / 300: loss 0.599940\n",
      "iteration 101 / 300: loss 0.621968\n",
      "iteration 101 / 300: loss 0.581458\n",
      "iteration 101 / 300: loss 0.599625\n",
      "iteration 101 / 300: loss 0.591207\n",
      "iteration 101 / 300: loss 0.599939\n",
      "iteration 101 / 300: loss 0.596035\n",
      "iteration 101 / 300: loss 0.590780\n",
      "iteration 101 / 300: loss 0.591983\n",
      "iteration 101 / 300: loss 0.615489\n",
      "iteration 101 / 300: loss 0.621379\n",
      "iteration 101 / 300: loss 0.587286\n",
      "iteration 101 / 300: loss 0.582503\n",
      "iteration 101 / 300: loss 0.585592\n",
      "iteration 101 / 300: loss 0.603689\n",
      "iteration 101 / 300: loss 0.585215\n",
      "iteration 101 / 300: loss 0.578900\n",
      "iteration 101 / 300: loss 0.576436\n",
      "iteration 101 / 300: loss 0.574115\n",
      "iteration 101 / 300: loss 0.600515\n",
      "iteration 101 / 300: loss 0.584508\n",
      "iteration 101 / 300: loss 0.584851\n",
      "iteration 101 / 300: loss 0.568341\n",
      "iteration 101 / 300: loss 0.592045\n",
      "iteration 101 / 300: loss 0.612136\n",
      "iteration 101 / 300: loss 0.608940\n",
      "iteration 101 / 300: loss 0.607633\n",
      "iteration 101 / 300: loss 0.595551\n",
      "iteration 101 / 300: loss 0.592855\n",
      "iteration 101 / 300: loss 0.598009\n",
      "iteration 101 / 300: loss 0.597697\n",
      "iteration 101 / 300: loss 0.600971\n",
      "iteration 101 / 300: loss 0.597443\n",
      "iteration 101 / 300: loss 0.598791\n",
      "iteration 101 / 300: loss 0.587826\n",
      "iteration 101 / 300: loss 0.600518\n",
      "iteration 101 / 300: loss 0.599669\n",
      "iteration 101 / 300: loss 0.617560\n",
      "iteration 101 / 300: loss 0.598892\n",
      "iteration 101 / 300: loss 0.600817\n",
      "iteration 101 / 300: loss 0.605326\n",
      "iteration 101 / 300: loss 0.598612\n",
      "iteration 101 / 300: loss 0.591492\n",
      "iteration 101 / 300: loss 0.580400\n",
      "iteration 101 / 300: loss 0.598241\n",
      "iteration 101 / 300: loss 0.611703\n",
      "iteration 101 / 300: loss 0.613237\n",
      "iteration 101 / 300: loss 0.582229\n",
      "iteration 101 / 300: loss 0.601979\n",
      "iteration 101 / 300: loss 0.608977\n",
      "iteration 101 / 300: loss 0.601813\n",
      "iteration 101 / 300: loss 0.607968\n",
      "iteration 101 / 300: loss 0.620261\n",
      "iteration 101 / 300: loss 0.584837\n",
      "iteration 101 / 300: loss 0.583736\n",
      "iteration 101 / 300: loss 0.628868\n",
      "iteration 101 / 300: loss 0.609415\n",
      "iteration 101 / 300: loss 0.606285\n",
      "iteration 101 / 300: loss 0.599053\n",
      "iteration 101 / 300: loss 0.615898\n",
      "iteration 101 / 300: loss 0.596507\n",
      "iteration 101 / 300: loss 0.581451\n",
      "iteration 101 / 300: loss 0.609824\n",
      "iteration 101 / 300: loss 0.608142\n",
      "iteration 101 / 300: loss 0.598244\n",
      "iteration 101 / 300: loss 0.592042\n",
      "iteration 101 / 300: loss 0.611052\n",
      "iteration 101 / 300: loss 0.598568\n",
      "iteration 101 / 300: loss 0.581398\n",
      "iteration 101 / 300: loss 0.609599\n",
      "iteration 102 / 300: loss 0.578405\n",
      "iteration 102 / 300: loss 0.596233\n",
      "iteration 102 / 300: loss 0.569472\n",
      "iteration 102 / 300: loss 0.597869\n",
      "iteration 102 / 300: loss 0.598958\n",
      "iteration 102 / 300: loss 0.603895\n",
      "iteration 102 / 300: loss 0.615274\n",
      "iteration 102 / 300: loss 0.588244\n",
      "iteration 102 / 300: loss 0.627187\n",
      "iteration 102 / 300: loss 0.592621\n",
      "iteration 102 / 300: loss 0.621521\n",
      "iteration 102 / 300: loss 0.593109\n",
      "iteration 102 / 300: loss 0.600558\n",
      "iteration 102 / 300: loss 0.571014\n",
      "iteration 102 / 300: loss 0.592929\n",
      "iteration 102 / 300: loss 0.600061\n",
      "iteration 102 / 300: loss 0.598068\n",
      "iteration 102 / 300: loss 0.583726\n",
      "iteration 102 / 300: loss 0.614371\n",
      "iteration 102 / 300: loss 0.591303\n",
      "iteration 102 / 300: loss 0.591406\n",
      "iteration 102 / 300: loss 0.594020\n",
      "iteration 102 / 300: loss 0.596757\n",
      "iteration 102 / 300: loss 0.596730\n",
      "iteration 102 / 300: loss 0.611752\n",
      "iteration 102 / 300: loss 0.607281\n",
      "iteration 102 / 300: loss 0.597051\n",
      "iteration 102 / 300: loss 0.596316\n",
      "iteration 102 / 300: loss 0.627407\n",
      "iteration 102 / 300: loss 0.601603\n",
      "iteration 102 / 300: loss 0.599938\n",
      "iteration 102 / 300: loss 0.621967\n",
      "iteration 102 / 300: loss 0.581456\n",
      "iteration 102 / 300: loss 0.599623\n",
      "iteration 102 / 300: loss 0.591204\n",
      "iteration 102 / 300: loss 0.599937\n",
      "iteration 102 / 300: loss 0.596033\n",
      "iteration 102 / 300: loss 0.590778\n",
      "iteration 102 / 300: loss 0.591981\n",
      "iteration 102 / 300: loss 0.615487\n",
      "iteration 102 / 300: loss 0.621377\n",
      "iteration 102 / 300: loss 0.587284\n",
      "iteration 102 / 300: loss 0.582501\n",
      "iteration 102 / 300: loss 0.585590\n",
      "iteration 102 / 300: loss 0.603687\n",
      "iteration 102 / 300: loss 0.585213\n",
      "iteration 102 / 300: loss 0.578898\n",
      "iteration 102 / 300: loss 0.576434\n",
      "iteration 102 / 300: loss 0.574113\n",
      "iteration 102 / 300: loss 0.600514\n",
      "iteration 102 / 300: loss 0.584506\n",
      "iteration 102 / 300: loss 0.584849\n",
      "iteration 102 / 300: loss 0.568339\n",
      "iteration 102 / 300: loss 0.592043\n",
      "iteration 102 / 300: loss 0.612134\n",
      "iteration 102 / 300: loss 0.608939\n",
      "iteration 102 / 300: loss 0.607631\n",
      "iteration 102 / 300: loss 0.595549\n",
      "iteration 102 / 300: loss 0.592853\n",
      "iteration 102 / 300: loss 0.598007\n",
      "iteration 102 / 300: loss 0.597695\n",
      "iteration 102 / 300: loss 0.600970\n",
      "iteration 102 / 300: loss 0.597441\n",
      "iteration 102 / 300: loss 0.598790\n",
      "iteration 102 / 300: loss 0.587824\n",
      "iteration 102 / 300: loss 0.600517\n",
      "iteration 102 / 300: loss 0.599667\n",
      "iteration 102 / 300: loss 0.617558\n",
      "iteration 102 / 300: loss 0.598890\n",
      "iteration 102 / 300: loss 0.600815\n",
      "iteration 102 / 300: loss 0.605324\n",
      "iteration 102 / 300: loss 0.598610\n",
      "iteration 102 / 300: loss 0.591490\n",
      "iteration 102 / 300: loss 0.580398\n",
      "iteration 102 / 300: loss 0.598239\n",
      "iteration 102 / 300: loss 0.611701\n",
      "iteration 102 / 300: loss 0.613235\n",
      "iteration 102 / 300: loss 0.582228\n",
      "iteration 102 / 300: loss 0.601977\n",
      "iteration 102 / 300: loss 0.608975\n",
      "iteration 102 / 300: loss 0.601812\n",
      "iteration 102 / 300: loss 0.607965\n",
      "iteration 102 / 300: loss 0.620259\n",
      "iteration 102 / 300: loss 0.584835\n",
      "iteration 102 / 300: loss 0.583734\n",
      "iteration 102 / 300: loss 0.628866\n",
      "iteration 102 / 300: loss 0.609413\n",
      "iteration 102 / 300: loss 0.606283\n",
      "iteration 102 / 300: loss 0.599051\n",
      "iteration 102 / 300: loss 0.615896\n",
      "iteration 102 / 300: loss 0.596506\n",
      "iteration 102 / 300: loss 0.581449\n",
      "iteration 102 / 300: loss 0.609822\n",
      "iteration 102 / 300: loss 0.608140\n",
      "iteration 102 / 300: loss 0.598242\n",
      "iteration 102 / 300: loss 0.592040\n",
      "iteration 102 / 300: loss 0.611050\n",
      "iteration 102 / 300: loss 0.598566\n",
      "iteration 102 / 300: loss 0.581396\n",
      "iteration 102 / 300: loss 0.609597\n",
      "iteration 103 / 300: loss 0.578403\n",
      "iteration 103 / 300: loss 0.596231\n",
      "iteration 103 / 300: loss 0.569471\n",
      "iteration 103 / 300: loss 0.597867\n",
      "iteration 103 / 300: loss 0.598956\n",
      "iteration 103 / 300: loss 0.603893\n",
      "iteration 103 / 300: loss 0.615273\n",
      "iteration 103 / 300: loss 0.588243\n",
      "iteration 103 / 300: loss 0.627185\n",
      "iteration 103 / 300: loss 0.592619\n",
      "iteration 103 / 300: loss 0.621519\n",
      "iteration 103 / 300: loss 0.593108\n",
      "iteration 103 / 300: loss 0.600556\n",
      "iteration 103 / 300: loss 0.571013\n",
      "iteration 103 / 300: loss 0.592927\n",
      "iteration 103 / 300: loss 0.600060\n",
      "iteration 103 / 300: loss 0.598066\n",
      "iteration 103 / 300: loss 0.583724\n",
      "iteration 103 / 300: loss 0.614370\n",
      "iteration 103 / 300: loss 0.591301\n",
      "iteration 103 / 300: loss 0.591404\n",
      "iteration 103 / 300: loss 0.594018\n",
      "iteration 103 / 300: loss 0.596755\n",
      "iteration 103 / 300: loss 0.596728\n",
      "iteration 103 / 300: loss 0.611751\n",
      "iteration 103 / 300: loss 0.607279\n",
      "iteration 103 / 300: loss 0.597049\n",
      "iteration 103 / 300: loss 0.596315\n",
      "iteration 103 / 300: loss 0.627406\n",
      "iteration 103 / 300: loss 0.601601\n",
      "iteration 103 / 300: loss 0.599937\n",
      "iteration 103 / 300: loss 0.621965\n",
      "iteration 103 / 300: loss 0.581454\n",
      "iteration 103 / 300: loss 0.599621\n",
      "iteration 103 / 300: loss 0.591202\n",
      "iteration 103 / 300: loss 0.599936\n",
      "iteration 103 / 300: loss 0.596031\n",
      "iteration 103 / 300: loss 0.590776\n",
      "iteration 103 / 300: loss 0.591979\n",
      "iteration 103 / 300: loss 0.615485\n",
      "iteration 103 / 300: loss 0.621375\n",
      "iteration 103 / 300: loss 0.587282\n",
      "iteration 103 / 300: loss 0.582500\n",
      "iteration 103 / 300: loss 0.585588\n",
      "iteration 103 / 300: loss 0.603685\n",
      "iteration 103 / 300: loss 0.585211\n",
      "iteration 103 / 300: loss 0.578896\n",
      "iteration 103 / 300: loss 0.576433\n",
      "iteration 103 / 300: loss 0.574112\n",
      "iteration 103 / 300: loss 0.600512\n",
      "iteration 103 / 300: loss 0.584505\n",
      "iteration 103 / 300: loss 0.584848\n",
      "iteration 103 / 300: loss 0.568337\n",
      "iteration 103 / 300: loss 0.592041\n",
      "iteration 103 / 300: loss 0.612133\n",
      "iteration 103 / 300: loss 0.608937\n",
      "iteration 103 / 300: loss 0.607629\n",
      "iteration 103 / 300: loss 0.595548\n",
      "iteration 103 / 300: loss 0.592852\n",
      "iteration 103 / 300: loss 0.598005\n",
      "iteration 103 / 300: loss 0.597693\n",
      "iteration 103 / 300: loss 0.600968\n",
      "iteration 103 / 300: loss 0.597439\n",
      "iteration 103 / 300: loss 0.598789\n",
      "iteration 103 / 300: loss 0.587822\n",
      "iteration 103 / 300: loss 0.600515\n",
      "iteration 103 / 300: loss 0.599666\n",
      "iteration 103 / 300: loss 0.617556\n",
      "iteration 103 / 300: loss 0.598889\n",
      "iteration 103 / 300: loss 0.600814\n",
      "iteration 103 / 300: loss 0.605322\n",
      "iteration 103 / 300: loss 0.598608\n",
      "iteration 103 / 300: loss 0.591489\n",
      "iteration 103 / 300: loss 0.580396\n",
      "iteration 103 / 300: loss 0.598237\n",
      "iteration 103 / 300: loss 0.611700\n",
      "iteration 103 / 300: loss 0.613233\n",
      "iteration 103 / 300: loss 0.582226\n",
      "iteration 103 / 300: loss 0.601975\n",
      "iteration 103 / 300: loss 0.608974\n",
      "iteration 103 / 300: loss 0.601810\n",
      "iteration 103 / 300: loss 0.607963\n",
      "iteration 103 / 300: loss 0.620256\n",
      "iteration 103 / 300: loss 0.584833\n",
      "iteration 103 / 300: loss 0.583733\n",
      "iteration 103 / 300: loss 0.628864\n",
      "iteration 103 / 300: loss 0.609412\n",
      "iteration 103 / 300: loss 0.606282\n",
      "iteration 103 / 300: loss 0.599049\n",
      "iteration 103 / 300: loss 0.615894\n",
      "iteration 103 / 300: loss 0.596504\n",
      "iteration 103 / 300: loss 0.581447\n",
      "iteration 103 / 300: loss 0.609821\n",
      "iteration 103 / 300: loss 0.608139\n",
      "iteration 103 / 300: loss 0.598240\n",
      "iteration 103 / 300: loss 0.592038\n",
      "iteration 103 / 300: loss 0.611048\n",
      "iteration 103 / 300: loss 0.598565\n",
      "iteration 103 / 300: loss 0.581395\n",
      "iteration 103 / 300: loss 0.609595\n",
      "iteration 104 / 300: loss 0.578401\n",
      "iteration 104 / 300: loss 0.596229\n",
      "iteration 104 / 300: loss 0.569469\n",
      "iteration 104 / 300: loss 0.597865\n",
      "iteration 104 / 300: loss 0.598955\n",
      "iteration 104 / 300: loss 0.603891\n",
      "iteration 104 / 300: loss 0.615272\n",
      "iteration 104 / 300: loss 0.588241\n",
      "iteration 104 / 300: loss 0.627184\n",
      "iteration 104 / 300: loss 0.592617\n",
      "iteration 104 / 300: loss 0.621517\n",
      "iteration 104 / 300: loss 0.593106\n",
      "iteration 104 / 300: loss 0.600555\n",
      "iteration 104 / 300: loss 0.571012\n",
      "iteration 104 / 300: loss 0.592926\n",
      "iteration 104 / 300: loss 0.600058\n",
      "iteration 104 / 300: loss 0.598065\n",
      "iteration 104 / 300: loss 0.583723\n",
      "iteration 104 / 300: loss 0.614368\n",
      "iteration 104 / 300: loss 0.591299\n",
      "iteration 104 / 300: loss 0.591403\n",
      "iteration 104 / 300: loss 0.594017\n",
      "iteration 104 / 300: loss 0.596753\n",
      "iteration 104 / 300: loss 0.596726\n",
      "iteration 104 / 300: loss 0.611749\n",
      "iteration 104 / 300: loss 0.607277\n",
      "iteration 104 / 300: loss 0.597048\n",
      "iteration 104 / 300: loss 0.596313\n",
      "iteration 104 / 300: loss 0.627404\n",
      "iteration 104 / 300: loss 0.601599\n",
      "iteration 104 / 300: loss 0.599936\n",
      "iteration 104 / 300: loss 0.621964\n",
      "iteration 104 / 300: loss 0.581452\n",
      "iteration 104 / 300: loss 0.599620\n",
      "iteration 104 / 300: loss 0.591200\n",
      "iteration 104 / 300: loss 0.599934\n",
      "iteration 104 / 300: loss 0.596030\n",
      "iteration 104 / 300: loss 0.590775\n",
      "iteration 104 / 300: loss 0.591978\n",
      "iteration 104 / 300: loss 0.615484\n",
      "iteration 104 / 300: loss 0.621374\n",
      "iteration 104 / 300: loss 0.587281\n",
      "iteration 104 / 300: loss 0.582498\n",
      "iteration 104 / 300: loss 0.585587\n",
      "iteration 104 / 300: loss 0.603683\n",
      "iteration 104 / 300: loss 0.585209\n",
      "iteration 104 / 300: loss 0.578895\n",
      "iteration 104 / 300: loss 0.576432\n",
      "iteration 104 / 300: loss 0.574110\n",
      "iteration 104 / 300: loss 0.600511\n",
      "iteration 104 / 300: loss 0.584503\n",
      "iteration 104 / 300: loss 0.584846\n",
      "iteration 104 / 300: loss 0.568336\n",
      "iteration 104 / 300: loss 0.592040\n",
      "iteration 104 / 300: loss 0.612131\n",
      "iteration 104 / 300: loss 0.608936\n",
      "iteration 104 / 300: loss 0.607628\n",
      "iteration 104 / 300: loss 0.595546\n",
      "iteration 104 / 300: loss 0.592850\n",
      "iteration 104 / 300: loss 0.598003\n",
      "iteration 104 / 300: loss 0.597692\n",
      "iteration 104 / 300: loss 0.600967\n",
      "iteration 104 / 300: loss 0.597437\n",
      "iteration 104 / 300: loss 0.598787\n",
      "iteration 104 / 300: loss 0.587821\n",
      "iteration 104 / 300: loss 0.600513\n",
      "iteration 104 / 300: loss 0.599664\n",
      "iteration 104 / 300: loss 0.617555\n",
      "iteration 104 / 300: loss 0.598887\n",
      "iteration 104 / 300: loss 0.600813\n",
      "iteration 104 / 300: loss 0.605320\n",
      "iteration 104 / 300: loss 0.598607\n",
      "iteration 104 / 300: loss 0.591487\n",
      "iteration 104 / 300: loss 0.580395\n",
      "iteration 104 / 300: loss 0.598236\n",
      "iteration 104 / 300: loss 0.611698\n",
      "iteration 104 / 300: loss 0.613232\n",
      "iteration 104 / 300: loss 0.582225\n",
      "iteration 104 / 300: loss 0.601973\n",
      "iteration 104 / 300: loss 0.608972\n",
      "iteration 104 / 300: loss 0.601808\n",
      "iteration 104 / 300: loss 0.607962\n",
      "iteration 104 / 300: loss 0.620255\n",
      "iteration 104 / 300: loss 0.584832\n",
      "iteration 104 / 300: loss 0.583732\n",
      "iteration 104 / 300: loss 0.628863\n",
      "iteration 104 / 300: loss 0.609410\n",
      "iteration 104 / 300: loss 0.606280\n",
      "iteration 104 / 300: loss 0.599048\n",
      "iteration 104 / 300: loss 0.615892\n",
      "iteration 104 / 300: loss 0.596503\n",
      "iteration 104 / 300: loss 0.581445\n",
      "iteration 104 / 300: loss 0.609819\n",
      "iteration 104 / 300: loss 0.608138\n",
      "iteration 104 / 300: loss 0.598239\n",
      "iteration 104 / 300: loss 0.592037\n",
      "iteration 104 / 300: loss 0.611047\n",
      "iteration 104 / 300: loss 0.598563\n",
      "iteration 104 / 300: loss 0.581394\n",
      "iteration 104 / 300: loss 0.609594\n",
      "iteration 105 / 300: loss 0.578399\n",
      "iteration 105 / 300: loss 0.596228\n",
      "iteration 105 / 300: loss 0.569468\n",
      "iteration 105 / 300: loss 0.597864\n",
      "iteration 105 / 300: loss 0.598953\n",
      "iteration 105 / 300: loss 0.603890\n",
      "iteration 105 / 300: loss 0.615271\n",
      "iteration 105 / 300: loss 0.588240\n",
      "iteration 105 / 300: loss 0.627183\n",
      "iteration 105 / 300: loss 0.592616\n",
      "iteration 105 / 300: loss 0.621516\n",
      "iteration 105 / 300: loss 0.593105\n",
      "iteration 105 / 300: loss 0.600554\n",
      "iteration 105 / 300: loss 0.571010\n",
      "iteration 105 / 300: loss 0.592924\n",
      "iteration 105 / 300: loss 0.600056\n",
      "iteration 105 / 300: loss 0.598064\n",
      "iteration 105 / 300: loss 0.583722\n",
      "iteration 105 / 300: loss 0.614367\n",
      "iteration 105 / 300: loss 0.591298\n",
      "iteration 105 / 300: loss 0.591402\n",
      "iteration 105 / 300: loss 0.594016\n",
      "iteration 105 / 300: loss 0.596751\n",
      "iteration 105 / 300: loss 0.596725\n",
      "iteration 105 / 300: loss 0.611748\n",
      "iteration 105 / 300: loss 0.607275\n",
      "iteration 105 / 300: loss 0.597046\n",
      "iteration 105 / 300: loss 0.596312\n",
      "iteration 105 / 300: loss 0.627403\n",
      "iteration 105 / 300: loss 0.601598\n",
      "iteration 105 / 300: loss 0.599934\n",
      "iteration 105 / 300: loss 0.621963\n",
      "iteration 105 / 300: loss 0.581451\n",
      "iteration 105 / 300: loss 0.599618\n",
      "iteration 105 / 300: loss 0.591198\n",
      "iteration 105 / 300: loss 0.599933\n",
      "iteration 105 / 300: loss 0.596028\n",
      "iteration 105 / 300: loss 0.590773\n",
      "iteration 105 / 300: loss 0.591976\n",
      "iteration 105 / 300: loss 0.615482\n",
      "iteration 105 / 300: loss 0.621372\n",
      "iteration 105 / 300: loss 0.587280\n",
      "iteration 105 / 300: loss 0.582496\n",
      "iteration 105 / 300: loss 0.585585\n",
      "iteration 105 / 300: loss 0.603681\n",
      "iteration 105 / 300: loss 0.585207\n",
      "iteration 105 / 300: loss 0.578894\n",
      "iteration 105 / 300: loss 0.576430\n",
      "iteration 105 / 300: loss 0.574109\n",
      "iteration 105 / 300: loss 0.600510\n",
      "iteration 105 / 300: loss 0.584502\n",
      "iteration 105 / 300: loss 0.584845\n",
      "iteration 105 / 300: loss 0.568335\n",
      "iteration 105 / 300: loss 0.592038\n",
      "iteration 105 / 300: loss 0.612130\n",
      "iteration 105 / 300: loss 0.608935\n",
      "iteration 105 / 300: loss 0.607626\n",
      "iteration 105 / 300: loss 0.595545\n",
      "iteration 105 / 300: loss 0.592849\n",
      "iteration 105 / 300: loss 0.598002\n",
      "iteration 105 / 300: loss 0.597690\n",
      "iteration 105 / 300: loss 0.600965\n",
      "iteration 105 / 300: loss 0.597436\n",
      "iteration 105 / 300: loss 0.598786\n",
      "iteration 105 / 300: loss 0.587820\n",
      "iteration 105 / 300: loss 0.600512\n",
      "iteration 105 / 300: loss 0.599663\n",
      "iteration 105 / 300: loss 0.617553\n",
      "iteration 105 / 300: loss 0.598886\n",
      "iteration 105 / 300: loss 0.600812\n",
      "iteration 105 / 300: loss 0.605319\n",
      "iteration 105 / 300: loss 0.598605\n",
      "iteration 105 / 300: loss 0.591486\n",
      "iteration 105 / 300: loss 0.580394\n",
      "iteration 105 / 300: loss 0.598234\n",
      "iteration 105 / 300: loss 0.611697\n",
      "iteration 105 / 300: loss 0.613231\n",
      "iteration 105 / 300: loss 0.582224\n",
      "iteration 105 / 300: loss 0.601971\n",
      "iteration 105 / 300: loss 0.608970\n",
      "iteration 105 / 300: loss 0.601807\n",
      "iteration 105 / 300: loss 0.607960\n",
      "iteration 105 / 300: loss 0.620253\n",
      "iteration 105 / 300: loss 0.584830\n",
      "iteration 105 / 300: loss 0.583731\n",
      "iteration 105 / 300: loss 0.628862\n",
      "iteration 105 / 300: loss 0.609409\n",
      "iteration 105 / 300: loss 0.606279\n",
      "iteration 105 / 300: loss 0.599047\n",
      "iteration 105 / 300: loss 0.615891\n",
      "iteration 105 / 300: loss 0.596501\n",
      "iteration 105 / 300: loss 0.581444\n",
      "iteration 105 / 300: loss 0.609818\n",
      "iteration 105 / 300: loss 0.608137\n",
      "iteration 105 / 300: loss 0.598237\n",
      "iteration 105 / 300: loss 0.592035\n",
      "iteration 105 / 300: loss 0.611045\n",
      "iteration 105 / 300: loss 0.598562\n",
      "iteration 105 / 300: loss 0.581393\n",
      "iteration 105 / 300: loss 0.609593\n",
      "iteration 106 / 300: loss 0.578398\n",
      "iteration 106 / 300: loss 0.596226\n",
      "iteration 106 / 300: loss 0.569467\n",
      "iteration 106 / 300: loss 0.597862\n",
      "iteration 106 / 300: loss 0.598952\n",
      "iteration 106 / 300: loss 0.603889\n",
      "iteration 106 / 300: loss 0.615270\n",
      "iteration 106 / 300: loss 0.588239\n",
      "iteration 106 / 300: loss 0.627182\n",
      "iteration 106 / 300: loss 0.592614\n",
      "iteration 106 / 300: loss 0.621514\n",
      "iteration 106 / 300: loss 0.593104\n",
      "iteration 106 / 300: loss 0.600552\n",
      "iteration 106 / 300: loss 0.571009\n",
      "iteration 106 / 300: loss 0.592923\n",
      "iteration 106 / 300: loss 0.600055\n",
      "iteration 106 / 300: loss 0.598063\n",
      "iteration 106 / 300: loss 0.583721\n",
      "iteration 106 / 300: loss 0.614366\n",
      "iteration 106 / 300: loss 0.591297\n",
      "iteration 106 / 300: loss 0.591401\n",
      "iteration 106 / 300: loss 0.594015\n",
      "iteration 106 / 300: loss 0.596750\n",
      "iteration 106 / 300: loss 0.596724\n",
      "iteration 106 / 300: loss 0.611746\n",
      "iteration 106 / 300: loss 0.607274\n",
      "iteration 106 / 300: loss 0.597045\n",
      "iteration 106 / 300: loss 0.596311\n",
      "iteration 106 / 300: loss 0.627402\n",
      "iteration 106 / 300: loss 0.601597\n",
      "iteration 106 / 300: loss 0.599933\n",
      "iteration 106 / 300: loss 0.621962\n",
      "iteration 106 / 300: loss 0.581449\n",
      "iteration 106 / 300: loss 0.599617\n",
      "iteration 106 / 300: loss 0.591197\n",
      "iteration 106 / 300: loss 0.599931\n",
      "iteration 106 / 300: loss 0.596027\n",
      "iteration 106 / 300: loss 0.590772\n",
      "iteration 106 / 300: loss 0.591975\n",
      "iteration 106 / 300: loss 0.615481\n",
      "iteration 106 / 300: loss 0.621371\n",
      "iteration 106 / 300: loss 0.587278\n",
      "iteration 106 / 300: loss 0.582495\n",
      "iteration 106 / 300: loss 0.585584\n",
      "iteration 106 / 300: loss 0.603680\n",
      "iteration 106 / 300: loss 0.585206\n",
      "iteration 106 / 300: loss 0.578892\n",
      "iteration 106 / 300: loss 0.576429\n",
      "iteration 106 / 300: loss 0.574108\n",
      "iteration 106 / 300: loss 0.600509\n",
      "iteration 106 / 300: loss 0.584501\n",
      "iteration 106 / 300: loss 0.584844\n",
      "iteration 106 / 300: loss 0.568334\n",
      "iteration 106 / 300: loss 0.592037\n",
      "iteration 106 / 300: loss 0.612128\n",
      "iteration 106 / 300: loss 0.608933\n",
      "iteration 106 / 300: loss 0.607625\n",
      "iteration 106 / 300: loss 0.595544\n",
      "iteration 106 / 300: loss 0.592848\n",
      "iteration 106 / 300: loss 0.598001\n",
      "iteration 106 / 300: loss 0.597689\n",
      "iteration 106 / 300: loss 0.600964\n",
      "iteration 106 / 300: loss 0.597434\n",
      "iteration 106 / 300: loss 0.598785\n",
      "iteration 106 / 300: loss 0.587818\n",
      "iteration 106 / 300: loss 0.600511\n",
      "iteration 106 / 300: loss 0.599662\n",
      "iteration 106 / 300: loss 0.617552\n",
      "iteration 106 / 300: loss 0.598885\n",
      "iteration 106 / 300: loss 0.600811\n",
      "iteration 106 / 300: loss 0.605318\n",
      "iteration 106 / 300: loss 0.598604\n",
      "iteration 106 / 300: loss 0.591485\n",
      "iteration 106 / 300: loss 0.580393\n",
      "iteration 106 / 300: loss 0.598233\n",
      "iteration 106 / 300: loss 0.611696\n",
      "iteration 106 / 300: loss 0.613230\n",
      "iteration 106 / 300: loss 0.582223\n",
      "iteration 106 / 300: loss 0.601970\n",
      "iteration 106 / 300: loss 0.608969\n",
      "iteration 106 / 300: loss 0.601806\n",
      "iteration 106 / 300: loss 0.607958\n",
      "iteration 106 / 300: loss 0.620251\n",
      "iteration 106 / 300: loss 0.584829\n",
      "iteration 106 / 300: loss 0.583730\n",
      "iteration 106 / 300: loss 0.628860\n",
      "iteration 106 / 300: loss 0.609408\n",
      "iteration 106 / 300: loss 0.606277\n",
      "iteration 106 / 300: loss 0.599045\n",
      "iteration 106 / 300: loss 0.615889\n",
      "iteration 106 / 300: loss 0.596500\n",
      "iteration 106 / 300: loss 0.581442\n",
      "iteration 106 / 300: loss 0.609817\n",
      "iteration 106 / 300: loss 0.608135\n",
      "iteration 106 / 300: loss 0.598236\n",
      "iteration 106 / 300: loss 0.592034\n",
      "iteration 106 / 300: loss 0.611044\n",
      "iteration 106 / 300: loss 0.598561\n",
      "iteration 106 / 300: loss 0.581392\n",
      "iteration 106 / 300: loss 0.609591\n",
      "iteration 107 / 300: loss 0.578396\n",
      "iteration 107 / 300: loss 0.596225\n",
      "iteration 107 / 300: loss 0.569465\n",
      "iteration 107 / 300: loss 0.597861\n",
      "iteration 107 / 300: loss 0.598951\n",
      "iteration 107 / 300: loss 0.603887\n",
      "iteration 107 / 300: loss 0.615269\n",
      "iteration 107 / 300: loss 0.588237\n",
      "iteration 107 / 300: loss 0.627181\n",
      "iteration 107 / 300: loss 0.592613\n",
      "iteration 107 / 300: loss 0.621513\n",
      "iteration 107 / 300: loss 0.593103\n",
      "iteration 107 / 300: loss 0.600551\n",
      "iteration 107 / 300: loss 0.571008\n",
      "iteration 107 / 300: loss 0.592922\n",
      "iteration 107 / 300: loss 0.600054\n",
      "iteration 107 / 300: loss 0.598062\n",
      "iteration 107 / 300: loss 0.583720\n",
      "iteration 107 / 300: loss 0.614365\n",
      "iteration 107 / 300: loss 0.591296\n",
      "iteration 107 / 300: loss 0.591400\n",
      "iteration 107 / 300: loss 0.594014\n",
      "iteration 107 / 300: loss 0.596748\n",
      "iteration 107 / 300: loss 0.596723\n",
      "iteration 107 / 300: loss 0.611745\n",
      "iteration 107 / 300: loss 0.607272\n",
      "iteration 107 / 300: loss 0.597043\n",
      "iteration 107 / 300: loss 0.596310\n",
      "iteration 107 / 300: loss 0.627401\n",
      "iteration 107 / 300: loss 0.601596\n",
      "iteration 107 / 300: loss 0.599932\n",
      "iteration 107 / 300: loss 0.621961\n",
      "iteration 107 / 300: loss 0.581448\n",
      "iteration 107 / 300: loss 0.599616\n",
      "iteration 107 / 300: loss 0.591195\n",
      "iteration 107 / 300: loss 0.599930\n",
      "iteration 107 / 300: loss 0.596026\n",
      "iteration 107 / 300: loss 0.590771\n",
      "iteration 107 / 300: loss 0.591973\n",
      "iteration 107 / 300: loss 0.615480\n",
      "iteration 107 / 300: loss 0.621370\n",
      "iteration 107 / 300: loss 0.587277\n",
      "iteration 107 / 300: loss 0.582494\n",
      "iteration 107 / 300: loss 0.585583\n",
      "iteration 107 / 300: loss 0.603679\n",
      "iteration 107 / 300: loss 0.585205\n",
      "iteration 107 / 300: loss 0.578891\n",
      "iteration 107 / 300: loss 0.576428\n",
      "iteration 107 / 300: loss 0.574107\n",
      "iteration 107 / 300: loss 0.600508\n",
      "iteration 107 / 300: loss 0.584500\n",
      "iteration 107 / 300: loss 0.584843\n",
      "iteration 107 / 300: loss 0.568333\n",
      "iteration 107 / 300: loss 0.592036\n",
      "iteration 107 / 300: loss 0.612127\n",
      "iteration 107 / 300: loss 0.608932\n",
      "iteration 107 / 300: loss 0.607624\n",
      "iteration 107 / 300: loss 0.595543\n",
      "iteration 107 / 300: loss 0.592847\n",
      "iteration 107 / 300: loss 0.597999\n",
      "iteration 107 / 300: loss 0.597688\n",
      "iteration 107 / 300: loss 0.600963\n",
      "iteration 107 / 300: loss 0.597433\n",
      "iteration 107 / 300: loss 0.598784\n",
      "iteration 107 / 300: loss 0.587817\n",
      "iteration 107 / 300: loss 0.600510\n",
      "iteration 107 / 300: loss 0.599661\n",
      "iteration 107 / 300: loss 0.617551\n",
      "iteration 107 / 300: loss 0.598884\n",
      "iteration 107 / 300: loss 0.600810\n",
      "iteration 107 / 300: loss 0.605316\n",
      "iteration 107 / 300: loss 0.598603\n",
      "iteration 107 / 300: loss 0.591484\n",
      "iteration 107 / 300: loss 0.580392\n",
      "iteration 107 / 300: loss 0.598232\n",
      "iteration 107 / 300: loss 0.611695\n",
      "iteration 107 / 300: loss 0.613229\n",
      "iteration 107 / 300: loss 0.582222\n",
      "iteration 107 / 300: loss 0.601968\n",
      "iteration 107 / 300: loss 0.608968\n",
      "iteration 107 / 300: loss 0.601804\n",
      "iteration 107 / 300: loss 0.607957\n",
      "iteration 107 / 300: loss 0.620250\n",
      "iteration 107 / 300: loss 0.584828\n",
      "iteration 107 / 300: loss 0.583729\n",
      "iteration 107 / 300: loss 0.628859\n",
      "iteration 107 / 300: loss 0.609407\n",
      "iteration 107 / 300: loss 0.606276\n",
      "iteration 107 / 300: loss 0.599044\n",
      "iteration 107 / 300: loss 0.615888\n",
      "iteration 107 / 300: loss 0.596499\n",
      "iteration 107 / 300: loss 0.581441\n",
      "iteration 107 / 300: loss 0.609816\n",
      "iteration 107 / 300: loss 0.608134\n",
      "iteration 107 / 300: loss 0.598235\n",
      "iteration 107 / 300: loss 0.592033\n",
      "iteration 107 / 300: loss 0.611043\n",
      "iteration 107 / 300: loss 0.598560\n",
      "iteration 107 / 300: loss 0.581391\n",
      "iteration 107 / 300: loss 0.609590\n",
      "iteration 108 / 300: loss 0.578395\n",
      "iteration 108 / 300: loss 0.596224\n",
      "iteration 108 / 300: loss 0.569464\n",
      "iteration 108 / 300: loss 0.597860\n",
      "iteration 108 / 300: loss 0.598950\n",
      "iteration 108 / 300: loss 0.603886\n",
      "iteration 108 / 300: loss 0.615268\n",
      "iteration 108 / 300: loss 0.588236\n",
      "iteration 108 / 300: loss 0.627180\n",
      "iteration 108 / 300: loss 0.592612\n",
      "iteration 108 / 300: loss 0.621511\n",
      "iteration 108 / 300: loss 0.593102\n",
      "iteration 108 / 300: loss 0.600550\n",
      "iteration 108 / 300: loss 0.571008\n",
      "iteration 108 / 300: loss 0.592921\n",
      "iteration 108 / 300: loss 0.600053\n",
      "iteration 108 / 300: loss 0.598061\n",
      "iteration 108 / 300: loss 0.583719\n",
      "iteration 108 / 300: loss 0.614364\n",
      "iteration 108 / 300: loss 0.591295\n",
      "iteration 108 / 300: loss 0.591399\n",
      "iteration 108 / 300: loss 0.594013\n",
      "iteration 108 / 300: loss 0.596747\n",
      "iteration 108 / 300: loss 0.596722\n",
      "iteration 108 / 300: loss 0.611744\n",
      "iteration 108 / 300: loss 0.607271\n",
      "iteration 108 / 300: loss 0.597042\n",
      "iteration 108 / 300: loss 0.596309\n",
      "iteration 108 / 300: loss 0.627400\n",
      "iteration 108 / 300: loss 0.601594\n",
      "iteration 108 / 300: loss 0.599932\n",
      "iteration 108 / 300: loss 0.621960\n",
      "iteration 108 / 300: loss 0.581446\n",
      "iteration 108 / 300: loss 0.599615\n",
      "iteration 108 / 300: loss 0.591194\n",
      "iteration 108 / 300: loss 0.599929\n",
      "iteration 108 / 300: loss 0.596025\n",
      "iteration 108 / 300: loss 0.590770\n",
      "iteration 108 / 300: loss 0.591972\n",
      "iteration 108 / 300: loss 0.615478\n",
      "iteration 108 / 300: loss 0.621369\n",
      "iteration 108 / 300: loss 0.587276\n",
      "iteration 108 / 300: loss 0.582493\n",
      "iteration 108 / 300: loss 0.585582\n",
      "iteration 108 / 300: loss 0.603677\n",
      "iteration 108 / 300: loss 0.585204\n",
      "iteration 108 / 300: loss 0.578890\n",
      "iteration 108 / 300: loss 0.576427\n",
      "iteration 108 / 300: loss 0.574106\n",
      "iteration 108 / 300: loss 0.600508\n",
      "iteration 108 / 300: loss 0.584499\n",
      "iteration 108 / 300: loss 0.584842\n",
      "iteration 108 / 300: loss 0.568332\n",
      "iteration 108 / 300: loss 0.592035\n",
      "iteration 108 / 300: loss 0.612126\n",
      "iteration 108 / 300: loss 0.608931\n",
      "iteration 108 / 300: loss 0.607623\n",
      "iteration 108 / 300: loss 0.595542\n",
      "iteration 108 / 300: loss 0.592846\n",
      "iteration 108 / 300: loss 0.597998\n",
      "iteration 108 / 300: loss 0.597687\n",
      "iteration 108 / 300: loss 0.600962\n",
      "iteration 108 / 300: loss 0.597432\n",
      "iteration 108 / 300: loss 0.598784\n",
      "iteration 108 / 300: loss 0.587816\n",
      "iteration 108 / 300: loss 0.600509\n",
      "iteration 108 / 300: loss 0.599660\n",
      "iteration 108 / 300: loss 0.617550\n",
      "iteration 108 / 300: loss 0.598883\n",
      "iteration 108 / 300: loss 0.600809\n",
      "iteration 108 / 300: loss 0.605315\n",
      "iteration 108 / 300: loss 0.598602\n",
      "iteration 108 / 300: loss 0.591483\n",
      "iteration 108 / 300: loss 0.580391\n",
      "iteration 108 / 300: loss 0.598231\n",
      "iteration 108 / 300: loss 0.611694\n",
      "iteration 108 / 300: loss 0.613228\n",
      "iteration 108 / 300: loss 0.582221\n",
      "iteration 108 / 300: loss 0.601967\n",
      "iteration 108 / 300: loss 0.608967\n",
      "iteration 108 / 300: loss 0.601803\n",
      "iteration 108 / 300: loss 0.607956\n",
      "iteration 108 / 300: loss 0.620249\n",
      "iteration 108 / 300: loss 0.584827\n",
      "iteration 108 / 300: loss 0.583728\n",
      "iteration 108 / 300: loss 0.628858\n",
      "iteration 108 / 300: loss 0.609407\n",
      "iteration 108 / 300: loss 0.606275\n",
      "iteration 108 / 300: loss 0.599043\n",
      "iteration 108 / 300: loss 0.615887\n",
      "iteration 108 / 300: loss 0.596498\n",
      "iteration 108 / 300: loss 0.581440\n",
      "iteration 108 / 300: loss 0.609815\n",
      "iteration 108 / 300: loss 0.608134\n",
      "iteration 108 / 300: loss 0.598234\n",
      "iteration 108 / 300: loss 0.592032\n",
      "iteration 108 / 300: loss 0.611041\n",
      "iteration 108 / 300: loss 0.598559\n",
      "iteration 108 / 300: loss 0.581390\n",
      "iteration 108 / 300: loss 0.609589\n",
      "iteration 109 / 300: loss 0.578394\n",
      "iteration 109 / 300: loss 0.596223\n",
      "iteration 109 / 300: loss 0.569463\n",
      "iteration 109 / 300: loss 0.597859\n",
      "iteration 109 / 300: loss 0.598949\n",
      "iteration 109 / 300: loss 0.603885\n",
      "iteration 109 / 300: loss 0.615268\n",
      "iteration 109 / 300: loss 0.588235\n",
      "iteration 109 / 300: loss 0.627179\n",
      "iteration 109 / 300: loss 0.592610\n",
      "iteration 109 / 300: loss 0.621510\n",
      "iteration 109 / 300: loss 0.593101\n",
      "iteration 109 / 300: loss 0.600549\n",
      "iteration 109 / 300: loss 0.571007\n",
      "iteration 109 / 300: loss 0.592920\n",
      "iteration 109 / 300: loss 0.600052\n",
      "iteration 109 / 300: loss 0.598060\n",
      "iteration 109 / 300: loss 0.583719\n",
      "iteration 109 / 300: loss 0.614363\n",
      "iteration 109 / 300: loss 0.591294\n",
      "iteration 109 / 300: loss 0.591398\n",
      "iteration 109 / 300: loss 0.594012\n",
      "iteration 109 / 300: loss 0.596746\n",
      "iteration 109 / 300: loss 0.596721\n",
      "iteration 109 / 300: loss 0.611743\n",
      "iteration 109 / 300: loss 0.607270\n",
      "iteration 109 / 300: loss 0.597041\n",
      "iteration 109 / 300: loss 0.596308\n",
      "iteration 109 / 300: loss 0.627399\n",
      "iteration 109 / 300: loss 0.601593\n",
      "iteration 109 / 300: loss 0.599931\n",
      "iteration 109 / 300: loss 0.621959\n",
      "iteration 109 / 300: loss 0.581445\n",
      "iteration 109 / 300: loss 0.599614\n",
      "iteration 109 / 300: loss 0.591193\n",
      "iteration 109 / 300: loss 0.599928\n",
      "iteration 109 / 300: loss 0.596024\n",
      "iteration 109 / 300: loss 0.590769\n",
      "iteration 109 / 300: loss 0.591971\n",
      "iteration 109 / 300: loss 0.615477\n",
      "iteration 109 / 300: loss 0.621368\n",
      "iteration 109 / 300: loss 0.587275\n",
      "iteration 109 / 300: loss 0.582492\n",
      "iteration 109 / 300: loss 0.585581\n",
      "iteration 109 / 300: loss 0.603676\n",
      "iteration 109 / 300: loss 0.585202\n",
      "iteration 109 / 300: loss 0.578889\n",
      "iteration 109 / 300: loss 0.576426\n",
      "iteration 109 / 300: loss 0.574105\n",
      "iteration 109 / 300: loss 0.600507\n",
      "iteration 109 / 300: loss 0.584498\n",
      "iteration 109 / 300: loss 0.584841\n",
      "iteration 109 / 300: loss 0.568331\n",
      "iteration 109 / 300: loss 0.592034\n",
      "iteration 109 / 300: loss 0.612125\n",
      "iteration 109 / 300: loss 0.608931\n",
      "iteration 109 / 300: loss 0.607622\n",
      "iteration 109 / 300: loss 0.595541\n",
      "iteration 109 / 300: loss 0.592845\n",
      "iteration 109 / 300: loss 0.597997\n",
      "iteration 109 / 300: loss 0.597686\n",
      "iteration 109 / 300: loss 0.600961\n",
      "iteration 109 / 300: loss 0.597431\n",
      "iteration 109 / 300: loss 0.598783\n",
      "iteration 109 / 300: loss 0.587815\n",
      "iteration 109 / 300: loss 0.600508\n",
      "iteration 109 / 300: loss 0.599659\n",
      "iteration 109 / 300: loss 0.617549\n",
      "iteration 109 / 300: loss 0.598882\n",
      "iteration 109 / 300: loss 0.600808\n",
      "iteration 109 / 300: loss 0.605314\n",
      "iteration 109 / 300: loss 0.598601\n",
      "iteration 109 / 300: loss 0.591482\n",
      "iteration 109 / 300: loss 0.580390\n",
      "iteration 109 / 300: loss 0.598230\n",
      "iteration 109 / 300: loss 0.611693\n",
      "iteration 109 / 300: loss 0.613227\n",
      "iteration 109 / 300: loss 0.582221\n",
      "iteration 109 / 300: loss 0.601966\n",
      "iteration 109 / 300: loss 0.608966\n",
      "iteration 109 / 300: loss 0.601803\n",
      "iteration 109 / 300: loss 0.607955\n",
      "iteration 109 / 300: loss 0.620247\n",
      "iteration 109 / 300: loss 0.584826\n",
      "iteration 109 / 300: loss 0.583728\n",
      "iteration 109 / 300: loss 0.628857\n",
      "iteration 109 / 300: loss 0.609406\n",
      "iteration 109 / 300: loss 0.606274\n",
      "iteration 109 / 300: loss 0.599043\n",
      "iteration 109 / 300: loss 0.615886\n",
      "iteration 109 / 300: loss 0.596497\n",
      "iteration 109 / 300: loss 0.581439\n",
      "iteration 109 / 300: loss 0.609815\n",
      "iteration 109 / 300: loss 0.608133\n",
      "iteration 109 / 300: loss 0.598233\n",
      "iteration 109 / 300: loss 0.592031\n",
      "iteration 109 / 300: loss 0.611040\n",
      "iteration 109 / 300: loss 0.598558\n",
      "iteration 109 / 300: loss 0.581389\n",
      "iteration 109 / 300: loss 0.609588\n",
      "iteration 110 / 300: loss 0.578393\n",
      "iteration 110 / 300: loss 0.596222\n",
      "iteration 110 / 300: loss 0.569463\n",
      "iteration 110 / 300: loss 0.597858\n",
      "iteration 110 / 300: loss 0.598948\n",
      "iteration 110 / 300: loss 0.603885\n",
      "iteration 110 / 300: loss 0.615267\n",
      "iteration 110 / 300: loss 0.588235\n",
      "iteration 110 / 300: loss 0.627178\n",
      "iteration 110 / 300: loss 0.592609\n",
      "iteration 110 / 300: loss 0.621509\n",
      "iteration 110 / 300: loss 0.593100\n",
      "iteration 110 / 300: loss 0.600549\n",
      "iteration 110 / 300: loss 0.571006\n",
      "iteration 110 / 300: loss 0.592919\n",
      "iteration 110 / 300: loss 0.600051\n",
      "iteration 110 / 300: loss 0.598059\n",
      "iteration 110 / 300: loss 0.583718\n",
      "iteration 110 / 300: loss 0.614362\n",
      "iteration 110 / 300: loss 0.591293\n",
      "iteration 110 / 300: loss 0.591397\n",
      "iteration 110 / 300: loss 0.594011\n",
      "iteration 110 / 300: loss 0.596745\n",
      "iteration 110 / 300: loss 0.596720\n",
      "iteration 110 / 300: loss 0.611743\n",
      "iteration 110 / 300: loss 0.607269\n",
      "iteration 110 / 300: loss 0.597040\n",
      "iteration 110 / 300: loss 0.596308\n",
      "iteration 110 / 300: loss 0.627398\n",
      "iteration 110 / 300: loss 0.601593\n",
      "iteration 110 / 300: loss 0.599930\n",
      "iteration 110 / 300: loss 0.621958\n",
      "iteration 110 / 300: loss 0.581444\n",
      "iteration 110 / 300: loss 0.599613\n",
      "iteration 110 / 300: loss 0.591192\n",
      "iteration 110 / 300: loss 0.599928\n",
      "iteration 110 / 300: loss 0.596023\n",
      "iteration 110 / 300: loss 0.590768\n",
      "iteration 110 / 300: loss 0.591970\n",
      "iteration 110 / 300: loss 0.615476\n",
      "iteration 110 / 300: loss 0.621368\n",
      "iteration 110 / 300: loss 0.587275\n",
      "iteration 110 / 300: loss 0.582491\n",
      "iteration 110 / 300: loss 0.585580\n",
      "iteration 110 / 300: loss 0.603675\n",
      "iteration 110 / 300: loss 0.585202\n",
      "iteration 110 / 300: loss 0.578888\n",
      "iteration 110 / 300: loss 0.576426\n",
      "iteration 110 / 300: loss 0.574104\n",
      "iteration 110 / 300: loss 0.600506\n",
      "iteration 110 / 300: loss 0.584497\n",
      "iteration 110 / 300: loss 0.584841\n",
      "iteration 110 / 300: loss 0.568330\n",
      "iteration 110 / 300: loss 0.592033\n",
      "iteration 110 / 300: loss 0.612124\n",
      "iteration 110 / 300: loss 0.608930\n",
      "iteration 110 / 300: loss 0.607621\n",
      "iteration 110 / 300: loss 0.595541\n",
      "iteration 110 / 300: loss 0.592844\n",
      "iteration 110 / 300: loss 0.597997\n",
      "iteration 110 / 300: loss 0.597685\n",
      "iteration 110 / 300: loss 0.600960\n",
      "iteration 110 / 300: loss 0.597430\n",
      "iteration 110 / 300: loss 0.598782\n",
      "iteration 110 / 300: loss 0.587814\n",
      "iteration 110 / 300: loss 0.600507\n",
      "iteration 110 / 300: loss 0.599658\n",
      "iteration 110 / 300: loss 0.617548\n",
      "iteration 110 / 300: loss 0.598882\n",
      "iteration 110 / 300: loss 0.600807\n",
      "iteration 110 / 300: loss 0.605313\n",
      "iteration 110 / 300: loss 0.598600\n",
      "iteration 110 / 300: loss 0.591481\n",
      "iteration 110 / 300: loss 0.580389\n",
      "iteration 110 / 300: loss 0.598229\n",
      "iteration 110 / 300: loss 0.611692\n",
      "iteration 110 / 300: loss 0.613226\n",
      "iteration 110 / 300: loss 0.582220\n",
      "iteration 110 / 300: loss 0.601965\n",
      "iteration 110 / 300: loss 0.608965\n",
      "iteration 110 / 300: loss 0.601802\n",
      "iteration 110 / 300: loss 0.607954\n",
      "iteration 110 / 300: loss 0.620246\n",
      "iteration 110 / 300: loss 0.584825\n",
      "iteration 110 / 300: loss 0.583727\n",
      "iteration 110 / 300: loss 0.628857\n",
      "iteration 110 / 300: loss 0.609405\n",
      "iteration 110 / 300: loss 0.606273\n",
      "iteration 110 / 300: loss 0.599042\n",
      "iteration 110 / 300: loss 0.615885\n",
      "iteration 110 / 300: loss 0.596496\n",
      "iteration 110 / 300: loss 0.581438\n",
      "iteration 110 / 300: loss 0.609814\n",
      "iteration 110 / 300: loss 0.608132\n",
      "iteration 110 / 300: loss 0.598232\n",
      "iteration 110 / 300: loss 0.592030\n",
      "iteration 110 / 300: loss 0.611040\n",
      "iteration 110 / 300: loss 0.598557\n",
      "iteration 110 / 300: loss 0.581388\n",
      "iteration 110 / 300: loss 0.609588\n",
      "iteration 111 / 300: loss 0.578392\n",
      "iteration 111 / 300: loss 0.596222\n",
      "iteration 111 / 300: loss 0.569462\n",
      "iteration 111 / 300: loss 0.597857\n",
      "iteration 111 / 300: loss 0.598947\n",
      "iteration 111 / 300: loss 0.603884\n",
      "iteration 111 / 300: loss 0.615267\n",
      "iteration 111 / 300: loss 0.588234\n",
      "iteration 111 / 300: loss 0.627178\n",
      "iteration 111 / 300: loss 0.592608\n",
      "iteration 111 / 300: loss 0.621508\n",
      "iteration 111 / 300: loss 0.593100\n",
      "iteration 111 / 300: loss 0.600548\n",
      "iteration 111 / 300: loss 0.571006\n",
      "iteration 111 / 300: loss 0.592918\n",
      "iteration 111 / 300: loss 0.600050\n",
      "iteration 111 / 300: loss 0.598059\n",
      "iteration 111 / 300: loss 0.583718\n",
      "iteration 111 / 300: loss 0.614361\n",
      "iteration 111 / 300: loss 0.591292\n",
      "iteration 111 / 300: loss 0.591397\n",
      "iteration 111 / 300: loss 0.594011\n",
      "iteration 111 / 300: loss 0.596744\n",
      "iteration 111 / 300: loss 0.596719\n",
      "iteration 111 / 300: loss 0.611742\n",
      "iteration 111 / 300: loss 0.607268\n",
      "iteration 111 / 300: loss 0.597040\n",
      "iteration 111 / 300: loss 0.596307\n",
      "iteration 111 / 300: loss 0.627398\n",
      "iteration 111 / 300: loss 0.601592\n",
      "iteration 111 / 300: loss 0.599929\n",
      "iteration 111 / 300: loss 0.621958\n",
      "iteration 111 / 300: loss 0.581443\n",
      "iteration 111 / 300: loss 0.599612\n",
      "iteration 111 / 300: loss 0.591191\n",
      "iteration 111 / 300: loss 0.599927\n",
      "iteration 111 / 300: loss 0.596022\n",
      "iteration 111 / 300: loss 0.590767\n",
      "iteration 111 / 300: loss 0.591969\n",
      "iteration 111 / 300: loss 0.615476\n",
      "iteration 111 / 300: loss 0.621367\n",
      "iteration 111 / 300: loss 0.587274\n",
      "iteration 111 / 300: loss 0.582490\n",
      "iteration 111 / 300: loss 0.585580\n",
      "iteration 111 / 300: loss 0.603674\n",
      "iteration 111 / 300: loss 0.585201\n",
      "iteration 111 / 300: loss 0.578888\n",
      "iteration 111 / 300: loss 0.576425\n",
      "iteration 111 / 300: loss 0.574104\n",
      "iteration 111 / 300: loss 0.600506\n",
      "iteration 111 / 300: loss 0.584497\n",
      "iteration 111 / 300: loss 0.584840\n",
      "iteration 111 / 300: loss 0.568330\n",
      "iteration 111 / 300: loss 0.592032\n",
      "iteration 111 / 300: loss 0.612124\n",
      "iteration 111 / 300: loss 0.608929\n",
      "iteration 111 / 300: loss 0.607620\n",
      "iteration 111 / 300: loss 0.595540\n",
      "iteration 111 / 300: loss 0.592843\n",
      "iteration 111 / 300: loss 0.597996\n",
      "iteration 111 / 300: loss 0.597684\n",
      "iteration 111 / 300: loss 0.600960\n",
      "iteration 111 / 300: loss 0.597429\n",
      "iteration 111 / 300: loss 0.598782\n",
      "iteration 111 / 300: loss 0.587814\n",
      "iteration 111 / 300: loss 0.600506\n",
      "iteration 111 / 300: loss 0.599657\n",
      "iteration 111 / 300: loss 0.617547\n",
      "iteration 111 / 300: loss 0.598881\n",
      "iteration 111 / 300: loss 0.600807\n",
      "iteration 111 / 300: loss 0.605313\n",
      "iteration 111 / 300: loss 0.598599\n",
      "iteration 111 / 300: loss 0.591480\n",
      "iteration 111 / 300: loss 0.580389\n",
      "iteration 111 / 300: loss 0.598228\n",
      "iteration 111 / 300: loss 0.611691\n",
      "iteration 111 / 300: loss 0.613225\n",
      "iteration 111 / 300: loss 0.582219\n",
      "iteration 111 / 300: loss 0.601964\n",
      "iteration 111 / 300: loss 0.608964\n",
      "iteration 111 / 300: loss 0.601801\n",
      "iteration 111 / 300: loss 0.607953\n",
      "iteration 111 / 300: loss 0.620245\n",
      "iteration 111 / 300: loss 0.584824\n",
      "iteration 111 / 300: loss 0.583726\n",
      "iteration 111 / 300: loss 0.628856\n",
      "iteration 111 / 300: loss 0.609405\n",
      "iteration 111 / 300: loss 0.606272\n",
      "iteration 111 / 300: loss 0.599041\n",
      "iteration 111 / 300: loss 0.615884\n",
      "iteration 111 / 300: loss 0.596496\n",
      "iteration 111 / 300: loss 0.581438\n",
      "iteration 111 / 300: loss 0.609813\n",
      "iteration 111 / 300: loss 0.608132\n",
      "iteration 111 / 300: loss 0.598231\n",
      "iteration 111 / 300: loss 0.592029\n",
      "iteration 111 / 300: loss 0.611039\n",
      "iteration 111 / 300: loss 0.598556\n",
      "iteration 111 / 300: loss 0.581388\n",
      "iteration 111 / 300: loss 0.609587\n",
      "iteration 112 / 300: loss 0.578392\n",
      "iteration 112 / 300: loss 0.596221\n",
      "iteration 112 / 300: loss 0.569461\n",
      "iteration 112 / 300: loss 0.597856\n",
      "iteration 112 / 300: loss 0.598946\n",
      "iteration 112 / 300: loss 0.603883\n",
      "iteration 112 / 300: loss 0.615266\n",
      "iteration 112 / 300: loss 0.588233\n",
      "iteration 112 / 300: loss 0.627177\n",
      "iteration 112 / 300: loss 0.592608\n",
      "iteration 112 / 300: loss 0.621508\n",
      "iteration 112 / 300: loss 0.593099\n",
      "iteration 112 / 300: loss 0.600547\n",
      "iteration 112 / 300: loss 0.571005\n",
      "iteration 112 / 300: loss 0.592918\n",
      "iteration 112 / 300: loss 0.600049\n",
      "iteration 112 / 300: loss 0.598058\n",
      "iteration 112 / 300: loss 0.583717\n",
      "iteration 112 / 300: loss 0.614361\n",
      "iteration 112 / 300: loss 0.591292\n",
      "iteration 112 / 300: loss 0.591396\n",
      "iteration 112 / 300: loss 0.594010\n",
      "iteration 112 / 300: loss 0.596743\n",
      "iteration 112 / 300: loss 0.596719\n",
      "iteration 112 / 300: loss 0.611741\n",
      "iteration 112 / 300: loss 0.607267\n",
      "iteration 112 / 300: loss 0.597039\n",
      "iteration 112 / 300: loss 0.596306\n",
      "iteration 112 / 300: loss 0.627397\n",
      "iteration 112 / 300: loss 0.601591\n",
      "iteration 112 / 300: loss 0.599929\n",
      "iteration 112 / 300: loss 0.621957\n",
      "iteration 112 / 300: loss 0.581443\n",
      "iteration 112 / 300: loss 0.599611\n",
      "iteration 112 / 300: loss 0.591190\n",
      "iteration 112 / 300: loss 0.599926\n",
      "iteration 112 / 300: loss 0.596022\n",
      "iteration 112 / 300: loss 0.590767\n",
      "iteration 112 / 300: loss 0.591969\n",
      "iteration 112 / 300: loss 0.615475\n",
      "iteration 112 / 300: loss 0.621366\n",
      "iteration 112 / 300: loss 0.587273\n",
      "iteration 112 / 300: loss 0.582490\n",
      "iteration 112 / 300: loss 0.585579\n",
      "iteration 112 / 300: loss 0.603673\n",
      "iteration 112 / 300: loss 0.585200\n",
      "iteration 112 / 300: loss 0.578887\n",
      "iteration 112 / 300: loss 0.576424\n",
      "iteration 112 / 300: loss 0.574103\n",
      "iteration 112 / 300: loss 0.600505\n",
      "iteration 112 / 300: loss 0.584496\n",
      "iteration 112 / 300: loss 0.584839\n",
      "iteration 112 / 300: loss 0.568329\n",
      "iteration 112 / 300: loss 0.592032\n",
      "iteration 112 / 300: loss 0.612123\n",
      "iteration 112 / 300: loss 0.608929\n",
      "iteration 112 / 300: loss 0.607619\n",
      "iteration 112 / 300: loss 0.595539\n",
      "iteration 112 / 300: loss 0.592843\n",
      "iteration 112 / 300: loss 0.597995\n",
      "iteration 112 / 300: loss 0.597683\n",
      "iteration 112 / 300: loss 0.600959\n",
      "iteration 112 / 300: loss 0.597429\n",
      "iteration 112 / 300: loss 0.598781\n",
      "iteration 112 / 300: loss 0.587813\n",
      "iteration 112 / 300: loss 0.600506\n",
      "iteration 112 / 300: loss 0.599657\n",
      "iteration 112 / 300: loss 0.617547\n",
      "iteration 112 / 300: loss 0.598880\n",
      "iteration 112 / 300: loss 0.600806\n",
      "iteration 112 / 300: loss 0.605312\n",
      "iteration 112 / 300: loss 0.598599\n",
      "iteration 112 / 300: loss 0.591480\n",
      "iteration 112 / 300: loss 0.580388\n",
      "iteration 112 / 300: loss 0.598228\n",
      "iteration 112 / 300: loss 0.611691\n",
      "iteration 112 / 300: loss 0.613225\n",
      "iteration 112 / 300: loss 0.582219\n",
      "iteration 112 / 300: loss 0.601963\n",
      "iteration 112 / 300: loss 0.608963\n",
      "iteration 112 / 300: loss 0.601800\n",
      "iteration 112 / 300: loss 0.607952\n",
      "iteration 112 / 300: loss 0.620245\n",
      "iteration 112 / 300: loss 0.584823\n",
      "iteration 112 / 300: loss 0.583726\n",
      "iteration 112 / 300: loss 0.628855\n",
      "iteration 112 / 300: loss 0.609404\n",
      "iteration 112 / 300: loss 0.606272\n",
      "iteration 112 / 300: loss 0.599040\n",
      "iteration 112 / 300: loss 0.615884\n",
      "iteration 112 / 300: loss 0.596495\n",
      "iteration 112 / 300: loss 0.581437\n",
      "iteration 112 / 300: loss 0.609813\n",
      "iteration 112 / 300: loss 0.608131\n",
      "iteration 112 / 300: loss 0.598231\n",
      "iteration 112 / 300: loss 0.592029\n",
      "iteration 112 / 300: loss 0.611038\n",
      "iteration 112 / 300: loss 0.598556\n",
      "iteration 112 / 300: loss 0.581387\n",
      "iteration 112 / 300: loss 0.609586\n",
      "iteration 113 / 300: loss 0.578391\n",
      "iteration 113 / 300: loss 0.596220\n",
      "iteration 113 / 300: loss 0.569461\n",
      "iteration 113 / 300: loss 0.597856\n",
      "iteration 113 / 300: loss 0.598946\n",
      "iteration 113 / 300: loss 0.603882\n",
      "iteration 113 / 300: loss 0.615266\n",
      "iteration 113 / 300: loss 0.588233\n",
      "iteration 113 / 300: loss 0.627177\n",
      "iteration 113 / 300: loss 0.592607\n",
      "iteration 113 / 300: loss 0.621507\n",
      "iteration 113 / 300: loss 0.593099\n",
      "iteration 113 / 300: loss 0.600547\n",
      "iteration 113 / 300: loss 0.571005\n",
      "iteration 113 / 300: loss 0.592917\n",
      "iteration 113 / 300: loss 0.600049\n",
      "iteration 113 / 300: loss 0.598058\n",
      "iteration 113 / 300: loss 0.583717\n",
      "iteration 113 / 300: loss 0.614360\n",
      "iteration 113 / 300: loss 0.591291\n",
      "iteration 113 / 300: loss 0.591396\n",
      "iteration 113 / 300: loss 0.594010\n",
      "iteration 113 / 300: loss 0.596742\n",
      "iteration 113 / 300: loss 0.596718\n",
      "iteration 113 / 300: loss 0.611741\n",
      "iteration 113 / 300: loss 0.607266\n",
      "iteration 113 / 300: loss 0.597038\n",
      "iteration 113 / 300: loss 0.596306\n",
      "iteration 113 / 300: loss 0.627396\n",
      "iteration 113 / 300: loss 0.601590\n",
      "iteration 113 / 300: loss 0.599928\n",
      "iteration 113 / 300: loss 0.621957\n",
      "iteration 113 / 300: loss 0.581442\n",
      "iteration 113 / 300: loss 0.599611\n",
      "iteration 113 / 300: loss 0.591189\n",
      "iteration 113 / 300: loss 0.599925\n",
      "iteration 113 / 300: loss 0.596021\n",
      "iteration 113 / 300: loss 0.590766\n",
      "iteration 113 / 300: loss 0.591968\n",
      "iteration 113 / 300: loss 0.615474\n",
      "iteration 113 / 300: loss 0.621366\n",
      "iteration 113 / 300: loss 0.587273\n",
      "iteration 113 / 300: loss 0.582489\n",
      "iteration 113 / 300: loss 0.585578\n",
      "iteration 113 / 300: loss 0.603673\n",
      "iteration 113 / 300: loss 0.585199\n",
      "iteration 113 / 300: loss 0.578886\n",
      "iteration 113 / 300: loss 0.576424\n",
      "iteration 113 / 300: loss 0.574103\n",
      "iteration 113 / 300: loss 0.600505\n",
      "iteration 113 / 300: loss 0.584495\n",
      "iteration 113 / 300: loss 0.584839\n",
      "iteration 113 / 300: loss 0.568329\n",
      "iteration 113 / 300: loss 0.592031\n",
      "iteration 113 / 300: loss 0.612122\n",
      "iteration 113 / 300: loss 0.608928\n",
      "iteration 113 / 300: loss 0.607619\n",
      "iteration 113 / 300: loss 0.595539\n",
      "iteration 113 / 300: loss 0.592842\n",
      "iteration 113 / 300: loss 0.597994\n",
      "iteration 113 / 300: loss 0.597683\n",
      "iteration 113 / 300: loss 0.600958\n",
      "iteration 113 / 300: loss 0.597428\n",
      "iteration 113 / 300: loss 0.598781\n",
      "iteration 113 / 300: loss 0.587812\n",
      "iteration 113 / 300: loss 0.600505\n",
      "iteration 113 / 300: loss 0.599656\n",
      "iteration 113 / 300: loss 0.617546\n",
      "iteration 113 / 300: loss 0.598880\n",
      "iteration 113 / 300: loss 0.600806\n",
      "iteration 113 / 300: loss 0.605311\n",
      "iteration 113 / 300: loss 0.598598\n",
      "iteration 113 / 300: loss 0.591479\n",
      "iteration 113 / 300: loss 0.580387\n",
      "iteration 113 / 300: loss 0.598227\n",
      "iteration 113 / 300: loss 0.611690\n",
      "iteration 113 / 300: loss 0.613224\n",
      "iteration 113 / 300: loss 0.582218\n",
      "iteration 113 / 300: loss 0.601962\n",
      "iteration 113 / 300: loss 0.608963\n",
      "iteration 113 / 300: loss 0.601800\n",
      "iteration 113 / 300: loss 0.607951\n",
      "iteration 113 / 300: loss 0.620244\n",
      "iteration 113 / 300: loss 0.584823\n",
      "iteration 113 / 300: loss 0.583725\n",
      "iteration 113 / 300: loss 0.628855\n",
      "iteration 113 / 300: loss 0.609404\n",
      "iteration 113 / 300: loss 0.606271\n",
      "iteration 113 / 300: loss 0.599040\n",
      "iteration 113 / 300: loss 0.615883\n",
      "iteration 113 / 300: loss 0.596494\n",
      "iteration 113 / 300: loss 0.581436\n",
      "iteration 113 / 300: loss 0.609812\n",
      "iteration 113 / 300: loss 0.608130\n",
      "iteration 113 / 300: loss 0.598230\n",
      "iteration 113 / 300: loss 0.592028\n",
      "iteration 113 / 300: loss 0.611037\n",
      "iteration 113 / 300: loss 0.598555\n",
      "iteration 113 / 300: loss 0.581387\n",
      "iteration 113 / 300: loss 0.609585\n",
      "iteration 114 / 300: loss 0.578390\n",
      "iteration 114 / 300: loss 0.596220\n",
      "iteration 114 / 300: loss 0.569460\n",
      "iteration 114 / 300: loss 0.597855\n",
      "iteration 114 / 300: loss 0.598945\n",
      "iteration 114 / 300: loss 0.603882\n",
      "iteration 114 / 300: loss 0.615265\n",
      "iteration 114 / 300: loss 0.588232\n",
      "iteration 114 / 300: loss 0.627176\n",
      "iteration 114 / 300: loss 0.592606\n",
      "iteration 114 / 300: loss 0.621506\n",
      "iteration 114 / 300: loss 0.593098\n",
      "iteration 114 / 300: loss 0.600546\n",
      "iteration 114 / 300: loss 0.571004\n",
      "iteration 114 / 300: loss 0.592917\n",
      "iteration 114 / 300: loss 0.600048\n",
      "iteration 114 / 300: loss 0.598057\n",
      "iteration 114 / 300: loss 0.583716\n",
      "iteration 114 / 300: loss 0.614360\n",
      "iteration 114 / 300: loss 0.591291\n",
      "iteration 114 / 300: loss 0.591395\n",
      "iteration 114 / 300: loss 0.594009\n",
      "iteration 114 / 300: loss 0.596741\n",
      "iteration 114 / 300: loss 0.596717\n",
      "iteration 114 / 300: loss 0.611740\n",
      "iteration 114 / 300: loss 0.607265\n",
      "iteration 114 / 300: loss 0.597037\n",
      "iteration 114 / 300: loss 0.596305\n",
      "iteration 114 / 300: loss 0.627396\n",
      "iteration 114 / 300: loss 0.601590\n",
      "iteration 114 / 300: loss 0.599928\n",
      "iteration 114 / 300: loss 0.621956\n",
      "iteration 114 / 300: loss 0.581441\n",
      "iteration 114 / 300: loss 0.599610\n",
      "iteration 114 / 300: loss 0.591189\n",
      "iteration 114 / 300: loss 0.599925\n",
      "iteration 114 / 300: loss 0.596021\n",
      "iteration 114 / 300: loss 0.590766\n",
      "iteration 114 / 300: loss 0.591967\n",
      "iteration 114 / 300: loss 0.615474\n",
      "iteration 114 / 300: loss 0.621365\n",
      "iteration 114 / 300: loss 0.587272\n",
      "iteration 114 / 300: loss 0.582488\n",
      "iteration 114 / 300: loss 0.585578\n",
      "iteration 114 / 300: loss 0.603672\n",
      "iteration 114 / 300: loss 0.585198\n",
      "iteration 114 / 300: loss 0.578886\n",
      "iteration 114 / 300: loss 0.576423\n",
      "iteration 114 / 300: loss 0.574102\n",
      "iteration 114 / 300: loss 0.600504\n",
      "iteration 114 / 300: loss 0.584495\n",
      "iteration 114 / 300: loss 0.584838\n",
      "iteration 114 / 300: loss 0.568328\n",
      "iteration 114 / 300: loss 0.592031\n",
      "iteration 114 / 300: loss 0.612122\n",
      "iteration 114 / 300: loss 0.608927\n",
      "iteration 114 / 300: loss 0.607618\n",
      "iteration 114 / 300: loss 0.595538\n",
      "iteration 114 / 300: loss 0.592842\n",
      "iteration 114 / 300: loss 0.597994\n",
      "iteration 114 / 300: loss 0.597682\n",
      "iteration 114 / 300: loss 0.600958\n",
      "iteration 114 / 300: loss 0.597427\n",
      "iteration 114 / 300: loss 0.598780\n",
      "iteration 114 / 300: loss 0.587812\n",
      "iteration 114 / 300: loss 0.600505\n",
      "iteration 114 / 300: loss 0.599655\n",
      "iteration 114 / 300: loss 0.617546\n",
      "iteration 114 / 300: loss 0.598879\n",
      "iteration 114 / 300: loss 0.600805\n",
      "iteration 114 / 300: loss 0.605311\n",
      "iteration 114 / 300: loss 0.598597\n",
      "iteration 114 / 300: loss 0.591479\n",
      "iteration 114 / 300: loss 0.580387\n",
      "iteration 114 / 300: loss 0.598227\n",
      "iteration 114 / 300: loss 0.611690\n",
      "iteration 114 / 300: loss 0.613224\n",
      "iteration 114 / 300: loss 0.582218\n",
      "iteration 114 / 300: loss 0.601962\n",
      "iteration 114 / 300: loss 0.608962\n",
      "iteration 114 / 300: loss 0.601799\n",
      "iteration 114 / 300: loss 0.607951\n",
      "iteration 114 / 300: loss 0.620243\n",
      "iteration 114 / 300: loss 0.584822\n",
      "iteration 114 / 300: loss 0.583725\n",
      "iteration 114 / 300: loss 0.628854\n",
      "iteration 114 / 300: loss 0.609403\n",
      "iteration 114 / 300: loss 0.606271\n",
      "iteration 114 / 300: loss 0.599039\n",
      "iteration 114 / 300: loss 0.615882\n",
      "iteration 114 / 300: loss 0.596494\n",
      "iteration 114 / 300: loss 0.581436\n",
      "iteration 114 / 300: loss 0.609812\n",
      "iteration 114 / 300: loss 0.608130\n",
      "iteration 114 / 300: loss 0.598230\n",
      "iteration 114 / 300: loss 0.592027\n",
      "iteration 114 / 300: loss 0.611037\n",
      "iteration 114 / 300: loss 0.598555\n",
      "iteration 114 / 300: loss 0.581386\n",
      "iteration 114 / 300: loss 0.609585\n",
      "iteration 115 / 300: loss 0.578390\n",
      "iteration 115 / 300: loss 0.596219\n",
      "iteration 115 / 300: loss 0.569459\n",
      "iteration 115 / 300: loss 0.597855\n",
      "iteration 115 / 300: loss 0.598945\n",
      "iteration 115 / 300: loss 0.603881\n",
      "iteration 115 / 300: loss 0.615265\n",
      "iteration 115 / 300: loss 0.588231\n",
      "iteration 115 / 300: loss 0.627176\n",
      "iteration 115 / 300: loss 0.592606\n",
      "iteration 115 / 300: loss 0.621505\n",
      "iteration 115 / 300: loss 0.593098\n",
      "iteration 115 / 300: loss 0.600546\n",
      "iteration 115 / 300: loss 0.571004\n",
      "iteration 115 / 300: loss 0.592916\n",
      "iteration 115 / 300: loss 0.600048\n",
      "iteration 115 / 300: loss 0.598057\n",
      "iteration 115 / 300: loss 0.583716\n",
      "iteration 115 / 300: loss 0.614359\n",
      "iteration 115 / 300: loss 0.591290\n",
      "iteration 115 / 300: loss 0.591395\n",
      "iteration 115 / 300: loss 0.594009\n",
      "iteration 115 / 300: loss 0.596741\n",
      "iteration 115 / 300: loss 0.596717\n",
      "iteration 115 / 300: loss 0.611739\n",
      "iteration 115 / 300: loss 0.607264\n",
      "iteration 115 / 300: loss 0.597037\n",
      "iteration 115 / 300: loss 0.596305\n",
      "iteration 115 / 300: loss 0.627395\n",
      "iteration 115 / 300: loss 0.601589\n",
      "iteration 115 / 300: loss 0.599927\n",
      "iteration 115 / 300: loss 0.621956\n",
      "iteration 115 / 300: loss 0.581441\n",
      "iteration 115 / 300: loss 0.599609\n",
      "iteration 115 / 300: loss 0.591188\n",
      "iteration 115 / 300: loss 0.599924\n",
      "iteration 115 / 300: loss 0.596020\n",
      "iteration 115 / 300: loss 0.590765\n",
      "iteration 115 / 300: loss 0.591967\n",
      "iteration 115 / 300: loss 0.615473\n",
      "iteration 115 / 300: loss 0.621365\n",
      "iteration 115 / 300: loss 0.587271\n",
      "iteration 115 / 300: loss 0.582488\n",
      "iteration 115 / 300: loss 0.585577\n",
      "iteration 115 / 300: loss 0.603671\n",
      "iteration 115 / 300: loss 0.585198\n",
      "iteration 115 / 300: loss 0.578885\n",
      "iteration 115 / 300: loss 0.576423\n",
      "iteration 115 / 300: loss 0.574102\n",
      "iteration 115 / 300: loss 0.600504\n",
      "iteration 115 / 300: loss 0.584494\n",
      "iteration 115 / 300: loss 0.584838\n",
      "iteration 115 / 300: loss 0.568328\n",
      "iteration 115 / 300: loss 0.592030\n",
      "iteration 115 / 300: loss 0.612121\n",
      "iteration 115 / 300: loss 0.608927\n",
      "iteration 115 / 300: loss 0.607618\n",
      "iteration 115 / 300: loss 0.595538\n",
      "iteration 115 / 300: loss 0.592841\n",
      "iteration 115 / 300: loss 0.597993\n",
      "iteration 115 / 300: loss 0.597682\n",
      "iteration 115 / 300: loss 0.600957\n",
      "iteration 115 / 300: loss 0.597427\n",
      "iteration 115 / 300: loss 0.598780\n",
      "iteration 115 / 300: loss 0.587811\n",
      "iteration 115 / 300: loss 0.600504\n",
      "iteration 115 / 300: loss 0.599655\n",
      "iteration 115 / 300: loss 0.617545\n",
      "iteration 115 / 300: loss 0.598879\n",
      "iteration 115 / 300: loss 0.600805\n",
      "iteration 115 / 300: loss 0.605310\n",
      "iteration 115 / 300: loss 0.598597\n",
      "iteration 115 / 300: loss 0.591478\n",
      "iteration 115 / 300: loss 0.580387\n",
      "iteration 115 / 300: loss 0.598226\n",
      "iteration 115 / 300: loss 0.611689\n",
      "iteration 115 / 300: loss 0.613223\n",
      "iteration 115 / 300: loss 0.582218\n",
      "iteration 115 / 300: loss 0.601961\n",
      "iteration 115 / 300: loss 0.608961\n",
      "iteration 115 / 300: loss 0.601799\n",
      "iteration 115 / 300: loss 0.607950\n",
      "iteration 115 / 300: loss 0.620242\n",
      "iteration 115 / 300: loss 0.584822\n",
      "iteration 115 / 300: loss 0.583725\n",
      "iteration 115 / 300: loss 0.628854\n",
      "iteration 115 / 300: loss 0.609403\n",
      "iteration 115 / 300: loss 0.606270\n",
      "iteration 115 / 300: loss 0.599039\n",
      "iteration 115 / 300: loss 0.615882\n",
      "iteration 115 / 300: loss 0.596493\n",
      "iteration 115 / 300: loss 0.581435\n",
      "iteration 115 / 300: loss 0.609811\n",
      "iteration 115 / 300: loss 0.608129\n",
      "iteration 115 / 300: loss 0.598229\n",
      "iteration 115 / 300: loss 0.592027\n",
      "iteration 115 / 300: loss 0.611036\n",
      "iteration 115 / 300: loss 0.598554\n",
      "iteration 115 / 300: loss 0.581386\n",
      "iteration 115 / 300: loss 0.609584\n",
      "iteration 116 / 300: loss 0.578389\n",
      "iteration 116 / 300: loss 0.596219\n",
      "iteration 116 / 300: loss 0.569459\n",
      "iteration 116 / 300: loss 0.597854\n",
      "iteration 116 / 300: loss 0.598944\n",
      "iteration 116 / 300: loss 0.603881\n",
      "iteration 116 / 300: loss 0.615265\n",
      "iteration 116 / 300: loss 0.588231\n",
      "iteration 116 / 300: loss 0.627175\n",
      "iteration 116 / 300: loss 0.592605\n",
      "iteration 116 / 300: loss 0.621505\n",
      "iteration 116 / 300: loss 0.593097\n",
      "iteration 116 / 300: loss 0.600545\n",
      "iteration 116 / 300: loss 0.571003\n",
      "iteration 116 / 300: loss 0.592916\n",
      "iteration 116 / 300: loss 0.600047\n",
      "iteration 116 / 300: loss 0.598056\n",
      "iteration 116 / 300: loss 0.583715\n",
      "iteration 116 / 300: loss 0.614359\n",
      "iteration 116 / 300: loss 0.591290\n",
      "iteration 116 / 300: loss 0.591394\n",
      "iteration 116 / 300: loss 0.594008\n",
      "iteration 116 / 300: loss 0.596740\n",
      "iteration 116 / 300: loss 0.596716\n",
      "iteration 116 / 300: loss 0.611739\n",
      "iteration 116 / 300: loss 0.607264\n",
      "iteration 116 / 300: loss 0.597036\n",
      "iteration 116 / 300: loss 0.596304\n",
      "iteration 116 / 300: loss 0.627395\n",
      "iteration 116 / 300: loss 0.601589\n",
      "iteration 116 / 300: loss 0.599927\n",
      "iteration 116 / 300: loss 0.621955\n",
      "iteration 116 / 300: loss 0.581440\n",
      "iteration 116 / 300: loss 0.599609\n",
      "iteration 116 / 300: loss 0.591187\n",
      "iteration 116 / 300: loss 0.599924\n",
      "iteration 116 / 300: loss 0.596020\n",
      "iteration 116 / 300: loss 0.590765\n",
      "iteration 116 / 300: loss 0.591966\n",
      "iteration 116 / 300: loss 0.615472\n",
      "iteration 116 / 300: loss 0.621364\n",
      "iteration 116 / 300: loss 0.587271\n",
      "iteration 116 / 300: loss 0.582487\n",
      "iteration 116 / 300: loss 0.585577\n",
      "iteration 116 / 300: loss 0.603671\n",
      "iteration 116 / 300: loss 0.585197\n",
      "iteration 116 / 300: loss 0.578885\n",
      "iteration 116 / 300: loss 0.576422\n",
      "iteration 116 / 300: loss 0.574101\n",
      "iteration 116 / 300: loss 0.600503\n",
      "iteration 116 / 300: loss 0.584494\n",
      "iteration 116 / 300: loss 0.584837\n",
      "iteration 116 / 300: loss 0.568327\n",
      "iteration 116 / 300: loss 0.592030\n",
      "iteration 116 / 300: loss 0.612121\n",
      "iteration 116 / 300: loss 0.608927\n",
      "iteration 116 / 300: loss 0.607617\n",
      "iteration 116 / 300: loss 0.595537\n",
      "iteration 116 / 300: loss 0.592841\n",
      "iteration 116 / 300: loss 0.597993\n",
      "iteration 116 / 300: loss 0.597681\n",
      "iteration 116 / 300: loss 0.600957\n",
      "iteration 116 / 300: loss 0.597426\n",
      "iteration 116 / 300: loss 0.598779\n",
      "iteration 116 / 300: loss 0.587811\n",
      "iteration 116 / 300: loss 0.600504\n",
      "iteration 116 / 300: loss 0.599654\n",
      "iteration 116 / 300: loss 0.617545\n",
      "iteration 116 / 300: loss 0.598878\n",
      "iteration 116 / 300: loss 0.600805\n",
      "iteration 116 / 300: loss 0.605310\n",
      "iteration 116 / 300: loss 0.598597\n",
      "iteration 116 / 300: loss 0.591478\n",
      "iteration 116 / 300: loss 0.580386\n",
      "iteration 116 / 300: loss 0.598226\n",
      "iteration 116 / 300: loss 0.611689\n",
      "iteration 116 / 300: loss 0.613223\n",
      "iteration 116 / 300: loss 0.582217\n",
      "iteration 116 / 300: loss 0.601961\n",
      "iteration 116 / 300: loss 0.608961\n",
      "iteration 116 / 300: loss 0.601798\n",
      "iteration 116 / 300: loss 0.607950\n",
      "iteration 116 / 300: loss 0.620242\n",
      "iteration 116 / 300: loss 0.584821\n",
      "iteration 116 / 300: loss 0.583724\n",
      "iteration 116 / 300: loss 0.628853\n",
      "iteration 116 / 300: loss 0.609402\n",
      "iteration 116 / 300: loss 0.606270\n",
      "iteration 116 / 300: loss 0.599038\n",
      "iteration 116 / 300: loss 0.615881\n",
      "iteration 116 / 300: loss 0.596493\n",
      "iteration 116 / 300: loss 0.581435\n",
      "iteration 116 / 300: loss 0.609811\n",
      "iteration 116 / 300: loss 0.608129\n",
      "iteration 116 / 300: loss 0.598229\n",
      "iteration 116 / 300: loss 0.592026\n",
      "iteration 116 / 300: loss 0.611036\n",
      "iteration 116 / 300: loss 0.598554\n",
      "iteration 116 / 300: loss 0.581385\n",
      "iteration 116 / 300: loss 0.609584\n",
      "iteration 117 / 300: loss 0.578389\n",
      "iteration 117 / 300: loss 0.596218\n",
      "iteration 117 / 300: loss 0.569459\n",
      "iteration 117 / 300: loss 0.597854\n",
      "iteration 117 / 300: loss 0.598944\n",
      "iteration 117 / 300: loss 0.603880\n",
      "iteration 117 / 300: loss 0.615264\n",
      "iteration 117 / 300: loss 0.588231\n",
      "iteration 117 / 300: loss 0.627175\n",
      "iteration 117 / 300: loss 0.592605\n",
      "iteration 117 / 300: loss 0.621504\n",
      "iteration 117 / 300: loss 0.593097\n",
      "iteration 117 / 300: loss 0.600545\n",
      "iteration 117 / 300: loss 0.571003\n",
      "iteration 117 / 300: loss 0.592915\n",
      "iteration 117 / 300: loss 0.600047\n",
      "iteration 117 / 300: loss 0.598056\n",
      "iteration 117 / 300: loss 0.583715\n",
      "iteration 117 / 300: loss 0.614358\n",
      "iteration 117 / 300: loss 0.591289\n",
      "iteration 117 / 300: loss 0.591394\n",
      "iteration 117 / 300: loss 0.594008\n",
      "iteration 117 / 300: loss 0.596740\n",
      "iteration 117 / 300: loss 0.596716\n",
      "iteration 117 / 300: loss 0.611739\n",
      "iteration 117 / 300: loss 0.607263\n",
      "iteration 117 / 300: loss 0.597036\n",
      "iteration 117 / 300: loss 0.596304\n",
      "iteration 117 / 300: loss 0.627395\n",
      "iteration 117 / 300: loss 0.601588\n",
      "iteration 117 / 300: loss 0.599927\n",
      "iteration 117 / 300: loss 0.621955\n",
      "iteration 117 / 300: loss 0.581439\n",
      "iteration 117 / 300: loss 0.599608\n",
      "iteration 117 / 300: loss 0.591187\n",
      "iteration 117 / 300: loss 0.599923\n",
      "iteration 117 / 300: loss 0.596019\n",
      "iteration 117 / 300: loss 0.590764\n",
      "iteration 117 / 300: loss 0.591966\n",
      "iteration 117 / 300: loss 0.615472\n",
      "iteration 117 / 300: loss 0.621364\n",
      "iteration 117 / 300: loss 0.587271\n",
      "iteration 117 / 300: loss 0.582487\n",
      "iteration 117 / 300: loss 0.585576\n",
      "iteration 117 / 300: loss 0.603670\n",
      "iteration 117 / 300: loss 0.585197\n",
      "iteration 117 / 300: loss 0.578884\n",
      "iteration 117 / 300: loss 0.576422\n",
      "iteration 117 / 300: loss 0.574101\n",
      "iteration 117 / 300: loss 0.600503\n",
      "iteration 117 / 300: loss 0.584494\n",
      "iteration 117 / 300: loss 0.584837\n",
      "iteration 117 / 300: loss 0.568327\n",
      "iteration 117 / 300: loss 0.592029\n",
      "iteration 117 / 300: loss 0.612120\n",
      "iteration 117 / 300: loss 0.608926\n",
      "iteration 117 / 300: loss 0.607617\n",
      "iteration 117 / 300: loss 0.595537\n",
      "iteration 117 / 300: loss 0.592840\n",
      "iteration 117 / 300: loss 0.597992\n",
      "iteration 117 / 300: loss 0.597681\n",
      "iteration 117 / 300: loss 0.600957\n",
      "iteration 117 / 300: loss 0.597426\n",
      "iteration 117 / 300: loss 0.598779\n",
      "iteration 117 / 300: loss 0.587810\n",
      "iteration 117 / 300: loss 0.600503\n",
      "iteration 117 / 300: loss 0.599654\n",
      "iteration 117 / 300: loss 0.617544\n",
      "iteration 117 / 300: loss 0.598878\n",
      "iteration 117 / 300: loss 0.600804\n",
      "iteration 117 / 300: loss 0.605309\n",
      "iteration 117 / 300: loss 0.598596\n",
      "iteration 117 / 300: loss 0.591477\n",
      "iteration 117 / 300: loss 0.580386\n",
      "iteration 117 / 300: loss 0.598225\n",
      "iteration 117 / 300: loss 0.611688\n",
      "iteration 117 / 300: loss 0.613223\n",
      "iteration 117 / 300: loss 0.582217\n",
      "iteration 117 / 300: loss 0.601960\n",
      "iteration 117 / 300: loss 0.608961\n",
      "iteration 117 / 300: loss 0.601798\n",
      "iteration 117 / 300: loss 0.607949\n",
      "iteration 117 / 300: loss 0.620241\n",
      "iteration 117 / 300: loss 0.584821\n",
      "iteration 117 / 300: loss 0.583724\n",
      "iteration 117 / 300: loss 0.628853\n",
      "iteration 117 / 300: loss 0.609402\n",
      "iteration 117 / 300: loss 0.606269\n",
      "iteration 117 / 300: loss 0.599038\n",
      "iteration 117 / 300: loss 0.615881\n",
      "iteration 117 / 300: loss 0.596492\n",
      "iteration 117 / 300: loss 0.581434\n",
      "iteration 117 / 300: loss 0.609810\n",
      "iteration 117 / 300: loss 0.608129\n",
      "iteration 117 / 300: loss 0.598228\n",
      "iteration 117 / 300: loss 0.592026\n",
      "iteration 117 / 300: loss 0.611035\n",
      "iteration 117 / 300: loss 0.598553\n",
      "iteration 117 / 300: loss 0.581385\n",
      "iteration 117 / 300: loss 0.609584\n",
      "iteration 118 / 300: loss 0.578388\n",
      "iteration 118 / 300: loss 0.596218\n",
      "iteration 118 / 300: loss 0.569458\n",
      "iteration 118 / 300: loss 0.597853\n",
      "iteration 118 / 300: loss 0.598943\n",
      "iteration 118 / 300: loss 0.603880\n",
      "iteration 118 / 300: loss 0.615264\n",
      "iteration 118 / 300: loss 0.588230\n",
      "iteration 118 / 300: loss 0.627174\n",
      "iteration 118 / 300: loss 0.592604\n",
      "iteration 118 / 300: loss 0.621504\n",
      "iteration 118 / 300: loss 0.593097\n",
      "iteration 118 / 300: loss 0.600544\n",
      "iteration 118 / 300: loss 0.571003\n",
      "iteration 118 / 300: loss 0.592915\n",
      "iteration 118 / 300: loss 0.600046\n",
      "iteration 118 / 300: loss 0.598056\n",
      "iteration 118 / 300: loss 0.583715\n",
      "iteration 118 / 300: loss 0.614358\n",
      "iteration 118 / 300: loss 0.591289\n",
      "iteration 118 / 300: loss 0.591394\n",
      "iteration 118 / 300: loss 0.594008\n",
      "iteration 118 / 300: loss 0.596739\n",
      "iteration 118 / 300: loss 0.596716\n",
      "iteration 118 / 300: loss 0.611738\n",
      "iteration 118 / 300: loss 0.607263\n",
      "iteration 118 / 300: loss 0.597035\n",
      "iteration 118 / 300: loss 0.596304\n",
      "iteration 118 / 300: loss 0.627394\n",
      "iteration 118 / 300: loss 0.601588\n",
      "iteration 118 / 300: loss 0.599926\n",
      "iteration 118 / 300: loss 0.621955\n",
      "iteration 118 / 300: loss 0.581439\n",
      "iteration 118 / 300: loss 0.599608\n",
      "iteration 118 / 300: loss 0.591186\n",
      "iteration 118 / 300: loss 0.599923\n",
      "iteration 118 / 300: loss 0.596019\n",
      "iteration 118 / 300: loss 0.590764\n",
      "iteration 118 / 300: loss 0.591965\n",
      "iteration 118 / 300: loss 0.615472\n",
      "iteration 118 / 300: loss 0.621363\n",
      "iteration 118 / 300: loss 0.587270\n",
      "iteration 118 / 300: loss 0.582487\n",
      "iteration 118 / 300: loss 0.585576\n",
      "iteration 118 / 300: loss 0.603670\n",
      "iteration 118 / 300: loss 0.585196\n",
      "iteration 118 / 300: loss 0.578884\n",
      "iteration 118 / 300: loss 0.576422\n",
      "iteration 118 / 300: loss 0.574100\n",
      "iteration 118 / 300: loss 0.600503\n",
      "iteration 118 / 300: loss 0.584493\n",
      "iteration 118 / 300: loss 0.584837\n",
      "iteration 118 / 300: loss 0.568326\n",
      "iteration 118 / 300: loss 0.592029\n",
      "iteration 118 / 300: loss 0.612120\n",
      "iteration 118 / 300: loss 0.608926\n",
      "iteration 118 / 300: loss 0.607616\n",
      "iteration 118 / 300: loss 0.595537\n",
      "iteration 118 / 300: loss 0.592840\n",
      "iteration 118 / 300: loss 0.597992\n",
      "iteration 118 / 300: loss 0.597680\n",
      "iteration 118 / 300: loss 0.600956\n",
      "iteration 118 / 300: loss 0.597426\n",
      "iteration 118 / 300: loss 0.598779\n",
      "iteration 118 / 300: loss 0.587810\n",
      "iteration 118 / 300: loss 0.600503\n",
      "iteration 118 / 300: loss 0.599654\n",
      "iteration 118 / 300: loss 0.617544\n",
      "iteration 118 / 300: loss 0.598878\n",
      "iteration 118 / 300: loss 0.600804\n",
      "iteration 118 / 300: loss 0.605309\n",
      "iteration 118 / 300: loss 0.598596\n",
      "iteration 118 / 300: loss 0.591477\n",
      "iteration 118 / 300: loss 0.580385\n",
      "iteration 118 / 300: loss 0.598225\n",
      "iteration 118 / 300: loss 0.611688\n",
      "iteration 118 / 300: loss 0.613222\n",
      "iteration 118 / 300: loss 0.582217\n",
      "iteration 118 / 300: loss 0.601960\n",
      "iteration 118 / 300: loss 0.608960\n",
      "iteration 118 / 300: loss 0.601797\n",
      "iteration 118 / 300: loss 0.607949\n",
      "iteration 118 / 300: loss 0.620241\n",
      "iteration 118 / 300: loss 0.584820\n",
      "iteration 118 / 300: loss 0.583724\n",
      "iteration 118 / 300: loss 0.628852\n",
      "iteration 118 / 300: loss 0.609402\n",
      "iteration 118 / 300: loss 0.606269\n",
      "iteration 118 / 300: loss 0.599038\n",
      "iteration 118 / 300: loss 0.615880\n",
      "iteration 118 / 300: loss 0.596492\n",
      "iteration 118 / 300: loss 0.581434\n",
      "iteration 118 / 300: loss 0.609810\n",
      "iteration 118 / 300: loss 0.608128\n",
      "iteration 118 / 300: loss 0.598228\n",
      "iteration 118 / 300: loss 0.592026\n",
      "iteration 118 / 300: loss 0.611035\n",
      "iteration 118 / 300: loss 0.598553\n",
      "iteration 118 / 300: loss 0.581385\n",
      "iteration 118 / 300: loss 0.609583\n",
      "iteration 119 / 300: loss 0.578388\n",
      "iteration 119 / 300: loss 0.596217\n",
      "iteration 119 / 300: loss 0.569458\n",
      "iteration 119 / 300: loss 0.597853\n",
      "iteration 119 / 300: loss 0.598943\n",
      "iteration 119 / 300: loss 0.603880\n",
      "iteration 119 / 300: loss 0.615264\n",
      "iteration 119 / 300: loss 0.588230\n",
      "iteration 119 / 300: loss 0.627174\n",
      "iteration 119 / 300: loss 0.592604\n",
      "iteration 119 / 300: loss 0.621503\n",
      "iteration 119 / 300: loss 0.593096\n",
      "iteration 119 / 300: loss 0.600544\n",
      "iteration 119 / 300: loss 0.571002\n",
      "iteration 119 / 300: loss 0.592914\n",
      "iteration 119 / 300: loss 0.600046\n",
      "iteration 119 / 300: loss 0.598055\n",
      "iteration 119 / 300: loss 0.583715\n",
      "iteration 119 / 300: loss 0.614358\n",
      "iteration 119 / 300: loss 0.591288\n",
      "iteration 119 / 300: loss 0.591393\n",
      "iteration 119 / 300: loss 0.594007\n",
      "iteration 119 / 300: loss 0.596739\n",
      "iteration 119 / 300: loss 0.596715\n",
      "iteration 119 / 300: loss 0.611738\n",
      "iteration 119 / 300: loss 0.607262\n",
      "iteration 119 / 300: loss 0.597035\n",
      "iteration 119 / 300: loss 0.596303\n",
      "iteration 119 / 300: loss 0.627394\n",
      "iteration 119 / 300: loss 0.601588\n",
      "iteration 119 / 300: loss 0.599926\n",
      "iteration 119 / 300: loss 0.621955\n",
      "iteration 119 / 300: loss 0.581439\n",
      "iteration 119 / 300: loss 0.599608\n",
      "iteration 119 / 300: loss 0.591186\n",
      "iteration 119 / 300: loss 0.599923\n",
      "iteration 119 / 300: loss 0.596018\n",
      "iteration 119 / 300: loss 0.590763\n",
      "iteration 119 / 300: loss 0.591965\n",
      "iteration 119 / 300: loss 0.615471\n",
      "iteration 119 / 300: loss 0.621363\n",
      "iteration 119 / 300: loss 0.587270\n",
      "iteration 119 / 300: loss 0.582486\n",
      "iteration 119 / 300: loss 0.585576\n",
      "iteration 119 / 300: loss 0.603670\n",
      "iteration 119 / 300: loss 0.585196\n",
      "iteration 119 / 300: loss 0.578884\n",
      "iteration 119 / 300: loss 0.576421\n",
      "iteration 119 / 300: loss 0.574100\n",
      "iteration 119 / 300: loss 0.600503\n",
      "iteration 119 / 300: loss 0.584493\n",
      "iteration 119 / 300: loss 0.584836\n",
      "iteration 119 / 300: loss 0.568326\n",
      "iteration 119 / 300: loss 0.592029\n",
      "iteration 119 / 300: loss 0.612120\n",
      "iteration 119 / 300: loss 0.608926\n",
      "iteration 119 / 300: loss 0.607616\n",
      "iteration 119 / 300: loss 0.595536\n",
      "iteration 119 / 300: loss 0.592840\n",
      "iteration 119 / 300: loss 0.597992\n",
      "iteration 119 / 300: loss 0.597680\n",
      "iteration 119 / 300: loss 0.600956\n",
      "iteration 119 / 300: loss 0.597425\n",
      "iteration 119 / 300: loss 0.598779\n",
      "iteration 119 / 300: loss 0.587810\n",
      "iteration 119 / 300: loss 0.600503\n",
      "iteration 119 / 300: loss 0.599653\n",
      "iteration 119 / 300: loss 0.617543\n",
      "iteration 119 / 300: loss 0.598877\n",
      "iteration 119 / 300: loss 0.600804\n",
      "iteration 119 / 300: loss 0.605308\n",
      "iteration 119 / 300: loss 0.598595\n",
      "iteration 119 / 300: loss 0.591477\n",
      "iteration 119 / 300: loss 0.580385\n",
      "iteration 119 / 300: loss 0.598224\n",
      "iteration 119 / 300: loss 0.611688\n",
      "iteration 119 / 300: loss 0.613222\n",
      "iteration 119 / 300: loss 0.582216\n",
      "iteration 119 / 300: loss 0.601959\n",
      "iteration 119 / 300: loss 0.608960\n",
      "iteration 119 / 300: loss 0.601797\n",
      "iteration 119 / 300: loss 0.607948\n",
      "iteration 119 / 300: loss 0.620240\n",
      "iteration 119 / 300: loss 0.584820\n",
      "iteration 119 / 300: loss 0.583723\n",
      "iteration 119 / 300: loss 0.628852\n",
      "iteration 119 / 300: loss 0.609401\n",
      "iteration 119 / 300: loss 0.606268\n",
      "iteration 119 / 300: loss 0.599037\n",
      "iteration 119 / 300: loss 0.615880\n",
      "iteration 119 / 300: loss 0.596492\n",
      "iteration 119 / 300: loss 0.581433\n",
      "iteration 119 / 300: loss 0.609810\n",
      "iteration 119 / 300: loss 0.608128\n",
      "iteration 119 / 300: loss 0.598228\n",
      "iteration 119 / 300: loss 0.592025\n",
      "iteration 119 / 300: loss 0.611035\n",
      "iteration 119 / 300: loss 0.598553\n",
      "iteration 119 / 300: loss 0.581385\n",
      "iteration 119 / 300: loss 0.609583\n",
      "iteration 120 / 300: loss 0.578387\n",
      "iteration 120 / 300: loss 0.596217\n",
      "iteration 120 / 300: loss 0.569458\n",
      "iteration 120 / 300: loss 0.597852\n",
      "iteration 120 / 300: loss 0.598943\n",
      "iteration 120 / 300: loss 0.603879\n",
      "iteration 120 / 300: loss 0.615263\n",
      "iteration 120 / 300: loss 0.588230\n",
      "iteration 120 / 300: loss 0.627174\n",
      "iteration 120 / 300: loss 0.592603\n",
      "iteration 120 / 300: loss 0.621503\n",
      "iteration 120 / 300: loss 0.593096\n",
      "iteration 120 / 300: loss 0.600544\n",
      "iteration 120 / 300: loss 0.571002\n",
      "iteration 120 / 300: loss 0.592914\n",
      "iteration 120 / 300: loss 0.600046\n",
      "iteration 120 / 300: loss 0.598055\n",
      "iteration 120 / 300: loss 0.583714\n",
      "iteration 120 / 300: loss 0.614358\n",
      "iteration 120 / 300: loss 0.591288\n",
      "iteration 120 / 300: loss 0.591393\n",
      "iteration 120 / 300: loss 0.594007\n",
      "iteration 120 / 300: loss 0.596738\n",
      "iteration 120 / 300: loss 0.596715\n",
      "iteration 120 / 300: loss 0.611738\n",
      "iteration 120 / 300: loss 0.607262\n",
      "iteration 120 / 300: loss 0.597035\n",
      "iteration 120 / 300: loss 0.596303\n",
      "iteration 120 / 300: loss 0.627394\n",
      "iteration 120 / 300: loss 0.601587\n",
      "iteration 120 / 300: loss 0.599926\n",
      "iteration 120 / 300: loss 0.621954\n",
      "iteration 120 / 300: loss 0.581438\n",
      "iteration 120 / 300: loss 0.599607\n",
      "iteration 120 / 300: loss 0.591186\n",
      "iteration 120 / 300: loss 0.599922\n",
      "iteration 120 / 300: loss 0.596018\n",
      "iteration 120 / 300: loss 0.590763\n",
      "iteration 120 / 300: loss 0.591965\n",
      "iteration 120 / 300: loss 0.615471\n",
      "iteration 120 / 300: loss 0.621363\n",
      "iteration 120 / 300: loss 0.587270\n",
      "iteration 120 / 300: loss 0.582486\n",
      "iteration 120 / 300: loss 0.585575\n",
      "iteration 120 / 300: loss 0.603669\n",
      "iteration 120 / 300: loss 0.585196\n",
      "iteration 120 / 300: loss 0.578883\n",
      "iteration 120 / 300: loss 0.576421\n",
      "iteration 120 / 300: loss 0.574100\n",
      "iteration 120 / 300: loss 0.600502\n",
      "iteration 120 / 300: loss 0.584493\n",
      "iteration 120 / 300: loss 0.584836\n",
      "iteration 120 / 300: loss 0.568326\n",
      "iteration 120 / 300: loss 0.592028\n",
      "iteration 120 / 300: loss 0.612119\n",
      "iteration 120 / 300: loss 0.608925\n",
      "iteration 120 / 300: loss 0.607616\n",
      "iteration 120 / 300: loss 0.595536\n",
      "iteration 120 / 300: loss 0.592839\n",
      "iteration 120 / 300: loss 0.597991\n",
      "iteration 120 / 300: loss 0.597680\n",
      "iteration 120 / 300: loss 0.600956\n",
      "iteration 120 / 300: loss 0.597425\n",
      "iteration 120 / 300: loss 0.598778\n",
      "iteration 120 / 300: loss 0.587809\n",
      "iteration 120 / 300: loss 0.600502\n",
      "iteration 120 / 300: loss 0.599653\n",
      "iteration 120 / 300: loss 0.617543\n",
      "iteration 120 / 300: loss 0.598877\n",
      "iteration 120 / 300: loss 0.600803\n",
      "iteration 120 / 300: loss 0.605308\n",
      "iteration 120 / 300: loss 0.598595\n",
      "iteration 120 / 300: loss 0.591476\n",
      "iteration 120 / 300: loss 0.580385\n",
      "iteration 120 / 300: loss 0.598224\n",
      "iteration 120 / 300: loss 0.611687\n",
      "iteration 120 / 300: loss 0.613222\n",
      "iteration 120 / 300: loss 0.582216\n",
      "iteration 120 / 300: loss 0.601959\n",
      "iteration 120 / 300: loss 0.608959\n",
      "iteration 120 / 300: loss 0.601797\n",
      "iteration 120 / 300: loss 0.607948\n",
      "iteration 120 / 300: loss 0.620240\n",
      "iteration 120 / 300: loss 0.584820\n",
      "iteration 120 / 300: loss 0.583723\n",
      "iteration 120 / 300: loss 0.628852\n",
      "iteration 120 / 300: loss 0.609401\n",
      "iteration 120 / 300: loss 0.606268\n",
      "iteration 120 / 300: loss 0.599037\n",
      "iteration 120 / 300: loss 0.615880\n",
      "iteration 120 / 300: loss 0.596491\n",
      "iteration 120 / 300: loss 0.581433\n",
      "iteration 120 / 300: loss 0.609809\n",
      "iteration 120 / 300: loss 0.608128\n",
      "iteration 120 / 300: loss 0.598227\n",
      "iteration 120 / 300: loss 0.592025\n",
      "iteration 120 / 300: loss 0.611034\n",
      "iteration 120 / 300: loss 0.598552\n",
      "iteration 120 / 300: loss 0.581384\n",
      "iteration 120 / 300: loss 0.609583\n",
      "iteration 121 / 300: loss 0.578387\n",
      "iteration 121 / 300: loss 0.596217\n",
      "iteration 121 / 300: loss 0.569457\n",
      "iteration 121 / 300: loss 0.597852\n",
      "iteration 121 / 300: loss 0.598943\n",
      "iteration 121 / 300: loss 0.603879\n",
      "iteration 121 / 300: loss 0.615263\n",
      "iteration 121 / 300: loss 0.588229\n",
      "iteration 121 / 300: loss 0.627174\n",
      "iteration 121 / 300: loss 0.592603\n",
      "iteration 121 / 300: loss 0.621503\n",
      "iteration 121 / 300: loss 0.593096\n",
      "iteration 121 / 300: loss 0.600543\n",
      "iteration 121 / 300: loss 0.571002\n",
      "iteration 121 / 300: loss 0.592914\n",
      "iteration 121 / 300: loss 0.600045\n",
      "iteration 121 / 300: loss 0.598055\n",
      "iteration 121 / 300: loss 0.583714\n",
      "iteration 121 / 300: loss 0.614357\n",
      "iteration 121 / 300: loss 0.591288\n",
      "iteration 121 / 300: loss 0.591393\n",
      "iteration 121 / 300: loss 0.594007\n",
      "iteration 121 / 300: loss 0.596738\n",
      "iteration 121 / 300: loss 0.596715\n",
      "iteration 121 / 300: loss 0.611737\n",
      "iteration 121 / 300: loss 0.607262\n",
      "iteration 121 / 300: loss 0.597034\n",
      "iteration 121 / 300: loss 0.596303\n",
      "iteration 121 / 300: loss 0.627394\n",
      "iteration 121 / 300: loss 0.601587\n",
      "iteration 121 / 300: loss 0.599926\n",
      "iteration 121 / 300: loss 0.621954\n",
      "iteration 121 / 300: loss 0.581438\n",
      "iteration 121 / 300: loss 0.599607\n",
      "iteration 121 / 300: loss 0.591185\n",
      "iteration 121 / 300: loss 0.599922\n",
      "iteration 121 / 300: loss 0.596018\n",
      "iteration 121 / 300: loss 0.590763\n",
      "iteration 121 / 300: loss 0.591964\n",
      "iteration 121 / 300: loss 0.615471\n",
      "iteration 121 / 300: loss 0.621363\n",
      "iteration 121 / 300: loss 0.587269\n",
      "iteration 121 / 300: loss 0.582486\n",
      "iteration 121 / 300: loss 0.585575\n",
      "iteration 121 / 300: loss 0.603669\n",
      "iteration 121 / 300: loss 0.585195\n",
      "iteration 121 / 300: loss 0.578883\n",
      "iteration 121 / 300: loss 0.576421\n",
      "iteration 121 / 300: loss 0.574100\n",
      "iteration 121 / 300: loss 0.600502\n",
      "iteration 121 / 300: loss 0.584492\n",
      "iteration 121 / 300: loss 0.584836\n",
      "iteration 121 / 300: loss 0.568326\n",
      "iteration 121 / 300: loss 0.592028\n",
      "iteration 121 / 300: loss 0.612119\n",
      "iteration 121 / 300: loss 0.608925\n",
      "iteration 121 / 300: loss 0.607616\n",
      "iteration 121 / 300: loss 0.595536\n",
      "iteration 121 / 300: loss 0.592839\n",
      "iteration 121 / 300: loss 0.597991\n",
      "iteration 121 / 300: loss 0.597679\n",
      "iteration 121 / 300: loss 0.600955\n",
      "iteration 121 / 300: loss 0.597425\n",
      "iteration 121 / 300: loss 0.598778\n",
      "iteration 121 / 300: loss 0.587809\n",
      "iteration 121 / 300: loss 0.600502\n",
      "iteration 121 / 300: loss 0.599653\n",
      "iteration 121 / 300: loss 0.617543\n",
      "iteration 121 / 300: loss 0.598877\n",
      "iteration 121 / 300: loss 0.600803\n",
      "iteration 121 / 300: loss 0.605308\n",
      "iteration 121 / 300: loss 0.598595\n",
      "iteration 121 / 300: loss 0.591476\n",
      "iteration 121 / 300: loss 0.580385\n",
      "iteration 121 / 300: loss 0.598224\n",
      "iteration 121 / 300: loss 0.611687\n",
      "iteration 121 / 300: loss 0.613221\n",
      "iteration 121 / 300: loss 0.582216\n",
      "iteration 121 / 300: loss 0.601958\n",
      "iteration 121 / 300: loss 0.608959\n",
      "iteration 121 / 300: loss 0.601796\n",
      "iteration 121 / 300: loss 0.607947\n",
      "iteration 121 / 300: loss 0.620240\n",
      "iteration 121 / 300: loss 0.584819\n",
      "iteration 121 / 300: loss 0.583723\n",
      "iteration 121 / 300: loss 0.628851\n",
      "iteration 121 / 300: loss 0.609401\n",
      "iteration 121 / 300: loss 0.606268\n",
      "iteration 121 / 300: loss 0.599037\n",
      "iteration 121 / 300: loss 0.615879\n",
      "iteration 121 / 300: loss 0.596491\n",
      "iteration 121 / 300: loss 0.581433\n",
      "iteration 121 / 300: loss 0.609809\n",
      "iteration 121 / 300: loss 0.608128\n",
      "iteration 121 / 300: loss 0.598227\n",
      "iteration 121 / 300: loss 0.592025\n",
      "iteration 121 / 300: loss 0.611034\n",
      "iteration 121 / 300: loss 0.598552\n",
      "iteration 121 / 300: loss 0.581384\n",
      "iteration 121 / 300: loss 0.609582\n",
      "iteration 122 / 300: loss 0.578387\n",
      "iteration 122 / 300: loss 0.596216\n",
      "iteration 122 / 300: loss 0.569457\n",
      "iteration 122 / 300: loss 0.597852\n",
      "iteration 122 / 300: loss 0.598942\n",
      "iteration 122 / 300: loss 0.603879\n",
      "iteration 122 / 300: loss 0.615263\n",
      "iteration 122 / 300: loss 0.588229\n",
      "iteration 122 / 300: loss 0.627173\n",
      "iteration 122 / 300: loss 0.592603\n",
      "iteration 122 / 300: loss 0.621502\n",
      "iteration 122 / 300: loss 0.593096\n",
      "iteration 122 / 300: loss 0.600543\n",
      "iteration 122 / 300: loss 0.571002\n",
      "iteration 122 / 300: loss 0.592914\n",
      "iteration 122 / 300: loss 0.600045\n",
      "iteration 122 / 300: loss 0.598055\n",
      "iteration 122 / 300: loss 0.583714\n",
      "iteration 122 / 300: loss 0.614357\n",
      "iteration 122 / 300: loss 0.591288\n",
      "iteration 122 / 300: loss 0.591393\n",
      "iteration 122 / 300: loss 0.594007\n",
      "iteration 122 / 300: loss 0.596738\n",
      "iteration 122 / 300: loss 0.596714\n",
      "iteration 122 / 300: loss 0.611737\n",
      "iteration 122 / 300: loss 0.607261\n",
      "iteration 122 / 300: loss 0.597034\n",
      "iteration 122 / 300: loss 0.596303\n",
      "iteration 122 / 300: loss 0.627393\n",
      "iteration 122 / 300: loss 0.601587\n",
      "iteration 122 / 300: loss 0.599925\n",
      "iteration 122 / 300: loss 0.621954\n",
      "iteration 122 / 300: loss 0.581438\n",
      "iteration 122 / 300: loss 0.599607\n",
      "iteration 122 / 300: loss 0.591185\n",
      "iteration 122 / 300: loss 0.599922\n",
      "iteration 122 / 300: loss 0.596018\n",
      "iteration 122 / 300: loss 0.590763\n",
      "iteration 122 / 300: loss 0.591964\n",
      "iteration 122 / 300: loss 0.615470\n",
      "iteration 122 / 300: loss 0.621362\n",
      "iteration 122 / 300: loss 0.587269\n",
      "iteration 122 / 300: loss 0.582485\n",
      "iteration 122 / 300: loss 0.585575\n",
      "iteration 122 / 300: loss 0.603669\n",
      "iteration 122 / 300: loss 0.585195\n",
      "iteration 122 / 300: loss 0.578883\n",
      "iteration 122 / 300: loss 0.576420\n",
      "iteration 122 / 300: loss 0.574099\n",
      "iteration 122 / 300: loss 0.600502\n",
      "iteration 122 / 300: loss 0.584492\n",
      "iteration 122 / 300: loss 0.584836\n",
      "iteration 122 / 300: loss 0.568325\n",
      "iteration 122 / 300: loss 0.592028\n",
      "iteration 122 / 300: loss 0.612119\n",
      "iteration 122 / 300: loss 0.608925\n",
      "iteration 122 / 300: loss 0.607615\n",
      "iteration 122 / 300: loss 0.595536\n",
      "iteration 122 / 300: loss 0.592839\n",
      "iteration 122 / 300: loss 0.597991\n",
      "iteration 122 / 300: loss 0.597679\n",
      "iteration 122 / 300: loss 0.600955\n",
      "iteration 122 / 300: loss 0.597424\n",
      "iteration 122 / 300: loss 0.598778\n",
      "iteration 122 / 300: loss 0.587809\n",
      "iteration 122 / 300: loss 0.600502\n",
      "iteration 122 / 300: loss 0.599653\n",
      "iteration 122 / 300: loss 0.617543\n",
      "iteration 122 / 300: loss 0.598877\n",
      "iteration 122 / 300: loss 0.600803\n",
      "iteration 122 / 300: loss 0.605308\n",
      "iteration 122 / 300: loss 0.598595\n",
      "iteration 122 / 300: loss 0.591476\n",
      "iteration 122 / 300: loss 0.580384\n",
      "iteration 122 / 300: loss 0.598224\n",
      "iteration 122 / 300: loss 0.611687\n",
      "iteration 122 / 300: loss 0.613221\n",
      "iteration 122 / 300: loss 0.582216\n",
      "iteration 122 / 300: loss 0.601958\n",
      "iteration 122 / 300: loss 0.608959\n",
      "iteration 122 / 300: loss 0.601796\n",
      "iteration 122 / 300: loss 0.607947\n",
      "iteration 122 / 300: loss 0.620239\n",
      "iteration 122 / 300: loss 0.584819\n",
      "iteration 122 / 300: loss 0.583723\n",
      "iteration 122 / 300: loss 0.628851\n",
      "iteration 122 / 300: loss 0.609401\n",
      "iteration 122 / 300: loss 0.606268\n",
      "iteration 122 / 300: loss 0.599037\n",
      "iteration 122 / 300: loss 0.615879\n",
      "iteration 122 / 300: loss 0.596491\n",
      "iteration 122 / 300: loss 0.581433\n",
      "iteration 122 / 300: loss 0.609809\n",
      "iteration 122 / 300: loss 0.608127\n",
      "iteration 122 / 300: loss 0.598227\n",
      "iteration 122 / 300: loss 0.592024\n",
      "iteration 122 / 300: loss 0.611034\n",
      "iteration 122 / 300: loss 0.598552\n",
      "iteration 122 / 300: loss 0.581384\n",
      "iteration 122 / 300: loss 0.609582\n",
      "iteration 123 / 300: loss 0.578386\n",
      "iteration 123 / 300: loss 0.596216\n",
      "iteration 123 / 300: loss 0.569457\n",
      "iteration 123 / 300: loss 0.597852\n",
      "iteration 123 / 300: loss 0.598942\n",
      "iteration 123 / 300: loss 0.603878\n",
      "iteration 123 / 300: loss 0.615263\n",
      "iteration 123 / 300: loss 0.588229\n",
      "iteration 123 / 300: loss 0.627173\n",
      "iteration 123 / 300: loss 0.592602\n",
      "iteration 123 / 300: loss 0.621502\n",
      "iteration 123 / 300: loss 0.593095\n",
      "iteration 123 / 300: loss 0.600543\n",
      "iteration 123 / 300: loss 0.571002\n",
      "iteration 123 / 300: loss 0.592913\n",
      "iteration 123 / 300: loss 0.600045\n",
      "iteration 123 / 300: loss 0.598054\n",
      "iteration 123 / 300: loss 0.583714\n",
      "iteration 123 / 300: loss 0.614357\n",
      "iteration 123 / 300: loss 0.591287\n",
      "iteration 123 / 300: loss 0.591392\n",
      "iteration 123 / 300: loss 0.594007\n",
      "iteration 123 / 300: loss 0.596737\n",
      "iteration 123 / 300: loss 0.596714\n",
      "iteration 123 / 300: loss 0.611737\n",
      "iteration 123 / 300: loss 0.607261\n",
      "iteration 123 / 300: loss 0.597034\n",
      "iteration 123 / 300: loss 0.596303\n",
      "iteration 123 / 300: loss 0.627393\n",
      "iteration 123 / 300: loss 0.601586\n",
      "iteration 123 / 300: loss 0.599925\n",
      "iteration 123 / 300: loss 0.621954\n",
      "iteration 123 / 300: loss 0.581437\n",
      "iteration 123 / 300: loss 0.599607\n",
      "iteration 123 / 300: loss 0.591185\n",
      "iteration 123 / 300: loss 0.599922\n",
      "iteration 123 / 300: loss 0.596017\n",
      "iteration 123 / 300: loss 0.590762\n",
      "iteration 123 / 300: loss 0.591964\n",
      "iteration 123 / 300: loss 0.615470\n",
      "iteration 123 / 300: loss 0.621362\n",
      "iteration 123 / 300: loss 0.587269\n",
      "iteration 123 / 300: loss 0.582485\n",
      "iteration 123 / 300: loss 0.585575\n",
      "iteration 123 / 300: loss 0.603668\n",
      "iteration 123 / 300: loss 0.585195\n",
      "iteration 123 / 300: loss 0.578882\n",
      "iteration 123 / 300: loss 0.576420\n",
      "iteration 123 / 300: loss 0.574099\n",
      "iteration 123 / 300: loss 0.600502\n",
      "iteration 123 / 300: loss 0.584492\n",
      "iteration 123 / 300: loss 0.584836\n",
      "iteration 123 / 300: loss 0.568325\n",
      "iteration 123 / 300: loss 0.592028\n",
      "iteration 123 / 300: loss 0.612118\n",
      "iteration 123 / 300: loss 0.608925\n",
      "iteration 123 / 300: loss 0.607615\n",
      "iteration 123 / 300: loss 0.595535\n",
      "iteration 123 / 300: loss 0.592839\n",
      "iteration 123 / 300: loss 0.597991\n",
      "iteration 123 / 300: loss 0.597679\n",
      "iteration 123 / 300: loss 0.600955\n",
      "iteration 123 / 300: loss 0.597424\n",
      "iteration 123 / 300: loss 0.598778\n",
      "iteration 123 / 300: loss 0.587808\n",
      "iteration 123 / 300: loss 0.600501\n",
      "iteration 123 / 300: loss 0.599652\n",
      "iteration 123 / 300: loss 0.617542\n",
      "iteration 123 / 300: loss 0.598877\n",
      "iteration 123 / 300: loss 0.600803\n",
      "iteration 123 / 300: loss 0.605307\n",
      "iteration 123 / 300: loss 0.598594\n",
      "iteration 123 / 300: loss 0.591476\n",
      "iteration 123 / 300: loss 0.580384\n",
      "iteration 123 / 300: loss 0.598223\n",
      "iteration 123 / 300: loss 0.611687\n",
      "iteration 123 / 300: loss 0.613221\n",
      "iteration 123 / 300: loss 0.582216\n",
      "iteration 123 / 300: loss 0.601958\n",
      "iteration 123 / 300: loss 0.608959\n",
      "iteration 123 / 300: loss 0.601796\n",
      "iteration 123 / 300: loss 0.607947\n",
      "iteration 123 / 300: loss 0.620239\n",
      "iteration 123 / 300: loss 0.584819\n",
      "iteration 123 / 300: loss 0.583723\n",
      "iteration 123 / 300: loss 0.628851\n",
      "iteration 123 / 300: loss 0.609401\n",
      "iteration 123 / 300: loss 0.606267\n",
      "iteration 123 / 300: loss 0.599036\n",
      "iteration 123 / 300: loss 0.615879\n",
      "iteration 123 / 300: loss 0.596491\n",
      "iteration 123 / 300: loss 0.581432\n",
      "iteration 123 / 300: loss 0.609809\n",
      "iteration 123 / 300: loss 0.608127\n",
      "iteration 123 / 300: loss 0.598226\n",
      "iteration 123 / 300: loss 0.592024\n",
      "iteration 123 / 300: loss 0.611033\n",
      "iteration 123 / 300: loss 0.598552\n",
      "iteration 123 / 300: loss 0.581384\n",
      "iteration 123 / 300: loss 0.609582\n",
      "iteration 124 / 300: loss 0.578386\n",
      "iteration 124 / 300: loss 0.596216\n",
      "iteration 124 / 300: loss 0.569457\n",
      "iteration 124 / 300: loss 0.597851\n",
      "iteration 124 / 300: loss 0.598942\n",
      "iteration 124 / 300: loss 0.603878\n",
      "iteration 124 / 300: loss 0.615263\n",
      "iteration 124 / 300: loss 0.588229\n",
      "iteration 124 / 300: loss 0.627173\n",
      "iteration 124 / 300: loss 0.592602\n",
      "iteration 124 / 300: loss 0.621502\n",
      "iteration 124 / 300: loss 0.593095\n",
      "iteration 124 / 300: loss 0.600543\n",
      "iteration 124 / 300: loss 0.571001\n",
      "iteration 124 / 300: loss 0.592913\n",
      "iteration 124 / 300: loss 0.600045\n",
      "iteration 124 / 300: loss 0.598054\n",
      "iteration 124 / 300: loss 0.583714\n",
      "iteration 124 / 300: loss 0.614357\n",
      "iteration 124 / 300: loss 0.591287\n",
      "iteration 124 / 300: loss 0.591392\n",
      "iteration 124 / 300: loss 0.594006\n",
      "iteration 124 / 300: loss 0.596737\n",
      "iteration 124 / 300: loss 0.596714\n",
      "iteration 124 / 300: loss 0.611737\n",
      "iteration 124 / 300: loss 0.607261\n",
      "iteration 124 / 300: loss 0.597034\n",
      "iteration 124 / 300: loss 0.596302\n",
      "iteration 124 / 300: loss 0.627393\n",
      "iteration 124 / 300: loss 0.601586\n",
      "iteration 124 / 300: loss 0.599925\n",
      "iteration 124 / 300: loss 0.621953\n",
      "iteration 124 / 300: loss 0.581437\n",
      "iteration 124 / 300: loss 0.599606\n",
      "iteration 124 / 300: loss 0.591184\n",
      "iteration 124 / 300: loss 0.599921\n",
      "iteration 124 / 300: loss 0.596017\n",
      "iteration 124 / 300: loss 0.590762\n",
      "iteration 124 / 300: loss 0.591964\n",
      "iteration 124 / 300: loss 0.615470\n",
      "iteration 124 / 300: loss 0.621362\n",
      "iteration 124 / 300: loss 0.587269\n",
      "iteration 124 / 300: loss 0.582485\n",
      "iteration 124 / 300: loss 0.585574\n",
      "iteration 124 / 300: loss 0.603668\n",
      "iteration 124 / 300: loss 0.585195\n",
      "iteration 124 / 300: loss 0.578882\n",
      "iteration 124 / 300: loss 0.576420\n",
      "iteration 124 / 300: loss 0.574099\n",
      "iteration 124 / 300: loss 0.600502\n",
      "iteration 124 / 300: loss 0.584492\n",
      "iteration 124 / 300: loss 0.584835\n",
      "iteration 124 / 300: loss 0.568325\n",
      "iteration 124 / 300: loss 0.592027\n",
      "iteration 124 / 300: loss 0.612118\n",
      "iteration 124 / 300: loss 0.608924\n",
      "iteration 124 / 300: loss 0.607615\n",
      "iteration 124 / 300: loss 0.595535\n",
      "iteration 124 / 300: loss 0.592839\n",
      "iteration 124 / 300: loss 0.597990\n",
      "iteration 124 / 300: loss 0.597679\n",
      "iteration 124 / 300: loss 0.600955\n",
      "iteration 124 / 300: loss 0.597424\n",
      "iteration 124 / 300: loss 0.598778\n",
      "iteration 124 / 300: loss 0.587808\n",
      "iteration 124 / 300: loss 0.600501\n",
      "iteration 124 / 300: loss 0.599652\n",
      "iteration 124 / 300: loss 0.617542\n",
      "iteration 124 / 300: loss 0.598876\n",
      "iteration 124 / 300: loss 0.600803\n",
      "iteration 124 / 300: loss 0.605307\n",
      "iteration 124 / 300: loss 0.598594\n",
      "iteration 124 / 300: loss 0.591475\n",
      "iteration 124 / 300: loss 0.580384\n",
      "iteration 124 / 300: loss 0.598223\n",
      "iteration 124 / 300: loss 0.611686\n",
      "iteration 124 / 300: loss 0.613221\n",
      "iteration 124 / 300: loss 0.582215\n",
      "iteration 124 / 300: loss 0.601958\n",
      "iteration 124 / 300: loss 0.608958\n",
      "iteration 124 / 300: loss 0.601796\n",
      "iteration 124 / 300: loss 0.607947\n",
      "iteration 124 / 300: loss 0.620239\n",
      "iteration 124 / 300: loss 0.584819\n",
      "iteration 124 / 300: loss 0.583723\n",
      "iteration 124 / 300: loss 0.628851\n",
      "iteration 124 / 300: loss 0.609400\n",
      "iteration 124 / 300: loss 0.606267\n",
      "iteration 124 / 300: loss 0.599036\n",
      "iteration 124 / 300: loss 0.615879\n",
      "iteration 124 / 300: loss 0.596490\n",
      "iteration 124 / 300: loss 0.581432\n",
      "iteration 124 / 300: loss 0.609809\n",
      "iteration 124 / 300: loss 0.608127\n",
      "iteration 124 / 300: loss 0.598226\n",
      "iteration 124 / 300: loss 0.592024\n",
      "iteration 124 / 300: loss 0.611033\n",
      "iteration 124 / 300: loss 0.598551\n",
      "iteration 124 / 300: loss 0.581384\n",
      "iteration 124 / 300: loss 0.609582\n",
      "iteration 125 / 300: loss 0.578386\n",
      "iteration 125 / 300: loss 0.596216\n",
      "iteration 125 / 300: loss 0.569456\n",
      "iteration 125 / 300: loss 0.597851\n",
      "iteration 125 / 300: loss 0.598942\n",
      "iteration 125 / 300: loss 0.603878\n",
      "iteration 125 / 300: loss 0.615263\n",
      "iteration 125 / 300: loss 0.588228\n",
      "iteration 125 / 300: loss 0.627173\n",
      "iteration 125 / 300: loss 0.592602\n",
      "iteration 125 / 300: loss 0.621502\n",
      "iteration 125 / 300: loss 0.593095\n",
      "iteration 125 / 300: loss 0.600543\n",
      "iteration 125 / 300: loss 0.571001\n",
      "iteration 125 / 300: loss 0.592913\n",
      "iteration 125 / 300: loss 0.600044\n",
      "iteration 125 / 300: loss 0.598054\n",
      "iteration 125 / 300: loss 0.583713\n",
      "iteration 125 / 300: loss 0.614356\n",
      "iteration 125 / 300: loss 0.591287\n",
      "iteration 125 / 300: loss 0.591392\n",
      "iteration 125 / 300: loss 0.594006\n",
      "iteration 125 / 300: loss 0.596737\n",
      "iteration 125 / 300: loss 0.596714\n",
      "iteration 125 / 300: loss 0.611736\n",
      "iteration 125 / 300: loss 0.607260\n",
      "iteration 125 / 300: loss 0.597033\n",
      "iteration 125 / 300: loss 0.596302\n",
      "iteration 125 / 300: loss 0.627393\n",
      "iteration 125 / 300: loss 0.601586\n",
      "iteration 125 / 300: loss 0.599925\n",
      "iteration 125 / 300: loss 0.621953\n",
      "iteration 125 / 300: loss 0.581437\n",
      "iteration 125 / 300: loss 0.599606\n",
      "iteration 125 / 300: loss 0.591184\n",
      "iteration 125 / 300: loss 0.599921\n",
      "iteration 125 / 300: loss 0.596017\n",
      "iteration 125 / 300: loss 0.590762\n",
      "iteration 125 / 300: loss 0.591963\n",
      "iteration 125 / 300: loss 0.615470\n",
      "iteration 125 / 300: loss 0.621362\n",
      "iteration 125 / 300: loss 0.587269\n",
      "iteration 125 / 300: loss 0.582485\n",
      "iteration 125 / 300: loss 0.585574\n",
      "iteration 125 / 300: loss 0.603668\n",
      "iteration 125 / 300: loss 0.585194\n",
      "iteration 125 / 300: loss 0.578882\n",
      "iteration 125 / 300: loss 0.576420\n",
      "iteration 125 / 300: loss 0.574099\n",
      "iteration 125 / 300: loss 0.600501\n",
      "iteration 125 / 300: loss 0.584492\n",
      "iteration 125 / 300: loss 0.584835\n",
      "iteration 125 / 300: loss 0.568325\n",
      "iteration 125 / 300: loss 0.592027\n",
      "iteration 125 / 300: loss 0.612118\n",
      "iteration 125 / 300: loss 0.608924\n",
      "iteration 125 / 300: loss 0.607615\n",
      "iteration 125 / 300: loss 0.595535\n",
      "iteration 125 / 300: loss 0.592838\n",
      "iteration 125 / 300: loss 0.597990\n",
      "iteration 125 / 300: loss 0.597678\n",
      "iteration 125 / 300: loss 0.600954\n",
      "iteration 125 / 300: loss 0.597424\n",
      "iteration 125 / 300: loss 0.598777\n",
      "iteration 125 / 300: loss 0.587808\n",
      "iteration 125 / 300: loss 0.600501\n",
      "iteration 125 / 300: loss 0.599652\n",
      "iteration 125 / 300: loss 0.617542\n",
      "iteration 125 / 300: loss 0.598876\n",
      "iteration 125 / 300: loss 0.600802\n",
      "iteration 125 / 300: loss 0.605307\n",
      "iteration 125 / 300: loss 0.598594\n",
      "iteration 125 / 300: loss 0.591475\n",
      "iteration 125 / 300: loss 0.580384\n",
      "iteration 125 / 300: loss 0.598223\n",
      "iteration 125 / 300: loss 0.611686\n",
      "iteration 125 / 300: loss 0.613221\n",
      "iteration 125 / 300: loss 0.582215\n",
      "iteration 125 / 300: loss 0.601957\n",
      "iteration 125 / 300: loss 0.608958\n",
      "iteration 125 / 300: loss 0.601795\n",
      "iteration 125 / 300: loss 0.607946\n",
      "iteration 125 / 300: loss 0.620239\n",
      "iteration 125 / 300: loss 0.584818\n",
      "iteration 125 / 300: loss 0.583722\n",
      "iteration 125 / 300: loss 0.628851\n",
      "iteration 125 / 300: loss 0.609400\n",
      "iteration 125 / 300: loss 0.606267\n",
      "iteration 125 / 300: loss 0.599036\n",
      "iteration 125 / 300: loss 0.615878\n",
      "iteration 125 / 300: loss 0.596490\n",
      "iteration 125 / 300: loss 0.581432\n",
      "iteration 125 / 300: loss 0.609808\n",
      "iteration 125 / 300: loss 0.608127\n",
      "iteration 125 / 300: loss 0.598226\n",
      "iteration 125 / 300: loss 0.592024\n",
      "iteration 125 / 300: loss 0.611033\n",
      "iteration 125 / 300: loss 0.598551\n",
      "iteration 125 / 300: loss 0.581383\n",
      "iteration 125 / 300: loss 0.609581\n",
      "iteration 126 / 300: loss 0.578386\n",
      "iteration 126 / 300: loss 0.596216\n",
      "iteration 126 / 300: loss 0.569456\n",
      "iteration 126 / 300: loss 0.597851\n",
      "iteration 126 / 300: loss 0.598941\n",
      "iteration 126 / 300: loss 0.603878\n",
      "iteration 126 / 300: loss 0.615263\n",
      "iteration 126 / 300: loss 0.588228\n",
      "iteration 126 / 300: loss 0.627173\n",
      "iteration 126 / 300: loss 0.592602\n",
      "iteration 126 / 300: loss 0.621501\n",
      "iteration 126 / 300: loss 0.593095\n",
      "iteration 126 / 300: loss 0.600542\n",
      "iteration 126 / 300: loss 0.571001\n",
      "iteration 126 / 300: loss 0.592913\n",
      "iteration 126 / 300: loss 0.600044\n",
      "iteration 126 / 300: loss 0.598054\n",
      "iteration 126 / 300: loss 0.583713\n",
      "iteration 126 / 300: loss 0.614356\n",
      "iteration 126 / 300: loss 0.591287\n",
      "iteration 126 / 300: loss 0.591392\n",
      "iteration 126 / 300: loss 0.594006\n",
      "iteration 126 / 300: loss 0.596737\n",
      "iteration 126 / 300: loss 0.596714\n",
      "iteration 126 / 300: loss 0.611736\n",
      "iteration 126 / 300: loss 0.607260\n",
      "iteration 126 / 300: loss 0.597033\n",
      "iteration 126 / 300: loss 0.596302\n",
      "iteration 126 / 300: loss 0.627393\n",
      "iteration 126 / 300: loss 0.601586\n",
      "iteration 126 / 300: loss 0.599925\n",
      "iteration 126 / 300: loss 0.621953\n",
      "iteration 126 / 300: loss 0.581437\n",
      "iteration 126 / 300: loss 0.599606\n",
      "iteration 126 / 300: loss 0.591184\n",
      "iteration 126 / 300: loss 0.599921\n",
      "iteration 126 / 300: loss 0.596017\n",
      "iteration 126 / 300: loss 0.590762\n",
      "iteration 126 / 300: loss 0.591963\n",
      "iteration 126 / 300: loss 0.615469\n",
      "iteration 126 / 300: loss 0.621362\n",
      "iteration 126 / 300: loss 0.587268\n",
      "iteration 126 / 300: loss 0.582484\n",
      "iteration 126 / 300: loss 0.585574\n",
      "iteration 126 / 300: loss 0.603668\n",
      "iteration 126 / 300: loss 0.585194\n",
      "iteration 126 / 300: loss 0.578882\n",
      "iteration 126 / 300: loss 0.576420\n",
      "iteration 126 / 300: loss 0.574099\n",
      "iteration 126 / 300: loss 0.600501\n",
      "iteration 126 / 300: loss 0.584492\n",
      "iteration 126 / 300: loss 0.584835\n",
      "iteration 126 / 300: loss 0.568325\n",
      "iteration 126 / 300: loss 0.592027\n",
      "iteration 126 / 300: loss 0.612118\n",
      "iteration 126 / 300: loss 0.608924\n",
      "iteration 126 / 300: loss 0.607614\n",
      "iteration 126 / 300: loss 0.595535\n",
      "iteration 126 / 300: loss 0.592838\n",
      "iteration 126 / 300: loss 0.597990\n",
      "iteration 126 / 300: loss 0.597678\n",
      "iteration 126 / 300: loss 0.600954\n",
      "iteration 126 / 300: loss 0.597423\n",
      "iteration 126 / 300: loss 0.598777\n",
      "iteration 126 / 300: loss 0.587808\n",
      "iteration 126 / 300: loss 0.600501\n",
      "iteration 126 / 300: loss 0.599652\n",
      "iteration 126 / 300: loss 0.617542\n",
      "iteration 126 / 300: loss 0.598876\n",
      "iteration 126 / 300: loss 0.600802\n",
      "iteration 126 / 300: loss 0.605307\n",
      "iteration 126 / 300: loss 0.598594\n",
      "iteration 126 / 300: loss 0.591475\n",
      "iteration 126 / 300: loss 0.580384\n",
      "iteration 126 / 300: loss 0.598223\n",
      "iteration 126 / 300: loss 0.611686\n",
      "iteration 126 / 300: loss 0.613220\n",
      "iteration 126 / 300: loss 0.582215\n",
      "iteration 126 / 300: loss 0.601957\n",
      "iteration 126 / 300: loss 0.608958\n",
      "iteration 126 / 300: loss 0.601795\n",
      "iteration 126 / 300: loss 0.607946\n",
      "iteration 126 / 300: loss 0.620238\n",
      "iteration 126 / 300: loss 0.584818\n",
      "iteration 126 / 300: loss 0.583722\n",
      "iteration 126 / 300: loss 0.628850\n",
      "iteration 126 / 300: loss 0.609400\n",
      "iteration 126 / 300: loss 0.606267\n",
      "iteration 126 / 300: loss 0.599036\n",
      "iteration 126 / 300: loss 0.615878\n",
      "iteration 126 / 300: loss 0.596490\n",
      "iteration 126 / 300: loss 0.581432\n",
      "iteration 126 / 300: loss 0.609808\n",
      "iteration 126 / 300: loss 0.608127\n",
      "iteration 126 / 300: loss 0.598226\n",
      "iteration 126 / 300: loss 0.592024\n",
      "iteration 126 / 300: loss 0.611033\n",
      "iteration 126 / 300: loss 0.598551\n",
      "iteration 126 / 300: loss 0.581383\n",
      "iteration 126 / 300: loss 0.609581\n",
      "iteration 127 / 300: loss 0.578386\n",
      "iteration 127 / 300: loss 0.596215\n",
      "iteration 127 / 300: loss 0.569456\n",
      "iteration 127 / 300: loss 0.597851\n",
      "iteration 127 / 300: loss 0.598941\n",
      "iteration 127 / 300: loss 0.603878\n",
      "iteration 127 / 300: loss 0.615262\n",
      "iteration 127 / 300: loss 0.588228\n",
      "iteration 127 / 300: loss 0.627173\n",
      "iteration 127 / 300: loss 0.592602\n",
      "iteration 127 / 300: loss 0.621501\n",
      "iteration 127 / 300: loss 0.593095\n",
      "iteration 127 / 300: loss 0.600542\n",
      "iteration 127 / 300: loss 0.571001\n",
      "iteration 127 / 300: loss 0.592913\n",
      "iteration 127 / 300: loss 0.600044\n",
      "iteration 127 / 300: loss 0.598054\n",
      "iteration 127 / 300: loss 0.583713\n",
      "iteration 127 / 300: loss 0.614356\n",
      "iteration 127 / 300: loss 0.591287\n",
      "iteration 127 / 300: loss 0.591392\n",
      "iteration 127 / 300: loss 0.594006\n",
      "iteration 127 / 300: loss 0.596736\n",
      "iteration 127 / 300: loss 0.596714\n",
      "iteration 127 / 300: loss 0.611736\n",
      "iteration 127 / 300: loss 0.607260\n",
      "iteration 127 / 300: loss 0.597033\n",
      "iteration 127 / 300: loss 0.596302\n",
      "iteration 127 / 300: loss 0.627392\n",
      "iteration 127 / 300: loss 0.601586\n",
      "iteration 127 / 300: loss 0.599925\n",
      "iteration 127 / 300: loss 0.621953\n",
      "iteration 127 / 300: loss 0.581436\n",
      "iteration 127 / 300: loss 0.599606\n",
      "iteration 127 / 300: loss 0.591184\n",
      "iteration 127 / 300: loss 0.599921\n",
      "iteration 127 / 300: loss 0.596017\n",
      "iteration 127 / 300: loss 0.590762\n",
      "iteration 127 / 300: loss 0.591963\n",
      "iteration 127 / 300: loss 0.615469\n",
      "iteration 127 / 300: loss 0.621361\n",
      "iteration 127 / 300: loss 0.587268\n",
      "iteration 127 / 300: loss 0.582484\n",
      "iteration 127 / 300: loss 0.585574\n",
      "iteration 127 / 300: loss 0.603667\n",
      "iteration 127 / 300: loss 0.585194\n",
      "iteration 127 / 300: loss 0.578882\n",
      "iteration 127 / 300: loss 0.576420\n",
      "iteration 127 / 300: loss 0.574098\n",
      "iteration 127 / 300: loss 0.600501\n",
      "iteration 127 / 300: loss 0.584491\n",
      "iteration 127 / 300: loss 0.584835\n",
      "iteration 127 / 300: loss 0.568325\n",
      "iteration 127 / 300: loss 0.592027\n",
      "iteration 127 / 300: loss 0.612118\n",
      "iteration 127 / 300: loss 0.608924\n",
      "iteration 127 / 300: loss 0.607614\n",
      "iteration 127 / 300: loss 0.595535\n",
      "iteration 127 / 300: loss 0.592838\n",
      "iteration 127 / 300: loss 0.597990\n",
      "iteration 127 / 300: loss 0.597678\n",
      "iteration 127 / 300: loss 0.600954\n",
      "iteration 127 / 300: loss 0.597423\n",
      "iteration 127 / 300: loss 0.598777\n",
      "iteration 127 / 300: loss 0.587808\n",
      "iteration 127 / 300: loss 0.600501\n",
      "iteration 127 / 300: loss 0.599652\n",
      "iteration 127 / 300: loss 0.617542\n",
      "iteration 127 / 300: loss 0.598876\n",
      "iteration 127 / 300: loss 0.600802\n",
      "iteration 127 / 300: loss 0.605307\n",
      "iteration 127 / 300: loss 0.598594\n",
      "iteration 127 / 300: loss 0.591475\n",
      "iteration 127 / 300: loss 0.580384\n",
      "iteration 127 / 300: loss 0.598223\n",
      "iteration 127 / 300: loss 0.611686\n",
      "iteration 127 / 300: loss 0.613220\n",
      "iteration 127 / 300: loss 0.582215\n",
      "iteration 127 / 300: loss 0.601957\n",
      "iteration 127 / 300: loss 0.608958\n",
      "iteration 127 / 300: loss 0.601795\n",
      "iteration 127 / 300: loss 0.607946\n",
      "iteration 127 / 300: loss 0.620238\n",
      "iteration 127 / 300: loss 0.584818\n",
      "iteration 127 / 300: loss 0.583722\n",
      "iteration 127 / 300: loss 0.628850\n",
      "iteration 127 / 300: loss 0.609400\n",
      "iteration 127 / 300: loss 0.606267\n",
      "iteration 127 / 300: loss 0.599036\n",
      "iteration 127 / 300: loss 0.615878\n",
      "iteration 127 / 300: loss 0.596490\n",
      "iteration 127 / 300: loss 0.581432\n",
      "iteration 127 / 300: loss 0.609808\n",
      "iteration 127 / 300: loss 0.608127\n",
      "iteration 127 / 300: loss 0.598226\n",
      "iteration 127 / 300: loss 0.592024\n",
      "iteration 127 / 300: loss 0.611033\n",
      "iteration 127 / 300: loss 0.598551\n",
      "iteration 127 / 300: loss 0.581383\n",
      "iteration 127 / 300: loss 0.609581\n",
      "iteration 128 / 300: loss 0.578385\n",
      "iteration 128 / 300: loss 0.596215\n",
      "iteration 128 / 300: loss 0.569456\n",
      "iteration 128 / 300: loss 0.597851\n",
      "iteration 128 / 300: loss 0.598941\n",
      "iteration 128 / 300: loss 0.603878\n",
      "iteration 128 / 300: loss 0.615262\n",
      "iteration 128 / 300: loss 0.588228\n",
      "iteration 128 / 300: loss 0.627173\n",
      "iteration 128 / 300: loss 0.592601\n",
      "iteration 128 / 300: loss 0.621501\n",
      "iteration 128 / 300: loss 0.593095\n",
      "iteration 128 / 300: loss 0.600542\n",
      "iteration 128 / 300: loss 0.571001\n",
      "iteration 128 / 300: loss 0.592913\n",
      "iteration 128 / 300: loss 0.600044\n",
      "iteration 128 / 300: loss 0.598054\n",
      "iteration 128 / 300: loss 0.583713\n",
      "iteration 128 / 300: loss 0.614356\n",
      "iteration 128 / 300: loss 0.591287\n",
      "iteration 128 / 300: loss 0.591392\n",
      "iteration 128 / 300: loss 0.594006\n",
      "iteration 128 / 300: loss 0.596736\n",
      "iteration 128 / 300: loss 0.596713\n",
      "iteration 128 / 300: loss 0.611736\n",
      "iteration 128 / 300: loss 0.607260\n",
      "iteration 128 / 300: loss 0.597033\n",
      "iteration 128 / 300: loss 0.596302\n",
      "iteration 128 / 300: loss 0.627392\n",
      "iteration 128 / 300: loss 0.601586\n",
      "iteration 128 / 300: loss 0.599924\n",
      "iteration 128 / 300: loss 0.621953\n",
      "iteration 128 / 300: loss 0.581436\n",
      "iteration 128 / 300: loss 0.599606\n",
      "iteration 128 / 300: loss 0.591184\n",
      "iteration 128 / 300: loss 0.599921\n",
      "iteration 128 / 300: loss 0.596016\n",
      "iteration 128 / 300: loss 0.590762\n",
      "iteration 128 / 300: loss 0.591963\n",
      "iteration 128 / 300: loss 0.615469\n",
      "iteration 128 / 300: loss 0.621361\n",
      "iteration 128 / 300: loss 0.587268\n",
      "iteration 128 / 300: loss 0.582484\n",
      "iteration 128 / 300: loss 0.585574\n",
      "iteration 128 / 300: loss 0.603667\n",
      "iteration 128 / 300: loss 0.585194\n",
      "iteration 128 / 300: loss 0.578882\n",
      "iteration 128 / 300: loss 0.576419\n",
      "iteration 128 / 300: loss 0.574098\n",
      "iteration 128 / 300: loss 0.600501\n",
      "iteration 128 / 300: loss 0.584491\n",
      "iteration 128 / 300: loss 0.584835\n",
      "iteration 128 / 300: loss 0.568324\n",
      "iteration 128 / 300: loss 0.592027\n",
      "iteration 128 / 300: loss 0.612118\n",
      "iteration 128 / 300: loss 0.608924\n",
      "iteration 128 / 300: loss 0.607614\n",
      "iteration 128 / 300: loss 0.595535\n",
      "iteration 128 / 300: loss 0.592838\n",
      "iteration 128 / 300: loss 0.597990\n",
      "iteration 128 / 300: loss 0.597678\n",
      "iteration 128 / 300: loss 0.600954\n",
      "iteration 128 / 300: loss 0.597423\n",
      "iteration 128 / 300: loss 0.598777\n",
      "iteration 128 / 300: loss 0.587808\n",
      "iteration 128 / 300: loss 0.600501\n",
      "iteration 128 / 300: loss 0.599652\n",
      "iteration 128 / 300: loss 0.617541\n",
      "iteration 128 / 300: loss 0.598876\n",
      "iteration 128 / 300: loss 0.600802\n",
      "iteration 128 / 300: loss 0.605306\n",
      "iteration 128 / 300: loss 0.598593\n",
      "iteration 128 / 300: loss 0.591475\n",
      "iteration 128 / 300: loss 0.580383\n",
      "iteration 128 / 300: loss 0.598222\n",
      "iteration 128 / 300: loss 0.611686\n",
      "iteration 128 / 300: loss 0.613220\n",
      "iteration 128 / 300: loss 0.582215\n",
      "iteration 128 / 300: loss 0.601957\n",
      "iteration 128 / 300: loss 0.608958\n",
      "iteration 128 / 300: loss 0.601795\n",
      "iteration 128 / 300: loss 0.607946\n",
      "iteration 128 / 300: loss 0.620238\n",
      "iteration 128 / 300: loss 0.584818\n",
      "iteration 128 / 300: loss 0.583722\n",
      "iteration 128 / 300: loss 0.628850\n",
      "iteration 128 / 300: loss 0.609400\n",
      "iteration 128 / 300: loss 0.606266\n",
      "iteration 128 / 300: loss 0.599036\n",
      "iteration 128 / 300: loss 0.615878\n",
      "iteration 128 / 300: loss 0.596490\n",
      "iteration 128 / 300: loss 0.581431\n",
      "iteration 128 / 300: loss 0.609808\n",
      "iteration 128 / 300: loss 0.608127\n",
      "iteration 128 / 300: loss 0.598226\n",
      "iteration 128 / 300: loss 0.592023\n",
      "iteration 128 / 300: loss 0.611032\n",
      "iteration 128 / 300: loss 0.598551\n",
      "iteration 128 / 300: loss 0.581383\n",
      "iteration 128 / 300: loss 0.609581\n",
      "iteration 129 / 300: loss 0.578385\n",
      "iteration 129 / 300: loss 0.596215\n",
      "iteration 129 / 300: loss 0.569456\n",
      "iteration 129 / 300: loss 0.597851\n",
      "iteration 129 / 300: loss 0.598941\n",
      "iteration 129 / 300: loss 0.603877\n",
      "iteration 129 / 300: loss 0.615262\n",
      "iteration 129 / 300: loss 0.588228\n",
      "iteration 129 / 300: loss 0.627172\n",
      "iteration 129 / 300: loss 0.592601\n",
      "iteration 129 / 300: loss 0.621501\n",
      "iteration 129 / 300: loss 0.593095\n",
      "iteration 129 / 300: loss 0.600542\n",
      "iteration 129 / 300: loss 0.571001\n",
      "iteration 129 / 300: loss 0.592912\n",
      "iteration 129 / 300: loss 0.600044\n",
      "iteration 129 / 300: loss 0.598054\n",
      "iteration 129 / 300: loss 0.583713\n",
      "iteration 129 / 300: loss 0.614356\n",
      "iteration 129 / 300: loss 0.591286\n",
      "iteration 129 / 300: loss 0.591392\n",
      "iteration 129 / 300: loss 0.594006\n",
      "iteration 129 / 300: loss 0.596736\n",
      "iteration 129 / 300: loss 0.596713\n",
      "iteration 129 / 300: loss 0.611736\n",
      "iteration 129 / 300: loss 0.607260\n",
      "iteration 129 / 300: loss 0.597033\n",
      "iteration 129 / 300: loss 0.596302\n",
      "iteration 129 / 300: loss 0.627392\n",
      "iteration 129 / 300: loss 0.601585\n",
      "iteration 129 / 300: loss 0.599924\n",
      "iteration 129 / 300: loss 0.621953\n",
      "iteration 129 / 300: loss 0.581436\n",
      "iteration 129 / 300: loss 0.599606\n",
      "iteration 129 / 300: loss 0.591183\n",
      "iteration 129 / 300: loss 0.599921\n",
      "iteration 129 / 300: loss 0.596016\n",
      "iteration 129 / 300: loss 0.590761\n",
      "iteration 129 / 300: loss 0.591963\n",
      "iteration 129 / 300: loss 0.615469\n",
      "iteration 129 / 300: loss 0.621361\n",
      "iteration 129 / 300: loss 0.587268\n",
      "iteration 129 / 300: loss 0.582484\n",
      "iteration 129 / 300: loss 0.585574\n",
      "iteration 129 / 300: loss 0.603667\n",
      "iteration 129 / 300: loss 0.585194\n",
      "iteration 129 / 300: loss 0.578881\n",
      "iteration 129 / 300: loss 0.576419\n",
      "iteration 129 / 300: loss 0.574098\n",
      "iteration 129 / 300: loss 0.600501\n",
      "iteration 129 / 300: loss 0.584491\n",
      "iteration 129 / 300: loss 0.584835\n",
      "iteration 129 / 300: loss 0.568324\n",
      "iteration 129 / 300: loss 0.592027\n",
      "iteration 129 / 300: loss 0.612117\n",
      "iteration 129 / 300: loss 0.608924\n",
      "iteration 129 / 300: loss 0.607614\n",
      "iteration 129 / 300: loss 0.595534\n",
      "iteration 129 / 300: loss 0.592838\n",
      "iteration 129 / 300: loss 0.597990\n",
      "iteration 129 / 300: loss 0.597678\n",
      "iteration 129 / 300: loss 0.600954\n",
      "iteration 129 / 300: loss 0.597423\n",
      "iteration 129 / 300: loss 0.598777\n",
      "iteration 129 / 300: loss 0.587807\n",
      "iteration 129 / 300: loss 0.600501\n",
      "iteration 129 / 300: loss 0.599651\n",
      "iteration 129 / 300: loss 0.617541\n",
      "iteration 129 / 300: loss 0.598876\n",
      "iteration 129 / 300: loss 0.600802\n",
      "iteration 129 / 300: loss 0.605306\n",
      "iteration 129 / 300: loss 0.598593\n",
      "iteration 129 / 300: loss 0.591475\n",
      "iteration 129 / 300: loss 0.580383\n",
      "iteration 129 / 300: loss 0.598222\n",
      "iteration 129 / 300: loss 0.611686\n",
      "iteration 129 / 300: loss 0.613220\n",
      "iteration 129 / 300: loss 0.582215\n",
      "iteration 129 / 300: loss 0.601957\n",
      "iteration 129 / 300: loss 0.608958\n",
      "iteration 129 / 300: loss 0.601795\n",
      "iteration 129 / 300: loss 0.607946\n",
      "iteration 129 / 300: loss 0.620238\n",
      "iteration 129 / 300: loss 0.584818\n",
      "iteration 129 / 300: loss 0.583722\n",
      "iteration 129 / 300: loss 0.628850\n",
      "iteration 129 / 300: loss 0.609400\n",
      "iteration 129 / 300: loss 0.606266\n",
      "iteration 129 / 300: loss 0.599035\n",
      "iteration 129 / 300: loss 0.615878\n",
      "iteration 129 / 300: loss 0.596490\n",
      "iteration 129 / 300: loss 0.581431\n",
      "iteration 129 / 300: loss 0.609808\n",
      "iteration 129 / 300: loss 0.608126\n",
      "iteration 129 / 300: loss 0.598226\n",
      "iteration 129 / 300: loss 0.592023\n",
      "iteration 129 / 300: loss 0.611032\n",
      "iteration 129 / 300: loss 0.598551\n",
      "iteration 129 / 300: loss 0.581383\n",
      "iteration 129 / 300: loss 0.609581\n",
      "iteration 130 / 300: loss 0.578385\n",
      "iteration 130 / 300: loss 0.596215\n",
      "iteration 130 / 300: loss 0.569456\n",
      "iteration 130 / 300: loss 0.597850\n",
      "iteration 130 / 300: loss 0.598941\n",
      "iteration 130 / 300: loss 0.603877\n",
      "iteration 130 / 300: loss 0.615262\n",
      "iteration 130 / 300: loss 0.588228\n",
      "iteration 130 / 300: loss 0.627172\n",
      "iteration 130 / 300: loss 0.592601\n",
      "iteration 130 / 300: loss 0.621501\n",
      "iteration 130 / 300: loss 0.593094\n",
      "iteration 130 / 300: loss 0.600542\n",
      "iteration 130 / 300: loss 0.571001\n",
      "iteration 130 / 300: loss 0.592912\n",
      "iteration 130 / 300: loss 0.600044\n",
      "iteration 130 / 300: loss 0.598054\n",
      "iteration 130 / 300: loss 0.583713\n",
      "iteration 130 / 300: loss 0.614356\n",
      "iteration 130 / 300: loss 0.591286\n",
      "iteration 130 / 300: loss 0.591392\n",
      "iteration 130 / 300: loss 0.594006\n",
      "iteration 130 / 300: loss 0.596736\n",
      "iteration 130 / 300: loss 0.596713\n",
      "iteration 130 / 300: loss 0.611736\n",
      "iteration 130 / 300: loss 0.607260\n",
      "iteration 130 / 300: loss 0.597033\n",
      "iteration 130 / 300: loss 0.596302\n",
      "iteration 130 / 300: loss 0.627392\n",
      "iteration 130 / 300: loss 0.601585\n",
      "iteration 130 / 300: loss 0.599924\n",
      "iteration 130 / 300: loss 0.621953\n",
      "iteration 130 / 300: loss 0.581436\n",
      "iteration 130 / 300: loss 0.599605\n",
      "iteration 130 / 300: loss 0.591183\n",
      "iteration 130 / 300: loss 0.599921\n",
      "iteration 130 / 300: loss 0.596016\n",
      "iteration 130 / 300: loss 0.590761\n",
      "iteration 130 / 300: loss 0.591963\n",
      "iteration 130 / 300: loss 0.615469\n",
      "iteration 130 / 300: loss 0.621361\n",
      "iteration 130 / 300: loss 0.587268\n",
      "iteration 130 / 300: loss 0.582484\n",
      "iteration 130 / 300: loss 0.585573\n",
      "iteration 130 / 300: loss 0.603667\n",
      "iteration 130 / 300: loss 0.585194\n",
      "iteration 130 / 300: loss 0.578881\n",
      "iteration 130 / 300: loss 0.576419\n",
      "iteration 130 / 300: loss 0.574098\n",
      "iteration 130 / 300: loss 0.600501\n",
      "iteration 130 / 300: loss 0.584491\n",
      "iteration 130 / 300: loss 0.584835\n",
      "iteration 130 / 300: loss 0.568324\n",
      "iteration 130 / 300: loss 0.592026\n",
      "iteration 130 / 300: loss 0.612117\n",
      "iteration 130 / 300: loss 0.608924\n",
      "iteration 130 / 300: loss 0.607614\n",
      "iteration 130 / 300: loss 0.595534\n",
      "iteration 130 / 300: loss 0.592838\n",
      "iteration 130 / 300: loss 0.597989\n",
      "iteration 130 / 300: loss 0.597678\n",
      "iteration 130 / 300: loss 0.600954\n",
      "iteration 130 / 300: loss 0.597423\n",
      "iteration 130 / 300: loss 0.598777\n",
      "iteration 130 / 300: loss 0.587807\n",
      "iteration 130 / 300: loss 0.600500\n",
      "iteration 130 / 300: loss 0.599651\n",
      "iteration 130 / 300: loss 0.617541\n",
      "iteration 130 / 300: loss 0.598876\n",
      "iteration 130 / 300: loss 0.600802\n",
      "iteration 130 / 300: loss 0.605306\n",
      "iteration 130 / 300: loss 0.598593\n",
      "iteration 130 / 300: loss 0.591475\n",
      "iteration 130 / 300: loss 0.580383\n",
      "iteration 130 / 300: loss 0.598222\n",
      "iteration 130 / 300: loss 0.611686\n",
      "iteration 130 / 300: loss 0.613220\n",
      "iteration 130 / 300: loss 0.582215\n",
      "iteration 130 / 300: loss 0.601957\n",
      "iteration 130 / 300: loss 0.608957\n",
      "iteration 130 / 300: loss 0.601795\n",
      "iteration 130 / 300: loss 0.607946\n",
      "iteration 130 / 300: loss 0.620238\n",
      "iteration 130 / 300: loss 0.584818\n",
      "iteration 130 / 300: loss 0.583722\n",
      "iteration 130 / 300: loss 0.628850\n",
      "iteration 130 / 300: loss 0.609400\n",
      "iteration 130 / 300: loss 0.606266\n",
      "iteration 130 / 300: loss 0.599035\n",
      "iteration 130 / 300: loss 0.615878\n",
      "iteration 130 / 300: loss 0.596490\n",
      "iteration 130 / 300: loss 0.581431\n",
      "iteration 130 / 300: loss 0.609808\n",
      "iteration 130 / 300: loss 0.608126\n",
      "iteration 130 / 300: loss 0.598225\n",
      "iteration 130 / 300: loss 0.592023\n",
      "iteration 130 / 300: loss 0.611032\n",
      "iteration 130 / 300: loss 0.598551\n",
      "iteration 130 / 300: loss 0.581383\n",
      "iteration 130 / 300: loss 0.609581\n",
      "iteration 131 / 300: loss 0.578385\n",
      "iteration 131 / 300: loss 0.596215\n",
      "iteration 131 / 300: loss 0.569456\n",
      "iteration 131 / 300: loss 0.597850\n",
      "iteration 131 / 300: loss 0.598941\n",
      "iteration 131 / 300: loss 0.603877\n",
      "iteration 131 / 300: loss 0.615262\n",
      "iteration 131 / 300: loss 0.588228\n",
      "iteration 131 / 300: loss 0.627172\n",
      "iteration 131 / 300: loss 0.592601\n",
      "iteration 131 / 300: loss 0.621501\n",
      "iteration 131 / 300: loss 0.593094\n",
      "iteration 131 / 300: loss 0.600542\n",
      "iteration 131 / 300: loss 0.571001\n",
      "iteration 131 / 300: loss 0.592912\n",
      "iteration 131 / 300: loss 0.600044\n",
      "iteration 131 / 300: loss 0.598053\n",
      "iteration 131 / 300: loss 0.583713\n",
      "iteration 131 / 300: loss 0.614356\n",
      "iteration 131 / 300: loss 0.591286\n",
      "iteration 131 / 300: loss 0.591391\n",
      "iteration 131 / 300: loss 0.594006\n",
      "iteration 131 / 300: loss 0.596736\n",
      "iteration 131 / 300: loss 0.596713\n",
      "iteration 131 / 300: loss 0.611736\n",
      "iteration 131 / 300: loss 0.607259\n",
      "iteration 131 / 300: loss 0.597033\n",
      "iteration 131 / 300: loss 0.596302\n",
      "iteration 131 / 300: loss 0.627392\n",
      "iteration 131 / 300: loss 0.601585\n",
      "iteration 131 / 300: loss 0.599924\n",
      "iteration 131 / 300: loss 0.621953\n",
      "iteration 131 / 300: loss 0.581436\n",
      "iteration 131 / 300: loss 0.599605\n",
      "iteration 131 / 300: loss 0.591183\n",
      "iteration 131 / 300: loss 0.599920\n",
      "iteration 131 / 300: loss 0.596016\n",
      "iteration 131 / 300: loss 0.590761\n",
      "iteration 131 / 300: loss 0.591962\n",
      "iteration 131 / 300: loss 0.615469\n",
      "iteration 131 / 300: loss 0.621361\n",
      "iteration 131 / 300: loss 0.587268\n",
      "iteration 131 / 300: loss 0.582484\n",
      "iteration 131 / 300: loss 0.585573\n",
      "iteration 131 / 300: loss 0.603667\n",
      "iteration 131 / 300: loss 0.585193\n",
      "iteration 131 / 300: loss 0.578881\n",
      "iteration 131 / 300: loss 0.576419\n",
      "iteration 131 / 300: loss 0.574098\n",
      "iteration 131 / 300: loss 0.600501\n",
      "iteration 131 / 300: loss 0.584491\n",
      "iteration 131 / 300: loss 0.584835\n",
      "iteration 131 / 300: loss 0.568324\n",
      "iteration 131 / 300: loss 0.592026\n",
      "iteration 131 / 300: loss 0.612117\n",
      "iteration 131 / 300: loss 0.608924\n",
      "iteration 131 / 300: loss 0.607614\n",
      "iteration 131 / 300: loss 0.595534\n",
      "iteration 131 / 300: loss 0.592838\n",
      "iteration 131 / 300: loss 0.597989\n",
      "iteration 131 / 300: loss 0.597678\n",
      "iteration 131 / 300: loss 0.600954\n",
      "iteration 131 / 300: loss 0.597423\n",
      "iteration 131 / 300: loss 0.598777\n",
      "iteration 131 / 300: loss 0.587807\n",
      "iteration 131 / 300: loss 0.600500\n",
      "iteration 131 / 300: loss 0.599651\n",
      "iteration 131 / 300: loss 0.617541\n",
      "iteration 131 / 300: loss 0.598876\n",
      "iteration 131 / 300: loss 0.600802\n",
      "iteration 131 / 300: loss 0.605306\n",
      "iteration 131 / 300: loss 0.598593\n",
      "iteration 131 / 300: loss 0.591475\n",
      "iteration 131 / 300: loss 0.580383\n",
      "iteration 131 / 300: loss 0.598222\n",
      "iteration 131 / 300: loss 0.611686\n",
      "iteration 131 / 300: loss 0.613220\n",
      "iteration 131 / 300: loss 0.582215\n",
      "iteration 131 / 300: loss 0.601956\n",
      "iteration 131 / 300: loss 0.608957\n",
      "iteration 131 / 300: loss 0.601795\n",
      "iteration 131 / 300: loss 0.607945\n",
      "iteration 131 / 300: loss 0.620238\n",
      "iteration 131 / 300: loss 0.584818\n",
      "iteration 131 / 300: loss 0.583722\n",
      "iteration 131 / 300: loss 0.628850\n",
      "iteration 131 / 300: loss 0.609400\n",
      "iteration 131 / 300: loss 0.606266\n",
      "iteration 131 / 300: loss 0.599035\n",
      "iteration 131 / 300: loss 0.615878\n",
      "iteration 131 / 300: loss 0.596490\n",
      "iteration 131 / 300: loss 0.581431\n",
      "iteration 131 / 300: loss 0.609808\n",
      "iteration 131 / 300: loss 0.608126\n",
      "iteration 131 / 300: loss 0.598225\n",
      "iteration 131 / 300: loss 0.592023\n",
      "iteration 131 / 300: loss 0.611032\n",
      "iteration 131 / 300: loss 0.598551\n",
      "iteration 131 / 300: loss 0.581383\n",
      "iteration 131 / 300: loss 0.609581\n",
      "iteration 132 / 300: loss 0.578385\n",
      "iteration 132 / 300: loss 0.596215\n",
      "iteration 132 / 300: loss 0.569456\n",
      "iteration 132 / 300: loss 0.597850\n",
      "iteration 132 / 300: loss 0.598941\n",
      "iteration 132 / 300: loss 0.603877\n",
      "iteration 132 / 300: loss 0.615262\n",
      "iteration 132 / 300: loss 0.588228\n",
      "iteration 132 / 300: loss 0.627172\n",
      "iteration 132 / 300: loss 0.592601\n",
      "iteration 132 / 300: loss 0.621501\n",
      "iteration 132 / 300: loss 0.593094\n",
      "iteration 132 / 300: loss 0.600542\n",
      "iteration 132 / 300: loss 0.571001\n",
      "iteration 132 / 300: loss 0.592912\n",
      "iteration 132 / 300: loss 0.600043\n",
      "iteration 132 / 300: loss 0.598053\n",
      "iteration 132 / 300: loss 0.583713\n",
      "iteration 132 / 300: loss 0.614356\n",
      "iteration 132 / 300: loss 0.591286\n",
      "iteration 132 / 300: loss 0.591391\n",
      "iteration 132 / 300: loss 0.594006\n",
      "iteration 132 / 300: loss 0.596736\n",
      "iteration 132 / 300: loss 0.596713\n",
      "iteration 132 / 300: loss 0.611736\n",
      "iteration 132 / 300: loss 0.607259\n",
      "iteration 132 / 300: loss 0.597032\n",
      "iteration 132 / 300: loss 0.596301\n",
      "iteration 132 / 300: loss 0.627392\n",
      "iteration 132 / 300: loss 0.601585\n",
      "iteration 132 / 300: loss 0.599924\n",
      "iteration 132 / 300: loss 0.621953\n",
      "iteration 132 / 300: loss 0.581436\n",
      "iteration 132 / 300: loss 0.599605\n",
      "iteration 132 / 300: loss 0.591183\n",
      "iteration 132 / 300: loss 0.599920\n",
      "iteration 132 / 300: loss 0.596016\n",
      "iteration 132 / 300: loss 0.590761\n",
      "iteration 132 / 300: loss 0.591962\n",
      "iteration 132 / 300: loss 0.615469\n",
      "iteration 132 / 300: loss 0.621361\n",
      "iteration 132 / 300: loss 0.587268\n",
      "iteration 132 / 300: loss 0.582484\n",
      "iteration 132 / 300: loss 0.585573\n",
      "iteration 132 / 300: loss 0.603667\n",
      "iteration 132 / 300: loss 0.585193\n",
      "iteration 132 / 300: loss 0.578881\n",
      "iteration 132 / 300: loss 0.576419\n",
      "iteration 132 / 300: loss 0.574098\n",
      "iteration 132 / 300: loss 0.600501\n",
      "iteration 132 / 300: loss 0.584491\n",
      "iteration 132 / 300: loss 0.584834\n",
      "iteration 132 / 300: loss 0.568324\n",
      "iteration 132 / 300: loss 0.592026\n",
      "iteration 132 / 300: loss 0.612117\n",
      "iteration 132 / 300: loss 0.608923\n",
      "iteration 132 / 300: loss 0.607614\n",
      "iteration 132 / 300: loss 0.595534\n",
      "iteration 132 / 300: loss 0.592838\n",
      "iteration 132 / 300: loss 0.597989\n",
      "iteration 132 / 300: loss 0.597678\n",
      "iteration 132 / 300: loss 0.600954\n",
      "iteration 132 / 300: loss 0.597423\n",
      "iteration 132 / 300: loss 0.598777\n",
      "iteration 132 / 300: loss 0.587807\n",
      "iteration 132 / 300: loss 0.600500\n",
      "iteration 132 / 300: loss 0.599651\n",
      "iteration 132 / 300: loss 0.617541\n",
      "iteration 132 / 300: loss 0.598875\n",
      "iteration 132 / 300: loss 0.600802\n",
      "iteration 132 / 300: loss 0.605306\n",
      "iteration 132 / 300: loss 0.598593\n",
      "iteration 132 / 300: loss 0.591474\n",
      "iteration 132 / 300: loss 0.580383\n",
      "iteration 132 / 300: loss 0.598222\n",
      "iteration 132 / 300: loss 0.611685\n",
      "iteration 132 / 300: loss 0.613220\n",
      "iteration 132 / 300: loss 0.582215\n",
      "iteration 132 / 300: loss 0.601956\n",
      "iteration 132 / 300: loss 0.608957\n",
      "iteration 132 / 300: loss 0.601795\n",
      "iteration 132 / 300: loss 0.607945\n",
      "iteration 132 / 300: loss 0.620237\n",
      "iteration 132 / 300: loss 0.584817\n",
      "iteration 132 / 300: loss 0.583722\n",
      "iteration 132 / 300: loss 0.628850\n",
      "iteration 132 / 300: loss 0.609400\n",
      "iteration 132 / 300: loss 0.606266\n",
      "iteration 132 / 300: loss 0.599035\n",
      "iteration 132 / 300: loss 0.615877\n",
      "iteration 132 / 300: loss 0.596489\n",
      "iteration 132 / 300: loss 0.581431\n",
      "iteration 132 / 300: loss 0.609808\n",
      "iteration 132 / 300: loss 0.608126\n",
      "iteration 132 / 300: loss 0.598225\n",
      "iteration 132 / 300: loss 0.592023\n",
      "iteration 132 / 300: loss 0.611032\n",
      "iteration 132 / 300: loss 0.598550\n",
      "iteration 132 / 300: loss 0.581383\n",
      "iteration 132 / 300: loss 0.609581\n",
      "iteration 133 / 300: loss 0.578385\n",
      "iteration 133 / 300: loss 0.596215\n",
      "iteration 133 / 300: loss 0.569455\n",
      "iteration 133 / 300: loss 0.597850\n",
      "iteration 133 / 300: loss 0.598941\n",
      "iteration 133 / 300: loss 0.603877\n",
      "iteration 133 / 300: loss 0.615262\n",
      "iteration 133 / 300: loss 0.588227\n",
      "iteration 133 / 300: loss 0.627172\n",
      "iteration 133 / 300: loss 0.592601\n",
      "iteration 133 / 300: loss 0.621500\n",
      "iteration 133 / 300: loss 0.593094\n",
      "iteration 133 / 300: loss 0.600542\n",
      "iteration 133 / 300: loss 0.571000\n",
      "iteration 133 / 300: loss 0.592912\n",
      "iteration 133 / 300: loss 0.600043\n",
      "iteration 133 / 300: loss 0.598053\n",
      "iteration 133 / 300: loss 0.583713\n",
      "iteration 133 / 300: loss 0.614356\n",
      "iteration 133 / 300: loss 0.591286\n",
      "iteration 133 / 300: loss 0.591391\n",
      "iteration 133 / 300: loss 0.594005\n",
      "iteration 133 / 300: loss 0.596736\n",
      "iteration 133 / 300: loss 0.596713\n",
      "iteration 133 / 300: loss 0.611735\n",
      "iteration 133 / 300: loss 0.607259\n",
      "iteration 133 / 300: loss 0.597032\n",
      "iteration 133 / 300: loss 0.596301\n",
      "iteration 133 / 300: loss 0.627392\n",
      "iteration 133 / 300: loss 0.601585\n",
      "iteration 133 / 300: loss 0.599924\n",
      "iteration 133 / 300: loss 0.621952\n",
      "iteration 133 / 300: loss 0.581436\n",
      "iteration 133 / 300: loss 0.599605\n",
      "iteration 133 / 300: loss 0.591183\n",
      "iteration 133 / 300: loss 0.599920\n",
      "iteration 133 / 300: loss 0.596016\n",
      "iteration 133 / 300: loss 0.590761\n",
      "iteration 133 / 300: loss 0.591962\n",
      "iteration 133 / 300: loss 0.615468\n",
      "iteration 133 / 300: loss 0.621361\n",
      "iteration 133 / 300: loss 0.587268\n",
      "iteration 133 / 300: loss 0.582484\n",
      "iteration 133 / 300: loss 0.585573\n",
      "iteration 133 / 300: loss 0.603667\n",
      "iteration 133 / 300: loss 0.585193\n",
      "iteration 133 / 300: loss 0.578881\n",
      "iteration 133 / 300: loss 0.576419\n",
      "iteration 133 / 300: loss 0.574098\n",
      "iteration 133 / 300: loss 0.600501\n",
      "iteration 133 / 300: loss 0.584491\n",
      "iteration 133 / 300: loss 0.584834\n",
      "iteration 133 / 300: loss 0.568324\n",
      "iteration 133 / 300: loss 0.592026\n",
      "iteration 133 / 300: loss 0.612117\n",
      "iteration 133 / 300: loss 0.608923\n",
      "iteration 133 / 300: loss 0.607614\n",
      "iteration 133 / 300: loss 0.595534\n",
      "iteration 133 / 300: loss 0.592837\n",
      "iteration 133 / 300: loss 0.597989\n",
      "iteration 133 / 300: loss 0.597677\n",
      "iteration 133 / 300: loss 0.600954\n",
      "iteration 133 / 300: loss 0.597423\n",
      "iteration 133 / 300: loss 0.598777\n",
      "iteration 133 / 300: loss 0.587807\n",
      "iteration 133 / 300: loss 0.600500\n",
      "iteration 133 / 300: loss 0.599651\n",
      "iteration 133 / 300: loss 0.617541\n",
      "iteration 133 / 300: loss 0.598875\n",
      "iteration 133 / 300: loss 0.600802\n",
      "iteration 133 / 300: loss 0.605306\n",
      "iteration 133 / 300: loss 0.598593\n",
      "iteration 133 / 300: loss 0.591474\n",
      "iteration 133 / 300: loss 0.580383\n",
      "iteration 133 / 300: loss 0.598222\n",
      "iteration 133 / 300: loss 0.611685\n",
      "iteration 133 / 300: loss 0.613220\n",
      "iteration 133 / 300: loss 0.582214\n",
      "iteration 133 / 300: loss 0.601956\n",
      "iteration 133 / 300: loss 0.608957\n",
      "iteration 133 / 300: loss 0.601794\n",
      "iteration 133 / 300: loss 0.607945\n",
      "iteration 133 / 300: loss 0.620237\n",
      "iteration 133 / 300: loss 0.584817\n",
      "iteration 133 / 300: loss 0.583722\n",
      "iteration 133 / 300: loss 0.628850\n",
      "iteration 133 / 300: loss 0.609399\n",
      "iteration 133 / 300: loss 0.606266\n",
      "iteration 133 / 300: loss 0.599035\n",
      "iteration 133 / 300: loss 0.615877\n",
      "iteration 133 / 300: loss 0.596489\n",
      "iteration 133 / 300: loss 0.581431\n",
      "iteration 133 / 300: loss 0.609808\n",
      "iteration 133 / 300: loss 0.608126\n",
      "iteration 133 / 300: loss 0.598225\n",
      "iteration 133 / 300: loss 0.592023\n",
      "iteration 133 / 300: loss 0.611032\n",
      "iteration 133 / 300: loss 0.598550\n",
      "iteration 133 / 300: loss 0.581383\n",
      "iteration 133 / 300: loss 0.609580\n",
      "iteration 134 / 300: loss 0.578385\n",
      "iteration 134 / 300: loss 0.596215\n",
      "iteration 134 / 300: loss 0.569455\n",
      "iteration 134 / 300: loss 0.597850\n",
      "iteration 134 / 300: loss 0.598941\n",
      "iteration 134 / 300: loss 0.603877\n",
      "iteration 134 / 300: loss 0.615262\n",
      "iteration 134 / 300: loss 0.588227\n",
      "iteration 134 / 300: loss 0.627172\n",
      "iteration 134 / 300: loss 0.592601\n",
      "iteration 134 / 300: loss 0.621500\n",
      "iteration 134 / 300: loss 0.593094\n",
      "iteration 134 / 300: loss 0.600542\n",
      "iteration 134 / 300: loss 0.571000\n",
      "iteration 134 / 300: loss 0.592912\n",
      "iteration 134 / 300: loss 0.600043\n",
      "iteration 134 / 300: loss 0.598053\n",
      "iteration 134 / 300: loss 0.583713\n",
      "iteration 134 / 300: loss 0.614355\n",
      "iteration 134 / 300: loss 0.591286\n",
      "iteration 134 / 300: loss 0.591391\n",
      "iteration 134 / 300: loss 0.594005\n",
      "iteration 134 / 300: loss 0.596735\n",
      "iteration 134 / 300: loss 0.596713\n",
      "iteration 134 / 300: loss 0.611735\n",
      "iteration 134 / 300: loss 0.607259\n",
      "iteration 134 / 300: loss 0.597032\n",
      "iteration 134 / 300: loss 0.596301\n",
      "iteration 134 / 300: loss 0.627392\n",
      "iteration 134 / 300: loss 0.601585\n",
      "iteration 134 / 300: loss 0.599924\n",
      "iteration 134 / 300: loss 0.621952\n",
      "iteration 134 / 300: loss 0.581436\n",
      "iteration 134 / 300: loss 0.599605\n",
      "iteration 134 / 300: loss 0.591183\n",
      "iteration 134 / 300: loss 0.599920\n",
      "iteration 134 / 300: loss 0.596016\n",
      "iteration 134 / 300: loss 0.590761\n",
      "iteration 134 / 300: loss 0.591962\n",
      "iteration 134 / 300: loss 0.615468\n",
      "iteration 134 / 300: loss 0.621361\n",
      "iteration 134 / 300: loss 0.587268\n",
      "iteration 134 / 300: loss 0.582484\n",
      "iteration 134 / 300: loss 0.585573\n",
      "iteration 134 / 300: loss 0.603667\n",
      "iteration 134 / 300: loss 0.585193\n",
      "iteration 134 / 300: loss 0.578881\n",
      "iteration 134 / 300: loss 0.576419\n",
      "iteration 134 / 300: loss 0.574098\n",
      "iteration 134 / 300: loss 0.600501\n",
      "iteration 134 / 300: loss 0.584491\n",
      "iteration 134 / 300: loss 0.584834\n",
      "iteration 134 / 300: loss 0.568324\n",
      "iteration 134 / 300: loss 0.592026\n",
      "iteration 134 / 300: loss 0.612117\n",
      "iteration 134 / 300: loss 0.608923\n",
      "iteration 134 / 300: loss 0.607614\n",
      "iteration 134 / 300: loss 0.595534\n",
      "iteration 134 / 300: loss 0.592837\n",
      "iteration 134 / 300: loss 0.597989\n",
      "iteration 134 / 300: loss 0.597677\n",
      "iteration 134 / 300: loss 0.600953\n",
      "iteration 134 / 300: loss 0.597422\n",
      "iteration 134 / 300: loss 0.598777\n",
      "iteration 134 / 300: loss 0.587807\n",
      "iteration 134 / 300: loss 0.600500\n",
      "iteration 134 / 300: loss 0.599651\n",
      "iteration 134 / 300: loss 0.617541\n",
      "iteration 134 / 300: loss 0.598875\n",
      "iteration 134 / 300: loss 0.600802\n",
      "iteration 134 / 300: loss 0.605306\n",
      "iteration 134 / 300: loss 0.598593\n",
      "iteration 134 / 300: loss 0.591474\n",
      "iteration 134 / 300: loss 0.580383\n",
      "iteration 134 / 300: loss 0.598222\n",
      "iteration 134 / 300: loss 0.611685\n",
      "iteration 134 / 300: loss 0.613220\n",
      "iteration 134 / 300: loss 0.582214\n",
      "iteration 134 / 300: loss 0.601956\n",
      "iteration 134 / 300: loss 0.608957\n",
      "iteration 134 / 300: loss 0.601794\n",
      "iteration 134 / 300: loss 0.607945\n",
      "iteration 134 / 300: loss 0.620237\n",
      "iteration 134 / 300: loss 0.584817\n",
      "iteration 134 / 300: loss 0.583722\n",
      "iteration 134 / 300: loss 0.628850\n",
      "iteration 134 / 300: loss 0.609399\n",
      "iteration 134 / 300: loss 0.606266\n",
      "iteration 134 / 300: loss 0.599035\n",
      "iteration 134 / 300: loss 0.615877\n",
      "iteration 134 / 300: loss 0.596489\n",
      "iteration 134 / 300: loss 0.581431\n",
      "iteration 134 / 300: loss 0.609808\n",
      "iteration 134 / 300: loss 0.608126\n",
      "iteration 134 / 300: loss 0.598225\n",
      "iteration 134 / 300: loss 0.592023\n",
      "iteration 134 / 300: loss 0.611032\n",
      "iteration 134 / 300: loss 0.598550\n",
      "iteration 134 / 300: loss 0.581383\n",
      "iteration 134 / 300: loss 0.609580\n",
      "iteration 135 / 300: loss 0.578385\n",
      "iteration 135 / 300: loss 0.596215\n",
      "iteration 135 / 300: loss 0.569455\n",
      "iteration 135 / 300: loss 0.597850\n",
      "iteration 135 / 300: loss 0.598940\n",
      "iteration 135 / 300: loss 0.603877\n",
      "iteration 135 / 300: loss 0.615262\n",
      "iteration 135 / 300: loss 0.588227\n",
      "iteration 135 / 300: loss 0.627172\n",
      "iteration 135 / 300: loss 0.592601\n",
      "iteration 135 / 300: loss 0.621500\n",
      "iteration 135 / 300: loss 0.593094\n",
      "iteration 135 / 300: loss 0.600541\n",
      "iteration 135 / 300: loss 0.571000\n",
      "iteration 135 / 300: loss 0.592912\n",
      "iteration 135 / 300: loss 0.600043\n",
      "iteration 135 / 300: loss 0.598053\n",
      "iteration 135 / 300: loss 0.583713\n",
      "iteration 135 / 300: loss 0.614355\n",
      "iteration 135 / 300: loss 0.591286\n",
      "iteration 135 / 300: loss 0.591391\n",
      "iteration 135 / 300: loss 0.594005\n",
      "iteration 135 / 300: loss 0.596735\n",
      "iteration 135 / 300: loss 0.596713\n",
      "iteration 135 / 300: loss 0.611735\n",
      "iteration 135 / 300: loss 0.607259\n",
      "iteration 135 / 300: loss 0.597032\n",
      "iteration 135 / 300: loss 0.596301\n",
      "iteration 135 / 300: loss 0.627392\n",
      "iteration 135 / 300: loss 0.601585\n",
      "iteration 135 / 300: loss 0.599924\n",
      "iteration 135 / 300: loss 0.621952\n",
      "iteration 135 / 300: loss 0.581435\n",
      "iteration 135 / 300: loss 0.599605\n",
      "iteration 135 / 300: loss 0.591183\n",
      "iteration 135 / 300: loss 0.599920\n",
      "iteration 135 / 300: loss 0.596016\n",
      "iteration 135 / 300: loss 0.590761\n",
      "iteration 135 / 300: loss 0.591962\n",
      "iteration 135 / 300: loss 0.615468\n",
      "iteration 135 / 300: loss 0.621361\n",
      "iteration 135 / 300: loss 0.587267\n",
      "iteration 135 / 300: loss 0.582483\n",
      "iteration 135 / 300: loss 0.585573\n",
      "iteration 135 / 300: loss 0.603666\n",
      "iteration 135 / 300: loss 0.585193\n",
      "iteration 135 / 300: loss 0.578881\n",
      "iteration 135 / 300: loss 0.576419\n",
      "iteration 135 / 300: loss 0.574098\n",
      "iteration 135 / 300: loss 0.600501\n",
      "iteration 135 / 300: loss 0.584491\n",
      "iteration 135 / 300: loss 0.584834\n",
      "iteration 135 / 300: loss 0.568324\n",
      "iteration 135 / 300: loss 0.592026\n",
      "iteration 135 / 300: loss 0.612117\n",
      "iteration 135 / 300: loss 0.608923\n",
      "iteration 135 / 300: loss 0.607614\n",
      "iteration 135 / 300: loss 0.595534\n",
      "iteration 135 / 300: loss 0.592837\n",
      "iteration 135 / 300: loss 0.597989\n",
      "iteration 135 / 300: loss 0.597677\n",
      "iteration 135 / 300: loss 0.600953\n",
      "iteration 135 / 300: loss 0.597422\n",
      "iteration 135 / 300: loss 0.598777\n",
      "iteration 135 / 300: loss 0.587807\n",
      "iteration 135 / 300: loss 0.600500\n",
      "iteration 135 / 300: loss 0.599651\n",
      "iteration 135 / 300: loss 0.617541\n",
      "iteration 135 / 300: loss 0.598875\n",
      "iteration 135 / 300: loss 0.600802\n",
      "iteration 135 / 300: loss 0.605306\n",
      "iteration 135 / 300: loss 0.598593\n",
      "iteration 135 / 300: loss 0.591474\n",
      "iteration 135 / 300: loss 0.580383\n",
      "iteration 135 / 300: loss 0.598222\n",
      "iteration 135 / 300: loss 0.611685\n",
      "iteration 135 / 300: loss 0.613220\n",
      "iteration 135 / 300: loss 0.582214\n",
      "iteration 135 / 300: loss 0.601956\n",
      "iteration 135 / 300: loss 0.608957\n",
      "iteration 135 / 300: loss 0.601794\n",
      "iteration 135 / 300: loss 0.607945\n",
      "iteration 135 / 300: loss 0.620237\n",
      "iteration 135 / 300: loss 0.584817\n",
      "iteration 135 / 300: loss 0.583722\n",
      "iteration 135 / 300: loss 0.628850\n",
      "iteration 135 / 300: loss 0.609399\n",
      "iteration 135 / 300: loss 0.606266\n",
      "iteration 135 / 300: loss 0.599035\n",
      "iteration 135 / 300: loss 0.615877\n",
      "iteration 135 / 300: loss 0.596489\n",
      "iteration 135 / 300: loss 0.581431\n",
      "iteration 135 / 300: loss 0.609807\n",
      "iteration 135 / 300: loss 0.608126\n",
      "iteration 135 / 300: loss 0.598225\n",
      "iteration 135 / 300: loss 0.592023\n",
      "iteration 135 / 300: loss 0.611032\n",
      "iteration 135 / 300: loss 0.598550\n",
      "iteration 135 / 300: loss 0.581383\n",
      "iteration 135 / 300: loss 0.609580\n",
      "iteration 136 / 300: loss 0.578385\n",
      "iteration 136 / 300: loss 0.596215\n",
      "iteration 136 / 300: loss 0.569455\n",
      "iteration 136 / 300: loss 0.597850\n",
      "iteration 136 / 300: loss 0.598940\n",
      "iteration 136 / 300: loss 0.603877\n",
      "iteration 136 / 300: loss 0.615262\n",
      "iteration 136 / 300: loss 0.588227\n",
      "iteration 136 / 300: loss 0.627172\n",
      "iteration 136 / 300: loss 0.592601\n",
      "iteration 136 / 300: loss 0.621500\n",
      "iteration 136 / 300: loss 0.593094\n",
      "iteration 136 / 300: loss 0.600541\n",
      "iteration 136 / 300: loss 0.571000\n",
      "iteration 136 / 300: loss 0.592912\n",
      "iteration 136 / 300: loss 0.600043\n",
      "iteration 136 / 300: loss 0.598053\n",
      "iteration 136 / 300: loss 0.583712\n",
      "iteration 136 / 300: loss 0.614355\n",
      "iteration 136 / 300: loss 0.591286\n",
      "iteration 136 / 300: loss 0.591391\n",
      "iteration 136 / 300: loss 0.594005\n",
      "iteration 136 / 300: loss 0.596735\n",
      "iteration 136 / 300: loss 0.596713\n",
      "iteration 136 / 300: loss 0.611735\n",
      "iteration 136 / 300: loss 0.607259\n",
      "iteration 136 / 300: loss 0.597032\n",
      "iteration 136 / 300: loss 0.596301\n",
      "iteration 136 / 300: loss 0.627392\n",
      "iteration 136 / 300: loss 0.601585\n",
      "iteration 136 / 300: loss 0.599924\n",
      "iteration 136 / 300: loss 0.621952\n",
      "iteration 136 / 300: loss 0.581435\n",
      "iteration 136 / 300: loss 0.599605\n",
      "iteration 136 / 300: loss 0.591183\n",
      "iteration 136 / 300: loss 0.599920\n",
      "iteration 136 / 300: loss 0.596016\n",
      "iteration 136 / 300: loss 0.590761\n",
      "iteration 136 / 300: loss 0.591962\n",
      "iteration 136 / 300: loss 0.615468\n",
      "iteration 136 / 300: loss 0.621361\n",
      "iteration 136 / 300: loss 0.587267\n",
      "iteration 136 / 300: loss 0.582483\n",
      "iteration 136 / 300: loss 0.585573\n",
      "iteration 136 / 300: loss 0.603666\n",
      "iteration 136 / 300: loss 0.585193\n",
      "iteration 136 / 300: loss 0.578881\n",
      "iteration 136 / 300: loss 0.576419\n",
      "iteration 136 / 300: loss 0.574098\n",
      "iteration 136 / 300: loss 0.600501\n",
      "iteration 136 / 300: loss 0.584491\n",
      "iteration 136 / 300: loss 0.584834\n",
      "iteration 136 / 300: loss 0.568324\n",
      "iteration 136 / 300: loss 0.592026\n",
      "iteration 136 / 300: loss 0.612117\n",
      "iteration 136 / 300: loss 0.608923\n",
      "iteration 136 / 300: loss 0.607613\n",
      "iteration 136 / 300: loss 0.595534\n",
      "iteration 136 / 300: loss 0.592837\n",
      "iteration 136 / 300: loss 0.597989\n",
      "iteration 136 / 300: loss 0.597677\n",
      "iteration 136 / 300: loss 0.600953\n",
      "iteration 136 / 300: loss 0.597422\n",
      "iteration 136 / 300: loss 0.598777\n",
      "iteration 136 / 300: loss 0.587807\n",
      "iteration 136 / 300: loss 0.600500\n",
      "iteration 136 / 300: loss 0.599651\n",
      "iteration 136 / 300: loss 0.617541\n",
      "iteration 136 / 300: loss 0.598875\n",
      "iteration 136 / 300: loss 0.600802\n",
      "iteration 136 / 300: loss 0.605306\n",
      "iteration 136 / 300: loss 0.598593\n",
      "iteration 136 / 300: loss 0.591474\n",
      "iteration 136 / 300: loss 0.580383\n",
      "iteration 136 / 300: loss 0.598222\n",
      "iteration 136 / 300: loss 0.611685\n",
      "iteration 136 / 300: loss 0.613220\n",
      "iteration 136 / 300: loss 0.582214\n",
      "iteration 136 / 300: loss 0.601956\n",
      "iteration 136 / 300: loss 0.608957\n",
      "iteration 136 / 300: loss 0.601794\n",
      "iteration 136 / 300: loss 0.607945\n",
      "iteration 136 / 300: loss 0.620237\n",
      "iteration 136 / 300: loss 0.584817\n",
      "iteration 136 / 300: loss 0.583721\n",
      "iteration 136 / 300: loss 0.628849\n",
      "iteration 136 / 300: loss 0.609399\n",
      "iteration 136 / 300: loss 0.606266\n",
      "iteration 136 / 300: loss 0.599035\n",
      "iteration 136 / 300: loss 0.615877\n",
      "iteration 136 / 300: loss 0.596489\n",
      "iteration 136 / 300: loss 0.581431\n",
      "iteration 136 / 300: loss 0.609807\n",
      "iteration 136 / 300: loss 0.608126\n",
      "iteration 136 / 300: loss 0.598225\n",
      "iteration 136 / 300: loss 0.592023\n",
      "iteration 136 / 300: loss 0.611032\n",
      "iteration 136 / 300: loss 0.598550\n",
      "iteration 136 / 300: loss 0.581382\n",
      "iteration 136 / 300: loss 0.609580\n",
      "iteration 137 / 300: loss 0.578385\n",
      "iteration 137 / 300: loss 0.596214\n",
      "iteration 137 / 300: loss 0.569455\n",
      "iteration 137 / 300: loss 0.597850\n",
      "iteration 137 / 300: loss 0.598940\n",
      "iteration 137 / 300: loss 0.603877\n",
      "iteration 137 / 300: loss 0.615262\n",
      "iteration 137 / 300: loss 0.588227\n",
      "iteration 137 / 300: loss 0.627172\n",
      "iteration 137 / 300: loss 0.592600\n",
      "iteration 137 / 300: loss 0.621500\n",
      "iteration 137 / 300: loss 0.593094\n",
      "iteration 137 / 300: loss 0.600541\n",
      "iteration 137 / 300: loss 0.571000\n",
      "iteration 137 / 300: loss 0.592912\n",
      "iteration 137 / 300: loss 0.600043\n",
      "iteration 137 / 300: loss 0.598053\n",
      "iteration 137 / 300: loss 0.583712\n",
      "iteration 137 / 300: loss 0.614355\n",
      "iteration 137 / 300: loss 0.591286\n",
      "iteration 137 / 300: loss 0.591391\n",
      "iteration 137 / 300: loss 0.594005\n",
      "iteration 137 / 300: loss 0.596735\n",
      "iteration 137 / 300: loss 0.596713\n",
      "iteration 137 / 300: loss 0.611735\n",
      "iteration 137 / 300: loss 0.607259\n",
      "iteration 137 / 300: loss 0.597032\n",
      "iteration 137 / 300: loss 0.596301\n",
      "iteration 137 / 300: loss 0.627392\n",
      "iteration 137 / 300: loss 0.601585\n",
      "iteration 137 / 300: loss 0.599924\n",
      "iteration 137 / 300: loss 0.621952\n",
      "iteration 137 / 300: loss 0.581435\n",
      "iteration 137 / 300: loss 0.599605\n",
      "iteration 137 / 300: loss 0.591183\n",
      "iteration 137 / 300: loss 0.599920\n",
      "iteration 137 / 300: loss 0.596016\n",
      "iteration 137 / 300: loss 0.590761\n",
      "iteration 137 / 300: loss 0.591962\n",
      "iteration 137 / 300: loss 0.615468\n",
      "iteration 137 / 300: loss 0.621361\n",
      "iteration 137 / 300: loss 0.587267\n",
      "iteration 137 / 300: loss 0.582483\n",
      "iteration 137 / 300: loss 0.585573\n",
      "iteration 137 / 300: loss 0.603666\n",
      "iteration 137 / 300: loss 0.585193\n",
      "iteration 137 / 300: loss 0.578881\n",
      "iteration 137 / 300: loss 0.576419\n",
      "iteration 137 / 300: loss 0.574098\n",
      "iteration 137 / 300: loss 0.600501\n",
      "iteration 137 / 300: loss 0.584491\n",
      "iteration 137 / 300: loss 0.584834\n",
      "iteration 137 / 300: loss 0.568324\n",
      "iteration 137 / 300: loss 0.592026\n",
      "iteration 137 / 300: loss 0.612117\n",
      "iteration 137 / 300: loss 0.608923\n",
      "iteration 137 / 300: loss 0.607613\n",
      "iteration 137 / 300: loss 0.595534\n",
      "iteration 137 / 300: loss 0.592837\n",
      "iteration 137 / 300: loss 0.597989\n",
      "iteration 137 / 300: loss 0.597677\n",
      "iteration 137 / 300: loss 0.600953\n",
      "iteration 137 / 300: loss 0.597422\n",
      "iteration 137 / 300: loss 0.598776\n",
      "iteration 137 / 300: loss 0.587807\n",
      "iteration 137 / 300: loss 0.600500\n",
      "iteration 137 / 300: loss 0.599651\n",
      "iteration 137 / 300: loss 0.617541\n",
      "iteration 137 / 300: loss 0.598875\n",
      "iteration 137 / 300: loss 0.600801\n",
      "iteration 137 / 300: loss 0.605306\n",
      "iteration 137 / 300: loss 0.598593\n",
      "iteration 137 / 300: loss 0.591474\n",
      "iteration 137 / 300: loss 0.580383\n",
      "iteration 137 / 300: loss 0.598222\n",
      "iteration 137 / 300: loss 0.611685\n",
      "iteration 137 / 300: loss 0.613219\n",
      "iteration 137 / 300: loss 0.582214\n",
      "iteration 137 / 300: loss 0.601956\n",
      "iteration 137 / 300: loss 0.608957\n",
      "iteration 137 / 300: loss 0.601794\n",
      "iteration 137 / 300: loss 0.607945\n",
      "iteration 137 / 300: loss 0.620237\n",
      "iteration 137 / 300: loss 0.584817\n",
      "iteration 137 / 300: loss 0.583721\n",
      "iteration 137 / 300: loss 0.628849\n",
      "iteration 137 / 300: loss 0.609399\n",
      "iteration 137 / 300: loss 0.606266\n",
      "iteration 137 / 300: loss 0.599035\n",
      "iteration 137 / 300: loss 0.615877\n",
      "iteration 137 / 300: loss 0.596489\n",
      "iteration 137 / 300: loss 0.581431\n",
      "iteration 137 / 300: loss 0.609807\n",
      "iteration 137 / 300: loss 0.608126\n",
      "iteration 137 / 300: loss 0.598225\n",
      "iteration 137 / 300: loss 0.592023\n",
      "iteration 137 / 300: loss 0.611032\n",
      "iteration 137 / 300: loss 0.598550\n",
      "iteration 137 / 300: loss 0.581382\n",
      "iteration 137 / 300: loss 0.609580\n",
      "iteration 138 / 300: loss 0.578384\n",
      "iteration 138 / 300: loss 0.596214\n",
      "iteration 138 / 300: loss 0.569455\n",
      "iteration 138 / 300: loss 0.597850\n",
      "iteration 138 / 300: loss 0.598940\n",
      "iteration 138 / 300: loss 0.603877\n",
      "iteration 138 / 300: loss 0.615262\n",
      "iteration 138 / 300: loss 0.588227\n",
      "iteration 138 / 300: loss 0.627172\n",
      "iteration 138 / 300: loss 0.592600\n",
      "iteration 138 / 300: loss 0.621500\n",
      "iteration 138 / 300: loss 0.593094\n",
      "iteration 138 / 300: loss 0.600541\n",
      "iteration 138 / 300: loss 0.571000\n",
      "iteration 138 / 300: loss 0.592912\n",
      "iteration 138 / 300: loss 0.600043\n",
      "iteration 138 / 300: loss 0.598053\n",
      "iteration 138 / 300: loss 0.583712\n",
      "iteration 138 / 300: loss 0.614355\n",
      "iteration 138 / 300: loss 0.591286\n",
      "iteration 138 / 300: loss 0.591391\n",
      "iteration 138 / 300: loss 0.594005\n",
      "iteration 138 / 300: loss 0.596735\n",
      "iteration 138 / 300: loss 0.596713\n",
      "iteration 138 / 300: loss 0.611735\n",
      "iteration 138 / 300: loss 0.607259\n",
      "iteration 138 / 300: loss 0.597032\n",
      "iteration 138 / 300: loss 0.596301\n",
      "iteration 138 / 300: loss 0.627392\n",
      "iteration 138 / 300: loss 0.601585\n",
      "iteration 138 / 300: loss 0.599924\n",
      "iteration 138 / 300: loss 0.621952\n",
      "iteration 138 / 300: loss 0.581435\n",
      "iteration 138 / 300: loss 0.599605\n",
      "iteration 138 / 300: loss 0.591183\n",
      "iteration 138 / 300: loss 0.599920\n",
      "iteration 138 / 300: loss 0.596016\n",
      "iteration 138 / 300: loss 0.590761\n",
      "iteration 138 / 300: loss 0.591962\n",
      "iteration 138 / 300: loss 0.615468\n",
      "iteration 138 / 300: loss 0.621361\n",
      "iteration 138 / 300: loss 0.587267\n",
      "iteration 138 / 300: loss 0.582483\n",
      "iteration 138 / 300: loss 0.585573\n",
      "iteration 138 / 300: loss 0.603666\n",
      "iteration 138 / 300: loss 0.585193\n",
      "iteration 138 / 300: loss 0.578881\n",
      "iteration 138 / 300: loss 0.576419\n",
      "iteration 138 / 300: loss 0.574098\n",
      "iteration 138 / 300: loss 0.600500\n",
      "iteration 138 / 300: loss 0.584490\n",
      "iteration 138 / 300: loss 0.584834\n",
      "iteration 138 / 300: loss 0.568324\n",
      "iteration 138 / 300: loss 0.592026\n",
      "iteration 138 / 300: loss 0.612117\n",
      "iteration 138 / 300: loss 0.608923\n",
      "iteration 138 / 300: loss 0.607613\n",
      "iteration 138 / 300: loss 0.595534\n",
      "iteration 138 / 300: loss 0.592837\n",
      "iteration 138 / 300: loss 0.597989\n",
      "iteration 138 / 300: loss 0.597677\n",
      "iteration 138 / 300: loss 0.600953\n",
      "iteration 138 / 300: loss 0.597422\n",
      "iteration 138 / 300: loss 0.598776\n",
      "iteration 138 / 300: loss 0.587807\n",
      "iteration 138 / 300: loss 0.600500\n",
      "iteration 138 / 300: loss 0.599651\n",
      "iteration 138 / 300: loss 0.617541\n",
      "iteration 138 / 300: loss 0.598875\n",
      "iteration 138 / 300: loss 0.600801\n",
      "iteration 138 / 300: loss 0.605306\n",
      "iteration 138 / 300: loss 0.598593\n",
      "iteration 138 / 300: loss 0.591474\n",
      "iteration 138 / 300: loss 0.580383\n",
      "iteration 138 / 300: loss 0.598222\n",
      "iteration 138 / 300: loss 0.611685\n",
      "iteration 138 / 300: loss 0.613219\n",
      "iteration 138 / 300: loss 0.582214\n",
      "iteration 138 / 300: loss 0.601956\n",
      "iteration 138 / 300: loss 0.608957\n",
      "iteration 138 / 300: loss 0.601794\n",
      "iteration 138 / 300: loss 0.607945\n",
      "iteration 138 / 300: loss 0.620237\n",
      "iteration 138 / 300: loss 0.584817\n",
      "iteration 138 / 300: loss 0.583721\n",
      "iteration 138 / 300: loss 0.628849\n",
      "iteration 138 / 300: loss 0.609399\n",
      "iteration 138 / 300: loss 0.606266\n",
      "iteration 138 / 300: loss 0.599035\n",
      "iteration 138 / 300: loss 0.615877\n",
      "iteration 138 / 300: loss 0.596489\n",
      "iteration 138 / 300: loss 0.581431\n",
      "iteration 138 / 300: loss 0.609807\n",
      "iteration 138 / 300: loss 0.608126\n",
      "iteration 138 / 300: loss 0.598225\n",
      "iteration 138 / 300: loss 0.592023\n",
      "iteration 138 / 300: loss 0.611032\n",
      "iteration 138 / 300: loss 0.598550\n",
      "iteration 138 / 300: loss 0.581382\n",
      "iteration 138 / 300: loss 0.609580\n",
      "iteration 139 / 300: loss 0.578384\n",
      "iteration 139 / 300: loss 0.596214\n",
      "iteration 139 / 300: loss 0.569455\n",
      "iteration 139 / 300: loss 0.597850\n",
      "iteration 139 / 300: loss 0.598940\n",
      "iteration 139 / 300: loss 0.603877\n",
      "iteration 139 / 300: loss 0.615262\n",
      "iteration 139 / 300: loss 0.588227\n",
      "iteration 139 / 300: loss 0.627172\n",
      "iteration 139 / 300: loss 0.592600\n",
      "iteration 139 / 300: loss 0.621500\n",
      "iteration 139 / 300: loss 0.593094\n",
      "iteration 139 / 300: loss 0.600541\n",
      "iteration 139 / 300: loss 0.571000\n",
      "iteration 139 / 300: loss 0.592912\n",
      "iteration 139 / 300: loss 0.600043\n",
      "iteration 139 / 300: loss 0.598053\n",
      "iteration 139 / 300: loss 0.583712\n",
      "iteration 139 / 300: loss 0.614355\n",
      "iteration 139 / 300: loss 0.591286\n",
      "iteration 139 / 300: loss 0.591391\n",
      "iteration 139 / 300: loss 0.594005\n",
      "iteration 139 / 300: loss 0.596735\n",
      "iteration 139 / 300: loss 0.596713\n",
      "iteration 139 / 300: loss 0.611735\n",
      "iteration 139 / 300: loss 0.607259\n",
      "iteration 139 / 300: loss 0.597032\n",
      "iteration 139 / 300: loss 0.596301\n",
      "iteration 139 / 300: loss 0.627392\n",
      "iteration 139 / 300: loss 0.601585\n",
      "iteration 139 / 300: loss 0.599924\n",
      "iteration 139 / 300: loss 0.621952\n",
      "iteration 139 / 300: loss 0.581435\n",
      "iteration 139 / 300: loss 0.599605\n",
      "iteration 139 / 300: loss 0.591182\n",
      "iteration 139 / 300: loss 0.599920\n",
      "iteration 139 / 300: loss 0.596016\n",
      "iteration 139 / 300: loss 0.590761\n",
      "iteration 139 / 300: loss 0.591962\n",
      "iteration 139 / 300: loss 0.615468\n",
      "iteration 139 / 300: loss 0.621360\n",
      "iteration 139 / 300: loss 0.587267\n",
      "iteration 139 / 300: loss 0.582483\n",
      "iteration 139 / 300: loss 0.585573\n",
      "iteration 139 / 300: loss 0.603666\n",
      "iteration 139 / 300: loss 0.585193\n",
      "iteration 139 / 300: loss 0.578881\n",
      "iteration 139 / 300: loss 0.576419\n",
      "iteration 139 / 300: loss 0.574098\n",
      "iteration 139 / 300: loss 0.600500\n",
      "iteration 139 / 300: loss 0.584490\n",
      "iteration 139 / 300: loss 0.584834\n",
      "iteration 139 / 300: loss 0.568324\n",
      "iteration 139 / 300: loss 0.592026\n",
      "iteration 139 / 300: loss 0.612117\n",
      "iteration 139 / 300: loss 0.608923\n",
      "iteration 139 / 300: loss 0.607613\n",
      "iteration 139 / 300: loss 0.595534\n",
      "iteration 139 / 300: loss 0.592837\n",
      "iteration 139 / 300: loss 0.597989\n",
      "iteration 139 / 300: loss 0.597677\n",
      "iteration 139 / 300: loss 0.600953\n",
      "iteration 139 / 300: loss 0.597422\n",
      "iteration 139 / 300: loss 0.598776\n",
      "iteration 139 / 300: loss 0.587807\n",
      "iteration 139 / 300: loss 0.600500\n",
      "iteration 139 / 300: loss 0.599651\n",
      "iteration 139 / 300: loss 0.617541\n",
      "iteration 139 / 300: loss 0.598875\n",
      "iteration 139 / 300: loss 0.600801\n",
      "iteration 139 / 300: loss 0.605306\n",
      "iteration 139 / 300: loss 0.598593\n",
      "iteration 139 / 300: loss 0.591474\n",
      "iteration 139 / 300: loss 0.580383\n",
      "iteration 139 / 300: loss 0.598222\n",
      "iteration 139 / 300: loss 0.611685\n",
      "iteration 139 / 300: loss 0.613219\n",
      "iteration 139 / 300: loss 0.582214\n",
      "iteration 139 / 300: loss 0.601956\n",
      "iteration 139 / 300: loss 0.608957\n",
      "iteration 139 / 300: loss 0.601794\n",
      "iteration 139 / 300: loss 0.607945\n",
      "iteration 139 / 300: loss 0.620237\n",
      "iteration 139 / 300: loss 0.584817\n",
      "iteration 139 / 300: loss 0.583721\n",
      "iteration 139 / 300: loss 0.628849\n",
      "iteration 139 / 300: loss 0.609399\n",
      "iteration 139 / 300: loss 0.606265\n",
      "iteration 139 / 300: loss 0.599035\n",
      "iteration 139 / 300: loss 0.615877\n",
      "iteration 139 / 300: loss 0.596489\n",
      "iteration 139 / 300: loss 0.581430\n",
      "iteration 139 / 300: loss 0.609807\n",
      "iteration 139 / 300: loss 0.608126\n",
      "iteration 139 / 300: loss 0.598225\n",
      "iteration 139 / 300: loss 0.592022\n",
      "iteration 139 / 300: loss 0.611032\n",
      "iteration 139 / 300: loss 0.598550\n",
      "iteration 139 / 300: loss 0.581382\n",
      "iteration 139 / 300: loss 0.609580\n",
      "iteration 140 / 300: loss 0.578384\n",
      "iteration 140 / 300: loss 0.596214\n",
      "iteration 140 / 300: loss 0.569455\n",
      "iteration 140 / 300: loss 0.597850\n",
      "iteration 140 / 300: loss 0.598940\n",
      "iteration 140 / 300: loss 0.603877\n",
      "iteration 140 / 300: loss 0.615262\n",
      "iteration 140 / 300: loss 0.588227\n",
      "iteration 140 / 300: loss 0.627172\n",
      "iteration 140 / 300: loss 0.592600\n",
      "iteration 140 / 300: loss 0.621500\n",
      "iteration 140 / 300: loss 0.593094\n",
      "iteration 140 / 300: loss 0.600541\n",
      "iteration 140 / 300: loss 0.571000\n",
      "iteration 140 / 300: loss 0.592912\n",
      "iteration 140 / 300: loss 0.600043\n",
      "iteration 140 / 300: loss 0.598053\n",
      "iteration 140 / 300: loss 0.583712\n",
      "iteration 140 / 300: loss 0.614355\n",
      "iteration 140 / 300: loss 0.591286\n",
      "iteration 140 / 300: loss 0.591391\n",
      "iteration 140 / 300: loss 0.594005\n",
      "iteration 140 / 300: loss 0.596735\n",
      "iteration 140 / 300: loss 0.596712\n",
      "iteration 140 / 300: loss 0.611735\n",
      "iteration 140 / 300: loss 0.607259\n",
      "iteration 140 / 300: loss 0.597032\n",
      "iteration 140 / 300: loss 0.596301\n",
      "iteration 140 / 300: loss 0.627392\n",
      "iteration 140 / 300: loss 0.601585\n",
      "iteration 140 / 300: loss 0.599924\n",
      "iteration 140 / 300: loss 0.621952\n",
      "iteration 140 / 300: loss 0.581435\n",
      "iteration 140 / 300: loss 0.599605\n",
      "iteration 140 / 300: loss 0.591182\n",
      "iteration 140 / 300: loss 0.599920\n",
      "iteration 140 / 300: loss 0.596016\n",
      "iteration 140 / 300: loss 0.590761\n",
      "iteration 140 / 300: loss 0.591962\n",
      "iteration 140 / 300: loss 0.615468\n",
      "iteration 140 / 300: loss 0.621360\n",
      "iteration 140 / 300: loss 0.587267\n",
      "iteration 140 / 300: loss 0.582483\n",
      "iteration 140 / 300: loss 0.585573\n",
      "iteration 140 / 300: loss 0.603666\n",
      "iteration 140 / 300: loss 0.585193\n",
      "iteration 140 / 300: loss 0.578881\n",
      "iteration 140 / 300: loss 0.576419\n",
      "iteration 140 / 300: loss 0.574098\n",
      "iteration 140 / 300: loss 0.600500\n",
      "iteration 140 / 300: loss 0.584490\n",
      "iteration 140 / 300: loss 0.584834\n",
      "iteration 140 / 300: loss 0.568324\n",
      "iteration 140 / 300: loss 0.592026\n",
      "iteration 140 / 300: loss 0.612117\n",
      "iteration 140 / 300: loss 0.608923\n",
      "iteration 140 / 300: loss 0.607613\n",
      "iteration 140 / 300: loss 0.595534\n",
      "iteration 140 / 300: loss 0.592837\n",
      "iteration 140 / 300: loss 0.597989\n",
      "iteration 140 / 300: loss 0.597677\n",
      "iteration 140 / 300: loss 0.600953\n",
      "iteration 140 / 300: loss 0.597422\n",
      "iteration 140 / 300: loss 0.598776\n",
      "iteration 140 / 300: loss 0.587807\n",
      "iteration 140 / 300: loss 0.600500\n",
      "iteration 140 / 300: loss 0.599651\n",
      "iteration 140 / 300: loss 0.617541\n",
      "iteration 140 / 300: loss 0.598875\n",
      "iteration 140 / 300: loss 0.600801\n",
      "iteration 140 / 300: loss 0.605306\n",
      "iteration 140 / 300: loss 0.598593\n",
      "iteration 140 / 300: loss 0.591474\n",
      "iteration 140 / 300: loss 0.580383\n",
      "iteration 140 / 300: loss 0.598222\n",
      "iteration 140 / 300: loss 0.611685\n",
      "iteration 140 / 300: loss 0.613219\n",
      "iteration 140 / 300: loss 0.582214\n",
      "iteration 140 / 300: loss 0.601956\n",
      "iteration 140 / 300: loss 0.608957\n",
      "iteration 140 / 300: loss 0.601794\n",
      "iteration 140 / 300: loss 0.607945\n",
      "iteration 140 / 300: loss 0.620237\n",
      "iteration 140 / 300: loss 0.584817\n",
      "iteration 140 / 300: loss 0.583721\n",
      "iteration 140 / 300: loss 0.628849\n",
      "iteration 140 / 300: loss 0.609399\n",
      "iteration 140 / 300: loss 0.606265\n",
      "iteration 140 / 300: loss 0.599035\n",
      "iteration 140 / 300: loss 0.615877\n",
      "iteration 140 / 300: loss 0.596489\n",
      "iteration 140 / 300: loss 0.581430\n",
      "iteration 140 / 300: loss 0.609807\n",
      "iteration 140 / 300: loss 0.608126\n",
      "iteration 140 / 300: loss 0.598225\n",
      "iteration 140 / 300: loss 0.592022\n",
      "iteration 140 / 300: loss 0.611032\n",
      "iteration 140 / 300: loss 0.598550\n",
      "iteration 140 / 300: loss 0.581382\n",
      "iteration 140 / 300: loss 0.609580\n",
      "iteration 141 / 300: loss 0.578384\n",
      "iteration 141 / 300: loss 0.596214\n",
      "iteration 141 / 300: loss 0.569455\n",
      "iteration 141 / 300: loss 0.597850\n",
      "iteration 141 / 300: loss 0.598940\n",
      "iteration 141 / 300: loss 0.603877\n",
      "iteration 141 / 300: loss 0.615262\n",
      "iteration 141 / 300: loss 0.588227\n",
      "iteration 141 / 300: loss 0.627172\n",
      "iteration 141 / 300: loss 0.592600\n",
      "iteration 141 / 300: loss 0.621500\n",
      "iteration 141 / 300: loss 0.593094\n",
      "iteration 141 / 300: loss 0.600541\n",
      "iteration 141 / 300: loss 0.571000\n",
      "iteration 141 / 300: loss 0.592912\n",
      "iteration 141 / 300: loss 0.600043\n",
      "iteration 141 / 300: loss 0.598053\n",
      "iteration 141 / 300: loss 0.583712\n",
      "iteration 141 / 300: loss 0.614355\n",
      "iteration 141 / 300: loss 0.591286\n",
      "iteration 141 / 300: loss 0.591391\n",
      "iteration 141 / 300: loss 0.594005\n",
      "iteration 141 / 300: loss 0.596735\n",
      "iteration 141 / 300: loss 0.596712\n",
      "iteration 141 / 300: loss 0.611735\n",
      "iteration 141 / 300: loss 0.607259\n",
      "iteration 141 / 300: loss 0.597032\n",
      "iteration 141 / 300: loss 0.596301\n",
      "iteration 141 / 300: loss 0.627391\n",
      "iteration 141 / 300: loss 0.601585\n",
      "iteration 141 / 300: loss 0.599924\n",
      "iteration 141 / 300: loss 0.621952\n",
      "iteration 141 / 300: loss 0.581435\n",
      "iteration 141 / 300: loss 0.599605\n",
      "iteration 141 / 300: loss 0.591182\n",
      "iteration 141 / 300: loss 0.599920\n",
      "iteration 141 / 300: loss 0.596016\n",
      "iteration 141 / 300: loss 0.590761\n",
      "iteration 141 / 300: loss 0.591962\n",
      "iteration 141 / 300: loss 0.615468\n",
      "iteration 141 / 300: loss 0.621360\n",
      "iteration 141 / 300: loss 0.587267\n",
      "iteration 141 / 300: loss 0.582483\n",
      "iteration 141 / 300: loss 0.585573\n",
      "iteration 141 / 300: loss 0.603666\n",
      "iteration 141 / 300: loss 0.585193\n",
      "iteration 141 / 300: loss 0.578881\n",
      "iteration 141 / 300: loss 0.576419\n",
      "iteration 141 / 300: loss 0.574098\n",
      "iteration 141 / 300: loss 0.600500\n",
      "iteration 141 / 300: loss 0.584490\n",
      "iteration 141 / 300: loss 0.584834\n",
      "iteration 141 / 300: loss 0.568324\n",
      "iteration 141 / 300: loss 0.592026\n",
      "iteration 141 / 300: loss 0.612117\n",
      "iteration 141 / 300: loss 0.608923\n",
      "iteration 141 / 300: loss 0.607613\n",
      "iteration 141 / 300: loss 0.595534\n",
      "iteration 141 / 300: loss 0.592837\n",
      "iteration 141 / 300: loss 0.597989\n",
      "iteration 141 / 300: loss 0.597677\n",
      "iteration 141 / 300: loss 0.600953\n",
      "iteration 141 / 300: loss 0.597422\n",
      "iteration 141 / 300: loss 0.598776\n",
      "iteration 141 / 300: loss 0.587807\n",
      "iteration 141 / 300: loss 0.600500\n",
      "iteration 141 / 300: loss 0.599651\n",
      "iteration 141 / 300: loss 0.617540\n",
      "iteration 141 / 300: loss 0.598875\n",
      "iteration 141 / 300: loss 0.600801\n",
      "iteration 141 / 300: loss 0.605305\n",
      "iteration 141 / 300: loss 0.598592\n",
      "iteration 141 / 300: loss 0.591474\n",
      "iteration 141 / 300: loss 0.580383\n",
      "iteration 141 / 300: loss 0.598221\n",
      "iteration 141 / 300: loss 0.611685\n",
      "iteration 141 / 300: loss 0.613219\n",
      "iteration 141 / 300: loss 0.582214\n",
      "iteration 141 / 300: loss 0.601956\n",
      "iteration 141 / 300: loss 0.608957\n",
      "iteration 141 / 300: loss 0.601794\n",
      "iteration 141 / 300: loss 0.607945\n",
      "iteration 141 / 300: loss 0.620237\n",
      "iteration 141 / 300: loss 0.584817\n",
      "iteration 141 / 300: loss 0.583721\n",
      "iteration 141 / 300: loss 0.628849\n",
      "iteration 141 / 300: loss 0.609399\n",
      "iteration 141 / 300: loss 0.606265\n",
      "iteration 141 / 300: loss 0.599035\n",
      "iteration 141 / 300: loss 0.615877\n",
      "iteration 141 / 300: loss 0.596489\n",
      "iteration 141 / 300: loss 0.581430\n",
      "iteration 141 / 300: loss 0.609807\n",
      "iteration 141 / 300: loss 0.608126\n",
      "iteration 141 / 300: loss 0.598225\n",
      "iteration 141 / 300: loss 0.592022\n",
      "iteration 141 / 300: loss 0.611031\n",
      "iteration 141 / 300: loss 0.598550\n",
      "iteration 141 / 300: loss 0.581382\n",
      "iteration 141 / 300: loss 0.609580\n",
      "iteration 142 / 300: loss 0.578384\n",
      "iteration 142 / 300: loss 0.596214\n",
      "iteration 142 / 300: loss 0.569455\n",
      "iteration 142 / 300: loss 0.597850\n",
      "iteration 142 / 300: loss 0.598940\n",
      "iteration 142 / 300: loss 0.603877\n",
      "iteration 142 / 300: loss 0.615262\n",
      "iteration 142 / 300: loss 0.588227\n",
      "iteration 142 / 300: loss 0.627172\n",
      "iteration 142 / 300: loss 0.592600\n",
      "iteration 142 / 300: loss 0.621500\n",
      "iteration 142 / 300: loss 0.593094\n",
      "iteration 142 / 300: loss 0.600541\n",
      "iteration 142 / 300: loss 0.571000\n",
      "iteration 142 / 300: loss 0.592912\n",
      "iteration 142 / 300: loss 0.600043\n",
      "iteration 142 / 300: loss 0.598053\n",
      "iteration 142 / 300: loss 0.583712\n",
      "iteration 142 / 300: loss 0.614355\n",
      "iteration 142 / 300: loss 0.591286\n",
      "iteration 142 / 300: loss 0.591391\n",
      "iteration 142 / 300: loss 0.594005\n",
      "iteration 142 / 300: loss 0.596735\n",
      "iteration 142 / 300: loss 0.596712\n",
      "iteration 142 / 300: loss 0.611735\n",
      "iteration 142 / 300: loss 0.607259\n",
      "iteration 142 / 300: loss 0.597032\n",
      "iteration 142 / 300: loss 0.596301\n",
      "iteration 142 / 300: loss 0.627391\n",
      "iteration 142 / 300: loss 0.601584\n",
      "iteration 142 / 300: loss 0.599924\n",
      "iteration 142 / 300: loss 0.621952\n",
      "iteration 142 / 300: loss 0.581435\n",
      "iteration 142 / 300: loss 0.599605\n",
      "iteration 142 / 300: loss 0.591182\n",
      "iteration 142 / 300: loss 0.599920\n",
      "iteration 142 / 300: loss 0.596015\n",
      "iteration 142 / 300: loss 0.590761\n",
      "iteration 142 / 300: loss 0.591962\n",
      "iteration 142 / 300: loss 0.615468\n",
      "iteration 142 / 300: loss 0.621360\n",
      "iteration 142 / 300: loss 0.587267\n",
      "iteration 142 / 300: loss 0.582483\n",
      "iteration 142 / 300: loss 0.585573\n",
      "iteration 142 / 300: loss 0.603666\n",
      "iteration 142 / 300: loss 0.585193\n",
      "iteration 142 / 300: loss 0.578881\n",
      "iteration 142 / 300: loss 0.576419\n",
      "iteration 142 / 300: loss 0.574097\n",
      "iteration 142 / 300: loss 0.600500\n",
      "iteration 142 / 300: loss 0.584490\n",
      "iteration 142 / 300: loss 0.584834\n",
      "iteration 142 / 300: loss 0.568324\n",
      "iteration 142 / 300: loss 0.592026\n",
      "iteration 142 / 300: loss 0.612117\n",
      "iteration 142 / 300: loss 0.608923\n",
      "iteration 142 / 300: loss 0.607613\n",
      "iteration 142 / 300: loss 0.595534\n",
      "iteration 142 / 300: loss 0.592837\n",
      "iteration 142 / 300: loss 0.597989\n",
      "iteration 142 / 300: loss 0.597677\n",
      "iteration 142 / 300: loss 0.600953\n",
      "iteration 142 / 300: loss 0.597422\n",
      "iteration 142 / 300: loss 0.598776\n",
      "iteration 142 / 300: loss 0.587807\n",
      "iteration 142 / 300: loss 0.600500\n",
      "iteration 142 / 300: loss 0.599651\n",
      "iteration 142 / 300: loss 0.617540\n",
      "iteration 142 / 300: loss 0.598875\n",
      "iteration 142 / 300: loss 0.600801\n",
      "iteration 142 / 300: loss 0.605305\n",
      "iteration 142 / 300: loss 0.598592\n",
      "iteration 142 / 300: loss 0.591474\n",
      "iteration 142 / 300: loss 0.580383\n",
      "iteration 142 / 300: loss 0.598221\n",
      "iteration 142 / 300: loss 0.611685\n",
      "iteration 142 / 300: loss 0.613219\n",
      "iteration 142 / 300: loss 0.582214\n",
      "iteration 142 / 300: loss 0.601956\n",
      "iteration 142 / 300: loss 0.608957\n",
      "iteration 142 / 300: loss 0.601794\n",
      "iteration 142 / 300: loss 0.607945\n",
      "iteration 142 / 300: loss 0.620237\n",
      "iteration 142 / 300: loss 0.584817\n",
      "iteration 142 / 300: loss 0.583721\n",
      "iteration 142 / 300: loss 0.628849\n",
      "iteration 142 / 300: loss 0.609399\n",
      "iteration 142 / 300: loss 0.606265\n",
      "iteration 142 / 300: loss 0.599035\n",
      "iteration 142 / 300: loss 0.615877\n",
      "iteration 142 / 300: loss 0.596489\n",
      "iteration 142 / 300: loss 0.581430\n",
      "iteration 142 / 300: loss 0.609807\n",
      "iteration 142 / 300: loss 0.608126\n",
      "iteration 142 / 300: loss 0.598225\n",
      "iteration 142 / 300: loss 0.592022\n",
      "iteration 142 / 300: loss 0.611031\n",
      "iteration 142 / 300: loss 0.598550\n",
      "iteration 142 / 300: loss 0.581382\n",
      "iteration 142 / 300: loss 0.609580\n",
      "iteration 143 / 300: loss 0.578384\n",
      "iteration 143 / 300: loss 0.596214\n",
      "iteration 143 / 300: loss 0.569455\n",
      "iteration 143 / 300: loss 0.597850\n",
      "iteration 143 / 300: loss 0.598940\n",
      "iteration 143 / 300: loss 0.603877\n",
      "iteration 143 / 300: loss 0.615262\n",
      "iteration 143 / 300: loss 0.588227\n",
      "iteration 143 / 300: loss 0.627172\n",
      "iteration 143 / 300: loss 0.592600\n",
      "iteration 143 / 300: loss 0.621500\n",
      "iteration 143 / 300: loss 0.593094\n",
      "iteration 143 / 300: loss 0.600541\n",
      "iteration 143 / 300: loss 0.571000\n",
      "iteration 143 / 300: loss 0.592912\n",
      "iteration 143 / 300: loss 0.600043\n",
      "iteration 143 / 300: loss 0.598053\n",
      "iteration 143 / 300: loss 0.583712\n",
      "iteration 143 / 300: loss 0.614355\n",
      "iteration 143 / 300: loss 0.591286\n",
      "iteration 143 / 300: loss 0.591391\n",
      "iteration 143 / 300: loss 0.594005\n",
      "iteration 143 / 300: loss 0.596735\n",
      "iteration 143 / 300: loss 0.596712\n",
      "iteration 143 / 300: loss 0.611735\n",
      "iteration 143 / 300: loss 0.607259\n",
      "iteration 143 / 300: loss 0.597032\n",
      "iteration 143 / 300: loss 0.596301\n",
      "iteration 143 / 300: loss 0.627391\n",
      "iteration 143 / 300: loss 0.601584\n",
      "iteration 143 / 300: loss 0.599924\n",
      "iteration 143 / 300: loss 0.621952\n",
      "iteration 143 / 300: loss 0.581435\n",
      "iteration 143 / 300: loss 0.599605\n",
      "iteration 143 / 300: loss 0.591182\n",
      "iteration 143 / 300: loss 0.599920\n",
      "iteration 143 / 300: loss 0.596015\n",
      "iteration 143 / 300: loss 0.590760\n",
      "iteration 143 / 300: loss 0.591962\n",
      "iteration 143 / 300: loss 0.615468\n",
      "iteration 143 / 300: loss 0.621360\n",
      "iteration 143 / 300: loss 0.587267\n",
      "iteration 143 / 300: loss 0.582483\n",
      "iteration 143 / 300: loss 0.585573\n",
      "iteration 143 / 300: loss 0.603666\n",
      "iteration 143 / 300: loss 0.585193\n",
      "iteration 143 / 300: loss 0.578881\n",
      "iteration 143 / 300: loss 0.576418\n",
      "iteration 143 / 300: loss 0.574097\n",
      "iteration 143 / 300: loss 0.600500\n",
      "iteration 143 / 300: loss 0.584490\n",
      "iteration 143 / 300: loss 0.584834\n",
      "iteration 143 / 300: loss 0.568324\n",
      "iteration 143 / 300: loss 0.592026\n",
      "iteration 143 / 300: loss 0.612117\n",
      "iteration 143 / 300: loss 0.608923\n",
      "iteration 143 / 300: loss 0.607613\n",
      "iteration 143 / 300: loss 0.595534\n",
      "iteration 143 / 300: loss 0.592837\n",
      "iteration 143 / 300: loss 0.597989\n",
      "iteration 143 / 300: loss 0.597677\n",
      "iteration 143 / 300: loss 0.600953\n",
      "iteration 143 / 300: loss 0.597422\n",
      "iteration 143 / 300: loss 0.598776\n",
      "iteration 143 / 300: loss 0.587807\n",
      "iteration 143 / 300: loss 0.600500\n",
      "iteration 143 / 300: loss 0.599651\n",
      "iteration 143 / 300: loss 0.617540\n",
      "iteration 143 / 300: loss 0.598875\n",
      "iteration 143 / 300: loss 0.600801\n",
      "iteration 143 / 300: loss 0.605305\n",
      "iteration 143 / 300: loss 0.598592\n",
      "iteration 143 / 300: loss 0.591474\n",
      "iteration 143 / 300: loss 0.580383\n",
      "iteration 143 / 300: loss 0.598221\n",
      "iteration 143 / 300: loss 0.611685\n",
      "iteration 143 / 300: loss 0.613219\n",
      "iteration 143 / 300: loss 0.582214\n",
      "iteration 143 / 300: loss 0.601956\n",
      "iteration 143 / 300: loss 0.608957\n",
      "iteration 143 / 300: loss 0.601794\n",
      "iteration 143 / 300: loss 0.607945\n",
      "iteration 143 / 300: loss 0.620237\n",
      "iteration 143 / 300: loss 0.584817\n",
      "iteration 143 / 300: loss 0.583721\n",
      "iteration 143 / 300: loss 0.628849\n",
      "iteration 143 / 300: loss 0.609399\n",
      "iteration 143 / 300: loss 0.606265\n",
      "iteration 143 / 300: loss 0.599035\n",
      "iteration 143 / 300: loss 0.615877\n",
      "iteration 143 / 300: loss 0.596489\n",
      "iteration 143 / 300: loss 0.581430\n",
      "iteration 143 / 300: loss 0.609807\n",
      "iteration 143 / 300: loss 0.608126\n",
      "iteration 143 / 300: loss 0.598225\n",
      "iteration 143 / 300: loss 0.592022\n",
      "iteration 143 / 300: loss 0.611031\n",
      "iteration 143 / 300: loss 0.598550\n",
      "iteration 143 / 300: loss 0.581382\n",
      "iteration 143 / 300: loss 0.609580\n",
      "iteration 144 / 300: loss 0.578384\n",
      "iteration 144 / 300: loss 0.596214\n",
      "iteration 144 / 300: loss 0.569455\n",
      "iteration 144 / 300: loss 0.597850\n",
      "iteration 144 / 300: loss 0.598940\n",
      "iteration 144 / 300: loss 0.603876\n",
      "iteration 144 / 300: loss 0.615262\n",
      "iteration 144 / 300: loss 0.588227\n",
      "iteration 144 / 300: loss 0.627172\n",
      "iteration 144 / 300: loss 0.592600\n",
      "iteration 144 / 300: loss 0.621500\n",
      "iteration 144 / 300: loss 0.593094\n",
      "iteration 144 / 300: loss 0.600541\n",
      "iteration 144 / 300: loss 0.571000\n",
      "iteration 144 / 300: loss 0.592911\n",
      "iteration 144 / 300: loss 0.600043\n",
      "iteration 144 / 300: loss 0.598053\n",
      "iteration 144 / 300: loss 0.583712\n",
      "iteration 144 / 300: loss 0.614355\n",
      "iteration 144 / 300: loss 0.591286\n",
      "iteration 144 / 300: loss 0.591391\n",
      "iteration 144 / 300: loss 0.594005\n",
      "iteration 144 / 300: loss 0.596735\n",
      "iteration 144 / 300: loss 0.596712\n",
      "iteration 144 / 300: loss 0.611735\n",
      "iteration 144 / 300: loss 0.607258\n",
      "iteration 144 / 300: loss 0.597032\n",
      "iteration 144 / 300: loss 0.596301\n",
      "iteration 144 / 300: loss 0.627391\n",
      "iteration 144 / 300: loss 0.601584\n",
      "iteration 144 / 300: loss 0.599924\n",
      "iteration 144 / 300: loss 0.621952\n",
      "iteration 144 / 300: loss 0.581435\n",
      "iteration 144 / 300: loss 0.599605\n",
      "iteration 144 / 300: loss 0.591182\n",
      "iteration 144 / 300: loss 0.599920\n",
      "iteration 144 / 300: loss 0.596015\n",
      "iteration 144 / 300: loss 0.590760\n",
      "iteration 144 / 300: loss 0.591962\n",
      "iteration 144 / 300: loss 0.615468\n",
      "iteration 144 / 300: loss 0.621360\n",
      "iteration 144 / 300: loss 0.587267\n",
      "iteration 144 / 300: loss 0.582483\n",
      "iteration 144 / 300: loss 0.585573\n",
      "iteration 144 / 300: loss 0.603666\n",
      "iteration 144 / 300: loss 0.585193\n",
      "iteration 144 / 300: loss 0.578881\n",
      "iteration 144 / 300: loss 0.576418\n",
      "iteration 144 / 300: loss 0.574097\n",
      "iteration 144 / 300: loss 0.600500\n",
      "iteration 144 / 300: loss 0.584490\n",
      "iteration 144 / 300: loss 0.584834\n",
      "iteration 144 / 300: loss 0.568324\n",
      "iteration 144 / 300: loss 0.592026\n",
      "iteration 144 / 300: loss 0.612116\n",
      "iteration 144 / 300: loss 0.608923\n",
      "iteration 144 / 300: loss 0.607613\n",
      "iteration 144 / 300: loss 0.595534\n",
      "iteration 144 / 300: loss 0.592837\n",
      "iteration 144 / 300: loss 0.597989\n",
      "iteration 144 / 300: loss 0.597677\n",
      "iteration 144 / 300: loss 0.600953\n",
      "iteration 144 / 300: loss 0.597422\n",
      "iteration 144 / 300: loss 0.598776\n",
      "iteration 144 / 300: loss 0.587807\n",
      "iteration 144 / 300: loss 0.600500\n",
      "iteration 144 / 300: loss 0.599651\n",
      "iteration 144 / 300: loss 0.617540\n",
      "iteration 144 / 300: loss 0.598875\n",
      "iteration 144 / 300: loss 0.600801\n",
      "iteration 144 / 300: loss 0.605305\n",
      "iteration 144 / 300: loss 0.598592\n",
      "iteration 144 / 300: loss 0.591474\n",
      "iteration 144 / 300: loss 0.580383\n",
      "iteration 144 / 300: loss 0.598221\n",
      "iteration 144 / 300: loss 0.611685\n",
      "iteration 144 / 300: loss 0.613219\n",
      "iteration 144 / 300: loss 0.582214\n",
      "iteration 144 / 300: loss 0.601956\n",
      "iteration 144 / 300: loss 0.608957\n",
      "iteration 144 / 300: loss 0.601794\n",
      "iteration 144 / 300: loss 0.607945\n",
      "iteration 144 / 300: loss 0.620237\n",
      "iteration 144 / 300: loss 0.584817\n",
      "iteration 144 / 300: loss 0.583721\n",
      "iteration 144 / 300: loss 0.628849\n",
      "iteration 144 / 300: loss 0.609399\n",
      "iteration 144 / 300: loss 0.606265\n",
      "iteration 144 / 300: loss 0.599035\n",
      "iteration 144 / 300: loss 0.615877\n",
      "iteration 144 / 300: loss 0.596489\n",
      "iteration 144 / 300: loss 0.581430\n",
      "iteration 144 / 300: loss 0.609807\n",
      "iteration 144 / 300: loss 0.608126\n",
      "iteration 144 / 300: loss 0.598225\n",
      "iteration 144 / 300: loss 0.592022\n",
      "iteration 144 / 300: loss 0.611031\n",
      "iteration 144 / 300: loss 0.598550\n",
      "iteration 144 / 300: loss 0.581382\n",
      "iteration 144 / 300: loss 0.609580\n",
      "iteration 145 / 300: loss 0.578384\n",
      "iteration 145 / 300: loss 0.596214\n",
      "iteration 145 / 300: loss 0.569455\n",
      "iteration 145 / 300: loss 0.597850\n",
      "iteration 145 / 300: loss 0.598940\n",
      "iteration 145 / 300: loss 0.603876\n",
      "iteration 145 / 300: loss 0.615262\n",
      "iteration 145 / 300: loss 0.588227\n",
      "iteration 145 / 300: loss 0.627172\n",
      "iteration 145 / 300: loss 0.592600\n",
      "iteration 145 / 300: loss 0.621500\n",
      "iteration 145 / 300: loss 0.593094\n",
      "iteration 145 / 300: loss 0.600541\n",
      "iteration 145 / 300: loss 0.571000\n",
      "iteration 145 / 300: loss 0.592911\n",
      "iteration 145 / 300: loss 0.600043\n",
      "iteration 145 / 300: loss 0.598053\n",
      "iteration 145 / 300: loss 0.583712\n",
      "iteration 145 / 300: loss 0.614355\n",
      "iteration 145 / 300: loss 0.591286\n",
      "iteration 145 / 300: loss 0.591391\n",
      "iteration 145 / 300: loss 0.594005\n",
      "iteration 145 / 300: loss 0.596735\n",
      "iteration 145 / 300: loss 0.596712\n",
      "iteration 145 / 300: loss 0.611735\n",
      "iteration 145 / 300: loss 0.607258\n",
      "iteration 145 / 300: loss 0.597032\n",
      "iteration 145 / 300: loss 0.596301\n",
      "iteration 145 / 300: loss 0.627391\n",
      "iteration 145 / 300: loss 0.601584\n",
      "iteration 145 / 300: loss 0.599924\n",
      "iteration 145 / 300: loss 0.621952\n",
      "iteration 145 / 300: loss 0.581435\n",
      "iteration 145 / 300: loss 0.599605\n",
      "iteration 145 / 300: loss 0.591182\n",
      "iteration 145 / 300: loss 0.599920\n",
      "iteration 145 / 300: loss 0.596015\n",
      "iteration 145 / 300: loss 0.590760\n",
      "iteration 145 / 300: loss 0.591962\n",
      "iteration 145 / 300: loss 0.615468\n",
      "iteration 145 / 300: loss 0.621360\n",
      "iteration 145 / 300: loss 0.587267\n",
      "iteration 145 / 300: loss 0.582483\n",
      "iteration 145 / 300: loss 0.585573\n",
      "iteration 145 / 300: loss 0.603666\n",
      "iteration 145 / 300: loss 0.585193\n",
      "iteration 145 / 300: loss 0.578880\n",
      "iteration 145 / 300: loss 0.576418\n",
      "iteration 145 / 300: loss 0.574097\n",
      "iteration 145 / 300: loss 0.600500\n",
      "iteration 145 / 300: loss 0.584490\n",
      "iteration 145 / 300: loss 0.584834\n",
      "iteration 145 / 300: loss 0.568324\n",
      "iteration 145 / 300: loss 0.592026\n",
      "iteration 145 / 300: loss 0.612116\n",
      "iteration 145 / 300: loss 0.608923\n",
      "iteration 145 / 300: loss 0.607613\n",
      "iteration 145 / 300: loss 0.595534\n",
      "iteration 145 / 300: loss 0.592837\n",
      "iteration 145 / 300: loss 0.597989\n",
      "iteration 145 / 300: loss 0.597677\n",
      "iteration 145 / 300: loss 0.600953\n",
      "iteration 145 / 300: loss 0.597422\n",
      "iteration 145 / 300: loss 0.598776\n",
      "iteration 145 / 300: loss 0.587807\n",
      "iteration 145 / 300: loss 0.600500\n",
      "iteration 145 / 300: loss 0.599651\n",
      "iteration 145 / 300: loss 0.617540\n",
      "iteration 145 / 300: loss 0.598875\n",
      "iteration 145 / 300: loss 0.600801\n",
      "iteration 145 / 300: loss 0.605305\n",
      "iteration 145 / 300: loss 0.598592\n",
      "iteration 145 / 300: loss 0.591474\n",
      "iteration 145 / 300: loss 0.580383\n",
      "iteration 145 / 300: loss 0.598221\n",
      "iteration 145 / 300: loss 0.611685\n",
      "iteration 145 / 300: loss 0.613219\n",
      "iteration 145 / 300: loss 0.582214\n",
      "iteration 145 / 300: loss 0.601956\n",
      "iteration 145 / 300: loss 0.608956\n",
      "iteration 145 / 300: loss 0.601794\n",
      "iteration 145 / 300: loss 0.607945\n",
      "iteration 145 / 300: loss 0.620237\n",
      "iteration 145 / 300: loss 0.584817\n",
      "iteration 145 / 300: loss 0.583721\n",
      "iteration 145 / 300: loss 0.628849\n",
      "iteration 145 / 300: loss 0.609399\n",
      "iteration 145 / 300: loss 0.606265\n",
      "iteration 145 / 300: loss 0.599035\n",
      "iteration 145 / 300: loss 0.615877\n",
      "iteration 145 / 300: loss 0.596489\n",
      "iteration 145 / 300: loss 0.581430\n",
      "iteration 145 / 300: loss 0.609807\n",
      "iteration 145 / 300: loss 0.608126\n",
      "iteration 145 / 300: loss 0.598225\n",
      "iteration 145 / 300: loss 0.592022\n",
      "iteration 145 / 300: loss 0.611031\n",
      "iteration 145 / 300: loss 0.598550\n",
      "iteration 145 / 300: loss 0.581382\n",
      "iteration 145 / 300: loss 0.609580\n",
      "iteration 146 / 300: loss 0.578384\n",
      "iteration 146 / 300: loss 0.596214\n",
      "iteration 146 / 300: loss 0.569455\n",
      "iteration 146 / 300: loss 0.597849\n",
      "iteration 146 / 300: loss 0.598940\n",
      "iteration 146 / 300: loss 0.603876\n",
      "iteration 146 / 300: loss 0.615261\n",
      "iteration 146 / 300: loss 0.588227\n",
      "iteration 146 / 300: loss 0.627172\n",
      "iteration 146 / 300: loss 0.592600\n",
      "iteration 146 / 300: loss 0.621500\n",
      "iteration 146 / 300: loss 0.593094\n",
      "iteration 146 / 300: loss 0.600541\n",
      "iteration 146 / 300: loss 0.571000\n",
      "iteration 146 / 300: loss 0.592911\n",
      "iteration 146 / 300: loss 0.600043\n",
      "iteration 146 / 300: loss 0.598053\n",
      "iteration 146 / 300: loss 0.583712\n",
      "iteration 146 / 300: loss 0.614355\n",
      "iteration 146 / 300: loss 0.591286\n",
      "iteration 146 / 300: loss 0.591391\n",
      "iteration 146 / 300: loss 0.594005\n",
      "iteration 146 / 300: loss 0.596735\n",
      "iteration 146 / 300: loss 0.596712\n",
      "iteration 146 / 300: loss 0.611735\n",
      "iteration 146 / 300: loss 0.607258\n",
      "iteration 146 / 300: loss 0.597032\n",
      "iteration 146 / 300: loss 0.596301\n",
      "iteration 146 / 300: loss 0.627391\n",
      "iteration 146 / 300: loss 0.601584\n",
      "iteration 146 / 300: loss 0.599923\n",
      "iteration 146 / 300: loss 0.621952\n",
      "iteration 146 / 300: loss 0.581435\n",
      "iteration 146 / 300: loss 0.599604\n",
      "iteration 146 / 300: loss 0.591182\n",
      "iteration 146 / 300: loss 0.599920\n",
      "iteration 146 / 300: loss 0.596015\n",
      "iteration 146 / 300: loss 0.590760\n",
      "iteration 146 / 300: loss 0.591962\n",
      "iteration 146 / 300: loss 0.615468\n",
      "iteration 146 / 300: loss 0.621360\n",
      "iteration 146 / 300: loss 0.587267\n",
      "iteration 146 / 300: loss 0.582483\n",
      "iteration 146 / 300: loss 0.585573\n",
      "iteration 146 / 300: loss 0.603666\n",
      "iteration 146 / 300: loss 0.585193\n",
      "iteration 146 / 300: loss 0.578880\n",
      "iteration 146 / 300: loss 0.576418\n",
      "iteration 146 / 300: loss 0.574097\n",
      "iteration 146 / 300: loss 0.600500\n",
      "iteration 146 / 300: loss 0.584490\n",
      "iteration 146 / 300: loss 0.584834\n",
      "iteration 146 / 300: loss 0.568324\n",
      "iteration 146 / 300: loss 0.592026\n",
      "iteration 146 / 300: loss 0.612116\n",
      "iteration 146 / 300: loss 0.608923\n",
      "iteration 146 / 300: loss 0.607613\n",
      "iteration 146 / 300: loss 0.595534\n",
      "iteration 146 / 300: loss 0.592837\n",
      "iteration 146 / 300: loss 0.597989\n",
      "iteration 146 / 300: loss 0.597677\n",
      "iteration 146 / 300: loss 0.600953\n",
      "iteration 146 / 300: loss 0.597422\n",
      "iteration 146 / 300: loss 0.598776\n",
      "iteration 146 / 300: loss 0.587806\n",
      "iteration 146 / 300: loss 0.600500\n",
      "iteration 146 / 300: loss 0.599650\n",
      "iteration 146 / 300: loss 0.617540\n",
      "iteration 146 / 300: loss 0.598875\n",
      "iteration 146 / 300: loss 0.600801\n",
      "iteration 146 / 300: loss 0.605305\n",
      "iteration 146 / 300: loss 0.598592\n",
      "iteration 146 / 300: loss 0.591474\n",
      "iteration 146 / 300: loss 0.580382\n",
      "iteration 146 / 300: loss 0.598221\n",
      "iteration 146 / 300: loss 0.611685\n",
      "iteration 146 / 300: loss 0.613219\n",
      "iteration 146 / 300: loss 0.582214\n",
      "iteration 146 / 300: loss 0.601956\n",
      "iteration 146 / 300: loss 0.608956\n",
      "iteration 146 / 300: loss 0.601794\n",
      "iteration 146 / 300: loss 0.607945\n",
      "iteration 146 / 300: loss 0.620237\n",
      "iteration 146 / 300: loss 0.584817\n",
      "iteration 146 / 300: loss 0.583721\n",
      "iteration 146 / 300: loss 0.628849\n",
      "iteration 146 / 300: loss 0.609399\n",
      "iteration 146 / 300: loss 0.606265\n",
      "iteration 146 / 300: loss 0.599035\n",
      "iteration 146 / 300: loss 0.615877\n",
      "iteration 146 / 300: loss 0.596489\n",
      "iteration 146 / 300: loss 0.581430\n",
      "iteration 146 / 300: loss 0.609807\n",
      "iteration 146 / 300: loss 0.608126\n",
      "iteration 146 / 300: loss 0.598225\n",
      "iteration 146 / 300: loss 0.592022\n",
      "iteration 146 / 300: loss 0.611031\n",
      "iteration 146 / 300: loss 0.598550\n",
      "iteration 146 / 300: loss 0.581382\n",
      "iteration 146 / 300: loss 0.609580\n",
      "iteration 147 / 300: loss 0.578384\n",
      "iteration 147 / 300: loss 0.596214\n",
      "iteration 147 / 300: loss 0.569455\n",
      "iteration 147 / 300: loss 0.597849\n",
      "iteration 147 / 300: loss 0.598940\n",
      "iteration 147 / 300: loss 0.603876\n",
      "iteration 147 / 300: loss 0.615261\n",
      "iteration 147 / 300: loss 0.588227\n",
      "iteration 147 / 300: loss 0.627172\n",
      "iteration 147 / 300: loss 0.592600\n",
      "iteration 147 / 300: loss 0.621500\n",
      "iteration 147 / 300: loss 0.593094\n",
      "iteration 147 / 300: loss 0.600541\n",
      "iteration 147 / 300: loss 0.571000\n",
      "iteration 147 / 300: loss 0.592911\n",
      "iteration 147 / 300: loss 0.600043\n",
      "iteration 147 / 300: loss 0.598053\n",
      "iteration 147 / 300: loss 0.583712\n",
      "iteration 147 / 300: loss 0.614355\n",
      "iteration 147 / 300: loss 0.591286\n",
      "iteration 147 / 300: loss 0.591391\n",
      "iteration 147 / 300: loss 0.594005\n",
      "iteration 147 / 300: loss 0.596735\n",
      "iteration 147 / 300: loss 0.596712\n",
      "iteration 147 / 300: loss 0.611735\n",
      "iteration 147 / 300: loss 0.607258\n",
      "iteration 147 / 300: loss 0.597032\n",
      "iteration 147 / 300: loss 0.596301\n",
      "iteration 147 / 300: loss 0.627391\n",
      "iteration 147 / 300: loss 0.601584\n",
      "iteration 147 / 300: loss 0.599923\n",
      "iteration 147 / 300: loss 0.621952\n",
      "iteration 147 / 300: loss 0.581435\n",
      "iteration 147 / 300: loss 0.599604\n",
      "iteration 147 / 300: loss 0.591182\n",
      "iteration 147 / 300: loss 0.599920\n",
      "iteration 147 / 300: loss 0.596015\n",
      "iteration 147 / 300: loss 0.590760\n",
      "iteration 147 / 300: loss 0.591962\n",
      "iteration 147 / 300: loss 0.615468\n",
      "iteration 147 / 300: loss 0.621360\n",
      "iteration 147 / 300: loss 0.587267\n",
      "iteration 147 / 300: loss 0.582483\n",
      "iteration 147 / 300: loss 0.585573\n",
      "iteration 147 / 300: loss 0.603666\n",
      "iteration 147 / 300: loss 0.585193\n",
      "iteration 147 / 300: loss 0.578880\n",
      "iteration 147 / 300: loss 0.576418\n",
      "iteration 147 / 300: loss 0.574097\n",
      "iteration 147 / 300: loss 0.600500\n",
      "iteration 147 / 300: loss 0.584490\n",
      "iteration 147 / 300: loss 0.584834\n",
      "iteration 147 / 300: loss 0.568324\n",
      "iteration 147 / 300: loss 0.592026\n",
      "iteration 147 / 300: loss 0.612116\n",
      "iteration 147 / 300: loss 0.608923\n",
      "iteration 147 / 300: loss 0.607613\n",
      "iteration 147 / 300: loss 0.595534\n",
      "iteration 147 / 300: loss 0.592837\n",
      "iteration 147 / 300: loss 0.597989\n",
      "iteration 147 / 300: loss 0.597677\n",
      "iteration 147 / 300: loss 0.600953\n",
      "iteration 147 / 300: loss 0.597422\n",
      "iteration 147 / 300: loss 0.598776\n",
      "iteration 147 / 300: loss 0.587806\n",
      "iteration 147 / 300: loss 0.600500\n",
      "iteration 147 / 300: loss 0.599650\n",
      "iteration 147 / 300: loss 0.617540\n",
      "iteration 147 / 300: loss 0.598875\n",
      "iteration 147 / 300: loss 0.600801\n",
      "iteration 147 / 300: loss 0.605305\n",
      "iteration 147 / 300: loss 0.598592\n",
      "iteration 147 / 300: loss 0.591474\n",
      "iteration 147 / 300: loss 0.580382\n",
      "iteration 147 / 300: loss 0.598221\n",
      "iteration 147 / 300: loss 0.611685\n",
      "iteration 147 / 300: loss 0.613219\n",
      "iteration 147 / 300: loss 0.582214\n",
      "iteration 147 / 300: loss 0.601955\n",
      "iteration 147 / 300: loss 0.608956\n",
      "iteration 147 / 300: loss 0.601794\n",
      "iteration 147 / 300: loss 0.607945\n",
      "iteration 147 / 300: loss 0.620237\n",
      "iteration 147 / 300: loss 0.584817\n",
      "iteration 147 / 300: loss 0.583721\n",
      "iteration 147 / 300: loss 0.628849\n",
      "iteration 147 / 300: loss 0.609399\n",
      "iteration 147 / 300: loss 0.606265\n",
      "iteration 147 / 300: loss 0.599035\n",
      "iteration 147 / 300: loss 0.615877\n",
      "iteration 147 / 300: loss 0.596489\n",
      "iteration 147 / 300: loss 0.581430\n",
      "iteration 147 / 300: loss 0.609807\n",
      "iteration 147 / 300: loss 0.608126\n",
      "iteration 147 / 300: loss 0.598225\n",
      "iteration 147 / 300: loss 0.592022\n",
      "iteration 147 / 300: loss 0.611031\n",
      "iteration 147 / 300: loss 0.598550\n",
      "iteration 147 / 300: loss 0.581382\n",
      "iteration 147 / 300: loss 0.609580\n",
      "iteration 148 / 300: loss 0.578384\n",
      "iteration 148 / 300: loss 0.596214\n",
      "iteration 148 / 300: loss 0.569455\n",
      "iteration 148 / 300: loss 0.597849\n",
      "iteration 148 / 300: loss 0.598940\n",
      "iteration 148 / 300: loss 0.603876\n",
      "iteration 148 / 300: loss 0.615261\n",
      "iteration 148 / 300: loss 0.588227\n",
      "iteration 148 / 300: loss 0.627172\n",
      "iteration 148 / 300: loss 0.592600\n",
      "iteration 148 / 300: loss 0.621500\n",
      "iteration 148 / 300: loss 0.593094\n",
      "iteration 148 / 300: loss 0.600541\n",
      "iteration 148 / 300: loss 0.571000\n",
      "iteration 148 / 300: loss 0.592911\n",
      "iteration 148 / 300: loss 0.600043\n",
      "iteration 148 / 300: loss 0.598053\n",
      "iteration 148 / 300: loss 0.583712\n",
      "iteration 148 / 300: loss 0.614355\n",
      "iteration 148 / 300: loss 0.591286\n",
      "iteration 148 / 300: loss 0.591391\n",
      "iteration 148 / 300: loss 0.594005\n",
      "iteration 148 / 300: loss 0.596735\n",
      "iteration 148 / 300: loss 0.596712\n",
      "iteration 148 / 300: loss 0.611735\n",
      "iteration 148 / 300: loss 0.607258\n",
      "iteration 148 / 300: loss 0.597032\n",
      "iteration 148 / 300: loss 0.596301\n",
      "iteration 148 / 300: loss 0.627391\n",
      "iteration 148 / 300: loss 0.601584\n",
      "iteration 148 / 300: loss 0.599923\n",
      "iteration 148 / 300: loss 0.621952\n",
      "iteration 148 / 300: loss 0.581435\n",
      "iteration 148 / 300: loss 0.599604\n",
      "iteration 148 / 300: loss 0.591182\n",
      "iteration 148 / 300: loss 0.599920\n",
      "iteration 148 / 300: loss 0.596015\n",
      "iteration 148 / 300: loss 0.590760\n",
      "iteration 148 / 300: loss 0.591962\n",
      "iteration 148 / 300: loss 0.615468\n",
      "iteration 148 / 300: loss 0.621360\n",
      "iteration 148 / 300: loss 0.587267\n",
      "iteration 148 / 300: loss 0.582483\n",
      "iteration 148 / 300: loss 0.585573\n",
      "iteration 148 / 300: loss 0.603666\n",
      "iteration 148 / 300: loss 0.585193\n",
      "iteration 148 / 300: loss 0.578880\n",
      "iteration 148 / 300: loss 0.576418\n",
      "iteration 148 / 300: loss 0.574097\n",
      "iteration 148 / 300: loss 0.600500\n",
      "iteration 148 / 300: loss 0.584490\n",
      "iteration 148 / 300: loss 0.584834\n",
      "iteration 148 / 300: loss 0.568323\n",
      "iteration 148 / 300: loss 0.592026\n",
      "iteration 148 / 300: loss 0.612116\n",
      "iteration 148 / 300: loss 0.608923\n",
      "iteration 148 / 300: loss 0.607613\n",
      "iteration 148 / 300: loss 0.595534\n",
      "iteration 148 / 300: loss 0.592837\n",
      "iteration 148 / 300: loss 0.597989\n",
      "iteration 148 / 300: loss 0.597677\n",
      "iteration 148 / 300: loss 0.600953\n",
      "iteration 148 / 300: loss 0.597422\n",
      "iteration 148 / 300: loss 0.598776\n",
      "iteration 148 / 300: loss 0.587806\n",
      "iteration 148 / 300: loss 0.600500\n",
      "iteration 148 / 300: loss 0.599650\n",
      "iteration 148 / 300: loss 0.617540\n",
      "iteration 148 / 300: loss 0.598875\n",
      "iteration 148 / 300: loss 0.600801\n",
      "iteration 148 / 300: loss 0.605305\n",
      "iteration 148 / 300: loss 0.598592\n",
      "iteration 148 / 300: loss 0.591474\n",
      "iteration 148 / 300: loss 0.580382\n",
      "iteration 148 / 300: loss 0.598221\n",
      "iteration 148 / 300: loss 0.611685\n",
      "iteration 148 / 300: loss 0.613219\n",
      "iteration 148 / 300: loss 0.582214\n",
      "iteration 148 / 300: loss 0.601955\n",
      "iteration 148 / 300: loss 0.608956\n",
      "iteration 148 / 300: loss 0.601794\n",
      "iteration 148 / 300: loss 0.607945\n",
      "iteration 148 / 300: loss 0.620237\n",
      "iteration 148 / 300: loss 0.584817\n",
      "iteration 148 / 300: loss 0.583721\n",
      "iteration 148 / 300: loss 0.628849\n",
      "iteration 148 / 300: loss 0.609399\n",
      "iteration 148 / 300: loss 0.606265\n",
      "iteration 148 / 300: loss 0.599035\n",
      "iteration 148 / 300: loss 0.615877\n",
      "iteration 148 / 300: loss 0.596489\n",
      "iteration 148 / 300: loss 0.581430\n",
      "iteration 148 / 300: loss 0.609807\n",
      "iteration 148 / 300: loss 0.608126\n",
      "iteration 148 / 300: loss 0.598225\n",
      "iteration 148 / 300: loss 0.592022\n",
      "iteration 148 / 300: loss 0.611031\n",
      "iteration 148 / 300: loss 0.598550\n",
      "iteration 148 / 300: loss 0.581382\n",
      "iteration 148 / 300: loss 0.609580\n",
      "iteration 149 / 300: loss 0.578384\n",
      "iteration 149 / 300: loss 0.596214\n",
      "iteration 149 / 300: loss 0.569455\n",
      "iteration 149 / 300: loss 0.597849\n",
      "iteration 149 / 300: loss 0.598940\n",
      "iteration 149 / 300: loss 0.603876\n",
      "iteration 149 / 300: loss 0.615261\n",
      "iteration 149 / 300: loss 0.588227\n",
      "iteration 149 / 300: loss 0.627172\n",
      "iteration 149 / 300: loss 0.592600\n",
      "iteration 149 / 300: loss 0.621500\n",
      "iteration 149 / 300: loss 0.593094\n",
      "iteration 149 / 300: loss 0.600541\n",
      "iteration 149 / 300: loss 0.571000\n",
      "iteration 149 / 300: loss 0.592911\n",
      "iteration 149 / 300: loss 0.600043\n",
      "iteration 149 / 300: loss 0.598053\n",
      "iteration 149 / 300: loss 0.583712\n",
      "iteration 149 / 300: loss 0.614355\n",
      "iteration 149 / 300: loss 0.591285\n",
      "iteration 149 / 300: loss 0.591391\n",
      "iteration 149 / 300: loss 0.594005\n",
      "iteration 149 / 300: loss 0.596735\n",
      "iteration 149 / 300: loss 0.596712\n",
      "iteration 149 / 300: loss 0.611735\n",
      "iteration 149 / 300: loss 0.607258\n",
      "iteration 149 / 300: loss 0.597032\n",
      "iteration 149 / 300: loss 0.596301\n",
      "iteration 149 / 300: loss 0.627391\n",
      "iteration 149 / 300: loss 0.601584\n",
      "iteration 149 / 300: loss 0.599923\n",
      "iteration 149 / 300: loss 0.621952\n",
      "iteration 149 / 300: loss 0.581435\n",
      "iteration 149 / 300: loss 0.599604\n",
      "iteration 149 / 300: loss 0.591182\n",
      "iteration 149 / 300: loss 0.599920\n",
      "iteration 149 / 300: loss 0.596015\n",
      "iteration 149 / 300: loss 0.590760\n",
      "iteration 149 / 300: loss 0.591961\n",
      "iteration 149 / 300: loss 0.615468\n",
      "iteration 149 / 300: loss 0.621360\n",
      "iteration 149 / 300: loss 0.587267\n",
      "iteration 149 / 300: loss 0.582483\n",
      "iteration 149 / 300: loss 0.585573\n",
      "iteration 149 / 300: loss 0.603666\n",
      "iteration 149 / 300: loss 0.585193\n",
      "iteration 149 / 300: loss 0.578880\n",
      "iteration 149 / 300: loss 0.576418\n",
      "iteration 149 / 300: loss 0.574097\n",
      "iteration 149 / 300: loss 0.600500\n",
      "iteration 149 / 300: loss 0.584490\n",
      "iteration 149 / 300: loss 0.584834\n",
      "iteration 149 / 300: loss 0.568323\n",
      "iteration 149 / 300: loss 0.592026\n",
      "iteration 149 / 300: loss 0.612116\n",
      "iteration 149 / 300: loss 0.608923\n",
      "iteration 149 / 300: loss 0.607613\n",
      "iteration 149 / 300: loss 0.595534\n",
      "iteration 149 / 300: loss 0.592837\n",
      "iteration 149 / 300: loss 0.597989\n",
      "iteration 149 / 300: loss 0.597677\n",
      "iteration 149 / 300: loss 0.600953\n",
      "iteration 149 / 300: loss 0.597422\n",
      "iteration 149 / 300: loss 0.598776\n",
      "iteration 149 / 300: loss 0.587806\n",
      "iteration 149 / 300: loss 0.600500\n",
      "iteration 149 / 300: loss 0.599650\n",
      "iteration 149 / 300: loss 0.617540\n",
      "iteration 149 / 300: loss 0.598875\n",
      "iteration 149 / 300: loss 0.600801\n",
      "iteration 149 / 300: loss 0.605305\n",
      "iteration 149 / 300: loss 0.598592\n",
      "iteration 149 / 300: loss 0.591474\n",
      "iteration 149 / 300: loss 0.580382\n",
      "iteration 149 / 300: loss 0.598221\n",
      "iteration 149 / 300: loss 0.611685\n",
      "iteration 149 / 300: loss 0.613219\n",
      "iteration 149 / 300: loss 0.582214\n",
      "iteration 149 / 300: loss 0.601955\n",
      "iteration 149 / 300: loss 0.608956\n",
      "iteration 149 / 300: loss 0.601794\n",
      "iteration 149 / 300: loss 0.607945\n",
      "iteration 149 / 300: loss 0.620237\n",
      "iteration 149 / 300: loss 0.584817\n",
      "iteration 149 / 300: loss 0.583721\n",
      "iteration 149 / 300: loss 0.628849\n",
      "iteration 149 / 300: loss 0.609399\n",
      "iteration 149 / 300: loss 0.606265\n",
      "iteration 149 / 300: loss 0.599035\n",
      "iteration 149 / 300: loss 0.615877\n",
      "iteration 149 / 300: loss 0.596489\n",
      "iteration 149 / 300: loss 0.581430\n",
      "iteration 149 / 300: loss 0.609807\n",
      "iteration 149 / 300: loss 0.608126\n",
      "iteration 149 / 300: loss 0.598224\n",
      "iteration 149 / 300: loss 0.592022\n",
      "iteration 149 / 300: loss 0.611031\n",
      "iteration 149 / 300: loss 0.598550\n",
      "iteration 149 / 300: loss 0.581382\n",
      "iteration 149 / 300: loss 0.609580\n",
      "iteration 150 / 300: loss 0.578384\n",
      "iteration 150 / 300: loss 0.596214\n",
      "iteration 150 / 300: loss 0.569455\n",
      "iteration 150 / 300: loss 0.597849\n",
      "iteration 150 / 300: loss 0.598940\n",
      "iteration 150 / 300: loss 0.603876\n",
      "iteration 150 / 300: loss 0.615261\n",
      "iteration 150 / 300: loss 0.588227\n",
      "iteration 150 / 300: loss 0.627172\n",
      "iteration 150 / 300: loss 0.592600\n",
      "iteration 150 / 300: loss 0.621500\n",
      "iteration 150 / 300: loss 0.593094\n",
      "iteration 150 / 300: loss 0.600541\n",
      "iteration 150 / 300: loss 0.571000\n",
      "iteration 150 / 300: loss 0.592911\n",
      "iteration 150 / 300: loss 0.600043\n",
      "iteration 150 / 300: loss 0.598053\n",
      "iteration 150 / 300: loss 0.583712\n",
      "iteration 150 / 300: loss 0.614355\n",
      "iteration 150 / 300: loss 0.591285\n",
      "iteration 150 / 300: loss 0.591391\n",
      "iteration 150 / 300: loss 0.594005\n",
      "iteration 150 / 300: loss 0.596735\n",
      "iteration 150 / 300: loss 0.596712\n",
      "iteration 150 / 300: loss 0.611735\n",
      "iteration 150 / 300: loss 0.607258\n",
      "iteration 150 / 300: loss 0.597032\n",
      "iteration 150 / 300: loss 0.596301\n",
      "iteration 150 / 300: loss 0.627391\n",
      "iteration 150 / 300: loss 0.601584\n",
      "iteration 150 / 300: loss 0.599923\n",
      "iteration 150 / 300: loss 0.621952\n",
      "iteration 150 / 300: loss 0.581435\n",
      "iteration 150 / 300: loss 0.599604\n",
      "iteration 150 / 300: loss 0.591182\n",
      "iteration 150 / 300: loss 0.599920\n",
      "iteration 150 / 300: loss 0.596015\n",
      "iteration 150 / 300: loss 0.590760\n",
      "iteration 150 / 300: loss 0.591961\n",
      "iteration 150 / 300: loss 0.615468\n",
      "iteration 150 / 300: loss 0.621360\n",
      "iteration 150 / 300: loss 0.587267\n",
      "iteration 150 / 300: loss 0.582483\n",
      "iteration 150 / 300: loss 0.585572\n",
      "iteration 150 / 300: loss 0.603666\n",
      "iteration 150 / 300: loss 0.585193\n",
      "iteration 150 / 300: loss 0.578880\n",
      "iteration 150 / 300: loss 0.576418\n",
      "iteration 150 / 300: loss 0.574097\n",
      "iteration 150 / 300: loss 0.600500\n",
      "iteration 150 / 300: loss 0.584490\n",
      "iteration 150 / 300: loss 0.584834\n",
      "iteration 150 / 300: loss 0.568323\n",
      "iteration 150 / 300: loss 0.592026\n",
      "iteration 150 / 300: loss 0.612116\n",
      "iteration 150 / 300: loss 0.608923\n",
      "iteration 150 / 300: loss 0.607613\n",
      "iteration 150 / 300: loss 0.595534\n",
      "iteration 150 / 300: loss 0.592837\n",
      "iteration 150 / 300: loss 0.597989\n",
      "iteration 150 / 300: loss 0.597677\n",
      "iteration 150 / 300: loss 0.600953\n",
      "iteration 150 / 300: loss 0.597422\n",
      "iteration 150 / 300: loss 0.598776\n",
      "iteration 150 / 300: loss 0.587806\n",
      "iteration 150 / 300: loss 0.600500\n",
      "iteration 150 / 300: loss 0.599650\n",
      "iteration 150 / 300: loss 0.617540\n",
      "iteration 150 / 300: loss 0.598875\n",
      "iteration 150 / 300: loss 0.600801\n",
      "iteration 150 / 300: loss 0.605305\n",
      "iteration 150 / 300: loss 0.598592\n",
      "iteration 150 / 300: loss 0.591474\n",
      "iteration 150 / 300: loss 0.580382\n",
      "iteration 150 / 300: loss 0.598221\n",
      "iteration 150 / 300: loss 0.611685\n",
      "iteration 150 / 300: loss 0.613219\n",
      "iteration 150 / 300: loss 0.582214\n",
      "iteration 150 / 300: loss 0.601955\n",
      "iteration 150 / 300: loss 0.608956\n",
      "iteration 150 / 300: loss 0.601794\n",
      "iteration 150 / 300: loss 0.607945\n",
      "iteration 150 / 300: loss 0.620237\n",
      "iteration 150 / 300: loss 0.584817\n",
      "iteration 150 / 300: loss 0.583721\n",
      "iteration 150 / 300: loss 0.628849\n",
      "iteration 150 / 300: loss 0.609399\n",
      "iteration 150 / 300: loss 0.606265\n",
      "iteration 150 / 300: loss 0.599035\n",
      "iteration 150 / 300: loss 0.615877\n",
      "iteration 150 / 300: loss 0.596489\n",
      "iteration 150 / 300: loss 0.581430\n",
      "iteration 150 / 300: loss 0.609807\n",
      "iteration 150 / 300: loss 0.608126\n",
      "iteration 150 / 300: loss 0.598224\n",
      "iteration 150 / 300: loss 0.592022\n",
      "iteration 150 / 300: loss 0.611031\n",
      "iteration 150 / 300: loss 0.598550\n",
      "iteration 150 / 300: loss 0.581382\n",
      "iteration 150 / 300: loss 0.609580\n",
      "iteration 151 / 300: loss 0.578384\n",
      "iteration 151 / 300: loss 0.596214\n",
      "iteration 151 / 300: loss 0.569455\n",
      "iteration 151 / 300: loss 0.597849\n",
      "iteration 151 / 300: loss 0.598940\n",
      "iteration 151 / 300: loss 0.603876\n",
      "iteration 151 / 300: loss 0.615261\n",
      "iteration 151 / 300: loss 0.588227\n",
      "iteration 151 / 300: loss 0.627171\n",
      "iteration 151 / 300: loss 0.592600\n",
      "iteration 151 / 300: loss 0.621500\n",
      "iteration 151 / 300: loss 0.593094\n",
      "iteration 151 / 300: loss 0.600541\n",
      "iteration 151 / 300: loss 0.571000\n",
      "iteration 151 / 300: loss 0.592911\n",
      "iteration 151 / 300: loss 0.600043\n",
      "iteration 151 / 300: loss 0.598053\n",
      "iteration 151 / 300: loss 0.583712\n",
      "iteration 151 / 300: loss 0.614355\n",
      "iteration 151 / 300: loss 0.591285\n",
      "iteration 151 / 300: loss 0.591391\n",
      "iteration 151 / 300: loss 0.594005\n",
      "iteration 151 / 300: loss 0.596735\n",
      "iteration 151 / 300: loss 0.596712\n",
      "iteration 151 / 300: loss 0.611735\n",
      "iteration 151 / 300: loss 0.607258\n",
      "iteration 151 / 300: loss 0.597032\n",
      "iteration 151 / 300: loss 0.596301\n",
      "iteration 151 / 300: loss 0.627391\n",
      "iteration 151 / 300: loss 0.601584\n",
      "iteration 151 / 300: loss 0.599923\n",
      "iteration 151 / 300: loss 0.621952\n",
      "iteration 151 / 300: loss 0.581435\n",
      "iteration 151 / 300: loss 0.599604\n",
      "iteration 151 / 300: loss 0.591182\n",
      "iteration 151 / 300: loss 0.599920\n",
      "iteration 151 / 300: loss 0.596015\n",
      "iteration 151 / 300: loss 0.590760\n",
      "iteration 151 / 300: loss 0.591961\n",
      "iteration 151 / 300: loss 0.615468\n",
      "iteration 151 / 300: loss 0.621360\n",
      "iteration 151 / 300: loss 0.587267\n",
      "iteration 151 / 300: loss 0.582483\n",
      "iteration 151 / 300: loss 0.585572\n",
      "iteration 151 / 300: loss 0.603666\n",
      "iteration 151 / 300: loss 0.585193\n",
      "iteration 151 / 300: loss 0.578880\n",
      "iteration 151 / 300: loss 0.576418\n",
      "iteration 151 / 300: loss 0.574097\n",
      "iteration 151 / 300: loss 0.600500\n",
      "iteration 151 / 300: loss 0.584490\n",
      "iteration 151 / 300: loss 0.584834\n",
      "iteration 151 / 300: loss 0.568323\n",
      "iteration 151 / 300: loss 0.592026\n",
      "iteration 151 / 300: loss 0.612116\n",
      "iteration 151 / 300: loss 0.608923\n",
      "iteration 151 / 300: loss 0.607613\n",
      "iteration 151 / 300: loss 0.595534\n",
      "iteration 151 / 300: loss 0.592837\n",
      "iteration 151 / 300: loss 0.597989\n",
      "iteration 151 / 300: loss 0.597677\n",
      "iteration 151 / 300: loss 0.600953\n",
      "iteration 151 / 300: loss 0.597422\n",
      "iteration 151 / 300: loss 0.598776\n",
      "iteration 151 / 300: loss 0.587806\n",
      "iteration 151 / 300: loss 0.600500\n",
      "iteration 151 / 300: loss 0.599650\n",
      "iteration 151 / 300: loss 0.617540\n",
      "iteration 151 / 300: loss 0.598875\n",
      "iteration 151 / 300: loss 0.600801\n",
      "iteration 151 / 300: loss 0.605305\n",
      "iteration 151 / 300: loss 0.598592\n",
      "iteration 151 / 300: loss 0.591474\n",
      "iteration 151 / 300: loss 0.580382\n",
      "iteration 151 / 300: loss 0.598221\n",
      "iteration 151 / 300: loss 0.611685\n",
      "iteration 151 / 300: loss 0.613219\n",
      "iteration 151 / 300: loss 0.582214\n",
      "iteration 151 / 300: loss 0.601955\n",
      "iteration 151 / 300: loss 0.608956\n",
      "iteration 151 / 300: loss 0.601794\n",
      "iteration 151 / 300: loss 0.607944\n",
      "iteration 151 / 300: loss 0.620236\n",
      "iteration 151 / 300: loss 0.584817\n",
      "iteration 151 / 300: loss 0.583721\n",
      "iteration 151 / 300: loss 0.628849\n",
      "iteration 151 / 300: loss 0.609399\n",
      "iteration 151 / 300: loss 0.606265\n",
      "iteration 151 / 300: loss 0.599035\n",
      "iteration 151 / 300: loss 0.615877\n",
      "iteration 151 / 300: loss 0.596489\n",
      "iteration 151 / 300: loss 0.581430\n",
      "iteration 151 / 300: loss 0.609807\n",
      "iteration 151 / 300: loss 0.608126\n",
      "iteration 151 / 300: loss 0.598224\n",
      "iteration 151 / 300: loss 0.592022\n",
      "iteration 151 / 300: loss 0.611031\n",
      "iteration 151 / 300: loss 0.598550\n",
      "iteration 151 / 300: loss 0.581382\n",
      "iteration 151 / 300: loss 0.609580\n",
      "iteration 152 / 300: loss 0.578384\n",
      "iteration 152 / 300: loss 0.596214\n",
      "iteration 152 / 300: loss 0.569455\n",
      "iteration 152 / 300: loss 0.597849\n",
      "iteration 152 / 300: loss 0.598940\n",
      "iteration 152 / 300: loss 0.603876\n",
      "iteration 152 / 300: loss 0.615261\n",
      "iteration 152 / 300: loss 0.588227\n",
      "iteration 152 / 300: loss 0.627171\n",
      "iteration 152 / 300: loss 0.592600\n",
      "iteration 152 / 300: loss 0.621500\n",
      "iteration 152 / 300: loss 0.593094\n",
      "iteration 152 / 300: loss 0.600541\n",
      "iteration 152 / 300: loss 0.571000\n",
      "iteration 152 / 300: loss 0.592911\n",
      "iteration 152 / 300: loss 0.600043\n",
      "iteration 152 / 300: loss 0.598053\n",
      "iteration 152 / 300: loss 0.583712\n",
      "iteration 152 / 300: loss 0.614355\n",
      "iteration 152 / 300: loss 0.591285\n",
      "iteration 152 / 300: loss 0.591391\n",
      "iteration 152 / 300: loss 0.594005\n",
      "iteration 152 / 300: loss 0.596735\n",
      "iteration 152 / 300: loss 0.596712\n",
      "iteration 152 / 300: loss 0.611735\n",
      "iteration 152 / 300: loss 0.607258\n",
      "iteration 152 / 300: loss 0.597032\n",
      "iteration 152 / 300: loss 0.596301\n",
      "iteration 152 / 300: loss 0.627391\n",
      "iteration 152 / 300: loss 0.601584\n",
      "iteration 152 / 300: loss 0.599923\n",
      "iteration 152 / 300: loss 0.621952\n",
      "iteration 152 / 300: loss 0.581435\n",
      "iteration 152 / 300: loss 0.599604\n",
      "iteration 152 / 300: loss 0.591182\n",
      "iteration 152 / 300: loss 0.599920\n",
      "iteration 152 / 300: loss 0.596015\n",
      "iteration 152 / 300: loss 0.590760\n",
      "iteration 152 / 300: loss 0.591961\n",
      "iteration 152 / 300: loss 0.615468\n",
      "iteration 152 / 300: loss 0.621360\n",
      "iteration 152 / 300: loss 0.587267\n",
      "iteration 152 / 300: loss 0.582483\n",
      "iteration 152 / 300: loss 0.585572\n",
      "iteration 152 / 300: loss 0.603666\n",
      "iteration 152 / 300: loss 0.585192\n",
      "iteration 152 / 300: loss 0.578880\n",
      "iteration 152 / 300: loss 0.576418\n",
      "iteration 152 / 300: loss 0.574097\n",
      "iteration 152 / 300: loss 0.600500\n",
      "iteration 152 / 300: loss 0.584490\n",
      "iteration 152 / 300: loss 0.584834\n",
      "iteration 152 / 300: loss 0.568323\n",
      "iteration 152 / 300: loss 0.592026\n",
      "iteration 152 / 300: loss 0.612116\n",
      "iteration 152 / 300: loss 0.608923\n",
      "iteration 152 / 300: loss 0.607613\n",
      "iteration 152 / 300: loss 0.595534\n",
      "iteration 152 / 300: loss 0.592837\n",
      "iteration 152 / 300: loss 0.597988\n",
      "iteration 152 / 300: loss 0.597677\n",
      "iteration 152 / 300: loss 0.600953\n",
      "iteration 152 / 300: loss 0.597422\n",
      "iteration 152 / 300: loss 0.598776\n",
      "iteration 152 / 300: loss 0.587806\n",
      "iteration 152 / 300: loss 0.600499\n",
      "iteration 152 / 300: loss 0.599650\n",
      "iteration 152 / 300: loss 0.617540\n",
      "iteration 152 / 300: loss 0.598875\n",
      "iteration 152 / 300: loss 0.600801\n",
      "iteration 152 / 300: loss 0.605305\n",
      "iteration 152 / 300: loss 0.598592\n",
      "iteration 152 / 300: loss 0.591474\n",
      "iteration 152 / 300: loss 0.580382\n",
      "iteration 152 / 300: loss 0.598221\n",
      "iteration 152 / 300: loss 0.611685\n",
      "iteration 152 / 300: loss 0.613219\n",
      "iteration 152 / 300: loss 0.582214\n",
      "iteration 152 / 300: loss 0.601955\n",
      "iteration 152 / 300: loss 0.608956\n",
      "iteration 152 / 300: loss 0.601794\n",
      "iteration 152 / 300: loss 0.607944\n",
      "iteration 152 / 300: loss 0.620236\n",
      "iteration 152 / 300: loss 0.584817\n",
      "iteration 152 / 300: loss 0.583721\n",
      "iteration 152 / 300: loss 0.628849\n",
      "iteration 152 / 300: loss 0.609399\n",
      "iteration 152 / 300: loss 0.606265\n",
      "iteration 152 / 300: loss 0.599034\n",
      "iteration 152 / 300: loss 0.615877\n",
      "iteration 152 / 300: loss 0.596489\n",
      "iteration 152 / 300: loss 0.581430\n",
      "iteration 152 / 300: loss 0.609807\n",
      "iteration 152 / 300: loss 0.608126\n",
      "iteration 152 / 300: loss 0.598224\n",
      "iteration 152 / 300: loss 0.592022\n",
      "iteration 152 / 300: loss 0.611031\n",
      "iteration 152 / 300: loss 0.598550\n",
      "iteration 152 / 300: loss 0.581382\n",
      "iteration 152 / 300: loss 0.609580\n",
      "iteration 153 / 300: loss 0.578384\n",
      "iteration 153 / 300: loss 0.596214\n",
      "iteration 153 / 300: loss 0.569455\n",
      "iteration 153 / 300: loss 0.597849\n",
      "iteration 153 / 300: loss 0.598940\n",
      "iteration 153 / 300: loss 0.603876\n",
      "iteration 153 / 300: loss 0.615261\n",
      "iteration 153 / 300: loss 0.588227\n",
      "iteration 153 / 300: loss 0.627171\n",
      "iteration 153 / 300: loss 0.592600\n",
      "iteration 153 / 300: loss 0.621500\n",
      "iteration 153 / 300: loss 0.593094\n",
      "iteration 153 / 300: loss 0.600541\n",
      "iteration 153 / 300: loss 0.571000\n",
      "iteration 153 / 300: loss 0.592911\n",
      "iteration 153 / 300: loss 0.600043\n",
      "iteration 153 / 300: loss 0.598053\n",
      "iteration 153 / 300: loss 0.583712\n",
      "iteration 153 / 300: loss 0.614355\n",
      "iteration 153 / 300: loss 0.591285\n",
      "iteration 153 / 300: loss 0.591391\n",
      "iteration 153 / 300: loss 0.594005\n",
      "iteration 153 / 300: loss 0.596735\n",
      "iteration 153 / 300: loss 0.596712\n",
      "iteration 153 / 300: loss 0.611735\n",
      "iteration 153 / 300: loss 0.607258\n",
      "iteration 153 / 300: loss 0.597032\n",
      "iteration 153 / 300: loss 0.596301\n",
      "iteration 153 / 300: loss 0.627391\n",
      "iteration 153 / 300: loss 0.601584\n",
      "iteration 153 / 300: loss 0.599923\n",
      "iteration 153 / 300: loss 0.621952\n",
      "iteration 153 / 300: loss 0.581435\n",
      "iteration 153 / 300: loss 0.599604\n",
      "iteration 153 / 300: loss 0.591182\n",
      "iteration 153 / 300: loss 0.599920\n",
      "iteration 153 / 300: loss 0.596015\n",
      "iteration 153 / 300: loss 0.590760\n",
      "iteration 153 / 300: loss 0.591961\n",
      "iteration 153 / 300: loss 0.615468\n",
      "iteration 153 / 300: loss 0.621360\n",
      "iteration 153 / 300: loss 0.587267\n",
      "iteration 153 / 300: loss 0.582483\n",
      "iteration 153 / 300: loss 0.585572\n",
      "iteration 153 / 300: loss 0.603666\n",
      "iteration 153 / 300: loss 0.585192\n",
      "iteration 153 / 300: loss 0.578880\n",
      "iteration 153 / 300: loss 0.576418\n",
      "iteration 153 / 300: loss 0.574097\n",
      "iteration 153 / 300: loss 0.600500\n",
      "iteration 153 / 300: loss 0.584490\n",
      "iteration 153 / 300: loss 0.584834\n",
      "iteration 153 / 300: loss 0.568323\n",
      "iteration 153 / 300: loss 0.592026\n",
      "iteration 153 / 300: loss 0.612116\n",
      "iteration 153 / 300: loss 0.608923\n",
      "iteration 153 / 300: loss 0.607613\n",
      "iteration 153 / 300: loss 0.595533\n",
      "iteration 153 / 300: loss 0.592837\n",
      "iteration 153 / 300: loss 0.597988\n",
      "iteration 153 / 300: loss 0.597677\n",
      "iteration 153 / 300: loss 0.600953\n",
      "iteration 153 / 300: loss 0.597422\n",
      "iteration 153 / 300: loss 0.598776\n",
      "iteration 153 / 300: loss 0.587806\n",
      "iteration 153 / 300: loss 0.600499\n",
      "iteration 153 / 300: loss 0.599650\n",
      "iteration 153 / 300: loss 0.617540\n",
      "iteration 153 / 300: loss 0.598875\n",
      "iteration 153 / 300: loss 0.600801\n",
      "iteration 153 / 300: loss 0.605305\n",
      "iteration 153 / 300: loss 0.598592\n",
      "iteration 153 / 300: loss 0.591474\n",
      "iteration 153 / 300: loss 0.580382\n",
      "iteration 153 / 300: loss 0.598221\n",
      "iteration 153 / 300: loss 0.611685\n",
      "iteration 153 / 300: loss 0.613219\n",
      "iteration 153 / 300: loss 0.582214\n",
      "iteration 153 / 300: loss 0.601955\n",
      "iteration 153 / 300: loss 0.608956\n",
      "iteration 153 / 300: loss 0.601794\n",
      "iteration 153 / 300: loss 0.607944\n",
      "iteration 153 / 300: loss 0.620236\n",
      "iteration 153 / 300: loss 0.584817\n",
      "iteration 153 / 300: loss 0.583721\n",
      "iteration 153 / 300: loss 0.628849\n",
      "iteration 153 / 300: loss 0.609399\n",
      "iteration 153 / 300: loss 0.606265\n",
      "iteration 153 / 300: loss 0.599034\n",
      "iteration 153 / 300: loss 0.615877\n",
      "iteration 153 / 300: loss 0.596489\n",
      "iteration 153 / 300: loss 0.581430\n",
      "iteration 153 / 300: loss 0.609807\n",
      "iteration 153 / 300: loss 0.608126\n",
      "iteration 153 / 300: loss 0.598224\n",
      "iteration 153 / 300: loss 0.592022\n",
      "iteration 153 / 300: loss 0.611031\n",
      "iteration 153 / 300: loss 0.598550\n",
      "iteration 153 / 300: loss 0.581382\n",
      "iteration 153 / 300: loss 0.609580\n",
      "iteration 154 / 300: loss 0.578384\n",
      "iteration 154 / 300: loss 0.596214\n",
      "iteration 154 / 300: loss 0.569455\n",
      "iteration 154 / 300: loss 0.597849\n",
      "iteration 154 / 300: loss 0.598940\n",
      "iteration 154 / 300: loss 0.603876\n",
      "iteration 154 / 300: loss 0.615261\n",
      "iteration 154 / 300: loss 0.588227\n",
      "iteration 154 / 300: loss 0.627171\n",
      "iteration 154 / 300: loss 0.592600\n",
      "iteration 154 / 300: loss 0.621500\n",
      "iteration 154 / 300: loss 0.593094\n",
      "iteration 154 / 300: loss 0.600541\n",
      "iteration 154 / 300: loss 0.571000\n",
      "iteration 154 / 300: loss 0.592911\n",
      "iteration 154 / 300: loss 0.600043\n",
      "iteration 154 / 300: loss 0.598053\n",
      "iteration 154 / 300: loss 0.583712\n",
      "iteration 154 / 300: loss 0.614355\n",
      "iteration 154 / 300: loss 0.591285\n",
      "iteration 154 / 300: loss 0.591391\n",
      "iteration 154 / 300: loss 0.594005\n",
      "iteration 154 / 300: loss 0.596735\n",
      "iteration 154 / 300: loss 0.596712\n",
      "iteration 154 / 300: loss 0.611735\n",
      "iteration 154 / 300: loss 0.607258\n",
      "iteration 154 / 300: loss 0.597032\n",
      "iteration 154 / 300: loss 0.596301\n",
      "iteration 154 / 300: loss 0.627391\n",
      "iteration 154 / 300: loss 0.601584\n",
      "iteration 154 / 300: loss 0.599923\n",
      "iteration 154 / 300: loss 0.621952\n",
      "iteration 154 / 300: loss 0.581435\n",
      "iteration 154 / 300: loss 0.599604\n",
      "iteration 154 / 300: loss 0.591182\n",
      "iteration 154 / 300: loss 0.599920\n",
      "iteration 154 / 300: loss 0.596015\n",
      "iteration 154 / 300: loss 0.590760\n",
      "iteration 154 / 300: loss 0.591961\n",
      "iteration 154 / 300: loss 0.615468\n",
      "iteration 154 / 300: loss 0.621360\n",
      "iteration 154 / 300: loss 0.587267\n",
      "iteration 154 / 300: loss 0.582483\n",
      "iteration 154 / 300: loss 0.585572\n",
      "iteration 154 / 300: loss 0.603666\n",
      "iteration 154 / 300: loss 0.585192\n",
      "iteration 154 / 300: loss 0.578880\n",
      "iteration 154 / 300: loss 0.576418\n",
      "iteration 154 / 300: loss 0.574097\n",
      "iteration 154 / 300: loss 0.600500\n",
      "iteration 154 / 300: loss 0.584490\n",
      "iteration 154 / 300: loss 0.584834\n",
      "iteration 154 / 300: loss 0.568323\n",
      "iteration 154 / 300: loss 0.592025\n",
      "iteration 154 / 300: loss 0.612116\n",
      "iteration 154 / 300: loss 0.608923\n",
      "iteration 154 / 300: loss 0.607613\n",
      "iteration 154 / 300: loss 0.595533\n",
      "iteration 154 / 300: loss 0.592837\n",
      "iteration 154 / 300: loss 0.597988\n",
      "iteration 154 / 300: loss 0.597677\n",
      "iteration 154 / 300: loss 0.600953\n",
      "iteration 154 / 300: loss 0.597422\n",
      "iteration 154 / 300: loss 0.598776\n",
      "iteration 154 / 300: loss 0.587806\n",
      "iteration 154 / 300: loss 0.600499\n",
      "iteration 154 / 300: loss 0.599650\n",
      "iteration 154 / 300: loss 0.617540\n",
      "iteration 154 / 300: loss 0.598875\n",
      "iteration 154 / 300: loss 0.600801\n",
      "iteration 154 / 300: loss 0.605305\n",
      "iteration 154 / 300: loss 0.598592\n",
      "iteration 154 / 300: loss 0.591474\n",
      "iteration 154 / 300: loss 0.580382\n",
      "iteration 154 / 300: loss 0.598221\n",
      "iteration 154 / 300: loss 0.611685\n",
      "iteration 154 / 300: loss 0.613219\n",
      "iteration 154 / 300: loss 0.582214\n",
      "iteration 154 / 300: loss 0.601955\n",
      "iteration 154 / 300: loss 0.608956\n",
      "iteration 154 / 300: loss 0.601794\n",
      "iteration 154 / 300: loss 0.607944\n",
      "iteration 154 / 300: loss 0.620236\n",
      "iteration 154 / 300: loss 0.584817\n",
      "iteration 154 / 300: loss 0.583721\n",
      "iteration 154 / 300: loss 0.628849\n",
      "iteration 154 / 300: loss 0.609399\n",
      "iteration 154 / 300: loss 0.606265\n",
      "iteration 154 / 300: loss 0.599034\n",
      "iteration 154 / 300: loss 0.615877\n",
      "iteration 154 / 300: loss 0.596489\n",
      "iteration 154 / 300: loss 0.581430\n",
      "iteration 154 / 300: loss 0.609807\n",
      "iteration 154 / 300: loss 0.608126\n",
      "iteration 154 / 300: loss 0.598224\n",
      "iteration 154 / 300: loss 0.592022\n",
      "iteration 154 / 300: loss 0.611031\n",
      "iteration 154 / 300: loss 0.598550\n",
      "iteration 154 / 300: loss 0.581382\n",
      "iteration 154 / 300: loss 0.609580\n",
      "iteration 155 / 300: loss 0.578384\n",
      "iteration 155 / 300: loss 0.596214\n",
      "iteration 155 / 300: loss 0.569455\n",
      "iteration 155 / 300: loss 0.597849\n",
      "iteration 155 / 300: loss 0.598940\n",
      "iteration 155 / 300: loss 0.603876\n",
      "iteration 155 / 300: loss 0.615261\n",
      "iteration 155 / 300: loss 0.588227\n",
      "iteration 155 / 300: loss 0.627171\n",
      "iteration 155 / 300: loss 0.592600\n",
      "iteration 155 / 300: loss 0.621500\n",
      "iteration 155 / 300: loss 0.593094\n",
      "iteration 155 / 300: loss 0.600541\n",
      "iteration 155 / 300: loss 0.571000\n",
      "iteration 155 / 300: loss 0.592911\n",
      "iteration 155 / 300: loss 0.600043\n",
      "iteration 155 / 300: loss 0.598053\n",
      "iteration 155 / 300: loss 0.583712\n",
      "iteration 155 / 300: loss 0.614355\n",
      "iteration 155 / 300: loss 0.591285\n",
      "iteration 155 / 300: loss 0.591391\n",
      "iteration 155 / 300: loss 0.594005\n",
      "iteration 155 / 300: loss 0.596735\n",
      "iteration 155 / 300: loss 0.596712\n",
      "iteration 155 / 300: loss 0.611735\n",
      "iteration 155 / 300: loss 0.607258\n",
      "iteration 155 / 300: loss 0.597032\n",
      "iteration 155 / 300: loss 0.596301\n",
      "iteration 155 / 300: loss 0.627391\n",
      "iteration 155 / 300: loss 0.601584\n",
      "iteration 155 / 300: loss 0.599923\n",
      "iteration 155 / 300: loss 0.621952\n",
      "iteration 155 / 300: loss 0.581435\n",
      "iteration 155 / 300: loss 0.599604\n",
      "iteration 155 / 300: loss 0.591182\n",
      "iteration 155 / 300: loss 0.599920\n",
      "iteration 155 / 300: loss 0.596015\n",
      "iteration 155 / 300: loss 0.590760\n",
      "iteration 155 / 300: loss 0.591961\n",
      "iteration 155 / 300: loss 0.615468\n",
      "iteration 155 / 300: loss 0.621360\n",
      "iteration 155 / 300: loss 0.587267\n",
      "iteration 155 / 300: loss 0.582483\n",
      "iteration 155 / 300: loss 0.585572\n",
      "iteration 155 / 300: loss 0.603666\n",
      "iteration 155 / 300: loss 0.585192\n",
      "iteration 155 / 300: loss 0.578880\n",
      "iteration 155 / 300: loss 0.576418\n",
      "iteration 155 / 300: loss 0.574097\n",
      "iteration 155 / 300: loss 0.600500\n",
      "iteration 155 / 300: loss 0.584490\n",
      "iteration 155 / 300: loss 0.584834\n",
      "iteration 155 / 300: loss 0.568323\n",
      "iteration 155 / 300: loss 0.592025\n",
      "iteration 155 / 300: loss 0.612116\n",
      "iteration 155 / 300: loss 0.608923\n",
      "iteration 155 / 300: loss 0.607613\n",
      "iteration 155 / 300: loss 0.595533\n",
      "iteration 155 / 300: loss 0.592837\n",
      "iteration 155 / 300: loss 0.597988\n",
      "iteration 155 / 300: loss 0.597677\n",
      "iteration 155 / 300: loss 0.600953\n",
      "iteration 155 / 300: loss 0.597422\n",
      "iteration 155 / 300: loss 0.598776\n",
      "iteration 155 / 300: loss 0.587806\n",
      "iteration 155 / 300: loss 0.600499\n",
      "iteration 155 / 300: loss 0.599650\n",
      "iteration 155 / 300: loss 0.617540\n",
      "iteration 155 / 300: loss 0.598875\n",
      "iteration 155 / 300: loss 0.600801\n",
      "iteration 155 / 300: loss 0.605305\n",
      "iteration 155 / 300: loss 0.598592\n",
      "iteration 155 / 300: loss 0.591474\n",
      "iteration 155 / 300: loss 0.580382\n",
      "iteration 155 / 300: loss 0.598221\n",
      "iteration 155 / 300: loss 0.611685\n",
      "iteration 155 / 300: loss 0.613219\n",
      "iteration 155 / 300: loss 0.582214\n",
      "iteration 155 / 300: loss 0.601955\n",
      "iteration 155 / 300: loss 0.608956\n",
      "iteration 155 / 300: loss 0.601794\n",
      "iteration 155 / 300: loss 0.607944\n",
      "iteration 155 / 300: loss 0.620236\n",
      "iteration 155 / 300: loss 0.584817\n",
      "iteration 155 / 300: loss 0.583721\n",
      "iteration 155 / 300: loss 0.628849\n",
      "iteration 155 / 300: loss 0.609399\n",
      "iteration 155 / 300: loss 0.606265\n",
      "iteration 155 / 300: loss 0.599034\n",
      "iteration 155 / 300: loss 0.615877\n",
      "iteration 155 / 300: loss 0.596489\n",
      "iteration 155 / 300: loss 0.581430\n",
      "iteration 155 / 300: loss 0.609807\n",
      "iteration 155 / 300: loss 0.608125\n",
      "iteration 155 / 300: loss 0.598224\n",
      "iteration 155 / 300: loss 0.592022\n",
      "iteration 155 / 300: loss 0.611031\n",
      "iteration 155 / 300: loss 0.598550\n",
      "iteration 155 / 300: loss 0.581382\n",
      "iteration 155 / 300: loss 0.609580\n",
      "iteration 156 / 300: loss 0.578384\n",
      "iteration 156 / 300: loss 0.596214\n",
      "iteration 156 / 300: loss 0.569455\n",
      "iteration 156 / 300: loss 0.597849\n",
      "iteration 156 / 300: loss 0.598940\n",
      "iteration 156 / 300: loss 0.603876\n",
      "iteration 156 / 300: loss 0.615261\n",
      "iteration 156 / 300: loss 0.588227\n",
      "iteration 156 / 300: loss 0.627171\n",
      "iteration 156 / 300: loss 0.592600\n",
      "iteration 156 / 300: loss 0.621500\n",
      "iteration 156 / 300: loss 0.593094\n",
      "iteration 156 / 300: loss 0.600541\n",
      "iteration 156 / 300: loss 0.571000\n",
      "iteration 156 / 300: loss 0.592911\n",
      "iteration 156 / 300: loss 0.600043\n",
      "iteration 156 / 300: loss 0.598053\n",
      "iteration 156 / 300: loss 0.583712\n",
      "iteration 156 / 300: loss 0.614355\n",
      "iteration 156 / 300: loss 0.591285\n",
      "iteration 156 / 300: loss 0.591391\n",
      "iteration 156 / 300: loss 0.594005\n",
      "iteration 156 / 300: loss 0.596735\n",
      "iteration 156 / 300: loss 0.596712\n",
      "iteration 156 / 300: loss 0.611735\n",
      "iteration 156 / 300: loss 0.607258\n",
      "iteration 156 / 300: loss 0.597032\n",
      "iteration 156 / 300: loss 0.596301\n",
      "iteration 156 / 300: loss 0.627391\n",
      "iteration 156 / 300: loss 0.601584\n",
      "iteration 156 / 300: loss 0.599923\n",
      "iteration 156 / 300: loss 0.621952\n",
      "iteration 156 / 300: loss 0.581435\n",
      "iteration 156 / 300: loss 0.599604\n",
      "iteration 156 / 300: loss 0.591182\n",
      "iteration 156 / 300: loss 0.599920\n",
      "iteration 156 / 300: loss 0.596015\n",
      "iteration 156 / 300: loss 0.590760\n",
      "iteration 156 / 300: loss 0.591961\n",
      "iteration 156 / 300: loss 0.615468\n",
      "iteration 156 / 300: loss 0.621360\n",
      "iteration 156 / 300: loss 0.587267\n",
      "iteration 156 / 300: loss 0.582483\n",
      "iteration 156 / 300: loss 0.585572\n",
      "iteration 156 / 300: loss 0.603666\n",
      "iteration 156 / 300: loss 0.585192\n",
      "iteration 156 / 300: loss 0.578880\n",
      "iteration 156 / 300: loss 0.576418\n",
      "iteration 156 / 300: loss 0.574097\n",
      "iteration 156 / 300: loss 0.600500\n",
      "iteration 156 / 300: loss 0.584490\n",
      "iteration 156 / 300: loss 0.584834\n",
      "iteration 156 / 300: loss 0.568323\n",
      "iteration 156 / 300: loss 0.592025\n",
      "iteration 156 / 300: loss 0.612116\n",
      "iteration 156 / 300: loss 0.608923\n",
      "iteration 156 / 300: loss 0.607613\n",
      "iteration 156 / 300: loss 0.595533\n",
      "iteration 156 / 300: loss 0.592837\n",
      "iteration 156 / 300: loss 0.597988\n",
      "iteration 156 / 300: loss 0.597677\n",
      "iteration 156 / 300: loss 0.600953\n",
      "iteration 156 / 300: loss 0.597422\n",
      "iteration 156 / 300: loss 0.598776\n",
      "iteration 156 / 300: loss 0.587806\n",
      "iteration 156 / 300: loss 0.600499\n",
      "iteration 156 / 300: loss 0.599650\n",
      "iteration 156 / 300: loss 0.617540\n",
      "iteration 156 / 300: loss 0.598875\n",
      "iteration 156 / 300: loss 0.600801\n",
      "iteration 156 / 300: loss 0.605305\n",
      "iteration 156 / 300: loss 0.598592\n",
      "iteration 156 / 300: loss 0.591474\n",
      "iteration 156 / 300: loss 0.580382\n",
      "iteration 156 / 300: loss 0.598221\n",
      "iteration 156 / 300: loss 0.611685\n",
      "iteration 156 / 300: loss 0.613219\n",
      "iteration 156 / 300: loss 0.582214\n",
      "iteration 156 / 300: loss 0.601955\n",
      "iteration 156 / 300: loss 0.608956\n",
      "iteration 156 / 300: loss 0.601794\n",
      "iteration 156 / 300: loss 0.607944\n",
      "iteration 156 / 300: loss 0.620236\n",
      "iteration 156 / 300: loss 0.584817\n",
      "iteration 156 / 300: loss 0.583721\n",
      "iteration 156 / 300: loss 0.628849\n",
      "iteration 156 / 300: loss 0.609399\n",
      "iteration 156 / 300: loss 0.606265\n",
      "iteration 156 / 300: loss 0.599034\n",
      "iteration 156 / 300: loss 0.615877\n",
      "iteration 156 / 300: loss 0.596489\n",
      "iteration 156 / 300: loss 0.581430\n",
      "iteration 156 / 300: loss 0.609807\n",
      "iteration 156 / 300: loss 0.608125\n",
      "iteration 156 / 300: loss 0.598224\n",
      "iteration 156 / 300: loss 0.592022\n",
      "iteration 156 / 300: loss 0.611031\n",
      "iteration 156 / 300: loss 0.598550\n",
      "iteration 156 / 300: loss 0.581382\n",
      "iteration 156 / 300: loss 0.609580\n",
      "iteration 157 / 300: loss 0.578384\n",
      "iteration 157 / 300: loss 0.596214\n",
      "iteration 157 / 300: loss 0.569455\n",
      "iteration 157 / 300: loss 0.597849\n",
      "iteration 157 / 300: loss 0.598940\n",
      "iteration 157 / 300: loss 0.603876\n",
      "iteration 157 / 300: loss 0.615261\n",
      "iteration 157 / 300: loss 0.588227\n",
      "iteration 157 / 300: loss 0.627171\n",
      "iteration 157 / 300: loss 0.592600\n",
      "iteration 157 / 300: loss 0.621500\n",
      "iteration 157 / 300: loss 0.593094\n",
      "iteration 157 / 300: loss 0.600541\n",
      "iteration 157 / 300: loss 0.571000\n",
      "iteration 157 / 300: loss 0.592911\n",
      "iteration 157 / 300: loss 0.600043\n",
      "iteration 157 / 300: loss 0.598053\n",
      "iteration 157 / 300: loss 0.583712\n",
      "iteration 157 / 300: loss 0.614355\n",
      "iteration 157 / 300: loss 0.591285\n",
      "iteration 157 / 300: loss 0.591391\n",
      "iteration 157 / 300: loss 0.594005\n",
      "iteration 157 / 300: loss 0.596735\n",
      "iteration 157 / 300: loss 0.596712\n",
      "iteration 157 / 300: loss 0.611735\n",
      "iteration 157 / 300: loss 0.607258\n",
      "iteration 157 / 300: loss 0.597032\n",
      "iteration 157 / 300: loss 0.596301\n",
      "iteration 157 / 300: loss 0.627391\n",
      "iteration 157 / 300: loss 0.601584\n",
      "iteration 157 / 300: loss 0.599923\n",
      "iteration 157 / 300: loss 0.621952\n",
      "iteration 157 / 300: loss 0.581435\n",
      "iteration 157 / 300: loss 0.599604\n",
      "iteration 157 / 300: loss 0.591182\n",
      "iteration 157 / 300: loss 0.599920\n",
      "iteration 157 / 300: loss 0.596015\n",
      "iteration 157 / 300: loss 0.590760\n",
      "iteration 157 / 300: loss 0.591961\n",
      "iteration 157 / 300: loss 0.615468\n",
      "iteration 157 / 300: loss 0.621360\n",
      "iteration 157 / 300: loss 0.587267\n",
      "iteration 157 / 300: loss 0.582483\n",
      "iteration 157 / 300: loss 0.585572\n",
      "iteration 157 / 300: loss 0.603666\n",
      "iteration 157 / 300: loss 0.585192\n",
      "iteration 157 / 300: loss 0.578880\n",
      "iteration 157 / 300: loss 0.576418\n",
      "iteration 157 / 300: loss 0.574097\n",
      "iteration 157 / 300: loss 0.600500\n",
      "iteration 157 / 300: loss 0.584490\n",
      "iteration 157 / 300: loss 0.584834\n",
      "iteration 157 / 300: loss 0.568323\n",
      "iteration 157 / 300: loss 0.592025\n",
      "iteration 157 / 300: loss 0.612116\n",
      "iteration 157 / 300: loss 0.608923\n",
      "iteration 157 / 300: loss 0.607613\n",
      "iteration 157 / 300: loss 0.595533\n",
      "iteration 157 / 300: loss 0.592837\n",
      "iteration 157 / 300: loss 0.597988\n",
      "iteration 157 / 300: loss 0.597677\n",
      "iteration 157 / 300: loss 0.600953\n",
      "iteration 157 / 300: loss 0.597422\n",
      "iteration 157 / 300: loss 0.598776\n",
      "iteration 157 / 300: loss 0.587806\n",
      "iteration 157 / 300: loss 0.600499\n",
      "iteration 157 / 300: loss 0.599650\n",
      "iteration 157 / 300: loss 0.617540\n",
      "iteration 157 / 300: loss 0.598875\n",
      "iteration 157 / 300: loss 0.600801\n",
      "iteration 157 / 300: loss 0.605305\n",
      "iteration 157 / 300: loss 0.598592\n",
      "iteration 157 / 300: loss 0.591474\n",
      "iteration 157 / 300: loss 0.580382\n",
      "iteration 157 / 300: loss 0.598221\n",
      "iteration 157 / 300: loss 0.611685\n",
      "iteration 157 / 300: loss 0.613219\n",
      "iteration 157 / 300: loss 0.582214\n",
      "iteration 157 / 300: loss 0.601955\n",
      "iteration 157 / 300: loss 0.608956\n",
      "iteration 157 / 300: loss 0.601794\n",
      "iteration 157 / 300: loss 0.607944\n",
      "iteration 157 / 300: loss 0.620236\n",
      "iteration 157 / 300: loss 0.584817\n",
      "iteration 157 / 300: loss 0.583721\n",
      "iteration 157 / 300: loss 0.628849\n",
      "iteration 157 / 300: loss 0.609399\n",
      "iteration 157 / 300: loss 0.606265\n",
      "iteration 157 / 300: loss 0.599034\n",
      "iteration 157 / 300: loss 0.615877\n",
      "iteration 157 / 300: loss 0.596489\n",
      "iteration 157 / 300: loss 0.581430\n",
      "iteration 157 / 300: loss 0.609807\n",
      "iteration 157 / 300: loss 0.608125\n",
      "iteration 157 / 300: loss 0.598224\n",
      "iteration 157 / 300: loss 0.592022\n",
      "iteration 157 / 300: loss 0.611031\n",
      "iteration 157 / 300: loss 0.598550\n",
      "iteration 157 / 300: loss 0.581382\n",
      "iteration 157 / 300: loss 0.609580\n",
      "iteration 158 / 300: loss 0.578384\n",
      "iteration 158 / 300: loss 0.596214\n",
      "iteration 158 / 300: loss 0.569455\n",
      "iteration 158 / 300: loss 0.597849\n",
      "iteration 158 / 300: loss 0.598940\n",
      "iteration 158 / 300: loss 0.603876\n",
      "iteration 158 / 300: loss 0.615261\n",
      "iteration 158 / 300: loss 0.588227\n",
      "iteration 158 / 300: loss 0.627171\n",
      "iteration 158 / 300: loss 0.592600\n",
      "iteration 158 / 300: loss 0.621500\n",
      "iteration 158 / 300: loss 0.593094\n",
      "iteration 158 / 300: loss 0.600541\n",
      "iteration 158 / 300: loss 0.571000\n",
      "iteration 158 / 300: loss 0.592911\n",
      "iteration 158 / 300: loss 0.600043\n",
      "iteration 158 / 300: loss 0.598053\n",
      "iteration 158 / 300: loss 0.583712\n",
      "iteration 158 / 300: loss 0.614355\n",
      "iteration 158 / 300: loss 0.591285\n",
      "iteration 158 / 300: loss 0.591391\n",
      "iteration 158 / 300: loss 0.594005\n",
      "iteration 158 / 300: loss 0.596735\n",
      "iteration 158 / 300: loss 0.596712\n",
      "iteration 158 / 300: loss 0.611735\n",
      "iteration 158 / 300: loss 0.607258\n",
      "iteration 158 / 300: loss 0.597032\n",
      "iteration 158 / 300: loss 0.596301\n",
      "iteration 158 / 300: loss 0.627391\n",
      "iteration 158 / 300: loss 0.601584\n",
      "iteration 158 / 300: loss 0.599923\n",
      "iteration 158 / 300: loss 0.621952\n",
      "iteration 158 / 300: loss 0.581435\n",
      "iteration 158 / 300: loss 0.599604\n",
      "iteration 158 / 300: loss 0.591182\n",
      "iteration 158 / 300: loss 0.599920\n",
      "iteration 158 / 300: loss 0.596015\n",
      "iteration 158 / 300: loss 0.590760\n",
      "iteration 158 / 300: loss 0.591961\n",
      "iteration 158 / 300: loss 0.615468\n",
      "iteration 158 / 300: loss 0.621360\n",
      "iteration 158 / 300: loss 0.587267\n",
      "iteration 158 / 300: loss 0.582483\n",
      "iteration 158 / 300: loss 0.585572\n",
      "iteration 158 / 300: loss 0.603666\n",
      "iteration 158 / 300: loss 0.585192\n",
      "iteration 158 / 300: loss 0.578880\n",
      "iteration 158 / 300: loss 0.576418\n",
      "iteration 158 / 300: loss 0.574097\n",
      "iteration 158 / 300: loss 0.600500\n",
      "iteration 158 / 300: loss 0.584490\n",
      "iteration 158 / 300: loss 0.584834\n",
      "iteration 158 / 300: loss 0.568323\n",
      "iteration 158 / 300: loss 0.592025\n",
      "iteration 158 / 300: loss 0.612116\n",
      "iteration 158 / 300: loss 0.608923\n",
      "iteration 158 / 300: loss 0.607613\n",
      "iteration 158 / 300: loss 0.595533\n",
      "iteration 158 / 300: loss 0.592837\n",
      "iteration 158 / 300: loss 0.597988\n",
      "iteration 158 / 300: loss 0.597677\n",
      "iteration 158 / 300: loss 0.600953\n",
      "iteration 158 / 300: loss 0.597422\n",
      "iteration 158 / 300: loss 0.598776\n",
      "iteration 158 / 300: loss 0.587806\n",
      "iteration 158 / 300: loss 0.600499\n",
      "iteration 158 / 300: loss 0.599650\n",
      "iteration 158 / 300: loss 0.617540\n",
      "iteration 158 / 300: loss 0.598875\n",
      "iteration 158 / 300: loss 0.600801\n",
      "iteration 158 / 300: loss 0.605305\n",
      "iteration 158 / 300: loss 0.598592\n",
      "iteration 158 / 300: loss 0.591474\n",
      "iteration 158 / 300: loss 0.580382\n",
      "iteration 158 / 300: loss 0.598221\n",
      "iteration 158 / 300: loss 0.611685\n",
      "iteration 158 / 300: loss 0.613219\n",
      "iteration 158 / 300: loss 0.582214\n",
      "iteration 158 / 300: loss 0.601955\n",
      "iteration 158 / 300: loss 0.608956\n",
      "iteration 158 / 300: loss 0.601794\n",
      "iteration 158 / 300: loss 0.607944\n",
      "iteration 158 / 300: loss 0.620236\n",
      "iteration 158 / 300: loss 0.584817\n",
      "iteration 158 / 300: loss 0.583721\n",
      "iteration 158 / 300: loss 0.628849\n",
      "iteration 158 / 300: loss 0.609399\n",
      "iteration 158 / 300: loss 0.606265\n",
      "iteration 158 / 300: loss 0.599034\n",
      "iteration 158 / 300: loss 0.615877\n",
      "iteration 158 / 300: loss 0.596489\n",
      "iteration 158 / 300: loss 0.581430\n",
      "iteration 158 / 300: loss 0.609807\n",
      "iteration 158 / 300: loss 0.608125\n",
      "iteration 158 / 300: loss 0.598224\n",
      "iteration 158 / 300: loss 0.592022\n",
      "iteration 158 / 300: loss 0.611031\n",
      "iteration 158 / 300: loss 0.598550\n",
      "iteration 158 / 300: loss 0.581382\n",
      "iteration 158 / 300: loss 0.609580\n",
      "iteration 159 / 300: loss 0.578384\n",
      "iteration 159 / 300: loss 0.596214\n",
      "iteration 159 / 300: loss 0.569455\n",
      "iteration 159 / 300: loss 0.597849\n",
      "iteration 159 / 300: loss 0.598940\n",
      "iteration 159 / 300: loss 0.603876\n",
      "iteration 159 / 300: loss 0.615261\n",
      "iteration 159 / 300: loss 0.588227\n",
      "iteration 159 / 300: loss 0.627171\n",
      "iteration 159 / 300: loss 0.592600\n",
      "iteration 159 / 300: loss 0.621500\n",
      "iteration 159 / 300: loss 0.593094\n",
      "iteration 159 / 300: loss 0.600541\n",
      "iteration 159 / 300: loss 0.571000\n",
      "iteration 159 / 300: loss 0.592911\n",
      "iteration 159 / 300: loss 0.600043\n",
      "iteration 159 / 300: loss 0.598053\n",
      "iteration 159 / 300: loss 0.583712\n",
      "iteration 159 / 300: loss 0.614355\n",
      "iteration 159 / 300: loss 0.591285\n",
      "iteration 159 / 300: loss 0.591391\n",
      "iteration 159 / 300: loss 0.594005\n",
      "iteration 159 / 300: loss 0.596735\n",
      "iteration 159 / 300: loss 0.596712\n",
      "iteration 159 / 300: loss 0.611735\n",
      "iteration 159 / 300: loss 0.607258\n",
      "iteration 159 / 300: loss 0.597032\n",
      "iteration 159 / 300: loss 0.596301\n",
      "iteration 159 / 300: loss 0.627391\n",
      "iteration 159 / 300: loss 0.601584\n",
      "iteration 159 / 300: loss 0.599923\n",
      "iteration 159 / 300: loss 0.621952\n",
      "iteration 159 / 300: loss 0.581435\n",
      "iteration 159 / 300: loss 0.599604\n",
      "iteration 159 / 300: loss 0.591182\n",
      "iteration 159 / 300: loss 0.599919\n",
      "iteration 159 / 300: loss 0.596015\n",
      "iteration 159 / 300: loss 0.590760\n",
      "iteration 159 / 300: loss 0.591961\n",
      "iteration 159 / 300: loss 0.615468\n",
      "iteration 159 / 300: loss 0.621360\n",
      "iteration 159 / 300: loss 0.587267\n",
      "iteration 159 / 300: loss 0.582483\n",
      "iteration 159 / 300: loss 0.585572\n",
      "iteration 159 / 300: loss 0.603666\n",
      "iteration 159 / 300: loss 0.585192\n",
      "iteration 159 / 300: loss 0.578880\n",
      "iteration 159 / 300: loss 0.576418\n",
      "iteration 159 / 300: loss 0.574097\n",
      "iteration 159 / 300: loss 0.600500\n",
      "iteration 159 / 300: loss 0.584490\n",
      "iteration 159 / 300: loss 0.584834\n",
      "iteration 159 / 300: loss 0.568323\n",
      "iteration 159 / 300: loss 0.592025\n",
      "iteration 159 / 300: loss 0.612116\n",
      "iteration 159 / 300: loss 0.608923\n",
      "iteration 159 / 300: loss 0.607613\n",
      "iteration 159 / 300: loss 0.595533\n",
      "iteration 159 / 300: loss 0.592837\n",
      "iteration 159 / 300: loss 0.597988\n",
      "iteration 159 / 300: loss 0.597677\n",
      "iteration 159 / 300: loss 0.600953\n",
      "iteration 159 / 300: loss 0.597422\n",
      "iteration 159 / 300: loss 0.598776\n",
      "iteration 159 / 300: loss 0.587806\n",
      "iteration 159 / 300: loss 0.600499\n",
      "iteration 159 / 300: loss 0.599650\n",
      "iteration 159 / 300: loss 0.617540\n",
      "iteration 159 / 300: loss 0.598875\n",
      "iteration 159 / 300: loss 0.600801\n",
      "iteration 159 / 300: loss 0.605305\n",
      "iteration 159 / 300: loss 0.598592\n",
      "iteration 159 / 300: loss 0.591474\n",
      "iteration 159 / 300: loss 0.580382\n",
      "iteration 159 / 300: loss 0.598221\n",
      "iteration 159 / 300: loss 0.611685\n",
      "iteration 159 / 300: loss 0.613219\n",
      "iteration 159 / 300: loss 0.582214\n",
      "iteration 159 / 300: loss 0.601955\n",
      "iteration 159 / 300: loss 0.608956\n",
      "iteration 159 / 300: loss 0.601794\n",
      "iteration 159 / 300: loss 0.607944\n",
      "iteration 159 / 300: loss 0.620236\n",
      "iteration 159 / 300: loss 0.584817\n",
      "iteration 159 / 300: loss 0.583721\n",
      "iteration 159 / 300: loss 0.628849\n",
      "iteration 159 / 300: loss 0.609399\n",
      "iteration 159 / 300: loss 0.606265\n",
      "iteration 159 / 300: loss 0.599034\n",
      "iteration 159 / 300: loss 0.615877\n",
      "iteration 159 / 300: loss 0.596489\n",
      "iteration 159 / 300: loss 0.581430\n",
      "iteration 159 / 300: loss 0.609807\n",
      "iteration 159 / 300: loss 0.608125\n",
      "iteration 159 / 300: loss 0.598224\n",
      "iteration 159 / 300: loss 0.592022\n",
      "iteration 159 / 300: loss 0.611031\n",
      "iteration 159 / 300: loss 0.598550\n",
      "iteration 159 / 300: loss 0.581382\n",
      "iteration 159 / 300: loss 0.609580\n",
      "iteration 160 / 300: loss 0.578384\n",
      "iteration 160 / 300: loss 0.596214\n",
      "iteration 160 / 300: loss 0.569455\n",
      "iteration 160 / 300: loss 0.597849\n",
      "iteration 160 / 300: loss 0.598940\n",
      "iteration 160 / 300: loss 0.603876\n",
      "iteration 160 / 300: loss 0.615261\n",
      "iteration 160 / 300: loss 0.588227\n",
      "iteration 160 / 300: loss 0.627171\n",
      "iteration 160 / 300: loss 0.592600\n",
      "iteration 160 / 300: loss 0.621500\n",
      "iteration 160 / 300: loss 0.593094\n",
      "iteration 160 / 300: loss 0.600541\n",
      "iteration 160 / 300: loss 0.571000\n",
      "iteration 160 / 300: loss 0.592911\n",
      "iteration 160 / 300: loss 0.600043\n",
      "iteration 160 / 300: loss 0.598053\n",
      "iteration 160 / 300: loss 0.583712\n",
      "iteration 160 / 300: loss 0.614355\n",
      "iteration 160 / 300: loss 0.591285\n",
      "iteration 160 / 300: loss 0.591391\n",
      "iteration 160 / 300: loss 0.594005\n",
      "iteration 160 / 300: loss 0.596735\n",
      "iteration 160 / 300: loss 0.596712\n",
      "iteration 160 / 300: loss 0.611735\n",
      "iteration 160 / 300: loss 0.607258\n",
      "iteration 160 / 300: loss 0.597032\n",
      "iteration 160 / 300: loss 0.596301\n",
      "iteration 160 / 300: loss 0.627391\n",
      "iteration 160 / 300: loss 0.601584\n",
      "iteration 160 / 300: loss 0.599923\n",
      "iteration 160 / 300: loss 0.621952\n",
      "iteration 160 / 300: loss 0.581435\n",
      "iteration 160 / 300: loss 0.599604\n",
      "iteration 160 / 300: loss 0.591182\n",
      "iteration 160 / 300: loss 0.599919\n",
      "iteration 160 / 300: loss 0.596015\n",
      "iteration 160 / 300: loss 0.590760\n",
      "iteration 160 / 300: loss 0.591961\n",
      "iteration 160 / 300: loss 0.615468\n",
      "iteration 160 / 300: loss 0.621360\n",
      "iteration 160 / 300: loss 0.587267\n",
      "iteration 160 / 300: loss 0.582483\n",
      "iteration 160 / 300: loss 0.585572\n",
      "iteration 160 / 300: loss 0.603666\n",
      "iteration 160 / 300: loss 0.585192\n",
      "iteration 160 / 300: loss 0.578880\n",
      "iteration 160 / 300: loss 0.576418\n",
      "iteration 160 / 300: loss 0.574097\n",
      "iteration 160 / 300: loss 0.600500\n",
      "iteration 160 / 300: loss 0.584490\n",
      "iteration 160 / 300: loss 0.584834\n",
      "iteration 160 / 300: loss 0.568323\n",
      "iteration 160 / 300: loss 0.592025\n",
      "iteration 160 / 300: loss 0.612116\n",
      "iteration 160 / 300: loss 0.608923\n",
      "iteration 160 / 300: loss 0.607613\n",
      "iteration 160 / 300: loss 0.595533\n",
      "iteration 160 / 300: loss 0.592837\n",
      "iteration 160 / 300: loss 0.597988\n",
      "iteration 160 / 300: loss 0.597677\n",
      "iteration 160 / 300: loss 0.600953\n",
      "iteration 160 / 300: loss 0.597422\n",
      "iteration 160 / 300: loss 0.598776\n",
      "iteration 160 / 300: loss 0.587806\n",
      "iteration 160 / 300: loss 0.600499\n",
      "iteration 160 / 300: loss 0.599650\n",
      "iteration 160 / 300: loss 0.617540\n",
      "iteration 160 / 300: loss 0.598875\n",
      "iteration 160 / 300: loss 0.600801\n",
      "iteration 160 / 300: loss 0.605305\n",
      "iteration 160 / 300: loss 0.598592\n",
      "iteration 160 / 300: loss 0.591474\n",
      "iteration 160 / 300: loss 0.580382\n",
      "iteration 160 / 300: loss 0.598221\n",
      "iteration 160 / 300: loss 0.611685\n",
      "iteration 160 / 300: loss 0.613219\n",
      "iteration 160 / 300: loss 0.582214\n",
      "iteration 160 / 300: loss 0.601955\n",
      "iteration 160 / 300: loss 0.608956\n",
      "iteration 160 / 300: loss 0.601794\n",
      "iteration 160 / 300: loss 0.607944\n",
      "iteration 160 / 300: loss 0.620236\n",
      "iteration 160 / 300: loss 0.584817\n",
      "iteration 160 / 300: loss 0.583721\n",
      "iteration 160 / 300: loss 0.628849\n",
      "iteration 160 / 300: loss 0.609399\n",
      "iteration 160 / 300: loss 0.606265\n",
      "iteration 160 / 300: loss 0.599034\n",
      "iteration 160 / 300: loss 0.615877\n",
      "iteration 160 / 300: loss 0.596489\n",
      "iteration 160 / 300: loss 0.581430\n",
      "iteration 160 / 300: loss 0.609807\n",
      "iteration 160 / 300: loss 0.608125\n",
      "iteration 160 / 300: loss 0.598224\n",
      "iteration 160 / 300: loss 0.592022\n",
      "iteration 160 / 300: loss 0.611031\n",
      "iteration 160 / 300: loss 0.598550\n",
      "iteration 160 / 300: loss 0.581382\n",
      "iteration 160 / 300: loss 0.609580\n",
      "iteration 161 / 300: loss 0.578384\n",
      "iteration 161 / 300: loss 0.596214\n",
      "iteration 161 / 300: loss 0.569455\n",
      "iteration 161 / 300: loss 0.597849\n",
      "iteration 161 / 300: loss 0.598940\n",
      "iteration 161 / 300: loss 0.603876\n",
      "iteration 161 / 300: loss 0.615261\n",
      "iteration 161 / 300: loss 0.588227\n",
      "iteration 161 / 300: loss 0.627171\n",
      "iteration 161 / 300: loss 0.592600\n",
      "iteration 161 / 300: loss 0.621500\n",
      "iteration 161 / 300: loss 0.593094\n",
      "iteration 161 / 300: loss 0.600541\n",
      "iteration 161 / 300: loss 0.571000\n",
      "iteration 161 / 300: loss 0.592911\n",
      "iteration 161 / 300: loss 0.600043\n",
      "iteration 161 / 300: loss 0.598053\n",
      "iteration 161 / 300: loss 0.583712\n",
      "iteration 161 / 300: loss 0.614355\n",
      "iteration 161 / 300: loss 0.591285\n",
      "iteration 161 / 300: loss 0.591391\n",
      "iteration 161 / 300: loss 0.594005\n",
      "iteration 161 / 300: loss 0.596735\n",
      "iteration 161 / 300: loss 0.596712\n",
      "iteration 161 / 300: loss 0.611735\n",
      "iteration 161 / 300: loss 0.607258\n",
      "iteration 161 / 300: loss 0.597032\n",
      "iteration 161 / 300: loss 0.596301\n",
      "iteration 161 / 300: loss 0.627391\n",
      "iteration 161 / 300: loss 0.601584\n",
      "iteration 161 / 300: loss 0.599923\n",
      "iteration 161 / 300: loss 0.621952\n",
      "iteration 161 / 300: loss 0.581435\n",
      "iteration 161 / 300: loss 0.599604\n",
      "iteration 161 / 300: loss 0.591182\n",
      "iteration 161 / 300: loss 0.599919\n",
      "iteration 161 / 300: loss 0.596015\n",
      "iteration 161 / 300: loss 0.590760\n",
      "iteration 161 / 300: loss 0.591961\n",
      "iteration 161 / 300: loss 0.615468\n",
      "iteration 161 / 300: loss 0.621360\n",
      "iteration 161 / 300: loss 0.587267\n",
      "iteration 161 / 300: loss 0.582483\n",
      "iteration 161 / 300: loss 0.585572\n",
      "iteration 161 / 300: loss 0.603666\n",
      "iteration 161 / 300: loss 0.585192\n",
      "iteration 161 / 300: loss 0.578880\n",
      "iteration 161 / 300: loss 0.576418\n",
      "iteration 161 / 300: loss 0.574097\n",
      "iteration 161 / 300: loss 0.600500\n",
      "iteration 161 / 300: loss 0.584490\n",
      "iteration 161 / 300: loss 0.584834\n",
      "iteration 161 / 300: loss 0.568323\n",
      "iteration 161 / 300: loss 0.592025\n",
      "iteration 161 / 300: loss 0.612116\n",
      "iteration 161 / 300: loss 0.608923\n",
      "iteration 161 / 300: loss 0.607613\n",
      "iteration 161 / 300: loss 0.595533\n",
      "iteration 161 / 300: loss 0.592837\n",
      "iteration 161 / 300: loss 0.597988\n",
      "iteration 161 / 300: loss 0.597677\n",
      "iteration 161 / 300: loss 0.600953\n",
      "iteration 161 / 300: loss 0.597422\n",
      "iteration 161 / 300: loss 0.598776\n",
      "iteration 161 / 300: loss 0.587806\n",
      "iteration 161 / 300: loss 0.600499\n",
      "iteration 161 / 300: loss 0.599650\n",
      "iteration 161 / 300: loss 0.617540\n",
      "iteration 161 / 300: loss 0.598875\n",
      "iteration 161 / 300: loss 0.600801\n",
      "iteration 161 / 300: loss 0.605305\n",
      "iteration 161 / 300: loss 0.598592\n",
      "iteration 161 / 300: loss 0.591474\n",
      "iteration 161 / 300: loss 0.580382\n",
      "iteration 161 / 300: loss 0.598221\n",
      "iteration 161 / 300: loss 0.611685\n",
      "iteration 161 / 300: loss 0.613219\n",
      "iteration 161 / 300: loss 0.582214\n",
      "iteration 161 / 300: loss 0.601955\n",
      "iteration 161 / 300: loss 0.608956\n",
      "iteration 161 / 300: loss 0.601794\n",
      "iteration 161 / 300: loss 0.607944\n",
      "iteration 161 / 300: loss 0.620236\n",
      "iteration 161 / 300: loss 0.584817\n",
      "iteration 161 / 300: loss 0.583721\n",
      "iteration 161 / 300: loss 0.628849\n",
      "iteration 161 / 300: loss 0.609399\n",
      "iteration 161 / 300: loss 0.606265\n",
      "iteration 161 / 300: loss 0.599034\n",
      "iteration 161 / 300: loss 0.615877\n",
      "iteration 161 / 300: loss 0.596489\n",
      "iteration 161 / 300: loss 0.581430\n",
      "iteration 161 / 300: loss 0.609807\n",
      "iteration 161 / 300: loss 0.608125\n",
      "iteration 161 / 300: loss 0.598224\n",
      "iteration 161 / 300: loss 0.592022\n",
      "iteration 161 / 300: loss 0.611031\n",
      "iteration 161 / 300: loss 0.598550\n",
      "iteration 161 / 300: loss 0.581382\n",
      "iteration 161 / 300: loss 0.609580\n",
      "iteration 162 / 300: loss 0.578384\n",
      "iteration 162 / 300: loss 0.596214\n",
      "iteration 162 / 300: loss 0.569455\n",
      "iteration 162 / 300: loss 0.597849\n",
      "iteration 162 / 300: loss 0.598940\n",
      "iteration 162 / 300: loss 0.603876\n",
      "iteration 162 / 300: loss 0.615261\n",
      "iteration 162 / 300: loss 0.588227\n",
      "iteration 162 / 300: loss 0.627171\n",
      "iteration 162 / 300: loss 0.592600\n",
      "iteration 162 / 300: loss 0.621500\n",
      "iteration 162 / 300: loss 0.593094\n",
      "iteration 162 / 300: loss 0.600541\n",
      "iteration 162 / 300: loss 0.571000\n",
      "iteration 162 / 300: loss 0.592911\n",
      "iteration 162 / 300: loss 0.600043\n",
      "iteration 162 / 300: loss 0.598053\n",
      "iteration 162 / 300: loss 0.583712\n",
      "iteration 162 / 300: loss 0.614355\n",
      "iteration 162 / 300: loss 0.591285\n",
      "iteration 162 / 300: loss 0.591391\n",
      "iteration 162 / 300: loss 0.594005\n",
      "iteration 162 / 300: loss 0.596735\n",
      "iteration 162 / 300: loss 0.596712\n",
      "iteration 162 / 300: loss 0.611735\n",
      "iteration 162 / 300: loss 0.607258\n",
      "iteration 162 / 300: loss 0.597032\n",
      "iteration 162 / 300: loss 0.596301\n",
      "iteration 162 / 300: loss 0.627391\n",
      "iteration 162 / 300: loss 0.601584\n",
      "iteration 162 / 300: loss 0.599923\n",
      "iteration 162 / 300: loss 0.621952\n",
      "iteration 162 / 300: loss 0.581435\n",
      "iteration 162 / 300: loss 0.599604\n",
      "iteration 162 / 300: loss 0.591182\n",
      "iteration 162 / 300: loss 0.599919\n",
      "iteration 162 / 300: loss 0.596015\n",
      "iteration 162 / 300: loss 0.590760\n",
      "iteration 162 / 300: loss 0.591961\n",
      "iteration 162 / 300: loss 0.615468\n",
      "iteration 162 / 300: loss 0.621360\n",
      "iteration 162 / 300: loss 0.587267\n",
      "iteration 162 / 300: loss 0.582483\n",
      "iteration 162 / 300: loss 0.585572\n",
      "iteration 162 / 300: loss 0.603666\n",
      "iteration 162 / 300: loss 0.585192\n",
      "iteration 162 / 300: loss 0.578880\n",
      "iteration 162 / 300: loss 0.576418\n",
      "iteration 162 / 300: loss 0.574097\n",
      "iteration 162 / 300: loss 0.600500\n",
      "iteration 162 / 300: loss 0.584490\n",
      "iteration 162 / 300: loss 0.584834\n",
      "iteration 162 / 300: loss 0.568323\n",
      "iteration 162 / 300: loss 0.592025\n",
      "iteration 162 / 300: loss 0.612116\n",
      "iteration 162 / 300: loss 0.608923\n",
      "iteration 162 / 300: loss 0.607613\n",
      "iteration 162 / 300: loss 0.595533\n",
      "iteration 162 / 300: loss 0.592837\n",
      "iteration 162 / 300: loss 0.597988\n",
      "iteration 162 / 300: loss 0.597677\n",
      "iteration 162 / 300: loss 0.600953\n",
      "iteration 162 / 300: loss 0.597422\n",
      "iteration 162 / 300: loss 0.598776\n",
      "iteration 162 / 300: loss 0.587806\n",
      "iteration 162 / 300: loss 0.600499\n",
      "iteration 162 / 300: loss 0.599650\n",
      "iteration 162 / 300: loss 0.617540\n",
      "iteration 162 / 300: loss 0.598875\n",
      "iteration 162 / 300: loss 0.600801\n",
      "iteration 162 / 300: loss 0.605305\n",
      "iteration 162 / 300: loss 0.598592\n",
      "iteration 162 / 300: loss 0.591474\n",
      "iteration 162 / 300: loss 0.580382\n",
      "iteration 162 / 300: loss 0.598221\n",
      "iteration 162 / 300: loss 0.611685\n",
      "iteration 162 / 300: loss 0.613219\n",
      "iteration 162 / 300: loss 0.582214\n",
      "iteration 162 / 300: loss 0.601955\n",
      "iteration 162 / 300: loss 0.608956\n",
      "iteration 162 / 300: loss 0.601794\n",
      "iteration 162 / 300: loss 0.607944\n",
      "iteration 162 / 300: loss 0.620236\n",
      "iteration 162 / 300: loss 0.584817\n",
      "iteration 162 / 300: loss 0.583721\n",
      "iteration 162 / 300: loss 0.628849\n",
      "iteration 162 / 300: loss 0.609399\n",
      "iteration 162 / 300: loss 0.606265\n",
      "iteration 162 / 300: loss 0.599034\n",
      "iteration 162 / 300: loss 0.615877\n",
      "iteration 162 / 300: loss 0.596489\n",
      "iteration 162 / 300: loss 0.581430\n",
      "iteration 162 / 300: loss 0.609807\n",
      "iteration 162 / 300: loss 0.608125\n",
      "iteration 162 / 300: loss 0.598224\n",
      "iteration 162 / 300: loss 0.592022\n",
      "iteration 162 / 300: loss 0.611031\n",
      "iteration 162 / 300: loss 0.598550\n",
      "iteration 162 / 300: loss 0.581382\n",
      "iteration 162 / 300: loss 0.609580\n",
      "iteration 163 / 300: loss 0.578384\n",
      "iteration 163 / 300: loss 0.596214\n",
      "iteration 163 / 300: loss 0.569455\n",
      "iteration 163 / 300: loss 0.597849\n",
      "iteration 163 / 300: loss 0.598940\n",
      "iteration 163 / 300: loss 0.603876\n",
      "iteration 163 / 300: loss 0.615261\n",
      "iteration 163 / 300: loss 0.588227\n",
      "iteration 163 / 300: loss 0.627171\n",
      "iteration 163 / 300: loss 0.592600\n",
      "iteration 163 / 300: loss 0.621500\n",
      "iteration 163 / 300: loss 0.593094\n",
      "iteration 163 / 300: loss 0.600541\n",
      "iteration 163 / 300: loss 0.571000\n",
      "iteration 163 / 300: loss 0.592911\n",
      "iteration 163 / 300: loss 0.600043\n",
      "iteration 163 / 300: loss 0.598053\n",
      "iteration 163 / 300: loss 0.583712\n",
      "iteration 163 / 300: loss 0.614355\n",
      "iteration 163 / 300: loss 0.591285\n",
      "iteration 163 / 300: loss 0.591391\n",
      "iteration 163 / 300: loss 0.594005\n",
      "iteration 163 / 300: loss 0.596735\n",
      "iteration 163 / 300: loss 0.596712\n",
      "iteration 163 / 300: loss 0.611735\n",
      "iteration 163 / 300: loss 0.607258\n",
      "iteration 163 / 300: loss 0.597032\n",
      "iteration 163 / 300: loss 0.596301\n",
      "iteration 163 / 300: loss 0.627391\n",
      "iteration 163 / 300: loss 0.601584\n",
      "iteration 163 / 300: loss 0.599923\n",
      "iteration 163 / 300: loss 0.621952\n",
      "iteration 163 / 300: loss 0.581435\n",
      "iteration 163 / 300: loss 0.599604\n",
      "iteration 163 / 300: loss 0.591182\n",
      "iteration 163 / 300: loss 0.599919\n",
      "iteration 163 / 300: loss 0.596015\n",
      "iteration 163 / 300: loss 0.590760\n",
      "iteration 163 / 300: loss 0.591961\n",
      "iteration 163 / 300: loss 0.615468\n",
      "iteration 163 / 300: loss 0.621360\n",
      "iteration 163 / 300: loss 0.587267\n",
      "iteration 163 / 300: loss 0.582483\n",
      "iteration 163 / 300: loss 0.585572\n",
      "iteration 163 / 300: loss 0.603666\n",
      "iteration 163 / 300: loss 0.585192\n",
      "iteration 163 / 300: loss 0.578880\n",
      "iteration 163 / 300: loss 0.576418\n",
      "iteration 163 / 300: loss 0.574097\n",
      "iteration 163 / 300: loss 0.600500\n",
      "iteration 163 / 300: loss 0.584490\n",
      "iteration 163 / 300: loss 0.584834\n",
      "iteration 163 / 300: loss 0.568323\n",
      "iteration 163 / 300: loss 0.592025\n",
      "iteration 163 / 300: loss 0.612116\n",
      "iteration 163 / 300: loss 0.608923\n",
      "iteration 163 / 300: loss 0.607613\n",
      "iteration 163 / 300: loss 0.595533\n",
      "iteration 163 / 300: loss 0.592837\n",
      "iteration 163 / 300: loss 0.597988\n",
      "iteration 163 / 300: loss 0.597677\n",
      "iteration 163 / 300: loss 0.600953\n",
      "iteration 163 / 300: loss 0.597422\n",
      "iteration 163 / 300: loss 0.598776\n",
      "iteration 163 / 300: loss 0.587806\n",
      "iteration 163 / 300: loss 0.600499\n",
      "iteration 163 / 300: loss 0.599650\n",
      "iteration 163 / 300: loss 0.617540\n",
      "iteration 163 / 300: loss 0.598875\n",
      "iteration 163 / 300: loss 0.600801\n",
      "iteration 163 / 300: loss 0.605305\n",
      "iteration 163 / 300: loss 0.598592\n",
      "iteration 163 / 300: loss 0.591474\n",
      "iteration 163 / 300: loss 0.580382\n",
      "iteration 163 / 300: loss 0.598221\n",
      "iteration 163 / 300: loss 0.611685\n",
      "iteration 163 / 300: loss 0.613219\n",
      "iteration 163 / 300: loss 0.582214\n",
      "iteration 163 / 300: loss 0.601955\n",
      "iteration 163 / 300: loss 0.608956\n",
      "iteration 163 / 300: loss 0.601794\n",
      "iteration 163 / 300: loss 0.607944\n",
      "iteration 163 / 300: loss 0.620236\n",
      "iteration 163 / 300: loss 0.584817\n",
      "iteration 163 / 300: loss 0.583721\n",
      "iteration 163 / 300: loss 0.628849\n",
      "iteration 163 / 300: loss 0.609399\n",
      "iteration 163 / 300: loss 0.606265\n",
      "iteration 163 / 300: loss 0.599034\n",
      "iteration 163 / 300: loss 0.615877\n",
      "iteration 163 / 300: loss 0.596489\n",
      "iteration 163 / 300: loss 0.581430\n",
      "iteration 163 / 300: loss 0.609807\n",
      "iteration 163 / 300: loss 0.608125\n",
      "iteration 163 / 300: loss 0.598224\n",
      "iteration 163 / 300: loss 0.592022\n",
      "iteration 163 / 300: loss 0.611031\n",
      "iteration 163 / 300: loss 0.598550\n",
      "iteration 163 / 300: loss 0.581382\n",
      "iteration 163 / 300: loss 0.609580\n",
      "iteration 164 / 300: loss 0.578384\n",
      "iteration 164 / 300: loss 0.596214\n",
      "iteration 164 / 300: loss 0.569455\n",
      "iteration 164 / 300: loss 0.597849\n",
      "iteration 164 / 300: loss 0.598940\n",
      "iteration 164 / 300: loss 0.603876\n",
      "iteration 164 / 300: loss 0.615261\n",
      "iteration 164 / 300: loss 0.588227\n",
      "iteration 164 / 300: loss 0.627171\n",
      "iteration 164 / 300: loss 0.592600\n",
      "iteration 164 / 300: loss 0.621500\n",
      "iteration 164 / 300: loss 0.593094\n",
      "iteration 164 / 300: loss 0.600541\n",
      "iteration 164 / 300: loss 0.571000\n",
      "iteration 164 / 300: loss 0.592911\n",
      "iteration 164 / 300: loss 0.600043\n",
      "iteration 164 / 300: loss 0.598053\n",
      "iteration 164 / 300: loss 0.583712\n",
      "iteration 164 / 300: loss 0.614355\n",
      "iteration 164 / 300: loss 0.591285\n",
      "iteration 164 / 300: loss 0.591391\n",
      "iteration 164 / 300: loss 0.594005\n",
      "iteration 164 / 300: loss 0.596735\n",
      "iteration 164 / 300: loss 0.596712\n",
      "iteration 164 / 300: loss 0.611735\n",
      "iteration 164 / 300: loss 0.607258\n",
      "iteration 164 / 300: loss 0.597032\n",
      "iteration 164 / 300: loss 0.596301\n",
      "iteration 164 / 300: loss 0.627391\n",
      "iteration 164 / 300: loss 0.601584\n",
      "iteration 164 / 300: loss 0.599923\n",
      "iteration 164 / 300: loss 0.621952\n",
      "iteration 164 / 300: loss 0.581435\n",
      "iteration 164 / 300: loss 0.599604\n",
      "iteration 164 / 300: loss 0.591182\n",
      "iteration 164 / 300: loss 0.599919\n",
      "iteration 164 / 300: loss 0.596015\n",
      "iteration 164 / 300: loss 0.590760\n",
      "iteration 164 / 300: loss 0.591961\n",
      "iteration 164 / 300: loss 0.615468\n",
      "iteration 164 / 300: loss 0.621360\n",
      "iteration 164 / 300: loss 0.587267\n",
      "iteration 164 / 300: loss 0.582483\n",
      "iteration 164 / 300: loss 0.585572\n",
      "iteration 164 / 300: loss 0.603666\n",
      "iteration 164 / 300: loss 0.585192\n",
      "iteration 164 / 300: loss 0.578880\n",
      "iteration 164 / 300: loss 0.576418\n",
      "iteration 164 / 300: loss 0.574097\n",
      "iteration 164 / 300: loss 0.600500\n",
      "iteration 164 / 300: loss 0.584490\n",
      "iteration 164 / 300: loss 0.584834\n",
      "iteration 164 / 300: loss 0.568323\n",
      "iteration 164 / 300: loss 0.592025\n",
      "iteration 164 / 300: loss 0.612116\n",
      "iteration 164 / 300: loss 0.608923\n",
      "iteration 164 / 300: loss 0.607613\n",
      "iteration 164 / 300: loss 0.595533\n",
      "iteration 164 / 300: loss 0.592837\n",
      "iteration 164 / 300: loss 0.597988\n",
      "iteration 164 / 300: loss 0.597677\n",
      "iteration 164 / 300: loss 0.600953\n",
      "iteration 164 / 300: loss 0.597422\n",
      "iteration 164 / 300: loss 0.598776\n",
      "iteration 164 / 300: loss 0.587806\n",
      "iteration 164 / 300: loss 0.600499\n",
      "iteration 164 / 300: loss 0.599650\n",
      "iteration 164 / 300: loss 0.617540\n",
      "iteration 164 / 300: loss 0.598875\n",
      "iteration 164 / 300: loss 0.600801\n",
      "iteration 164 / 300: loss 0.605305\n",
      "iteration 164 / 300: loss 0.598592\n",
      "iteration 164 / 300: loss 0.591474\n",
      "iteration 164 / 300: loss 0.580382\n",
      "iteration 164 / 300: loss 0.598221\n",
      "iteration 164 / 300: loss 0.611685\n",
      "iteration 164 / 300: loss 0.613219\n",
      "iteration 164 / 300: loss 0.582214\n",
      "iteration 164 / 300: loss 0.601955\n",
      "iteration 164 / 300: loss 0.608956\n",
      "iteration 164 / 300: loss 0.601794\n",
      "iteration 164 / 300: loss 0.607944\n",
      "iteration 164 / 300: loss 0.620236\n",
      "iteration 164 / 300: loss 0.584817\n",
      "iteration 164 / 300: loss 0.583721\n",
      "iteration 164 / 300: loss 0.628849\n",
      "iteration 164 / 300: loss 0.609399\n",
      "iteration 164 / 300: loss 0.606265\n",
      "iteration 164 / 300: loss 0.599034\n",
      "iteration 164 / 300: loss 0.615877\n",
      "iteration 164 / 300: loss 0.596489\n",
      "iteration 164 / 300: loss 0.581430\n",
      "iteration 164 / 300: loss 0.609807\n",
      "iteration 164 / 300: loss 0.608125\n",
      "iteration 164 / 300: loss 0.598224\n",
      "iteration 164 / 300: loss 0.592022\n",
      "iteration 164 / 300: loss 0.611031\n",
      "iteration 164 / 300: loss 0.598550\n",
      "iteration 164 / 300: loss 0.581382\n",
      "iteration 164 / 300: loss 0.609580\n",
      "iteration 165 / 300: loss 0.578384\n",
      "iteration 165 / 300: loss 0.596214\n",
      "iteration 165 / 300: loss 0.569455\n",
      "iteration 165 / 300: loss 0.597849\n",
      "iteration 165 / 300: loss 0.598940\n",
      "iteration 165 / 300: loss 0.603876\n",
      "iteration 165 / 300: loss 0.615261\n",
      "iteration 165 / 300: loss 0.588227\n",
      "iteration 165 / 300: loss 0.627171\n",
      "iteration 165 / 300: loss 0.592600\n",
      "iteration 165 / 300: loss 0.621500\n",
      "iteration 165 / 300: loss 0.593093\n",
      "iteration 165 / 300: loss 0.600541\n",
      "iteration 165 / 300: loss 0.571000\n",
      "iteration 165 / 300: loss 0.592911\n",
      "iteration 165 / 300: loss 0.600043\n",
      "iteration 165 / 300: loss 0.598053\n",
      "iteration 165 / 300: loss 0.583712\n",
      "iteration 165 / 300: loss 0.614355\n",
      "iteration 165 / 300: loss 0.591285\n",
      "iteration 165 / 300: loss 0.591391\n",
      "iteration 165 / 300: loss 0.594005\n",
      "iteration 165 / 300: loss 0.596735\n",
      "iteration 165 / 300: loss 0.596712\n",
      "iteration 165 / 300: loss 0.611735\n",
      "iteration 165 / 300: loss 0.607258\n",
      "iteration 165 / 300: loss 0.597031\n",
      "iteration 165 / 300: loss 0.596301\n",
      "iteration 165 / 300: loss 0.627391\n",
      "iteration 165 / 300: loss 0.601584\n",
      "iteration 165 / 300: loss 0.599923\n",
      "iteration 165 / 300: loss 0.621952\n",
      "iteration 165 / 300: loss 0.581435\n",
      "iteration 165 / 300: loss 0.599604\n",
      "iteration 165 / 300: loss 0.591182\n",
      "iteration 165 / 300: loss 0.599919\n",
      "iteration 165 / 300: loss 0.596015\n",
      "iteration 165 / 300: loss 0.590760\n",
      "iteration 165 / 300: loss 0.591961\n",
      "iteration 165 / 300: loss 0.615468\n",
      "iteration 165 / 300: loss 0.621360\n",
      "iteration 165 / 300: loss 0.587267\n",
      "iteration 165 / 300: loss 0.582483\n",
      "iteration 165 / 300: loss 0.585572\n",
      "iteration 165 / 300: loss 0.603666\n",
      "iteration 165 / 300: loss 0.585192\n",
      "iteration 165 / 300: loss 0.578880\n",
      "iteration 165 / 300: loss 0.576418\n",
      "iteration 165 / 300: loss 0.574097\n",
      "iteration 165 / 300: loss 0.600500\n",
      "iteration 165 / 300: loss 0.584490\n",
      "iteration 165 / 300: loss 0.584834\n",
      "iteration 165 / 300: loss 0.568323\n",
      "iteration 165 / 300: loss 0.592025\n",
      "iteration 165 / 300: loss 0.612116\n",
      "iteration 165 / 300: loss 0.608923\n",
      "iteration 165 / 300: loss 0.607613\n",
      "iteration 165 / 300: loss 0.595533\n",
      "iteration 165 / 300: loss 0.592837\n",
      "iteration 165 / 300: loss 0.597988\n",
      "iteration 165 / 300: loss 0.597677\n",
      "iteration 165 / 300: loss 0.600953\n",
      "iteration 165 / 300: loss 0.597422\n",
      "iteration 165 / 300: loss 0.598776\n",
      "iteration 165 / 300: loss 0.587806\n",
      "iteration 165 / 300: loss 0.600499\n",
      "iteration 165 / 300: loss 0.599650\n",
      "iteration 165 / 300: loss 0.617540\n",
      "iteration 165 / 300: loss 0.598875\n",
      "iteration 165 / 300: loss 0.600801\n",
      "iteration 165 / 300: loss 0.605305\n",
      "iteration 165 / 300: loss 0.598592\n",
      "iteration 165 / 300: loss 0.591474\n",
      "iteration 165 / 300: loss 0.580382\n",
      "iteration 165 / 300: loss 0.598221\n",
      "iteration 165 / 300: loss 0.611685\n",
      "iteration 165 / 300: loss 0.613219\n",
      "iteration 165 / 300: loss 0.582214\n",
      "iteration 165 / 300: loss 0.601955\n",
      "iteration 165 / 300: loss 0.608956\n",
      "iteration 165 / 300: loss 0.601794\n",
      "iteration 165 / 300: loss 0.607944\n",
      "iteration 165 / 300: loss 0.620236\n",
      "iteration 165 / 300: loss 0.584817\n",
      "iteration 165 / 300: loss 0.583721\n",
      "iteration 165 / 300: loss 0.628849\n",
      "iteration 165 / 300: loss 0.609399\n",
      "iteration 165 / 300: loss 0.606265\n",
      "iteration 165 / 300: loss 0.599034\n",
      "iteration 165 / 300: loss 0.615877\n",
      "iteration 165 / 300: loss 0.596489\n",
      "iteration 165 / 300: loss 0.581430\n",
      "iteration 165 / 300: loss 0.609807\n",
      "iteration 165 / 300: loss 0.608125\n",
      "iteration 165 / 300: loss 0.598224\n",
      "iteration 165 / 300: loss 0.592022\n",
      "iteration 165 / 300: loss 0.611031\n",
      "iteration 165 / 300: loss 0.598550\n",
      "iteration 165 / 300: loss 0.581382\n",
      "iteration 165 / 300: loss 0.609580\n",
      "iteration 166 / 300: loss 0.578384\n",
      "iteration 166 / 300: loss 0.596214\n",
      "iteration 166 / 300: loss 0.569455\n",
      "iteration 166 / 300: loss 0.597849\n",
      "iteration 166 / 300: loss 0.598940\n",
      "iteration 166 / 300: loss 0.603876\n",
      "iteration 166 / 300: loss 0.615261\n",
      "iteration 166 / 300: loss 0.588227\n",
      "iteration 166 / 300: loss 0.627171\n",
      "iteration 166 / 300: loss 0.592600\n",
      "iteration 166 / 300: loss 0.621500\n",
      "iteration 166 / 300: loss 0.593093\n",
      "iteration 166 / 300: loss 0.600541\n",
      "iteration 166 / 300: loss 0.571000\n",
      "iteration 166 / 300: loss 0.592911\n",
      "iteration 166 / 300: loss 0.600043\n",
      "iteration 166 / 300: loss 0.598053\n",
      "iteration 166 / 300: loss 0.583712\n",
      "iteration 166 / 300: loss 0.614355\n",
      "iteration 166 / 300: loss 0.591285\n",
      "iteration 166 / 300: loss 0.591391\n",
      "iteration 166 / 300: loss 0.594005\n",
      "iteration 166 / 300: loss 0.596735\n",
      "iteration 166 / 300: loss 0.596712\n",
      "iteration 166 / 300: loss 0.611735\n",
      "iteration 166 / 300: loss 0.607258\n",
      "iteration 166 / 300: loss 0.597031\n",
      "iteration 166 / 300: loss 0.596301\n",
      "iteration 166 / 300: loss 0.627391\n",
      "iteration 166 / 300: loss 0.601584\n",
      "iteration 166 / 300: loss 0.599923\n",
      "iteration 166 / 300: loss 0.621952\n",
      "iteration 166 / 300: loss 0.581435\n",
      "iteration 166 / 300: loss 0.599604\n",
      "iteration 166 / 300: loss 0.591182\n",
      "iteration 166 / 300: loss 0.599919\n",
      "iteration 166 / 300: loss 0.596015\n",
      "iteration 166 / 300: loss 0.590760\n",
      "iteration 166 / 300: loss 0.591961\n",
      "iteration 166 / 300: loss 0.615468\n",
      "iteration 166 / 300: loss 0.621360\n",
      "iteration 166 / 300: loss 0.587267\n",
      "iteration 166 / 300: loss 0.582483\n",
      "iteration 166 / 300: loss 0.585572\n",
      "iteration 166 / 300: loss 0.603666\n",
      "iteration 166 / 300: loss 0.585192\n",
      "iteration 166 / 300: loss 0.578880\n",
      "iteration 166 / 300: loss 0.576418\n",
      "iteration 166 / 300: loss 0.574097\n",
      "iteration 166 / 300: loss 0.600500\n",
      "iteration 166 / 300: loss 0.584490\n",
      "iteration 166 / 300: loss 0.584834\n",
      "iteration 166 / 300: loss 0.568323\n",
      "iteration 166 / 300: loss 0.592025\n",
      "iteration 166 / 300: loss 0.612116\n",
      "iteration 166 / 300: loss 0.608923\n",
      "iteration 166 / 300: loss 0.607613\n",
      "iteration 166 / 300: loss 0.595533\n",
      "iteration 166 / 300: loss 0.592837\n",
      "iteration 166 / 300: loss 0.597988\n",
      "iteration 166 / 300: loss 0.597677\n",
      "iteration 166 / 300: loss 0.600953\n",
      "iteration 166 / 300: loss 0.597422\n",
      "iteration 166 / 300: loss 0.598776\n",
      "iteration 166 / 300: loss 0.587806\n",
      "iteration 166 / 300: loss 0.600499\n",
      "iteration 166 / 300: loss 0.599650\n",
      "iteration 166 / 300: loss 0.617540\n",
      "iteration 166 / 300: loss 0.598875\n",
      "iteration 166 / 300: loss 0.600801\n",
      "iteration 166 / 300: loss 0.605305\n",
      "iteration 166 / 300: loss 0.598592\n",
      "iteration 166 / 300: loss 0.591474\n",
      "iteration 166 / 300: loss 0.580382\n",
      "iteration 166 / 300: loss 0.598221\n",
      "iteration 166 / 300: loss 0.611685\n",
      "iteration 166 / 300: loss 0.613219\n",
      "iteration 166 / 300: loss 0.582214\n",
      "iteration 166 / 300: loss 0.601955\n",
      "iteration 166 / 300: loss 0.608956\n",
      "iteration 166 / 300: loss 0.601794\n",
      "iteration 166 / 300: loss 0.607944\n",
      "iteration 166 / 300: loss 0.620236\n",
      "iteration 166 / 300: loss 0.584817\n",
      "iteration 166 / 300: loss 0.583721\n",
      "iteration 166 / 300: loss 0.628849\n",
      "iteration 166 / 300: loss 0.609399\n",
      "iteration 166 / 300: loss 0.606265\n",
      "iteration 166 / 300: loss 0.599034\n",
      "iteration 166 / 300: loss 0.615876\n",
      "iteration 166 / 300: loss 0.596489\n",
      "iteration 166 / 300: loss 0.581430\n",
      "iteration 166 / 300: loss 0.609807\n",
      "iteration 166 / 300: loss 0.608125\n",
      "iteration 166 / 300: loss 0.598224\n",
      "iteration 166 / 300: loss 0.592022\n",
      "iteration 166 / 300: loss 0.611031\n",
      "iteration 166 / 300: loss 0.598550\n",
      "iteration 166 / 300: loss 0.581382\n",
      "iteration 166 / 300: loss 0.609580\n",
      "iteration 167 / 300: loss 0.578384\n",
      "iteration 167 / 300: loss 0.596214\n",
      "iteration 167 / 300: loss 0.569455\n",
      "iteration 167 / 300: loss 0.597849\n",
      "iteration 167 / 300: loss 0.598940\n",
      "iteration 167 / 300: loss 0.603876\n",
      "iteration 167 / 300: loss 0.615261\n",
      "iteration 167 / 300: loss 0.588227\n",
      "iteration 167 / 300: loss 0.627171\n",
      "iteration 167 / 300: loss 0.592600\n",
      "iteration 167 / 300: loss 0.621500\n",
      "iteration 167 / 300: loss 0.593093\n",
      "iteration 167 / 300: loss 0.600541\n",
      "iteration 167 / 300: loss 0.571000\n",
      "iteration 167 / 300: loss 0.592911\n",
      "iteration 167 / 300: loss 0.600043\n",
      "iteration 167 / 300: loss 0.598053\n",
      "iteration 167 / 300: loss 0.583712\n",
      "iteration 167 / 300: loss 0.614355\n",
      "iteration 167 / 300: loss 0.591285\n",
      "iteration 167 / 300: loss 0.591391\n",
      "iteration 167 / 300: loss 0.594005\n",
      "iteration 167 / 300: loss 0.596735\n",
      "iteration 167 / 300: loss 0.596712\n",
      "iteration 167 / 300: loss 0.611735\n",
      "iteration 167 / 300: loss 0.607258\n",
      "iteration 167 / 300: loss 0.597031\n",
      "iteration 167 / 300: loss 0.596301\n",
      "iteration 167 / 300: loss 0.627391\n",
      "iteration 167 / 300: loss 0.601584\n",
      "iteration 167 / 300: loss 0.599923\n",
      "iteration 167 / 300: loss 0.621952\n",
      "iteration 167 / 300: loss 0.581435\n",
      "iteration 167 / 300: loss 0.599604\n",
      "iteration 167 / 300: loss 0.591182\n",
      "iteration 167 / 300: loss 0.599919\n",
      "iteration 167 / 300: loss 0.596015\n",
      "iteration 167 / 300: loss 0.590760\n",
      "iteration 167 / 300: loss 0.591961\n",
      "iteration 167 / 300: loss 0.615468\n",
      "iteration 167 / 300: loss 0.621360\n",
      "iteration 167 / 300: loss 0.587267\n",
      "iteration 167 / 300: loss 0.582483\n",
      "iteration 167 / 300: loss 0.585572\n",
      "iteration 167 / 300: loss 0.603666\n",
      "iteration 167 / 300: loss 0.585192\n",
      "iteration 167 / 300: loss 0.578880\n",
      "iteration 167 / 300: loss 0.576418\n",
      "iteration 167 / 300: loss 0.574097\n",
      "iteration 167 / 300: loss 0.600500\n",
      "iteration 167 / 300: loss 0.584490\n",
      "iteration 167 / 300: loss 0.584834\n",
      "iteration 167 / 300: loss 0.568323\n",
      "iteration 167 / 300: loss 0.592025\n",
      "iteration 167 / 300: loss 0.612116\n",
      "iteration 167 / 300: loss 0.608923\n",
      "iteration 167 / 300: loss 0.607613\n",
      "iteration 167 / 300: loss 0.595533\n",
      "iteration 167 / 300: loss 0.592837\n",
      "iteration 167 / 300: loss 0.597988\n",
      "iteration 167 / 300: loss 0.597677\n",
      "iteration 167 / 300: loss 0.600953\n",
      "iteration 167 / 300: loss 0.597422\n",
      "iteration 167 / 300: loss 0.598776\n",
      "iteration 167 / 300: loss 0.587806\n",
      "iteration 167 / 300: loss 0.600499\n",
      "iteration 167 / 300: loss 0.599650\n",
      "iteration 167 / 300: loss 0.617540\n",
      "iteration 167 / 300: loss 0.598875\n",
      "iteration 167 / 300: loss 0.600801\n",
      "iteration 167 / 300: loss 0.605305\n",
      "iteration 167 / 300: loss 0.598592\n",
      "iteration 167 / 300: loss 0.591474\n",
      "iteration 167 / 300: loss 0.580382\n",
      "iteration 167 / 300: loss 0.598221\n",
      "iteration 167 / 300: loss 0.611685\n",
      "iteration 167 / 300: loss 0.613219\n",
      "iteration 167 / 300: loss 0.582214\n",
      "iteration 167 / 300: loss 0.601955\n",
      "iteration 167 / 300: loss 0.608956\n",
      "iteration 167 / 300: loss 0.601794\n",
      "iteration 167 / 300: loss 0.607944\n",
      "iteration 167 / 300: loss 0.620236\n",
      "iteration 167 / 300: loss 0.584817\n",
      "iteration 167 / 300: loss 0.583721\n",
      "iteration 167 / 300: loss 0.628849\n",
      "iteration 167 / 300: loss 0.609399\n",
      "iteration 167 / 300: loss 0.606265\n",
      "iteration 167 / 300: loss 0.599034\n",
      "iteration 167 / 300: loss 0.615876\n",
      "iteration 167 / 300: loss 0.596489\n",
      "iteration 167 / 300: loss 0.581430\n",
      "iteration 167 / 300: loss 0.609807\n",
      "iteration 167 / 300: loss 0.608125\n",
      "iteration 167 / 300: loss 0.598224\n",
      "iteration 167 / 300: loss 0.592022\n",
      "iteration 167 / 300: loss 0.611031\n",
      "iteration 167 / 300: loss 0.598550\n",
      "iteration 167 / 300: loss 0.581382\n",
      "iteration 167 / 300: loss 0.609580\n",
      "iteration 168 / 300: loss 0.578384\n",
      "iteration 168 / 300: loss 0.596214\n",
      "iteration 168 / 300: loss 0.569455\n",
      "iteration 168 / 300: loss 0.597849\n",
      "iteration 168 / 300: loss 0.598940\n",
      "iteration 168 / 300: loss 0.603876\n",
      "iteration 168 / 300: loss 0.615261\n",
      "iteration 168 / 300: loss 0.588227\n",
      "iteration 168 / 300: loss 0.627171\n",
      "iteration 168 / 300: loss 0.592600\n",
      "iteration 168 / 300: loss 0.621500\n",
      "iteration 168 / 300: loss 0.593093\n",
      "iteration 168 / 300: loss 0.600541\n",
      "iteration 168 / 300: loss 0.571000\n",
      "iteration 168 / 300: loss 0.592911\n",
      "iteration 168 / 300: loss 0.600043\n",
      "iteration 168 / 300: loss 0.598053\n",
      "iteration 168 / 300: loss 0.583712\n",
      "iteration 168 / 300: loss 0.614355\n",
      "iteration 168 / 300: loss 0.591285\n",
      "iteration 168 / 300: loss 0.591391\n",
      "iteration 168 / 300: loss 0.594005\n",
      "iteration 168 / 300: loss 0.596735\n",
      "iteration 168 / 300: loss 0.596712\n",
      "iteration 168 / 300: loss 0.611735\n",
      "iteration 168 / 300: loss 0.607258\n",
      "iteration 168 / 300: loss 0.597031\n",
      "iteration 168 / 300: loss 0.596301\n",
      "iteration 168 / 300: loss 0.627391\n",
      "iteration 168 / 300: loss 0.601584\n",
      "iteration 168 / 300: loss 0.599923\n",
      "iteration 168 / 300: loss 0.621952\n",
      "iteration 168 / 300: loss 0.581435\n",
      "iteration 168 / 300: loss 0.599604\n",
      "iteration 168 / 300: loss 0.591182\n",
      "iteration 168 / 300: loss 0.599919\n",
      "iteration 168 / 300: loss 0.596015\n",
      "iteration 168 / 300: loss 0.590760\n",
      "iteration 168 / 300: loss 0.591961\n",
      "iteration 168 / 300: loss 0.615468\n",
      "iteration 168 / 300: loss 0.621360\n",
      "iteration 168 / 300: loss 0.587267\n",
      "iteration 168 / 300: loss 0.582483\n",
      "iteration 168 / 300: loss 0.585572\n",
      "iteration 168 / 300: loss 0.603666\n",
      "iteration 168 / 300: loss 0.585192\n",
      "iteration 168 / 300: loss 0.578880\n",
      "iteration 168 / 300: loss 0.576418\n",
      "iteration 168 / 300: loss 0.574097\n",
      "iteration 168 / 300: loss 0.600500\n",
      "iteration 168 / 300: loss 0.584490\n",
      "iteration 168 / 300: loss 0.584834\n",
      "iteration 168 / 300: loss 0.568323\n",
      "iteration 168 / 300: loss 0.592025\n",
      "iteration 168 / 300: loss 0.612116\n",
      "iteration 168 / 300: loss 0.608923\n",
      "iteration 168 / 300: loss 0.607613\n",
      "iteration 168 / 300: loss 0.595533\n",
      "iteration 168 / 300: loss 0.592837\n",
      "iteration 168 / 300: loss 0.597988\n",
      "iteration 168 / 300: loss 0.597677\n",
      "iteration 168 / 300: loss 0.600953\n",
      "iteration 168 / 300: loss 0.597422\n",
      "iteration 168 / 300: loss 0.598776\n",
      "iteration 168 / 300: loss 0.587806\n",
      "iteration 168 / 300: loss 0.600499\n",
      "iteration 168 / 300: loss 0.599650\n",
      "iteration 168 / 300: loss 0.617540\n",
      "iteration 168 / 300: loss 0.598875\n",
      "iteration 168 / 300: loss 0.600801\n",
      "iteration 168 / 300: loss 0.605305\n",
      "iteration 168 / 300: loss 0.598592\n",
      "iteration 168 / 300: loss 0.591474\n",
      "iteration 168 / 300: loss 0.580382\n",
      "iteration 168 / 300: loss 0.598221\n",
      "iteration 168 / 300: loss 0.611685\n",
      "iteration 168 / 300: loss 0.613219\n",
      "iteration 168 / 300: loss 0.582214\n",
      "iteration 168 / 300: loss 0.601955\n",
      "iteration 168 / 300: loss 0.608956\n",
      "iteration 168 / 300: loss 0.601794\n",
      "iteration 168 / 300: loss 0.607944\n",
      "iteration 168 / 300: loss 0.620236\n",
      "iteration 168 / 300: loss 0.584817\n",
      "iteration 168 / 300: loss 0.583721\n",
      "iteration 168 / 300: loss 0.628849\n",
      "iteration 168 / 300: loss 0.609399\n",
      "iteration 168 / 300: loss 0.606265\n",
      "iteration 168 / 300: loss 0.599034\n",
      "iteration 168 / 300: loss 0.615876\n",
      "iteration 168 / 300: loss 0.596489\n",
      "iteration 168 / 300: loss 0.581430\n",
      "iteration 168 / 300: loss 0.609807\n",
      "iteration 168 / 300: loss 0.608125\n",
      "iteration 168 / 300: loss 0.598224\n",
      "iteration 168 / 300: loss 0.592022\n",
      "iteration 168 / 300: loss 0.611031\n",
      "iteration 168 / 300: loss 0.598550\n",
      "iteration 168 / 300: loss 0.581382\n",
      "iteration 168 / 300: loss 0.609580\n",
      "iteration 169 / 300: loss 0.578384\n",
      "iteration 169 / 300: loss 0.596214\n",
      "iteration 169 / 300: loss 0.569455\n",
      "iteration 169 / 300: loss 0.597849\n",
      "iteration 169 / 300: loss 0.598940\n",
      "iteration 169 / 300: loss 0.603876\n",
      "iteration 169 / 300: loss 0.615261\n",
      "iteration 169 / 300: loss 0.588227\n",
      "iteration 169 / 300: loss 0.627171\n",
      "iteration 169 / 300: loss 0.592600\n",
      "iteration 169 / 300: loss 0.621500\n",
      "iteration 169 / 300: loss 0.593093\n",
      "iteration 169 / 300: loss 0.600541\n",
      "iteration 169 / 300: loss 0.571000\n",
      "iteration 169 / 300: loss 0.592911\n",
      "iteration 169 / 300: loss 0.600043\n",
      "iteration 169 / 300: loss 0.598053\n",
      "iteration 169 / 300: loss 0.583712\n",
      "iteration 169 / 300: loss 0.614355\n",
      "iteration 169 / 300: loss 0.591285\n",
      "iteration 169 / 300: loss 0.591391\n",
      "iteration 169 / 300: loss 0.594005\n",
      "iteration 169 / 300: loss 0.596735\n",
      "iteration 169 / 300: loss 0.596712\n",
      "iteration 169 / 300: loss 0.611735\n",
      "iteration 169 / 300: loss 0.607258\n",
      "iteration 169 / 300: loss 0.597031\n",
      "iteration 169 / 300: loss 0.596301\n",
      "iteration 169 / 300: loss 0.627391\n",
      "iteration 169 / 300: loss 0.601584\n",
      "iteration 169 / 300: loss 0.599923\n",
      "iteration 169 / 300: loss 0.621952\n",
      "iteration 169 / 300: loss 0.581435\n",
      "iteration 169 / 300: loss 0.599604\n",
      "iteration 169 / 300: loss 0.591182\n",
      "iteration 169 / 300: loss 0.599919\n",
      "iteration 169 / 300: loss 0.596015\n",
      "iteration 169 / 300: loss 0.590760\n",
      "iteration 169 / 300: loss 0.591961\n",
      "iteration 169 / 300: loss 0.615468\n",
      "iteration 169 / 300: loss 0.621360\n",
      "iteration 169 / 300: loss 0.587267\n",
      "iteration 169 / 300: loss 0.582483\n",
      "iteration 169 / 300: loss 0.585572\n",
      "iteration 169 / 300: loss 0.603666\n",
      "iteration 169 / 300: loss 0.585192\n",
      "iteration 169 / 300: loss 0.578880\n",
      "iteration 169 / 300: loss 0.576418\n",
      "iteration 169 / 300: loss 0.574097\n",
      "iteration 169 / 300: loss 0.600500\n",
      "iteration 169 / 300: loss 0.584490\n",
      "iteration 169 / 300: loss 0.584834\n",
      "iteration 169 / 300: loss 0.568323\n",
      "iteration 169 / 300: loss 0.592025\n",
      "iteration 169 / 300: loss 0.612116\n",
      "iteration 169 / 300: loss 0.608923\n",
      "iteration 169 / 300: loss 0.607613\n",
      "iteration 169 / 300: loss 0.595533\n",
      "iteration 169 / 300: loss 0.592837\n",
      "iteration 169 / 300: loss 0.597988\n",
      "iteration 169 / 300: loss 0.597677\n",
      "iteration 169 / 300: loss 0.600953\n",
      "iteration 169 / 300: loss 0.597422\n",
      "iteration 169 / 300: loss 0.598776\n",
      "iteration 169 / 300: loss 0.587806\n",
      "iteration 169 / 300: loss 0.600499\n",
      "iteration 169 / 300: loss 0.599650\n",
      "iteration 169 / 300: loss 0.617540\n",
      "iteration 169 / 300: loss 0.598875\n",
      "iteration 169 / 300: loss 0.600801\n",
      "iteration 169 / 300: loss 0.605305\n",
      "iteration 169 / 300: loss 0.598592\n",
      "iteration 169 / 300: loss 0.591474\n",
      "iteration 169 / 300: loss 0.580382\n",
      "iteration 169 / 300: loss 0.598221\n",
      "iteration 169 / 300: loss 0.611685\n",
      "iteration 169 / 300: loss 0.613219\n",
      "iteration 169 / 300: loss 0.582214\n",
      "iteration 169 / 300: loss 0.601955\n",
      "iteration 169 / 300: loss 0.608956\n",
      "iteration 169 / 300: loss 0.601794\n",
      "iteration 169 / 300: loss 0.607944\n",
      "iteration 169 / 300: loss 0.620236\n",
      "iteration 169 / 300: loss 0.584817\n",
      "iteration 169 / 300: loss 0.583721\n",
      "iteration 169 / 300: loss 0.628849\n",
      "iteration 169 / 300: loss 0.609399\n",
      "iteration 169 / 300: loss 0.606265\n",
      "iteration 169 / 300: loss 0.599034\n",
      "iteration 169 / 300: loss 0.615876\n",
      "iteration 169 / 300: loss 0.596489\n",
      "iteration 169 / 300: loss 0.581430\n",
      "iteration 169 / 300: loss 0.609807\n",
      "iteration 169 / 300: loss 0.608125\n",
      "iteration 169 / 300: loss 0.598224\n",
      "iteration 169 / 300: loss 0.592022\n",
      "iteration 169 / 300: loss 0.611031\n",
      "iteration 169 / 300: loss 0.598550\n",
      "iteration 169 / 300: loss 0.581382\n",
      "iteration 169 / 300: loss 0.609580\n",
      "iteration 170 / 300: loss 0.578384\n",
      "iteration 170 / 300: loss 0.596214\n",
      "iteration 170 / 300: loss 0.569455\n",
      "iteration 170 / 300: loss 0.597849\n",
      "iteration 170 / 300: loss 0.598940\n",
      "iteration 170 / 300: loss 0.603876\n",
      "iteration 170 / 300: loss 0.615261\n",
      "iteration 170 / 300: loss 0.588227\n",
      "iteration 170 / 300: loss 0.627171\n",
      "iteration 170 / 300: loss 0.592600\n",
      "iteration 170 / 300: loss 0.621500\n",
      "iteration 170 / 300: loss 0.593093\n",
      "iteration 170 / 300: loss 0.600541\n",
      "iteration 170 / 300: loss 0.571000\n",
      "iteration 170 / 300: loss 0.592911\n",
      "iteration 170 / 300: loss 0.600043\n",
      "iteration 170 / 300: loss 0.598053\n",
      "iteration 170 / 300: loss 0.583712\n",
      "iteration 170 / 300: loss 0.614355\n",
      "iteration 170 / 300: loss 0.591285\n",
      "iteration 170 / 300: loss 0.591391\n",
      "iteration 170 / 300: loss 0.594005\n",
      "iteration 170 / 300: loss 0.596735\n",
      "iteration 170 / 300: loss 0.596712\n",
      "iteration 170 / 300: loss 0.611735\n",
      "iteration 170 / 300: loss 0.607258\n",
      "iteration 170 / 300: loss 0.597031\n",
      "iteration 170 / 300: loss 0.596301\n",
      "iteration 170 / 300: loss 0.627391\n",
      "iteration 170 / 300: loss 0.601584\n",
      "iteration 170 / 300: loss 0.599923\n",
      "iteration 170 / 300: loss 0.621952\n",
      "iteration 170 / 300: loss 0.581435\n",
      "iteration 170 / 300: loss 0.599604\n",
      "iteration 170 / 300: loss 0.591182\n",
      "iteration 170 / 300: loss 0.599919\n",
      "iteration 170 / 300: loss 0.596015\n",
      "iteration 170 / 300: loss 0.590760\n",
      "iteration 170 / 300: loss 0.591961\n",
      "iteration 170 / 300: loss 0.615468\n",
      "iteration 170 / 300: loss 0.621360\n",
      "iteration 170 / 300: loss 0.587267\n",
      "iteration 170 / 300: loss 0.582483\n",
      "iteration 170 / 300: loss 0.585572\n",
      "iteration 170 / 300: loss 0.603666\n",
      "iteration 170 / 300: loss 0.585192\n",
      "iteration 170 / 300: loss 0.578880\n",
      "iteration 170 / 300: loss 0.576418\n",
      "iteration 170 / 300: loss 0.574097\n",
      "iteration 170 / 300: loss 0.600500\n",
      "iteration 170 / 300: loss 0.584490\n",
      "iteration 170 / 300: loss 0.584834\n",
      "iteration 170 / 300: loss 0.568323\n",
      "iteration 170 / 300: loss 0.592025\n",
      "iteration 170 / 300: loss 0.612116\n",
      "iteration 170 / 300: loss 0.608923\n",
      "iteration 170 / 300: loss 0.607613\n",
      "iteration 170 / 300: loss 0.595533\n",
      "iteration 170 / 300: loss 0.592837\n",
      "iteration 170 / 300: loss 0.597988\n",
      "iteration 170 / 300: loss 0.597677\n",
      "iteration 170 / 300: loss 0.600953\n",
      "iteration 170 / 300: loss 0.597422\n",
      "iteration 170 / 300: loss 0.598776\n",
      "iteration 170 / 300: loss 0.587806\n",
      "iteration 170 / 300: loss 0.600499\n",
      "iteration 170 / 300: loss 0.599650\n",
      "iteration 170 / 300: loss 0.617540\n",
      "iteration 170 / 300: loss 0.598875\n",
      "iteration 170 / 300: loss 0.600801\n",
      "iteration 170 / 300: loss 0.605305\n",
      "iteration 170 / 300: loss 0.598592\n",
      "iteration 170 / 300: loss 0.591474\n",
      "iteration 170 / 300: loss 0.580382\n",
      "iteration 170 / 300: loss 0.598221\n",
      "iteration 170 / 300: loss 0.611685\n",
      "iteration 170 / 300: loss 0.613219\n",
      "iteration 170 / 300: loss 0.582214\n",
      "iteration 170 / 300: loss 0.601955\n",
      "iteration 170 / 300: loss 0.608956\n",
      "iteration 170 / 300: loss 0.601794\n",
      "iteration 170 / 300: loss 0.607944\n",
      "iteration 170 / 300: loss 0.620236\n",
      "iteration 170 / 300: loss 0.584817\n",
      "iteration 170 / 300: loss 0.583721\n",
      "iteration 170 / 300: loss 0.628849\n",
      "iteration 170 / 300: loss 0.609399\n",
      "iteration 170 / 300: loss 0.606265\n",
      "iteration 170 / 300: loss 0.599034\n",
      "iteration 170 / 300: loss 0.615876\n",
      "iteration 170 / 300: loss 0.596489\n",
      "iteration 170 / 300: loss 0.581430\n",
      "iteration 170 / 300: loss 0.609807\n",
      "iteration 170 / 300: loss 0.608125\n",
      "iteration 170 / 300: loss 0.598224\n",
      "iteration 170 / 300: loss 0.592022\n",
      "iteration 170 / 300: loss 0.611031\n",
      "iteration 170 / 300: loss 0.598550\n",
      "iteration 170 / 300: loss 0.581382\n",
      "iteration 170 / 300: loss 0.609580\n",
      "iteration 171 / 300: loss 0.578384\n",
      "iteration 171 / 300: loss 0.596214\n",
      "iteration 171 / 300: loss 0.569455\n",
      "iteration 171 / 300: loss 0.597849\n",
      "iteration 171 / 300: loss 0.598940\n",
      "iteration 171 / 300: loss 0.603876\n",
      "iteration 171 / 300: loss 0.615261\n",
      "iteration 171 / 300: loss 0.588227\n",
      "iteration 171 / 300: loss 0.627171\n",
      "iteration 171 / 300: loss 0.592600\n",
      "iteration 171 / 300: loss 0.621500\n",
      "iteration 171 / 300: loss 0.593093\n",
      "iteration 171 / 300: loss 0.600541\n",
      "iteration 171 / 300: loss 0.571000\n",
      "iteration 171 / 300: loss 0.592911\n",
      "iteration 171 / 300: loss 0.600043\n",
      "iteration 171 / 300: loss 0.598053\n",
      "iteration 171 / 300: loss 0.583712\n",
      "iteration 171 / 300: loss 0.614355\n",
      "iteration 171 / 300: loss 0.591285\n",
      "iteration 171 / 300: loss 0.591391\n",
      "iteration 171 / 300: loss 0.594005\n",
      "iteration 171 / 300: loss 0.596735\n",
      "iteration 171 / 300: loss 0.596712\n",
      "iteration 171 / 300: loss 0.611735\n",
      "iteration 171 / 300: loss 0.607258\n",
      "iteration 171 / 300: loss 0.597031\n",
      "iteration 171 / 300: loss 0.596301\n",
      "iteration 171 / 300: loss 0.627391\n",
      "iteration 171 / 300: loss 0.601584\n",
      "iteration 171 / 300: loss 0.599923\n",
      "iteration 171 / 300: loss 0.621952\n",
      "iteration 171 / 300: loss 0.581435\n",
      "iteration 171 / 300: loss 0.599604\n",
      "iteration 171 / 300: loss 0.591182\n",
      "iteration 171 / 300: loss 0.599919\n",
      "iteration 171 / 300: loss 0.596015\n",
      "iteration 171 / 300: loss 0.590760\n",
      "iteration 171 / 300: loss 0.591961\n",
      "iteration 171 / 300: loss 0.615468\n",
      "iteration 171 / 300: loss 0.621360\n",
      "iteration 171 / 300: loss 0.587267\n",
      "iteration 171 / 300: loss 0.582483\n",
      "iteration 171 / 300: loss 0.585572\n",
      "iteration 171 / 300: loss 0.603666\n",
      "iteration 171 / 300: loss 0.585192\n",
      "iteration 171 / 300: loss 0.578880\n",
      "iteration 171 / 300: loss 0.576418\n",
      "iteration 171 / 300: loss 0.574097\n",
      "iteration 171 / 300: loss 0.600500\n",
      "iteration 171 / 300: loss 0.584490\n",
      "iteration 171 / 300: loss 0.584834\n",
      "iteration 171 / 300: loss 0.568323\n",
      "iteration 171 / 300: loss 0.592025\n",
      "iteration 171 / 300: loss 0.612116\n",
      "iteration 171 / 300: loss 0.608923\n",
      "iteration 171 / 300: loss 0.607613\n",
      "iteration 171 / 300: loss 0.595533\n",
      "iteration 171 / 300: loss 0.592837\n",
      "iteration 171 / 300: loss 0.597988\n",
      "iteration 171 / 300: loss 0.597677\n",
      "iteration 171 / 300: loss 0.600953\n",
      "iteration 171 / 300: loss 0.597422\n",
      "iteration 171 / 300: loss 0.598776\n",
      "iteration 171 / 300: loss 0.587806\n",
      "iteration 171 / 300: loss 0.600499\n",
      "iteration 171 / 300: loss 0.599650\n",
      "iteration 171 / 300: loss 0.617540\n",
      "iteration 171 / 300: loss 0.598875\n",
      "iteration 171 / 300: loss 0.600801\n",
      "iteration 171 / 300: loss 0.605305\n",
      "iteration 171 / 300: loss 0.598592\n",
      "iteration 171 / 300: loss 0.591474\n",
      "iteration 171 / 300: loss 0.580382\n",
      "iteration 171 / 300: loss 0.598221\n",
      "iteration 171 / 300: loss 0.611685\n",
      "iteration 171 / 300: loss 0.613219\n",
      "iteration 171 / 300: loss 0.582214\n",
      "iteration 171 / 300: loss 0.601955\n",
      "iteration 171 / 300: loss 0.608956\n",
      "iteration 171 / 300: loss 0.601794\n",
      "iteration 171 / 300: loss 0.607944\n",
      "iteration 171 / 300: loss 0.620236\n",
      "iteration 171 / 300: loss 0.584817\n",
      "iteration 171 / 300: loss 0.583721\n",
      "iteration 171 / 300: loss 0.628849\n",
      "iteration 171 / 300: loss 0.609399\n",
      "iteration 171 / 300: loss 0.606265\n",
      "iteration 171 / 300: loss 0.599034\n",
      "iteration 171 / 300: loss 0.615876\n",
      "iteration 171 / 300: loss 0.596489\n",
      "iteration 171 / 300: loss 0.581430\n",
      "iteration 171 / 300: loss 0.609807\n",
      "iteration 171 / 300: loss 0.608125\n",
      "iteration 171 / 300: loss 0.598224\n",
      "iteration 171 / 300: loss 0.592022\n",
      "iteration 171 / 300: loss 0.611031\n",
      "iteration 171 / 300: loss 0.598550\n",
      "iteration 171 / 300: loss 0.581382\n",
      "iteration 171 / 300: loss 0.609580\n",
      "iteration 172 / 300: loss 0.578384\n",
      "iteration 172 / 300: loss 0.596214\n",
      "iteration 172 / 300: loss 0.569455\n",
      "iteration 172 / 300: loss 0.597849\n",
      "iteration 172 / 300: loss 0.598940\n",
      "iteration 172 / 300: loss 0.603876\n",
      "iteration 172 / 300: loss 0.615261\n",
      "iteration 172 / 300: loss 0.588227\n",
      "iteration 172 / 300: loss 0.627171\n",
      "iteration 172 / 300: loss 0.592600\n",
      "iteration 172 / 300: loss 0.621500\n",
      "iteration 172 / 300: loss 0.593093\n",
      "iteration 172 / 300: loss 0.600541\n",
      "iteration 172 / 300: loss 0.571000\n",
      "iteration 172 / 300: loss 0.592911\n",
      "iteration 172 / 300: loss 0.600043\n",
      "iteration 172 / 300: loss 0.598053\n",
      "iteration 172 / 300: loss 0.583712\n",
      "iteration 172 / 300: loss 0.614355\n",
      "iteration 172 / 300: loss 0.591285\n",
      "iteration 172 / 300: loss 0.591391\n",
      "iteration 172 / 300: loss 0.594005\n",
      "iteration 172 / 300: loss 0.596735\n",
      "iteration 172 / 300: loss 0.596712\n",
      "iteration 172 / 300: loss 0.611735\n",
      "iteration 172 / 300: loss 0.607258\n",
      "iteration 172 / 300: loss 0.597031\n",
      "iteration 172 / 300: loss 0.596301\n",
      "iteration 172 / 300: loss 0.627391\n",
      "iteration 172 / 300: loss 0.601584\n",
      "iteration 172 / 300: loss 0.599923\n",
      "iteration 172 / 300: loss 0.621952\n",
      "iteration 172 / 300: loss 0.581435\n",
      "iteration 172 / 300: loss 0.599604\n",
      "iteration 172 / 300: loss 0.591182\n",
      "iteration 172 / 300: loss 0.599919\n",
      "iteration 172 / 300: loss 0.596015\n",
      "iteration 172 / 300: loss 0.590760\n",
      "iteration 172 / 300: loss 0.591961\n",
      "iteration 172 / 300: loss 0.615468\n",
      "iteration 172 / 300: loss 0.621360\n",
      "iteration 172 / 300: loss 0.587267\n",
      "iteration 172 / 300: loss 0.582483\n",
      "iteration 172 / 300: loss 0.585572\n",
      "iteration 172 / 300: loss 0.603666\n",
      "iteration 172 / 300: loss 0.585192\n",
      "iteration 172 / 300: loss 0.578880\n",
      "iteration 172 / 300: loss 0.576418\n",
      "iteration 172 / 300: loss 0.574097\n",
      "iteration 172 / 300: loss 0.600500\n",
      "iteration 172 / 300: loss 0.584490\n",
      "iteration 172 / 300: loss 0.584834\n",
      "iteration 172 / 300: loss 0.568323\n",
      "iteration 172 / 300: loss 0.592025\n",
      "iteration 172 / 300: loss 0.612116\n",
      "iteration 172 / 300: loss 0.608923\n",
      "iteration 172 / 300: loss 0.607613\n",
      "iteration 172 / 300: loss 0.595533\n",
      "iteration 172 / 300: loss 0.592837\n",
      "iteration 172 / 300: loss 0.597988\n",
      "iteration 172 / 300: loss 0.597677\n",
      "iteration 172 / 300: loss 0.600953\n",
      "iteration 172 / 300: loss 0.597422\n",
      "iteration 172 / 300: loss 0.598776\n",
      "iteration 172 / 300: loss 0.587806\n",
      "iteration 172 / 300: loss 0.600499\n",
      "iteration 172 / 300: loss 0.599650\n",
      "iteration 172 / 300: loss 0.617540\n",
      "iteration 172 / 300: loss 0.598875\n",
      "iteration 172 / 300: loss 0.600801\n",
      "iteration 172 / 300: loss 0.605305\n",
      "iteration 172 / 300: loss 0.598592\n",
      "iteration 172 / 300: loss 0.591474\n",
      "iteration 172 / 300: loss 0.580382\n",
      "iteration 172 / 300: loss 0.598221\n",
      "iteration 172 / 300: loss 0.611685\n",
      "iteration 172 / 300: loss 0.613219\n",
      "iteration 172 / 300: loss 0.582214\n",
      "iteration 172 / 300: loss 0.601955\n",
      "iteration 172 / 300: loss 0.608956\n",
      "iteration 172 / 300: loss 0.601794\n",
      "iteration 172 / 300: loss 0.607944\n",
      "iteration 172 / 300: loss 0.620236\n",
      "iteration 172 / 300: loss 0.584817\n",
      "iteration 172 / 300: loss 0.583721\n",
      "iteration 172 / 300: loss 0.628849\n",
      "iteration 172 / 300: loss 0.609399\n",
      "iteration 172 / 300: loss 0.606265\n",
      "iteration 172 / 300: loss 0.599034\n",
      "iteration 172 / 300: loss 0.615876\n",
      "iteration 172 / 300: loss 0.596489\n",
      "iteration 172 / 300: loss 0.581430\n",
      "iteration 172 / 300: loss 0.609807\n",
      "iteration 172 / 300: loss 0.608125\n",
      "iteration 172 / 300: loss 0.598224\n",
      "iteration 172 / 300: loss 0.592022\n",
      "iteration 172 / 300: loss 0.611031\n",
      "iteration 172 / 300: loss 0.598550\n",
      "iteration 172 / 300: loss 0.581382\n",
      "iteration 172 / 300: loss 0.609580\n",
      "iteration 173 / 300: loss 0.578384\n",
      "iteration 173 / 300: loss 0.596214\n",
      "iteration 173 / 300: loss 0.569455\n",
      "iteration 173 / 300: loss 0.597849\n",
      "iteration 173 / 300: loss 0.598940\n",
      "iteration 173 / 300: loss 0.603876\n",
      "iteration 173 / 300: loss 0.615261\n",
      "iteration 173 / 300: loss 0.588227\n",
      "iteration 173 / 300: loss 0.627171\n",
      "iteration 173 / 300: loss 0.592600\n",
      "iteration 173 / 300: loss 0.621500\n",
      "iteration 173 / 300: loss 0.593093\n",
      "iteration 173 / 300: loss 0.600541\n",
      "iteration 173 / 300: loss 0.571000\n",
      "iteration 173 / 300: loss 0.592911\n",
      "iteration 173 / 300: loss 0.600043\n",
      "iteration 173 / 300: loss 0.598053\n",
      "iteration 173 / 300: loss 0.583712\n",
      "iteration 173 / 300: loss 0.614355\n",
      "iteration 173 / 300: loss 0.591285\n",
      "iteration 173 / 300: loss 0.591391\n",
      "iteration 173 / 300: loss 0.594005\n",
      "iteration 173 / 300: loss 0.596735\n",
      "iteration 173 / 300: loss 0.596712\n",
      "iteration 173 / 300: loss 0.611735\n",
      "iteration 173 / 300: loss 0.607258\n",
      "iteration 173 / 300: loss 0.597031\n",
      "iteration 173 / 300: loss 0.596301\n",
      "iteration 173 / 300: loss 0.627391\n",
      "iteration 173 / 300: loss 0.601584\n",
      "iteration 173 / 300: loss 0.599923\n",
      "iteration 173 / 300: loss 0.621952\n",
      "iteration 173 / 300: loss 0.581435\n",
      "iteration 173 / 300: loss 0.599604\n",
      "iteration 173 / 300: loss 0.591182\n",
      "iteration 173 / 300: loss 0.599919\n",
      "iteration 173 / 300: loss 0.596015\n",
      "iteration 173 / 300: loss 0.590760\n",
      "iteration 173 / 300: loss 0.591961\n",
      "iteration 173 / 300: loss 0.615468\n",
      "iteration 173 / 300: loss 0.621360\n",
      "iteration 173 / 300: loss 0.587267\n",
      "iteration 173 / 300: loss 0.582483\n",
      "iteration 173 / 300: loss 0.585572\n",
      "iteration 173 / 300: loss 0.603666\n",
      "iteration 173 / 300: loss 0.585192\n",
      "iteration 173 / 300: loss 0.578880\n",
      "iteration 173 / 300: loss 0.576418\n",
      "iteration 173 / 300: loss 0.574097\n",
      "iteration 173 / 300: loss 0.600500\n",
      "iteration 173 / 300: loss 0.584490\n",
      "iteration 173 / 300: loss 0.584834\n",
      "iteration 173 / 300: loss 0.568323\n",
      "iteration 173 / 300: loss 0.592025\n",
      "iteration 173 / 300: loss 0.612116\n",
      "iteration 173 / 300: loss 0.608923\n",
      "iteration 173 / 300: loss 0.607613\n",
      "iteration 173 / 300: loss 0.595533\n",
      "iteration 173 / 300: loss 0.592837\n",
      "iteration 173 / 300: loss 0.597988\n",
      "iteration 173 / 300: loss 0.597677\n",
      "iteration 173 / 300: loss 0.600953\n",
      "iteration 173 / 300: loss 0.597422\n",
      "iteration 173 / 300: loss 0.598776\n",
      "iteration 173 / 300: loss 0.587806\n",
      "iteration 173 / 300: loss 0.600499\n",
      "iteration 173 / 300: loss 0.599650\n",
      "iteration 173 / 300: loss 0.617540\n",
      "iteration 173 / 300: loss 0.598875\n",
      "iteration 173 / 300: loss 0.600801\n",
      "iteration 173 / 300: loss 0.605305\n",
      "iteration 173 / 300: loss 0.598592\n",
      "iteration 173 / 300: loss 0.591474\n",
      "iteration 173 / 300: loss 0.580382\n",
      "iteration 173 / 300: loss 0.598221\n",
      "iteration 173 / 300: loss 0.611685\n",
      "iteration 173 / 300: loss 0.613219\n",
      "iteration 173 / 300: loss 0.582214\n",
      "iteration 173 / 300: loss 0.601955\n",
      "iteration 173 / 300: loss 0.608956\n",
      "iteration 173 / 300: loss 0.601794\n",
      "iteration 173 / 300: loss 0.607944\n",
      "iteration 173 / 300: loss 0.620236\n",
      "iteration 173 / 300: loss 0.584817\n",
      "iteration 173 / 300: loss 0.583721\n",
      "iteration 173 / 300: loss 0.628849\n",
      "iteration 173 / 300: loss 0.609399\n",
      "iteration 173 / 300: loss 0.606265\n",
      "iteration 173 / 300: loss 0.599034\n",
      "iteration 173 / 300: loss 0.615876\n",
      "iteration 173 / 300: loss 0.596489\n",
      "iteration 173 / 300: loss 0.581430\n",
      "iteration 173 / 300: loss 0.609807\n",
      "iteration 173 / 300: loss 0.608125\n",
      "iteration 173 / 300: loss 0.598224\n",
      "iteration 173 / 300: loss 0.592022\n",
      "iteration 173 / 300: loss 0.611031\n",
      "iteration 173 / 300: loss 0.598550\n",
      "iteration 173 / 300: loss 0.581382\n",
      "iteration 173 / 300: loss 0.609580\n",
      "iteration 174 / 300: loss 0.578384\n",
      "iteration 174 / 300: loss 0.596214\n",
      "iteration 174 / 300: loss 0.569455\n",
      "iteration 174 / 300: loss 0.597849\n",
      "iteration 174 / 300: loss 0.598940\n",
      "iteration 174 / 300: loss 0.603876\n",
      "iteration 174 / 300: loss 0.615261\n",
      "iteration 174 / 300: loss 0.588227\n",
      "iteration 174 / 300: loss 0.627171\n",
      "iteration 174 / 300: loss 0.592600\n",
      "iteration 174 / 300: loss 0.621500\n",
      "iteration 174 / 300: loss 0.593093\n",
      "iteration 174 / 300: loss 0.600541\n",
      "iteration 174 / 300: loss 0.571000\n",
      "iteration 174 / 300: loss 0.592911\n",
      "iteration 174 / 300: loss 0.600043\n",
      "iteration 174 / 300: loss 0.598053\n",
      "iteration 174 / 300: loss 0.583712\n",
      "iteration 174 / 300: loss 0.614355\n",
      "iteration 174 / 300: loss 0.591285\n",
      "iteration 174 / 300: loss 0.591391\n",
      "iteration 174 / 300: loss 0.594005\n",
      "iteration 174 / 300: loss 0.596735\n",
      "iteration 174 / 300: loss 0.596712\n",
      "iteration 174 / 300: loss 0.611735\n",
      "iteration 174 / 300: loss 0.607258\n",
      "iteration 174 / 300: loss 0.597031\n",
      "iteration 174 / 300: loss 0.596301\n",
      "iteration 174 / 300: loss 0.627391\n",
      "iteration 174 / 300: loss 0.601584\n",
      "iteration 174 / 300: loss 0.599923\n",
      "iteration 174 / 300: loss 0.621952\n",
      "iteration 174 / 300: loss 0.581435\n",
      "iteration 174 / 300: loss 0.599604\n",
      "iteration 174 / 300: loss 0.591182\n",
      "iteration 174 / 300: loss 0.599919\n",
      "iteration 174 / 300: loss 0.596015\n",
      "iteration 174 / 300: loss 0.590760\n",
      "iteration 174 / 300: loss 0.591961\n",
      "iteration 174 / 300: loss 0.615468\n",
      "iteration 174 / 300: loss 0.621360\n",
      "iteration 174 / 300: loss 0.587267\n",
      "iteration 174 / 300: loss 0.582483\n",
      "iteration 174 / 300: loss 0.585572\n",
      "iteration 174 / 300: loss 0.603666\n",
      "iteration 174 / 300: loss 0.585192\n",
      "iteration 174 / 300: loss 0.578880\n",
      "iteration 174 / 300: loss 0.576418\n",
      "iteration 174 / 300: loss 0.574097\n",
      "iteration 174 / 300: loss 0.600500\n",
      "iteration 174 / 300: loss 0.584490\n",
      "iteration 174 / 300: loss 0.584834\n",
      "iteration 174 / 300: loss 0.568323\n",
      "iteration 174 / 300: loss 0.592025\n",
      "iteration 174 / 300: loss 0.612116\n",
      "iteration 174 / 300: loss 0.608923\n",
      "iteration 174 / 300: loss 0.607613\n",
      "iteration 174 / 300: loss 0.595533\n",
      "iteration 174 / 300: loss 0.592837\n",
      "iteration 174 / 300: loss 0.597988\n",
      "iteration 174 / 300: loss 0.597677\n",
      "iteration 174 / 300: loss 0.600953\n",
      "iteration 174 / 300: loss 0.597422\n",
      "iteration 174 / 300: loss 0.598776\n",
      "iteration 174 / 300: loss 0.587806\n",
      "iteration 174 / 300: loss 0.600499\n",
      "iteration 174 / 300: loss 0.599650\n",
      "iteration 174 / 300: loss 0.617540\n",
      "iteration 174 / 300: loss 0.598875\n",
      "iteration 174 / 300: loss 0.600801\n",
      "iteration 174 / 300: loss 0.605305\n",
      "iteration 174 / 300: loss 0.598592\n",
      "iteration 174 / 300: loss 0.591474\n",
      "iteration 174 / 300: loss 0.580382\n",
      "iteration 174 / 300: loss 0.598221\n",
      "iteration 174 / 300: loss 0.611685\n",
      "iteration 174 / 300: loss 0.613219\n",
      "iteration 174 / 300: loss 0.582214\n",
      "iteration 174 / 300: loss 0.601955\n",
      "iteration 174 / 300: loss 0.608956\n",
      "iteration 174 / 300: loss 0.601794\n",
      "iteration 174 / 300: loss 0.607944\n",
      "iteration 174 / 300: loss 0.620236\n",
      "iteration 174 / 300: loss 0.584817\n",
      "iteration 174 / 300: loss 0.583721\n",
      "iteration 174 / 300: loss 0.628849\n",
      "iteration 174 / 300: loss 0.609399\n",
      "iteration 174 / 300: loss 0.606265\n",
      "iteration 174 / 300: loss 0.599034\n",
      "iteration 174 / 300: loss 0.615876\n",
      "iteration 174 / 300: loss 0.596489\n",
      "iteration 174 / 300: loss 0.581430\n",
      "iteration 174 / 300: loss 0.609807\n",
      "iteration 174 / 300: loss 0.608125\n",
      "iteration 174 / 300: loss 0.598224\n",
      "iteration 174 / 300: loss 0.592022\n",
      "iteration 174 / 300: loss 0.611031\n",
      "iteration 174 / 300: loss 0.598550\n",
      "iteration 174 / 300: loss 0.581382\n",
      "iteration 174 / 300: loss 0.609580\n",
      "iteration 175 / 300: loss 0.578384\n",
      "iteration 175 / 300: loss 0.596214\n",
      "iteration 175 / 300: loss 0.569455\n",
      "iteration 175 / 300: loss 0.597849\n",
      "iteration 175 / 300: loss 0.598940\n",
      "iteration 175 / 300: loss 0.603876\n",
      "iteration 175 / 300: loss 0.615261\n",
      "iteration 175 / 300: loss 0.588227\n",
      "iteration 175 / 300: loss 0.627171\n",
      "iteration 175 / 300: loss 0.592600\n",
      "iteration 175 / 300: loss 0.621500\n",
      "iteration 175 / 300: loss 0.593093\n",
      "iteration 175 / 300: loss 0.600541\n",
      "iteration 175 / 300: loss 0.571000\n",
      "iteration 175 / 300: loss 0.592911\n",
      "iteration 175 / 300: loss 0.600043\n",
      "iteration 175 / 300: loss 0.598053\n",
      "iteration 175 / 300: loss 0.583712\n",
      "iteration 175 / 300: loss 0.614355\n",
      "iteration 175 / 300: loss 0.591285\n",
      "iteration 175 / 300: loss 0.591391\n",
      "iteration 175 / 300: loss 0.594005\n",
      "iteration 175 / 300: loss 0.596735\n",
      "iteration 175 / 300: loss 0.596712\n",
      "iteration 175 / 300: loss 0.611735\n",
      "iteration 175 / 300: loss 0.607258\n",
      "iteration 175 / 300: loss 0.597031\n",
      "iteration 175 / 300: loss 0.596301\n",
      "iteration 175 / 300: loss 0.627391\n",
      "iteration 175 / 300: loss 0.601584\n",
      "iteration 175 / 300: loss 0.599923\n",
      "iteration 175 / 300: loss 0.621952\n",
      "iteration 175 / 300: loss 0.581435\n",
      "iteration 175 / 300: loss 0.599604\n",
      "iteration 175 / 300: loss 0.591182\n",
      "iteration 175 / 300: loss 0.599919\n",
      "iteration 175 / 300: loss 0.596015\n",
      "iteration 175 / 300: loss 0.590760\n",
      "iteration 175 / 300: loss 0.591961\n",
      "iteration 175 / 300: loss 0.615468\n",
      "iteration 175 / 300: loss 0.621360\n",
      "iteration 175 / 300: loss 0.587267\n",
      "iteration 175 / 300: loss 0.582483\n",
      "iteration 175 / 300: loss 0.585572\n",
      "iteration 175 / 300: loss 0.603666\n",
      "iteration 175 / 300: loss 0.585192\n",
      "iteration 175 / 300: loss 0.578880\n",
      "iteration 175 / 300: loss 0.576418\n",
      "iteration 175 / 300: loss 0.574097\n",
      "iteration 175 / 300: loss 0.600500\n",
      "iteration 175 / 300: loss 0.584490\n",
      "iteration 175 / 300: loss 0.584834\n",
      "iteration 175 / 300: loss 0.568323\n",
      "iteration 175 / 300: loss 0.592025\n",
      "iteration 175 / 300: loss 0.612116\n",
      "iteration 175 / 300: loss 0.608923\n",
      "iteration 175 / 300: loss 0.607613\n",
      "iteration 175 / 300: loss 0.595533\n",
      "iteration 175 / 300: loss 0.592837\n",
      "iteration 175 / 300: loss 0.597988\n",
      "iteration 175 / 300: loss 0.597677\n",
      "iteration 175 / 300: loss 0.600953\n",
      "iteration 175 / 300: loss 0.597422\n",
      "iteration 175 / 300: loss 0.598776\n",
      "iteration 175 / 300: loss 0.587806\n",
      "iteration 175 / 300: loss 0.600499\n",
      "iteration 175 / 300: loss 0.599650\n",
      "iteration 175 / 300: loss 0.617540\n",
      "iteration 175 / 300: loss 0.598875\n",
      "iteration 175 / 300: loss 0.600801\n",
      "iteration 175 / 300: loss 0.605305\n",
      "iteration 175 / 300: loss 0.598592\n",
      "iteration 175 / 300: loss 0.591474\n",
      "iteration 175 / 300: loss 0.580382\n",
      "iteration 175 / 300: loss 0.598221\n",
      "iteration 175 / 300: loss 0.611685\n",
      "iteration 175 / 300: loss 0.613219\n",
      "iteration 175 / 300: loss 0.582214\n",
      "iteration 175 / 300: loss 0.601955\n",
      "iteration 175 / 300: loss 0.608956\n",
      "iteration 175 / 300: loss 0.601794\n",
      "iteration 175 / 300: loss 0.607944\n",
      "iteration 175 / 300: loss 0.620236\n",
      "iteration 175 / 300: loss 0.584817\n",
      "iteration 175 / 300: loss 0.583721\n",
      "iteration 175 / 300: loss 0.628849\n",
      "iteration 175 / 300: loss 0.609399\n",
      "iteration 175 / 300: loss 0.606265\n",
      "iteration 175 / 300: loss 0.599034\n",
      "iteration 175 / 300: loss 0.615876\n",
      "iteration 175 / 300: loss 0.596489\n",
      "iteration 175 / 300: loss 0.581430\n",
      "iteration 175 / 300: loss 0.609807\n",
      "iteration 175 / 300: loss 0.608125\n",
      "iteration 175 / 300: loss 0.598224\n",
      "iteration 175 / 300: loss 0.592022\n",
      "iteration 175 / 300: loss 0.611031\n",
      "iteration 175 / 300: loss 0.598550\n",
      "iteration 175 / 300: loss 0.581382\n",
      "iteration 175 / 300: loss 0.609580\n",
      "iteration 176 / 300: loss 0.578384\n",
      "iteration 176 / 300: loss 0.596214\n",
      "iteration 176 / 300: loss 0.569455\n",
      "iteration 176 / 300: loss 0.597849\n",
      "iteration 176 / 300: loss 0.598940\n",
      "iteration 176 / 300: loss 0.603876\n",
      "iteration 176 / 300: loss 0.615261\n",
      "iteration 176 / 300: loss 0.588227\n",
      "iteration 176 / 300: loss 0.627171\n",
      "iteration 176 / 300: loss 0.592600\n",
      "iteration 176 / 300: loss 0.621500\n",
      "iteration 176 / 300: loss 0.593093\n",
      "iteration 176 / 300: loss 0.600541\n",
      "iteration 176 / 300: loss 0.571000\n",
      "iteration 176 / 300: loss 0.592911\n",
      "iteration 176 / 300: loss 0.600043\n",
      "iteration 176 / 300: loss 0.598053\n",
      "iteration 176 / 300: loss 0.583712\n",
      "iteration 176 / 300: loss 0.614355\n",
      "iteration 176 / 300: loss 0.591285\n",
      "iteration 176 / 300: loss 0.591391\n",
      "iteration 176 / 300: loss 0.594005\n",
      "iteration 176 / 300: loss 0.596735\n",
      "iteration 176 / 300: loss 0.596712\n",
      "iteration 176 / 300: loss 0.611735\n",
      "iteration 176 / 300: loss 0.607258\n",
      "iteration 176 / 300: loss 0.597031\n",
      "iteration 176 / 300: loss 0.596301\n",
      "iteration 176 / 300: loss 0.627391\n",
      "iteration 176 / 300: loss 0.601584\n",
      "iteration 176 / 300: loss 0.599923\n",
      "iteration 176 / 300: loss 0.621952\n",
      "iteration 176 / 300: loss 0.581435\n",
      "iteration 176 / 300: loss 0.599604\n",
      "iteration 176 / 300: loss 0.591182\n",
      "iteration 176 / 300: loss 0.599919\n",
      "iteration 176 / 300: loss 0.596015\n",
      "iteration 176 / 300: loss 0.590760\n",
      "iteration 176 / 300: loss 0.591961\n",
      "iteration 176 / 300: loss 0.615468\n",
      "iteration 176 / 300: loss 0.621360\n",
      "iteration 176 / 300: loss 0.587267\n",
      "iteration 176 / 300: loss 0.582483\n",
      "iteration 176 / 300: loss 0.585572\n",
      "iteration 176 / 300: loss 0.603666\n",
      "iteration 176 / 300: loss 0.585192\n",
      "iteration 176 / 300: loss 0.578880\n",
      "iteration 176 / 300: loss 0.576418\n",
      "iteration 176 / 300: loss 0.574097\n",
      "iteration 176 / 300: loss 0.600500\n",
      "iteration 176 / 300: loss 0.584490\n",
      "iteration 176 / 300: loss 0.584834\n",
      "iteration 176 / 300: loss 0.568323\n",
      "iteration 176 / 300: loss 0.592025\n",
      "iteration 176 / 300: loss 0.612116\n",
      "iteration 176 / 300: loss 0.608923\n",
      "iteration 176 / 300: loss 0.607613\n",
      "iteration 176 / 300: loss 0.595533\n",
      "iteration 176 / 300: loss 0.592837\n",
      "iteration 176 / 300: loss 0.597988\n",
      "iteration 176 / 300: loss 0.597677\n",
      "iteration 176 / 300: loss 0.600953\n",
      "iteration 176 / 300: loss 0.597422\n",
      "iteration 176 / 300: loss 0.598776\n",
      "iteration 176 / 300: loss 0.587806\n",
      "iteration 176 / 300: loss 0.600499\n",
      "iteration 176 / 300: loss 0.599650\n",
      "iteration 176 / 300: loss 0.617540\n",
      "iteration 176 / 300: loss 0.598875\n",
      "iteration 176 / 300: loss 0.600801\n",
      "iteration 176 / 300: loss 0.605305\n",
      "iteration 176 / 300: loss 0.598592\n",
      "iteration 176 / 300: loss 0.591474\n",
      "iteration 176 / 300: loss 0.580382\n",
      "iteration 176 / 300: loss 0.598221\n",
      "iteration 176 / 300: loss 0.611685\n",
      "iteration 176 / 300: loss 0.613219\n",
      "iteration 176 / 300: loss 0.582214\n",
      "iteration 176 / 300: loss 0.601955\n",
      "iteration 176 / 300: loss 0.608956\n",
      "iteration 176 / 300: loss 0.601794\n",
      "iteration 176 / 300: loss 0.607944\n",
      "iteration 176 / 300: loss 0.620236\n",
      "iteration 176 / 300: loss 0.584817\n",
      "iteration 176 / 300: loss 0.583721\n",
      "iteration 176 / 300: loss 0.628849\n",
      "iteration 176 / 300: loss 0.609399\n",
      "iteration 176 / 300: loss 0.606265\n",
      "iteration 176 / 300: loss 0.599034\n",
      "iteration 176 / 300: loss 0.615876\n",
      "iteration 176 / 300: loss 0.596489\n",
      "iteration 176 / 300: loss 0.581430\n",
      "iteration 176 / 300: loss 0.609807\n",
      "iteration 176 / 300: loss 0.608125\n",
      "iteration 176 / 300: loss 0.598224\n",
      "iteration 176 / 300: loss 0.592022\n",
      "iteration 176 / 300: loss 0.611031\n",
      "iteration 176 / 300: loss 0.598550\n",
      "iteration 176 / 300: loss 0.581382\n",
      "iteration 176 / 300: loss 0.609580\n",
      "iteration 177 / 300: loss 0.578384\n",
      "iteration 177 / 300: loss 0.596214\n",
      "iteration 177 / 300: loss 0.569455\n",
      "iteration 177 / 300: loss 0.597849\n",
      "iteration 177 / 300: loss 0.598940\n",
      "iteration 177 / 300: loss 0.603876\n",
      "iteration 177 / 300: loss 0.615261\n",
      "iteration 177 / 300: loss 0.588227\n",
      "iteration 177 / 300: loss 0.627171\n",
      "iteration 177 / 300: loss 0.592600\n",
      "iteration 177 / 300: loss 0.621500\n",
      "iteration 177 / 300: loss 0.593093\n",
      "iteration 177 / 300: loss 0.600541\n",
      "iteration 177 / 300: loss 0.571000\n",
      "iteration 177 / 300: loss 0.592911\n",
      "iteration 177 / 300: loss 0.600043\n",
      "iteration 177 / 300: loss 0.598053\n",
      "iteration 177 / 300: loss 0.583712\n",
      "iteration 177 / 300: loss 0.614355\n",
      "iteration 177 / 300: loss 0.591285\n",
      "iteration 177 / 300: loss 0.591391\n",
      "iteration 177 / 300: loss 0.594005\n",
      "iteration 177 / 300: loss 0.596735\n",
      "iteration 177 / 300: loss 0.596712\n",
      "iteration 177 / 300: loss 0.611735\n",
      "iteration 177 / 300: loss 0.607258\n",
      "iteration 177 / 300: loss 0.597031\n",
      "iteration 177 / 300: loss 0.596301\n",
      "iteration 177 / 300: loss 0.627391\n",
      "iteration 177 / 300: loss 0.601584\n",
      "iteration 177 / 300: loss 0.599923\n",
      "iteration 177 / 300: loss 0.621952\n",
      "iteration 177 / 300: loss 0.581435\n",
      "iteration 177 / 300: loss 0.599604\n",
      "iteration 177 / 300: loss 0.591182\n",
      "iteration 177 / 300: loss 0.599919\n",
      "iteration 177 / 300: loss 0.596015\n",
      "iteration 177 / 300: loss 0.590760\n",
      "iteration 177 / 300: loss 0.591961\n",
      "iteration 177 / 300: loss 0.615468\n",
      "iteration 177 / 300: loss 0.621360\n",
      "iteration 177 / 300: loss 0.587267\n",
      "iteration 177 / 300: loss 0.582483\n",
      "iteration 177 / 300: loss 0.585572\n",
      "iteration 177 / 300: loss 0.603666\n",
      "iteration 177 / 300: loss 0.585192\n",
      "iteration 177 / 300: loss 0.578880\n",
      "iteration 177 / 300: loss 0.576418\n",
      "iteration 177 / 300: loss 0.574097\n",
      "iteration 177 / 300: loss 0.600500\n",
      "iteration 177 / 300: loss 0.584490\n",
      "iteration 177 / 300: loss 0.584834\n",
      "iteration 177 / 300: loss 0.568323\n",
      "iteration 177 / 300: loss 0.592025\n",
      "iteration 177 / 300: loss 0.612116\n",
      "iteration 177 / 300: loss 0.608923\n",
      "iteration 177 / 300: loss 0.607613\n",
      "iteration 177 / 300: loss 0.595533\n",
      "iteration 177 / 300: loss 0.592837\n",
      "iteration 177 / 300: loss 0.597988\n",
      "iteration 177 / 300: loss 0.597677\n",
      "iteration 177 / 300: loss 0.600953\n",
      "iteration 177 / 300: loss 0.597422\n",
      "iteration 177 / 300: loss 0.598776\n",
      "iteration 177 / 300: loss 0.587806\n",
      "iteration 177 / 300: loss 0.600499\n",
      "iteration 177 / 300: loss 0.599650\n",
      "iteration 177 / 300: loss 0.617540\n",
      "iteration 177 / 300: loss 0.598875\n",
      "iteration 177 / 300: loss 0.600801\n",
      "iteration 177 / 300: loss 0.605305\n",
      "iteration 177 / 300: loss 0.598592\n",
      "iteration 177 / 300: loss 0.591474\n",
      "iteration 177 / 300: loss 0.580382\n",
      "iteration 177 / 300: loss 0.598221\n",
      "iteration 177 / 300: loss 0.611685\n",
      "iteration 177 / 300: loss 0.613219\n",
      "iteration 177 / 300: loss 0.582214\n",
      "iteration 177 / 300: loss 0.601955\n",
      "iteration 177 / 300: loss 0.608956\n",
      "iteration 177 / 300: loss 0.601794\n",
      "iteration 177 / 300: loss 0.607944\n",
      "iteration 177 / 300: loss 0.620236\n",
      "iteration 177 / 300: loss 0.584817\n",
      "iteration 177 / 300: loss 0.583721\n",
      "iteration 177 / 300: loss 0.628849\n",
      "iteration 177 / 300: loss 0.609399\n",
      "iteration 177 / 300: loss 0.606265\n",
      "iteration 177 / 300: loss 0.599034\n",
      "iteration 177 / 300: loss 0.615876\n",
      "iteration 177 / 300: loss 0.596489\n",
      "iteration 177 / 300: loss 0.581430\n",
      "iteration 177 / 300: loss 0.609807\n",
      "iteration 177 / 300: loss 0.608125\n",
      "iteration 177 / 300: loss 0.598224\n",
      "iteration 177 / 300: loss 0.592022\n",
      "iteration 177 / 300: loss 0.611031\n",
      "iteration 177 / 300: loss 0.598550\n",
      "iteration 177 / 300: loss 0.581382\n",
      "iteration 177 / 300: loss 0.609580\n",
      "iteration 178 / 300: loss 0.578384\n",
      "iteration 178 / 300: loss 0.596214\n",
      "iteration 178 / 300: loss 0.569455\n",
      "iteration 178 / 300: loss 0.597849\n",
      "iteration 178 / 300: loss 0.598940\n",
      "iteration 178 / 300: loss 0.603876\n",
      "iteration 178 / 300: loss 0.615261\n",
      "iteration 178 / 300: loss 0.588227\n",
      "iteration 178 / 300: loss 0.627171\n",
      "iteration 178 / 300: loss 0.592600\n",
      "iteration 178 / 300: loss 0.621500\n",
      "iteration 178 / 300: loss 0.593093\n",
      "iteration 178 / 300: loss 0.600541\n",
      "iteration 178 / 300: loss 0.571000\n",
      "iteration 178 / 300: loss 0.592911\n",
      "iteration 178 / 300: loss 0.600043\n",
      "iteration 178 / 300: loss 0.598053\n",
      "iteration 178 / 300: loss 0.583712\n",
      "iteration 178 / 300: loss 0.614355\n",
      "iteration 178 / 300: loss 0.591285\n",
      "iteration 178 / 300: loss 0.591391\n",
      "iteration 178 / 300: loss 0.594005\n",
      "iteration 178 / 300: loss 0.596735\n",
      "iteration 178 / 300: loss 0.596712\n",
      "iteration 178 / 300: loss 0.611735\n",
      "iteration 178 / 300: loss 0.607258\n",
      "iteration 178 / 300: loss 0.597031\n",
      "iteration 178 / 300: loss 0.596301\n",
      "iteration 178 / 300: loss 0.627391\n",
      "iteration 178 / 300: loss 0.601584\n",
      "iteration 178 / 300: loss 0.599923\n",
      "iteration 178 / 300: loss 0.621952\n",
      "iteration 178 / 300: loss 0.581435\n",
      "iteration 178 / 300: loss 0.599604\n",
      "iteration 178 / 300: loss 0.591182\n",
      "iteration 178 / 300: loss 0.599919\n",
      "iteration 178 / 300: loss 0.596015\n",
      "iteration 178 / 300: loss 0.590760\n",
      "iteration 178 / 300: loss 0.591961\n",
      "iteration 178 / 300: loss 0.615468\n",
      "iteration 178 / 300: loss 0.621360\n",
      "iteration 178 / 300: loss 0.587267\n",
      "iteration 178 / 300: loss 0.582483\n",
      "iteration 178 / 300: loss 0.585572\n",
      "iteration 178 / 300: loss 0.603666\n",
      "iteration 178 / 300: loss 0.585192\n",
      "iteration 178 / 300: loss 0.578880\n",
      "iteration 178 / 300: loss 0.576418\n",
      "iteration 178 / 300: loss 0.574097\n",
      "iteration 178 / 300: loss 0.600500\n",
      "iteration 178 / 300: loss 0.584490\n",
      "iteration 178 / 300: loss 0.584834\n",
      "iteration 178 / 300: loss 0.568323\n",
      "iteration 178 / 300: loss 0.592025\n",
      "iteration 178 / 300: loss 0.612116\n",
      "iteration 178 / 300: loss 0.608923\n",
      "iteration 178 / 300: loss 0.607613\n",
      "iteration 178 / 300: loss 0.595533\n",
      "iteration 178 / 300: loss 0.592837\n",
      "iteration 178 / 300: loss 0.597988\n",
      "iteration 178 / 300: loss 0.597677\n",
      "iteration 178 / 300: loss 0.600953\n",
      "iteration 178 / 300: loss 0.597422\n",
      "iteration 178 / 300: loss 0.598776\n",
      "iteration 178 / 300: loss 0.587806\n",
      "iteration 178 / 300: loss 0.600499\n",
      "iteration 178 / 300: loss 0.599650\n",
      "iteration 178 / 300: loss 0.617540\n",
      "iteration 178 / 300: loss 0.598875\n",
      "iteration 178 / 300: loss 0.600801\n",
      "iteration 178 / 300: loss 0.605305\n",
      "iteration 178 / 300: loss 0.598592\n",
      "iteration 178 / 300: loss 0.591474\n",
      "iteration 178 / 300: loss 0.580382\n",
      "iteration 178 / 300: loss 0.598221\n",
      "iteration 178 / 300: loss 0.611685\n",
      "iteration 178 / 300: loss 0.613219\n",
      "iteration 178 / 300: loss 0.582214\n",
      "iteration 178 / 300: loss 0.601955\n",
      "iteration 178 / 300: loss 0.608956\n",
      "iteration 178 / 300: loss 0.601794\n",
      "iteration 178 / 300: loss 0.607944\n",
      "iteration 178 / 300: loss 0.620236\n",
      "iteration 178 / 300: loss 0.584817\n",
      "iteration 178 / 300: loss 0.583721\n",
      "iteration 178 / 300: loss 0.628849\n",
      "iteration 178 / 300: loss 0.609399\n",
      "iteration 178 / 300: loss 0.606265\n",
      "iteration 178 / 300: loss 0.599034\n",
      "iteration 178 / 300: loss 0.615876\n",
      "iteration 178 / 300: loss 0.596489\n",
      "iteration 178 / 300: loss 0.581430\n",
      "iteration 178 / 300: loss 0.609807\n",
      "iteration 178 / 300: loss 0.608125\n",
      "iteration 178 / 300: loss 0.598224\n",
      "iteration 178 / 300: loss 0.592022\n",
      "iteration 178 / 300: loss 0.611031\n",
      "iteration 178 / 300: loss 0.598550\n",
      "iteration 178 / 300: loss 0.581382\n",
      "iteration 178 / 300: loss 0.609580\n",
      "iteration 179 / 300: loss 0.578384\n",
      "iteration 179 / 300: loss 0.596214\n",
      "iteration 179 / 300: loss 0.569455\n",
      "iteration 179 / 300: loss 0.597849\n",
      "iteration 179 / 300: loss 0.598940\n",
      "iteration 179 / 300: loss 0.603876\n",
      "iteration 179 / 300: loss 0.615261\n",
      "iteration 179 / 300: loss 0.588227\n",
      "iteration 179 / 300: loss 0.627171\n",
      "iteration 179 / 300: loss 0.592600\n",
      "iteration 179 / 300: loss 0.621500\n",
      "iteration 179 / 300: loss 0.593093\n",
      "iteration 179 / 300: loss 0.600541\n",
      "iteration 179 / 300: loss 0.571000\n",
      "iteration 179 / 300: loss 0.592911\n",
      "iteration 179 / 300: loss 0.600043\n",
      "iteration 179 / 300: loss 0.598053\n",
      "iteration 179 / 300: loss 0.583712\n",
      "iteration 179 / 300: loss 0.614355\n",
      "iteration 179 / 300: loss 0.591285\n",
      "iteration 179 / 300: loss 0.591391\n",
      "iteration 179 / 300: loss 0.594005\n",
      "iteration 179 / 300: loss 0.596735\n",
      "iteration 179 / 300: loss 0.596712\n",
      "iteration 179 / 300: loss 0.611735\n",
      "iteration 179 / 300: loss 0.607258\n",
      "iteration 179 / 300: loss 0.597031\n",
      "iteration 179 / 300: loss 0.596301\n",
      "iteration 179 / 300: loss 0.627391\n",
      "iteration 179 / 300: loss 0.601584\n",
      "iteration 179 / 300: loss 0.599923\n",
      "iteration 179 / 300: loss 0.621952\n",
      "iteration 179 / 300: loss 0.581435\n",
      "iteration 179 / 300: loss 0.599604\n",
      "iteration 179 / 300: loss 0.591182\n",
      "iteration 179 / 300: loss 0.599919\n",
      "iteration 179 / 300: loss 0.596015\n",
      "iteration 179 / 300: loss 0.590760\n",
      "iteration 179 / 300: loss 0.591961\n",
      "iteration 179 / 300: loss 0.615468\n",
      "iteration 179 / 300: loss 0.621360\n",
      "iteration 179 / 300: loss 0.587267\n",
      "iteration 179 / 300: loss 0.582483\n",
      "iteration 179 / 300: loss 0.585572\n",
      "iteration 179 / 300: loss 0.603666\n",
      "iteration 179 / 300: loss 0.585192\n",
      "iteration 179 / 300: loss 0.578880\n",
      "iteration 179 / 300: loss 0.576418\n",
      "iteration 179 / 300: loss 0.574097\n",
      "iteration 179 / 300: loss 0.600500\n",
      "iteration 179 / 300: loss 0.584490\n",
      "iteration 179 / 300: loss 0.584834\n",
      "iteration 179 / 300: loss 0.568323\n",
      "iteration 179 / 300: loss 0.592025\n",
      "iteration 179 / 300: loss 0.612116\n",
      "iteration 179 / 300: loss 0.608923\n",
      "iteration 179 / 300: loss 0.607613\n",
      "iteration 179 / 300: loss 0.595533\n",
      "iteration 179 / 300: loss 0.592837\n",
      "iteration 179 / 300: loss 0.597988\n",
      "iteration 179 / 300: loss 0.597677\n",
      "iteration 179 / 300: loss 0.600953\n",
      "iteration 179 / 300: loss 0.597422\n",
      "iteration 179 / 300: loss 0.598776\n",
      "iteration 179 / 300: loss 0.587806\n",
      "iteration 179 / 300: loss 0.600499\n",
      "iteration 179 / 300: loss 0.599650\n",
      "iteration 179 / 300: loss 0.617540\n",
      "iteration 179 / 300: loss 0.598875\n",
      "iteration 179 / 300: loss 0.600801\n",
      "iteration 179 / 300: loss 0.605305\n",
      "iteration 179 / 300: loss 0.598592\n",
      "iteration 179 / 300: loss 0.591474\n",
      "iteration 179 / 300: loss 0.580382\n",
      "iteration 179 / 300: loss 0.598221\n",
      "iteration 179 / 300: loss 0.611685\n",
      "iteration 179 / 300: loss 0.613219\n",
      "iteration 179 / 300: loss 0.582214\n",
      "iteration 179 / 300: loss 0.601955\n",
      "iteration 179 / 300: loss 0.608956\n",
      "iteration 179 / 300: loss 0.601794\n",
      "iteration 179 / 300: loss 0.607944\n",
      "iteration 179 / 300: loss 0.620236\n",
      "iteration 179 / 300: loss 0.584817\n",
      "iteration 179 / 300: loss 0.583721\n",
      "iteration 179 / 300: loss 0.628849\n",
      "iteration 179 / 300: loss 0.609399\n",
      "iteration 179 / 300: loss 0.606265\n",
      "iteration 179 / 300: loss 0.599034\n",
      "iteration 179 / 300: loss 0.615876\n",
      "iteration 179 / 300: loss 0.596489\n",
      "iteration 179 / 300: loss 0.581430\n",
      "iteration 179 / 300: loss 0.609807\n",
      "iteration 179 / 300: loss 0.608125\n",
      "iteration 179 / 300: loss 0.598224\n",
      "iteration 179 / 300: loss 0.592022\n",
      "iteration 179 / 300: loss 0.611031\n",
      "iteration 179 / 300: loss 0.598550\n",
      "iteration 179 / 300: loss 0.581382\n",
      "iteration 179 / 300: loss 0.609580\n",
      "iteration 180 / 300: loss 0.578384\n",
      "iteration 180 / 300: loss 0.596214\n",
      "iteration 180 / 300: loss 0.569455\n",
      "iteration 180 / 300: loss 0.597849\n",
      "iteration 180 / 300: loss 0.598940\n",
      "iteration 180 / 300: loss 0.603876\n",
      "iteration 180 / 300: loss 0.615261\n",
      "iteration 180 / 300: loss 0.588227\n",
      "iteration 180 / 300: loss 0.627171\n",
      "iteration 180 / 300: loss 0.592600\n",
      "iteration 180 / 300: loss 0.621500\n",
      "iteration 180 / 300: loss 0.593093\n",
      "iteration 180 / 300: loss 0.600541\n",
      "iteration 180 / 300: loss 0.571000\n",
      "iteration 180 / 300: loss 0.592911\n",
      "iteration 180 / 300: loss 0.600043\n",
      "iteration 180 / 300: loss 0.598053\n",
      "iteration 180 / 300: loss 0.583712\n",
      "iteration 180 / 300: loss 0.614355\n",
      "iteration 180 / 300: loss 0.591285\n",
      "iteration 180 / 300: loss 0.591391\n",
      "iteration 180 / 300: loss 0.594005\n",
      "iteration 180 / 300: loss 0.596735\n",
      "iteration 180 / 300: loss 0.596712\n",
      "iteration 180 / 300: loss 0.611735\n",
      "iteration 180 / 300: loss 0.607258\n",
      "iteration 180 / 300: loss 0.597031\n",
      "iteration 180 / 300: loss 0.596301\n",
      "iteration 180 / 300: loss 0.627391\n",
      "iteration 180 / 300: loss 0.601584\n",
      "iteration 180 / 300: loss 0.599923\n",
      "iteration 180 / 300: loss 0.621952\n",
      "iteration 180 / 300: loss 0.581435\n",
      "iteration 180 / 300: loss 0.599604\n",
      "iteration 180 / 300: loss 0.591182\n",
      "iteration 180 / 300: loss 0.599919\n",
      "iteration 180 / 300: loss 0.596015\n",
      "iteration 180 / 300: loss 0.590760\n",
      "iteration 180 / 300: loss 0.591961\n",
      "iteration 180 / 300: loss 0.615468\n",
      "iteration 180 / 300: loss 0.621360\n",
      "iteration 180 / 300: loss 0.587267\n",
      "iteration 180 / 300: loss 0.582483\n",
      "iteration 180 / 300: loss 0.585572\n",
      "iteration 180 / 300: loss 0.603666\n",
      "iteration 180 / 300: loss 0.585192\n",
      "iteration 180 / 300: loss 0.578880\n",
      "iteration 180 / 300: loss 0.576418\n",
      "iteration 180 / 300: loss 0.574097\n",
      "iteration 180 / 300: loss 0.600500\n",
      "iteration 180 / 300: loss 0.584490\n",
      "iteration 180 / 300: loss 0.584834\n",
      "iteration 180 / 300: loss 0.568323\n",
      "iteration 180 / 300: loss 0.592025\n",
      "iteration 180 / 300: loss 0.612116\n",
      "iteration 180 / 300: loss 0.608923\n",
      "iteration 180 / 300: loss 0.607613\n",
      "iteration 180 / 300: loss 0.595533\n",
      "iteration 180 / 300: loss 0.592837\n",
      "iteration 180 / 300: loss 0.597988\n",
      "iteration 180 / 300: loss 0.597677\n",
      "iteration 180 / 300: loss 0.600953\n",
      "iteration 180 / 300: loss 0.597422\n",
      "iteration 180 / 300: loss 0.598776\n",
      "iteration 180 / 300: loss 0.587806\n",
      "iteration 180 / 300: loss 0.600499\n",
      "iteration 180 / 300: loss 0.599650\n",
      "iteration 180 / 300: loss 0.617540\n",
      "iteration 180 / 300: loss 0.598875\n",
      "iteration 180 / 300: loss 0.600801\n",
      "iteration 180 / 300: loss 0.605305\n",
      "iteration 180 / 300: loss 0.598592\n",
      "iteration 180 / 300: loss 0.591474\n",
      "iteration 180 / 300: loss 0.580382\n",
      "iteration 180 / 300: loss 0.598221\n",
      "iteration 180 / 300: loss 0.611685\n",
      "iteration 180 / 300: loss 0.613219\n",
      "iteration 180 / 300: loss 0.582214\n",
      "iteration 180 / 300: loss 0.601955\n",
      "iteration 180 / 300: loss 0.608956\n",
      "iteration 180 / 300: loss 0.601794\n",
      "iteration 180 / 300: loss 0.607944\n",
      "iteration 180 / 300: loss 0.620236\n",
      "iteration 180 / 300: loss 0.584817\n",
      "iteration 180 / 300: loss 0.583721\n",
      "iteration 180 / 300: loss 0.628849\n",
      "iteration 180 / 300: loss 0.609399\n",
      "iteration 180 / 300: loss 0.606265\n",
      "iteration 180 / 300: loss 0.599034\n",
      "iteration 180 / 300: loss 0.615876\n",
      "iteration 180 / 300: loss 0.596489\n",
      "iteration 180 / 300: loss 0.581430\n",
      "iteration 180 / 300: loss 0.609807\n",
      "iteration 180 / 300: loss 0.608125\n",
      "iteration 180 / 300: loss 0.598224\n",
      "iteration 180 / 300: loss 0.592022\n",
      "iteration 180 / 300: loss 0.611031\n",
      "iteration 180 / 300: loss 0.598550\n",
      "iteration 180 / 300: loss 0.581382\n",
      "iteration 180 / 300: loss 0.609580\n",
      "iteration 181 / 300: loss 0.578384\n",
      "iteration 181 / 300: loss 0.596214\n",
      "iteration 181 / 300: loss 0.569455\n",
      "iteration 181 / 300: loss 0.597849\n",
      "iteration 181 / 300: loss 0.598940\n",
      "iteration 181 / 300: loss 0.603876\n",
      "iteration 181 / 300: loss 0.615261\n",
      "iteration 181 / 300: loss 0.588227\n",
      "iteration 181 / 300: loss 0.627171\n",
      "iteration 181 / 300: loss 0.592600\n",
      "iteration 181 / 300: loss 0.621500\n",
      "iteration 181 / 300: loss 0.593093\n",
      "iteration 181 / 300: loss 0.600541\n",
      "iteration 181 / 300: loss 0.571000\n",
      "iteration 181 / 300: loss 0.592911\n",
      "iteration 181 / 300: loss 0.600043\n",
      "iteration 181 / 300: loss 0.598053\n",
      "iteration 181 / 300: loss 0.583712\n",
      "iteration 181 / 300: loss 0.614355\n",
      "iteration 181 / 300: loss 0.591285\n",
      "iteration 181 / 300: loss 0.591391\n",
      "iteration 181 / 300: loss 0.594005\n",
      "iteration 181 / 300: loss 0.596735\n",
      "iteration 181 / 300: loss 0.596712\n",
      "iteration 181 / 300: loss 0.611735\n",
      "iteration 181 / 300: loss 0.607258\n",
      "iteration 181 / 300: loss 0.597031\n",
      "iteration 181 / 300: loss 0.596301\n",
      "iteration 181 / 300: loss 0.627391\n",
      "iteration 181 / 300: loss 0.601584\n",
      "iteration 181 / 300: loss 0.599923\n",
      "iteration 181 / 300: loss 0.621952\n",
      "iteration 181 / 300: loss 0.581435\n",
      "iteration 181 / 300: loss 0.599604\n",
      "iteration 181 / 300: loss 0.591182\n",
      "iteration 181 / 300: loss 0.599919\n",
      "iteration 181 / 300: loss 0.596015\n",
      "iteration 181 / 300: loss 0.590760\n",
      "iteration 181 / 300: loss 0.591961\n",
      "iteration 181 / 300: loss 0.615468\n",
      "iteration 181 / 300: loss 0.621360\n",
      "iteration 181 / 300: loss 0.587267\n",
      "iteration 181 / 300: loss 0.582483\n",
      "iteration 181 / 300: loss 0.585572\n",
      "iteration 181 / 300: loss 0.603666\n",
      "iteration 181 / 300: loss 0.585192\n",
      "iteration 181 / 300: loss 0.578880\n",
      "iteration 181 / 300: loss 0.576418\n",
      "iteration 181 / 300: loss 0.574097\n",
      "iteration 181 / 300: loss 0.600500\n",
      "iteration 181 / 300: loss 0.584490\n",
      "iteration 181 / 300: loss 0.584834\n",
      "iteration 181 / 300: loss 0.568323\n",
      "iteration 181 / 300: loss 0.592025\n",
      "iteration 181 / 300: loss 0.612116\n",
      "iteration 181 / 300: loss 0.608923\n",
      "iteration 181 / 300: loss 0.607613\n",
      "iteration 181 / 300: loss 0.595533\n",
      "iteration 181 / 300: loss 0.592837\n",
      "iteration 181 / 300: loss 0.597988\n",
      "iteration 181 / 300: loss 0.597677\n",
      "iteration 181 / 300: loss 0.600953\n",
      "iteration 181 / 300: loss 0.597422\n",
      "iteration 181 / 300: loss 0.598776\n",
      "iteration 181 / 300: loss 0.587806\n",
      "iteration 181 / 300: loss 0.600499\n",
      "iteration 181 / 300: loss 0.599650\n",
      "iteration 181 / 300: loss 0.617540\n",
      "iteration 181 / 300: loss 0.598875\n",
      "iteration 181 / 300: loss 0.600801\n",
      "iteration 181 / 300: loss 0.605305\n",
      "iteration 181 / 300: loss 0.598592\n",
      "iteration 181 / 300: loss 0.591474\n",
      "iteration 181 / 300: loss 0.580382\n",
      "iteration 181 / 300: loss 0.598221\n",
      "iteration 181 / 300: loss 0.611685\n",
      "iteration 181 / 300: loss 0.613219\n",
      "iteration 181 / 300: loss 0.582214\n",
      "iteration 181 / 300: loss 0.601955\n",
      "iteration 181 / 300: loss 0.608956\n",
      "iteration 181 / 300: loss 0.601794\n",
      "iteration 181 / 300: loss 0.607944\n",
      "iteration 181 / 300: loss 0.620236\n",
      "iteration 181 / 300: loss 0.584817\n",
      "iteration 181 / 300: loss 0.583721\n",
      "iteration 181 / 300: loss 0.628849\n",
      "iteration 181 / 300: loss 0.609399\n",
      "iteration 181 / 300: loss 0.606265\n",
      "iteration 181 / 300: loss 0.599034\n",
      "iteration 181 / 300: loss 0.615876\n",
      "iteration 181 / 300: loss 0.596489\n",
      "iteration 181 / 300: loss 0.581430\n",
      "iteration 181 / 300: loss 0.609807\n",
      "iteration 181 / 300: loss 0.608125\n",
      "iteration 181 / 300: loss 0.598224\n",
      "iteration 181 / 300: loss 0.592022\n",
      "iteration 181 / 300: loss 0.611031\n",
      "iteration 181 / 300: loss 0.598550\n",
      "iteration 181 / 300: loss 0.581382\n",
      "iteration 181 / 300: loss 0.609580\n",
      "iteration 182 / 300: loss 0.578384\n",
      "iteration 182 / 300: loss 0.596214\n",
      "iteration 182 / 300: loss 0.569455\n",
      "iteration 182 / 300: loss 0.597849\n",
      "iteration 182 / 300: loss 0.598940\n",
      "iteration 182 / 300: loss 0.603876\n",
      "iteration 182 / 300: loss 0.615261\n",
      "iteration 182 / 300: loss 0.588227\n",
      "iteration 182 / 300: loss 0.627171\n",
      "iteration 182 / 300: loss 0.592600\n",
      "iteration 182 / 300: loss 0.621500\n",
      "iteration 182 / 300: loss 0.593093\n",
      "iteration 182 / 300: loss 0.600541\n",
      "iteration 182 / 300: loss 0.571000\n",
      "iteration 182 / 300: loss 0.592911\n",
      "iteration 182 / 300: loss 0.600043\n",
      "iteration 182 / 300: loss 0.598053\n",
      "iteration 182 / 300: loss 0.583712\n",
      "iteration 182 / 300: loss 0.614355\n",
      "iteration 182 / 300: loss 0.591285\n",
      "iteration 182 / 300: loss 0.591391\n",
      "iteration 182 / 300: loss 0.594005\n",
      "iteration 182 / 300: loss 0.596735\n",
      "iteration 182 / 300: loss 0.596712\n",
      "iteration 182 / 300: loss 0.611735\n",
      "iteration 182 / 300: loss 0.607258\n",
      "iteration 182 / 300: loss 0.597031\n",
      "iteration 182 / 300: loss 0.596301\n",
      "iteration 182 / 300: loss 0.627391\n",
      "iteration 182 / 300: loss 0.601584\n",
      "iteration 182 / 300: loss 0.599923\n",
      "iteration 182 / 300: loss 0.621952\n",
      "iteration 182 / 300: loss 0.581435\n",
      "iteration 182 / 300: loss 0.599604\n",
      "iteration 182 / 300: loss 0.591182\n",
      "iteration 182 / 300: loss 0.599919\n",
      "iteration 182 / 300: loss 0.596015\n",
      "iteration 182 / 300: loss 0.590760\n",
      "iteration 182 / 300: loss 0.591961\n",
      "iteration 182 / 300: loss 0.615468\n",
      "iteration 182 / 300: loss 0.621360\n",
      "iteration 182 / 300: loss 0.587267\n",
      "iteration 182 / 300: loss 0.582483\n",
      "iteration 182 / 300: loss 0.585572\n",
      "iteration 182 / 300: loss 0.603666\n",
      "iteration 182 / 300: loss 0.585192\n",
      "iteration 182 / 300: loss 0.578880\n",
      "iteration 182 / 300: loss 0.576418\n",
      "iteration 182 / 300: loss 0.574097\n",
      "iteration 182 / 300: loss 0.600500\n",
      "iteration 182 / 300: loss 0.584490\n",
      "iteration 182 / 300: loss 0.584834\n",
      "iteration 182 / 300: loss 0.568323\n",
      "iteration 182 / 300: loss 0.592025\n",
      "iteration 182 / 300: loss 0.612116\n",
      "iteration 182 / 300: loss 0.608923\n",
      "iteration 182 / 300: loss 0.607613\n",
      "iteration 182 / 300: loss 0.595533\n",
      "iteration 182 / 300: loss 0.592837\n",
      "iteration 182 / 300: loss 0.597988\n",
      "iteration 182 / 300: loss 0.597677\n",
      "iteration 182 / 300: loss 0.600953\n",
      "iteration 182 / 300: loss 0.597422\n",
      "iteration 182 / 300: loss 0.598776\n",
      "iteration 182 / 300: loss 0.587806\n",
      "iteration 182 / 300: loss 0.600499\n",
      "iteration 182 / 300: loss 0.599650\n",
      "iteration 182 / 300: loss 0.617540\n",
      "iteration 182 / 300: loss 0.598875\n",
      "iteration 182 / 300: loss 0.600801\n",
      "iteration 182 / 300: loss 0.605305\n",
      "iteration 182 / 300: loss 0.598592\n",
      "iteration 182 / 300: loss 0.591474\n",
      "iteration 182 / 300: loss 0.580382\n",
      "iteration 182 / 300: loss 0.598221\n",
      "iteration 182 / 300: loss 0.611685\n",
      "iteration 182 / 300: loss 0.613219\n",
      "iteration 182 / 300: loss 0.582214\n",
      "iteration 182 / 300: loss 0.601955\n",
      "iteration 182 / 300: loss 0.608956\n",
      "iteration 182 / 300: loss 0.601794\n",
      "iteration 182 / 300: loss 0.607944\n",
      "iteration 182 / 300: loss 0.620236\n",
      "iteration 182 / 300: loss 0.584817\n",
      "iteration 182 / 300: loss 0.583721\n",
      "iteration 182 / 300: loss 0.628849\n",
      "iteration 182 / 300: loss 0.609399\n",
      "iteration 182 / 300: loss 0.606265\n",
      "iteration 182 / 300: loss 0.599034\n",
      "iteration 182 / 300: loss 0.615876\n",
      "iteration 182 / 300: loss 0.596489\n",
      "iteration 182 / 300: loss 0.581430\n",
      "iteration 182 / 300: loss 0.609807\n",
      "iteration 182 / 300: loss 0.608125\n",
      "iteration 182 / 300: loss 0.598224\n",
      "iteration 182 / 300: loss 0.592022\n",
      "iteration 182 / 300: loss 0.611031\n",
      "iteration 182 / 300: loss 0.598550\n",
      "iteration 182 / 300: loss 0.581382\n",
      "iteration 182 / 300: loss 0.609580\n",
      "iteration 183 / 300: loss 0.578384\n",
      "iteration 183 / 300: loss 0.596214\n",
      "iteration 183 / 300: loss 0.569455\n",
      "iteration 183 / 300: loss 0.597849\n",
      "iteration 183 / 300: loss 0.598940\n",
      "iteration 183 / 300: loss 0.603876\n",
      "iteration 183 / 300: loss 0.615261\n",
      "iteration 183 / 300: loss 0.588227\n",
      "iteration 183 / 300: loss 0.627171\n",
      "iteration 183 / 300: loss 0.592600\n",
      "iteration 183 / 300: loss 0.621500\n",
      "iteration 183 / 300: loss 0.593093\n",
      "iteration 183 / 300: loss 0.600541\n",
      "iteration 183 / 300: loss 0.571000\n",
      "iteration 183 / 300: loss 0.592911\n",
      "iteration 183 / 300: loss 0.600043\n",
      "iteration 183 / 300: loss 0.598053\n",
      "iteration 183 / 300: loss 0.583712\n",
      "iteration 183 / 300: loss 0.614355\n",
      "iteration 183 / 300: loss 0.591285\n",
      "iteration 183 / 300: loss 0.591391\n",
      "iteration 183 / 300: loss 0.594005\n",
      "iteration 183 / 300: loss 0.596735\n",
      "iteration 183 / 300: loss 0.596712\n",
      "iteration 183 / 300: loss 0.611735\n",
      "iteration 183 / 300: loss 0.607258\n",
      "iteration 183 / 300: loss 0.597031\n",
      "iteration 183 / 300: loss 0.596301\n",
      "iteration 183 / 300: loss 0.627391\n",
      "iteration 183 / 300: loss 0.601584\n",
      "iteration 183 / 300: loss 0.599923\n",
      "iteration 183 / 300: loss 0.621952\n",
      "iteration 183 / 300: loss 0.581435\n",
      "iteration 183 / 300: loss 0.599604\n",
      "iteration 183 / 300: loss 0.591182\n",
      "iteration 183 / 300: loss 0.599919\n",
      "iteration 183 / 300: loss 0.596015\n",
      "iteration 183 / 300: loss 0.590760\n",
      "iteration 183 / 300: loss 0.591961\n",
      "iteration 183 / 300: loss 0.615468\n",
      "iteration 183 / 300: loss 0.621360\n",
      "iteration 183 / 300: loss 0.587267\n",
      "iteration 183 / 300: loss 0.582483\n",
      "iteration 183 / 300: loss 0.585572\n",
      "iteration 183 / 300: loss 0.603666\n",
      "iteration 183 / 300: loss 0.585192\n",
      "iteration 183 / 300: loss 0.578880\n",
      "iteration 183 / 300: loss 0.576418\n",
      "iteration 183 / 300: loss 0.574097\n",
      "iteration 183 / 300: loss 0.600500\n",
      "iteration 183 / 300: loss 0.584490\n",
      "iteration 183 / 300: loss 0.584834\n",
      "iteration 183 / 300: loss 0.568323\n",
      "iteration 183 / 300: loss 0.592025\n",
      "iteration 183 / 300: loss 0.612116\n",
      "iteration 183 / 300: loss 0.608923\n",
      "iteration 183 / 300: loss 0.607613\n",
      "iteration 183 / 300: loss 0.595533\n",
      "iteration 183 / 300: loss 0.592837\n",
      "iteration 183 / 300: loss 0.597988\n",
      "iteration 183 / 300: loss 0.597677\n",
      "iteration 183 / 300: loss 0.600953\n",
      "iteration 183 / 300: loss 0.597422\n",
      "iteration 183 / 300: loss 0.598776\n",
      "iteration 183 / 300: loss 0.587806\n",
      "iteration 183 / 300: loss 0.600499\n",
      "iteration 183 / 300: loss 0.599650\n",
      "iteration 183 / 300: loss 0.617540\n",
      "iteration 183 / 300: loss 0.598875\n",
      "iteration 183 / 300: loss 0.600801\n",
      "iteration 183 / 300: loss 0.605305\n",
      "iteration 183 / 300: loss 0.598592\n",
      "iteration 183 / 300: loss 0.591474\n",
      "iteration 183 / 300: loss 0.580382\n",
      "iteration 183 / 300: loss 0.598221\n",
      "iteration 183 / 300: loss 0.611685\n",
      "iteration 183 / 300: loss 0.613219\n",
      "iteration 183 / 300: loss 0.582214\n",
      "iteration 183 / 300: loss 0.601955\n",
      "iteration 183 / 300: loss 0.608956\n",
      "iteration 183 / 300: loss 0.601794\n",
      "iteration 183 / 300: loss 0.607944\n",
      "iteration 183 / 300: loss 0.620236\n",
      "iteration 183 / 300: loss 0.584817\n",
      "iteration 183 / 300: loss 0.583721\n",
      "iteration 183 / 300: loss 0.628849\n",
      "iteration 183 / 300: loss 0.609399\n",
      "iteration 183 / 300: loss 0.606265\n",
      "iteration 183 / 300: loss 0.599034\n",
      "iteration 183 / 300: loss 0.615876\n",
      "iteration 183 / 300: loss 0.596489\n",
      "iteration 183 / 300: loss 0.581430\n",
      "iteration 183 / 300: loss 0.609807\n",
      "iteration 183 / 300: loss 0.608125\n",
      "iteration 183 / 300: loss 0.598224\n",
      "iteration 183 / 300: loss 0.592022\n",
      "iteration 183 / 300: loss 0.611031\n",
      "iteration 183 / 300: loss 0.598550\n",
      "iteration 183 / 300: loss 0.581382\n",
      "iteration 183 / 300: loss 0.609580\n",
      "iteration 184 / 300: loss 0.578384\n",
      "iteration 184 / 300: loss 0.596214\n",
      "iteration 184 / 300: loss 0.569455\n",
      "iteration 184 / 300: loss 0.597849\n",
      "iteration 184 / 300: loss 0.598940\n",
      "iteration 184 / 300: loss 0.603876\n",
      "iteration 184 / 300: loss 0.615261\n",
      "iteration 184 / 300: loss 0.588227\n",
      "iteration 184 / 300: loss 0.627171\n",
      "iteration 184 / 300: loss 0.592600\n",
      "iteration 184 / 300: loss 0.621500\n",
      "iteration 184 / 300: loss 0.593093\n",
      "iteration 184 / 300: loss 0.600541\n",
      "iteration 184 / 300: loss 0.571000\n",
      "iteration 184 / 300: loss 0.592911\n",
      "iteration 184 / 300: loss 0.600043\n",
      "iteration 184 / 300: loss 0.598053\n",
      "iteration 184 / 300: loss 0.583712\n",
      "iteration 184 / 300: loss 0.614355\n",
      "iteration 184 / 300: loss 0.591285\n",
      "iteration 184 / 300: loss 0.591391\n",
      "iteration 184 / 300: loss 0.594005\n",
      "iteration 184 / 300: loss 0.596735\n",
      "iteration 184 / 300: loss 0.596712\n",
      "iteration 184 / 300: loss 0.611735\n",
      "iteration 184 / 300: loss 0.607258\n",
      "iteration 184 / 300: loss 0.597031\n",
      "iteration 184 / 300: loss 0.596301\n",
      "iteration 184 / 300: loss 0.627391\n",
      "iteration 184 / 300: loss 0.601584\n",
      "iteration 184 / 300: loss 0.599923\n",
      "iteration 184 / 300: loss 0.621952\n",
      "iteration 184 / 300: loss 0.581435\n",
      "iteration 184 / 300: loss 0.599604\n",
      "iteration 184 / 300: loss 0.591182\n",
      "iteration 184 / 300: loss 0.599919\n",
      "iteration 184 / 300: loss 0.596015\n",
      "iteration 184 / 300: loss 0.590760\n",
      "iteration 184 / 300: loss 0.591961\n",
      "iteration 184 / 300: loss 0.615468\n",
      "iteration 184 / 300: loss 0.621360\n",
      "iteration 184 / 300: loss 0.587267\n",
      "iteration 184 / 300: loss 0.582483\n",
      "iteration 184 / 300: loss 0.585572\n",
      "iteration 184 / 300: loss 0.603666\n",
      "iteration 184 / 300: loss 0.585192\n",
      "iteration 184 / 300: loss 0.578880\n",
      "iteration 184 / 300: loss 0.576418\n",
      "iteration 184 / 300: loss 0.574097\n",
      "iteration 184 / 300: loss 0.600500\n",
      "iteration 184 / 300: loss 0.584490\n",
      "iteration 184 / 300: loss 0.584834\n",
      "iteration 184 / 300: loss 0.568323\n",
      "iteration 184 / 300: loss 0.592025\n",
      "iteration 184 / 300: loss 0.612116\n",
      "iteration 184 / 300: loss 0.608923\n",
      "iteration 184 / 300: loss 0.607613\n",
      "iteration 184 / 300: loss 0.595533\n",
      "iteration 184 / 300: loss 0.592837\n",
      "iteration 184 / 300: loss 0.597988\n",
      "iteration 184 / 300: loss 0.597677\n",
      "iteration 184 / 300: loss 0.600953\n",
      "iteration 184 / 300: loss 0.597422\n",
      "iteration 184 / 300: loss 0.598776\n",
      "iteration 184 / 300: loss 0.587806\n",
      "iteration 184 / 300: loss 0.600499\n",
      "iteration 184 / 300: loss 0.599650\n",
      "iteration 184 / 300: loss 0.617540\n",
      "iteration 184 / 300: loss 0.598875\n",
      "iteration 184 / 300: loss 0.600801\n",
      "iteration 184 / 300: loss 0.605305\n",
      "iteration 184 / 300: loss 0.598592\n",
      "iteration 184 / 300: loss 0.591474\n",
      "iteration 184 / 300: loss 0.580382\n",
      "iteration 184 / 300: loss 0.598221\n",
      "iteration 184 / 300: loss 0.611685\n",
      "iteration 184 / 300: loss 0.613219\n",
      "iteration 184 / 300: loss 0.582214\n",
      "iteration 184 / 300: loss 0.601955\n",
      "iteration 184 / 300: loss 0.608956\n",
      "iteration 184 / 300: loss 0.601794\n",
      "iteration 184 / 300: loss 0.607944\n",
      "iteration 184 / 300: loss 0.620236\n",
      "iteration 184 / 300: loss 0.584817\n",
      "iteration 184 / 300: loss 0.583721\n",
      "iteration 184 / 300: loss 0.628849\n",
      "iteration 184 / 300: loss 0.609399\n",
      "iteration 184 / 300: loss 0.606265\n",
      "iteration 184 / 300: loss 0.599034\n",
      "iteration 184 / 300: loss 0.615876\n",
      "iteration 184 / 300: loss 0.596489\n",
      "iteration 184 / 300: loss 0.581430\n",
      "iteration 184 / 300: loss 0.609807\n",
      "iteration 184 / 300: loss 0.608125\n",
      "iteration 184 / 300: loss 0.598224\n",
      "iteration 184 / 300: loss 0.592022\n",
      "iteration 184 / 300: loss 0.611031\n",
      "iteration 184 / 300: loss 0.598550\n",
      "iteration 184 / 300: loss 0.581382\n",
      "iteration 184 / 300: loss 0.609580\n",
      "iteration 185 / 300: loss 0.578384\n",
      "iteration 185 / 300: loss 0.596214\n",
      "iteration 185 / 300: loss 0.569455\n",
      "iteration 185 / 300: loss 0.597849\n",
      "iteration 185 / 300: loss 0.598940\n",
      "iteration 185 / 300: loss 0.603876\n",
      "iteration 185 / 300: loss 0.615261\n",
      "iteration 185 / 300: loss 0.588227\n",
      "iteration 185 / 300: loss 0.627171\n",
      "iteration 185 / 300: loss 0.592600\n",
      "iteration 185 / 300: loss 0.621500\n",
      "iteration 185 / 300: loss 0.593093\n",
      "iteration 185 / 300: loss 0.600541\n",
      "iteration 185 / 300: loss 0.571000\n",
      "iteration 185 / 300: loss 0.592911\n",
      "iteration 185 / 300: loss 0.600043\n",
      "iteration 185 / 300: loss 0.598053\n",
      "iteration 185 / 300: loss 0.583712\n",
      "iteration 185 / 300: loss 0.614355\n",
      "iteration 185 / 300: loss 0.591285\n",
      "iteration 185 / 300: loss 0.591391\n",
      "iteration 185 / 300: loss 0.594005\n",
      "iteration 185 / 300: loss 0.596735\n",
      "iteration 185 / 300: loss 0.596712\n",
      "iteration 185 / 300: loss 0.611735\n",
      "iteration 185 / 300: loss 0.607258\n",
      "iteration 185 / 300: loss 0.597031\n",
      "iteration 185 / 300: loss 0.596301\n",
      "iteration 185 / 300: loss 0.627391\n",
      "iteration 185 / 300: loss 0.601584\n",
      "iteration 185 / 300: loss 0.599923\n",
      "iteration 185 / 300: loss 0.621952\n",
      "iteration 185 / 300: loss 0.581435\n",
      "iteration 185 / 300: loss 0.599604\n",
      "iteration 185 / 300: loss 0.591182\n",
      "iteration 185 / 300: loss 0.599919\n",
      "iteration 185 / 300: loss 0.596015\n",
      "iteration 185 / 300: loss 0.590760\n",
      "iteration 185 / 300: loss 0.591961\n",
      "iteration 185 / 300: loss 0.615468\n",
      "iteration 185 / 300: loss 0.621360\n",
      "iteration 185 / 300: loss 0.587267\n",
      "iteration 185 / 300: loss 0.582483\n",
      "iteration 185 / 300: loss 0.585572\n",
      "iteration 185 / 300: loss 0.603666\n",
      "iteration 185 / 300: loss 0.585192\n",
      "iteration 185 / 300: loss 0.578880\n",
      "iteration 185 / 300: loss 0.576418\n",
      "iteration 185 / 300: loss 0.574097\n",
      "iteration 185 / 300: loss 0.600500\n",
      "iteration 185 / 300: loss 0.584490\n",
      "iteration 185 / 300: loss 0.584834\n",
      "iteration 185 / 300: loss 0.568323\n",
      "iteration 185 / 300: loss 0.592025\n",
      "iteration 185 / 300: loss 0.612116\n",
      "iteration 185 / 300: loss 0.608923\n",
      "iteration 185 / 300: loss 0.607613\n",
      "iteration 185 / 300: loss 0.595533\n",
      "iteration 185 / 300: loss 0.592837\n",
      "iteration 185 / 300: loss 0.597988\n",
      "iteration 185 / 300: loss 0.597677\n",
      "iteration 185 / 300: loss 0.600953\n",
      "iteration 185 / 300: loss 0.597422\n",
      "iteration 185 / 300: loss 0.598776\n",
      "iteration 185 / 300: loss 0.587806\n",
      "iteration 185 / 300: loss 0.600499\n",
      "iteration 185 / 300: loss 0.599650\n",
      "iteration 185 / 300: loss 0.617540\n",
      "iteration 185 / 300: loss 0.598875\n",
      "iteration 185 / 300: loss 0.600801\n",
      "iteration 185 / 300: loss 0.605305\n",
      "iteration 185 / 300: loss 0.598592\n",
      "iteration 185 / 300: loss 0.591474\n",
      "iteration 185 / 300: loss 0.580382\n",
      "iteration 185 / 300: loss 0.598221\n",
      "iteration 185 / 300: loss 0.611685\n",
      "iteration 185 / 300: loss 0.613219\n",
      "iteration 185 / 300: loss 0.582214\n",
      "iteration 185 / 300: loss 0.601955\n",
      "iteration 185 / 300: loss 0.608956\n",
      "iteration 185 / 300: loss 0.601794\n",
      "iteration 185 / 300: loss 0.607944\n",
      "iteration 185 / 300: loss 0.620236\n",
      "iteration 185 / 300: loss 0.584817\n",
      "iteration 185 / 300: loss 0.583721\n",
      "iteration 185 / 300: loss 0.628849\n",
      "iteration 185 / 300: loss 0.609399\n",
      "iteration 185 / 300: loss 0.606265\n",
      "iteration 185 / 300: loss 0.599034\n",
      "iteration 185 / 300: loss 0.615876\n",
      "iteration 185 / 300: loss 0.596489\n",
      "iteration 185 / 300: loss 0.581430\n",
      "iteration 185 / 300: loss 0.609807\n",
      "iteration 185 / 300: loss 0.608125\n",
      "iteration 185 / 300: loss 0.598224\n",
      "iteration 185 / 300: loss 0.592022\n",
      "iteration 185 / 300: loss 0.611031\n",
      "iteration 185 / 300: loss 0.598550\n",
      "iteration 185 / 300: loss 0.581382\n",
      "iteration 185 / 300: loss 0.609580\n",
      "iteration 186 / 300: loss 0.578384\n",
      "iteration 186 / 300: loss 0.596214\n",
      "iteration 186 / 300: loss 0.569455\n",
      "iteration 186 / 300: loss 0.597849\n",
      "iteration 186 / 300: loss 0.598940\n",
      "iteration 186 / 300: loss 0.603876\n",
      "iteration 186 / 300: loss 0.615261\n",
      "iteration 186 / 300: loss 0.588227\n",
      "iteration 186 / 300: loss 0.627171\n",
      "iteration 186 / 300: loss 0.592600\n",
      "iteration 186 / 300: loss 0.621500\n",
      "iteration 186 / 300: loss 0.593093\n",
      "iteration 186 / 300: loss 0.600541\n",
      "iteration 186 / 300: loss 0.571000\n",
      "iteration 186 / 300: loss 0.592911\n",
      "iteration 186 / 300: loss 0.600043\n",
      "iteration 186 / 300: loss 0.598053\n",
      "iteration 186 / 300: loss 0.583712\n",
      "iteration 186 / 300: loss 0.614355\n",
      "iteration 186 / 300: loss 0.591285\n",
      "iteration 186 / 300: loss 0.591391\n",
      "iteration 186 / 300: loss 0.594005\n",
      "iteration 186 / 300: loss 0.596735\n",
      "iteration 186 / 300: loss 0.596712\n",
      "iteration 186 / 300: loss 0.611735\n",
      "iteration 186 / 300: loss 0.607258\n",
      "iteration 186 / 300: loss 0.597031\n",
      "iteration 186 / 300: loss 0.596301\n",
      "iteration 186 / 300: loss 0.627391\n",
      "iteration 186 / 300: loss 0.601584\n",
      "iteration 186 / 300: loss 0.599923\n",
      "iteration 186 / 300: loss 0.621952\n",
      "iteration 186 / 300: loss 0.581435\n",
      "iteration 186 / 300: loss 0.599604\n",
      "iteration 186 / 300: loss 0.591182\n",
      "iteration 186 / 300: loss 0.599919\n",
      "iteration 186 / 300: loss 0.596015\n",
      "iteration 186 / 300: loss 0.590760\n",
      "iteration 186 / 300: loss 0.591961\n",
      "iteration 186 / 300: loss 0.615468\n",
      "iteration 186 / 300: loss 0.621360\n",
      "iteration 186 / 300: loss 0.587267\n",
      "iteration 186 / 300: loss 0.582483\n",
      "iteration 186 / 300: loss 0.585572\n",
      "iteration 186 / 300: loss 0.603666\n",
      "iteration 186 / 300: loss 0.585192\n",
      "iteration 186 / 300: loss 0.578880\n",
      "iteration 186 / 300: loss 0.576418\n",
      "iteration 186 / 300: loss 0.574097\n",
      "iteration 186 / 300: loss 0.600500\n",
      "iteration 186 / 300: loss 0.584490\n",
      "iteration 186 / 300: loss 0.584834\n",
      "iteration 186 / 300: loss 0.568323\n",
      "iteration 186 / 300: loss 0.592025\n",
      "iteration 186 / 300: loss 0.612116\n",
      "iteration 186 / 300: loss 0.608923\n",
      "iteration 186 / 300: loss 0.607613\n",
      "iteration 186 / 300: loss 0.595533\n",
      "iteration 186 / 300: loss 0.592837\n",
      "iteration 186 / 300: loss 0.597988\n",
      "iteration 186 / 300: loss 0.597677\n",
      "iteration 186 / 300: loss 0.600953\n",
      "iteration 186 / 300: loss 0.597422\n",
      "iteration 186 / 300: loss 0.598776\n",
      "iteration 186 / 300: loss 0.587806\n",
      "iteration 186 / 300: loss 0.600499\n",
      "iteration 186 / 300: loss 0.599650\n",
      "iteration 186 / 300: loss 0.617540\n",
      "iteration 186 / 300: loss 0.598875\n",
      "iteration 186 / 300: loss 0.600801\n",
      "iteration 186 / 300: loss 0.605305\n",
      "iteration 186 / 300: loss 0.598592\n",
      "iteration 186 / 300: loss 0.591474\n",
      "iteration 186 / 300: loss 0.580382\n",
      "iteration 186 / 300: loss 0.598221\n",
      "iteration 186 / 300: loss 0.611685\n",
      "iteration 186 / 300: loss 0.613219\n",
      "iteration 186 / 300: loss 0.582214\n",
      "iteration 186 / 300: loss 0.601955\n",
      "iteration 186 / 300: loss 0.608956\n",
      "iteration 186 / 300: loss 0.601794\n",
      "iteration 186 / 300: loss 0.607944\n",
      "iteration 186 / 300: loss 0.620236\n",
      "iteration 186 / 300: loss 0.584817\n",
      "iteration 186 / 300: loss 0.583721\n",
      "iteration 186 / 300: loss 0.628849\n",
      "iteration 186 / 300: loss 0.609399\n",
      "iteration 186 / 300: loss 0.606265\n",
      "iteration 186 / 300: loss 0.599034\n",
      "iteration 186 / 300: loss 0.615876\n",
      "iteration 186 / 300: loss 0.596489\n",
      "iteration 186 / 300: loss 0.581430\n",
      "iteration 186 / 300: loss 0.609807\n",
      "iteration 186 / 300: loss 0.608125\n",
      "iteration 186 / 300: loss 0.598224\n",
      "iteration 186 / 300: loss 0.592022\n",
      "iteration 186 / 300: loss 0.611031\n",
      "iteration 186 / 300: loss 0.598550\n",
      "iteration 186 / 300: loss 0.581382\n",
      "iteration 186 / 300: loss 0.609580\n",
      "iteration 187 / 300: loss 0.578384\n",
      "iteration 187 / 300: loss 0.596214\n",
      "iteration 187 / 300: loss 0.569455\n",
      "iteration 187 / 300: loss 0.597849\n",
      "iteration 187 / 300: loss 0.598940\n",
      "iteration 187 / 300: loss 0.603876\n",
      "iteration 187 / 300: loss 0.615261\n",
      "iteration 187 / 300: loss 0.588227\n",
      "iteration 187 / 300: loss 0.627171\n",
      "iteration 187 / 300: loss 0.592600\n",
      "iteration 187 / 300: loss 0.621500\n",
      "iteration 187 / 300: loss 0.593093\n",
      "iteration 187 / 300: loss 0.600541\n",
      "iteration 187 / 300: loss 0.571000\n",
      "iteration 187 / 300: loss 0.592911\n",
      "iteration 187 / 300: loss 0.600043\n",
      "iteration 187 / 300: loss 0.598053\n",
      "iteration 187 / 300: loss 0.583712\n",
      "iteration 187 / 300: loss 0.614355\n",
      "iteration 187 / 300: loss 0.591285\n",
      "iteration 187 / 300: loss 0.591391\n",
      "iteration 187 / 300: loss 0.594005\n",
      "iteration 187 / 300: loss 0.596735\n",
      "iteration 187 / 300: loss 0.596712\n",
      "iteration 187 / 300: loss 0.611735\n",
      "iteration 187 / 300: loss 0.607258\n",
      "iteration 187 / 300: loss 0.597031\n",
      "iteration 187 / 300: loss 0.596301\n",
      "iteration 187 / 300: loss 0.627391\n",
      "iteration 187 / 300: loss 0.601584\n",
      "iteration 187 / 300: loss 0.599923\n",
      "iteration 187 / 300: loss 0.621952\n",
      "iteration 187 / 300: loss 0.581435\n",
      "iteration 187 / 300: loss 0.599604\n",
      "iteration 187 / 300: loss 0.591182\n",
      "iteration 187 / 300: loss 0.599919\n",
      "iteration 187 / 300: loss 0.596015\n",
      "iteration 187 / 300: loss 0.590760\n",
      "iteration 187 / 300: loss 0.591961\n",
      "iteration 187 / 300: loss 0.615468\n",
      "iteration 187 / 300: loss 0.621360\n",
      "iteration 187 / 300: loss 0.587267\n",
      "iteration 187 / 300: loss 0.582483\n",
      "iteration 187 / 300: loss 0.585572\n",
      "iteration 187 / 300: loss 0.603666\n",
      "iteration 187 / 300: loss 0.585192\n",
      "iteration 187 / 300: loss 0.578880\n",
      "iteration 187 / 300: loss 0.576418\n",
      "iteration 187 / 300: loss 0.574097\n",
      "iteration 187 / 300: loss 0.600500\n",
      "iteration 187 / 300: loss 0.584490\n",
      "iteration 187 / 300: loss 0.584834\n",
      "iteration 187 / 300: loss 0.568323\n",
      "iteration 187 / 300: loss 0.592025\n",
      "iteration 187 / 300: loss 0.612116\n",
      "iteration 187 / 300: loss 0.608923\n",
      "iteration 187 / 300: loss 0.607613\n",
      "iteration 187 / 300: loss 0.595533\n",
      "iteration 187 / 300: loss 0.592837\n",
      "iteration 187 / 300: loss 0.597988\n",
      "iteration 187 / 300: loss 0.597677\n",
      "iteration 187 / 300: loss 0.600953\n",
      "iteration 187 / 300: loss 0.597422\n",
      "iteration 187 / 300: loss 0.598776\n",
      "iteration 187 / 300: loss 0.587806\n",
      "iteration 187 / 300: loss 0.600499\n",
      "iteration 187 / 300: loss 0.599650\n",
      "iteration 187 / 300: loss 0.617540\n",
      "iteration 187 / 300: loss 0.598875\n",
      "iteration 187 / 300: loss 0.600801\n",
      "iteration 187 / 300: loss 0.605305\n",
      "iteration 187 / 300: loss 0.598592\n",
      "iteration 187 / 300: loss 0.591474\n",
      "iteration 187 / 300: loss 0.580382\n",
      "iteration 187 / 300: loss 0.598221\n",
      "iteration 187 / 300: loss 0.611685\n",
      "iteration 187 / 300: loss 0.613219\n",
      "iteration 187 / 300: loss 0.582214\n",
      "iteration 187 / 300: loss 0.601955\n",
      "iteration 187 / 300: loss 0.608956\n",
      "iteration 187 / 300: loss 0.601794\n",
      "iteration 187 / 300: loss 0.607944\n",
      "iteration 187 / 300: loss 0.620236\n",
      "iteration 187 / 300: loss 0.584817\n",
      "iteration 187 / 300: loss 0.583721\n",
      "iteration 187 / 300: loss 0.628849\n",
      "iteration 187 / 300: loss 0.609399\n",
      "iteration 187 / 300: loss 0.606265\n",
      "iteration 187 / 300: loss 0.599034\n",
      "iteration 187 / 300: loss 0.615876\n",
      "iteration 187 / 300: loss 0.596489\n",
      "iteration 187 / 300: loss 0.581430\n",
      "iteration 187 / 300: loss 0.609807\n",
      "iteration 187 / 300: loss 0.608125\n",
      "iteration 187 / 300: loss 0.598224\n",
      "iteration 187 / 300: loss 0.592022\n",
      "iteration 187 / 300: loss 0.611031\n",
      "iteration 187 / 300: loss 0.598550\n",
      "iteration 187 / 300: loss 0.581382\n",
      "iteration 187 / 300: loss 0.609580\n",
      "iteration 188 / 300: loss 0.578384\n",
      "iteration 188 / 300: loss 0.596214\n",
      "iteration 188 / 300: loss 0.569455\n",
      "iteration 188 / 300: loss 0.597849\n",
      "iteration 188 / 300: loss 0.598940\n",
      "iteration 188 / 300: loss 0.603876\n",
      "iteration 188 / 300: loss 0.615261\n",
      "iteration 188 / 300: loss 0.588227\n",
      "iteration 188 / 300: loss 0.627171\n",
      "iteration 188 / 300: loss 0.592600\n",
      "iteration 188 / 300: loss 0.621500\n",
      "iteration 188 / 300: loss 0.593093\n",
      "iteration 188 / 300: loss 0.600541\n",
      "iteration 188 / 300: loss 0.571000\n",
      "iteration 188 / 300: loss 0.592911\n",
      "iteration 188 / 300: loss 0.600043\n",
      "iteration 188 / 300: loss 0.598053\n",
      "iteration 188 / 300: loss 0.583712\n",
      "iteration 188 / 300: loss 0.614355\n",
      "iteration 188 / 300: loss 0.591285\n",
      "iteration 188 / 300: loss 0.591391\n",
      "iteration 188 / 300: loss 0.594005\n",
      "iteration 188 / 300: loss 0.596735\n",
      "iteration 188 / 300: loss 0.596712\n",
      "iteration 188 / 300: loss 0.611735\n",
      "iteration 188 / 300: loss 0.607258\n",
      "iteration 188 / 300: loss 0.597031\n",
      "iteration 188 / 300: loss 0.596301\n",
      "iteration 188 / 300: loss 0.627391\n",
      "iteration 188 / 300: loss 0.601584\n",
      "iteration 188 / 300: loss 0.599923\n",
      "iteration 188 / 300: loss 0.621952\n",
      "iteration 188 / 300: loss 0.581435\n",
      "iteration 188 / 300: loss 0.599604\n",
      "iteration 188 / 300: loss 0.591182\n",
      "iteration 188 / 300: loss 0.599919\n",
      "iteration 188 / 300: loss 0.596015\n",
      "iteration 188 / 300: loss 0.590760\n",
      "iteration 188 / 300: loss 0.591961\n",
      "iteration 188 / 300: loss 0.615468\n",
      "iteration 188 / 300: loss 0.621360\n",
      "iteration 188 / 300: loss 0.587267\n",
      "iteration 188 / 300: loss 0.582483\n",
      "iteration 188 / 300: loss 0.585572\n",
      "iteration 188 / 300: loss 0.603666\n",
      "iteration 188 / 300: loss 0.585192\n",
      "iteration 188 / 300: loss 0.578880\n",
      "iteration 188 / 300: loss 0.576418\n",
      "iteration 188 / 300: loss 0.574097\n",
      "iteration 188 / 300: loss 0.600500\n",
      "iteration 188 / 300: loss 0.584490\n",
      "iteration 188 / 300: loss 0.584834\n",
      "iteration 188 / 300: loss 0.568323\n",
      "iteration 188 / 300: loss 0.592025\n",
      "iteration 188 / 300: loss 0.612116\n",
      "iteration 188 / 300: loss 0.608923\n",
      "iteration 188 / 300: loss 0.607613\n",
      "iteration 188 / 300: loss 0.595533\n",
      "iteration 188 / 300: loss 0.592837\n",
      "iteration 188 / 300: loss 0.597988\n",
      "iteration 188 / 300: loss 0.597677\n",
      "iteration 188 / 300: loss 0.600953\n",
      "iteration 188 / 300: loss 0.597422\n",
      "iteration 188 / 300: loss 0.598776\n",
      "iteration 188 / 300: loss 0.587806\n",
      "iteration 188 / 300: loss 0.600499\n",
      "iteration 188 / 300: loss 0.599650\n",
      "iteration 188 / 300: loss 0.617540\n",
      "iteration 188 / 300: loss 0.598875\n",
      "iteration 188 / 300: loss 0.600801\n",
      "iteration 188 / 300: loss 0.605305\n",
      "iteration 188 / 300: loss 0.598592\n",
      "iteration 188 / 300: loss 0.591474\n",
      "iteration 188 / 300: loss 0.580382\n",
      "iteration 188 / 300: loss 0.598221\n",
      "iteration 188 / 300: loss 0.611685\n",
      "iteration 188 / 300: loss 0.613219\n",
      "iteration 188 / 300: loss 0.582214\n",
      "iteration 188 / 300: loss 0.601955\n",
      "iteration 188 / 300: loss 0.608956\n",
      "iteration 188 / 300: loss 0.601794\n",
      "iteration 188 / 300: loss 0.607944\n",
      "iteration 188 / 300: loss 0.620236\n",
      "iteration 188 / 300: loss 0.584817\n",
      "iteration 188 / 300: loss 0.583721\n",
      "iteration 188 / 300: loss 0.628849\n",
      "iteration 188 / 300: loss 0.609399\n",
      "iteration 188 / 300: loss 0.606265\n",
      "iteration 188 / 300: loss 0.599034\n",
      "iteration 188 / 300: loss 0.615876\n",
      "iteration 188 / 300: loss 0.596489\n",
      "iteration 188 / 300: loss 0.581430\n",
      "iteration 188 / 300: loss 0.609807\n",
      "iteration 188 / 300: loss 0.608125\n",
      "iteration 188 / 300: loss 0.598224\n",
      "iteration 188 / 300: loss 0.592022\n",
      "iteration 188 / 300: loss 0.611031\n",
      "iteration 188 / 300: loss 0.598550\n",
      "iteration 188 / 300: loss 0.581382\n",
      "iteration 188 / 300: loss 0.609580\n",
      "iteration 189 / 300: loss 0.578384\n",
      "iteration 189 / 300: loss 0.596214\n",
      "iteration 189 / 300: loss 0.569455\n",
      "iteration 189 / 300: loss 0.597849\n",
      "iteration 189 / 300: loss 0.598940\n",
      "iteration 189 / 300: loss 0.603876\n",
      "iteration 189 / 300: loss 0.615261\n",
      "iteration 189 / 300: loss 0.588227\n",
      "iteration 189 / 300: loss 0.627171\n",
      "iteration 189 / 300: loss 0.592600\n",
      "iteration 189 / 300: loss 0.621500\n",
      "iteration 189 / 300: loss 0.593093\n",
      "iteration 189 / 300: loss 0.600541\n",
      "iteration 189 / 300: loss 0.571000\n",
      "iteration 189 / 300: loss 0.592911\n",
      "iteration 189 / 300: loss 0.600043\n",
      "iteration 189 / 300: loss 0.598053\n",
      "iteration 189 / 300: loss 0.583712\n",
      "iteration 189 / 300: loss 0.614355\n",
      "iteration 189 / 300: loss 0.591285\n",
      "iteration 189 / 300: loss 0.591391\n",
      "iteration 189 / 300: loss 0.594005\n",
      "iteration 189 / 300: loss 0.596735\n",
      "iteration 189 / 300: loss 0.596712\n",
      "iteration 189 / 300: loss 0.611735\n",
      "iteration 189 / 300: loss 0.607258\n",
      "iteration 189 / 300: loss 0.597031\n",
      "iteration 189 / 300: loss 0.596301\n",
      "iteration 189 / 300: loss 0.627391\n",
      "iteration 189 / 300: loss 0.601584\n",
      "iteration 189 / 300: loss 0.599923\n",
      "iteration 189 / 300: loss 0.621952\n",
      "iteration 189 / 300: loss 0.581435\n",
      "iteration 189 / 300: loss 0.599604\n",
      "iteration 189 / 300: loss 0.591182\n",
      "iteration 189 / 300: loss 0.599919\n",
      "iteration 189 / 300: loss 0.596015\n",
      "iteration 189 / 300: loss 0.590760\n",
      "iteration 189 / 300: loss 0.591961\n",
      "iteration 189 / 300: loss 0.615468\n",
      "iteration 189 / 300: loss 0.621360\n",
      "iteration 189 / 300: loss 0.587267\n",
      "iteration 189 / 300: loss 0.582483\n",
      "iteration 189 / 300: loss 0.585572\n",
      "iteration 189 / 300: loss 0.603666\n",
      "iteration 189 / 300: loss 0.585192\n",
      "iteration 189 / 300: loss 0.578880\n",
      "iteration 189 / 300: loss 0.576418\n",
      "iteration 189 / 300: loss 0.574097\n",
      "iteration 189 / 300: loss 0.600500\n",
      "iteration 189 / 300: loss 0.584490\n",
      "iteration 189 / 300: loss 0.584834\n",
      "iteration 189 / 300: loss 0.568323\n",
      "iteration 189 / 300: loss 0.592025\n",
      "iteration 189 / 300: loss 0.612116\n",
      "iteration 189 / 300: loss 0.608923\n",
      "iteration 189 / 300: loss 0.607613\n",
      "iteration 189 / 300: loss 0.595533\n",
      "iteration 189 / 300: loss 0.592837\n",
      "iteration 189 / 300: loss 0.597988\n",
      "iteration 189 / 300: loss 0.597677\n",
      "iteration 189 / 300: loss 0.600953\n",
      "iteration 189 / 300: loss 0.597422\n",
      "iteration 189 / 300: loss 0.598776\n",
      "iteration 189 / 300: loss 0.587806\n",
      "iteration 189 / 300: loss 0.600499\n",
      "iteration 189 / 300: loss 0.599650\n",
      "iteration 189 / 300: loss 0.617540\n",
      "iteration 189 / 300: loss 0.598875\n",
      "iteration 189 / 300: loss 0.600801\n",
      "iteration 189 / 300: loss 0.605305\n",
      "iteration 189 / 300: loss 0.598592\n",
      "iteration 189 / 300: loss 0.591474\n",
      "iteration 189 / 300: loss 0.580382\n",
      "iteration 189 / 300: loss 0.598221\n",
      "iteration 189 / 300: loss 0.611685\n",
      "iteration 189 / 300: loss 0.613219\n",
      "iteration 189 / 300: loss 0.582214\n",
      "iteration 189 / 300: loss 0.601955\n",
      "iteration 189 / 300: loss 0.608956\n",
      "iteration 189 / 300: loss 0.601794\n",
      "iteration 189 / 300: loss 0.607944\n",
      "iteration 189 / 300: loss 0.620236\n",
      "iteration 189 / 300: loss 0.584817\n",
      "iteration 189 / 300: loss 0.583721\n",
      "iteration 189 / 300: loss 0.628849\n",
      "iteration 189 / 300: loss 0.609399\n",
      "iteration 189 / 300: loss 0.606265\n",
      "iteration 189 / 300: loss 0.599034\n",
      "iteration 189 / 300: loss 0.615876\n",
      "iteration 189 / 300: loss 0.596489\n",
      "iteration 189 / 300: loss 0.581430\n",
      "iteration 189 / 300: loss 0.609807\n",
      "iteration 189 / 300: loss 0.608125\n",
      "iteration 189 / 300: loss 0.598224\n",
      "iteration 189 / 300: loss 0.592022\n",
      "iteration 189 / 300: loss 0.611031\n",
      "iteration 189 / 300: loss 0.598550\n",
      "iteration 189 / 300: loss 0.581382\n",
      "iteration 189 / 300: loss 0.609580\n",
      "iteration 190 / 300: loss 0.578384\n",
      "iteration 190 / 300: loss 0.596214\n",
      "iteration 190 / 300: loss 0.569455\n",
      "iteration 190 / 300: loss 0.597849\n",
      "iteration 190 / 300: loss 0.598940\n",
      "iteration 190 / 300: loss 0.603876\n",
      "iteration 190 / 300: loss 0.615261\n",
      "iteration 190 / 300: loss 0.588227\n",
      "iteration 190 / 300: loss 0.627171\n",
      "iteration 190 / 300: loss 0.592600\n",
      "iteration 190 / 300: loss 0.621500\n",
      "iteration 190 / 300: loss 0.593093\n",
      "iteration 190 / 300: loss 0.600541\n",
      "iteration 190 / 300: loss 0.571000\n",
      "iteration 190 / 300: loss 0.592911\n",
      "iteration 190 / 300: loss 0.600043\n",
      "iteration 190 / 300: loss 0.598053\n",
      "iteration 190 / 300: loss 0.583712\n",
      "iteration 190 / 300: loss 0.614355\n",
      "iteration 190 / 300: loss 0.591285\n",
      "iteration 190 / 300: loss 0.591391\n",
      "iteration 190 / 300: loss 0.594005\n",
      "iteration 190 / 300: loss 0.596735\n",
      "iteration 190 / 300: loss 0.596712\n",
      "iteration 190 / 300: loss 0.611735\n",
      "iteration 190 / 300: loss 0.607258\n",
      "iteration 190 / 300: loss 0.597031\n",
      "iteration 190 / 300: loss 0.596301\n",
      "iteration 190 / 300: loss 0.627391\n",
      "iteration 190 / 300: loss 0.601584\n",
      "iteration 190 / 300: loss 0.599923\n",
      "iteration 190 / 300: loss 0.621952\n",
      "iteration 190 / 300: loss 0.581435\n",
      "iteration 190 / 300: loss 0.599604\n",
      "iteration 190 / 300: loss 0.591182\n",
      "iteration 190 / 300: loss 0.599919\n",
      "iteration 190 / 300: loss 0.596015\n",
      "iteration 190 / 300: loss 0.590760\n",
      "iteration 190 / 300: loss 0.591961\n",
      "iteration 190 / 300: loss 0.615468\n",
      "iteration 190 / 300: loss 0.621360\n",
      "iteration 190 / 300: loss 0.587267\n",
      "iteration 190 / 300: loss 0.582483\n",
      "iteration 190 / 300: loss 0.585572\n",
      "iteration 190 / 300: loss 0.603666\n",
      "iteration 190 / 300: loss 0.585192\n",
      "iteration 190 / 300: loss 0.578880\n",
      "iteration 190 / 300: loss 0.576418\n",
      "iteration 190 / 300: loss 0.574097\n",
      "iteration 190 / 300: loss 0.600500\n",
      "iteration 190 / 300: loss 0.584490\n",
      "iteration 190 / 300: loss 0.584834\n",
      "iteration 190 / 300: loss 0.568323\n",
      "iteration 190 / 300: loss 0.592025\n",
      "iteration 190 / 300: loss 0.612116\n",
      "iteration 190 / 300: loss 0.608923\n",
      "iteration 190 / 300: loss 0.607613\n",
      "iteration 190 / 300: loss 0.595533\n",
      "iteration 190 / 300: loss 0.592837\n",
      "iteration 190 / 300: loss 0.597988\n",
      "iteration 190 / 300: loss 0.597677\n",
      "iteration 190 / 300: loss 0.600953\n",
      "iteration 190 / 300: loss 0.597422\n",
      "iteration 190 / 300: loss 0.598776\n",
      "iteration 190 / 300: loss 0.587806\n",
      "iteration 190 / 300: loss 0.600499\n",
      "iteration 190 / 300: loss 0.599650\n",
      "iteration 190 / 300: loss 0.617540\n",
      "iteration 190 / 300: loss 0.598875\n",
      "iteration 190 / 300: loss 0.600801\n",
      "iteration 190 / 300: loss 0.605305\n",
      "iteration 190 / 300: loss 0.598592\n",
      "iteration 190 / 300: loss 0.591474\n",
      "iteration 190 / 300: loss 0.580382\n",
      "iteration 190 / 300: loss 0.598221\n",
      "iteration 190 / 300: loss 0.611685\n",
      "iteration 190 / 300: loss 0.613219\n",
      "iteration 190 / 300: loss 0.582214\n",
      "iteration 190 / 300: loss 0.601955\n",
      "iteration 190 / 300: loss 0.608956\n",
      "iteration 190 / 300: loss 0.601794\n",
      "iteration 190 / 300: loss 0.607944\n",
      "iteration 190 / 300: loss 0.620236\n",
      "iteration 190 / 300: loss 0.584817\n",
      "iteration 190 / 300: loss 0.583721\n",
      "iteration 190 / 300: loss 0.628849\n",
      "iteration 190 / 300: loss 0.609399\n",
      "iteration 190 / 300: loss 0.606265\n",
      "iteration 190 / 300: loss 0.599034\n",
      "iteration 190 / 300: loss 0.615876\n",
      "iteration 190 / 300: loss 0.596489\n",
      "iteration 190 / 300: loss 0.581430\n",
      "iteration 190 / 300: loss 0.609807\n",
      "iteration 190 / 300: loss 0.608125\n",
      "iteration 190 / 300: loss 0.598224\n",
      "iteration 190 / 300: loss 0.592022\n",
      "iteration 190 / 300: loss 0.611031\n",
      "iteration 190 / 300: loss 0.598550\n",
      "iteration 190 / 300: loss 0.581382\n",
      "iteration 190 / 300: loss 0.609580\n",
      "iteration 191 / 300: loss 0.578384\n",
      "iteration 191 / 300: loss 0.596214\n",
      "iteration 191 / 300: loss 0.569455\n",
      "iteration 191 / 300: loss 0.597849\n",
      "iteration 191 / 300: loss 0.598940\n",
      "iteration 191 / 300: loss 0.603876\n",
      "iteration 191 / 300: loss 0.615261\n",
      "iteration 191 / 300: loss 0.588227\n",
      "iteration 191 / 300: loss 0.627171\n",
      "iteration 191 / 300: loss 0.592600\n",
      "iteration 191 / 300: loss 0.621500\n",
      "iteration 191 / 300: loss 0.593093\n",
      "iteration 191 / 300: loss 0.600541\n",
      "iteration 191 / 300: loss 0.571000\n",
      "iteration 191 / 300: loss 0.592911\n",
      "iteration 191 / 300: loss 0.600043\n",
      "iteration 191 / 300: loss 0.598053\n",
      "iteration 191 / 300: loss 0.583712\n",
      "iteration 191 / 300: loss 0.614355\n",
      "iteration 191 / 300: loss 0.591285\n",
      "iteration 191 / 300: loss 0.591391\n",
      "iteration 191 / 300: loss 0.594005\n",
      "iteration 191 / 300: loss 0.596735\n",
      "iteration 191 / 300: loss 0.596712\n",
      "iteration 191 / 300: loss 0.611735\n",
      "iteration 191 / 300: loss 0.607258\n",
      "iteration 191 / 300: loss 0.597031\n",
      "iteration 191 / 300: loss 0.596301\n",
      "iteration 191 / 300: loss 0.627391\n",
      "iteration 191 / 300: loss 0.601584\n",
      "iteration 191 / 300: loss 0.599923\n",
      "iteration 191 / 300: loss 0.621952\n",
      "iteration 191 / 300: loss 0.581435\n",
      "iteration 191 / 300: loss 0.599604\n",
      "iteration 191 / 300: loss 0.591182\n",
      "iteration 191 / 300: loss 0.599919\n",
      "iteration 191 / 300: loss 0.596015\n",
      "iteration 191 / 300: loss 0.590760\n",
      "iteration 191 / 300: loss 0.591961\n",
      "iteration 191 / 300: loss 0.615468\n",
      "iteration 191 / 300: loss 0.621360\n",
      "iteration 191 / 300: loss 0.587267\n",
      "iteration 191 / 300: loss 0.582483\n",
      "iteration 191 / 300: loss 0.585572\n",
      "iteration 191 / 300: loss 0.603666\n",
      "iteration 191 / 300: loss 0.585192\n",
      "iteration 191 / 300: loss 0.578880\n",
      "iteration 191 / 300: loss 0.576418\n",
      "iteration 191 / 300: loss 0.574097\n",
      "iteration 191 / 300: loss 0.600500\n",
      "iteration 191 / 300: loss 0.584490\n",
      "iteration 191 / 300: loss 0.584834\n",
      "iteration 191 / 300: loss 0.568323\n",
      "iteration 191 / 300: loss 0.592025\n",
      "iteration 191 / 300: loss 0.612116\n",
      "iteration 191 / 300: loss 0.608923\n",
      "iteration 191 / 300: loss 0.607613\n",
      "iteration 191 / 300: loss 0.595533\n",
      "iteration 191 / 300: loss 0.592837\n",
      "iteration 191 / 300: loss 0.597988\n",
      "iteration 191 / 300: loss 0.597677\n",
      "iteration 191 / 300: loss 0.600953\n",
      "iteration 191 / 300: loss 0.597422\n",
      "iteration 191 / 300: loss 0.598776\n",
      "iteration 191 / 300: loss 0.587806\n",
      "iteration 191 / 300: loss 0.600499\n",
      "iteration 191 / 300: loss 0.599650\n",
      "iteration 191 / 300: loss 0.617540\n",
      "iteration 191 / 300: loss 0.598875\n",
      "iteration 191 / 300: loss 0.600801\n",
      "iteration 191 / 300: loss 0.605305\n",
      "iteration 191 / 300: loss 0.598592\n",
      "iteration 191 / 300: loss 0.591474\n",
      "iteration 191 / 300: loss 0.580382\n",
      "iteration 191 / 300: loss 0.598221\n",
      "iteration 191 / 300: loss 0.611685\n",
      "iteration 191 / 300: loss 0.613219\n",
      "iteration 191 / 300: loss 0.582214\n",
      "iteration 191 / 300: loss 0.601955\n",
      "iteration 191 / 300: loss 0.608956\n",
      "iteration 191 / 300: loss 0.601794\n",
      "iteration 191 / 300: loss 0.607944\n",
      "iteration 191 / 300: loss 0.620236\n",
      "iteration 191 / 300: loss 0.584817\n",
      "iteration 191 / 300: loss 0.583721\n",
      "iteration 191 / 300: loss 0.628849\n",
      "iteration 191 / 300: loss 0.609399\n",
      "iteration 191 / 300: loss 0.606265\n",
      "iteration 191 / 300: loss 0.599034\n",
      "iteration 191 / 300: loss 0.615876\n",
      "iteration 191 / 300: loss 0.596489\n",
      "iteration 191 / 300: loss 0.581430\n",
      "iteration 191 / 300: loss 0.609807\n",
      "iteration 191 / 300: loss 0.608125\n",
      "iteration 191 / 300: loss 0.598224\n",
      "iteration 191 / 300: loss 0.592022\n",
      "iteration 191 / 300: loss 0.611031\n",
      "iteration 191 / 300: loss 0.598550\n",
      "iteration 191 / 300: loss 0.581382\n",
      "iteration 191 / 300: loss 0.609580\n",
      "iteration 192 / 300: loss 0.578384\n",
      "iteration 192 / 300: loss 0.596214\n",
      "iteration 192 / 300: loss 0.569455\n",
      "iteration 192 / 300: loss 0.597849\n",
      "iteration 192 / 300: loss 0.598940\n",
      "iteration 192 / 300: loss 0.603876\n",
      "iteration 192 / 300: loss 0.615261\n",
      "iteration 192 / 300: loss 0.588227\n",
      "iteration 192 / 300: loss 0.627171\n",
      "iteration 192 / 300: loss 0.592600\n",
      "iteration 192 / 300: loss 0.621500\n",
      "iteration 192 / 300: loss 0.593093\n",
      "iteration 192 / 300: loss 0.600541\n",
      "iteration 192 / 300: loss 0.571000\n",
      "iteration 192 / 300: loss 0.592911\n",
      "iteration 192 / 300: loss 0.600043\n",
      "iteration 192 / 300: loss 0.598053\n",
      "iteration 192 / 300: loss 0.583712\n",
      "iteration 192 / 300: loss 0.614355\n",
      "iteration 192 / 300: loss 0.591285\n",
      "iteration 192 / 300: loss 0.591391\n",
      "iteration 192 / 300: loss 0.594005\n",
      "iteration 192 / 300: loss 0.596735\n",
      "iteration 192 / 300: loss 0.596712\n",
      "iteration 192 / 300: loss 0.611735\n",
      "iteration 192 / 300: loss 0.607258\n",
      "iteration 192 / 300: loss 0.597031\n",
      "iteration 192 / 300: loss 0.596301\n",
      "iteration 192 / 300: loss 0.627391\n",
      "iteration 192 / 300: loss 0.601584\n",
      "iteration 192 / 300: loss 0.599923\n",
      "iteration 192 / 300: loss 0.621952\n",
      "iteration 192 / 300: loss 0.581435\n",
      "iteration 192 / 300: loss 0.599604\n",
      "iteration 192 / 300: loss 0.591182\n",
      "iteration 192 / 300: loss 0.599919\n",
      "iteration 192 / 300: loss 0.596015\n",
      "iteration 192 / 300: loss 0.590760\n",
      "iteration 192 / 300: loss 0.591961\n",
      "iteration 192 / 300: loss 0.615468\n",
      "iteration 192 / 300: loss 0.621360\n",
      "iteration 192 / 300: loss 0.587267\n",
      "iteration 192 / 300: loss 0.582483\n",
      "iteration 192 / 300: loss 0.585572\n",
      "iteration 192 / 300: loss 0.603666\n",
      "iteration 192 / 300: loss 0.585192\n",
      "iteration 192 / 300: loss 0.578880\n",
      "iteration 192 / 300: loss 0.576418\n",
      "iteration 192 / 300: loss 0.574097\n",
      "iteration 192 / 300: loss 0.600500\n",
      "iteration 192 / 300: loss 0.584490\n",
      "iteration 192 / 300: loss 0.584834\n",
      "iteration 192 / 300: loss 0.568323\n",
      "iteration 192 / 300: loss 0.592025\n",
      "iteration 192 / 300: loss 0.612116\n",
      "iteration 192 / 300: loss 0.608923\n",
      "iteration 192 / 300: loss 0.607613\n",
      "iteration 192 / 300: loss 0.595533\n",
      "iteration 192 / 300: loss 0.592837\n",
      "iteration 192 / 300: loss 0.597988\n",
      "iteration 192 / 300: loss 0.597677\n",
      "iteration 192 / 300: loss 0.600953\n",
      "iteration 192 / 300: loss 0.597422\n",
      "iteration 192 / 300: loss 0.598776\n",
      "iteration 192 / 300: loss 0.587806\n",
      "iteration 192 / 300: loss 0.600499\n",
      "iteration 192 / 300: loss 0.599650\n",
      "iteration 192 / 300: loss 0.617540\n",
      "iteration 192 / 300: loss 0.598875\n",
      "iteration 192 / 300: loss 0.600801\n",
      "iteration 192 / 300: loss 0.605305\n",
      "iteration 192 / 300: loss 0.598592\n",
      "iteration 192 / 300: loss 0.591474\n",
      "iteration 192 / 300: loss 0.580382\n",
      "iteration 192 / 300: loss 0.598221\n",
      "iteration 192 / 300: loss 0.611685\n",
      "iteration 192 / 300: loss 0.613219\n",
      "iteration 192 / 300: loss 0.582214\n",
      "iteration 192 / 300: loss 0.601955\n",
      "iteration 192 / 300: loss 0.608956\n",
      "iteration 192 / 300: loss 0.601794\n",
      "iteration 192 / 300: loss 0.607944\n",
      "iteration 192 / 300: loss 0.620236\n",
      "iteration 192 / 300: loss 0.584817\n",
      "iteration 192 / 300: loss 0.583721\n",
      "iteration 192 / 300: loss 0.628849\n",
      "iteration 192 / 300: loss 0.609399\n",
      "iteration 192 / 300: loss 0.606265\n",
      "iteration 192 / 300: loss 0.599034\n",
      "iteration 192 / 300: loss 0.615876\n",
      "iteration 192 / 300: loss 0.596489\n",
      "iteration 192 / 300: loss 0.581430\n",
      "iteration 192 / 300: loss 0.609807\n",
      "iteration 192 / 300: loss 0.608125\n",
      "iteration 192 / 300: loss 0.598224\n",
      "iteration 192 / 300: loss 0.592022\n",
      "iteration 192 / 300: loss 0.611031\n",
      "iteration 192 / 300: loss 0.598550\n",
      "iteration 192 / 300: loss 0.581382\n",
      "iteration 192 / 300: loss 0.609580\n",
      "iteration 193 / 300: loss 0.578384\n",
      "iteration 193 / 300: loss 0.596214\n",
      "iteration 193 / 300: loss 0.569455\n",
      "iteration 193 / 300: loss 0.597849\n",
      "iteration 193 / 300: loss 0.598940\n",
      "iteration 193 / 300: loss 0.603876\n",
      "iteration 193 / 300: loss 0.615261\n",
      "iteration 193 / 300: loss 0.588227\n",
      "iteration 193 / 300: loss 0.627171\n",
      "iteration 193 / 300: loss 0.592600\n",
      "iteration 193 / 300: loss 0.621500\n",
      "iteration 193 / 300: loss 0.593093\n",
      "iteration 193 / 300: loss 0.600541\n",
      "iteration 193 / 300: loss 0.571000\n",
      "iteration 193 / 300: loss 0.592911\n",
      "iteration 193 / 300: loss 0.600043\n",
      "iteration 193 / 300: loss 0.598053\n",
      "iteration 193 / 300: loss 0.583712\n",
      "iteration 193 / 300: loss 0.614355\n",
      "iteration 193 / 300: loss 0.591285\n",
      "iteration 193 / 300: loss 0.591391\n",
      "iteration 193 / 300: loss 0.594005\n",
      "iteration 193 / 300: loss 0.596735\n",
      "iteration 193 / 300: loss 0.596712\n",
      "iteration 193 / 300: loss 0.611735\n",
      "iteration 193 / 300: loss 0.607258\n",
      "iteration 193 / 300: loss 0.597031\n",
      "iteration 193 / 300: loss 0.596301\n",
      "iteration 193 / 300: loss 0.627391\n",
      "iteration 193 / 300: loss 0.601584\n",
      "iteration 193 / 300: loss 0.599923\n",
      "iteration 193 / 300: loss 0.621952\n",
      "iteration 193 / 300: loss 0.581435\n",
      "iteration 193 / 300: loss 0.599604\n",
      "iteration 193 / 300: loss 0.591182\n",
      "iteration 193 / 300: loss 0.599919\n",
      "iteration 193 / 300: loss 0.596015\n",
      "iteration 193 / 300: loss 0.590760\n",
      "iteration 193 / 300: loss 0.591961\n",
      "iteration 193 / 300: loss 0.615468\n",
      "iteration 193 / 300: loss 0.621360\n",
      "iteration 193 / 300: loss 0.587267\n",
      "iteration 193 / 300: loss 0.582483\n",
      "iteration 193 / 300: loss 0.585572\n",
      "iteration 193 / 300: loss 0.603666\n",
      "iteration 193 / 300: loss 0.585192\n",
      "iteration 193 / 300: loss 0.578880\n",
      "iteration 193 / 300: loss 0.576418\n",
      "iteration 193 / 300: loss 0.574097\n",
      "iteration 193 / 300: loss 0.600500\n",
      "iteration 193 / 300: loss 0.584490\n",
      "iteration 193 / 300: loss 0.584834\n",
      "iteration 193 / 300: loss 0.568323\n",
      "iteration 193 / 300: loss 0.592025\n",
      "iteration 193 / 300: loss 0.612116\n",
      "iteration 193 / 300: loss 0.608923\n",
      "iteration 193 / 300: loss 0.607613\n",
      "iteration 193 / 300: loss 0.595533\n",
      "iteration 193 / 300: loss 0.592837\n",
      "iteration 193 / 300: loss 0.597988\n",
      "iteration 193 / 300: loss 0.597677\n",
      "iteration 193 / 300: loss 0.600953\n",
      "iteration 193 / 300: loss 0.597422\n",
      "iteration 193 / 300: loss 0.598776\n",
      "iteration 193 / 300: loss 0.587806\n",
      "iteration 193 / 300: loss 0.600499\n",
      "iteration 193 / 300: loss 0.599650\n",
      "iteration 193 / 300: loss 0.617540\n",
      "iteration 193 / 300: loss 0.598875\n",
      "iteration 193 / 300: loss 0.600801\n",
      "iteration 193 / 300: loss 0.605305\n",
      "iteration 193 / 300: loss 0.598592\n",
      "iteration 193 / 300: loss 0.591474\n",
      "iteration 193 / 300: loss 0.580382\n",
      "iteration 193 / 300: loss 0.598221\n",
      "iteration 193 / 300: loss 0.611685\n",
      "iteration 193 / 300: loss 0.613219\n",
      "iteration 193 / 300: loss 0.582214\n",
      "iteration 193 / 300: loss 0.601955\n",
      "iteration 193 / 300: loss 0.608956\n",
      "iteration 193 / 300: loss 0.601794\n",
      "iteration 193 / 300: loss 0.607944\n",
      "iteration 193 / 300: loss 0.620236\n",
      "iteration 193 / 300: loss 0.584817\n",
      "iteration 193 / 300: loss 0.583721\n",
      "iteration 193 / 300: loss 0.628849\n",
      "iteration 193 / 300: loss 0.609399\n",
      "iteration 193 / 300: loss 0.606265\n",
      "iteration 193 / 300: loss 0.599034\n",
      "iteration 193 / 300: loss 0.615876\n",
      "iteration 193 / 300: loss 0.596489\n",
      "iteration 193 / 300: loss 0.581430\n",
      "iteration 193 / 300: loss 0.609807\n",
      "iteration 193 / 300: loss 0.608125\n",
      "iteration 193 / 300: loss 0.598224\n",
      "iteration 193 / 300: loss 0.592022\n",
      "iteration 193 / 300: loss 0.611031\n",
      "iteration 193 / 300: loss 0.598550\n",
      "iteration 193 / 300: loss 0.581382\n",
      "iteration 193 / 300: loss 0.609580\n",
      "iteration 194 / 300: loss 0.578384\n",
      "iteration 194 / 300: loss 0.596214\n",
      "iteration 194 / 300: loss 0.569455\n",
      "iteration 194 / 300: loss 0.597849\n",
      "iteration 194 / 300: loss 0.598940\n",
      "iteration 194 / 300: loss 0.603876\n",
      "iteration 194 / 300: loss 0.615261\n",
      "iteration 194 / 300: loss 0.588227\n",
      "iteration 194 / 300: loss 0.627171\n",
      "iteration 194 / 300: loss 0.592600\n",
      "iteration 194 / 300: loss 0.621500\n",
      "iteration 194 / 300: loss 0.593093\n",
      "iteration 194 / 300: loss 0.600541\n",
      "iteration 194 / 300: loss 0.571000\n",
      "iteration 194 / 300: loss 0.592911\n",
      "iteration 194 / 300: loss 0.600043\n",
      "iteration 194 / 300: loss 0.598053\n",
      "iteration 194 / 300: loss 0.583712\n",
      "iteration 194 / 300: loss 0.614355\n",
      "iteration 194 / 300: loss 0.591285\n",
      "iteration 194 / 300: loss 0.591391\n",
      "iteration 194 / 300: loss 0.594005\n",
      "iteration 194 / 300: loss 0.596735\n",
      "iteration 194 / 300: loss 0.596712\n",
      "iteration 194 / 300: loss 0.611735\n",
      "iteration 194 / 300: loss 0.607258\n",
      "iteration 194 / 300: loss 0.597031\n",
      "iteration 194 / 300: loss 0.596301\n",
      "iteration 194 / 300: loss 0.627391\n",
      "iteration 194 / 300: loss 0.601584\n",
      "iteration 194 / 300: loss 0.599923\n",
      "iteration 194 / 300: loss 0.621952\n",
      "iteration 194 / 300: loss 0.581435\n",
      "iteration 194 / 300: loss 0.599604\n",
      "iteration 194 / 300: loss 0.591182\n",
      "iteration 194 / 300: loss 0.599919\n",
      "iteration 194 / 300: loss 0.596015\n",
      "iteration 194 / 300: loss 0.590760\n",
      "iteration 194 / 300: loss 0.591961\n",
      "iteration 194 / 300: loss 0.615468\n",
      "iteration 194 / 300: loss 0.621360\n",
      "iteration 194 / 300: loss 0.587267\n",
      "iteration 194 / 300: loss 0.582483\n",
      "iteration 194 / 300: loss 0.585572\n",
      "iteration 194 / 300: loss 0.603666\n",
      "iteration 194 / 300: loss 0.585192\n",
      "iteration 194 / 300: loss 0.578880\n",
      "iteration 194 / 300: loss 0.576418\n",
      "iteration 194 / 300: loss 0.574097\n",
      "iteration 194 / 300: loss 0.600500\n",
      "iteration 194 / 300: loss 0.584490\n",
      "iteration 194 / 300: loss 0.584834\n",
      "iteration 194 / 300: loss 0.568323\n",
      "iteration 194 / 300: loss 0.592025\n",
      "iteration 194 / 300: loss 0.612116\n",
      "iteration 194 / 300: loss 0.608923\n",
      "iteration 194 / 300: loss 0.607613\n",
      "iteration 194 / 300: loss 0.595533\n",
      "iteration 194 / 300: loss 0.592837\n",
      "iteration 194 / 300: loss 0.597988\n",
      "iteration 194 / 300: loss 0.597677\n",
      "iteration 194 / 300: loss 0.600953\n",
      "iteration 194 / 300: loss 0.597422\n",
      "iteration 194 / 300: loss 0.598776\n",
      "iteration 194 / 300: loss 0.587806\n",
      "iteration 194 / 300: loss 0.600499\n",
      "iteration 194 / 300: loss 0.599650\n",
      "iteration 194 / 300: loss 0.617540\n",
      "iteration 194 / 300: loss 0.598875\n",
      "iteration 194 / 300: loss 0.600801\n",
      "iteration 194 / 300: loss 0.605305\n",
      "iteration 194 / 300: loss 0.598592\n",
      "iteration 194 / 300: loss 0.591474\n",
      "iteration 194 / 300: loss 0.580382\n",
      "iteration 194 / 300: loss 0.598221\n",
      "iteration 194 / 300: loss 0.611685\n",
      "iteration 194 / 300: loss 0.613219\n",
      "iteration 194 / 300: loss 0.582214\n",
      "iteration 194 / 300: loss 0.601955\n",
      "iteration 194 / 300: loss 0.608956\n",
      "iteration 194 / 300: loss 0.601794\n",
      "iteration 194 / 300: loss 0.607944\n",
      "iteration 194 / 300: loss 0.620236\n",
      "iteration 194 / 300: loss 0.584817\n",
      "iteration 194 / 300: loss 0.583721\n",
      "iteration 194 / 300: loss 0.628849\n",
      "iteration 194 / 300: loss 0.609399\n",
      "iteration 194 / 300: loss 0.606265\n",
      "iteration 194 / 300: loss 0.599034\n",
      "iteration 194 / 300: loss 0.615876\n",
      "iteration 194 / 300: loss 0.596489\n",
      "iteration 194 / 300: loss 0.581430\n",
      "iteration 194 / 300: loss 0.609807\n",
      "iteration 194 / 300: loss 0.608125\n",
      "iteration 194 / 300: loss 0.598224\n",
      "iteration 194 / 300: loss 0.592022\n",
      "iteration 194 / 300: loss 0.611031\n",
      "iteration 194 / 300: loss 0.598550\n",
      "iteration 194 / 300: loss 0.581382\n",
      "iteration 194 / 300: loss 0.609580\n",
      "iteration 195 / 300: loss 0.578384\n",
      "iteration 195 / 300: loss 0.596214\n",
      "iteration 195 / 300: loss 0.569455\n",
      "iteration 195 / 300: loss 0.597849\n",
      "iteration 195 / 300: loss 0.598940\n",
      "iteration 195 / 300: loss 0.603876\n",
      "iteration 195 / 300: loss 0.615261\n",
      "iteration 195 / 300: loss 0.588227\n",
      "iteration 195 / 300: loss 0.627171\n",
      "iteration 195 / 300: loss 0.592600\n",
      "iteration 195 / 300: loss 0.621500\n",
      "iteration 195 / 300: loss 0.593093\n",
      "iteration 195 / 300: loss 0.600541\n",
      "iteration 195 / 300: loss 0.571000\n",
      "iteration 195 / 300: loss 0.592911\n",
      "iteration 195 / 300: loss 0.600043\n",
      "iteration 195 / 300: loss 0.598053\n",
      "iteration 195 / 300: loss 0.583712\n",
      "iteration 195 / 300: loss 0.614355\n",
      "iteration 195 / 300: loss 0.591285\n",
      "iteration 195 / 300: loss 0.591391\n",
      "iteration 195 / 300: loss 0.594005\n",
      "iteration 195 / 300: loss 0.596735\n",
      "iteration 195 / 300: loss 0.596712\n",
      "iteration 195 / 300: loss 0.611735\n",
      "iteration 195 / 300: loss 0.607258\n",
      "iteration 195 / 300: loss 0.597031\n",
      "iteration 195 / 300: loss 0.596301\n",
      "iteration 195 / 300: loss 0.627391\n",
      "iteration 195 / 300: loss 0.601584\n",
      "iteration 195 / 300: loss 0.599923\n",
      "iteration 195 / 300: loss 0.621952\n",
      "iteration 195 / 300: loss 0.581435\n",
      "iteration 195 / 300: loss 0.599604\n",
      "iteration 195 / 300: loss 0.591182\n",
      "iteration 195 / 300: loss 0.599919\n",
      "iteration 195 / 300: loss 0.596015\n",
      "iteration 195 / 300: loss 0.590760\n",
      "iteration 195 / 300: loss 0.591961\n",
      "iteration 195 / 300: loss 0.615468\n",
      "iteration 195 / 300: loss 0.621360\n",
      "iteration 195 / 300: loss 0.587267\n",
      "iteration 195 / 300: loss 0.582483\n",
      "iteration 195 / 300: loss 0.585572\n",
      "iteration 195 / 300: loss 0.603666\n",
      "iteration 195 / 300: loss 0.585192\n",
      "iteration 195 / 300: loss 0.578880\n",
      "iteration 195 / 300: loss 0.576418\n",
      "iteration 195 / 300: loss 0.574097\n",
      "iteration 195 / 300: loss 0.600500\n",
      "iteration 195 / 300: loss 0.584490\n",
      "iteration 195 / 300: loss 0.584834\n",
      "iteration 195 / 300: loss 0.568323\n",
      "iteration 195 / 300: loss 0.592025\n",
      "iteration 195 / 300: loss 0.612116\n",
      "iteration 195 / 300: loss 0.608923\n",
      "iteration 195 / 300: loss 0.607613\n",
      "iteration 195 / 300: loss 0.595533\n",
      "iteration 195 / 300: loss 0.592837\n",
      "iteration 195 / 300: loss 0.597988\n",
      "iteration 195 / 300: loss 0.597677\n",
      "iteration 195 / 300: loss 0.600953\n",
      "iteration 195 / 300: loss 0.597422\n",
      "iteration 195 / 300: loss 0.598776\n",
      "iteration 195 / 300: loss 0.587806\n",
      "iteration 195 / 300: loss 0.600499\n",
      "iteration 195 / 300: loss 0.599650\n",
      "iteration 195 / 300: loss 0.617540\n",
      "iteration 195 / 300: loss 0.598875\n",
      "iteration 195 / 300: loss 0.600801\n",
      "iteration 195 / 300: loss 0.605305\n",
      "iteration 195 / 300: loss 0.598592\n",
      "iteration 195 / 300: loss 0.591474\n",
      "iteration 195 / 300: loss 0.580382\n",
      "iteration 195 / 300: loss 0.598221\n",
      "iteration 195 / 300: loss 0.611685\n",
      "iteration 195 / 300: loss 0.613219\n",
      "iteration 195 / 300: loss 0.582214\n",
      "iteration 195 / 300: loss 0.601955\n",
      "iteration 195 / 300: loss 0.608956\n",
      "iteration 195 / 300: loss 0.601794\n",
      "iteration 195 / 300: loss 0.607944\n",
      "iteration 195 / 300: loss 0.620236\n",
      "iteration 195 / 300: loss 0.584817\n",
      "iteration 195 / 300: loss 0.583721\n",
      "iteration 195 / 300: loss 0.628849\n",
      "iteration 195 / 300: loss 0.609399\n",
      "iteration 195 / 300: loss 0.606265\n",
      "iteration 195 / 300: loss 0.599034\n",
      "iteration 195 / 300: loss 0.615876\n",
      "iteration 195 / 300: loss 0.596489\n",
      "iteration 195 / 300: loss 0.581430\n",
      "iteration 195 / 300: loss 0.609807\n",
      "iteration 195 / 300: loss 0.608125\n",
      "iteration 195 / 300: loss 0.598224\n",
      "iteration 195 / 300: loss 0.592022\n",
      "iteration 195 / 300: loss 0.611031\n",
      "iteration 195 / 300: loss 0.598550\n",
      "iteration 195 / 300: loss 0.581382\n",
      "iteration 195 / 300: loss 0.609580\n",
      "iteration 196 / 300: loss 0.578384\n",
      "iteration 196 / 300: loss 0.596214\n",
      "iteration 196 / 300: loss 0.569455\n",
      "iteration 196 / 300: loss 0.597849\n",
      "iteration 196 / 300: loss 0.598940\n",
      "iteration 196 / 300: loss 0.603876\n",
      "iteration 196 / 300: loss 0.615261\n",
      "iteration 196 / 300: loss 0.588227\n",
      "iteration 196 / 300: loss 0.627171\n",
      "iteration 196 / 300: loss 0.592600\n",
      "iteration 196 / 300: loss 0.621500\n",
      "iteration 196 / 300: loss 0.593093\n",
      "iteration 196 / 300: loss 0.600541\n",
      "iteration 196 / 300: loss 0.571000\n",
      "iteration 196 / 300: loss 0.592911\n",
      "iteration 196 / 300: loss 0.600043\n",
      "iteration 196 / 300: loss 0.598053\n",
      "iteration 196 / 300: loss 0.583712\n",
      "iteration 196 / 300: loss 0.614355\n",
      "iteration 196 / 300: loss 0.591285\n",
      "iteration 196 / 300: loss 0.591391\n",
      "iteration 196 / 300: loss 0.594005\n",
      "iteration 196 / 300: loss 0.596735\n",
      "iteration 196 / 300: loss 0.596712\n",
      "iteration 196 / 300: loss 0.611735\n",
      "iteration 196 / 300: loss 0.607258\n",
      "iteration 196 / 300: loss 0.597031\n",
      "iteration 196 / 300: loss 0.596301\n",
      "iteration 196 / 300: loss 0.627391\n",
      "iteration 196 / 300: loss 0.601584\n",
      "iteration 196 / 300: loss 0.599923\n",
      "iteration 196 / 300: loss 0.621952\n",
      "iteration 196 / 300: loss 0.581435\n",
      "iteration 196 / 300: loss 0.599604\n",
      "iteration 196 / 300: loss 0.591182\n",
      "iteration 196 / 300: loss 0.599919\n",
      "iteration 196 / 300: loss 0.596015\n",
      "iteration 196 / 300: loss 0.590760\n",
      "iteration 196 / 300: loss 0.591961\n",
      "iteration 196 / 300: loss 0.615468\n",
      "iteration 196 / 300: loss 0.621360\n",
      "iteration 196 / 300: loss 0.587267\n",
      "iteration 196 / 300: loss 0.582483\n",
      "iteration 196 / 300: loss 0.585572\n",
      "iteration 196 / 300: loss 0.603666\n",
      "iteration 196 / 300: loss 0.585192\n",
      "iteration 196 / 300: loss 0.578880\n",
      "iteration 196 / 300: loss 0.576418\n",
      "iteration 196 / 300: loss 0.574097\n",
      "iteration 196 / 300: loss 0.600500\n",
      "iteration 196 / 300: loss 0.584490\n",
      "iteration 196 / 300: loss 0.584834\n",
      "iteration 196 / 300: loss 0.568323\n",
      "iteration 196 / 300: loss 0.592025\n",
      "iteration 196 / 300: loss 0.612116\n",
      "iteration 196 / 300: loss 0.608923\n",
      "iteration 196 / 300: loss 0.607613\n",
      "iteration 196 / 300: loss 0.595533\n",
      "iteration 196 / 300: loss 0.592837\n",
      "iteration 196 / 300: loss 0.597988\n",
      "iteration 196 / 300: loss 0.597677\n",
      "iteration 196 / 300: loss 0.600953\n",
      "iteration 196 / 300: loss 0.597422\n",
      "iteration 196 / 300: loss 0.598776\n",
      "iteration 196 / 300: loss 0.587806\n",
      "iteration 196 / 300: loss 0.600499\n",
      "iteration 196 / 300: loss 0.599650\n",
      "iteration 196 / 300: loss 0.617540\n",
      "iteration 196 / 300: loss 0.598875\n",
      "iteration 196 / 300: loss 0.600801\n",
      "iteration 196 / 300: loss 0.605305\n",
      "iteration 196 / 300: loss 0.598592\n",
      "iteration 196 / 300: loss 0.591474\n",
      "iteration 196 / 300: loss 0.580382\n",
      "iteration 196 / 300: loss 0.598221\n",
      "iteration 196 / 300: loss 0.611685\n",
      "iteration 196 / 300: loss 0.613219\n",
      "iteration 196 / 300: loss 0.582214\n",
      "iteration 196 / 300: loss 0.601955\n",
      "iteration 196 / 300: loss 0.608956\n",
      "iteration 196 / 300: loss 0.601794\n",
      "iteration 196 / 300: loss 0.607944\n",
      "iteration 196 / 300: loss 0.620236\n",
      "iteration 196 / 300: loss 0.584817\n",
      "iteration 196 / 300: loss 0.583721\n",
      "iteration 196 / 300: loss 0.628849\n",
      "iteration 196 / 300: loss 0.609399\n",
      "iteration 196 / 300: loss 0.606265\n",
      "iteration 196 / 300: loss 0.599034\n",
      "iteration 196 / 300: loss 0.615876\n",
      "iteration 196 / 300: loss 0.596489\n",
      "iteration 196 / 300: loss 0.581430\n",
      "iteration 196 / 300: loss 0.609807\n",
      "iteration 196 / 300: loss 0.608125\n",
      "iteration 196 / 300: loss 0.598224\n",
      "iteration 196 / 300: loss 0.592022\n",
      "iteration 196 / 300: loss 0.611031\n",
      "iteration 196 / 300: loss 0.598550\n",
      "iteration 196 / 300: loss 0.581382\n",
      "iteration 196 / 300: loss 0.609580\n",
      "iteration 197 / 300: loss 0.578384\n",
      "iteration 197 / 300: loss 0.596214\n",
      "iteration 197 / 300: loss 0.569455\n",
      "iteration 197 / 300: loss 0.597849\n",
      "iteration 197 / 300: loss 0.598940\n",
      "iteration 197 / 300: loss 0.603876\n",
      "iteration 197 / 300: loss 0.615261\n",
      "iteration 197 / 300: loss 0.588227\n",
      "iteration 197 / 300: loss 0.627171\n",
      "iteration 197 / 300: loss 0.592600\n",
      "iteration 197 / 300: loss 0.621500\n",
      "iteration 197 / 300: loss 0.593093\n",
      "iteration 197 / 300: loss 0.600541\n",
      "iteration 197 / 300: loss 0.571000\n",
      "iteration 197 / 300: loss 0.592911\n",
      "iteration 197 / 300: loss 0.600043\n",
      "iteration 197 / 300: loss 0.598053\n",
      "iteration 197 / 300: loss 0.583712\n",
      "iteration 197 / 300: loss 0.614355\n",
      "iteration 197 / 300: loss 0.591285\n",
      "iteration 197 / 300: loss 0.591391\n",
      "iteration 197 / 300: loss 0.594005\n",
      "iteration 197 / 300: loss 0.596735\n",
      "iteration 197 / 300: loss 0.596712\n",
      "iteration 197 / 300: loss 0.611735\n",
      "iteration 197 / 300: loss 0.607258\n",
      "iteration 197 / 300: loss 0.597031\n",
      "iteration 197 / 300: loss 0.596301\n",
      "iteration 197 / 300: loss 0.627391\n",
      "iteration 197 / 300: loss 0.601584\n",
      "iteration 197 / 300: loss 0.599923\n",
      "iteration 197 / 300: loss 0.621952\n",
      "iteration 197 / 300: loss 0.581435\n",
      "iteration 197 / 300: loss 0.599604\n",
      "iteration 197 / 300: loss 0.591182\n",
      "iteration 197 / 300: loss 0.599919\n",
      "iteration 197 / 300: loss 0.596015\n",
      "iteration 197 / 300: loss 0.590760\n",
      "iteration 197 / 300: loss 0.591961\n",
      "iteration 197 / 300: loss 0.615468\n",
      "iteration 197 / 300: loss 0.621360\n",
      "iteration 197 / 300: loss 0.587267\n",
      "iteration 197 / 300: loss 0.582483\n",
      "iteration 197 / 300: loss 0.585572\n",
      "iteration 197 / 300: loss 0.603666\n",
      "iteration 197 / 300: loss 0.585192\n",
      "iteration 197 / 300: loss 0.578880\n",
      "iteration 197 / 300: loss 0.576418\n",
      "iteration 197 / 300: loss 0.574097\n",
      "iteration 197 / 300: loss 0.600500\n",
      "iteration 197 / 300: loss 0.584490\n",
      "iteration 197 / 300: loss 0.584834\n",
      "iteration 197 / 300: loss 0.568323\n",
      "iteration 197 / 300: loss 0.592025\n",
      "iteration 197 / 300: loss 0.612116\n",
      "iteration 197 / 300: loss 0.608923\n",
      "iteration 197 / 300: loss 0.607613\n",
      "iteration 197 / 300: loss 0.595533\n",
      "iteration 197 / 300: loss 0.592837\n",
      "iteration 197 / 300: loss 0.597988\n",
      "iteration 197 / 300: loss 0.597677\n",
      "iteration 197 / 300: loss 0.600953\n",
      "iteration 197 / 300: loss 0.597422\n",
      "iteration 197 / 300: loss 0.598776\n",
      "iteration 197 / 300: loss 0.587806\n",
      "iteration 197 / 300: loss 0.600499\n",
      "iteration 197 / 300: loss 0.599650\n",
      "iteration 197 / 300: loss 0.617540\n",
      "iteration 197 / 300: loss 0.598875\n",
      "iteration 197 / 300: loss 0.600801\n",
      "iteration 197 / 300: loss 0.605305\n",
      "iteration 197 / 300: loss 0.598592\n",
      "iteration 197 / 300: loss 0.591474\n",
      "iteration 197 / 300: loss 0.580382\n",
      "iteration 197 / 300: loss 0.598221\n",
      "iteration 197 / 300: loss 0.611685\n",
      "iteration 197 / 300: loss 0.613219\n",
      "iteration 197 / 300: loss 0.582214\n",
      "iteration 197 / 300: loss 0.601955\n",
      "iteration 197 / 300: loss 0.608956\n",
      "iteration 197 / 300: loss 0.601794\n",
      "iteration 197 / 300: loss 0.607944\n",
      "iteration 197 / 300: loss 0.620236\n",
      "iteration 197 / 300: loss 0.584817\n",
      "iteration 197 / 300: loss 0.583721\n",
      "iteration 197 / 300: loss 0.628849\n",
      "iteration 197 / 300: loss 0.609399\n",
      "iteration 197 / 300: loss 0.606265\n",
      "iteration 197 / 300: loss 0.599034\n",
      "iteration 197 / 300: loss 0.615876\n",
      "iteration 197 / 300: loss 0.596489\n",
      "iteration 197 / 300: loss 0.581430\n",
      "iteration 197 / 300: loss 0.609807\n",
      "iteration 197 / 300: loss 0.608125\n",
      "iteration 197 / 300: loss 0.598224\n",
      "iteration 197 / 300: loss 0.592022\n",
      "iteration 197 / 300: loss 0.611031\n",
      "iteration 197 / 300: loss 0.598550\n",
      "iteration 197 / 300: loss 0.581382\n",
      "iteration 197 / 300: loss 0.609580\n",
      "iteration 198 / 300: loss 0.578384\n",
      "iteration 198 / 300: loss 0.596214\n",
      "iteration 198 / 300: loss 0.569455\n",
      "iteration 198 / 300: loss 0.597849\n",
      "iteration 198 / 300: loss 0.598940\n",
      "iteration 198 / 300: loss 0.603876\n",
      "iteration 198 / 300: loss 0.615261\n",
      "iteration 198 / 300: loss 0.588227\n",
      "iteration 198 / 300: loss 0.627171\n",
      "iteration 198 / 300: loss 0.592600\n",
      "iteration 198 / 300: loss 0.621500\n",
      "iteration 198 / 300: loss 0.593093\n",
      "iteration 198 / 300: loss 0.600541\n",
      "iteration 198 / 300: loss 0.571000\n",
      "iteration 198 / 300: loss 0.592911\n",
      "iteration 198 / 300: loss 0.600043\n",
      "iteration 198 / 300: loss 0.598053\n",
      "iteration 198 / 300: loss 0.583712\n",
      "iteration 198 / 300: loss 0.614355\n",
      "iteration 198 / 300: loss 0.591285\n",
      "iteration 198 / 300: loss 0.591391\n",
      "iteration 198 / 300: loss 0.594005\n",
      "iteration 198 / 300: loss 0.596735\n",
      "iteration 198 / 300: loss 0.596712\n",
      "iteration 198 / 300: loss 0.611735\n",
      "iteration 198 / 300: loss 0.607258\n",
      "iteration 198 / 300: loss 0.597031\n",
      "iteration 198 / 300: loss 0.596301\n",
      "iteration 198 / 300: loss 0.627391\n",
      "iteration 198 / 300: loss 0.601584\n",
      "iteration 198 / 300: loss 0.599923\n",
      "iteration 198 / 300: loss 0.621952\n",
      "iteration 198 / 300: loss 0.581435\n",
      "iteration 198 / 300: loss 0.599604\n",
      "iteration 198 / 300: loss 0.591182\n",
      "iteration 198 / 300: loss 0.599919\n",
      "iteration 198 / 300: loss 0.596015\n",
      "iteration 198 / 300: loss 0.590760\n",
      "iteration 198 / 300: loss 0.591961\n",
      "iteration 198 / 300: loss 0.615468\n",
      "iteration 198 / 300: loss 0.621360\n",
      "iteration 198 / 300: loss 0.587267\n",
      "iteration 198 / 300: loss 0.582483\n",
      "iteration 198 / 300: loss 0.585572\n",
      "iteration 198 / 300: loss 0.603666\n",
      "iteration 198 / 300: loss 0.585192\n",
      "iteration 198 / 300: loss 0.578880\n",
      "iteration 198 / 300: loss 0.576418\n",
      "iteration 198 / 300: loss 0.574097\n",
      "iteration 198 / 300: loss 0.600500\n",
      "iteration 198 / 300: loss 0.584490\n",
      "iteration 198 / 300: loss 0.584834\n",
      "iteration 198 / 300: loss 0.568323\n",
      "iteration 198 / 300: loss 0.592025\n",
      "iteration 198 / 300: loss 0.612116\n",
      "iteration 198 / 300: loss 0.608923\n",
      "iteration 198 / 300: loss 0.607613\n",
      "iteration 198 / 300: loss 0.595533\n",
      "iteration 198 / 300: loss 0.592837\n",
      "iteration 198 / 300: loss 0.597988\n",
      "iteration 198 / 300: loss 0.597677\n",
      "iteration 198 / 300: loss 0.600953\n",
      "iteration 198 / 300: loss 0.597422\n",
      "iteration 198 / 300: loss 0.598776\n",
      "iteration 198 / 300: loss 0.587806\n",
      "iteration 198 / 300: loss 0.600499\n",
      "iteration 198 / 300: loss 0.599650\n",
      "iteration 198 / 300: loss 0.617540\n",
      "iteration 198 / 300: loss 0.598875\n",
      "iteration 198 / 300: loss 0.600801\n",
      "iteration 198 / 300: loss 0.605305\n",
      "iteration 198 / 300: loss 0.598592\n",
      "iteration 198 / 300: loss 0.591474\n",
      "iteration 198 / 300: loss 0.580382\n",
      "iteration 198 / 300: loss 0.598221\n",
      "iteration 198 / 300: loss 0.611685\n",
      "iteration 198 / 300: loss 0.613219\n",
      "iteration 198 / 300: loss 0.582214\n",
      "iteration 198 / 300: loss 0.601955\n",
      "iteration 198 / 300: loss 0.608956\n",
      "iteration 198 / 300: loss 0.601794\n",
      "iteration 198 / 300: loss 0.607944\n",
      "iteration 198 / 300: loss 0.620236\n",
      "iteration 198 / 300: loss 0.584817\n",
      "iteration 198 / 300: loss 0.583721\n",
      "iteration 198 / 300: loss 0.628849\n",
      "iteration 198 / 300: loss 0.609399\n",
      "iteration 198 / 300: loss 0.606265\n",
      "iteration 198 / 300: loss 0.599034\n",
      "iteration 198 / 300: loss 0.615876\n",
      "iteration 198 / 300: loss 0.596489\n",
      "iteration 198 / 300: loss 0.581430\n",
      "iteration 198 / 300: loss 0.609807\n",
      "iteration 198 / 300: loss 0.608125\n",
      "iteration 198 / 300: loss 0.598224\n",
      "iteration 198 / 300: loss 0.592022\n",
      "iteration 198 / 300: loss 0.611031\n",
      "iteration 198 / 300: loss 0.598550\n",
      "iteration 198 / 300: loss 0.581382\n",
      "iteration 198 / 300: loss 0.609580\n",
      "iteration 199 / 300: loss 0.578384\n",
      "iteration 199 / 300: loss 0.596214\n",
      "iteration 199 / 300: loss 0.569455\n",
      "iteration 199 / 300: loss 0.597849\n",
      "iteration 199 / 300: loss 0.598940\n",
      "iteration 199 / 300: loss 0.603876\n",
      "iteration 199 / 300: loss 0.615261\n",
      "iteration 199 / 300: loss 0.588227\n",
      "iteration 199 / 300: loss 0.627171\n",
      "iteration 199 / 300: loss 0.592600\n",
      "iteration 199 / 300: loss 0.621500\n",
      "iteration 199 / 300: loss 0.593093\n",
      "iteration 199 / 300: loss 0.600541\n",
      "iteration 199 / 300: loss 0.571000\n",
      "iteration 199 / 300: loss 0.592911\n",
      "iteration 199 / 300: loss 0.600043\n",
      "iteration 199 / 300: loss 0.598053\n",
      "iteration 199 / 300: loss 0.583712\n",
      "iteration 199 / 300: loss 0.614355\n",
      "iteration 199 / 300: loss 0.591285\n",
      "iteration 199 / 300: loss 0.591391\n",
      "iteration 199 / 300: loss 0.594005\n",
      "iteration 199 / 300: loss 0.596735\n",
      "iteration 199 / 300: loss 0.596712\n",
      "iteration 199 / 300: loss 0.611735\n",
      "iteration 199 / 300: loss 0.607258\n",
      "iteration 199 / 300: loss 0.597031\n",
      "iteration 199 / 300: loss 0.596301\n",
      "iteration 199 / 300: loss 0.627391\n",
      "iteration 199 / 300: loss 0.601584\n",
      "iteration 199 / 300: loss 0.599923\n",
      "iteration 199 / 300: loss 0.621952\n",
      "iteration 199 / 300: loss 0.581435\n",
      "iteration 199 / 300: loss 0.599604\n",
      "iteration 199 / 300: loss 0.591182\n",
      "iteration 199 / 300: loss 0.599919\n",
      "iteration 199 / 300: loss 0.596015\n",
      "iteration 199 / 300: loss 0.590760\n",
      "iteration 199 / 300: loss 0.591961\n",
      "iteration 199 / 300: loss 0.615468\n",
      "iteration 199 / 300: loss 0.621360\n",
      "iteration 199 / 300: loss 0.587267\n",
      "iteration 199 / 300: loss 0.582483\n",
      "iteration 199 / 300: loss 0.585572\n",
      "iteration 199 / 300: loss 0.603666\n",
      "iteration 199 / 300: loss 0.585192\n",
      "iteration 199 / 300: loss 0.578880\n",
      "iteration 199 / 300: loss 0.576418\n",
      "iteration 199 / 300: loss 0.574097\n",
      "iteration 199 / 300: loss 0.600500\n",
      "iteration 199 / 300: loss 0.584490\n",
      "iteration 199 / 300: loss 0.584834\n",
      "iteration 199 / 300: loss 0.568323\n",
      "iteration 199 / 300: loss 0.592025\n",
      "iteration 199 / 300: loss 0.612116\n",
      "iteration 199 / 300: loss 0.608923\n",
      "iteration 199 / 300: loss 0.607613\n",
      "iteration 199 / 300: loss 0.595533\n",
      "iteration 199 / 300: loss 0.592837\n",
      "iteration 199 / 300: loss 0.597988\n",
      "iteration 199 / 300: loss 0.597677\n",
      "iteration 199 / 300: loss 0.600953\n",
      "iteration 199 / 300: loss 0.597422\n",
      "iteration 199 / 300: loss 0.598776\n",
      "iteration 199 / 300: loss 0.587806\n",
      "iteration 199 / 300: loss 0.600499\n",
      "iteration 199 / 300: loss 0.599650\n",
      "iteration 199 / 300: loss 0.617540\n",
      "iteration 199 / 300: loss 0.598875\n",
      "iteration 199 / 300: loss 0.600801\n",
      "iteration 199 / 300: loss 0.605305\n",
      "iteration 199 / 300: loss 0.598592\n",
      "iteration 199 / 300: loss 0.591474\n",
      "iteration 199 / 300: loss 0.580382\n",
      "iteration 199 / 300: loss 0.598221\n",
      "iteration 199 / 300: loss 0.611685\n",
      "iteration 199 / 300: loss 0.613219\n",
      "iteration 199 / 300: loss 0.582214\n",
      "iteration 199 / 300: loss 0.601955\n",
      "iteration 199 / 300: loss 0.608956\n",
      "iteration 199 / 300: loss 0.601794\n",
      "iteration 199 / 300: loss 0.607944\n",
      "iteration 199 / 300: loss 0.620236\n",
      "iteration 199 / 300: loss 0.584817\n",
      "iteration 199 / 300: loss 0.583721\n",
      "iteration 199 / 300: loss 0.628849\n",
      "iteration 199 / 300: loss 0.609399\n",
      "iteration 199 / 300: loss 0.606265\n",
      "iteration 199 / 300: loss 0.599034\n",
      "iteration 199 / 300: loss 0.615876\n",
      "iteration 199 / 300: loss 0.596489\n",
      "iteration 199 / 300: loss 0.581430\n",
      "iteration 199 / 300: loss 0.609807\n",
      "iteration 199 / 300: loss 0.608125\n",
      "iteration 199 / 300: loss 0.598224\n",
      "iteration 199 / 300: loss 0.592022\n",
      "iteration 199 / 300: loss 0.611031\n",
      "iteration 199 / 300: loss 0.598550\n",
      "iteration 199 / 300: loss 0.581382\n",
      "iteration 199 / 300: loss 0.609580\n",
      "iteration 200 / 300: loss 0.578384\n",
      "iteration 200 / 300: loss 0.596214\n",
      "iteration 200 / 300: loss 0.569455\n",
      "iteration 200 / 300: loss 0.597849\n",
      "iteration 200 / 300: loss 0.598940\n",
      "iteration 200 / 300: loss 0.603876\n",
      "iteration 200 / 300: loss 0.615261\n",
      "iteration 200 / 300: loss 0.588227\n",
      "iteration 200 / 300: loss 0.627171\n",
      "iteration 200 / 300: loss 0.592600\n",
      "iteration 200 / 300: loss 0.621500\n",
      "iteration 200 / 300: loss 0.593093\n",
      "iteration 200 / 300: loss 0.600541\n",
      "iteration 200 / 300: loss 0.571000\n",
      "iteration 200 / 300: loss 0.592911\n",
      "iteration 200 / 300: loss 0.600043\n",
      "iteration 200 / 300: loss 0.598053\n",
      "iteration 200 / 300: loss 0.583712\n",
      "iteration 200 / 300: loss 0.614355\n",
      "iteration 200 / 300: loss 0.591285\n",
      "iteration 200 / 300: loss 0.591391\n",
      "iteration 200 / 300: loss 0.594005\n",
      "iteration 200 / 300: loss 0.596735\n",
      "iteration 200 / 300: loss 0.596712\n",
      "iteration 200 / 300: loss 0.611735\n",
      "iteration 200 / 300: loss 0.607258\n",
      "iteration 200 / 300: loss 0.597031\n",
      "iteration 200 / 300: loss 0.596301\n",
      "iteration 200 / 300: loss 0.627391\n",
      "iteration 200 / 300: loss 0.601584\n",
      "iteration 200 / 300: loss 0.599923\n",
      "iteration 200 / 300: loss 0.621952\n",
      "iteration 200 / 300: loss 0.581435\n",
      "iteration 200 / 300: loss 0.599604\n",
      "iteration 200 / 300: loss 0.591182\n",
      "iteration 200 / 300: loss 0.599919\n",
      "iteration 200 / 300: loss 0.596015\n",
      "iteration 200 / 300: loss 0.590760\n",
      "iteration 200 / 300: loss 0.591961\n",
      "iteration 200 / 300: loss 0.615468\n",
      "iteration 200 / 300: loss 0.621360\n",
      "iteration 200 / 300: loss 0.587267\n",
      "iteration 200 / 300: loss 0.582483\n",
      "iteration 200 / 300: loss 0.585572\n",
      "iteration 200 / 300: loss 0.603666\n",
      "iteration 200 / 300: loss 0.585192\n",
      "iteration 200 / 300: loss 0.578880\n",
      "iteration 200 / 300: loss 0.576418\n",
      "iteration 200 / 300: loss 0.574097\n",
      "iteration 200 / 300: loss 0.600500\n",
      "iteration 200 / 300: loss 0.584490\n",
      "iteration 200 / 300: loss 0.584834\n",
      "iteration 200 / 300: loss 0.568323\n",
      "iteration 200 / 300: loss 0.592025\n",
      "iteration 200 / 300: loss 0.612116\n",
      "iteration 200 / 300: loss 0.608923\n",
      "iteration 200 / 300: loss 0.607613\n",
      "iteration 200 / 300: loss 0.595533\n",
      "iteration 200 / 300: loss 0.592837\n",
      "iteration 200 / 300: loss 0.597988\n",
      "iteration 200 / 300: loss 0.597677\n",
      "iteration 200 / 300: loss 0.600953\n",
      "iteration 200 / 300: loss 0.597422\n",
      "iteration 200 / 300: loss 0.598776\n",
      "iteration 200 / 300: loss 0.587806\n",
      "iteration 200 / 300: loss 0.600499\n",
      "iteration 200 / 300: loss 0.599650\n",
      "iteration 200 / 300: loss 0.617540\n",
      "iteration 200 / 300: loss 0.598875\n",
      "iteration 200 / 300: loss 0.600801\n",
      "iteration 200 / 300: loss 0.605305\n",
      "iteration 200 / 300: loss 0.598592\n",
      "iteration 200 / 300: loss 0.591474\n",
      "iteration 200 / 300: loss 0.580382\n",
      "iteration 200 / 300: loss 0.598221\n",
      "iteration 200 / 300: loss 0.611685\n",
      "iteration 200 / 300: loss 0.613219\n",
      "iteration 200 / 300: loss 0.582214\n",
      "iteration 200 / 300: loss 0.601955\n",
      "iteration 200 / 300: loss 0.608956\n",
      "iteration 200 / 300: loss 0.601794\n",
      "iteration 200 / 300: loss 0.607944\n",
      "iteration 200 / 300: loss 0.620236\n",
      "iteration 200 / 300: loss 0.584817\n",
      "iteration 200 / 300: loss 0.583721\n",
      "iteration 200 / 300: loss 0.628849\n",
      "iteration 200 / 300: loss 0.609399\n",
      "iteration 200 / 300: loss 0.606265\n",
      "iteration 200 / 300: loss 0.599034\n",
      "iteration 200 / 300: loss 0.615876\n",
      "iteration 200 / 300: loss 0.596489\n",
      "iteration 200 / 300: loss 0.581430\n",
      "iteration 200 / 300: loss 0.609807\n",
      "iteration 200 / 300: loss 0.608125\n",
      "iteration 200 / 300: loss 0.598224\n",
      "iteration 200 / 300: loss 0.592022\n",
      "iteration 200 / 300: loss 0.611031\n",
      "iteration 200 / 300: loss 0.598550\n",
      "iteration 200 / 300: loss 0.581382\n",
      "iteration 200 / 300: loss 0.609580\n",
      "iteration 201 / 300: loss 0.578384\n",
      "iteration 201 / 300: loss 0.596214\n",
      "iteration 201 / 300: loss 0.569455\n",
      "iteration 201 / 300: loss 0.597849\n",
      "iteration 201 / 300: loss 0.598940\n",
      "iteration 201 / 300: loss 0.603876\n",
      "iteration 201 / 300: loss 0.615261\n",
      "iteration 201 / 300: loss 0.588227\n",
      "iteration 201 / 300: loss 0.627171\n",
      "iteration 201 / 300: loss 0.592600\n",
      "iteration 201 / 300: loss 0.621500\n",
      "iteration 201 / 300: loss 0.593093\n",
      "iteration 201 / 300: loss 0.600541\n",
      "iteration 201 / 300: loss 0.571000\n",
      "iteration 201 / 300: loss 0.592911\n",
      "iteration 201 / 300: loss 0.600043\n",
      "iteration 201 / 300: loss 0.598053\n",
      "iteration 201 / 300: loss 0.583712\n",
      "iteration 201 / 300: loss 0.614355\n",
      "iteration 201 / 300: loss 0.591285\n",
      "iteration 201 / 300: loss 0.591391\n",
      "iteration 201 / 300: loss 0.594005\n",
      "iteration 201 / 300: loss 0.596735\n",
      "iteration 201 / 300: loss 0.596712\n",
      "iteration 201 / 300: loss 0.611735\n",
      "iteration 201 / 300: loss 0.607258\n",
      "iteration 201 / 300: loss 0.597031\n",
      "iteration 201 / 300: loss 0.596301\n",
      "iteration 201 / 300: loss 0.627391\n",
      "iteration 201 / 300: loss 0.601584\n",
      "iteration 201 / 300: loss 0.599923\n",
      "iteration 201 / 300: loss 0.621952\n",
      "iteration 201 / 300: loss 0.581435\n",
      "iteration 201 / 300: loss 0.599604\n",
      "iteration 201 / 300: loss 0.591182\n",
      "iteration 201 / 300: loss 0.599919\n",
      "iteration 201 / 300: loss 0.596015\n",
      "iteration 201 / 300: loss 0.590760\n",
      "iteration 201 / 300: loss 0.591961\n",
      "iteration 201 / 300: loss 0.615468\n",
      "iteration 201 / 300: loss 0.621360\n",
      "iteration 201 / 300: loss 0.587267\n",
      "iteration 201 / 300: loss 0.582483\n",
      "iteration 201 / 300: loss 0.585572\n",
      "iteration 201 / 300: loss 0.603666\n",
      "iteration 201 / 300: loss 0.585192\n",
      "iteration 201 / 300: loss 0.578880\n",
      "iteration 201 / 300: loss 0.576418\n",
      "iteration 201 / 300: loss 0.574097\n",
      "iteration 201 / 300: loss 0.600500\n",
      "iteration 201 / 300: loss 0.584490\n",
      "iteration 201 / 300: loss 0.584834\n",
      "iteration 201 / 300: loss 0.568323\n",
      "iteration 201 / 300: loss 0.592025\n",
      "iteration 201 / 300: loss 0.612116\n",
      "iteration 201 / 300: loss 0.608923\n",
      "iteration 201 / 300: loss 0.607613\n",
      "iteration 201 / 300: loss 0.595533\n",
      "iteration 201 / 300: loss 0.592837\n",
      "iteration 201 / 300: loss 0.597988\n",
      "iteration 201 / 300: loss 0.597677\n",
      "iteration 201 / 300: loss 0.600953\n",
      "iteration 201 / 300: loss 0.597422\n",
      "iteration 201 / 300: loss 0.598776\n",
      "iteration 201 / 300: loss 0.587806\n",
      "iteration 201 / 300: loss 0.600499\n",
      "iteration 201 / 300: loss 0.599650\n",
      "iteration 201 / 300: loss 0.617540\n",
      "iteration 201 / 300: loss 0.598875\n",
      "iteration 201 / 300: loss 0.600801\n",
      "iteration 201 / 300: loss 0.605305\n",
      "iteration 201 / 300: loss 0.598592\n",
      "iteration 201 / 300: loss 0.591474\n",
      "iteration 201 / 300: loss 0.580382\n",
      "iteration 201 / 300: loss 0.598221\n",
      "iteration 201 / 300: loss 0.611685\n",
      "iteration 201 / 300: loss 0.613219\n",
      "iteration 201 / 300: loss 0.582214\n",
      "iteration 201 / 300: loss 0.601955\n",
      "iteration 201 / 300: loss 0.608956\n",
      "iteration 201 / 300: loss 0.601794\n",
      "iteration 201 / 300: loss 0.607944\n",
      "iteration 201 / 300: loss 0.620236\n",
      "iteration 201 / 300: loss 0.584817\n",
      "iteration 201 / 300: loss 0.583721\n",
      "iteration 201 / 300: loss 0.628849\n",
      "iteration 201 / 300: loss 0.609399\n",
      "iteration 201 / 300: loss 0.606265\n",
      "iteration 201 / 300: loss 0.599034\n",
      "iteration 201 / 300: loss 0.615876\n",
      "iteration 201 / 300: loss 0.596489\n",
      "iteration 201 / 300: loss 0.581430\n",
      "iteration 201 / 300: loss 0.609807\n",
      "iteration 201 / 300: loss 0.608125\n",
      "iteration 201 / 300: loss 0.598224\n",
      "iteration 201 / 300: loss 0.592022\n",
      "iteration 201 / 300: loss 0.611031\n",
      "iteration 201 / 300: loss 0.598550\n",
      "iteration 201 / 300: loss 0.581382\n",
      "iteration 201 / 300: loss 0.609580\n",
      "iteration 202 / 300: loss 0.578384\n",
      "iteration 202 / 300: loss 0.596214\n",
      "iteration 202 / 300: loss 0.569455\n",
      "iteration 202 / 300: loss 0.597849\n",
      "iteration 202 / 300: loss 0.598940\n",
      "iteration 202 / 300: loss 0.603876\n",
      "iteration 202 / 300: loss 0.615261\n",
      "iteration 202 / 300: loss 0.588227\n",
      "iteration 202 / 300: loss 0.627171\n",
      "iteration 202 / 300: loss 0.592600\n",
      "iteration 202 / 300: loss 0.621500\n",
      "iteration 202 / 300: loss 0.593093\n",
      "iteration 202 / 300: loss 0.600541\n",
      "iteration 202 / 300: loss 0.571000\n",
      "iteration 202 / 300: loss 0.592911\n",
      "iteration 202 / 300: loss 0.600043\n",
      "iteration 202 / 300: loss 0.598053\n",
      "iteration 202 / 300: loss 0.583712\n",
      "iteration 202 / 300: loss 0.614355\n",
      "iteration 202 / 300: loss 0.591285\n",
      "iteration 202 / 300: loss 0.591391\n",
      "iteration 202 / 300: loss 0.594005\n",
      "iteration 202 / 300: loss 0.596735\n",
      "iteration 202 / 300: loss 0.596712\n",
      "iteration 202 / 300: loss 0.611735\n",
      "iteration 202 / 300: loss 0.607258\n",
      "iteration 202 / 300: loss 0.597031\n",
      "iteration 202 / 300: loss 0.596301\n",
      "iteration 202 / 300: loss 0.627391\n",
      "iteration 202 / 300: loss 0.601584\n",
      "iteration 202 / 300: loss 0.599923\n",
      "iteration 202 / 300: loss 0.621952\n",
      "iteration 202 / 300: loss 0.581435\n",
      "iteration 202 / 300: loss 0.599604\n",
      "iteration 202 / 300: loss 0.591182\n",
      "iteration 202 / 300: loss 0.599919\n",
      "iteration 202 / 300: loss 0.596015\n",
      "iteration 202 / 300: loss 0.590760\n",
      "iteration 202 / 300: loss 0.591961\n",
      "iteration 202 / 300: loss 0.615468\n",
      "iteration 202 / 300: loss 0.621360\n",
      "iteration 202 / 300: loss 0.587267\n",
      "iteration 202 / 300: loss 0.582483\n",
      "iteration 202 / 300: loss 0.585572\n",
      "iteration 202 / 300: loss 0.603666\n",
      "iteration 202 / 300: loss 0.585192\n",
      "iteration 202 / 300: loss 0.578880\n",
      "iteration 202 / 300: loss 0.576418\n",
      "iteration 202 / 300: loss 0.574097\n",
      "iteration 202 / 300: loss 0.600500\n",
      "iteration 202 / 300: loss 0.584490\n",
      "iteration 202 / 300: loss 0.584834\n",
      "iteration 202 / 300: loss 0.568323\n",
      "iteration 202 / 300: loss 0.592025\n",
      "iteration 202 / 300: loss 0.612116\n",
      "iteration 202 / 300: loss 0.608923\n",
      "iteration 202 / 300: loss 0.607613\n",
      "iteration 202 / 300: loss 0.595533\n",
      "iteration 202 / 300: loss 0.592837\n",
      "iteration 202 / 300: loss 0.597988\n",
      "iteration 202 / 300: loss 0.597677\n",
      "iteration 202 / 300: loss 0.600953\n",
      "iteration 202 / 300: loss 0.597422\n",
      "iteration 202 / 300: loss 0.598776\n",
      "iteration 202 / 300: loss 0.587806\n",
      "iteration 202 / 300: loss 0.600499\n",
      "iteration 202 / 300: loss 0.599650\n",
      "iteration 202 / 300: loss 0.617540\n",
      "iteration 202 / 300: loss 0.598875\n",
      "iteration 202 / 300: loss 0.600801\n",
      "iteration 202 / 300: loss 0.605305\n",
      "iteration 202 / 300: loss 0.598592\n",
      "iteration 202 / 300: loss 0.591474\n",
      "iteration 202 / 300: loss 0.580382\n",
      "iteration 202 / 300: loss 0.598221\n",
      "iteration 202 / 300: loss 0.611685\n",
      "iteration 202 / 300: loss 0.613219\n",
      "iteration 202 / 300: loss 0.582214\n",
      "iteration 202 / 300: loss 0.601955\n",
      "iteration 202 / 300: loss 0.608956\n",
      "iteration 202 / 300: loss 0.601794\n",
      "iteration 202 / 300: loss 0.607944\n",
      "iteration 202 / 300: loss 0.620236\n",
      "iteration 202 / 300: loss 0.584817\n",
      "iteration 202 / 300: loss 0.583721\n",
      "iteration 202 / 300: loss 0.628849\n",
      "iteration 202 / 300: loss 0.609399\n",
      "iteration 202 / 300: loss 0.606265\n",
      "iteration 202 / 300: loss 0.599034\n",
      "iteration 202 / 300: loss 0.615876\n",
      "iteration 202 / 300: loss 0.596489\n",
      "iteration 202 / 300: loss 0.581430\n",
      "iteration 202 / 300: loss 0.609807\n",
      "iteration 202 / 300: loss 0.608125\n",
      "iteration 202 / 300: loss 0.598224\n",
      "iteration 202 / 300: loss 0.592022\n",
      "iteration 202 / 300: loss 0.611031\n",
      "iteration 202 / 300: loss 0.598550\n",
      "iteration 202 / 300: loss 0.581382\n",
      "iteration 202 / 300: loss 0.609580\n",
      "iteration 203 / 300: loss 0.578384\n",
      "iteration 203 / 300: loss 0.596214\n",
      "iteration 203 / 300: loss 0.569455\n",
      "iteration 203 / 300: loss 0.597849\n",
      "iteration 203 / 300: loss 0.598940\n",
      "iteration 203 / 300: loss 0.603876\n",
      "iteration 203 / 300: loss 0.615261\n",
      "iteration 203 / 300: loss 0.588227\n",
      "iteration 203 / 300: loss 0.627171\n",
      "iteration 203 / 300: loss 0.592600\n",
      "iteration 203 / 300: loss 0.621500\n",
      "iteration 203 / 300: loss 0.593093\n",
      "iteration 203 / 300: loss 0.600541\n",
      "iteration 203 / 300: loss 0.571000\n",
      "iteration 203 / 300: loss 0.592911\n",
      "iteration 203 / 300: loss 0.600043\n",
      "iteration 203 / 300: loss 0.598053\n",
      "iteration 203 / 300: loss 0.583712\n",
      "iteration 203 / 300: loss 0.614355\n",
      "iteration 203 / 300: loss 0.591285\n",
      "iteration 203 / 300: loss 0.591391\n",
      "iteration 203 / 300: loss 0.594005\n",
      "iteration 203 / 300: loss 0.596735\n",
      "iteration 203 / 300: loss 0.596712\n",
      "iteration 203 / 300: loss 0.611735\n",
      "iteration 203 / 300: loss 0.607258\n",
      "iteration 203 / 300: loss 0.597031\n",
      "iteration 203 / 300: loss 0.596301\n",
      "iteration 203 / 300: loss 0.627391\n",
      "iteration 203 / 300: loss 0.601584\n",
      "iteration 203 / 300: loss 0.599923\n",
      "iteration 203 / 300: loss 0.621952\n",
      "iteration 203 / 300: loss 0.581435\n",
      "iteration 203 / 300: loss 0.599604\n",
      "iteration 203 / 300: loss 0.591182\n",
      "iteration 203 / 300: loss 0.599919\n",
      "iteration 203 / 300: loss 0.596015\n",
      "iteration 203 / 300: loss 0.590760\n",
      "iteration 203 / 300: loss 0.591961\n",
      "iteration 203 / 300: loss 0.615468\n",
      "iteration 203 / 300: loss 0.621360\n",
      "iteration 203 / 300: loss 0.587267\n",
      "iteration 203 / 300: loss 0.582483\n",
      "iteration 203 / 300: loss 0.585572\n",
      "iteration 203 / 300: loss 0.603666\n",
      "iteration 203 / 300: loss 0.585192\n",
      "iteration 203 / 300: loss 0.578880\n",
      "iteration 203 / 300: loss 0.576418\n",
      "iteration 203 / 300: loss 0.574097\n",
      "iteration 203 / 300: loss 0.600500\n",
      "iteration 203 / 300: loss 0.584490\n",
      "iteration 203 / 300: loss 0.584834\n",
      "iteration 203 / 300: loss 0.568323\n",
      "iteration 203 / 300: loss 0.592025\n",
      "iteration 203 / 300: loss 0.612116\n",
      "iteration 203 / 300: loss 0.608923\n",
      "iteration 203 / 300: loss 0.607613\n",
      "iteration 203 / 300: loss 0.595533\n",
      "iteration 203 / 300: loss 0.592837\n",
      "iteration 203 / 300: loss 0.597988\n",
      "iteration 203 / 300: loss 0.597677\n",
      "iteration 203 / 300: loss 0.600953\n",
      "iteration 203 / 300: loss 0.597422\n",
      "iteration 203 / 300: loss 0.598776\n",
      "iteration 203 / 300: loss 0.587806\n",
      "iteration 203 / 300: loss 0.600499\n",
      "iteration 203 / 300: loss 0.599650\n",
      "iteration 203 / 300: loss 0.617540\n",
      "iteration 203 / 300: loss 0.598875\n",
      "iteration 203 / 300: loss 0.600801\n",
      "iteration 203 / 300: loss 0.605305\n",
      "iteration 203 / 300: loss 0.598592\n",
      "iteration 203 / 300: loss 0.591474\n",
      "iteration 203 / 300: loss 0.580382\n",
      "iteration 203 / 300: loss 0.598221\n",
      "iteration 203 / 300: loss 0.611685\n",
      "iteration 203 / 300: loss 0.613219\n",
      "iteration 203 / 300: loss 0.582214\n",
      "iteration 203 / 300: loss 0.601955\n",
      "iteration 203 / 300: loss 0.608956\n",
      "iteration 203 / 300: loss 0.601794\n",
      "iteration 203 / 300: loss 0.607944\n",
      "iteration 203 / 300: loss 0.620236\n",
      "iteration 203 / 300: loss 0.584817\n",
      "iteration 203 / 300: loss 0.583721\n",
      "iteration 203 / 300: loss 0.628849\n",
      "iteration 203 / 300: loss 0.609399\n",
      "iteration 203 / 300: loss 0.606265\n",
      "iteration 203 / 300: loss 0.599034\n",
      "iteration 203 / 300: loss 0.615876\n",
      "iteration 203 / 300: loss 0.596489\n",
      "iteration 203 / 300: loss 0.581430\n",
      "iteration 203 / 300: loss 0.609807\n",
      "iteration 203 / 300: loss 0.608125\n",
      "iteration 203 / 300: loss 0.598224\n",
      "iteration 203 / 300: loss 0.592022\n",
      "iteration 203 / 300: loss 0.611031\n",
      "iteration 203 / 300: loss 0.598550\n",
      "iteration 203 / 300: loss 0.581382\n",
      "iteration 203 / 300: loss 0.609580\n",
      "iteration 204 / 300: loss 0.578384\n",
      "iteration 204 / 300: loss 0.596214\n",
      "iteration 204 / 300: loss 0.569455\n",
      "iteration 204 / 300: loss 0.597849\n",
      "iteration 204 / 300: loss 0.598940\n",
      "iteration 204 / 300: loss 0.603876\n",
      "iteration 204 / 300: loss 0.615261\n",
      "iteration 204 / 300: loss 0.588227\n",
      "iteration 204 / 300: loss 0.627171\n",
      "iteration 204 / 300: loss 0.592600\n",
      "iteration 204 / 300: loss 0.621500\n",
      "iteration 204 / 300: loss 0.593093\n",
      "iteration 204 / 300: loss 0.600541\n",
      "iteration 204 / 300: loss 0.571000\n",
      "iteration 204 / 300: loss 0.592911\n",
      "iteration 204 / 300: loss 0.600043\n",
      "iteration 204 / 300: loss 0.598053\n",
      "iteration 204 / 300: loss 0.583712\n",
      "iteration 204 / 300: loss 0.614355\n",
      "iteration 204 / 300: loss 0.591285\n",
      "iteration 204 / 300: loss 0.591391\n",
      "iteration 204 / 300: loss 0.594005\n",
      "iteration 204 / 300: loss 0.596735\n",
      "iteration 204 / 300: loss 0.596712\n",
      "iteration 204 / 300: loss 0.611735\n",
      "iteration 204 / 300: loss 0.607258\n",
      "iteration 204 / 300: loss 0.597031\n",
      "iteration 204 / 300: loss 0.596301\n",
      "iteration 204 / 300: loss 0.627391\n",
      "iteration 204 / 300: loss 0.601584\n",
      "iteration 204 / 300: loss 0.599923\n",
      "iteration 204 / 300: loss 0.621952\n",
      "iteration 204 / 300: loss 0.581435\n",
      "iteration 204 / 300: loss 0.599604\n",
      "iteration 204 / 300: loss 0.591182\n",
      "iteration 204 / 300: loss 0.599919\n",
      "iteration 204 / 300: loss 0.596015\n",
      "iteration 204 / 300: loss 0.590760\n",
      "iteration 204 / 300: loss 0.591961\n",
      "iteration 204 / 300: loss 0.615468\n",
      "iteration 204 / 300: loss 0.621360\n",
      "iteration 204 / 300: loss 0.587267\n",
      "iteration 204 / 300: loss 0.582483\n",
      "iteration 204 / 300: loss 0.585572\n",
      "iteration 204 / 300: loss 0.603666\n",
      "iteration 204 / 300: loss 0.585192\n",
      "iteration 204 / 300: loss 0.578880\n",
      "iteration 204 / 300: loss 0.576418\n",
      "iteration 204 / 300: loss 0.574097\n",
      "iteration 204 / 300: loss 0.600500\n",
      "iteration 204 / 300: loss 0.584490\n",
      "iteration 204 / 300: loss 0.584834\n",
      "iteration 204 / 300: loss 0.568323\n",
      "iteration 204 / 300: loss 0.592025\n",
      "iteration 204 / 300: loss 0.612116\n",
      "iteration 204 / 300: loss 0.608923\n",
      "iteration 204 / 300: loss 0.607613\n",
      "iteration 204 / 300: loss 0.595533\n",
      "iteration 204 / 300: loss 0.592837\n",
      "iteration 204 / 300: loss 0.597988\n",
      "iteration 204 / 300: loss 0.597677\n",
      "iteration 204 / 300: loss 0.600953\n",
      "iteration 204 / 300: loss 0.597422\n",
      "iteration 204 / 300: loss 0.598776\n",
      "iteration 204 / 300: loss 0.587806\n",
      "iteration 204 / 300: loss 0.600499\n",
      "iteration 204 / 300: loss 0.599650\n",
      "iteration 204 / 300: loss 0.617540\n",
      "iteration 204 / 300: loss 0.598875\n",
      "iteration 204 / 300: loss 0.600801\n",
      "iteration 204 / 300: loss 0.605305\n",
      "iteration 204 / 300: loss 0.598592\n",
      "iteration 204 / 300: loss 0.591474\n",
      "iteration 204 / 300: loss 0.580382\n",
      "iteration 204 / 300: loss 0.598221\n",
      "iteration 204 / 300: loss 0.611685\n",
      "iteration 204 / 300: loss 0.613219\n",
      "iteration 204 / 300: loss 0.582214\n",
      "iteration 204 / 300: loss 0.601955\n",
      "iteration 204 / 300: loss 0.608956\n",
      "iteration 204 / 300: loss 0.601794\n",
      "iteration 204 / 300: loss 0.607944\n",
      "iteration 204 / 300: loss 0.620236\n",
      "iteration 204 / 300: loss 0.584817\n",
      "iteration 204 / 300: loss 0.583721\n",
      "iteration 204 / 300: loss 0.628849\n",
      "iteration 204 / 300: loss 0.609399\n",
      "iteration 204 / 300: loss 0.606265\n",
      "iteration 204 / 300: loss 0.599034\n",
      "iteration 204 / 300: loss 0.615876\n",
      "iteration 204 / 300: loss 0.596489\n",
      "iteration 204 / 300: loss 0.581430\n",
      "iteration 204 / 300: loss 0.609807\n",
      "iteration 204 / 300: loss 0.608125\n",
      "iteration 204 / 300: loss 0.598224\n",
      "iteration 204 / 300: loss 0.592022\n",
      "iteration 204 / 300: loss 0.611031\n",
      "iteration 204 / 300: loss 0.598550\n",
      "iteration 204 / 300: loss 0.581382\n",
      "iteration 204 / 300: loss 0.609580\n",
      "iteration 205 / 300: loss 0.578384\n",
      "iteration 205 / 300: loss 0.596214\n",
      "iteration 205 / 300: loss 0.569455\n",
      "iteration 205 / 300: loss 0.597849\n",
      "iteration 205 / 300: loss 0.598940\n",
      "iteration 205 / 300: loss 0.603876\n",
      "iteration 205 / 300: loss 0.615261\n",
      "iteration 205 / 300: loss 0.588227\n",
      "iteration 205 / 300: loss 0.627171\n",
      "iteration 205 / 300: loss 0.592600\n",
      "iteration 205 / 300: loss 0.621500\n",
      "iteration 205 / 300: loss 0.593093\n",
      "iteration 205 / 300: loss 0.600541\n",
      "iteration 205 / 300: loss 0.571000\n",
      "iteration 205 / 300: loss 0.592911\n",
      "iteration 205 / 300: loss 0.600043\n",
      "iteration 205 / 300: loss 0.598053\n",
      "iteration 205 / 300: loss 0.583712\n",
      "iteration 205 / 300: loss 0.614355\n",
      "iteration 205 / 300: loss 0.591285\n",
      "iteration 205 / 300: loss 0.591391\n",
      "iteration 205 / 300: loss 0.594005\n",
      "iteration 205 / 300: loss 0.596735\n",
      "iteration 205 / 300: loss 0.596712\n",
      "iteration 205 / 300: loss 0.611735\n",
      "iteration 205 / 300: loss 0.607258\n",
      "iteration 205 / 300: loss 0.597031\n",
      "iteration 205 / 300: loss 0.596301\n",
      "iteration 205 / 300: loss 0.627391\n",
      "iteration 205 / 300: loss 0.601584\n",
      "iteration 205 / 300: loss 0.599923\n",
      "iteration 205 / 300: loss 0.621952\n",
      "iteration 205 / 300: loss 0.581435\n",
      "iteration 205 / 300: loss 0.599604\n",
      "iteration 205 / 300: loss 0.591182\n",
      "iteration 205 / 300: loss 0.599919\n",
      "iteration 205 / 300: loss 0.596015\n",
      "iteration 205 / 300: loss 0.590760\n",
      "iteration 205 / 300: loss 0.591961\n",
      "iteration 205 / 300: loss 0.615468\n",
      "iteration 205 / 300: loss 0.621360\n",
      "iteration 205 / 300: loss 0.587267\n",
      "iteration 205 / 300: loss 0.582483\n",
      "iteration 205 / 300: loss 0.585572\n",
      "iteration 205 / 300: loss 0.603666\n",
      "iteration 205 / 300: loss 0.585192\n",
      "iteration 205 / 300: loss 0.578880\n",
      "iteration 205 / 300: loss 0.576418\n",
      "iteration 205 / 300: loss 0.574097\n",
      "iteration 205 / 300: loss 0.600500\n",
      "iteration 205 / 300: loss 0.584490\n",
      "iteration 205 / 300: loss 0.584834\n",
      "iteration 205 / 300: loss 0.568323\n",
      "iteration 205 / 300: loss 0.592025\n",
      "iteration 205 / 300: loss 0.612116\n",
      "iteration 205 / 300: loss 0.608923\n",
      "iteration 205 / 300: loss 0.607613\n",
      "iteration 205 / 300: loss 0.595533\n",
      "iteration 205 / 300: loss 0.592837\n",
      "iteration 205 / 300: loss 0.597988\n",
      "iteration 205 / 300: loss 0.597677\n",
      "iteration 205 / 300: loss 0.600953\n",
      "iteration 205 / 300: loss 0.597422\n",
      "iteration 205 / 300: loss 0.598776\n",
      "iteration 205 / 300: loss 0.587806\n",
      "iteration 205 / 300: loss 0.600499\n",
      "iteration 205 / 300: loss 0.599650\n",
      "iteration 205 / 300: loss 0.617540\n",
      "iteration 205 / 300: loss 0.598875\n",
      "iteration 205 / 300: loss 0.600801\n",
      "iteration 205 / 300: loss 0.605305\n",
      "iteration 205 / 300: loss 0.598592\n",
      "iteration 205 / 300: loss 0.591474\n",
      "iteration 205 / 300: loss 0.580382\n",
      "iteration 205 / 300: loss 0.598221\n",
      "iteration 205 / 300: loss 0.611685\n",
      "iteration 205 / 300: loss 0.613219\n",
      "iteration 205 / 300: loss 0.582214\n",
      "iteration 205 / 300: loss 0.601955\n",
      "iteration 205 / 300: loss 0.608956\n",
      "iteration 205 / 300: loss 0.601794\n",
      "iteration 205 / 300: loss 0.607944\n",
      "iteration 205 / 300: loss 0.620236\n",
      "iteration 205 / 300: loss 0.584817\n",
      "iteration 205 / 300: loss 0.583721\n",
      "iteration 205 / 300: loss 0.628849\n",
      "iteration 205 / 300: loss 0.609399\n",
      "iteration 205 / 300: loss 0.606265\n",
      "iteration 205 / 300: loss 0.599034\n",
      "iteration 205 / 300: loss 0.615876\n",
      "iteration 205 / 300: loss 0.596489\n",
      "iteration 205 / 300: loss 0.581430\n",
      "iteration 205 / 300: loss 0.609807\n",
      "iteration 205 / 300: loss 0.608125\n",
      "iteration 205 / 300: loss 0.598224\n",
      "iteration 205 / 300: loss 0.592022\n",
      "iteration 205 / 300: loss 0.611031\n",
      "iteration 205 / 300: loss 0.598550\n",
      "iteration 205 / 300: loss 0.581382\n",
      "iteration 205 / 300: loss 0.609580\n",
      "iteration 206 / 300: loss 0.578384\n",
      "iteration 206 / 300: loss 0.596214\n",
      "iteration 206 / 300: loss 0.569455\n",
      "iteration 206 / 300: loss 0.597849\n",
      "iteration 206 / 300: loss 0.598940\n",
      "iteration 206 / 300: loss 0.603876\n",
      "iteration 206 / 300: loss 0.615261\n",
      "iteration 206 / 300: loss 0.588227\n",
      "iteration 206 / 300: loss 0.627171\n",
      "iteration 206 / 300: loss 0.592600\n",
      "iteration 206 / 300: loss 0.621500\n",
      "iteration 206 / 300: loss 0.593093\n",
      "iteration 206 / 300: loss 0.600541\n",
      "iteration 206 / 300: loss 0.571000\n",
      "iteration 206 / 300: loss 0.592911\n",
      "iteration 206 / 300: loss 0.600043\n",
      "iteration 206 / 300: loss 0.598053\n",
      "iteration 206 / 300: loss 0.583712\n",
      "iteration 206 / 300: loss 0.614355\n",
      "iteration 206 / 300: loss 0.591285\n",
      "iteration 206 / 300: loss 0.591391\n",
      "iteration 206 / 300: loss 0.594005\n",
      "iteration 206 / 300: loss 0.596735\n",
      "iteration 206 / 300: loss 0.596712\n",
      "iteration 206 / 300: loss 0.611735\n",
      "iteration 206 / 300: loss 0.607258\n",
      "iteration 206 / 300: loss 0.597031\n",
      "iteration 206 / 300: loss 0.596301\n",
      "iteration 206 / 300: loss 0.627391\n",
      "iteration 206 / 300: loss 0.601584\n",
      "iteration 206 / 300: loss 0.599923\n",
      "iteration 206 / 300: loss 0.621952\n",
      "iteration 206 / 300: loss 0.581435\n",
      "iteration 206 / 300: loss 0.599604\n",
      "iteration 206 / 300: loss 0.591182\n",
      "iteration 206 / 300: loss 0.599919\n",
      "iteration 206 / 300: loss 0.596015\n",
      "iteration 206 / 300: loss 0.590760\n",
      "iteration 206 / 300: loss 0.591961\n",
      "iteration 206 / 300: loss 0.615468\n",
      "iteration 206 / 300: loss 0.621360\n",
      "iteration 206 / 300: loss 0.587267\n",
      "iteration 206 / 300: loss 0.582483\n",
      "iteration 206 / 300: loss 0.585572\n",
      "iteration 206 / 300: loss 0.603666\n",
      "iteration 206 / 300: loss 0.585192\n",
      "iteration 206 / 300: loss 0.578880\n",
      "iteration 206 / 300: loss 0.576418\n",
      "iteration 206 / 300: loss 0.574097\n",
      "iteration 206 / 300: loss 0.600500\n",
      "iteration 206 / 300: loss 0.584490\n",
      "iteration 206 / 300: loss 0.584834\n",
      "iteration 206 / 300: loss 0.568323\n",
      "iteration 206 / 300: loss 0.592025\n",
      "iteration 206 / 300: loss 0.612116\n",
      "iteration 206 / 300: loss 0.608923\n",
      "iteration 206 / 300: loss 0.607613\n",
      "iteration 206 / 300: loss 0.595533\n",
      "iteration 206 / 300: loss 0.592837\n",
      "iteration 206 / 300: loss 0.597988\n",
      "iteration 206 / 300: loss 0.597677\n",
      "iteration 206 / 300: loss 0.600953\n",
      "iteration 206 / 300: loss 0.597422\n",
      "iteration 206 / 300: loss 0.598776\n",
      "iteration 206 / 300: loss 0.587806\n",
      "iteration 206 / 300: loss 0.600499\n",
      "iteration 206 / 300: loss 0.599650\n",
      "iteration 206 / 300: loss 0.617540\n",
      "iteration 206 / 300: loss 0.598875\n",
      "iteration 206 / 300: loss 0.600801\n",
      "iteration 206 / 300: loss 0.605305\n",
      "iteration 206 / 300: loss 0.598592\n",
      "iteration 206 / 300: loss 0.591474\n",
      "iteration 206 / 300: loss 0.580382\n",
      "iteration 206 / 300: loss 0.598221\n",
      "iteration 206 / 300: loss 0.611685\n",
      "iteration 206 / 300: loss 0.613219\n",
      "iteration 206 / 300: loss 0.582214\n",
      "iteration 206 / 300: loss 0.601955\n",
      "iteration 206 / 300: loss 0.608956\n",
      "iteration 206 / 300: loss 0.601794\n",
      "iteration 206 / 300: loss 0.607944\n",
      "iteration 206 / 300: loss 0.620236\n",
      "iteration 206 / 300: loss 0.584817\n",
      "iteration 206 / 300: loss 0.583721\n",
      "iteration 206 / 300: loss 0.628849\n",
      "iteration 206 / 300: loss 0.609399\n",
      "iteration 206 / 300: loss 0.606265\n",
      "iteration 206 / 300: loss 0.599034\n",
      "iteration 206 / 300: loss 0.615876\n",
      "iteration 206 / 300: loss 0.596489\n",
      "iteration 206 / 300: loss 0.581430\n",
      "iteration 206 / 300: loss 0.609807\n",
      "iteration 206 / 300: loss 0.608125\n",
      "iteration 206 / 300: loss 0.598224\n",
      "iteration 206 / 300: loss 0.592022\n",
      "iteration 206 / 300: loss 0.611031\n",
      "iteration 206 / 300: loss 0.598550\n",
      "iteration 206 / 300: loss 0.581382\n",
      "iteration 206 / 300: loss 0.609580\n",
      "iteration 207 / 300: loss 0.578384\n",
      "iteration 207 / 300: loss 0.596214\n",
      "iteration 207 / 300: loss 0.569455\n",
      "iteration 207 / 300: loss 0.597849\n",
      "iteration 207 / 300: loss 0.598940\n",
      "iteration 207 / 300: loss 0.603876\n",
      "iteration 207 / 300: loss 0.615261\n",
      "iteration 207 / 300: loss 0.588227\n",
      "iteration 207 / 300: loss 0.627171\n",
      "iteration 207 / 300: loss 0.592600\n",
      "iteration 207 / 300: loss 0.621500\n",
      "iteration 207 / 300: loss 0.593093\n",
      "iteration 207 / 300: loss 0.600541\n",
      "iteration 207 / 300: loss 0.571000\n",
      "iteration 207 / 300: loss 0.592911\n",
      "iteration 207 / 300: loss 0.600043\n",
      "iteration 207 / 300: loss 0.598053\n",
      "iteration 207 / 300: loss 0.583712\n",
      "iteration 207 / 300: loss 0.614355\n",
      "iteration 207 / 300: loss 0.591285\n",
      "iteration 207 / 300: loss 0.591391\n",
      "iteration 207 / 300: loss 0.594005\n",
      "iteration 207 / 300: loss 0.596735\n",
      "iteration 207 / 300: loss 0.596712\n",
      "iteration 207 / 300: loss 0.611735\n",
      "iteration 207 / 300: loss 0.607258\n",
      "iteration 207 / 300: loss 0.597031\n",
      "iteration 207 / 300: loss 0.596301\n",
      "iteration 207 / 300: loss 0.627391\n",
      "iteration 207 / 300: loss 0.601584\n",
      "iteration 207 / 300: loss 0.599923\n",
      "iteration 207 / 300: loss 0.621952\n",
      "iteration 207 / 300: loss 0.581435\n",
      "iteration 207 / 300: loss 0.599604\n",
      "iteration 207 / 300: loss 0.591182\n",
      "iteration 207 / 300: loss 0.599919\n",
      "iteration 207 / 300: loss 0.596015\n",
      "iteration 207 / 300: loss 0.590760\n",
      "iteration 207 / 300: loss 0.591961\n",
      "iteration 207 / 300: loss 0.615468\n",
      "iteration 207 / 300: loss 0.621360\n",
      "iteration 207 / 300: loss 0.587267\n",
      "iteration 207 / 300: loss 0.582483\n",
      "iteration 207 / 300: loss 0.585572\n",
      "iteration 207 / 300: loss 0.603666\n",
      "iteration 207 / 300: loss 0.585192\n",
      "iteration 207 / 300: loss 0.578880\n",
      "iteration 207 / 300: loss 0.576418\n",
      "iteration 207 / 300: loss 0.574097\n",
      "iteration 207 / 300: loss 0.600500\n",
      "iteration 207 / 300: loss 0.584490\n",
      "iteration 207 / 300: loss 0.584834\n",
      "iteration 207 / 300: loss 0.568323\n",
      "iteration 207 / 300: loss 0.592025\n",
      "iteration 207 / 300: loss 0.612116\n",
      "iteration 207 / 300: loss 0.608923\n",
      "iteration 207 / 300: loss 0.607613\n",
      "iteration 207 / 300: loss 0.595533\n",
      "iteration 207 / 300: loss 0.592837\n",
      "iteration 207 / 300: loss 0.597988\n",
      "iteration 207 / 300: loss 0.597677\n",
      "iteration 207 / 300: loss 0.600953\n",
      "iteration 207 / 300: loss 0.597422\n",
      "iteration 207 / 300: loss 0.598776\n",
      "iteration 207 / 300: loss 0.587806\n",
      "iteration 207 / 300: loss 0.600499\n",
      "iteration 207 / 300: loss 0.599650\n",
      "iteration 207 / 300: loss 0.617540\n",
      "iteration 207 / 300: loss 0.598875\n",
      "iteration 207 / 300: loss 0.600801\n",
      "iteration 207 / 300: loss 0.605305\n",
      "iteration 207 / 300: loss 0.598592\n",
      "iteration 207 / 300: loss 0.591474\n",
      "iteration 207 / 300: loss 0.580382\n",
      "iteration 207 / 300: loss 0.598221\n",
      "iteration 207 / 300: loss 0.611685\n",
      "iteration 207 / 300: loss 0.613219\n",
      "iteration 207 / 300: loss 0.582214\n",
      "iteration 207 / 300: loss 0.601955\n",
      "iteration 207 / 300: loss 0.608956\n",
      "iteration 207 / 300: loss 0.601794\n",
      "iteration 207 / 300: loss 0.607944\n",
      "iteration 207 / 300: loss 0.620236\n",
      "iteration 207 / 300: loss 0.584817\n",
      "iteration 207 / 300: loss 0.583721\n",
      "iteration 207 / 300: loss 0.628849\n",
      "iteration 207 / 300: loss 0.609399\n",
      "iteration 207 / 300: loss 0.606265\n",
      "iteration 207 / 300: loss 0.599034\n",
      "iteration 207 / 300: loss 0.615876\n",
      "iteration 207 / 300: loss 0.596489\n",
      "iteration 207 / 300: loss 0.581430\n",
      "iteration 207 / 300: loss 0.609807\n",
      "iteration 207 / 300: loss 0.608125\n",
      "iteration 207 / 300: loss 0.598224\n",
      "iteration 207 / 300: loss 0.592022\n",
      "iteration 207 / 300: loss 0.611031\n",
      "iteration 207 / 300: loss 0.598550\n",
      "iteration 207 / 300: loss 0.581382\n",
      "iteration 207 / 300: loss 0.609580\n",
      "iteration 208 / 300: loss 0.578384\n",
      "iteration 208 / 300: loss 0.596214\n",
      "iteration 208 / 300: loss 0.569455\n",
      "iteration 208 / 300: loss 0.597849\n",
      "iteration 208 / 300: loss 0.598940\n",
      "iteration 208 / 300: loss 0.603876\n",
      "iteration 208 / 300: loss 0.615261\n",
      "iteration 208 / 300: loss 0.588227\n",
      "iteration 208 / 300: loss 0.627171\n",
      "iteration 208 / 300: loss 0.592600\n",
      "iteration 208 / 300: loss 0.621500\n",
      "iteration 208 / 300: loss 0.593093\n",
      "iteration 208 / 300: loss 0.600541\n",
      "iteration 208 / 300: loss 0.571000\n",
      "iteration 208 / 300: loss 0.592911\n",
      "iteration 208 / 300: loss 0.600043\n",
      "iteration 208 / 300: loss 0.598053\n",
      "iteration 208 / 300: loss 0.583712\n",
      "iteration 208 / 300: loss 0.614355\n",
      "iteration 208 / 300: loss 0.591285\n",
      "iteration 208 / 300: loss 0.591391\n",
      "iteration 208 / 300: loss 0.594005\n",
      "iteration 208 / 300: loss 0.596735\n",
      "iteration 208 / 300: loss 0.596712\n",
      "iteration 208 / 300: loss 0.611735\n",
      "iteration 208 / 300: loss 0.607258\n",
      "iteration 208 / 300: loss 0.597031\n",
      "iteration 208 / 300: loss 0.596301\n",
      "iteration 208 / 300: loss 0.627391\n",
      "iteration 208 / 300: loss 0.601584\n",
      "iteration 208 / 300: loss 0.599923\n",
      "iteration 208 / 300: loss 0.621952\n",
      "iteration 208 / 300: loss 0.581435\n",
      "iteration 208 / 300: loss 0.599604\n",
      "iteration 208 / 300: loss 0.591182\n",
      "iteration 208 / 300: loss 0.599919\n",
      "iteration 208 / 300: loss 0.596015\n",
      "iteration 208 / 300: loss 0.590760\n",
      "iteration 208 / 300: loss 0.591961\n",
      "iteration 208 / 300: loss 0.615468\n",
      "iteration 208 / 300: loss 0.621360\n",
      "iteration 208 / 300: loss 0.587267\n",
      "iteration 208 / 300: loss 0.582483\n",
      "iteration 208 / 300: loss 0.585572\n",
      "iteration 208 / 300: loss 0.603666\n",
      "iteration 208 / 300: loss 0.585192\n",
      "iteration 208 / 300: loss 0.578880\n",
      "iteration 208 / 300: loss 0.576418\n",
      "iteration 208 / 300: loss 0.574097\n",
      "iteration 208 / 300: loss 0.600500\n",
      "iteration 208 / 300: loss 0.584490\n",
      "iteration 208 / 300: loss 0.584834\n",
      "iteration 208 / 300: loss 0.568323\n",
      "iteration 208 / 300: loss 0.592025\n",
      "iteration 208 / 300: loss 0.612116\n",
      "iteration 208 / 300: loss 0.608923\n",
      "iteration 208 / 300: loss 0.607613\n",
      "iteration 208 / 300: loss 0.595533\n",
      "iteration 208 / 300: loss 0.592837\n",
      "iteration 208 / 300: loss 0.597988\n",
      "iteration 208 / 300: loss 0.597677\n",
      "iteration 208 / 300: loss 0.600953\n",
      "iteration 208 / 300: loss 0.597422\n",
      "iteration 208 / 300: loss 0.598776\n",
      "iteration 208 / 300: loss 0.587806\n",
      "iteration 208 / 300: loss 0.600499\n",
      "iteration 208 / 300: loss 0.599650\n",
      "iteration 208 / 300: loss 0.617540\n",
      "iteration 208 / 300: loss 0.598875\n",
      "iteration 208 / 300: loss 0.600801\n",
      "iteration 208 / 300: loss 0.605305\n",
      "iteration 208 / 300: loss 0.598592\n",
      "iteration 208 / 300: loss 0.591474\n",
      "iteration 208 / 300: loss 0.580382\n",
      "iteration 208 / 300: loss 0.598221\n",
      "iteration 208 / 300: loss 0.611685\n",
      "iteration 208 / 300: loss 0.613219\n",
      "iteration 208 / 300: loss 0.582214\n",
      "iteration 208 / 300: loss 0.601955\n",
      "iteration 208 / 300: loss 0.608956\n",
      "iteration 208 / 300: loss 0.601794\n",
      "iteration 208 / 300: loss 0.607944\n",
      "iteration 208 / 300: loss 0.620236\n",
      "iteration 208 / 300: loss 0.584817\n",
      "iteration 208 / 300: loss 0.583721\n",
      "iteration 208 / 300: loss 0.628849\n",
      "iteration 208 / 300: loss 0.609399\n",
      "iteration 208 / 300: loss 0.606265\n",
      "iteration 208 / 300: loss 0.599034\n",
      "iteration 208 / 300: loss 0.615876\n",
      "iteration 208 / 300: loss 0.596489\n",
      "iteration 208 / 300: loss 0.581430\n",
      "iteration 208 / 300: loss 0.609807\n",
      "iteration 208 / 300: loss 0.608125\n",
      "iteration 208 / 300: loss 0.598224\n",
      "iteration 208 / 300: loss 0.592022\n",
      "iteration 208 / 300: loss 0.611031\n",
      "iteration 208 / 300: loss 0.598550\n",
      "iteration 208 / 300: loss 0.581382\n",
      "iteration 208 / 300: loss 0.609580\n",
      "iteration 209 / 300: loss 0.578384\n",
      "iteration 209 / 300: loss 0.596214\n",
      "iteration 209 / 300: loss 0.569455\n",
      "iteration 209 / 300: loss 0.597849\n",
      "iteration 209 / 300: loss 0.598940\n",
      "iteration 209 / 300: loss 0.603876\n",
      "iteration 209 / 300: loss 0.615261\n",
      "iteration 209 / 300: loss 0.588227\n",
      "iteration 209 / 300: loss 0.627171\n",
      "iteration 209 / 300: loss 0.592600\n",
      "iteration 209 / 300: loss 0.621500\n",
      "iteration 209 / 300: loss 0.593093\n",
      "iteration 209 / 300: loss 0.600541\n",
      "iteration 209 / 300: loss 0.571000\n",
      "iteration 209 / 300: loss 0.592911\n",
      "iteration 209 / 300: loss 0.600043\n",
      "iteration 209 / 300: loss 0.598053\n",
      "iteration 209 / 300: loss 0.583712\n",
      "iteration 209 / 300: loss 0.614355\n",
      "iteration 209 / 300: loss 0.591285\n",
      "iteration 209 / 300: loss 0.591391\n",
      "iteration 209 / 300: loss 0.594005\n",
      "iteration 209 / 300: loss 0.596735\n",
      "iteration 209 / 300: loss 0.596712\n",
      "iteration 209 / 300: loss 0.611735\n",
      "iteration 209 / 300: loss 0.607258\n",
      "iteration 209 / 300: loss 0.597031\n",
      "iteration 209 / 300: loss 0.596301\n",
      "iteration 209 / 300: loss 0.627391\n",
      "iteration 209 / 300: loss 0.601584\n",
      "iteration 209 / 300: loss 0.599923\n",
      "iteration 209 / 300: loss 0.621952\n",
      "iteration 209 / 300: loss 0.581435\n",
      "iteration 209 / 300: loss 0.599604\n",
      "iteration 209 / 300: loss 0.591182\n",
      "iteration 209 / 300: loss 0.599919\n",
      "iteration 209 / 300: loss 0.596015\n",
      "iteration 209 / 300: loss 0.590760\n",
      "iteration 209 / 300: loss 0.591961\n",
      "iteration 209 / 300: loss 0.615468\n",
      "iteration 209 / 300: loss 0.621360\n",
      "iteration 209 / 300: loss 0.587267\n",
      "iteration 209 / 300: loss 0.582483\n",
      "iteration 209 / 300: loss 0.585572\n",
      "iteration 209 / 300: loss 0.603666\n",
      "iteration 209 / 300: loss 0.585192\n",
      "iteration 209 / 300: loss 0.578880\n",
      "iteration 209 / 300: loss 0.576418\n",
      "iteration 209 / 300: loss 0.574097\n",
      "iteration 209 / 300: loss 0.600500\n",
      "iteration 209 / 300: loss 0.584490\n",
      "iteration 209 / 300: loss 0.584834\n",
      "iteration 209 / 300: loss 0.568323\n",
      "iteration 209 / 300: loss 0.592025\n",
      "iteration 209 / 300: loss 0.612116\n",
      "iteration 209 / 300: loss 0.608923\n",
      "iteration 209 / 300: loss 0.607613\n",
      "iteration 209 / 300: loss 0.595533\n",
      "iteration 209 / 300: loss 0.592837\n",
      "iteration 209 / 300: loss 0.597988\n",
      "iteration 209 / 300: loss 0.597677\n",
      "iteration 209 / 300: loss 0.600953\n",
      "iteration 209 / 300: loss 0.597422\n",
      "iteration 209 / 300: loss 0.598776\n",
      "iteration 209 / 300: loss 0.587806\n",
      "iteration 209 / 300: loss 0.600499\n",
      "iteration 209 / 300: loss 0.599650\n",
      "iteration 209 / 300: loss 0.617540\n",
      "iteration 209 / 300: loss 0.598875\n",
      "iteration 209 / 300: loss 0.600801\n",
      "iteration 209 / 300: loss 0.605305\n",
      "iteration 209 / 300: loss 0.598592\n",
      "iteration 209 / 300: loss 0.591474\n",
      "iteration 209 / 300: loss 0.580382\n",
      "iteration 209 / 300: loss 0.598221\n",
      "iteration 209 / 300: loss 0.611685\n",
      "iteration 209 / 300: loss 0.613219\n",
      "iteration 209 / 300: loss 0.582214\n",
      "iteration 209 / 300: loss 0.601955\n",
      "iteration 209 / 300: loss 0.608956\n",
      "iteration 209 / 300: loss 0.601794\n",
      "iteration 209 / 300: loss 0.607944\n",
      "iteration 209 / 300: loss 0.620236\n",
      "iteration 209 / 300: loss 0.584817\n",
      "iteration 209 / 300: loss 0.583721\n",
      "iteration 209 / 300: loss 0.628849\n",
      "iteration 209 / 300: loss 0.609399\n",
      "iteration 209 / 300: loss 0.606265\n",
      "iteration 209 / 300: loss 0.599034\n",
      "iteration 209 / 300: loss 0.615876\n",
      "iteration 209 / 300: loss 0.596489\n",
      "iteration 209 / 300: loss 0.581430\n",
      "iteration 209 / 300: loss 0.609807\n",
      "iteration 209 / 300: loss 0.608125\n",
      "iteration 209 / 300: loss 0.598224\n",
      "iteration 209 / 300: loss 0.592022\n",
      "iteration 209 / 300: loss 0.611031\n",
      "iteration 209 / 300: loss 0.598550\n",
      "iteration 209 / 300: loss 0.581382\n",
      "iteration 209 / 300: loss 0.609580\n",
      "iteration 210 / 300: loss 0.578384\n",
      "iteration 210 / 300: loss 0.596214\n",
      "iteration 210 / 300: loss 0.569455\n",
      "iteration 210 / 300: loss 0.597849\n",
      "iteration 210 / 300: loss 0.598940\n",
      "iteration 210 / 300: loss 0.603876\n",
      "iteration 210 / 300: loss 0.615261\n",
      "iteration 210 / 300: loss 0.588227\n",
      "iteration 210 / 300: loss 0.627171\n",
      "iteration 210 / 300: loss 0.592600\n",
      "iteration 210 / 300: loss 0.621500\n",
      "iteration 210 / 300: loss 0.593093\n",
      "iteration 210 / 300: loss 0.600541\n",
      "iteration 210 / 300: loss 0.571000\n",
      "iteration 210 / 300: loss 0.592911\n",
      "iteration 210 / 300: loss 0.600043\n",
      "iteration 210 / 300: loss 0.598053\n",
      "iteration 210 / 300: loss 0.583712\n",
      "iteration 210 / 300: loss 0.614355\n",
      "iteration 210 / 300: loss 0.591285\n",
      "iteration 210 / 300: loss 0.591391\n",
      "iteration 210 / 300: loss 0.594005\n",
      "iteration 210 / 300: loss 0.596735\n",
      "iteration 210 / 300: loss 0.596712\n",
      "iteration 210 / 300: loss 0.611735\n",
      "iteration 210 / 300: loss 0.607258\n",
      "iteration 210 / 300: loss 0.597031\n",
      "iteration 210 / 300: loss 0.596301\n",
      "iteration 210 / 300: loss 0.627391\n",
      "iteration 210 / 300: loss 0.601584\n",
      "iteration 210 / 300: loss 0.599923\n",
      "iteration 210 / 300: loss 0.621952\n",
      "iteration 210 / 300: loss 0.581435\n",
      "iteration 210 / 300: loss 0.599604\n",
      "iteration 210 / 300: loss 0.591182\n",
      "iteration 210 / 300: loss 0.599919\n",
      "iteration 210 / 300: loss 0.596015\n",
      "iteration 210 / 300: loss 0.590760\n",
      "iteration 210 / 300: loss 0.591961\n",
      "iteration 210 / 300: loss 0.615468\n",
      "iteration 210 / 300: loss 0.621360\n",
      "iteration 210 / 300: loss 0.587267\n",
      "iteration 210 / 300: loss 0.582483\n",
      "iteration 210 / 300: loss 0.585572\n",
      "iteration 210 / 300: loss 0.603666\n",
      "iteration 210 / 300: loss 0.585192\n",
      "iteration 210 / 300: loss 0.578880\n",
      "iteration 210 / 300: loss 0.576418\n",
      "iteration 210 / 300: loss 0.574097\n",
      "iteration 210 / 300: loss 0.600500\n",
      "iteration 210 / 300: loss 0.584490\n",
      "iteration 210 / 300: loss 0.584834\n",
      "iteration 210 / 300: loss 0.568323\n",
      "iteration 210 / 300: loss 0.592025\n",
      "iteration 210 / 300: loss 0.612116\n",
      "iteration 210 / 300: loss 0.608923\n",
      "iteration 210 / 300: loss 0.607613\n",
      "iteration 210 / 300: loss 0.595533\n",
      "iteration 210 / 300: loss 0.592837\n",
      "iteration 210 / 300: loss 0.597988\n",
      "iteration 210 / 300: loss 0.597677\n",
      "iteration 210 / 300: loss 0.600953\n",
      "iteration 210 / 300: loss 0.597422\n",
      "iteration 210 / 300: loss 0.598776\n",
      "iteration 210 / 300: loss 0.587806\n",
      "iteration 210 / 300: loss 0.600499\n",
      "iteration 210 / 300: loss 0.599650\n",
      "iteration 210 / 300: loss 0.617540\n",
      "iteration 210 / 300: loss 0.598875\n",
      "iteration 210 / 300: loss 0.600801\n",
      "iteration 210 / 300: loss 0.605305\n",
      "iteration 210 / 300: loss 0.598592\n",
      "iteration 210 / 300: loss 0.591474\n",
      "iteration 210 / 300: loss 0.580382\n",
      "iteration 210 / 300: loss 0.598221\n",
      "iteration 210 / 300: loss 0.611685\n",
      "iteration 210 / 300: loss 0.613219\n",
      "iteration 210 / 300: loss 0.582214\n",
      "iteration 210 / 300: loss 0.601955\n",
      "iteration 210 / 300: loss 0.608956\n",
      "iteration 210 / 300: loss 0.601794\n",
      "iteration 210 / 300: loss 0.607944\n",
      "iteration 210 / 300: loss 0.620236\n",
      "iteration 210 / 300: loss 0.584817\n",
      "iteration 210 / 300: loss 0.583721\n",
      "iteration 210 / 300: loss 0.628849\n",
      "iteration 210 / 300: loss 0.609399\n",
      "iteration 210 / 300: loss 0.606265\n",
      "iteration 210 / 300: loss 0.599034\n",
      "iteration 210 / 300: loss 0.615876\n",
      "iteration 210 / 300: loss 0.596489\n",
      "iteration 210 / 300: loss 0.581430\n",
      "iteration 210 / 300: loss 0.609807\n",
      "iteration 210 / 300: loss 0.608125\n",
      "iteration 210 / 300: loss 0.598224\n",
      "iteration 210 / 300: loss 0.592022\n",
      "iteration 210 / 300: loss 0.611031\n",
      "iteration 210 / 300: loss 0.598550\n",
      "iteration 210 / 300: loss 0.581382\n",
      "iteration 210 / 300: loss 0.609580\n",
      "iteration 211 / 300: loss 0.578384\n",
      "iteration 211 / 300: loss 0.596214\n",
      "iteration 211 / 300: loss 0.569455\n",
      "iteration 211 / 300: loss 0.597849\n",
      "iteration 211 / 300: loss 0.598940\n",
      "iteration 211 / 300: loss 0.603876\n",
      "iteration 211 / 300: loss 0.615261\n",
      "iteration 211 / 300: loss 0.588227\n",
      "iteration 211 / 300: loss 0.627171\n",
      "iteration 211 / 300: loss 0.592600\n",
      "iteration 211 / 300: loss 0.621500\n",
      "iteration 211 / 300: loss 0.593093\n",
      "iteration 211 / 300: loss 0.600541\n",
      "iteration 211 / 300: loss 0.571000\n",
      "iteration 211 / 300: loss 0.592911\n",
      "iteration 211 / 300: loss 0.600043\n",
      "iteration 211 / 300: loss 0.598053\n",
      "iteration 211 / 300: loss 0.583712\n",
      "iteration 211 / 300: loss 0.614355\n",
      "iteration 211 / 300: loss 0.591285\n",
      "iteration 211 / 300: loss 0.591391\n",
      "iteration 211 / 300: loss 0.594005\n",
      "iteration 211 / 300: loss 0.596735\n",
      "iteration 211 / 300: loss 0.596712\n",
      "iteration 211 / 300: loss 0.611735\n",
      "iteration 211 / 300: loss 0.607258\n",
      "iteration 211 / 300: loss 0.597031\n",
      "iteration 211 / 300: loss 0.596301\n",
      "iteration 211 / 300: loss 0.627391\n",
      "iteration 211 / 300: loss 0.601584\n",
      "iteration 211 / 300: loss 0.599923\n",
      "iteration 211 / 300: loss 0.621952\n",
      "iteration 211 / 300: loss 0.581435\n",
      "iteration 211 / 300: loss 0.599604\n",
      "iteration 211 / 300: loss 0.591182\n",
      "iteration 211 / 300: loss 0.599919\n",
      "iteration 211 / 300: loss 0.596015\n",
      "iteration 211 / 300: loss 0.590760\n",
      "iteration 211 / 300: loss 0.591961\n",
      "iteration 211 / 300: loss 0.615468\n",
      "iteration 211 / 300: loss 0.621360\n",
      "iteration 211 / 300: loss 0.587267\n",
      "iteration 211 / 300: loss 0.582483\n",
      "iteration 211 / 300: loss 0.585572\n",
      "iteration 211 / 300: loss 0.603666\n",
      "iteration 211 / 300: loss 0.585192\n",
      "iteration 211 / 300: loss 0.578880\n",
      "iteration 211 / 300: loss 0.576418\n",
      "iteration 211 / 300: loss 0.574097\n",
      "iteration 211 / 300: loss 0.600500\n",
      "iteration 211 / 300: loss 0.584490\n",
      "iteration 211 / 300: loss 0.584834\n",
      "iteration 211 / 300: loss 0.568323\n",
      "iteration 211 / 300: loss 0.592025\n",
      "iteration 211 / 300: loss 0.612116\n",
      "iteration 211 / 300: loss 0.608923\n",
      "iteration 211 / 300: loss 0.607613\n",
      "iteration 211 / 300: loss 0.595533\n",
      "iteration 211 / 300: loss 0.592837\n",
      "iteration 211 / 300: loss 0.597988\n",
      "iteration 211 / 300: loss 0.597677\n",
      "iteration 211 / 300: loss 0.600953\n",
      "iteration 211 / 300: loss 0.597422\n",
      "iteration 211 / 300: loss 0.598776\n",
      "iteration 211 / 300: loss 0.587806\n",
      "iteration 211 / 300: loss 0.600499\n",
      "iteration 211 / 300: loss 0.599650\n",
      "iteration 211 / 300: loss 0.617540\n",
      "iteration 211 / 300: loss 0.598875\n",
      "iteration 211 / 300: loss 0.600801\n",
      "iteration 211 / 300: loss 0.605305\n",
      "iteration 211 / 300: loss 0.598592\n",
      "iteration 211 / 300: loss 0.591474\n",
      "iteration 211 / 300: loss 0.580382\n",
      "iteration 211 / 300: loss 0.598221\n",
      "iteration 211 / 300: loss 0.611685\n",
      "iteration 211 / 300: loss 0.613219\n",
      "iteration 211 / 300: loss 0.582214\n",
      "iteration 211 / 300: loss 0.601955\n",
      "iteration 211 / 300: loss 0.608956\n",
      "iteration 211 / 300: loss 0.601794\n",
      "iteration 211 / 300: loss 0.607944\n",
      "iteration 211 / 300: loss 0.620236\n",
      "iteration 211 / 300: loss 0.584817\n",
      "iteration 211 / 300: loss 0.583721\n",
      "iteration 211 / 300: loss 0.628849\n",
      "iteration 211 / 300: loss 0.609399\n",
      "iteration 211 / 300: loss 0.606265\n",
      "iteration 211 / 300: loss 0.599034\n",
      "iteration 211 / 300: loss 0.615876\n",
      "iteration 211 / 300: loss 0.596489\n",
      "iteration 211 / 300: loss 0.581430\n",
      "iteration 211 / 300: loss 0.609807\n",
      "iteration 211 / 300: loss 0.608125\n",
      "iteration 211 / 300: loss 0.598224\n",
      "iteration 211 / 300: loss 0.592022\n",
      "iteration 211 / 300: loss 0.611031\n",
      "iteration 211 / 300: loss 0.598550\n",
      "iteration 211 / 300: loss 0.581382\n",
      "iteration 211 / 300: loss 0.609580\n",
      "iteration 212 / 300: loss 0.578384\n",
      "iteration 212 / 300: loss 0.596214\n",
      "iteration 212 / 300: loss 0.569455\n",
      "iteration 212 / 300: loss 0.597849\n",
      "iteration 212 / 300: loss 0.598940\n",
      "iteration 212 / 300: loss 0.603876\n",
      "iteration 212 / 300: loss 0.615261\n",
      "iteration 212 / 300: loss 0.588227\n",
      "iteration 212 / 300: loss 0.627171\n",
      "iteration 212 / 300: loss 0.592600\n",
      "iteration 212 / 300: loss 0.621500\n",
      "iteration 212 / 300: loss 0.593093\n",
      "iteration 212 / 300: loss 0.600541\n",
      "iteration 212 / 300: loss 0.571000\n",
      "iteration 212 / 300: loss 0.592911\n",
      "iteration 212 / 300: loss 0.600043\n",
      "iteration 212 / 300: loss 0.598053\n",
      "iteration 212 / 300: loss 0.583712\n",
      "iteration 212 / 300: loss 0.614355\n",
      "iteration 212 / 300: loss 0.591285\n",
      "iteration 212 / 300: loss 0.591391\n",
      "iteration 212 / 300: loss 0.594005\n",
      "iteration 212 / 300: loss 0.596735\n",
      "iteration 212 / 300: loss 0.596712\n",
      "iteration 212 / 300: loss 0.611735\n",
      "iteration 212 / 300: loss 0.607258\n",
      "iteration 212 / 300: loss 0.597031\n",
      "iteration 212 / 300: loss 0.596301\n",
      "iteration 212 / 300: loss 0.627391\n",
      "iteration 212 / 300: loss 0.601584\n",
      "iteration 212 / 300: loss 0.599923\n",
      "iteration 212 / 300: loss 0.621952\n",
      "iteration 212 / 300: loss 0.581435\n",
      "iteration 212 / 300: loss 0.599604\n",
      "iteration 212 / 300: loss 0.591182\n",
      "iteration 212 / 300: loss 0.599919\n",
      "iteration 212 / 300: loss 0.596015\n",
      "iteration 212 / 300: loss 0.590760\n",
      "iteration 212 / 300: loss 0.591961\n",
      "iteration 212 / 300: loss 0.615468\n",
      "iteration 212 / 300: loss 0.621360\n",
      "iteration 212 / 300: loss 0.587267\n",
      "iteration 212 / 300: loss 0.582483\n",
      "iteration 212 / 300: loss 0.585572\n",
      "iteration 212 / 300: loss 0.603666\n",
      "iteration 212 / 300: loss 0.585192\n",
      "iteration 212 / 300: loss 0.578880\n",
      "iteration 212 / 300: loss 0.576418\n",
      "iteration 212 / 300: loss 0.574097\n",
      "iteration 212 / 300: loss 0.600500\n",
      "iteration 212 / 300: loss 0.584490\n",
      "iteration 212 / 300: loss 0.584834\n",
      "iteration 212 / 300: loss 0.568323\n",
      "iteration 212 / 300: loss 0.592025\n",
      "iteration 212 / 300: loss 0.612116\n",
      "iteration 212 / 300: loss 0.608923\n",
      "iteration 212 / 300: loss 0.607613\n",
      "iteration 212 / 300: loss 0.595533\n",
      "iteration 212 / 300: loss 0.592837\n",
      "iteration 212 / 300: loss 0.597988\n",
      "iteration 212 / 300: loss 0.597677\n",
      "iteration 212 / 300: loss 0.600953\n",
      "iteration 212 / 300: loss 0.597422\n",
      "iteration 212 / 300: loss 0.598776\n",
      "iteration 212 / 300: loss 0.587806\n",
      "iteration 212 / 300: loss 0.600499\n",
      "iteration 212 / 300: loss 0.599650\n",
      "iteration 212 / 300: loss 0.617540\n",
      "iteration 212 / 300: loss 0.598875\n",
      "iteration 212 / 300: loss 0.600801\n",
      "iteration 212 / 300: loss 0.605305\n",
      "iteration 212 / 300: loss 0.598592\n",
      "iteration 212 / 300: loss 0.591474\n",
      "iteration 212 / 300: loss 0.580382\n",
      "iteration 212 / 300: loss 0.598221\n",
      "iteration 212 / 300: loss 0.611685\n",
      "iteration 212 / 300: loss 0.613219\n",
      "iteration 212 / 300: loss 0.582214\n",
      "iteration 212 / 300: loss 0.601955\n",
      "iteration 212 / 300: loss 0.608956\n",
      "iteration 212 / 300: loss 0.601794\n",
      "iteration 212 / 300: loss 0.607944\n",
      "iteration 212 / 300: loss 0.620236\n",
      "iteration 212 / 300: loss 0.584817\n",
      "iteration 212 / 300: loss 0.583721\n",
      "iteration 212 / 300: loss 0.628849\n",
      "iteration 212 / 300: loss 0.609399\n",
      "iteration 212 / 300: loss 0.606265\n",
      "iteration 212 / 300: loss 0.599034\n",
      "iteration 212 / 300: loss 0.615876\n",
      "iteration 212 / 300: loss 0.596489\n",
      "iteration 212 / 300: loss 0.581430\n",
      "iteration 212 / 300: loss 0.609807\n",
      "iteration 212 / 300: loss 0.608125\n",
      "iteration 212 / 300: loss 0.598224\n",
      "iteration 212 / 300: loss 0.592022\n",
      "iteration 212 / 300: loss 0.611031\n",
      "iteration 212 / 300: loss 0.598550\n",
      "iteration 212 / 300: loss 0.581382\n",
      "iteration 212 / 300: loss 0.609580\n",
      "iteration 213 / 300: loss 0.578384\n",
      "iteration 213 / 300: loss 0.596214\n",
      "iteration 213 / 300: loss 0.569455\n",
      "iteration 213 / 300: loss 0.597849\n",
      "iteration 213 / 300: loss 0.598940\n",
      "iteration 213 / 300: loss 0.603876\n",
      "iteration 213 / 300: loss 0.615261\n",
      "iteration 213 / 300: loss 0.588227\n",
      "iteration 213 / 300: loss 0.627171\n",
      "iteration 213 / 300: loss 0.592600\n",
      "iteration 213 / 300: loss 0.621500\n",
      "iteration 213 / 300: loss 0.593093\n",
      "iteration 213 / 300: loss 0.600541\n",
      "iteration 213 / 300: loss 0.571000\n",
      "iteration 213 / 300: loss 0.592911\n",
      "iteration 213 / 300: loss 0.600043\n",
      "iteration 213 / 300: loss 0.598053\n",
      "iteration 213 / 300: loss 0.583712\n",
      "iteration 213 / 300: loss 0.614355\n",
      "iteration 213 / 300: loss 0.591285\n",
      "iteration 213 / 300: loss 0.591391\n",
      "iteration 213 / 300: loss 0.594005\n",
      "iteration 213 / 300: loss 0.596735\n",
      "iteration 213 / 300: loss 0.596712\n",
      "iteration 213 / 300: loss 0.611735\n",
      "iteration 213 / 300: loss 0.607258\n",
      "iteration 213 / 300: loss 0.597031\n",
      "iteration 213 / 300: loss 0.596301\n",
      "iteration 213 / 300: loss 0.627391\n",
      "iteration 213 / 300: loss 0.601584\n",
      "iteration 213 / 300: loss 0.599923\n",
      "iteration 213 / 300: loss 0.621952\n",
      "iteration 213 / 300: loss 0.581435\n",
      "iteration 213 / 300: loss 0.599604\n",
      "iteration 213 / 300: loss 0.591182\n",
      "iteration 213 / 300: loss 0.599919\n",
      "iteration 213 / 300: loss 0.596015\n",
      "iteration 213 / 300: loss 0.590760\n",
      "iteration 213 / 300: loss 0.591961\n",
      "iteration 213 / 300: loss 0.615468\n",
      "iteration 213 / 300: loss 0.621360\n",
      "iteration 213 / 300: loss 0.587267\n",
      "iteration 213 / 300: loss 0.582483\n",
      "iteration 213 / 300: loss 0.585572\n",
      "iteration 213 / 300: loss 0.603666\n",
      "iteration 213 / 300: loss 0.585192\n",
      "iteration 213 / 300: loss 0.578880\n",
      "iteration 213 / 300: loss 0.576418\n",
      "iteration 213 / 300: loss 0.574097\n",
      "iteration 213 / 300: loss 0.600500\n",
      "iteration 213 / 300: loss 0.584490\n",
      "iteration 213 / 300: loss 0.584834\n",
      "iteration 213 / 300: loss 0.568323\n",
      "iteration 213 / 300: loss 0.592025\n",
      "iteration 213 / 300: loss 0.612116\n",
      "iteration 213 / 300: loss 0.608923\n",
      "iteration 213 / 300: loss 0.607613\n",
      "iteration 213 / 300: loss 0.595533\n",
      "iteration 213 / 300: loss 0.592837\n",
      "iteration 213 / 300: loss 0.597988\n",
      "iteration 213 / 300: loss 0.597677\n",
      "iteration 213 / 300: loss 0.600953\n",
      "iteration 213 / 300: loss 0.597422\n",
      "iteration 213 / 300: loss 0.598776\n",
      "iteration 213 / 300: loss 0.587806\n",
      "iteration 213 / 300: loss 0.600499\n",
      "iteration 213 / 300: loss 0.599650\n",
      "iteration 213 / 300: loss 0.617540\n",
      "iteration 213 / 300: loss 0.598875\n",
      "iteration 213 / 300: loss 0.600801\n",
      "iteration 213 / 300: loss 0.605305\n",
      "iteration 213 / 300: loss 0.598592\n",
      "iteration 213 / 300: loss 0.591474\n",
      "iteration 213 / 300: loss 0.580382\n",
      "iteration 213 / 300: loss 0.598221\n",
      "iteration 213 / 300: loss 0.611685\n",
      "iteration 213 / 300: loss 0.613219\n",
      "iteration 213 / 300: loss 0.582214\n",
      "iteration 213 / 300: loss 0.601955\n",
      "iteration 213 / 300: loss 0.608956\n",
      "iteration 213 / 300: loss 0.601794\n",
      "iteration 213 / 300: loss 0.607944\n",
      "iteration 213 / 300: loss 0.620236\n",
      "iteration 213 / 300: loss 0.584817\n",
      "iteration 213 / 300: loss 0.583721\n",
      "iteration 213 / 300: loss 0.628849\n",
      "iteration 213 / 300: loss 0.609399\n",
      "iteration 213 / 300: loss 0.606265\n",
      "iteration 213 / 300: loss 0.599034\n",
      "iteration 213 / 300: loss 0.615876\n",
      "iteration 213 / 300: loss 0.596489\n",
      "iteration 213 / 300: loss 0.581430\n",
      "iteration 213 / 300: loss 0.609807\n",
      "iteration 213 / 300: loss 0.608125\n",
      "iteration 213 / 300: loss 0.598224\n",
      "iteration 213 / 300: loss 0.592022\n",
      "iteration 213 / 300: loss 0.611031\n",
      "iteration 213 / 300: loss 0.598550\n",
      "iteration 213 / 300: loss 0.581382\n",
      "iteration 213 / 300: loss 0.609580\n",
      "iteration 214 / 300: loss 0.578384\n",
      "iteration 214 / 300: loss 0.596214\n",
      "iteration 214 / 300: loss 0.569455\n",
      "iteration 214 / 300: loss 0.597849\n",
      "iteration 214 / 300: loss 0.598940\n",
      "iteration 214 / 300: loss 0.603876\n",
      "iteration 214 / 300: loss 0.615261\n",
      "iteration 214 / 300: loss 0.588227\n",
      "iteration 214 / 300: loss 0.627171\n",
      "iteration 214 / 300: loss 0.592600\n",
      "iteration 214 / 300: loss 0.621500\n",
      "iteration 214 / 300: loss 0.593093\n",
      "iteration 214 / 300: loss 0.600541\n",
      "iteration 214 / 300: loss 0.571000\n",
      "iteration 214 / 300: loss 0.592911\n",
      "iteration 214 / 300: loss 0.600043\n",
      "iteration 214 / 300: loss 0.598053\n",
      "iteration 214 / 300: loss 0.583712\n",
      "iteration 214 / 300: loss 0.614355\n",
      "iteration 214 / 300: loss 0.591285\n",
      "iteration 214 / 300: loss 0.591391\n",
      "iteration 214 / 300: loss 0.594005\n",
      "iteration 214 / 300: loss 0.596735\n",
      "iteration 214 / 300: loss 0.596712\n",
      "iteration 214 / 300: loss 0.611735\n",
      "iteration 214 / 300: loss 0.607258\n",
      "iteration 214 / 300: loss 0.597031\n",
      "iteration 214 / 300: loss 0.596301\n",
      "iteration 214 / 300: loss 0.627391\n",
      "iteration 214 / 300: loss 0.601584\n",
      "iteration 214 / 300: loss 0.599923\n",
      "iteration 214 / 300: loss 0.621952\n",
      "iteration 214 / 300: loss 0.581435\n",
      "iteration 214 / 300: loss 0.599604\n",
      "iteration 214 / 300: loss 0.591182\n",
      "iteration 214 / 300: loss 0.599919\n",
      "iteration 214 / 300: loss 0.596015\n",
      "iteration 214 / 300: loss 0.590760\n",
      "iteration 214 / 300: loss 0.591961\n",
      "iteration 214 / 300: loss 0.615468\n",
      "iteration 214 / 300: loss 0.621360\n",
      "iteration 214 / 300: loss 0.587267\n",
      "iteration 214 / 300: loss 0.582483\n",
      "iteration 214 / 300: loss 0.585572\n",
      "iteration 214 / 300: loss 0.603666\n",
      "iteration 214 / 300: loss 0.585192\n",
      "iteration 214 / 300: loss 0.578880\n",
      "iteration 214 / 300: loss 0.576418\n",
      "iteration 214 / 300: loss 0.574097\n",
      "iteration 214 / 300: loss 0.600500\n",
      "iteration 214 / 300: loss 0.584490\n",
      "iteration 214 / 300: loss 0.584834\n",
      "iteration 214 / 300: loss 0.568323\n",
      "iteration 214 / 300: loss 0.592025\n",
      "iteration 214 / 300: loss 0.612116\n",
      "iteration 214 / 300: loss 0.608923\n",
      "iteration 214 / 300: loss 0.607613\n",
      "iteration 214 / 300: loss 0.595533\n",
      "iteration 214 / 300: loss 0.592837\n",
      "iteration 214 / 300: loss 0.597988\n",
      "iteration 214 / 300: loss 0.597677\n",
      "iteration 214 / 300: loss 0.600953\n",
      "iteration 214 / 300: loss 0.597422\n",
      "iteration 214 / 300: loss 0.598776\n",
      "iteration 214 / 300: loss 0.587806\n",
      "iteration 214 / 300: loss 0.600499\n",
      "iteration 214 / 300: loss 0.599650\n",
      "iteration 214 / 300: loss 0.617540\n",
      "iteration 214 / 300: loss 0.598875\n",
      "iteration 214 / 300: loss 0.600801\n",
      "iteration 214 / 300: loss 0.605305\n",
      "iteration 214 / 300: loss 0.598592\n",
      "iteration 214 / 300: loss 0.591474\n",
      "iteration 214 / 300: loss 0.580382\n",
      "iteration 214 / 300: loss 0.598221\n",
      "iteration 214 / 300: loss 0.611685\n",
      "iteration 214 / 300: loss 0.613219\n",
      "iteration 214 / 300: loss 0.582214\n",
      "iteration 214 / 300: loss 0.601955\n",
      "iteration 214 / 300: loss 0.608956\n",
      "iteration 214 / 300: loss 0.601794\n",
      "iteration 214 / 300: loss 0.607944\n",
      "iteration 214 / 300: loss 0.620236\n",
      "iteration 214 / 300: loss 0.584817\n",
      "iteration 214 / 300: loss 0.583721\n",
      "iteration 214 / 300: loss 0.628849\n",
      "iteration 214 / 300: loss 0.609399\n",
      "iteration 214 / 300: loss 0.606265\n",
      "iteration 214 / 300: loss 0.599034\n",
      "iteration 214 / 300: loss 0.615876\n",
      "iteration 214 / 300: loss 0.596489\n",
      "iteration 214 / 300: loss 0.581430\n",
      "iteration 214 / 300: loss 0.609807\n",
      "iteration 214 / 300: loss 0.608125\n",
      "iteration 214 / 300: loss 0.598224\n",
      "iteration 214 / 300: loss 0.592022\n",
      "iteration 214 / 300: loss 0.611031\n",
      "iteration 214 / 300: loss 0.598550\n",
      "iteration 214 / 300: loss 0.581382\n",
      "iteration 214 / 300: loss 0.609580\n",
      "iteration 215 / 300: loss 0.578384\n",
      "iteration 215 / 300: loss 0.596214\n",
      "iteration 215 / 300: loss 0.569455\n",
      "iteration 215 / 300: loss 0.597849\n",
      "iteration 215 / 300: loss 0.598940\n",
      "iteration 215 / 300: loss 0.603876\n",
      "iteration 215 / 300: loss 0.615261\n",
      "iteration 215 / 300: loss 0.588227\n",
      "iteration 215 / 300: loss 0.627171\n",
      "iteration 215 / 300: loss 0.592600\n",
      "iteration 215 / 300: loss 0.621500\n",
      "iteration 215 / 300: loss 0.593093\n",
      "iteration 215 / 300: loss 0.600541\n",
      "iteration 215 / 300: loss 0.571000\n",
      "iteration 215 / 300: loss 0.592911\n",
      "iteration 215 / 300: loss 0.600043\n",
      "iteration 215 / 300: loss 0.598053\n",
      "iteration 215 / 300: loss 0.583712\n",
      "iteration 215 / 300: loss 0.614355\n",
      "iteration 215 / 300: loss 0.591285\n",
      "iteration 215 / 300: loss 0.591391\n",
      "iteration 215 / 300: loss 0.594005\n",
      "iteration 215 / 300: loss 0.596735\n",
      "iteration 215 / 300: loss 0.596712\n",
      "iteration 215 / 300: loss 0.611735\n",
      "iteration 215 / 300: loss 0.607258\n",
      "iteration 215 / 300: loss 0.597031\n",
      "iteration 215 / 300: loss 0.596301\n",
      "iteration 215 / 300: loss 0.627391\n",
      "iteration 215 / 300: loss 0.601584\n",
      "iteration 215 / 300: loss 0.599923\n",
      "iteration 215 / 300: loss 0.621952\n",
      "iteration 215 / 300: loss 0.581435\n",
      "iteration 215 / 300: loss 0.599604\n",
      "iteration 215 / 300: loss 0.591182\n",
      "iteration 215 / 300: loss 0.599919\n",
      "iteration 215 / 300: loss 0.596015\n",
      "iteration 215 / 300: loss 0.590760\n",
      "iteration 215 / 300: loss 0.591961\n",
      "iteration 215 / 300: loss 0.615468\n",
      "iteration 215 / 300: loss 0.621360\n",
      "iteration 215 / 300: loss 0.587267\n",
      "iteration 215 / 300: loss 0.582483\n",
      "iteration 215 / 300: loss 0.585572\n",
      "iteration 215 / 300: loss 0.603666\n",
      "iteration 215 / 300: loss 0.585192\n",
      "iteration 215 / 300: loss 0.578880\n",
      "iteration 215 / 300: loss 0.576418\n",
      "iteration 215 / 300: loss 0.574097\n",
      "iteration 215 / 300: loss 0.600500\n",
      "iteration 215 / 300: loss 0.584490\n",
      "iteration 215 / 300: loss 0.584834\n",
      "iteration 215 / 300: loss 0.568323\n",
      "iteration 215 / 300: loss 0.592025\n",
      "iteration 215 / 300: loss 0.612116\n",
      "iteration 215 / 300: loss 0.608923\n",
      "iteration 215 / 300: loss 0.607613\n",
      "iteration 215 / 300: loss 0.595533\n",
      "iteration 215 / 300: loss 0.592837\n",
      "iteration 215 / 300: loss 0.597988\n",
      "iteration 215 / 300: loss 0.597677\n",
      "iteration 215 / 300: loss 0.600953\n",
      "iteration 215 / 300: loss 0.597422\n",
      "iteration 215 / 300: loss 0.598776\n",
      "iteration 215 / 300: loss 0.587806\n",
      "iteration 215 / 300: loss 0.600499\n",
      "iteration 215 / 300: loss 0.599650\n",
      "iteration 215 / 300: loss 0.617540\n",
      "iteration 215 / 300: loss 0.598875\n",
      "iteration 215 / 300: loss 0.600801\n",
      "iteration 215 / 300: loss 0.605305\n",
      "iteration 215 / 300: loss 0.598592\n",
      "iteration 215 / 300: loss 0.591474\n",
      "iteration 215 / 300: loss 0.580382\n",
      "iteration 215 / 300: loss 0.598221\n",
      "iteration 215 / 300: loss 0.611685\n",
      "iteration 215 / 300: loss 0.613219\n",
      "iteration 215 / 300: loss 0.582214\n",
      "iteration 215 / 300: loss 0.601955\n",
      "iteration 215 / 300: loss 0.608956\n",
      "iteration 215 / 300: loss 0.601794\n",
      "iteration 215 / 300: loss 0.607944\n",
      "iteration 215 / 300: loss 0.620236\n",
      "iteration 215 / 300: loss 0.584817\n",
      "iteration 215 / 300: loss 0.583721\n",
      "iteration 215 / 300: loss 0.628849\n",
      "iteration 215 / 300: loss 0.609399\n",
      "iteration 215 / 300: loss 0.606265\n",
      "iteration 215 / 300: loss 0.599034\n",
      "iteration 215 / 300: loss 0.615876\n",
      "iteration 215 / 300: loss 0.596489\n",
      "iteration 215 / 300: loss 0.581430\n",
      "iteration 215 / 300: loss 0.609807\n",
      "iteration 215 / 300: loss 0.608125\n",
      "iteration 215 / 300: loss 0.598224\n",
      "iteration 215 / 300: loss 0.592022\n",
      "iteration 215 / 300: loss 0.611031\n",
      "iteration 215 / 300: loss 0.598550\n",
      "iteration 215 / 300: loss 0.581382\n",
      "iteration 215 / 300: loss 0.609580\n",
      "iteration 216 / 300: loss 0.578384\n",
      "iteration 216 / 300: loss 0.596214\n",
      "iteration 216 / 300: loss 0.569455\n",
      "iteration 216 / 300: loss 0.597849\n",
      "iteration 216 / 300: loss 0.598940\n",
      "iteration 216 / 300: loss 0.603876\n",
      "iteration 216 / 300: loss 0.615261\n",
      "iteration 216 / 300: loss 0.588227\n",
      "iteration 216 / 300: loss 0.627171\n",
      "iteration 216 / 300: loss 0.592600\n",
      "iteration 216 / 300: loss 0.621500\n",
      "iteration 216 / 300: loss 0.593093\n",
      "iteration 216 / 300: loss 0.600541\n",
      "iteration 216 / 300: loss 0.571000\n",
      "iteration 216 / 300: loss 0.592911\n",
      "iteration 216 / 300: loss 0.600043\n",
      "iteration 216 / 300: loss 0.598053\n",
      "iteration 216 / 300: loss 0.583712\n",
      "iteration 216 / 300: loss 0.614355\n",
      "iteration 216 / 300: loss 0.591285\n",
      "iteration 216 / 300: loss 0.591391\n",
      "iteration 216 / 300: loss 0.594005\n",
      "iteration 216 / 300: loss 0.596735\n",
      "iteration 216 / 300: loss 0.596712\n",
      "iteration 216 / 300: loss 0.611735\n",
      "iteration 216 / 300: loss 0.607258\n",
      "iteration 216 / 300: loss 0.597031\n",
      "iteration 216 / 300: loss 0.596301\n",
      "iteration 216 / 300: loss 0.627391\n",
      "iteration 216 / 300: loss 0.601584\n",
      "iteration 216 / 300: loss 0.599923\n",
      "iteration 216 / 300: loss 0.621952\n",
      "iteration 216 / 300: loss 0.581435\n",
      "iteration 216 / 300: loss 0.599604\n",
      "iteration 216 / 300: loss 0.591182\n",
      "iteration 216 / 300: loss 0.599919\n",
      "iteration 216 / 300: loss 0.596015\n",
      "iteration 216 / 300: loss 0.590760\n",
      "iteration 216 / 300: loss 0.591961\n",
      "iteration 216 / 300: loss 0.615468\n",
      "iteration 216 / 300: loss 0.621360\n",
      "iteration 216 / 300: loss 0.587267\n",
      "iteration 216 / 300: loss 0.582483\n",
      "iteration 216 / 300: loss 0.585572\n",
      "iteration 216 / 300: loss 0.603666\n",
      "iteration 216 / 300: loss 0.585192\n",
      "iteration 216 / 300: loss 0.578880\n",
      "iteration 216 / 300: loss 0.576418\n",
      "iteration 216 / 300: loss 0.574097\n",
      "iteration 216 / 300: loss 0.600500\n",
      "iteration 216 / 300: loss 0.584490\n",
      "iteration 216 / 300: loss 0.584834\n",
      "iteration 216 / 300: loss 0.568323\n",
      "iteration 216 / 300: loss 0.592025\n",
      "iteration 216 / 300: loss 0.612116\n",
      "iteration 216 / 300: loss 0.608923\n",
      "iteration 216 / 300: loss 0.607613\n",
      "iteration 216 / 300: loss 0.595533\n",
      "iteration 216 / 300: loss 0.592837\n",
      "iteration 216 / 300: loss 0.597988\n",
      "iteration 216 / 300: loss 0.597677\n",
      "iteration 216 / 300: loss 0.600953\n",
      "iteration 216 / 300: loss 0.597422\n",
      "iteration 216 / 300: loss 0.598776\n",
      "iteration 216 / 300: loss 0.587806\n",
      "iteration 216 / 300: loss 0.600499\n",
      "iteration 216 / 300: loss 0.599650\n",
      "iteration 216 / 300: loss 0.617540\n",
      "iteration 216 / 300: loss 0.598875\n",
      "iteration 216 / 300: loss 0.600801\n",
      "iteration 216 / 300: loss 0.605305\n",
      "iteration 216 / 300: loss 0.598592\n",
      "iteration 216 / 300: loss 0.591474\n",
      "iteration 216 / 300: loss 0.580382\n",
      "iteration 216 / 300: loss 0.598221\n",
      "iteration 216 / 300: loss 0.611685\n",
      "iteration 216 / 300: loss 0.613219\n",
      "iteration 216 / 300: loss 0.582214\n",
      "iteration 216 / 300: loss 0.601955\n",
      "iteration 216 / 300: loss 0.608956\n",
      "iteration 216 / 300: loss 0.601794\n",
      "iteration 216 / 300: loss 0.607944\n",
      "iteration 216 / 300: loss 0.620236\n",
      "iteration 216 / 300: loss 0.584817\n",
      "iteration 216 / 300: loss 0.583721\n",
      "iteration 216 / 300: loss 0.628849\n",
      "iteration 216 / 300: loss 0.609399\n",
      "iteration 216 / 300: loss 0.606265\n",
      "iteration 216 / 300: loss 0.599034\n",
      "iteration 216 / 300: loss 0.615876\n",
      "iteration 216 / 300: loss 0.596489\n",
      "iteration 216 / 300: loss 0.581430\n",
      "iteration 216 / 300: loss 0.609807\n",
      "iteration 216 / 300: loss 0.608125\n",
      "iteration 216 / 300: loss 0.598224\n",
      "iteration 216 / 300: loss 0.592022\n",
      "iteration 216 / 300: loss 0.611031\n",
      "iteration 216 / 300: loss 0.598550\n",
      "iteration 216 / 300: loss 0.581382\n",
      "iteration 216 / 300: loss 0.609580\n",
      "iteration 217 / 300: loss 0.578384\n",
      "iteration 217 / 300: loss 0.596214\n",
      "iteration 217 / 300: loss 0.569455\n",
      "iteration 217 / 300: loss 0.597849\n",
      "iteration 217 / 300: loss 0.598940\n",
      "iteration 217 / 300: loss 0.603876\n",
      "iteration 217 / 300: loss 0.615261\n",
      "iteration 217 / 300: loss 0.588227\n",
      "iteration 217 / 300: loss 0.627171\n",
      "iteration 217 / 300: loss 0.592600\n",
      "iteration 217 / 300: loss 0.621500\n",
      "iteration 217 / 300: loss 0.593093\n",
      "iteration 217 / 300: loss 0.600541\n",
      "iteration 217 / 300: loss 0.571000\n",
      "iteration 217 / 300: loss 0.592911\n",
      "iteration 217 / 300: loss 0.600043\n",
      "iteration 217 / 300: loss 0.598053\n",
      "iteration 217 / 300: loss 0.583712\n",
      "iteration 217 / 300: loss 0.614355\n",
      "iteration 217 / 300: loss 0.591285\n",
      "iteration 217 / 300: loss 0.591391\n",
      "iteration 217 / 300: loss 0.594005\n",
      "iteration 217 / 300: loss 0.596735\n",
      "iteration 217 / 300: loss 0.596712\n",
      "iteration 217 / 300: loss 0.611735\n",
      "iteration 217 / 300: loss 0.607258\n",
      "iteration 217 / 300: loss 0.597031\n",
      "iteration 217 / 300: loss 0.596301\n",
      "iteration 217 / 300: loss 0.627391\n",
      "iteration 217 / 300: loss 0.601584\n",
      "iteration 217 / 300: loss 0.599923\n",
      "iteration 217 / 300: loss 0.621952\n",
      "iteration 217 / 300: loss 0.581435\n",
      "iteration 217 / 300: loss 0.599604\n",
      "iteration 217 / 300: loss 0.591182\n",
      "iteration 217 / 300: loss 0.599919\n",
      "iteration 217 / 300: loss 0.596015\n",
      "iteration 217 / 300: loss 0.590760\n",
      "iteration 217 / 300: loss 0.591961\n",
      "iteration 217 / 300: loss 0.615468\n",
      "iteration 217 / 300: loss 0.621360\n",
      "iteration 217 / 300: loss 0.587267\n",
      "iteration 217 / 300: loss 0.582483\n",
      "iteration 217 / 300: loss 0.585572\n",
      "iteration 217 / 300: loss 0.603666\n",
      "iteration 217 / 300: loss 0.585192\n",
      "iteration 217 / 300: loss 0.578880\n",
      "iteration 217 / 300: loss 0.576418\n",
      "iteration 217 / 300: loss 0.574097\n",
      "iteration 217 / 300: loss 0.600500\n",
      "iteration 217 / 300: loss 0.584490\n",
      "iteration 217 / 300: loss 0.584834\n",
      "iteration 217 / 300: loss 0.568323\n",
      "iteration 217 / 300: loss 0.592025\n",
      "iteration 217 / 300: loss 0.612116\n",
      "iteration 217 / 300: loss 0.608923\n",
      "iteration 217 / 300: loss 0.607613\n",
      "iteration 217 / 300: loss 0.595533\n",
      "iteration 217 / 300: loss 0.592837\n",
      "iteration 217 / 300: loss 0.597988\n",
      "iteration 217 / 300: loss 0.597677\n",
      "iteration 217 / 300: loss 0.600953\n",
      "iteration 217 / 300: loss 0.597422\n",
      "iteration 217 / 300: loss 0.598776\n",
      "iteration 217 / 300: loss 0.587806\n",
      "iteration 217 / 300: loss 0.600499\n",
      "iteration 217 / 300: loss 0.599650\n",
      "iteration 217 / 300: loss 0.617540\n",
      "iteration 217 / 300: loss 0.598875\n",
      "iteration 217 / 300: loss 0.600801\n",
      "iteration 217 / 300: loss 0.605305\n",
      "iteration 217 / 300: loss 0.598592\n",
      "iteration 217 / 300: loss 0.591474\n",
      "iteration 217 / 300: loss 0.580382\n",
      "iteration 217 / 300: loss 0.598221\n",
      "iteration 217 / 300: loss 0.611685\n",
      "iteration 217 / 300: loss 0.613219\n",
      "iteration 217 / 300: loss 0.582214\n",
      "iteration 217 / 300: loss 0.601955\n",
      "iteration 217 / 300: loss 0.608956\n",
      "iteration 217 / 300: loss 0.601794\n",
      "iteration 217 / 300: loss 0.607944\n",
      "iteration 217 / 300: loss 0.620236\n",
      "iteration 217 / 300: loss 0.584817\n",
      "iteration 217 / 300: loss 0.583721\n",
      "iteration 217 / 300: loss 0.628849\n",
      "iteration 217 / 300: loss 0.609399\n",
      "iteration 217 / 300: loss 0.606265\n",
      "iteration 217 / 300: loss 0.599034\n",
      "iteration 217 / 300: loss 0.615876\n",
      "iteration 217 / 300: loss 0.596489\n",
      "iteration 217 / 300: loss 0.581430\n",
      "iteration 217 / 300: loss 0.609807\n",
      "iteration 217 / 300: loss 0.608125\n",
      "iteration 217 / 300: loss 0.598224\n",
      "iteration 217 / 300: loss 0.592022\n",
      "iteration 217 / 300: loss 0.611031\n",
      "iteration 217 / 300: loss 0.598550\n",
      "iteration 217 / 300: loss 0.581382\n",
      "iteration 217 / 300: loss 0.609580\n",
      "iteration 218 / 300: loss 0.578384\n",
      "iteration 218 / 300: loss 0.596214\n",
      "iteration 218 / 300: loss 0.569455\n",
      "iteration 218 / 300: loss 0.597849\n",
      "iteration 218 / 300: loss 0.598940\n",
      "iteration 218 / 300: loss 0.603876\n",
      "iteration 218 / 300: loss 0.615261\n",
      "iteration 218 / 300: loss 0.588227\n",
      "iteration 218 / 300: loss 0.627171\n",
      "iteration 218 / 300: loss 0.592600\n",
      "iteration 218 / 300: loss 0.621500\n",
      "iteration 218 / 300: loss 0.593093\n",
      "iteration 218 / 300: loss 0.600541\n",
      "iteration 218 / 300: loss 0.571000\n",
      "iteration 218 / 300: loss 0.592911\n",
      "iteration 218 / 300: loss 0.600043\n",
      "iteration 218 / 300: loss 0.598053\n",
      "iteration 218 / 300: loss 0.583712\n",
      "iteration 218 / 300: loss 0.614355\n",
      "iteration 218 / 300: loss 0.591285\n",
      "iteration 218 / 300: loss 0.591391\n",
      "iteration 218 / 300: loss 0.594005\n",
      "iteration 218 / 300: loss 0.596735\n",
      "iteration 218 / 300: loss 0.596712\n",
      "iteration 218 / 300: loss 0.611735\n",
      "iteration 218 / 300: loss 0.607258\n",
      "iteration 218 / 300: loss 0.597031\n",
      "iteration 218 / 300: loss 0.596301\n",
      "iteration 218 / 300: loss 0.627391\n",
      "iteration 218 / 300: loss 0.601584\n",
      "iteration 218 / 300: loss 0.599923\n",
      "iteration 218 / 300: loss 0.621952\n",
      "iteration 218 / 300: loss 0.581435\n",
      "iteration 218 / 300: loss 0.599604\n",
      "iteration 218 / 300: loss 0.591182\n",
      "iteration 218 / 300: loss 0.599919\n",
      "iteration 218 / 300: loss 0.596015\n",
      "iteration 218 / 300: loss 0.590760\n",
      "iteration 218 / 300: loss 0.591961\n",
      "iteration 218 / 300: loss 0.615468\n",
      "iteration 218 / 300: loss 0.621360\n",
      "iteration 218 / 300: loss 0.587267\n",
      "iteration 218 / 300: loss 0.582483\n",
      "iteration 218 / 300: loss 0.585572\n",
      "iteration 218 / 300: loss 0.603666\n",
      "iteration 218 / 300: loss 0.585192\n",
      "iteration 218 / 300: loss 0.578880\n",
      "iteration 218 / 300: loss 0.576418\n",
      "iteration 218 / 300: loss 0.574097\n",
      "iteration 218 / 300: loss 0.600500\n",
      "iteration 218 / 300: loss 0.584490\n",
      "iteration 218 / 300: loss 0.584834\n",
      "iteration 218 / 300: loss 0.568323\n",
      "iteration 218 / 300: loss 0.592025\n",
      "iteration 218 / 300: loss 0.612116\n",
      "iteration 218 / 300: loss 0.608923\n",
      "iteration 218 / 300: loss 0.607613\n",
      "iteration 218 / 300: loss 0.595533\n",
      "iteration 218 / 300: loss 0.592837\n",
      "iteration 218 / 300: loss 0.597988\n",
      "iteration 218 / 300: loss 0.597677\n",
      "iteration 218 / 300: loss 0.600953\n",
      "iteration 218 / 300: loss 0.597422\n",
      "iteration 218 / 300: loss 0.598776\n",
      "iteration 218 / 300: loss 0.587806\n",
      "iteration 218 / 300: loss 0.600499\n",
      "iteration 218 / 300: loss 0.599650\n",
      "iteration 218 / 300: loss 0.617540\n",
      "iteration 218 / 300: loss 0.598875\n",
      "iteration 218 / 300: loss 0.600801\n",
      "iteration 218 / 300: loss 0.605305\n",
      "iteration 218 / 300: loss 0.598592\n",
      "iteration 218 / 300: loss 0.591474\n",
      "iteration 218 / 300: loss 0.580382\n",
      "iteration 218 / 300: loss 0.598221\n",
      "iteration 218 / 300: loss 0.611685\n",
      "iteration 218 / 300: loss 0.613219\n",
      "iteration 218 / 300: loss 0.582214\n",
      "iteration 218 / 300: loss 0.601955\n",
      "iteration 218 / 300: loss 0.608956\n",
      "iteration 218 / 300: loss 0.601794\n",
      "iteration 218 / 300: loss 0.607944\n",
      "iteration 218 / 300: loss 0.620236\n",
      "iteration 218 / 300: loss 0.584817\n",
      "iteration 218 / 300: loss 0.583721\n",
      "iteration 218 / 300: loss 0.628849\n",
      "iteration 218 / 300: loss 0.609399\n",
      "iteration 218 / 300: loss 0.606265\n",
      "iteration 218 / 300: loss 0.599034\n",
      "iteration 218 / 300: loss 0.615876\n",
      "iteration 218 / 300: loss 0.596489\n",
      "iteration 218 / 300: loss 0.581430\n",
      "iteration 218 / 300: loss 0.609807\n",
      "iteration 218 / 300: loss 0.608125\n",
      "iteration 218 / 300: loss 0.598224\n",
      "iteration 218 / 300: loss 0.592022\n",
      "iteration 218 / 300: loss 0.611031\n",
      "iteration 218 / 300: loss 0.598550\n",
      "iteration 218 / 300: loss 0.581382\n",
      "iteration 218 / 300: loss 0.609580\n",
      "iteration 219 / 300: loss 0.578384\n",
      "iteration 219 / 300: loss 0.596214\n",
      "iteration 219 / 300: loss 0.569455\n",
      "iteration 219 / 300: loss 0.597849\n",
      "iteration 219 / 300: loss 0.598940\n",
      "iteration 219 / 300: loss 0.603876\n",
      "iteration 219 / 300: loss 0.615261\n",
      "iteration 219 / 300: loss 0.588227\n",
      "iteration 219 / 300: loss 0.627171\n",
      "iteration 219 / 300: loss 0.592600\n",
      "iteration 219 / 300: loss 0.621500\n",
      "iteration 219 / 300: loss 0.593093\n",
      "iteration 219 / 300: loss 0.600541\n",
      "iteration 219 / 300: loss 0.571000\n",
      "iteration 219 / 300: loss 0.592911\n",
      "iteration 219 / 300: loss 0.600043\n",
      "iteration 219 / 300: loss 0.598053\n",
      "iteration 219 / 300: loss 0.583712\n",
      "iteration 219 / 300: loss 0.614355\n",
      "iteration 219 / 300: loss 0.591285\n",
      "iteration 219 / 300: loss 0.591391\n",
      "iteration 219 / 300: loss 0.594005\n",
      "iteration 219 / 300: loss 0.596735\n",
      "iteration 219 / 300: loss 0.596712\n",
      "iteration 219 / 300: loss 0.611735\n",
      "iteration 219 / 300: loss 0.607258\n",
      "iteration 219 / 300: loss 0.597031\n",
      "iteration 219 / 300: loss 0.596301\n",
      "iteration 219 / 300: loss 0.627391\n",
      "iteration 219 / 300: loss 0.601584\n",
      "iteration 219 / 300: loss 0.599923\n",
      "iteration 219 / 300: loss 0.621952\n",
      "iteration 219 / 300: loss 0.581435\n",
      "iteration 219 / 300: loss 0.599604\n",
      "iteration 219 / 300: loss 0.591182\n",
      "iteration 219 / 300: loss 0.599919\n",
      "iteration 219 / 300: loss 0.596015\n",
      "iteration 219 / 300: loss 0.590760\n",
      "iteration 219 / 300: loss 0.591961\n",
      "iteration 219 / 300: loss 0.615468\n",
      "iteration 219 / 300: loss 0.621360\n",
      "iteration 219 / 300: loss 0.587267\n",
      "iteration 219 / 300: loss 0.582483\n",
      "iteration 219 / 300: loss 0.585572\n",
      "iteration 219 / 300: loss 0.603666\n",
      "iteration 219 / 300: loss 0.585192\n",
      "iteration 219 / 300: loss 0.578880\n",
      "iteration 219 / 300: loss 0.576418\n",
      "iteration 219 / 300: loss 0.574097\n",
      "iteration 219 / 300: loss 0.600500\n",
      "iteration 219 / 300: loss 0.584490\n",
      "iteration 219 / 300: loss 0.584834\n",
      "iteration 219 / 300: loss 0.568323\n",
      "iteration 219 / 300: loss 0.592025\n",
      "iteration 219 / 300: loss 0.612116\n",
      "iteration 219 / 300: loss 0.608923\n",
      "iteration 219 / 300: loss 0.607613\n",
      "iteration 219 / 300: loss 0.595533\n",
      "iteration 219 / 300: loss 0.592837\n",
      "iteration 219 / 300: loss 0.597988\n",
      "iteration 219 / 300: loss 0.597677\n",
      "iteration 219 / 300: loss 0.600953\n",
      "iteration 219 / 300: loss 0.597422\n",
      "iteration 219 / 300: loss 0.598776\n",
      "iteration 219 / 300: loss 0.587806\n",
      "iteration 219 / 300: loss 0.600499\n",
      "iteration 219 / 300: loss 0.599650\n",
      "iteration 219 / 300: loss 0.617540\n",
      "iteration 219 / 300: loss 0.598875\n",
      "iteration 219 / 300: loss 0.600801\n",
      "iteration 219 / 300: loss 0.605305\n",
      "iteration 219 / 300: loss 0.598592\n",
      "iteration 219 / 300: loss 0.591474\n",
      "iteration 219 / 300: loss 0.580382\n",
      "iteration 219 / 300: loss 0.598221\n",
      "iteration 219 / 300: loss 0.611685\n",
      "iteration 219 / 300: loss 0.613219\n",
      "iteration 219 / 300: loss 0.582214\n",
      "iteration 219 / 300: loss 0.601955\n",
      "iteration 219 / 300: loss 0.608956\n",
      "iteration 219 / 300: loss 0.601794\n",
      "iteration 219 / 300: loss 0.607944\n",
      "iteration 219 / 300: loss 0.620236\n",
      "iteration 219 / 300: loss 0.584817\n",
      "iteration 219 / 300: loss 0.583721\n",
      "iteration 219 / 300: loss 0.628849\n",
      "iteration 219 / 300: loss 0.609399\n",
      "iteration 219 / 300: loss 0.606265\n",
      "iteration 219 / 300: loss 0.599034\n",
      "iteration 219 / 300: loss 0.615876\n",
      "iteration 219 / 300: loss 0.596489\n",
      "iteration 219 / 300: loss 0.581430\n",
      "iteration 219 / 300: loss 0.609807\n",
      "iteration 219 / 300: loss 0.608125\n",
      "iteration 219 / 300: loss 0.598224\n",
      "iteration 219 / 300: loss 0.592022\n",
      "iteration 219 / 300: loss 0.611031\n",
      "iteration 219 / 300: loss 0.598550\n",
      "iteration 219 / 300: loss 0.581382\n",
      "iteration 219 / 300: loss 0.609580\n",
      "iteration 220 / 300: loss 0.578384\n",
      "iteration 220 / 300: loss 0.596214\n",
      "iteration 220 / 300: loss 0.569455\n",
      "iteration 220 / 300: loss 0.597849\n",
      "iteration 220 / 300: loss 0.598940\n",
      "iteration 220 / 300: loss 0.603876\n",
      "iteration 220 / 300: loss 0.615261\n",
      "iteration 220 / 300: loss 0.588227\n",
      "iteration 220 / 300: loss 0.627171\n",
      "iteration 220 / 300: loss 0.592600\n",
      "iteration 220 / 300: loss 0.621500\n",
      "iteration 220 / 300: loss 0.593093\n",
      "iteration 220 / 300: loss 0.600541\n",
      "iteration 220 / 300: loss 0.571000\n",
      "iteration 220 / 300: loss 0.592911\n",
      "iteration 220 / 300: loss 0.600043\n",
      "iteration 220 / 300: loss 0.598053\n",
      "iteration 220 / 300: loss 0.583712\n",
      "iteration 220 / 300: loss 0.614355\n",
      "iteration 220 / 300: loss 0.591285\n",
      "iteration 220 / 300: loss 0.591391\n",
      "iteration 220 / 300: loss 0.594005\n",
      "iteration 220 / 300: loss 0.596735\n",
      "iteration 220 / 300: loss 0.596712\n",
      "iteration 220 / 300: loss 0.611735\n",
      "iteration 220 / 300: loss 0.607258\n",
      "iteration 220 / 300: loss 0.597031\n",
      "iteration 220 / 300: loss 0.596301\n",
      "iteration 220 / 300: loss 0.627391\n",
      "iteration 220 / 300: loss 0.601584\n",
      "iteration 220 / 300: loss 0.599923\n",
      "iteration 220 / 300: loss 0.621952\n",
      "iteration 220 / 300: loss 0.581435\n",
      "iteration 220 / 300: loss 0.599604\n",
      "iteration 220 / 300: loss 0.591182\n",
      "iteration 220 / 300: loss 0.599919\n",
      "iteration 220 / 300: loss 0.596015\n",
      "iteration 220 / 300: loss 0.590760\n",
      "iteration 220 / 300: loss 0.591961\n",
      "iteration 220 / 300: loss 0.615468\n",
      "iteration 220 / 300: loss 0.621360\n",
      "iteration 220 / 300: loss 0.587267\n",
      "iteration 220 / 300: loss 0.582483\n",
      "iteration 220 / 300: loss 0.585572\n",
      "iteration 220 / 300: loss 0.603666\n",
      "iteration 220 / 300: loss 0.585192\n",
      "iteration 220 / 300: loss 0.578880\n",
      "iteration 220 / 300: loss 0.576418\n",
      "iteration 220 / 300: loss 0.574097\n",
      "iteration 220 / 300: loss 0.600500\n",
      "iteration 220 / 300: loss 0.584490\n",
      "iteration 220 / 300: loss 0.584834\n",
      "iteration 220 / 300: loss 0.568323\n",
      "iteration 220 / 300: loss 0.592025\n",
      "iteration 220 / 300: loss 0.612116\n",
      "iteration 220 / 300: loss 0.608923\n",
      "iteration 220 / 300: loss 0.607613\n",
      "iteration 220 / 300: loss 0.595533\n",
      "iteration 220 / 300: loss 0.592837\n",
      "iteration 220 / 300: loss 0.597988\n",
      "iteration 220 / 300: loss 0.597677\n",
      "iteration 220 / 300: loss 0.600953\n",
      "iteration 220 / 300: loss 0.597422\n",
      "iteration 220 / 300: loss 0.598776\n",
      "iteration 220 / 300: loss 0.587806\n",
      "iteration 220 / 300: loss 0.600499\n",
      "iteration 220 / 300: loss 0.599650\n",
      "iteration 220 / 300: loss 0.617540\n",
      "iteration 220 / 300: loss 0.598875\n",
      "iteration 220 / 300: loss 0.600801\n",
      "iteration 220 / 300: loss 0.605305\n",
      "iteration 220 / 300: loss 0.598592\n",
      "iteration 220 / 300: loss 0.591474\n",
      "iteration 220 / 300: loss 0.580382\n",
      "iteration 220 / 300: loss 0.598221\n",
      "iteration 220 / 300: loss 0.611685\n",
      "iteration 220 / 300: loss 0.613219\n",
      "iteration 220 / 300: loss 0.582214\n",
      "iteration 220 / 300: loss 0.601955\n",
      "iteration 220 / 300: loss 0.608956\n",
      "iteration 220 / 300: loss 0.601794\n",
      "iteration 220 / 300: loss 0.607944\n",
      "iteration 220 / 300: loss 0.620236\n",
      "iteration 220 / 300: loss 0.584817\n",
      "iteration 220 / 300: loss 0.583721\n",
      "iteration 220 / 300: loss 0.628849\n",
      "iteration 220 / 300: loss 0.609399\n",
      "iteration 220 / 300: loss 0.606265\n",
      "iteration 220 / 300: loss 0.599034\n",
      "iteration 220 / 300: loss 0.615876\n",
      "iteration 220 / 300: loss 0.596489\n",
      "iteration 220 / 300: loss 0.581430\n",
      "iteration 220 / 300: loss 0.609807\n",
      "iteration 220 / 300: loss 0.608125\n",
      "iteration 220 / 300: loss 0.598224\n",
      "iteration 220 / 300: loss 0.592022\n",
      "iteration 220 / 300: loss 0.611031\n",
      "iteration 220 / 300: loss 0.598550\n",
      "iteration 220 / 300: loss 0.581382\n",
      "iteration 220 / 300: loss 0.609580\n",
      "iteration 221 / 300: loss 0.578384\n",
      "iteration 221 / 300: loss 0.596214\n",
      "iteration 221 / 300: loss 0.569455\n",
      "iteration 221 / 300: loss 0.597849\n",
      "iteration 221 / 300: loss 0.598940\n",
      "iteration 221 / 300: loss 0.603876\n",
      "iteration 221 / 300: loss 0.615261\n",
      "iteration 221 / 300: loss 0.588227\n",
      "iteration 221 / 300: loss 0.627171\n",
      "iteration 221 / 300: loss 0.592600\n",
      "iteration 221 / 300: loss 0.621500\n",
      "iteration 221 / 300: loss 0.593093\n",
      "iteration 221 / 300: loss 0.600541\n",
      "iteration 221 / 300: loss 0.571000\n",
      "iteration 221 / 300: loss 0.592911\n",
      "iteration 221 / 300: loss 0.600043\n",
      "iteration 221 / 300: loss 0.598053\n",
      "iteration 221 / 300: loss 0.583712\n",
      "iteration 221 / 300: loss 0.614355\n",
      "iteration 221 / 300: loss 0.591285\n",
      "iteration 221 / 300: loss 0.591391\n",
      "iteration 221 / 300: loss 0.594005\n",
      "iteration 221 / 300: loss 0.596735\n",
      "iteration 221 / 300: loss 0.596712\n",
      "iteration 221 / 300: loss 0.611735\n",
      "iteration 221 / 300: loss 0.607258\n",
      "iteration 221 / 300: loss 0.597031\n",
      "iteration 221 / 300: loss 0.596301\n",
      "iteration 221 / 300: loss 0.627391\n",
      "iteration 221 / 300: loss 0.601584\n",
      "iteration 221 / 300: loss 0.599923\n",
      "iteration 221 / 300: loss 0.621952\n",
      "iteration 221 / 300: loss 0.581435\n",
      "iteration 221 / 300: loss 0.599604\n",
      "iteration 221 / 300: loss 0.591182\n",
      "iteration 221 / 300: loss 0.599919\n",
      "iteration 221 / 300: loss 0.596015\n",
      "iteration 221 / 300: loss 0.590760\n",
      "iteration 221 / 300: loss 0.591961\n",
      "iteration 221 / 300: loss 0.615468\n",
      "iteration 221 / 300: loss 0.621360\n",
      "iteration 221 / 300: loss 0.587267\n",
      "iteration 221 / 300: loss 0.582483\n",
      "iteration 221 / 300: loss 0.585572\n",
      "iteration 221 / 300: loss 0.603666\n",
      "iteration 221 / 300: loss 0.585192\n",
      "iteration 221 / 300: loss 0.578880\n",
      "iteration 221 / 300: loss 0.576418\n",
      "iteration 221 / 300: loss 0.574097\n",
      "iteration 221 / 300: loss 0.600500\n",
      "iteration 221 / 300: loss 0.584490\n",
      "iteration 221 / 300: loss 0.584834\n",
      "iteration 221 / 300: loss 0.568323\n",
      "iteration 221 / 300: loss 0.592025\n",
      "iteration 221 / 300: loss 0.612116\n",
      "iteration 221 / 300: loss 0.608923\n",
      "iteration 221 / 300: loss 0.607613\n",
      "iteration 221 / 300: loss 0.595533\n",
      "iteration 221 / 300: loss 0.592837\n",
      "iteration 221 / 300: loss 0.597988\n",
      "iteration 221 / 300: loss 0.597677\n",
      "iteration 221 / 300: loss 0.600953\n",
      "iteration 221 / 300: loss 0.597422\n",
      "iteration 221 / 300: loss 0.598776\n",
      "iteration 221 / 300: loss 0.587806\n",
      "iteration 221 / 300: loss 0.600499\n",
      "iteration 221 / 300: loss 0.599650\n",
      "iteration 221 / 300: loss 0.617540\n",
      "iteration 221 / 300: loss 0.598875\n",
      "iteration 221 / 300: loss 0.600801\n",
      "iteration 221 / 300: loss 0.605305\n",
      "iteration 221 / 300: loss 0.598592\n",
      "iteration 221 / 300: loss 0.591474\n",
      "iteration 221 / 300: loss 0.580382\n",
      "iteration 221 / 300: loss 0.598221\n",
      "iteration 221 / 300: loss 0.611685\n",
      "iteration 221 / 300: loss 0.613219\n",
      "iteration 221 / 300: loss 0.582214\n",
      "iteration 221 / 300: loss 0.601955\n",
      "iteration 221 / 300: loss 0.608956\n",
      "iteration 221 / 300: loss 0.601794\n",
      "iteration 221 / 300: loss 0.607944\n",
      "iteration 221 / 300: loss 0.620236\n",
      "iteration 221 / 300: loss 0.584817\n",
      "iteration 221 / 300: loss 0.583721\n",
      "iteration 221 / 300: loss 0.628849\n",
      "iteration 221 / 300: loss 0.609399\n",
      "iteration 221 / 300: loss 0.606265\n",
      "iteration 221 / 300: loss 0.599034\n",
      "iteration 221 / 300: loss 0.615876\n",
      "iteration 221 / 300: loss 0.596489\n",
      "iteration 221 / 300: loss 0.581430\n",
      "iteration 221 / 300: loss 0.609807\n",
      "iteration 221 / 300: loss 0.608125\n",
      "iteration 221 / 300: loss 0.598224\n",
      "iteration 221 / 300: loss 0.592022\n",
      "iteration 221 / 300: loss 0.611031\n",
      "iteration 221 / 300: loss 0.598550\n",
      "iteration 221 / 300: loss 0.581382\n",
      "iteration 221 / 300: loss 0.609580\n",
      "iteration 222 / 300: loss 0.578384\n",
      "iteration 222 / 300: loss 0.596214\n",
      "iteration 222 / 300: loss 0.569455\n",
      "iteration 222 / 300: loss 0.597849\n",
      "iteration 222 / 300: loss 0.598940\n",
      "iteration 222 / 300: loss 0.603876\n",
      "iteration 222 / 300: loss 0.615261\n",
      "iteration 222 / 300: loss 0.588227\n",
      "iteration 222 / 300: loss 0.627171\n",
      "iteration 222 / 300: loss 0.592600\n",
      "iteration 222 / 300: loss 0.621500\n",
      "iteration 222 / 300: loss 0.593093\n",
      "iteration 222 / 300: loss 0.600541\n",
      "iteration 222 / 300: loss 0.571000\n",
      "iteration 222 / 300: loss 0.592911\n",
      "iteration 222 / 300: loss 0.600043\n",
      "iteration 222 / 300: loss 0.598053\n",
      "iteration 222 / 300: loss 0.583712\n",
      "iteration 222 / 300: loss 0.614355\n",
      "iteration 222 / 300: loss 0.591285\n",
      "iteration 222 / 300: loss 0.591391\n",
      "iteration 222 / 300: loss 0.594005\n",
      "iteration 222 / 300: loss 0.596735\n",
      "iteration 222 / 300: loss 0.596712\n",
      "iteration 222 / 300: loss 0.611735\n",
      "iteration 222 / 300: loss 0.607258\n",
      "iteration 222 / 300: loss 0.597031\n",
      "iteration 222 / 300: loss 0.596301\n",
      "iteration 222 / 300: loss 0.627391\n",
      "iteration 222 / 300: loss 0.601584\n",
      "iteration 222 / 300: loss 0.599923\n",
      "iteration 222 / 300: loss 0.621952\n",
      "iteration 222 / 300: loss 0.581435\n",
      "iteration 222 / 300: loss 0.599604\n",
      "iteration 222 / 300: loss 0.591182\n",
      "iteration 222 / 300: loss 0.599919\n",
      "iteration 222 / 300: loss 0.596015\n",
      "iteration 222 / 300: loss 0.590760\n",
      "iteration 222 / 300: loss 0.591961\n",
      "iteration 222 / 300: loss 0.615468\n",
      "iteration 222 / 300: loss 0.621360\n",
      "iteration 222 / 300: loss 0.587267\n",
      "iteration 222 / 300: loss 0.582483\n",
      "iteration 222 / 300: loss 0.585572\n",
      "iteration 222 / 300: loss 0.603666\n",
      "iteration 222 / 300: loss 0.585192\n",
      "iteration 222 / 300: loss 0.578880\n",
      "iteration 222 / 300: loss 0.576418\n",
      "iteration 222 / 300: loss 0.574097\n",
      "iteration 222 / 300: loss 0.600500\n",
      "iteration 222 / 300: loss 0.584490\n",
      "iteration 222 / 300: loss 0.584834\n",
      "iteration 222 / 300: loss 0.568323\n",
      "iteration 222 / 300: loss 0.592025\n",
      "iteration 222 / 300: loss 0.612116\n",
      "iteration 222 / 300: loss 0.608923\n",
      "iteration 222 / 300: loss 0.607613\n",
      "iteration 222 / 300: loss 0.595533\n",
      "iteration 222 / 300: loss 0.592837\n",
      "iteration 222 / 300: loss 0.597988\n",
      "iteration 222 / 300: loss 0.597677\n",
      "iteration 222 / 300: loss 0.600953\n",
      "iteration 222 / 300: loss 0.597422\n",
      "iteration 222 / 300: loss 0.598776\n",
      "iteration 222 / 300: loss 0.587806\n",
      "iteration 222 / 300: loss 0.600499\n",
      "iteration 222 / 300: loss 0.599650\n",
      "iteration 222 / 300: loss 0.617540\n",
      "iteration 222 / 300: loss 0.598875\n",
      "iteration 222 / 300: loss 0.600801\n",
      "iteration 222 / 300: loss 0.605305\n",
      "iteration 222 / 300: loss 0.598592\n",
      "iteration 222 / 300: loss 0.591474\n",
      "iteration 222 / 300: loss 0.580382\n",
      "iteration 222 / 300: loss 0.598221\n",
      "iteration 222 / 300: loss 0.611685\n",
      "iteration 222 / 300: loss 0.613219\n",
      "iteration 222 / 300: loss 0.582214\n",
      "iteration 222 / 300: loss 0.601955\n",
      "iteration 222 / 300: loss 0.608956\n",
      "iteration 222 / 300: loss 0.601794\n",
      "iteration 222 / 300: loss 0.607944\n",
      "iteration 222 / 300: loss 0.620236\n",
      "iteration 222 / 300: loss 0.584817\n",
      "iteration 222 / 300: loss 0.583721\n",
      "iteration 222 / 300: loss 0.628849\n",
      "iteration 222 / 300: loss 0.609399\n",
      "iteration 222 / 300: loss 0.606265\n",
      "iteration 222 / 300: loss 0.599034\n",
      "iteration 222 / 300: loss 0.615876\n",
      "iteration 222 / 300: loss 0.596489\n",
      "iteration 222 / 300: loss 0.581430\n",
      "iteration 222 / 300: loss 0.609807\n",
      "iteration 222 / 300: loss 0.608125\n",
      "iteration 222 / 300: loss 0.598224\n",
      "iteration 222 / 300: loss 0.592022\n",
      "iteration 222 / 300: loss 0.611031\n",
      "iteration 222 / 300: loss 0.598550\n",
      "iteration 222 / 300: loss 0.581382\n",
      "iteration 222 / 300: loss 0.609580\n",
      "iteration 223 / 300: loss 0.578384\n",
      "iteration 223 / 300: loss 0.596214\n",
      "iteration 223 / 300: loss 0.569455\n",
      "iteration 223 / 300: loss 0.597849\n",
      "iteration 223 / 300: loss 0.598940\n",
      "iteration 223 / 300: loss 0.603876\n",
      "iteration 223 / 300: loss 0.615261\n",
      "iteration 223 / 300: loss 0.588227\n",
      "iteration 223 / 300: loss 0.627171\n",
      "iteration 223 / 300: loss 0.592600\n",
      "iteration 223 / 300: loss 0.621500\n",
      "iteration 223 / 300: loss 0.593093\n",
      "iteration 223 / 300: loss 0.600541\n",
      "iteration 223 / 300: loss 0.571000\n",
      "iteration 223 / 300: loss 0.592911\n",
      "iteration 223 / 300: loss 0.600043\n",
      "iteration 223 / 300: loss 0.598053\n",
      "iteration 223 / 300: loss 0.583712\n",
      "iteration 223 / 300: loss 0.614355\n",
      "iteration 223 / 300: loss 0.591285\n",
      "iteration 223 / 300: loss 0.591391\n",
      "iteration 223 / 300: loss 0.594005\n",
      "iteration 223 / 300: loss 0.596735\n",
      "iteration 223 / 300: loss 0.596712\n",
      "iteration 223 / 300: loss 0.611735\n",
      "iteration 223 / 300: loss 0.607258\n",
      "iteration 223 / 300: loss 0.597031\n",
      "iteration 223 / 300: loss 0.596301\n",
      "iteration 223 / 300: loss 0.627391\n",
      "iteration 223 / 300: loss 0.601584\n",
      "iteration 223 / 300: loss 0.599923\n",
      "iteration 223 / 300: loss 0.621952\n",
      "iteration 223 / 300: loss 0.581435\n",
      "iteration 223 / 300: loss 0.599604\n",
      "iteration 223 / 300: loss 0.591182\n",
      "iteration 223 / 300: loss 0.599919\n",
      "iteration 223 / 300: loss 0.596015\n",
      "iteration 223 / 300: loss 0.590760\n",
      "iteration 223 / 300: loss 0.591961\n",
      "iteration 223 / 300: loss 0.615468\n",
      "iteration 223 / 300: loss 0.621360\n",
      "iteration 223 / 300: loss 0.587267\n",
      "iteration 223 / 300: loss 0.582483\n",
      "iteration 223 / 300: loss 0.585572\n",
      "iteration 223 / 300: loss 0.603666\n",
      "iteration 223 / 300: loss 0.585192\n",
      "iteration 223 / 300: loss 0.578880\n",
      "iteration 223 / 300: loss 0.576418\n",
      "iteration 223 / 300: loss 0.574097\n",
      "iteration 223 / 300: loss 0.600500\n",
      "iteration 223 / 300: loss 0.584490\n",
      "iteration 223 / 300: loss 0.584834\n",
      "iteration 223 / 300: loss 0.568323\n",
      "iteration 223 / 300: loss 0.592025\n",
      "iteration 223 / 300: loss 0.612116\n",
      "iteration 223 / 300: loss 0.608923\n",
      "iteration 223 / 300: loss 0.607613\n",
      "iteration 223 / 300: loss 0.595533\n",
      "iteration 223 / 300: loss 0.592837\n",
      "iteration 223 / 300: loss 0.597988\n",
      "iteration 223 / 300: loss 0.597677\n",
      "iteration 223 / 300: loss 0.600953\n",
      "iteration 223 / 300: loss 0.597422\n",
      "iteration 223 / 300: loss 0.598776\n",
      "iteration 223 / 300: loss 0.587806\n",
      "iteration 223 / 300: loss 0.600499\n",
      "iteration 223 / 300: loss 0.599650\n",
      "iteration 223 / 300: loss 0.617540\n",
      "iteration 223 / 300: loss 0.598875\n",
      "iteration 223 / 300: loss 0.600801\n",
      "iteration 223 / 300: loss 0.605305\n",
      "iteration 223 / 300: loss 0.598592\n",
      "iteration 223 / 300: loss 0.591474\n",
      "iteration 223 / 300: loss 0.580382\n",
      "iteration 223 / 300: loss 0.598221\n",
      "iteration 223 / 300: loss 0.611685\n",
      "iteration 223 / 300: loss 0.613219\n",
      "iteration 223 / 300: loss 0.582214\n",
      "iteration 223 / 300: loss 0.601955\n",
      "iteration 223 / 300: loss 0.608956\n",
      "iteration 223 / 300: loss 0.601794\n",
      "iteration 223 / 300: loss 0.607944\n",
      "iteration 223 / 300: loss 0.620236\n",
      "iteration 223 / 300: loss 0.584817\n",
      "iteration 223 / 300: loss 0.583721\n",
      "iteration 223 / 300: loss 0.628849\n",
      "iteration 223 / 300: loss 0.609399\n",
      "iteration 223 / 300: loss 0.606265\n",
      "iteration 223 / 300: loss 0.599034\n",
      "iteration 223 / 300: loss 0.615876\n",
      "iteration 223 / 300: loss 0.596489\n",
      "iteration 223 / 300: loss 0.581430\n",
      "iteration 223 / 300: loss 0.609807\n",
      "iteration 223 / 300: loss 0.608125\n",
      "iteration 223 / 300: loss 0.598224\n",
      "iteration 223 / 300: loss 0.592022\n",
      "iteration 223 / 300: loss 0.611031\n",
      "iteration 223 / 300: loss 0.598550\n",
      "iteration 223 / 300: loss 0.581382\n",
      "iteration 223 / 300: loss 0.609580\n",
      "iteration 224 / 300: loss 0.578384\n",
      "iteration 224 / 300: loss 0.596214\n",
      "iteration 224 / 300: loss 0.569455\n",
      "iteration 224 / 300: loss 0.597849\n",
      "iteration 224 / 300: loss 0.598940\n",
      "iteration 224 / 300: loss 0.603876\n",
      "iteration 224 / 300: loss 0.615261\n",
      "iteration 224 / 300: loss 0.588227\n",
      "iteration 224 / 300: loss 0.627171\n",
      "iteration 224 / 300: loss 0.592600\n",
      "iteration 224 / 300: loss 0.621500\n",
      "iteration 224 / 300: loss 0.593093\n",
      "iteration 224 / 300: loss 0.600541\n",
      "iteration 224 / 300: loss 0.571000\n",
      "iteration 224 / 300: loss 0.592911\n",
      "iteration 224 / 300: loss 0.600043\n",
      "iteration 224 / 300: loss 0.598053\n",
      "iteration 224 / 300: loss 0.583712\n",
      "iteration 224 / 300: loss 0.614355\n",
      "iteration 224 / 300: loss 0.591285\n",
      "iteration 224 / 300: loss 0.591391\n",
      "iteration 224 / 300: loss 0.594005\n",
      "iteration 224 / 300: loss 0.596735\n",
      "iteration 224 / 300: loss 0.596712\n",
      "iteration 224 / 300: loss 0.611735\n",
      "iteration 224 / 300: loss 0.607258\n",
      "iteration 224 / 300: loss 0.597031\n",
      "iteration 224 / 300: loss 0.596301\n",
      "iteration 224 / 300: loss 0.627391\n",
      "iteration 224 / 300: loss 0.601584\n",
      "iteration 224 / 300: loss 0.599923\n",
      "iteration 224 / 300: loss 0.621952\n",
      "iteration 224 / 300: loss 0.581435\n",
      "iteration 224 / 300: loss 0.599604\n",
      "iteration 224 / 300: loss 0.591182\n",
      "iteration 224 / 300: loss 0.599919\n",
      "iteration 224 / 300: loss 0.596015\n",
      "iteration 224 / 300: loss 0.590760\n",
      "iteration 224 / 300: loss 0.591961\n",
      "iteration 224 / 300: loss 0.615468\n",
      "iteration 224 / 300: loss 0.621360\n",
      "iteration 224 / 300: loss 0.587267\n",
      "iteration 224 / 300: loss 0.582483\n",
      "iteration 224 / 300: loss 0.585572\n",
      "iteration 224 / 300: loss 0.603666\n",
      "iteration 224 / 300: loss 0.585192\n",
      "iteration 224 / 300: loss 0.578880\n",
      "iteration 224 / 300: loss 0.576418\n",
      "iteration 224 / 300: loss 0.574097\n",
      "iteration 224 / 300: loss 0.600500\n",
      "iteration 224 / 300: loss 0.584490\n",
      "iteration 224 / 300: loss 0.584834\n",
      "iteration 224 / 300: loss 0.568323\n",
      "iteration 224 / 300: loss 0.592025\n",
      "iteration 224 / 300: loss 0.612116\n",
      "iteration 224 / 300: loss 0.608923\n",
      "iteration 224 / 300: loss 0.607613\n",
      "iteration 224 / 300: loss 0.595533\n",
      "iteration 224 / 300: loss 0.592837\n",
      "iteration 224 / 300: loss 0.597988\n",
      "iteration 224 / 300: loss 0.597677\n",
      "iteration 224 / 300: loss 0.600953\n",
      "iteration 224 / 300: loss 0.597422\n",
      "iteration 224 / 300: loss 0.598776\n",
      "iteration 224 / 300: loss 0.587806\n",
      "iteration 224 / 300: loss 0.600499\n",
      "iteration 224 / 300: loss 0.599650\n",
      "iteration 224 / 300: loss 0.617540\n",
      "iteration 224 / 300: loss 0.598875\n",
      "iteration 224 / 300: loss 0.600801\n",
      "iteration 224 / 300: loss 0.605305\n",
      "iteration 224 / 300: loss 0.598592\n",
      "iteration 224 / 300: loss 0.591474\n",
      "iteration 224 / 300: loss 0.580382\n",
      "iteration 224 / 300: loss 0.598221\n",
      "iteration 224 / 300: loss 0.611685\n",
      "iteration 224 / 300: loss 0.613219\n",
      "iteration 224 / 300: loss 0.582214\n",
      "iteration 224 / 300: loss 0.601955\n",
      "iteration 224 / 300: loss 0.608956\n",
      "iteration 224 / 300: loss 0.601794\n",
      "iteration 224 / 300: loss 0.607944\n",
      "iteration 224 / 300: loss 0.620236\n",
      "iteration 224 / 300: loss 0.584817\n",
      "iteration 224 / 300: loss 0.583721\n",
      "iteration 224 / 300: loss 0.628849\n",
      "iteration 224 / 300: loss 0.609399\n",
      "iteration 224 / 300: loss 0.606265\n",
      "iteration 224 / 300: loss 0.599034\n",
      "iteration 224 / 300: loss 0.615876\n",
      "iteration 224 / 300: loss 0.596489\n",
      "iteration 224 / 300: loss 0.581430\n",
      "iteration 224 / 300: loss 0.609807\n",
      "iteration 224 / 300: loss 0.608125\n",
      "iteration 224 / 300: loss 0.598224\n",
      "iteration 224 / 300: loss 0.592022\n",
      "iteration 224 / 300: loss 0.611031\n",
      "iteration 224 / 300: loss 0.598550\n",
      "iteration 224 / 300: loss 0.581382\n",
      "iteration 224 / 300: loss 0.609580\n",
      "iteration 225 / 300: loss 0.578384\n",
      "iteration 225 / 300: loss 0.596214\n",
      "iteration 225 / 300: loss 0.569455\n",
      "iteration 225 / 300: loss 0.597849\n",
      "iteration 225 / 300: loss 0.598940\n",
      "iteration 225 / 300: loss 0.603876\n",
      "iteration 225 / 300: loss 0.615261\n",
      "iteration 225 / 300: loss 0.588227\n",
      "iteration 225 / 300: loss 0.627171\n",
      "iteration 225 / 300: loss 0.592600\n",
      "iteration 225 / 300: loss 0.621500\n",
      "iteration 225 / 300: loss 0.593093\n",
      "iteration 225 / 300: loss 0.600541\n",
      "iteration 225 / 300: loss 0.571000\n",
      "iteration 225 / 300: loss 0.592911\n",
      "iteration 225 / 300: loss 0.600043\n",
      "iteration 225 / 300: loss 0.598053\n",
      "iteration 225 / 300: loss 0.583712\n",
      "iteration 225 / 300: loss 0.614355\n",
      "iteration 225 / 300: loss 0.591285\n",
      "iteration 225 / 300: loss 0.591391\n",
      "iteration 225 / 300: loss 0.594005\n",
      "iteration 225 / 300: loss 0.596735\n",
      "iteration 225 / 300: loss 0.596712\n",
      "iteration 225 / 300: loss 0.611735\n",
      "iteration 225 / 300: loss 0.607258\n",
      "iteration 225 / 300: loss 0.597031\n",
      "iteration 225 / 300: loss 0.596301\n",
      "iteration 225 / 300: loss 0.627391\n",
      "iteration 225 / 300: loss 0.601584\n",
      "iteration 225 / 300: loss 0.599923\n",
      "iteration 225 / 300: loss 0.621952\n",
      "iteration 225 / 300: loss 0.581435\n",
      "iteration 225 / 300: loss 0.599604\n",
      "iteration 225 / 300: loss 0.591182\n",
      "iteration 225 / 300: loss 0.599919\n",
      "iteration 225 / 300: loss 0.596015\n",
      "iteration 225 / 300: loss 0.590760\n",
      "iteration 225 / 300: loss 0.591961\n",
      "iteration 225 / 300: loss 0.615468\n",
      "iteration 225 / 300: loss 0.621360\n",
      "iteration 225 / 300: loss 0.587267\n",
      "iteration 225 / 300: loss 0.582483\n",
      "iteration 225 / 300: loss 0.585572\n",
      "iteration 225 / 300: loss 0.603666\n",
      "iteration 225 / 300: loss 0.585192\n",
      "iteration 225 / 300: loss 0.578880\n",
      "iteration 225 / 300: loss 0.576418\n",
      "iteration 225 / 300: loss 0.574097\n",
      "iteration 225 / 300: loss 0.600500\n",
      "iteration 225 / 300: loss 0.584490\n",
      "iteration 225 / 300: loss 0.584834\n",
      "iteration 225 / 300: loss 0.568323\n",
      "iteration 225 / 300: loss 0.592025\n",
      "iteration 225 / 300: loss 0.612116\n",
      "iteration 225 / 300: loss 0.608923\n",
      "iteration 225 / 300: loss 0.607613\n",
      "iteration 225 / 300: loss 0.595533\n",
      "iteration 225 / 300: loss 0.592837\n",
      "iteration 225 / 300: loss 0.597988\n",
      "iteration 225 / 300: loss 0.597677\n",
      "iteration 225 / 300: loss 0.600953\n",
      "iteration 225 / 300: loss 0.597422\n",
      "iteration 225 / 300: loss 0.598776\n",
      "iteration 225 / 300: loss 0.587806\n",
      "iteration 225 / 300: loss 0.600499\n",
      "iteration 225 / 300: loss 0.599650\n",
      "iteration 225 / 300: loss 0.617540\n",
      "iteration 225 / 300: loss 0.598875\n",
      "iteration 225 / 300: loss 0.600801\n",
      "iteration 225 / 300: loss 0.605305\n",
      "iteration 225 / 300: loss 0.598592\n",
      "iteration 225 / 300: loss 0.591474\n",
      "iteration 225 / 300: loss 0.580382\n",
      "iteration 225 / 300: loss 0.598221\n",
      "iteration 225 / 300: loss 0.611685\n",
      "iteration 225 / 300: loss 0.613219\n",
      "iteration 225 / 300: loss 0.582214\n",
      "iteration 225 / 300: loss 0.601955\n",
      "iteration 225 / 300: loss 0.608956\n",
      "iteration 225 / 300: loss 0.601794\n",
      "iteration 225 / 300: loss 0.607944\n",
      "iteration 225 / 300: loss 0.620236\n",
      "iteration 225 / 300: loss 0.584817\n",
      "iteration 225 / 300: loss 0.583721\n",
      "iteration 225 / 300: loss 0.628849\n",
      "iteration 225 / 300: loss 0.609399\n",
      "iteration 225 / 300: loss 0.606265\n",
      "iteration 225 / 300: loss 0.599034\n",
      "iteration 225 / 300: loss 0.615876\n",
      "iteration 225 / 300: loss 0.596489\n",
      "iteration 225 / 300: loss 0.581430\n",
      "iteration 225 / 300: loss 0.609807\n",
      "iteration 225 / 300: loss 0.608125\n",
      "iteration 225 / 300: loss 0.598224\n",
      "iteration 225 / 300: loss 0.592022\n",
      "iteration 225 / 300: loss 0.611031\n",
      "iteration 225 / 300: loss 0.598550\n",
      "iteration 225 / 300: loss 0.581382\n",
      "iteration 225 / 300: loss 0.609580\n",
      "iteration 226 / 300: loss 0.578384\n",
      "iteration 226 / 300: loss 0.596214\n",
      "iteration 226 / 300: loss 0.569455\n",
      "iteration 226 / 300: loss 0.597849\n",
      "iteration 226 / 300: loss 0.598940\n",
      "iteration 226 / 300: loss 0.603876\n",
      "iteration 226 / 300: loss 0.615261\n",
      "iteration 226 / 300: loss 0.588227\n",
      "iteration 226 / 300: loss 0.627171\n",
      "iteration 226 / 300: loss 0.592600\n",
      "iteration 226 / 300: loss 0.621500\n",
      "iteration 226 / 300: loss 0.593093\n",
      "iteration 226 / 300: loss 0.600541\n",
      "iteration 226 / 300: loss 0.571000\n",
      "iteration 226 / 300: loss 0.592911\n",
      "iteration 226 / 300: loss 0.600043\n",
      "iteration 226 / 300: loss 0.598053\n",
      "iteration 226 / 300: loss 0.583712\n",
      "iteration 226 / 300: loss 0.614355\n",
      "iteration 226 / 300: loss 0.591285\n",
      "iteration 226 / 300: loss 0.591391\n",
      "iteration 226 / 300: loss 0.594005\n",
      "iteration 226 / 300: loss 0.596735\n",
      "iteration 226 / 300: loss 0.596712\n",
      "iteration 226 / 300: loss 0.611735\n",
      "iteration 226 / 300: loss 0.607258\n",
      "iteration 226 / 300: loss 0.597031\n",
      "iteration 226 / 300: loss 0.596301\n",
      "iteration 226 / 300: loss 0.627391\n",
      "iteration 226 / 300: loss 0.601584\n",
      "iteration 226 / 300: loss 0.599923\n",
      "iteration 226 / 300: loss 0.621952\n",
      "iteration 226 / 300: loss 0.581435\n",
      "iteration 226 / 300: loss 0.599604\n",
      "iteration 226 / 300: loss 0.591182\n",
      "iteration 226 / 300: loss 0.599919\n",
      "iteration 226 / 300: loss 0.596015\n",
      "iteration 226 / 300: loss 0.590760\n",
      "iteration 226 / 300: loss 0.591961\n",
      "iteration 226 / 300: loss 0.615468\n",
      "iteration 226 / 300: loss 0.621360\n",
      "iteration 226 / 300: loss 0.587267\n",
      "iteration 226 / 300: loss 0.582483\n",
      "iteration 226 / 300: loss 0.585572\n",
      "iteration 226 / 300: loss 0.603666\n",
      "iteration 226 / 300: loss 0.585192\n",
      "iteration 226 / 300: loss 0.578880\n",
      "iteration 226 / 300: loss 0.576418\n",
      "iteration 226 / 300: loss 0.574097\n",
      "iteration 226 / 300: loss 0.600500\n",
      "iteration 226 / 300: loss 0.584490\n",
      "iteration 226 / 300: loss 0.584834\n",
      "iteration 226 / 300: loss 0.568323\n",
      "iteration 226 / 300: loss 0.592025\n",
      "iteration 226 / 300: loss 0.612116\n",
      "iteration 226 / 300: loss 0.608923\n",
      "iteration 226 / 300: loss 0.607613\n",
      "iteration 226 / 300: loss 0.595533\n",
      "iteration 226 / 300: loss 0.592837\n",
      "iteration 226 / 300: loss 0.597988\n",
      "iteration 226 / 300: loss 0.597677\n",
      "iteration 226 / 300: loss 0.600953\n",
      "iteration 226 / 300: loss 0.597422\n",
      "iteration 226 / 300: loss 0.598776\n",
      "iteration 226 / 300: loss 0.587806\n",
      "iteration 226 / 300: loss 0.600499\n",
      "iteration 226 / 300: loss 0.599650\n",
      "iteration 226 / 300: loss 0.617540\n",
      "iteration 226 / 300: loss 0.598875\n",
      "iteration 226 / 300: loss 0.600801\n",
      "iteration 226 / 300: loss 0.605305\n",
      "iteration 226 / 300: loss 0.598592\n",
      "iteration 226 / 300: loss 0.591474\n",
      "iteration 226 / 300: loss 0.580382\n",
      "iteration 226 / 300: loss 0.598221\n",
      "iteration 226 / 300: loss 0.611685\n",
      "iteration 226 / 300: loss 0.613219\n",
      "iteration 226 / 300: loss 0.582214\n",
      "iteration 226 / 300: loss 0.601955\n",
      "iteration 226 / 300: loss 0.608956\n",
      "iteration 226 / 300: loss 0.601794\n",
      "iteration 226 / 300: loss 0.607944\n",
      "iteration 226 / 300: loss 0.620236\n",
      "iteration 226 / 300: loss 0.584817\n",
      "iteration 226 / 300: loss 0.583721\n",
      "iteration 226 / 300: loss 0.628849\n",
      "iteration 226 / 300: loss 0.609399\n",
      "iteration 226 / 300: loss 0.606265\n",
      "iteration 226 / 300: loss 0.599034\n",
      "iteration 226 / 300: loss 0.615876\n",
      "iteration 226 / 300: loss 0.596489\n",
      "iteration 226 / 300: loss 0.581430\n",
      "iteration 226 / 300: loss 0.609807\n",
      "iteration 226 / 300: loss 0.608125\n",
      "iteration 226 / 300: loss 0.598224\n",
      "iteration 226 / 300: loss 0.592022\n",
      "iteration 226 / 300: loss 0.611031\n",
      "iteration 226 / 300: loss 0.598550\n",
      "iteration 226 / 300: loss 0.581382\n",
      "iteration 226 / 300: loss 0.609580\n",
      "iteration 227 / 300: loss 0.578384\n",
      "iteration 227 / 300: loss 0.596214\n",
      "iteration 227 / 300: loss 0.569455\n",
      "iteration 227 / 300: loss 0.597849\n",
      "iteration 227 / 300: loss 0.598940\n",
      "iteration 227 / 300: loss 0.603876\n",
      "iteration 227 / 300: loss 0.615261\n",
      "iteration 227 / 300: loss 0.588227\n",
      "iteration 227 / 300: loss 0.627171\n",
      "iteration 227 / 300: loss 0.592600\n",
      "iteration 227 / 300: loss 0.621500\n",
      "iteration 227 / 300: loss 0.593093\n",
      "iteration 227 / 300: loss 0.600541\n",
      "iteration 227 / 300: loss 0.571000\n",
      "iteration 227 / 300: loss 0.592911\n",
      "iteration 227 / 300: loss 0.600043\n",
      "iteration 227 / 300: loss 0.598053\n",
      "iteration 227 / 300: loss 0.583712\n",
      "iteration 227 / 300: loss 0.614355\n",
      "iteration 227 / 300: loss 0.591285\n",
      "iteration 227 / 300: loss 0.591391\n",
      "iteration 227 / 300: loss 0.594005\n",
      "iteration 227 / 300: loss 0.596735\n",
      "iteration 227 / 300: loss 0.596712\n",
      "iteration 227 / 300: loss 0.611735\n",
      "iteration 227 / 300: loss 0.607258\n",
      "iteration 227 / 300: loss 0.597031\n",
      "iteration 227 / 300: loss 0.596301\n",
      "iteration 227 / 300: loss 0.627391\n",
      "iteration 227 / 300: loss 0.601584\n",
      "iteration 227 / 300: loss 0.599923\n",
      "iteration 227 / 300: loss 0.621952\n",
      "iteration 227 / 300: loss 0.581435\n",
      "iteration 227 / 300: loss 0.599604\n",
      "iteration 227 / 300: loss 0.591182\n",
      "iteration 227 / 300: loss 0.599919\n",
      "iteration 227 / 300: loss 0.596015\n",
      "iteration 227 / 300: loss 0.590760\n",
      "iteration 227 / 300: loss 0.591961\n",
      "iteration 227 / 300: loss 0.615468\n",
      "iteration 227 / 300: loss 0.621360\n",
      "iteration 227 / 300: loss 0.587267\n",
      "iteration 227 / 300: loss 0.582483\n",
      "iteration 227 / 300: loss 0.585572\n",
      "iteration 227 / 300: loss 0.603666\n",
      "iteration 227 / 300: loss 0.585192\n",
      "iteration 227 / 300: loss 0.578880\n",
      "iteration 227 / 300: loss 0.576418\n",
      "iteration 227 / 300: loss 0.574097\n",
      "iteration 227 / 300: loss 0.600500\n",
      "iteration 227 / 300: loss 0.584490\n",
      "iteration 227 / 300: loss 0.584834\n",
      "iteration 227 / 300: loss 0.568323\n",
      "iteration 227 / 300: loss 0.592025\n",
      "iteration 227 / 300: loss 0.612116\n",
      "iteration 227 / 300: loss 0.608923\n",
      "iteration 227 / 300: loss 0.607613\n",
      "iteration 227 / 300: loss 0.595533\n",
      "iteration 227 / 300: loss 0.592837\n",
      "iteration 227 / 300: loss 0.597988\n",
      "iteration 227 / 300: loss 0.597677\n",
      "iteration 227 / 300: loss 0.600953\n",
      "iteration 227 / 300: loss 0.597422\n",
      "iteration 227 / 300: loss 0.598776\n",
      "iteration 227 / 300: loss 0.587806\n",
      "iteration 227 / 300: loss 0.600499\n",
      "iteration 227 / 300: loss 0.599650\n",
      "iteration 227 / 300: loss 0.617540\n",
      "iteration 227 / 300: loss 0.598875\n",
      "iteration 227 / 300: loss 0.600801\n",
      "iteration 227 / 300: loss 0.605305\n",
      "iteration 227 / 300: loss 0.598592\n",
      "iteration 227 / 300: loss 0.591474\n",
      "iteration 227 / 300: loss 0.580382\n",
      "iteration 227 / 300: loss 0.598221\n",
      "iteration 227 / 300: loss 0.611685\n",
      "iteration 227 / 300: loss 0.613219\n",
      "iteration 227 / 300: loss 0.582214\n",
      "iteration 227 / 300: loss 0.601955\n",
      "iteration 227 / 300: loss 0.608956\n",
      "iteration 227 / 300: loss 0.601794\n",
      "iteration 227 / 300: loss 0.607944\n",
      "iteration 227 / 300: loss 0.620236\n",
      "iteration 227 / 300: loss 0.584817\n",
      "iteration 227 / 300: loss 0.583721\n",
      "iteration 227 / 300: loss 0.628849\n",
      "iteration 227 / 300: loss 0.609399\n",
      "iteration 227 / 300: loss 0.606265\n",
      "iteration 227 / 300: loss 0.599034\n",
      "iteration 227 / 300: loss 0.615876\n",
      "iteration 227 / 300: loss 0.596489\n",
      "iteration 227 / 300: loss 0.581430\n",
      "iteration 227 / 300: loss 0.609807\n",
      "iteration 227 / 300: loss 0.608125\n",
      "iteration 227 / 300: loss 0.598224\n",
      "iteration 227 / 300: loss 0.592022\n",
      "iteration 227 / 300: loss 0.611031\n",
      "iteration 227 / 300: loss 0.598550\n",
      "iteration 227 / 300: loss 0.581382\n",
      "iteration 227 / 300: loss 0.609580\n",
      "iteration 228 / 300: loss 0.578384\n",
      "iteration 228 / 300: loss 0.596214\n",
      "iteration 228 / 300: loss 0.569455\n",
      "iteration 228 / 300: loss 0.597849\n",
      "iteration 228 / 300: loss 0.598940\n",
      "iteration 228 / 300: loss 0.603876\n",
      "iteration 228 / 300: loss 0.615261\n",
      "iteration 228 / 300: loss 0.588227\n",
      "iteration 228 / 300: loss 0.627171\n",
      "iteration 228 / 300: loss 0.592600\n",
      "iteration 228 / 300: loss 0.621500\n",
      "iteration 228 / 300: loss 0.593093\n",
      "iteration 228 / 300: loss 0.600541\n",
      "iteration 228 / 300: loss 0.571000\n",
      "iteration 228 / 300: loss 0.592911\n",
      "iteration 228 / 300: loss 0.600043\n",
      "iteration 228 / 300: loss 0.598053\n",
      "iteration 228 / 300: loss 0.583712\n",
      "iteration 228 / 300: loss 0.614355\n",
      "iteration 228 / 300: loss 0.591285\n",
      "iteration 228 / 300: loss 0.591391\n",
      "iteration 228 / 300: loss 0.594005\n",
      "iteration 228 / 300: loss 0.596735\n",
      "iteration 228 / 300: loss 0.596712\n",
      "iteration 228 / 300: loss 0.611735\n",
      "iteration 228 / 300: loss 0.607258\n",
      "iteration 228 / 300: loss 0.597031\n",
      "iteration 228 / 300: loss 0.596301\n",
      "iteration 228 / 300: loss 0.627391\n",
      "iteration 228 / 300: loss 0.601584\n",
      "iteration 228 / 300: loss 0.599923\n",
      "iteration 228 / 300: loss 0.621952\n",
      "iteration 228 / 300: loss 0.581435\n",
      "iteration 228 / 300: loss 0.599604\n",
      "iteration 228 / 300: loss 0.591182\n",
      "iteration 228 / 300: loss 0.599919\n",
      "iteration 228 / 300: loss 0.596015\n",
      "iteration 228 / 300: loss 0.590760\n",
      "iteration 228 / 300: loss 0.591961\n",
      "iteration 228 / 300: loss 0.615468\n",
      "iteration 228 / 300: loss 0.621360\n",
      "iteration 228 / 300: loss 0.587267\n",
      "iteration 228 / 300: loss 0.582483\n",
      "iteration 228 / 300: loss 0.585572\n",
      "iteration 228 / 300: loss 0.603666\n",
      "iteration 228 / 300: loss 0.585192\n",
      "iteration 228 / 300: loss 0.578880\n",
      "iteration 228 / 300: loss 0.576418\n",
      "iteration 228 / 300: loss 0.574097\n",
      "iteration 228 / 300: loss 0.600500\n",
      "iteration 228 / 300: loss 0.584490\n",
      "iteration 228 / 300: loss 0.584834\n",
      "iteration 228 / 300: loss 0.568323\n",
      "iteration 228 / 300: loss 0.592025\n",
      "iteration 228 / 300: loss 0.612116\n",
      "iteration 228 / 300: loss 0.608923\n",
      "iteration 228 / 300: loss 0.607613\n",
      "iteration 228 / 300: loss 0.595533\n",
      "iteration 228 / 300: loss 0.592837\n",
      "iteration 228 / 300: loss 0.597988\n",
      "iteration 228 / 300: loss 0.597677\n",
      "iteration 228 / 300: loss 0.600953\n",
      "iteration 228 / 300: loss 0.597422\n",
      "iteration 228 / 300: loss 0.598776\n",
      "iteration 228 / 300: loss 0.587806\n",
      "iteration 228 / 300: loss 0.600499\n",
      "iteration 228 / 300: loss 0.599650\n",
      "iteration 228 / 300: loss 0.617540\n",
      "iteration 228 / 300: loss 0.598875\n",
      "iteration 228 / 300: loss 0.600801\n",
      "iteration 228 / 300: loss 0.605305\n",
      "iteration 228 / 300: loss 0.598592\n",
      "iteration 228 / 300: loss 0.591474\n",
      "iteration 228 / 300: loss 0.580382\n",
      "iteration 228 / 300: loss 0.598221\n",
      "iteration 228 / 300: loss 0.611685\n",
      "iteration 228 / 300: loss 0.613219\n",
      "iteration 228 / 300: loss 0.582214\n",
      "iteration 228 / 300: loss 0.601955\n",
      "iteration 228 / 300: loss 0.608956\n",
      "iteration 228 / 300: loss 0.601794\n",
      "iteration 228 / 300: loss 0.607944\n",
      "iteration 228 / 300: loss 0.620236\n",
      "iteration 228 / 300: loss 0.584817\n",
      "iteration 228 / 300: loss 0.583721\n",
      "iteration 228 / 300: loss 0.628849\n",
      "iteration 228 / 300: loss 0.609399\n",
      "iteration 228 / 300: loss 0.606265\n",
      "iteration 228 / 300: loss 0.599034\n",
      "iteration 228 / 300: loss 0.615876\n",
      "iteration 228 / 300: loss 0.596489\n",
      "iteration 228 / 300: loss 0.581430\n",
      "iteration 228 / 300: loss 0.609807\n",
      "iteration 228 / 300: loss 0.608125\n",
      "iteration 228 / 300: loss 0.598224\n",
      "iteration 228 / 300: loss 0.592022\n",
      "iteration 228 / 300: loss 0.611031\n",
      "iteration 228 / 300: loss 0.598550\n",
      "iteration 228 / 300: loss 0.581382\n",
      "iteration 228 / 300: loss 0.609580\n",
      "iteration 229 / 300: loss 0.578384\n",
      "iteration 229 / 300: loss 0.596214\n",
      "iteration 229 / 300: loss 0.569455\n",
      "iteration 229 / 300: loss 0.597849\n",
      "iteration 229 / 300: loss 0.598940\n",
      "iteration 229 / 300: loss 0.603876\n",
      "iteration 229 / 300: loss 0.615261\n",
      "iteration 229 / 300: loss 0.588227\n",
      "iteration 229 / 300: loss 0.627171\n",
      "iteration 229 / 300: loss 0.592600\n",
      "iteration 229 / 300: loss 0.621500\n",
      "iteration 229 / 300: loss 0.593093\n",
      "iteration 229 / 300: loss 0.600541\n",
      "iteration 229 / 300: loss 0.571000\n",
      "iteration 229 / 300: loss 0.592911\n",
      "iteration 229 / 300: loss 0.600043\n",
      "iteration 229 / 300: loss 0.598053\n",
      "iteration 229 / 300: loss 0.583712\n",
      "iteration 229 / 300: loss 0.614355\n",
      "iteration 229 / 300: loss 0.591285\n",
      "iteration 229 / 300: loss 0.591391\n",
      "iteration 229 / 300: loss 0.594005\n",
      "iteration 229 / 300: loss 0.596735\n",
      "iteration 229 / 300: loss 0.596712\n",
      "iteration 229 / 300: loss 0.611735\n",
      "iteration 229 / 300: loss 0.607258\n",
      "iteration 229 / 300: loss 0.597031\n",
      "iteration 229 / 300: loss 0.596301\n",
      "iteration 229 / 300: loss 0.627391\n",
      "iteration 229 / 300: loss 0.601584\n",
      "iteration 229 / 300: loss 0.599923\n",
      "iteration 229 / 300: loss 0.621952\n",
      "iteration 229 / 300: loss 0.581435\n",
      "iteration 229 / 300: loss 0.599604\n",
      "iteration 229 / 300: loss 0.591182\n",
      "iteration 229 / 300: loss 0.599919\n",
      "iteration 229 / 300: loss 0.596015\n",
      "iteration 229 / 300: loss 0.590760\n",
      "iteration 229 / 300: loss 0.591961\n",
      "iteration 229 / 300: loss 0.615468\n",
      "iteration 229 / 300: loss 0.621360\n",
      "iteration 229 / 300: loss 0.587267\n",
      "iteration 229 / 300: loss 0.582483\n",
      "iteration 229 / 300: loss 0.585572\n",
      "iteration 229 / 300: loss 0.603666\n",
      "iteration 229 / 300: loss 0.585192\n",
      "iteration 229 / 300: loss 0.578880\n",
      "iteration 229 / 300: loss 0.576418\n",
      "iteration 229 / 300: loss 0.574097\n",
      "iteration 229 / 300: loss 0.600500\n",
      "iteration 229 / 300: loss 0.584490\n",
      "iteration 229 / 300: loss 0.584834\n",
      "iteration 229 / 300: loss 0.568323\n",
      "iteration 229 / 300: loss 0.592025\n",
      "iteration 229 / 300: loss 0.612116\n",
      "iteration 229 / 300: loss 0.608923\n",
      "iteration 229 / 300: loss 0.607613\n",
      "iteration 229 / 300: loss 0.595533\n",
      "iteration 229 / 300: loss 0.592837\n",
      "iteration 229 / 300: loss 0.597988\n",
      "iteration 229 / 300: loss 0.597677\n",
      "iteration 229 / 300: loss 0.600953\n",
      "iteration 229 / 300: loss 0.597422\n",
      "iteration 229 / 300: loss 0.598776\n",
      "iteration 229 / 300: loss 0.587806\n",
      "iteration 229 / 300: loss 0.600499\n",
      "iteration 229 / 300: loss 0.599650\n",
      "iteration 229 / 300: loss 0.617540\n",
      "iteration 229 / 300: loss 0.598875\n",
      "iteration 229 / 300: loss 0.600801\n",
      "iteration 229 / 300: loss 0.605305\n",
      "iteration 229 / 300: loss 0.598592\n",
      "iteration 229 / 300: loss 0.591474\n",
      "iteration 229 / 300: loss 0.580382\n",
      "iteration 229 / 300: loss 0.598221\n",
      "iteration 229 / 300: loss 0.611685\n",
      "iteration 229 / 300: loss 0.613219\n",
      "iteration 229 / 300: loss 0.582214\n",
      "iteration 229 / 300: loss 0.601955\n",
      "iteration 229 / 300: loss 0.608956\n",
      "iteration 229 / 300: loss 0.601794\n",
      "iteration 229 / 300: loss 0.607944\n",
      "iteration 229 / 300: loss 0.620236\n",
      "iteration 229 / 300: loss 0.584817\n",
      "iteration 229 / 300: loss 0.583721\n",
      "iteration 229 / 300: loss 0.628849\n",
      "iteration 229 / 300: loss 0.609399\n",
      "iteration 229 / 300: loss 0.606265\n",
      "iteration 229 / 300: loss 0.599034\n",
      "iteration 229 / 300: loss 0.615876\n",
      "iteration 229 / 300: loss 0.596489\n",
      "iteration 229 / 300: loss 0.581430\n",
      "iteration 229 / 300: loss 0.609807\n",
      "iteration 229 / 300: loss 0.608125\n",
      "iteration 229 / 300: loss 0.598224\n",
      "iteration 229 / 300: loss 0.592022\n",
      "iteration 229 / 300: loss 0.611031\n",
      "iteration 229 / 300: loss 0.598550\n",
      "iteration 229 / 300: loss 0.581382\n",
      "iteration 229 / 300: loss 0.609580\n",
      "iteration 230 / 300: loss 0.578384\n",
      "iteration 230 / 300: loss 0.596214\n",
      "iteration 230 / 300: loss 0.569455\n",
      "iteration 230 / 300: loss 0.597849\n",
      "iteration 230 / 300: loss 0.598940\n",
      "iteration 230 / 300: loss 0.603876\n",
      "iteration 230 / 300: loss 0.615261\n",
      "iteration 230 / 300: loss 0.588227\n",
      "iteration 230 / 300: loss 0.627171\n",
      "iteration 230 / 300: loss 0.592600\n",
      "iteration 230 / 300: loss 0.621500\n",
      "iteration 230 / 300: loss 0.593093\n",
      "iteration 230 / 300: loss 0.600541\n",
      "iteration 230 / 300: loss 0.571000\n",
      "iteration 230 / 300: loss 0.592911\n",
      "iteration 230 / 300: loss 0.600043\n",
      "iteration 230 / 300: loss 0.598053\n",
      "iteration 230 / 300: loss 0.583712\n",
      "iteration 230 / 300: loss 0.614355\n",
      "iteration 230 / 300: loss 0.591285\n",
      "iteration 230 / 300: loss 0.591391\n",
      "iteration 230 / 300: loss 0.594005\n",
      "iteration 230 / 300: loss 0.596735\n",
      "iteration 230 / 300: loss 0.596712\n",
      "iteration 230 / 300: loss 0.611735\n",
      "iteration 230 / 300: loss 0.607258\n",
      "iteration 230 / 300: loss 0.597031\n",
      "iteration 230 / 300: loss 0.596301\n",
      "iteration 230 / 300: loss 0.627391\n",
      "iteration 230 / 300: loss 0.601584\n",
      "iteration 230 / 300: loss 0.599923\n",
      "iteration 230 / 300: loss 0.621952\n",
      "iteration 230 / 300: loss 0.581435\n",
      "iteration 230 / 300: loss 0.599604\n",
      "iteration 230 / 300: loss 0.591182\n",
      "iteration 230 / 300: loss 0.599919\n",
      "iteration 230 / 300: loss 0.596015\n",
      "iteration 230 / 300: loss 0.590760\n",
      "iteration 230 / 300: loss 0.591961\n",
      "iteration 230 / 300: loss 0.615468\n",
      "iteration 230 / 300: loss 0.621360\n",
      "iteration 230 / 300: loss 0.587267\n",
      "iteration 230 / 300: loss 0.582483\n",
      "iteration 230 / 300: loss 0.585572\n",
      "iteration 230 / 300: loss 0.603666\n",
      "iteration 230 / 300: loss 0.585192\n",
      "iteration 230 / 300: loss 0.578880\n",
      "iteration 230 / 300: loss 0.576418\n",
      "iteration 230 / 300: loss 0.574097\n",
      "iteration 230 / 300: loss 0.600500\n",
      "iteration 230 / 300: loss 0.584490\n",
      "iteration 230 / 300: loss 0.584834\n",
      "iteration 230 / 300: loss 0.568323\n",
      "iteration 230 / 300: loss 0.592025\n",
      "iteration 230 / 300: loss 0.612116\n",
      "iteration 230 / 300: loss 0.608923\n",
      "iteration 230 / 300: loss 0.607613\n",
      "iteration 230 / 300: loss 0.595533\n",
      "iteration 230 / 300: loss 0.592837\n",
      "iteration 230 / 300: loss 0.597988\n",
      "iteration 230 / 300: loss 0.597677\n",
      "iteration 230 / 300: loss 0.600953\n",
      "iteration 230 / 300: loss 0.597422\n",
      "iteration 230 / 300: loss 0.598776\n",
      "iteration 230 / 300: loss 0.587806\n",
      "iteration 230 / 300: loss 0.600499\n",
      "iteration 230 / 300: loss 0.599650\n",
      "iteration 230 / 300: loss 0.617540\n",
      "iteration 230 / 300: loss 0.598875\n",
      "iteration 230 / 300: loss 0.600801\n",
      "iteration 230 / 300: loss 0.605305\n",
      "iteration 230 / 300: loss 0.598592\n",
      "iteration 230 / 300: loss 0.591474\n",
      "iteration 230 / 300: loss 0.580382\n",
      "iteration 230 / 300: loss 0.598221\n",
      "iteration 230 / 300: loss 0.611685\n",
      "iteration 230 / 300: loss 0.613219\n",
      "iteration 230 / 300: loss 0.582214\n",
      "iteration 230 / 300: loss 0.601955\n",
      "iteration 230 / 300: loss 0.608956\n",
      "iteration 230 / 300: loss 0.601794\n",
      "iteration 230 / 300: loss 0.607944\n",
      "iteration 230 / 300: loss 0.620236\n",
      "iteration 230 / 300: loss 0.584817\n",
      "iteration 230 / 300: loss 0.583721\n",
      "iteration 230 / 300: loss 0.628849\n",
      "iteration 230 / 300: loss 0.609399\n",
      "iteration 230 / 300: loss 0.606265\n",
      "iteration 230 / 300: loss 0.599034\n",
      "iteration 230 / 300: loss 0.615876\n",
      "iteration 230 / 300: loss 0.596489\n",
      "iteration 230 / 300: loss 0.581430\n",
      "iteration 230 / 300: loss 0.609807\n",
      "iteration 230 / 300: loss 0.608125\n",
      "iteration 230 / 300: loss 0.598224\n",
      "iteration 230 / 300: loss 0.592022\n",
      "iteration 230 / 300: loss 0.611031\n",
      "iteration 230 / 300: loss 0.598550\n",
      "iteration 230 / 300: loss 0.581382\n",
      "iteration 230 / 300: loss 0.609580\n",
      "iteration 231 / 300: loss 0.578384\n",
      "iteration 231 / 300: loss 0.596214\n",
      "iteration 231 / 300: loss 0.569455\n",
      "iteration 231 / 300: loss 0.597849\n",
      "iteration 231 / 300: loss 0.598940\n",
      "iteration 231 / 300: loss 0.603876\n",
      "iteration 231 / 300: loss 0.615261\n",
      "iteration 231 / 300: loss 0.588227\n",
      "iteration 231 / 300: loss 0.627171\n",
      "iteration 231 / 300: loss 0.592600\n",
      "iteration 231 / 300: loss 0.621500\n",
      "iteration 231 / 300: loss 0.593093\n",
      "iteration 231 / 300: loss 0.600541\n",
      "iteration 231 / 300: loss 0.571000\n",
      "iteration 231 / 300: loss 0.592911\n",
      "iteration 231 / 300: loss 0.600043\n",
      "iteration 231 / 300: loss 0.598053\n",
      "iteration 231 / 300: loss 0.583712\n",
      "iteration 231 / 300: loss 0.614355\n",
      "iteration 231 / 300: loss 0.591285\n",
      "iteration 231 / 300: loss 0.591391\n",
      "iteration 231 / 300: loss 0.594005\n",
      "iteration 231 / 300: loss 0.596735\n",
      "iteration 231 / 300: loss 0.596712\n",
      "iteration 231 / 300: loss 0.611735\n",
      "iteration 231 / 300: loss 0.607258\n",
      "iteration 231 / 300: loss 0.597031\n",
      "iteration 231 / 300: loss 0.596301\n",
      "iteration 231 / 300: loss 0.627391\n",
      "iteration 231 / 300: loss 0.601584\n",
      "iteration 231 / 300: loss 0.599923\n",
      "iteration 231 / 300: loss 0.621952\n",
      "iteration 231 / 300: loss 0.581435\n",
      "iteration 231 / 300: loss 0.599604\n",
      "iteration 231 / 300: loss 0.591182\n",
      "iteration 231 / 300: loss 0.599919\n",
      "iteration 231 / 300: loss 0.596015\n",
      "iteration 231 / 300: loss 0.590760\n",
      "iteration 231 / 300: loss 0.591961\n",
      "iteration 231 / 300: loss 0.615468\n",
      "iteration 231 / 300: loss 0.621360\n",
      "iteration 231 / 300: loss 0.587267\n",
      "iteration 231 / 300: loss 0.582483\n",
      "iteration 231 / 300: loss 0.585572\n",
      "iteration 231 / 300: loss 0.603666\n",
      "iteration 231 / 300: loss 0.585192\n",
      "iteration 231 / 300: loss 0.578880\n",
      "iteration 231 / 300: loss 0.576418\n",
      "iteration 231 / 300: loss 0.574097\n",
      "iteration 231 / 300: loss 0.600500\n",
      "iteration 231 / 300: loss 0.584490\n",
      "iteration 231 / 300: loss 0.584834\n",
      "iteration 231 / 300: loss 0.568323\n",
      "iteration 231 / 300: loss 0.592025\n",
      "iteration 231 / 300: loss 0.612116\n",
      "iteration 231 / 300: loss 0.608923\n",
      "iteration 231 / 300: loss 0.607613\n",
      "iteration 231 / 300: loss 0.595533\n",
      "iteration 231 / 300: loss 0.592837\n",
      "iteration 231 / 300: loss 0.597988\n",
      "iteration 231 / 300: loss 0.597677\n",
      "iteration 231 / 300: loss 0.600953\n",
      "iteration 231 / 300: loss 0.597422\n",
      "iteration 231 / 300: loss 0.598776\n",
      "iteration 231 / 300: loss 0.587806\n",
      "iteration 231 / 300: loss 0.600499\n",
      "iteration 231 / 300: loss 0.599650\n",
      "iteration 231 / 300: loss 0.617540\n",
      "iteration 231 / 300: loss 0.598875\n",
      "iteration 231 / 300: loss 0.600801\n",
      "iteration 231 / 300: loss 0.605305\n",
      "iteration 231 / 300: loss 0.598592\n",
      "iteration 231 / 300: loss 0.591474\n",
      "iteration 231 / 300: loss 0.580382\n",
      "iteration 231 / 300: loss 0.598221\n",
      "iteration 231 / 300: loss 0.611685\n",
      "iteration 231 / 300: loss 0.613219\n",
      "iteration 231 / 300: loss 0.582214\n",
      "iteration 231 / 300: loss 0.601955\n",
      "iteration 231 / 300: loss 0.608956\n",
      "iteration 231 / 300: loss 0.601794\n",
      "iteration 231 / 300: loss 0.607944\n",
      "iteration 231 / 300: loss 0.620236\n",
      "iteration 231 / 300: loss 0.584817\n",
      "iteration 231 / 300: loss 0.583721\n",
      "iteration 231 / 300: loss 0.628849\n",
      "iteration 231 / 300: loss 0.609399\n",
      "iteration 231 / 300: loss 0.606265\n",
      "iteration 231 / 300: loss 0.599034\n",
      "iteration 231 / 300: loss 0.615876\n",
      "iteration 231 / 300: loss 0.596489\n",
      "iteration 231 / 300: loss 0.581430\n",
      "iteration 231 / 300: loss 0.609807\n",
      "iteration 231 / 300: loss 0.608125\n",
      "iteration 231 / 300: loss 0.598224\n",
      "iteration 231 / 300: loss 0.592022\n",
      "iteration 231 / 300: loss 0.611031\n",
      "iteration 231 / 300: loss 0.598550\n",
      "iteration 231 / 300: loss 0.581382\n",
      "iteration 231 / 300: loss 0.609580\n",
      "iteration 232 / 300: loss 0.578384\n",
      "iteration 232 / 300: loss 0.596214\n",
      "iteration 232 / 300: loss 0.569455\n",
      "iteration 232 / 300: loss 0.597849\n",
      "iteration 232 / 300: loss 0.598940\n",
      "iteration 232 / 300: loss 0.603876\n",
      "iteration 232 / 300: loss 0.615261\n",
      "iteration 232 / 300: loss 0.588227\n",
      "iteration 232 / 300: loss 0.627171\n",
      "iteration 232 / 300: loss 0.592600\n",
      "iteration 232 / 300: loss 0.621500\n",
      "iteration 232 / 300: loss 0.593093\n",
      "iteration 232 / 300: loss 0.600541\n",
      "iteration 232 / 300: loss 0.571000\n",
      "iteration 232 / 300: loss 0.592911\n",
      "iteration 232 / 300: loss 0.600043\n",
      "iteration 232 / 300: loss 0.598053\n",
      "iteration 232 / 300: loss 0.583712\n",
      "iteration 232 / 300: loss 0.614355\n",
      "iteration 232 / 300: loss 0.591285\n",
      "iteration 232 / 300: loss 0.591391\n",
      "iteration 232 / 300: loss 0.594005\n",
      "iteration 232 / 300: loss 0.596735\n",
      "iteration 232 / 300: loss 0.596712\n",
      "iteration 232 / 300: loss 0.611735\n",
      "iteration 232 / 300: loss 0.607258\n",
      "iteration 232 / 300: loss 0.597031\n",
      "iteration 232 / 300: loss 0.596301\n",
      "iteration 232 / 300: loss 0.627391\n",
      "iteration 232 / 300: loss 0.601584\n",
      "iteration 232 / 300: loss 0.599923\n",
      "iteration 232 / 300: loss 0.621952\n",
      "iteration 232 / 300: loss 0.581435\n",
      "iteration 232 / 300: loss 0.599604\n",
      "iteration 232 / 300: loss 0.591182\n",
      "iteration 232 / 300: loss 0.599919\n",
      "iteration 232 / 300: loss 0.596015\n",
      "iteration 232 / 300: loss 0.590760\n",
      "iteration 232 / 300: loss 0.591961\n",
      "iteration 232 / 300: loss 0.615468\n",
      "iteration 232 / 300: loss 0.621360\n",
      "iteration 232 / 300: loss 0.587267\n",
      "iteration 232 / 300: loss 0.582483\n",
      "iteration 232 / 300: loss 0.585572\n",
      "iteration 232 / 300: loss 0.603666\n",
      "iteration 232 / 300: loss 0.585192\n",
      "iteration 232 / 300: loss 0.578880\n",
      "iteration 232 / 300: loss 0.576418\n",
      "iteration 232 / 300: loss 0.574097\n",
      "iteration 232 / 300: loss 0.600500\n",
      "iteration 232 / 300: loss 0.584490\n",
      "iteration 232 / 300: loss 0.584834\n",
      "iteration 232 / 300: loss 0.568323\n",
      "iteration 232 / 300: loss 0.592025\n",
      "iteration 232 / 300: loss 0.612116\n",
      "iteration 232 / 300: loss 0.608923\n",
      "iteration 232 / 300: loss 0.607613\n",
      "iteration 232 / 300: loss 0.595533\n",
      "iteration 232 / 300: loss 0.592837\n",
      "iteration 232 / 300: loss 0.597988\n",
      "iteration 232 / 300: loss 0.597677\n",
      "iteration 232 / 300: loss 0.600953\n",
      "iteration 232 / 300: loss 0.597422\n",
      "iteration 232 / 300: loss 0.598776\n",
      "iteration 232 / 300: loss 0.587806\n",
      "iteration 232 / 300: loss 0.600499\n",
      "iteration 232 / 300: loss 0.599650\n",
      "iteration 232 / 300: loss 0.617540\n",
      "iteration 232 / 300: loss 0.598875\n",
      "iteration 232 / 300: loss 0.600801\n",
      "iteration 232 / 300: loss 0.605305\n",
      "iteration 232 / 300: loss 0.598592\n",
      "iteration 232 / 300: loss 0.591474\n",
      "iteration 232 / 300: loss 0.580382\n",
      "iteration 232 / 300: loss 0.598221\n",
      "iteration 232 / 300: loss 0.611685\n",
      "iteration 232 / 300: loss 0.613219\n",
      "iteration 232 / 300: loss 0.582214\n",
      "iteration 232 / 300: loss 0.601955\n",
      "iteration 232 / 300: loss 0.608956\n",
      "iteration 232 / 300: loss 0.601794\n",
      "iteration 232 / 300: loss 0.607944\n",
      "iteration 232 / 300: loss 0.620236\n",
      "iteration 232 / 300: loss 0.584817\n",
      "iteration 232 / 300: loss 0.583721\n",
      "iteration 232 / 300: loss 0.628849\n",
      "iteration 232 / 300: loss 0.609399\n",
      "iteration 232 / 300: loss 0.606265\n",
      "iteration 232 / 300: loss 0.599034\n",
      "iteration 232 / 300: loss 0.615876\n",
      "iteration 232 / 300: loss 0.596489\n",
      "iteration 232 / 300: loss 0.581430\n",
      "iteration 232 / 300: loss 0.609807\n",
      "iteration 232 / 300: loss 0.608125\n",
      "iteration 232 / 300: loss 0.598224\n",
      "iteration 232 / 300: loss 0.592022\n",
      "iteration 232 / 300: loss 0.611031\n",
      "iteration 232 / 300: loss 0.598550\n",
      "iteration 232 / 300: loss 0.581382\n",
      "iteration 232 / 300: loss 0.609580\n",
      "iteration 233 / 300: loss 0.578384\n",
      "iteration 233 / 300: loss 0.596214\n",
      "iteration 233 / 300: loss 0.569455\n",
      "iteration 233 / 300: loss 0.597849\n",
      "iteration 233 / 300: loss 0.598940\n",
      "iteration 233 / 300: loss 0.603876\n",
      "iteration 233 / 300: loss 0.615261\n",
      "iteration 233 / 300: loss 0.588227\n",
      "iteration 233 / 300: loss 0.627171\n",
      "iteration 233 / 300: loss 0.592600\n",
      "iteration 233 / 300: loss 0.621500\n",
      "iteration 233 / 300: loss 0.593093\n",
      "iteration 233 / 300: loss 0.600541\n",
      "iteration 233 / 300: loss 0.571000\n",
      "iteration 233 / 300: loss 0.592911\n",
      "iteration 233 / 300: loss 0.600043\n",
      "iteration 233 / 300: loss 0.598053\n",
      "iteration 233 / 300: loss 0.583712\n",
      "iteration 233 / 300: loss 0.614355\n",
      "iteration 233 / 300: loss 0.591285\n",
      "iteration 233 / 300: loss 0.591391\n",
      "iteration 233 / 300: loss 0.594005\n",
      "iteration 233 / 300: loss 0.596735\n",
      "iteration 233 / 300: loss 0.596712\n",
      "iteration 233 / 300: loss 0.611735\n",
      "iteration 233 / 300: loss 0.607258\n",
      "iteration 233 / 300: loss 0.597031\n",
      "iteration 233 / 300: loss 0.596301\n",
      "iteration 233 / 300: loss 0.627391\n",
      "iteration 233 / 300: loss 0.601584\n",
      "iteration 233 / 300: loss 0.599923\n",
      "iteration 233 / 300: loss 0.621952\n",
      "iteration 233 / 300: loss 0.581435\n",
      "iteration 233 / 300: loss 0.599604\n",
      "iteration 233 / 300: loss 0.591182\n",
      "iteration 233 / 300: loss 0.599919\n",
      "iteration 233 / 300: loss 0.596015\n",
      "iteration 233 / 300: loss 0.590760\n",
      "iteration 233 / 300: loss 0.591961\n",
      "iteration 233 / 300: loss 0.615468\n",
      "iteration 233 / 300: loss 0.621360\n",
      "iteration 233 / 300: loss 0.587267\n",
      "iteration 233 / 300: loss 0.582483\n",
      "iteration 233 / 300: loss 0.585572\n",
      "iteration 233 / 300: loss 0.603666\n",
      "iteration 233 / 300: loss 0.585192\n",
      "iteration 233 / 300: loss 0.578880\n",
      "iteration 233 / 300: loss 0.576418\n",
      "iteration 233 / 300: loss 0.574097\n",
      "iteration 233 / 300: loss 0.600500\n",
      "iteration 233 / 300: loss 0.584490\n",
      "iteration 233 / 300: loss 0.584834\n",
      "iteration 233 / 300: loss 0.568323\n",
      "iteration 233 / 300: loss 0.592025\n",
      "iteration 233 / 300: loss 0.612116\n",
      "iteration 233 / 300: loss 0.608923\n",
      "iteration 233 / 300: loss 0.607613\n",
      "iteration 233 / 300: loss 0.595533\n",
      "iteration 233 / 300: loss 0.592837\n",
      "iteration 233 / 300: loss 0.597988\n",
      "iteration 233 / 300: loss 0.597677\n",
      "iteration 233 / 300: loss 0.600953\n",
      "iteration 233 / 300: loss 0.597422\n",
      "iteration 233 / 300: loss 0.598776\n",
      "iteration 233 / 300: loss 0.587806\n",
      "iteration 233 / 300: loss 0.600499\n",
      "iteration 233 / 300: loss 0.599650\n",
      "iteration 233 / 300: loss 0.617540\n",
      "iteration 233 / 300: loss 0.598875\n",
      "iteration 233 / 300: loss 0.600801\n",
      "iteration 233 / 300: loss 0.605305\n",
      "iteration 233 / 300: loss 0.598592\n",
      "iteration 233 / 300: loss 0.591474\n",
      "iteration 233 / 300: loss 0.580382\n",
      "iteration 233 / 300: loss 0.598221\n",
      "iteration 233 / 300: loss 0.611685\n",
      "iteration 233 / 300: loss 0.613219\n",
      "iteration 233 / 300: loss 0.582214\n",
      "iteration 233 / 300: loss 0.601955\n",
      "iteration 233 / 300: loss 0.608956\n",
      "iteration 233 / 300: loss 0.601794\n",
      "iteration 233 / 300: loss 0.607944\n",
      "iteration 233 / 300: loss 0.620236\n",
      "iteration 233 / 300: loss 0.584817\n",
      "iteration 233 / 300: loss 0.583721\n",
      "iteration 233 / 300: loss 0.628849\n",
      "iteration 233 / 300: loss 0.609399\n",
      "iteration 233 / 300: loss 0.606265\n",
      "iteration 233 / 300: loss 0.599034\n",
      "iteration 233 / 300: loss 0.615876\n",
      "iteration 233 / 300: loss 0.596489\n",
      "iteration 233 / 300: loss 0.581430\n",
      "iteration 233 / 300: loss 0.609807\n",
      "iteration 233 / 300: loss 0.608125\n",
      "iteration 233 / 300: loss 0.598224\n",
      "iteration 233 / 300: loss 0.592022\n",
      "iteration 233 / 300: loss 0.611031\n",
      "iteration 233 / 300: loss 0.598550\n",
      "iteration 233 / 300: loss 0.581382\n",
      "iteration 233 / 300: loss 0.609580\n",
      "iteration 234 / 300: loss 0.578384\n",
      "iteration 234 / 300: loss 0.596214\n",
      "iteration 234 / 300: loss 0.569455\n",
      "iteration 234 / 300: loss 0.597849\n",
      "iteration 234 / 300: loss 0.598940\n",
      "iteration 234 / 300: loss 0.603876\n",
      "iteration 234 / 300: loss 0.615261\n",
      "iteration 234 / 300: loss 0.588227\n",
      "iteration 234 / 300: loss 0.627171\n",
      "iteration 234 / 300: loss 0.592600\n",
      "iteration 234 / 300: loss 0.621500\n",
      "iteration 234 / 300: loss 0.593093\n",
      "iteration 234 / 300: loss 0.600541\n",
      "iteration 234 / 300: loss 0.571000\n",
      "iteration 234 / 300: loss 0.592911\n",
      "iteration 234 / 300: loss 0.600043\n",
      "iteration 234 / 300: loss 0.598053\n",
      "iteration 234 / 300: loss 0.583712\n",
      "iteration 234 / 300: loss 0.614355\n",
      "iteration 234 / 300: loss 0.591285\n",
      "iteration 234 / 300: loss 0.591391\n",
      "iteration 234 / 300: loss 0.594005\n",
      "iteration 234 / 300: loss 0.596735\n",
      "iteration 234 / 300: loss 0.596712\n",
      "iteration 234 / 300: loss 0.611735\n",
      "iteration 234 / 300: loss 0.607258\n",
      "iteration 234 / 300: loss 0.597031\n",
      "iteration 234 / 300: loss 0.596301\n",
      "iteration 234 / 300: loss 0.627391\n",
      "iteration 234 / 300: loss 0.601584\n",
      "iteration 234 / 300: loss 0.599923\n",
      "iteration 234 / 300: loss 0.621952\n",
      "iteration 234 / 300: loss 0.581435\n",
      "iteration 234 / 300: loss 0.599604\n",
      "iteration 234 / 300: loss 0.591182\n",
      "iteration 234 / 300: loss 0.599919\n",
      "iteration 234 / 300: loss 0.596015\n",
      "iteration 234 / 300: loss 0.590760\n",
      "iteration 234 / 300: loss 0.591961\n",
      "iteration 234 / 300: loss 0.615468\n",
      "iteration 234 / 300: loss 0.621360\n",
      "iteration 234 / 300: loss 0.587267\n",
      "iteration 234 / 300: loss 0.582483\n",
      "iteration 234 / 300: loss 0.585572\n",
      "iteration 234 / 300: loss 0.603666\n",
      "iteration 234 / 300: loss 0.585192\n",
      "iteration 234 / 300: loss 0.578880\n",
      "iteration 234 / 300: loss 0.576418\n",
      "iteration 234 / 300: loss 0.574097\n",
      "iteration 234 / 300: loss 0.600500\n",
      "iteration 234 / 300: loss 0.584490\n",
      "iteration 234 / 300: loss 0.584834\n",
      "iteration 234 / 300: loss 0.568323\n",
      "iteration 234 / 300: loss 0.592025\n",
      "iteration 234 / 300: loss 0.612116\n",
      "iteration 234 / 300: loss 0.608923\n",
      "iteration 234 / 300: loss 0.607613\n",
      "iteration 234 / 300: loss 0.595533\n",
      "iteration 234 / 300: loss 0.592837\n",
      "iteration 234 / 300: loss 0.597988\n",
      "iteration 234 / 300: loss 0.597677\n",
      "iteration 234 / 300: loss 0.600953\n",
      "iteration 234 / 300: loss 0.597422\n",
      "iteration 234 / 300: loss 0.598776\n",
      "iteration 234 / 300: loss 0.587806\n",
      "iteration 234 / 300: loss 0.600499\n",
      "iteration 234 / 300: loss 0.599650\n",
      "iteration 234 / 300: loss 0.617540\n",
      "iteration 234 / 300: loss 0.598875\n",
      "iteration 234 / 300: loss 0.600801\n",
      "iteration 234 / 300: loss 0.605305\n",
      "iteration 234 / 300: loss 0.598592\n",
      "iteration 234 / 300: loss 0.591474\n",
      "iteration 234 / 300: loss 0.580382\n",
      "iteration 234 / 300: loss 0.598221\n",
      "iteration 234 / 300: loss 0.611685\n",
      "iteration 234 / 300: loss 0.613219\n",
      "iteration 234 / 300: loss 0.582214\n",
      "iteration 234 / 300: loss 0.601955\n",
      "iteration 234 / 300: loss 0.608956\n",
      "iteration 234 / 300: loss 0.601794\n",
      "iteration 234 / 300: loss 0.607944\n",
      "iteration 234 / 300: loss 0.620236\n",
      "iteration 234 / 300: loss 0.584817\n",
      "iteration 234 / 300: loss 0.583721\n",
      "iteration 234 / 300: loss 0.628849\n",
      "iteration 234 / 300: loss 0.609399\n",
      "iteration 234 / 300: loss 0.606265\n",
      "iteration 234 / 300: loss 0.599034\n",
      "iteration 234 / 300: loss 0.615876\n",
      "iteration 234 / 300: loss 0.596489\n",
      "iteration 234 / 300: loss 0.581430\n",
      "iteration 234 / 300: loss 0.609807\n",
      "iteration 234 / 300: loss 0.608125\n",
      "iteration 234 / 300: loss 0.598224\n",
      "iteration 234 / 300: loss 0.592022\n",
      "iteration 234 / 300: loss 0.611031\n",
      "iteration 234 / 300: loss 0.598550\n",
      "iteration 234 / 300: loss 0.581382\n",
      "iteration 234 / 300: loss 0.609580\n",
      "iteration 235 / 300: loss 0.578384\n",
      "iteration 235 / 300: loss 0.596214\n",
      "iteration 235 / 300: loss 0.569455\n",
      "iteration 235 / 300: loss 0.597849\n",
      "iteration 235 / 300: loss 0.598940\n",
      "iteration 235 / 300: loss 0.603876\n",
      "iteration 235 / 300: loss 0.615261\n",
      "iteration 235 / 300: loss 0.588227\n",
      "iteration 235 / 300: loss 0.627171\n",
      "iteration 235 / 300: loss 0.592600\n",
      "iteration 235 / 300: loss 0.621500\n",
      "iteration 235 / 300: loss 0.593093\n",
      "iteration 235 / 300: loss 0.600541\n",
      "iteration 235 / 300: loss 0.571000\n",
      "iteration 235 / 300: loss 0.592911\n",
      "iteration 235 / 300: loss 0.600043\n",
      "iteration 235 / 300: loss 0.598053\n",
      "iteration 235 / 300: loss 0.583712\n",
      "iteration 235 / 300: loss 0.614355\n",
      "iteration 235 / 300: loss 0.591285\n",
      "iteration 235 / 300: loss 0.591391\n",
      "iteration 235 / 300: loss 0.594005\n",
      "iteration 235 / 300: loss 0.596735\n",
      "iteration 235 / 300: loss 0.596712\n",
      "iteration 235 / 300: loss 0.611735\n",
      "iteration 235 / 300: loss 0.607258\n",
      "iteration 235 / 300: loss 0.597031\n",
      "iteration 235 / 300: loss 0.596301\n",
      "iteration 235 / 300: loss 0.627391\n",
      "iteration 235 / 300: loss 0.601584\n",
      "iteration 235 / 300: loss 0.599923\n",
      "iteration 235 / 300: loss 0.621952\n",
      "iteration 235 / 300: loss 0.581435\n",
      "iteration 235 / 300: loss 0.599604\n",
      "iteration 235 / 300: loss 0.591182\n",
      "iteration 235 / 300: loss 0.599919\n",
      "iteration 235 / 300: loss 0.596015\n",
      "iteration 235 / 300: loss 0.590760\n",
      "iteration 235 / 300: loss 0.591961\n",
      "iteration 235 / 300: loss 0.615468\n",
      "iteration 235 / 300: loss 0.621360\n",
      "iteration 235 / 300: loss 0.587267\n",
      "iteration 235 / 300: loss 0.582483\n",
      "iteration 235 / 300: loss 0.585572\n",
      "iteration 235 / 300: loss 0.603666\n",
      "iteration 235 / 300: loss 0.585192\n",
      "iteration 235 / 300: loss 0.578880\n",
      "iteration 235 / 300: loss 0.576418\n",
      "iteration 235 / 300: loss 0.574097\n",
      "iteration 235 / 300: loss 0.600500\n",
      "iteration 235 / 300: loss 0.584490\n",
      "iteration 235 / 300: loss 0.584834\n",
      "iteration 235 / 300: loss 0.568323\n",
      "iteration 235 / 300: loss 0.592025\n",
      "iteration 235 / 300: loss 0.612116\n",
      "iteration 235 / 300: loss 0.608923\n",
      "iteration 235 / 300: loss 0.607613\n",
      "iteration 235 / 300: loss 0.595533\n",
      "iteration 235 / 300: loss 0.592837\n",
      "iteration 235 / 300: loss 0.597988\n",
      "iteration 235 / 300: loss 0.597677\n",
      "iteration 235 / 300: loss 0.600953\n",
      "iteration 235 / 300: loss 0.597422\n",
      "iteration 235 / 300: loss 0.598776\n",
      "iteration 235 / 300: loss 0.587806\n",
      "iteration 235 / 300: loss 0.600499\n",
      "iteration 235 / 300: loss 0.599650\n",
      "iteration 235 / 300: loss 0.617540\n",
      "iteration 235 / 300: loss 0.598875\n",
      "iteration 235 / 300: loss 0.600801\n",
      "iteration 235 / 300: loss 0.605305\n",
      "iteration 235 / 300: loss 0.598592\n",
      "iteration 235 / 300: loss 0.591474\n",
      "iteration 235 / 300: loss 0.580382\n",
      "iteration 235 / 300: loss 0.598221\n",
      "iteration 235 / 300: loss 0.611685\n",
      "iteration 235 / 300: loss 0.613219\n",
      "iteration 235 / 300: loss 0.582214\n",
      "iteration 235 / 300: loss 0.601955\n",
      "iteration 235 / 300: loss 0.608956\n",
      "iteration 235 / 300: loss 0.601794\n",
      "iteration 235 / 300: loss 0.607944\n",
      "iteration 235 / 300: loss 0.620236\n",
      "iteration 235 / 300: loss 0.584817\n",
      "iteration 235 / 300: loss 0.583721\n",
      "iteration 235 / 300: loss 0.628849\n",
      "iteration 235 / 300: loss 0.609399\n",
      "iteration 235 / 300: loss 0.606265\n",
      "iteration 235 / 300: loss 0.599034\n",
      "iteration 235 / 300: loss 0.615876\n",
      "iteration 235 / 300: loss 0.596489\n",
      "iteration 235 / 300: loss 0.581430\n",
      "iteration 235 / 300: loss 0.609807\n",
      "iteration 235 / 300: loss 0.608125\n",
      "iteration 235 / 300: loss 0.598224\n",
      "iteration 235 / 300: loss 0.592022\n",
      "iteration 235 / 300: loss 0.611031\n",
      "iteration 235 / 300: loss 0.598550\n",
      "iteration 235 / 300: loss 0.581382\n",
      "iteration 235 / 300: loss 0.609580\n",
      "iteration 236 / 300: loss 0.578384\n",
      "iteration 236 / 300: loss 0.596214\n",
      "iteration 236 / 300: loss 0.569455\n",
      "iteration 236 / 300: loss 0.597849\n",
      "iteration 236 / 300: loss 0.598940\n",
      "iteration 236 / 300: loss 0.603876\n",
      "iteration 236 / 300: loss 0.615261\n",
      "iteration 236 / 300: loss 0.588227\n",
      "iteration 236 / 300: loss 0.627171\n",
      "iteration 236 / 300: loss 0.592600\n",
      "iteration 236 / 300: loss 0.621500\n",
      "iteration 236 / 300: loss 0.593093\n",
      "iteration 236 / 300: loss 0.600541\n",
      "iteration 236 / 300: loss 0.571000\n",
      "iteration 236 / 300: loss 0.592911\n",
      "iteration 236 / 300: loss 0.600043\n",
      "iteration 236 / 300: loss 0.598053\n",
      "iteration 236 / 300: loss 0.583712\n",
      "iteration 236 / 300: loss 0.614355\n",
      "iteration 236 / 300: loss 0.591285\n",
      "iteration 236 / 300: loss 0.591391\n",
      "iteration 236 / 300: loss 0.594005\n",
      "iteration 236 / 300: loss 0.596735\n",
      "iteration 236 / 300: loss 0.596712\n",
      "iteration 236 / 300: loss 0.611735\n",
      "iteration 236 / 300: loss 0.607258\n",
      "iteration 236 / 300: loss 0.597031\n",
      "iteration 236 / 300: loss 0.596301\n",
      "iteration 236 / 300: loss 0.627391\n",
      "iteration 236 / 300: loss 0.601584\n",
      "iteration 236 / 300: loss 0.599923\n",
      "iteration 236 / 300: loss 0.621952\n",
      "iteration 236 / 300: loss 0.581435\n",
      "iteration 236 / 300: loss 0.599604\n",
      "iteration 236 / 300: loss 0.591182\n",
      "iteration 236 / 300: loss 0.599919\n",
      "iteration 236 / 300: loss 0.596015\n",
      "iteration 236 / 300: loss 0.590760\n",
      "iteration 236 / 300: loss 0.591961\n",
      "iteration 236 / 300: loss 0.615468\n",
      "iteration 236 / 300: loss 0.621360\n",
      "iteration 236 / 300: loss 0.587267\n",
      "iteration 236 / 300: loss 0.582483\n",
      "iteration 236 / 300: loss 0.585572\n",
      "iteration 236 / 300: loss 0.603666\n",
      "iteration 236 / 300: loss 0.585192\n",
      "iteration 236 / 300: loss 0.578880\n",
      "iteration 236 / 300: loss 0.576418\n",
      "iteration 236 / 300: loss 0.574097\n",
      "iteration 236 / 300: loss 0.600500\n",
      "iteration 236 / 300: loss 0.584490\n",
      "iteration 236 / 300: loss 0.584834\n",
      "iteration 236 / 300: loss 0.568323\n",
      "iteration 236 / 300: loss 0.592025\n",
      "iteration 236 / 300: loss 0.612116\n",
      "iteration 236 / 300: loss 0.608923\n",
      "iteration 236 / 300: loss 0.607613\n",
      "iteration 236 / 300: loss 0.595533\n",
      "iteration 236 / 300: loss 0.592837\n",
      "iteration 236 / 300: loss 0.597988\n",
      "iteration 236 / 300: loss 0.597677\n",
      "iteration 236 / 300: loss 0.600953\n",
      "iteration 236 / 300: loss 0.597422\n",
      "iteration 236 / 300: loss 0.598776\n",
      "iteration 236 / 300: loss 0.587806\n",
      "iteration 236 / 300: loss 0.600499\n",
      "iteration 236 / 300: loss 0.599650\n",
      "iteration 236 / 300: loss 0.617540\n",
      "iteration 236 / 300: loss 0.598875\n",
      "iteration 236 / 300: loss 0.600801\n",
      "iteration 236 / 300: loss 0.605305\n",
      "iteration 236 / 300: loss 0.598592\n",
      "iteration 236 / 300: loss 0.591474\n",
      "iteration 236 / 300: loss 0.580382\n",
      "iteration 236 / 300: loss 0.598221\n",
      "iteration 236 / 300: loss 0.611685\n",
      "iteration 236 / 300: loss 0.613219\n",
      "iteration 236 / 300: loss 0.582214\n",
      "iteration 236 / 300: loss 0.601955\n",
      "iteration 236 / 300: loss 0.608956\n",
      "iteration 236 / 300: loss 0.601794\n",
      "iteration 236 / 300: loss 0.607944\n",
      "iteration 236 / 300: loss 0.620236\n",
      "iteration 236 / 300: loss 0.584817\n",
      "iteration 236 / 300: loss 0.583721\n",
      "iteration 236 / 300: loss 0.628849\n",
      "iteration 236 / 300: loss 0.609399\n",
      "iteration 236 / 300: loss 0.606265\n",
      "iteration 236 / 300: loss 0.599034\n",
      "iteration 236 / 300: loss 0.615876\n",
      "iteration 236 / 300: loss 0.596489\n",
      "iteration 236 / 300: loss 0.581430\n",
      "iteration 236 / 300: loss 0.609807\n",
      "iteration 236 / 300: loss 0.608125\n",
      "iteration 236 / 300: loss 0.598224\n",
      "iteration 236 / 300: loss 0.592022\n",
      "iteration 236 / 300: loss 0.611031\n",
      "iteration 236 / 300: loss 0.598550\n",
      "iteration 236 / 300: loss 0.581382\n",
      "iteration 236 / 300: loss 0.609580\n",
      "iteration 237 / 300: loss 0.578384\n",
      "iteration 237 / 300: loss 0.596214\n",
      "iteration 237 / 300: loss 0.569455\n",
      "iteration 237 / 300: loss 0.597849\n",
      "iteration 237 / 300: loss 0.598940\n",
      "iteration 237 / 300: loss 0.603876\n",
      "iteration 237 / 300: loss 0.615261\n",
      "iteration 237 / 300: loss 0.588227\n",
      "iteration 237 / 300: loss 0.627171\n",
      "iteration 237 / 300: loss 0.592600\n",
      "iteration 237 / 300: loss 0.621500\n",
      "iteration 237 / 300: loss 0.593093\n",
      "iteration 237 / 300: loss 0.600541\n",
      "iteration 237 / 300: loss 0.571000\n",
      "iteration 237 / 300: loss 0.592911\n",
      "iteration 237 / 300: loss 0.600043\n",
      "iteration 237 / 300: loss 0.598053\n",
      "iteration 237 / 300: loss 0.583712\n",
      "iteration 237 / 300: loss 0.614355\n",
      "iteration 237 / 300: loss 0.591285\n",
      "iteration 237 / 300: loss 0.591391\n",
      "iteration 237 / 300: loss 0.594005\n",
      "iteration 237 / 300: loss 0.596735\n",
      "iteration 237 / 300: loss 0.596712\n",
      "iteration 237 / 300: loss 0.611735\n",
      "iteration 237 / 300: loss 0.607258\n",
      "iteration 237 / 300: loss 0.597031\n",
      "iteration 237 / 300: loss 0.596301\n",
      "iteration 237 / 300: loss 0.627391\n",
      "iteration 237 / 300: loss 0.601584\n",
      "iteration 237 / 300: loss 0.599923\n",
      "iteration 237 / 300: loss 0.621952\n",
      "iteration 237 / 300: loss 0.581435\n",
      "iteration 237 / 300: loss 0.599604\n",
      "iteration 237 / 300: loss 0.591182\n",
      "iteration 237 / 300: loss 0.599919\n",
      "iteration 237 / 300: loss 0.596015\n",
      "iteration 237 / 300: loss 0.590760\n",
      "iteration 237 / 300: loss 0.591961\n",
      "iteration 237 / 300: loss 0.615468\n",
      "iteration 237 / 300: loss 0.621360\n",
      "iteration 237 / 300: loss 0.587267\n",
      "iteration 237 / 300: loss 0.582483\n",
      "iteration 237 / 300: loss 0.585572\n",
      "iteration 237 / 300: loss 0.603666\n",
      "iteration 237 / 300: loss 0.585192\n",
      "iteration 237 / 300: loss 0.578880\n",
      "iteration 237 / 300: loss 0.576418\n",
      "iteration 237 / 300: loss 0.574097\n",
      "iteration 237 / 300: loss 0.600500\n",
      "iteration 237 / 300: loss 0.584490\n",
      "iteration 237 / 300: loss 0.584834\n",
      "iteration 237 / 300: loss 0.568323\n",
      "iteration 237 / 300: loss 0.592025\n",
      "iteration 237 / 300: loss 0.612116\n",
      "iteration 237 / 300: loss 0.608923\n",
      "iteration 237 / 300: loss 0.607613\n",
      "iteration 237 / 300: loss 0.595533\n",
      "iteration 237 / 300: loss 0.592837\n",
      "iteration 237 / 300: loss 0.597988\n",
      "iteration 237 / 300: loss 0.597677\n",
      "iteration 237 / 300: loss 0.600953\n",
      "iteration 237 / 300: loss 0.597422\n",
      "iteration 237 / 300: loss 0.598776\n",
      "iteration 237 / 300: loss 0.587806\n",
      "iteration 237 / 300: loss 0.600499\n",
      "iteration 237 / 300: loss 0.599650\n",
      "iteration 237 / 300: loss 0.617540\n",
      "iteration 237 / 300: loss 0.598875\n",
      "iteration 237 / 300: loss 0.600801\n",
      "iteration 237 / 300: loss 0.605305\n",
      "iteration 237 / 300: loss 0.598592\n",
      "iteration 237 / 300: loss 0.591474\n",
      "iteration 237 / 300: loss 0.580382\n",
      "iteration 237 / 300: loss 0.598221\n",
      "iteration 237 / 300: loss 0.611685\n",
      "iteration 237 / 300: loss 0.613219\n",
      "iteration 237 / 300: loss 0.582214\n",
      "iteration 237 / 300: loss 0.601955\n",
      "iteration 237 / 300: loss 0.608956\n",
      "iteration 237 / 300: loss 0.601794\n",
      "iteration 237 / 300: loss 0.607944\n",
      "iteration 237 / 300: loss 0.620236\n",
      "iteration 237 / 300: loss 0.584817\n",
      "iteration 237 / 300: loss 0.583721\n",
      "iteration 237 / 300: loss 0.628849\n",
      "iteration 237 / 300: loss 0.609399\n",
      "iteration 237 / 300: loss 0.606265\n",
      "iteration 237 / 300: loss 0.599034\n",
      "iteration 237 / 300: loss 0.615876\n",
      "iteration 237 / 300: loss 0.596489\n",
      "iteration 237 / 300: loss 0.581430\n",
      "iteration 237 / 300: loss 0.609807\n",
      "iteration 237 / 300: loss 0.608125\n",
      "iteration 237 / 300: loss 0.598224\n",
      "iteration 237 / 300: loss 0.592022\n",
      "iteration 237 / 300: loss 0.611031\n",
      "iteration 237 / 300: loss 0.598550\n",
      "iteration 237 / 300: loss 0.581382\n",
      "iteration 237 / 300: loss 0.609580\n",
      "iteration 238 / 300: loss 0.578384\n",
      "iteration 238 / 300: loss 0.596214\n",
      "iteration 238 / 300: loss 0.569455\n",
      "iteration 238 / 300: loss 0.597849\n",
      "iteration 238 / 300: loss 0.598940\n",
      "iteration 238 / 300: loss 0.603876\n",
      "iteration 238 / 300: loss 0.615261\n",
      "iteration 238 / 300: loss 0.588227\n",
      "iteration 238 / 300: loss 0.627171\n",
      "iteration 238 / 300: loss 0.592600\n",
      "iteration 238 / 300: loss 0.621500\n",
      "iteration 238 / 300: loss 0.593093\n",
      "iteration 238 / 300: loss 0.600541\n",
      "iteration 238 / 300: loss 0.571000\n",
      "iteration 238 / 300: loss 0.592911\n",
      "iteration 238 / 300: loss 0.600043\n",
      "iteration 238 / 300: loss 0.598053\n",
      "iteration 238 / 300: loss 0.583712\n",
      "iteration 238 / 300: loss 0.614355\n",
      "iteration 238 / 300: loss 0.591285\n",
      "iteration 238 / 300: loss 0.591391\n",
      "iteration 238 / 300: loss 0.594005\n",
      "iteration 238 / 300: loss 0.596735\n",
      "iteration 238 / 300: loss 0.596712\n",
      "iteration 238 / 300: loss 0.611735\n",
      "iteration 238 / 300: loss 0.607258\n",
      "iteration 238 / 300: loss 0.597031\n",
      "iteration 238 / 300: loss 0.596301\n",
      "iteration 238 / 300: loss 0.627391\n",
      "iteration 238 / 300: loss 0.601584\n",
      "iteration 238 / 300: loss 0.599923\n",
      "iteration 238 / 300: loss 0.621952\n",
      "iteration 238 / 300: loss 0.581435\n",
      "iteration 238 / 300: loss 0.599604\n",
      "iteration 238 / 300: loss 0.591182\n",
      "iteration 238 / 300: loss 0.599919\n",
      "iteration 238 / 300: loss 0.596015\n",
      "iteration 238 / 300: loss 0.590760\n",
      "iteration 238 / 300: loss 0.591961\n",
      "iteration 238 / 300: loss 0.615468\n",
      "iteration 238 / 300: loss 0.621360\n",
      "iteration 238 / 300: loss 0.587267\n",
      "iteration 238 / 300: loss 0.582483\n",
      "iteration 238 / 300: loss 0.585572\n",
      "iteration 238 / 300: loss 0.603666\n",
      "iteration 238 / 300: loss 0.585192\n",
      "iteration 238 / 300: loss 0.578880\n",
      "iteration 238 / 300: loss 0.576418\n",
      "iteration 238 / 300: loss 0.574097\n",
      "iteration 238 / 300: loss 0.600500\n",
      "iteration 238 / 300: loss 0.584490\n",
      "iteration 238 / 300: loss 0.584834\n",
      "iteration 238 / 300: loss 0.568323\n",
      "iteration 238 / 300: loss 0.592025\n",
      "iteration 238 / 300: loss 0.612116\n",
      "iteration 238 / 300: loss 0.608923\n",
      "iteration 238 / 300: loss 0.607613\n",
      "iteration 238 / 300: loss 0.595533\n",
      "iteration 238 / 300: loss 0.592837\n",
      "iteration 238 / 300: loss 0.597988\n",
      "iteration 238 / 300: loss 0.597677\n",
      "iteration 238 / 300: loss 0.600953\n",
      "iteration 238 / 300: loss 0.597422\n",
      "iteration 238 / 300: loss 0.598776\n",
      "iteration 238 / 300: loss 0.587806\n",
      "iteration 238 / 300: loss 0.600499\n",
      "iteration 238 / 300: loss 0.599650\n",
      "iteration 238 / 300: loss 0.617540\n",
      "iteration 238 / 300: loss 0.598875\n",
      "iteration 238 / 300: loss 0.600801\n",
      "iteration 238 / 300: loss 0.605305\n",
      "iteration 238 / 300: loss 0.598592\n",
      "iteration 238 / 300: loss 0.591474\n",
      "iteration 238 / 300: loss 0.580382\n",
      "iteration 238 / 300: loss 0.598221\n",
      "iteration 238 / 300: loss 0.611685\n",
      "iteration 238 / 300: loss 0.613219\n",
      "iteration 238 / 300: loss 0.582214\n",
      "iteration 238 / 300: loss 0.601955\n",
      "iteration 238 / 300: loss 0.608956\n",
      "iteration 238 / 300: loss 0.601794\n",
      "iteration 238 / 300: loss 0.607944\n",
      "iteration 238 / 300: loss 0.620236\n",
      "iteration 238 / 300: loss 0.584817\n",
      "iteration 238 / 300: loss 0.583721\n",
      "iteration 238 / 300: loss 0.628849\n",
      "iteration 238 / 300: loss 0.609399\n",
      "iteration 238 / 300: loss 0.606265\n",
      "iteration 238 / 300: loss 0.599034\n",
      "iteration 238 / 300: loss 0.615876\n",
      "iteration 238 / 300: loss 0.596489\n",
      "iteration 238 / 300: loss 0.581430\n",
      "iteration 238 / 300: loss 0.609807\n",
      "iteration 238 / 300: loss 0.608125\n",
      "iteration 238 / 300: loss 0.598224\n",
      "iteration 238 / 300: loss 0.592022\n",
      "iteration 238 / 300: loss 0.611031\n",
      "iteration 238 / 300: loss 0.598550\n",
      "iteration 238 / 300: loss 0.581382\n",
      "iteration 238 / 300: loss 0.609580\n",
      "iteration 239 / 300: loss 0.578384\n",
      "iteration 239 / 300: loss 0.596214\n",
      "iteration 239 / 300: loss 0.569455\n",
      "iteration 239 / 300: loss 0.597849\n",
      "iteration 239 / 300: loss 0.598940\n",
      "iteration 239 / 300: loss 0.603876\n",
      "iteration 239 / 300: loss 0.615261\n",
      "iteration 239 / 300: loss 0.588227\n",
      "iteration 239 / 300: loss 0.627171\n",
      "iteration 239 / 300: loss 0.592600\n",
      "iteration 239 / 300: loss 0.621500\n",
      "iteration 239 / 300: loss 0.593093\n",
      "iteration 239 / 300: loss 0.600541\n",
      "iteration 239 / 300: loss 0.571000\n",
      "iteration 239 / 300: loss 0.592911\n",
      "iteration 239 / 300: loss 0.600043\n",
      "iteration 239 / 300: loss 0.598053\n",
      "iteration 239 / 300: loss 0.583712\n",
      "iteration 239 / 300: loss 0.614355\n",
      "iteration 239 / 300: loss 0.591285\n",
      "iteration 239 / 300: loss 0.591391\n",
      "iteration 239 / 300: loss 0.594005\n",
      "iteration 239 / 300: loss 0.596735\n",
      "iteration 239 / 300: loss 0.596712\n",
      "iteration 239 / 300: loss 0.611735\n",
      "iteration 239 / 300: loss 0.607258\n",
      "iteration 239 / 300: loss 0.597031\n",
      "iteration 239 / 300: loss 0.596301\n",
      "iteration 239 / 300: loss 0.627391\n",
      "iteration 239 / 300: loss 0.601584\n",
      "iteration 239 / 300: loss 0.599923\n",
      "iteration 239 / 300: loss 0.621952\n",
      "iteration 239 / 300: loss 0.581435\n",
      "iteration 239 / 300: loss 0.599604\n",
      "iteration 239 / 300: loss 0.591182\n",
      "iteration 239 / 300: loss 0.599919\n",
      "iteration 239 / 300: loss 0.596015\n",
      "iteration 239 / 300: loss 0.590760\n",
      "iteration 239 / 300: loss 0.591961\n",
      "iteration 239 / 300: loss 0.615468\n",
      "iteration 239 / 300: loss 0.621360\n",
      "iteration 239 / 300: loss 0.587267\n",
      "iteration 239 / 300: loss 0.582483\n",
      "iteration 239 / 300: loss 0.585572\n",
      "iteration 239 / 300: loss 0.603666\n",
      "iteration 239 / 300: loss 0.585192\n",
      "iteration 239 / 300: loss 0.578880\n",
      "iteration 239 / 300: loss 0.576418\n",
      "iteration 239 / 300: loss 0.574097\n",
      "iteration 239 / 300: loss 0.600500\n",
      "iteration 239 / 300: loss 0.584490\n",
      "iteration 239 / 300: loss 0.584834\n",
      "iteration 239 / 300: loss 0.568323\n",
      "iteration 239 / 300: loss 0.592025\n",
      "iteration 239 / 300: loss 0.612116\n",
      "iteration 239 / 300: loss 0.608923\n",
      "iteration 239 / 300: loss 0.607613\n",
      "iteration 239 / 300: loss 0.595533\n",
      "iteration 239 / 300: loss 0.592837\n",
      "iteration 239 / 300: loss 0.597988\n",
      "iteration 239 / 300: loss 0.597677\n",
      "iteration 239 / 300: loss 0.600953\n",
      "iteration 239 / 300: loss 0.597422\n",
      "iteration 239 / 300: loss 0.598776\n",
      "iteration 239 / 300: loss 0.587806\n",
      "iteration 239 / 300: loss 0.600499\n",
      "iteration 239 / 300: loss 0.599650\n",
      "iteration 239 / 300: loss 0.617540\n",
      "iteration 239 / 300: loss 0.598875\n",
      "iteration 239 / 300: loss 0.600801\n",
      "iteration 239 / 300: loss 0.605305\n",
      "iteration 239 / 300: loss 0.598592\n",
      "iteration 239 / 300: loss 0.591474\n",
      "iteration 239 / 300: loss 0.580382\n",
      "iteration 239 / 300: loss 0.598221\n",
      "iteration 239 / 300: loss 0.611685\n",
      "iteration 239 / 300: loss 0.613219\n",
      "iteration 239 / 300: loss 0.582214\n",
      "iteration 239 / 300: loss 0.601955\n",
      "iteration 239 / 300: loss 0.608956\n",
      "iteration 239 / 300: loss 0.601794\n",
      "iteration 239 / 300: loss 0.607944\n",
      "iteration 239 / 300: loss 0.620236\n",
      "iteration 239 / 300: loss 0.584817\n",
      "iteration 239 / 300: loss 0.583721\n",
      "iteration 239 / 300: loss 0.628849\n",
      "iteration 239 / 300: loss 0.609399\n",
      "iteration 239 / 300: loss 0.606265\n",
      "iteration 239 / 300: loss 0.599034\n",
      "iteration 239 / 300: loss 0.615876\n",
      "iteration 239 / 300: loss 0.596489\n",
      "iteration 239 / 300: loss 0.581430\n",
      "iteration 239 / 300: loss 0.609807\n",
      "iteration 239 / 300: loss 0.608125\n",
      "iteration 239 / 300: loss 0.598224\n",
      "iteration 239 / 300: loss 0.592022\n",
      "iteration 239 / 300: loss 0.611031\n",
      "iteration 239 / 300: loss 0.598550\n",
      "iteration 239 / 300: loss 0.581382\n",
      "iteration 239 / 300: loss 0.609580\n",
      "iteration 240 / 300: loss 0.578384\n",
      "iteration 240 / 300: loss 0.596214\n",
      "iteration 240 / 300: loss 0.569455\n",
      "iteration 240 / 300: loss 0.597849\n",
      "iteration 240 / 300: loss 0.598940\n",
      "iteration 240 / 300: loss 0.603876\n",
      "iteration 240 / 300: loss 0.615261\n",
      "iteration 240 / 300: loss 0.588227\n",
      "iteration 240 / 300: loss 0.627171\n",
      "iteration 240 / 300: loss 0.592600\n",
      "iteration 240 / 300: loss 0.621500\n",
      "iteration 240 / 300: loss 0.593093\n",
      "iteration 240 / 300: loss 0.600541\n",
      "iteration 240 / 300: loss 0.571000\n",
      "iteration 240 / 300: loss 0.592911\n",
      "iteration 240 / 300: loss 0.600043\n",
      "iteration 240 / 300: loss 0.598053\n",
      "iteration 240 / 300: loss 0.583712\n",
      "iteration 240 / 300: loss 0.614355\n",
      "iteration 240 / 300: loss 0.591285\n",
      "iteration 240 / 300: loss 0.591391\n",
      "iteration 240 / 300: loss 0.594005\n",
      "iteration 240 / 300: loss 0.596735\n",
      "iteration 240 / 300: loss 0.596712\n",
      "iteration 240 / 300: loss 0.611735\n",
      "iteration 240 / 300: loss 0.607258\n",
      "iteration 240 / 300: loss 0.597031\n",
      "iteration 240 / 300: loss 0.596301\n",
      "iteration 240 / 300: loss 0.627391\n",
      "iteration 240 / 300: loss 0.601584\n",
      "iteration 240 / 300: loss 0.599923\n",
      "iteration 240 / 300: loss 0.621952\n",
      "iteration 240 / 300: loss 0.581435\n",
      "iteration 240 / 300: loss 0.599604\n",
      "iteration 240 / 300: loss 0.591182\n",
      "iteration 240 / 300: loss 0.599919\n",
      "iteration 240 / 300: loss 0.596015\n",
      "iteration 240 / 300: loss 0.590760\n",
      "iteration 240 / 300: loss 0.591961\n",
      "iteration 240 / 300: loss 0.615468\n",
      "iteration 240 / 300: loss 0.621360\n",
      "iteration 240 / 300: loss 0.587267\n",
      "iteration 240 / 300: loss 0.582483\n",
      "iteration 240 / 300: loss 0.585572\n",
      "iteration 240 / 300: loss 0.603666\n",
      "iteration 240 / 300: loss 0.585192\n",
      "iteration 240 / 300: loss 0.578880\n",
      "iteration 240 / 300: loss 0.576418\n",
      "iteration 240 / 300: loss 0.574097\n",
      "iteration 240 / 300: loss 0.600500\n",
      "iteration 240 / 300: loss 0.584490\n",
      "iteration 240 / 300: loss 0.584834\n",
      "iteration 240 / 300: loss 0.568323\n",
      "iteration 240 / 300: loss 0.592025\n",
      "iteration 240 / 300: loss 0.612116\n",
      "iteration 240 / 300: loss 0.608923\n",
      "iteration 240 / 300: loss 0.607613\n",
      "iteration 240 / 300: loss 0.595533\n",
      "iteration 240 / 300: loss 0.592837\n",
      "iteration 240 / 300: loss 0.597988\n",
      "iteration 240 / 300: loss 0.597677\n",
      "iteration 240 / 300: loss 0.600953\n",
      "iteration 240 / 300: loss 0.597422\n",
      "iteration 240 / 300: loss 0.598776\n",
      "iteration 240 / 300: loss 0.587806\n",
      "iteration 240 / 300: loss 0.600499\n",
      "iteration 240 / 300: loss 0.599650\n",
      "iteration 240 / 300: loss 0.617540\n",
      "iteration 240 / 300: loss 0.598875\n",
      "iteration 240 / 300: loss 0.600801\n",
      "iteration 240 / 300: loss 0.605305\n",
      "iteration 240 / 300: loss 0.598592\n",
      "iteration 240 / 300: loss 0.591474\n",
      "iteration 240 / 300: loss 0.580382\n",
      "iteration 240 / 300: loss 0.598221\n",
      "iteration 240 / 300: loss 0.611685\n",
      "iteration 240 / 300: loss 0.613219\n",
      "iteration 240 / 300: loss 0.582214\n",
      "iteration 240 / 300: loss 0.601955\n",
      "iteration 240 / 300: loss 0.608956\n",
      "iteration 240 / 300: loss 0.601794\n",
      "iteration 240 / 300: loss 0.607944\n",
      "iteration 240 / 300: loss 0.620236\n",
      "iteration 240 / 300: loss 0.584817\n",
      "iteration 240 / 300: loss 0.583721\n",
      "iteration 240 / 300: loss 0.628849\n",
      "iteration 240 / 300: loss 0.609399\n",
      "iteration 240 / 300: loss 0.606265\n",
      "iteration 240 / 300: loss 0.599034\n",
      "iteration 240 / 300: loss 0.615876\n",
      "iteration 240 / 300: loss 0.596489\n",
      "iteration 240 / 300: loss 0.581430\n",
      "iteration 240 / 300: loss 0.609807\n",
      "iteration 240 / 300: loss 0.608125\n",
      "iteration 240 / 300: loss 0.598224\n",
      "iteration 240 / 300: loss 0.592022\n",
      "iteration 240 / 300: loss 0.611031\n",
      "iteration 240 / 300: loss 0.598550\n",
      "iteration 240 / 300: loss 0.581382\n",
      "iteration 240 / 300: loss 0.609580\n",
      "iteration 241 / 300: loss 0.578384\n",
      "iteration 241 / 300: loss 0.596214\n",
      "iteration 241 / 300: loss 0.569455\n",
      "iteration 241 / 300: loss 0.597849\n",
      "iteration 241 / 300: loss 0.598940\n",
      "iteration 241 / 300: loss 0.603876\n",
      "iteration 241 / 300: loss 0.615261\n",
      "iteration 241 / 300: loss 0.588227\n",
      "iteration 241 / 300: loss 0.627171\n",
      "iteration 241 / 300: loss 0.592600\n",
      "iteration 241 / 300: loss 0.621500\n",
      "iteration 241 / 300: loss 0.593093\n",
      "iteration 241 / 300: loss 0.600541\n",
      "iteration 241 / 300: loss 0.571000\n",
      "iteration 241 / 300: loss 0.592911\n",
      "iteration 241 / 300: loss 0.600043\n",
      "iteration 241 / 300: loss 0.598053\n",
      "iteration 241 / 300: loss 0.583712\n",
      "iteration 241 / 300: loss 0.614355\n",
      "iteration 241 / 300: loss 0.591285\n",
      "iteration 241 / 300: loss 0.591391\n",
      "iteration 241 / 300: loss 0.594005\n",
      "iteration 241 / 300: loss 0.596735\n",
      "iteration 241 / 300: loss 0.596712\n",
      "iteration 241 / 300: loss 0.611735\n",
      "iteration 241 / 300: loss 0.607258\n",
      "iteration 241 / 300: loss 0.597031\n",
      "iteration 241 / 300: loss 0.596301\n",
      "iteration 241 / 300: loss 0.627391\n",
      "iteration 241 / 300: loss 0.601584\n",
      "iteration 241 / 300: loss 0.599923\n",
      "iteration 241 / 300: loss 0.621952\n",
      "iteration 241 / 300: loss 0.581435\n",
      "iteration 241 / 300: loss 0.599604\n",
      "iteration 241 / 300: loss 0.591182\n",
      "iteration 241 / 300: loss 0.599919\n",
      "iteration 241 / 300: loss 0.596015\n",
      "iteration 241 / 300: loss 0.590760\n",
      "iteration 241 / 300: loss 0.591961\n",
      "iteration 241 / 300: loss 0.615468\n",
      "iteration 241 / 300: loss 0.621360\n",
      "iteration 241 / 300: loss 0.587267\n",
      "iteration 241 / 300: loss 0.582483\n",
      "iteration 241 / 300: loss 0.585572\n",
      "iteration 241 / 300: loss 0.603666\n",
      "iteration 241 / 300: loss 0.585192\n",
      "iteration 241 / 300: loss 0.578880\n",
      "iteration 241 / 300: loss 0.576418\n",
      "iteration 241 / 300: loss 0.574097\n",
      "iteration 241 / 300: loss 0.600500\n",
      "iteration 241 / 300: loss 0.584490\n",
      "iteration 241 / 300: loss 0.584834\n",
      "iteration 241 / 300: loss 0.568323\n",
      "iteration 241 / 300: loss 0.592025\n",
      "iteration 241 / 300: loss 0.612116\n",
      "iteration 241 / 300: loss 0.608923\n",
      "iteration 241 / 300: loss 0.607613\n",
      "iteration 241 / 300: loss 0.595533\n",
      "iteration 241 / 300: loss 0.592837\n",
      "iteration 241 / 300: loss 0.597988\n",
      "iteration 241 / 300: loss 0.597677\n",
      "iteration 241 / 300: loss 0.600953\n",
      "iteration 241 / 300: loss 0.597422\n",
      "iteration 241 / 300: loss 0.598776\n",
      "iteration 241 / 300: loss 0.587806\n",
      "iteration 241 / 300: loss 0.600499\n",
      "iteration 241 / 300: loss 0.599650\n",
      "iteration 241 / 300: loss 0.617540\n",
      "iteration 241 / 300: loss 0.598875\n",
      "iteration 241 / 300: loss 0.600801\n",
      "iteration 241 / 300: loss 0.605305\n",
      "iteration 241 / 300: loss 0.598592\n",
      "iteration 241 / 300: loss 0.591474\n",
      "iteration 241 / 300: loss 0.580382\n",
      "iteration 241 / 300: loss 0.598221\n",
      "iteration 241 / 300: loss 0.611685\n",
      "iteration 241 / 300: loss 0.613219\n",
      "iteration 241 / 300: loss 0.582214\n",
      "iteration 241 / 300: loss 0.601955\n",
      "iteration 241 / 300: loss 0.608956\n",
      "iteration 241 / 300: loss 0.601794\n",
      "iteration 241 / 300: loss 0.607944\n",
      "iteration 241 / 300: loss 0.620236\n",
      "iteration 241 / 300: loss 0.584817\n",
      "iteration 241 / 300: loss 0.583721\n",
      "iteration 241 / 300: loss 0.628849\n",
      "iteration 241 / 300: loss 0.609399\n",
      "iteration 241 / 300: loss 0.606265\n",
      "iteration 241 / 300: loss 0.599034\n",
      "iteration 241 / 300: loss 0.615876\n",
      "iteration 241 / 300: loss 0.596489\n",
      "iteration 241 / 300: loss 0.581430\n",
      "iteration 241 / 300: loss 0.609807\n",
      "iteration 241 / 300: loss 0.608125\n",
      "iteration 241 / 300: loss 0.598224\n",
      "iteration 241 / 300: loss 0.592022\n",
      "iteration 241 / 300: loss 0.611031\n",
      "iteration 241 / 300: loss 0.598550\n",
      "iteration 241 / 300: loss 0.581382\n",
      "iteration 241 / 300: loss 0.609580\n",
      "iteration 242 / 300: loss 0.578384\n",
      "iteration 242 / 300: loss 0.596214\n",
      "iteration 242 / 300: loss 0.569455\n",
      "iteration 242 / 300: loss 0.597849\n",
      "iteration 242 / 300: loss 0.598940\n",
      "iteration 242 / 300: loss 0.603876\n",
      "iteration 242 / 300: loss 0.615261\n",
      "iteration 242 / 300: loss 0.588227\n",
      "iteration 242 / 300: loss 0.627171\n",
      "iteration 242 / 300: loss 0.592600\n",
      "iteration 242 / 300: loss 0.621500\n",
      "iteration 242 / 300: loss 0.593093\n",
      "iteration 242 / 300: loss 0.600541\n",
      "iteration 242 / 300: loss 0.571000\n",
      "iteration 242 / 300: loss 0.592911\n",
      "iteration 242 / 300: loss 0.600043\n",
      "iteration 242 / 300: loss 0.598053\n",
      "iteration 242 / 300: loss 0.583712\n",
      "iteration 242 / 300: loss 0.614355\n",
      "iteration 242 / 300: loss 0.591285\n",
      "iteration 242 / 300: loss 0.591391\n",
      "iteration 242 / 300: loss 0.594005\n",
      "iteration 242 / 300: loss 0.596735\n",
      "iteration 242 / 300: loss 0.596712\n",
      "iteration 242 / 300: loss 0.611735\n",
      "iteration 242 / 300: loss 0.607258\n",
      "iteration 242 / 300: loss 0.597031\n",
      "iteration 242 / 300: loss 0.596301\n",
      "iteration 242 / 300: loss 0.627391\n",
      "iteration 242 / 300: loss 0.601584\n",
      "iteration 242 / 300: loss 0.599923\n",
      "iteration 242 / 300: loss 0.621952\n",
      "iteration 242 / 300: loss 0.581435\n",
      "iteration 242 / 300: loss 0.599604\n",
      "iteration 242 / 300: loss 0.591182\n",
      "iteration 242 / 300: loss 0.599919\n",
      "iteration 242 / 300: loss 0.596015\n",
      "iteration 242 / 300: loss 0.590760\n",
      "iteration 242 / 300: loss 0.591961\n",
      "iteration 242 / 300: loss 0.615468\n",
      "iteration 242 / 300: loss 0.621360\n",
      "iteration 242 / 300: loss 0.587267\n",
      "iteration 242 / 300: loss 0.582483\n",
      "iteration 242 / 300: loss 0.585572\n",
      "iteration 242 / 300: loss 0.603666\n",
      "iteration 242 / 300: loss 0.585192\n",
      "iteration 242 / 300: loss 0.578880\n",
      "iteration 242 / 300: loss 0.576418\n",
      "iteration 242 / 300: loss 0.574097\n",
      "iteration 242 / 300: loss 0.600500\n",
      "iteration 242 / 300: loss 0.584490\n",
      "iteration 242 / 300: loss 0.584834\n",
      "iteration 242 / 300: loss 0.568323\n",
      "iteration 242 / 300: loss 0.592025\n",
      "iteration 242 / 300: loss 0.612116\n",
      "iteration 242 / 300: loss 0.608923\n",
      "iteration 242 / 300: loss 0.607613\n",
      "iteration 242 / 300: loss 0.595533\n",
      "iteration 242 / 300: loss 0.592837\n",
      "iteration 242 / 300: loss 0.597988\n",
      "iteration 242 / 300: loss 0.597677\n",
      "iteration 242 / 300: loss 0.600953\n",
      "iteration 242 / 300: loss 0.597422\n",
      "iteration 242 / 300: loss 0.598776\n",
      "iteration 242 / 300: loss 0.587806\n",
      "iteration 242 / 300: loss 0.600499\n",
      "iteration 242 / 300: loss 0.599650\n",
      "iteration 242 / 300: loss 0.617540\n",
      "iteration 242 / 300: loss 0.598875\n",
      "iteration 242 / 300: loss 0.600801\n",
      "iteration 242 / 300: loss 0.605305\n",
      "iteration 242 / 300: loss 0.598592\n",
      "iteration 242 / 300: loss 0.591474\n",
      "iteration 242 / 300: loss 0.580382\n",
      "iteration 242 / 300: loss 0.598221\n",
      "iteration 242 / 300: loss 0.611685\n",
      "iteration 242 / 300: loss 0.613219\n",
      "iteration 242 / 300: loss 0.582214\n",
      "iteration 242 / 300: loss 0.601955\n",
      "iteration 242 / 300: loss 0.608956\n",
      "iteration 242 / 300: loss 0.601794\n",
      "iteration 242 / 300: loss 0.607944\n",
      "iteration 242 / 300: loss 0.620236\n",
      "iteration 242 / 300: loss 0.584817\n",
      "iteration 242 / 300: loss 0.583721\n",
      "iteration 242 / 300: loss 0.628849\n",
      "iteration 242 / 300: loss 0.609399\n",
      "iteration 242 / 300: loss 0.606265\n",
      "iteration 242 / 300: loss 0.599034\n",
      "iteration 242 / 300: loss 0.615876\n",
      "iteration 242 / 300: loss 0.596489\n",
      "iteration 242 / 300: loss 0.581430\n",
      "iteration 242 / 300: loss 0.609807\n",
      "iteration 242 / 300: loss 0.608125\n",
      "iteration 242 / 300: loss 0.598224\n",
      "iteration 242 / 300: loss 0.592022\n",
      "iteration 242 / 300: loss 0.611031\n",
      "iteration 242 / 300: loss 0.598550\n",
      "iteration 242 / 300: loss 0.581382\n",
      "iteration 242 / 300: loss 0.609580\n",
      "iteration 243 / 300: loss 0.578384\n",
      "iteration 243 / 300: loss 0.596214\n",
      "iteration 243 / 300: loss 0.569455\n",
      "iteration 243 / 300: loss 0.597849\n",
      "iteration 243 / 300: loss 0.598940\n",
      "iteration 243 / 300: loss 0.603876\n",
      "iteration 243 / 300: loss 0.615261\n",
      "iteration 243 / 300: loss 0.588227\n",
      "iteration 243 / 300: loss 0.627171\n",
      "iteration 243 / 300: loss 0.592600\n",
      "iteration 243 / 300: loss 0.621500\n",
      "iteration 243 / 300: loss 0.593093\n",
      "iteration 243 / 300: loss 0.600541\n",
      "iteration 243 / 300: loss 0.571000\n",
      "iteration 243 / 300: loss 0.592911\n",
      "iteration 243 / 300: loss 0.600043\n",
      "iteration 243 / 300: loss 0.598053\n",
      "iteration 243 / 300: loss 0.583712\n",
      "iteration 243 / 300: loss 0.614355\n",
      "iteration 243 / 300: loss 0.591285\n",
      "iteration 243 / 300: loss 0.591391\n",
      "iteration 243 / 300: loss 0.594005\n",
      "iteration 243 / 300: loss 0.596735\n",
      "iteration 243 / 300: loss 0.596712\n",
      "iteration 243 / 300: loss 0.611735\n",
      "iteration 243 / 300: loss 0.607258\n",
      "iteration 243 / 300: loss 0.597031\n",
      "iteration 243 / 300: loss 0.596301\n",
      "iteration 243 / 300: loss 0.627391\n",
      "iteration 243 / 300: loss 0.601584\n",
      "iteration 243 / 300: loss 0.599923\n",
      "iteration 243 / 300: loss 0.621952\n",
      "iteration 243 / 300: loss 0.581435\n",
      "iteration 243 / 300: loss 0.599604\n",
      "iteration 243 / 300: loss 0.591182\n",
      "iteration 243 / 300: loss 0.599919\n",
      "iteration 243 / 300: loss 0.596015\n",
      "iteration 243 / 300: loss 0.590760\n",
      "iteration 243 / 300: loss 0.591961\n",
      "iteration 243 / 300: loss 0.615468\n",
      "iteration 243 / 300: loss 0.621360\n",
      "iteration 243 / 300: loss 0.587267\n",
      "iteration 243 / 300: loss 0.582483\n",
      "iteration 243 / 300: loss 0.585572\n",
      "iteration 243 / 300: loss 0.603666\n",
      "iteration 243 / 300: loss 0.585192\n",
      "iteration 243 / 300: loss 0.578880\n",
      "iteration 243 / 300: loss 0.576418\n",
      "iteration 243 / 300: loss 0.574097\n",
      "iteration 243 / 300: loss 0.600500\n",
      "iteration 243 / 300: loss 0.584490\n",
      "iteration 243 / 300: loss 0.584834\n",
      "iteration 243 / 300: loss 0.568323\n",
      "iteration 243 / 300: loss 0.592025\n",
      "iteration 243 / 300: loss 0.612116\n",
      "iteration 243 / 300: loss 0.608923\n",
      "iteration 243 / 300: loss 0.607613\n",
      "iteration 243 / 300: loss 0.595533\n",
      "iteration 243 / 300: loss 0.592837\n",
      "iteration 243 / 300: loss 0.597988\n",
      "iteration 243 / 300: loss 0.597677\n",
      "iteration 243 / 300: loss 0.600953\n",
      "iteration 243 / 300: loss 0.597422\n",
      "iteration 243 / 300: loss 0.598776\n",
      "iteration 243 / 300: loss 0.587806\n",
      "iteration 243 / 300: loss 0.600499\n",
      "iteration 243 / 300: loss 0.599650\n",
      "iteration 243 / 300: loss 0.617540\n",
      "iteration 243 / 300: loss 0.598875\n",
      "iteration 243 / 300: loss 0.600801\n",
      "iteration 243 / 300: loss 0.605305\n",
      "iteration 243 / 300: loss 0.598592\n",
      "iteration 243 / 300: loss 0.591474\n",
      "iteration 243 / 300: loss 0.580382\n",
      "iteration 243 / 300: loss 0.598221\n",
      "iteration 243 / 300: loss 0.611685\n",
      "iteration 243 / 300: loss 0.613219\n",
      "iteration 243 / 300: loss 0.582214\n",
      "iteration 243 / 300: loss 0.601955\n",
      "iteration 243 / 300: loss 0.608956\n",
      "iteration 243 / 300: loss 0.601794\n",
      "iteration 243 / 300: loss 0.607944\n",
      "iteration 243 / 300: loss 0.620236\n",
      "iteration 243 / 300: loss 0.584817\n",
      "iteration 243 / 300: loss 0.583721\n",
      "iteration 243 / 300: loss 0.628849\n",
      "iteration 243 / 300: loss 0.609399\n",
      "iteration 243 / 300: loss 0.606265\n",
      "iteration 243 / 300: loss 0.599034\n",
      "iteration 243 / 300: loss 0.615876\n",
      "iteration 243 / 300: loss 0.596489\n",
      "iteration 243 / 300: loss 0.581430\n",
      "iteration 243 / 300: loss 0.609807\n",
      "iteration 243 / 300: loss 0.608125\n",
      "iteration 243 / 300: loss 0.598224\n",
      "iteration 243 / 300: loss 0.592022\n",
      "iteration 243 / 300: loss 0.611031\n",
      "iteration 243 / 300: loss 0.598550\n",
      "iteration 243 / 300: loss 0.581382\n",
      "iteration 243 / 300: loss 0.609580\n",
      "iteration 244 / 300: loss 0.578384\n",
      "iteration 244 / 300: loss 0.596214\n",
      "iteration 244 / 300: loss 0.569455\n",
      "iteration 244 / 300: loss 0.597849\n",
      "iteration 244 / 300: loss 0.598940\n",
      "iteration 244 / 300: loss 0.603876\n",
      "iteration 244 / 300: loss 0.615261\n",
      "iteration 244 / 300: loss 0.588227\n",
      "iteration 244 / 300: loss 0.627171\n",
      "iteration 244 / 300: loss 0.592600\n",
      "iteration 244 / 300: loss 0.621500\n",
      "iteration 244 / 300: loss 0.593093\n",
      "iteration 244 / 300: loss 0.600541\n",
      "iteration 244 / 300: loss 0.571000\n",
      "iteration 244 / 300: loss 0.592911\n",
      "iteration 244 / 300: loss 0.600043\n",
      "iteration 244 / 300: loss 0.598053\n",
      "iteration 244 / 300: loss 0.583712\n",
      "iteration 244 / 300: loss 0.614355\n",
      "iteration 244 / 300: loss 0.591285\n",
      "iteration 244 / 300: loss 0.591391\n",
      "iteration 244 / 300: loss 0.594005\n",
      "iteration 244 / 300: loss 0.596735\n",
      "iteration 244 / 300: loss 0.596712\n",
      "iteration 244 / 300: loss 0.611735\n",
      "iteration 244 / 300: loss 0.607258\n",
      "iteration 244 / 300: loss 0.597031\n",
      "iteration 244 / 300: loss 0.596301\n",
      "iteration 244 / 300: loss 0.627391\n",
      "iteration 244 / 300: loss 0.601584\n",
      "iteration 244 / 300: loss 0.599923\n",
      "iteration 244 / 300: loss 0.621952\n",
      "iteration 244 / 300: loss 0.581435\n",
      "iteration 244 / 300: loss 0.599604\n",
      "iteration 244 / 300: loss 0.591182\n",
      "iteration 244 / 300: loss 0.599919\n",
      "iteration 244 / 300: loss 0.596015\n",
      "iteration 244 / 300: loss 0.590760\n",
      "iteration 244 / 300: loss 0.591961\n",
      "iteration 244 / 300: loss 0.615468\n",
      "iteration 244 / 300: loss 0.621360\n",
      "iteration 244 / 300: loss 0.587267\n",
      "iteration 244 / 300: loss 0.582483\n",
      "iteration 244 / 300: loss 0.585572\n",
      "iteration 244 / 300: loss 0.603666\n",
      "iteration 244 / 300: loss 0.585192\n",
      "iteration 244 / 300: loss 0.578880\n",
      "iteration 244 / 300: loss 0.576418\n",
      "iteration 244 / 300: loss 0.574097\n",
      "iteration 244 / 300: loss 0.600500\n",
      "iteration 244 / 300: loss 0.584490\n",
      "iteration 244 / 300: loss 0.584834\n",
      "iteration 244 / 300: loss 0.568323\n",
      "iteration 244 / 300: loss 0.592025\n",
      "iteration 244 / 300: loss 0.612116\n",
      "iteration 244 / 300: loss 0.608923\n",
      "iteration 244 / 300: loss 0.607613\n",
      "iteration 244 / 300: loss 0.595533\n",
      "iteration 244 / 300: loss 0.592837\n",
      "iteration 244 / 300: loss 0.597988\n",
      "iteration 244 / 300: loss 0.597677\n",
      "iteration 244 / 300: loss 0.600953\n",
      "iteration 244 / 300: loss 0.597422\n",
      "iteration 244 / 300: loss 0.598776\n",
      "iteration 244 / 300: loss 0.587806\n",
      "iteration 244 / 300: loss 0.600499\n",
      "iteration 244 / 300: loss 0.599650\n",
      "iteration 244 / 300: loss 0.617540\n",
      "iteration 244 / 300: loss 0.598875\n",
      "iteration 244 / 300: loss 0.600801\n",
      "iteration 244 / 300: loss 0.605305\n",
      "iteration 244 / 300: loss 0.598592\n",
      "iteration 244 / 300: loss 0.591474\n",
      "iteration 244 / 300: loss 0.580382\n",
      "iteration 244 / 300: loss 0.598221\n",
      "iteration 244 / 300: loss 0.611685\n",
      "iteration 244 / 300: loss 0.613219\n",
      "iteration 244 / 300: loss 0.582214\n",
      "iteration 244 / 300: loss 0.601955\n",
      "iteration 244 / 300: loss 0.608956\n",
      "iteration 244 / 300: loss 0.601794\n",
      "iteration 244 / 300: loss 0.607944\n",
      "iteration 244 / 300: loss 0.620236\n",
      "iteration 244 / 300: loss 0.584817\n",
      "iteration 244 / 300: loss 0.583721\n",
      "iteration 244 / 300: loss 0.628849\n",
      "iteration 244 / 300: loss 0.609399\n",
      "iteration 244 / 300: loss 0.606265\n",
      "iteration 244 / 300: loss 0.599034\n",
      "iteration 244 / 300: loss 0.615876\n",
      "iteration 244 / 300: loss 0.596489\n",
      "iteration 244 / 300: loss 0.581430\n",
      "iteration 244 / 300: loss 0.609807\n",
      "iteration 244 / 300: loss 0.608125\n",
      "iteration 244 / 300: loss 0.598224\n",
      "iteration 244 / 300: loss 0.592022\n",
      "iteration 244 / 300: loss 0.611031\n",
      "iteration 244 / 300: loss 0.598550\n",
      "iteration 244 / 300: loss 0.581382\n",
      "iteration 244 / 300: loss 0.609580\n",
      "iteration 245 / 300: loss 0.578384\n",
      "iteration 245 / 300: loss 0.596214\n",
      "iteration 245 / 300: loss 0.569455\n",
      "iteration 245 / 300: loss 0.597849\n",
      "iteration 245 / 300: loss 0.598940\n",
      "iteration 245 / 300: loss 0.603876\n",
      "iteration 245 / 300: loss 0.615261\n",
      "iteration 245 / 300: loss 0.588227\n",
      "iteration 245 / 300: loss 0.627171\n",
      "iteration 245 / 300: loss 0.592600\n",
      "iteration 245 / 300: loss 0.621500\n",
      "iteration 245 / 300: loss 0.593093\n",
      "iteration 245 / 300: loss 0.600541\n",
      "iteration 245 / 300: loss 0.571000\n",
      "iteration 245 / 300: loss 0.592911\n",
      "iteration 245 / 300: loss 0.600043\n",
      "iteration 245 / 300: loss 0.598053\n",
      "iteration 245 / 300: loss 0.583712\n",
      "iteration 245 / 300: loss 0.614355\n",
      "iteration 245 / 300: loss 0.591285\n",
      "iteration 245 / 300: loss 0.591391\n",
      "iteration 245 / 300: loss 0.594005\n",
      "iteration 245 / 300: loss 0.596735\n",
      "iteration 245 / 300: loss 0.596712\n",
      "iteration 245 / 300: loss 0.611735\n",
      "iteration 245 / 300: loss 0.607258\n",
      "iteration 245 / 300: loss 0.597031\n",
      "iteration 245 / 300: loss 0.596301\n",
      "iteration 245 / 300: loss 0.627391\n",
      "iteration 245 / 300: loss 0.601584\n",
      "iteration 245 / 300: loss 0.599923\n",
      "iteration 245 / 300: loss 0.621952\n",
      "iteration 245 / 300: loss 0.581435\n",
      "iteration 245 / 300: loss 0.599604\n",
      "iteration 245 / 300: loss 0.591182\n",
      "iteration 245 / 300: loss 0.599919\n",
      "iteration 245 / 300: loss 0.596015\n",
      "iteration 245 / 300: loss 0.590760\n",
      "iteration 245 / 300: loss 0.591961\n",
      "iteration 245 / 300: loss 0.615468\n",
      "iteration 245 / 300: loss 0.621360\n",
      "iteration 245 / 300: loss 0.587267\n",
      "iteration 245 / 300: loss 0.582483\n",
      "iteration 245 / 300: loss 0.585572\n",
      "iteration 245 / 300: loss 0.603666\n",
      "iteration 245 / 300: loss 0.585192\n",
      "iteration 245 / 300: loss 0.578880\n",
      "iteration 245 / 300: loss 0.576418\n",
      "iteration 245 / 300: loss 0.574097\n",
      "iteration 245 / 300: loss 0.600500\n",
      "iteration 245 / 300: loss 0.584490\n",
      "iteration 245 / 300: loss 0.584834\n",
      "iteration 245 / 300: loss 0.568323\n",
      "iteration 245 / 300: loss 0.592025\n",
      "iteration 245 / 300: loss 0.612116\n",
      "iteration 245 / 300: loss 0.608923\n",
      "iteration 245 / 300: loss 0.607613\n",
      "iteration 245 / 300: loss 0.595533\n",
      "iteration 245 / 300: loss 0.592837\n",
      "iteration 245 / 300: loss 0.597988\n",
      "iteration 245 / 300: loss 0.597677\n",
      "iteration 245 / 300: loss 0.600953\n",
      "iteration 245 / 300: loss 0.597422\n",
      "iteration 245 / 300: loss 0.598776\n",
      "iteration 245 / 300: loss 0.587806\n",
      "iteration 245 / 300: loss 0.600499\n",
      "iteration 245 / 300: loss 0.599650\n",
      "iteration 245 / 300: loss 0.617540\n",
      "iteration 245 / 300: loss 0.598875\n",
      "iteration 245 / 300: loss 0.600801\n",
      "iteration 245 / 300: loss 0.605305\n",
      "iteration 245 / 300: loss 0.598592\n",
      "iteration 245 / 300: loss 0.591474\n",
      "iteration 245 / 300: loss 0.580382\n",
      "iteration 245 / 300: loss 0.598221\n",
      "iteration 245 / 300: loss 0.611685\n",
      "iteration 245 / 300: loss 0.613219\n",
      "iteration 245 / 300: loss 0.582214\n",
      "iteration 245 / 300: loss 0.601955\n",
      "iteration 245 / 300: loss 0.608956\n",
      "iteration 245 / 300: loss 0.601794\n",
      "iteration 245 / 300: loss 0.607944\n",
      "iteration 245 / 300: loss 0.620236\n",
      "iteration 245 / 300: loss 0.584817\n",
      "iteration 245 / 300: loss 0.583721\n",
      "iteration 245 / 300: loss 0.628849\n",
      "iteration 245 / 300: loss 0.609399\n",
      "iteration 245 / 300: loss 0.606265\n",
      "iteration 245 / 300: loss 0.599034\n",
      "iteration 245 / 300: loss 0.615876\n",
      "iteration 245 / 300: loss 0.596489\n",
      "iteration 245 / 300: loss 0.581430\n",
      "iteration 245 / 300: loss 0.609807\n",
      "iteration 245 / 300: loss 0.608125\n",
      "iteration 245 / 300: loss 0.598224\n",
      "iteration 245 / 300: loss 0.592022\n",
      "iteration 245 / 300: loss 0.611031\n",
      "iteration 245 / 300: loss 0.598550\n",
      "iteration 245 / 300: loss 0.581382\n",
      "iteration 245 / 300: loss 0.609580\n",
      "iteration 246 / 300: loss 0.578384\n",
      "iteration 246 / 300: loss 0.596214\n",
      "iteration 246 / 300: loss 0.569455\n",
      "iteration 246 / 300: loss 0.597849\n",
      "iteration 246 / 300: loss 0.598940\n",
      "iteration 246 / 300: loss 0.603876\n",
      "iteration 246 / 300: loss 0.615261\n",
      "iteration 246 / 300: loss 0.588227\n",
      "iteration 246 / 300: loss 0.627171\n",
      "iteration 246 / 300: loss 0.592600\n",
      "iteration 246 / 300: loss 0.621500\n",
      "iteration 246 / 300: loss 0.593093\n",
      "iteration 246 / 300: loss 0.600541\n",
      "iteration 246 / 300: loss 0.571000\n",
      "iteration 246 / 300: loss 0.592911\n",
      "iteration 246 / 300: loss 0.600043\n",
      "iteration 246 / 300: loss 0.598053\n",
      "iteration 246 / 300: loss 0.583712\n",
      "iteration 246 / 300: loss 0.614355\n",
      "iteration 246 / 300: loss 0.591285\n",
      "iteration 246 / 300: loss 0.591391\n",
      "iteration 246 / 300: loss 0.594005\n",
      "iteration 246 / 300: loss 0.596735\n",
      "iteration 246 / 300: loss 0.596712\n",
      "iteration 246 / 300: loss 0.611735\n",
      "iteration 246 / 300: loss 0.607258\n",
      "iteration 246 / 300: loss 0.597031\n",
      "iteration 246 / 300: loss 0.596301\n",
      "iteration 246 / 300: loss 0.627391\n",
      "iteration 246 / 300: loss 0.601584\n",
      "iteration 246 / 300: loss 0.599923\n",
      "iteration 246 / 300: loss 0.621952\n",
      "iteration 246 / 300: loss 0.581435\n",
      "iteration 246 / 300: loss 0.599604\n",
      "iteration 246 / 300: loss 0.591182\n",
      "iteration 246 / 300: loss 0.599919\n",
      "iteration 246 / 300: loss 0.596015\n",
      "iteration 246 / 300: loss 0.590760\n",
      "iteration 246 / 300: loss 0.591961\n",
      "iteration 246 / 300: loss 0.615468\n",
      "iteration 246 / 300: loss 0.621360\n",
      "iteration 246 / 300: loss 0.587267\n",
      "iteration 246 / 300: loss 0.582483\n",
      "iteration 246 / 300: loss 0.585572\n",
      "iteration 246 / 300: loss 0.603666\n",
      "iteration 246 / 300: loss 0.585192\n",
      "iteration 246 / 300: loss 0.578880\n",
      "iteration 246 / 300: loss 0.576418\n",
      "iteration 246 / 300: loss 0.574097\n",
      "iteration 246 / 300: loss 0.600500\n",
      "iteration 246 / 300: loss 0.584490\n",
      "iteration 246 / 300: loss 0.584834\n",
      "iteration 246 / 300: loss 0.568323\n",
      "iteration 246 / 300: loss 0.592025\n",
      "iteration 246 / 300: loss 0.612116\n",
      "iteration 246 / 300: loss 0.608923\n",
      "iteration 246 / 300: loss 0.607613\n",
      "iteration 246 / 300: loss 0.595533\n",
      "iteration 246 / 300: loss 0.592837\n",
      "iteration 246 / 300: loss 0.597988\n",
      "iteration 246 / 300: loss 0.597677\n",
      "iteration 246 / 300: loss 0.600953\n",
      "iteration 246 / 300: loss 0.597422\n",
      "iteration 246 / 300: loss 0.598776\n",
      "iteration 246 / 300: loss 0.587806\n",
      "iteration 246 / 300: loss 0.600499\n",
      "iteration 246 / 300: loss 0.599650\n",
      "iteration 246 / 300: loss 0.617540\n",
      "iteration 246 / 300: loss 0.598875\n",
      "iteration 246 / 300: loss 0.600801\n",
      "iteration 246 / 300: loss 0.605305\n",
      "iteration 246 / 300: loss 0.598592\n",
      "iteration 246 / 300: loss 0.591474\n",
      "iteration 246 / 300: loss 0.580382\n",
      "iteration 246 / 300: loss 0.598221\n",
      "iteration 246 / 300: loss 0.611685\n",
      "iteration 246 / 300: loss 0.613219\n",
      "iteration 246 / 300: loss 0.582214\n",
      "iteration 246 / 300: loss 0.601955\n",
      "iteration 246 / 300: loss 0.608956\n",
      "iteration 246 / 300: loss 0.601794\n",
      "iteration 246 / 300: loss 0.607944\n",
      "iteration 246 / 300: loss 0.620236\n",
      "iteration 246 / 300: loss 0.584817\n",
      "iteration 246 / 300: loss 0.583721\n",
      "iteration 246 / 300: loss 0.628849\n",
      "iteration 246 / 300: loss 0.609399\n",
      "iteration 246 / 300: loss 0.606265\n",
      "iteration 246 / 300: loss 0.599034\n",
      "iteration 246 / 300: loss 0.615876\n",
      "iteration 246 / 300: loss 0.596489\n",
      "iteration 246 / 300: loss 0.581430\n",
      "iteration 246 / 300: loss 0.609807\n",
      "iteration 246 / 300: loss 0.608125\n",
      "iteration 246 / 300: loss 0.598224\n",
      "iteration 246 / 300: loss 0.592022\n",
      "iteration 246 / 300: loss 0.611031\n",
      "iteration 246 / 300: loss 0.598550\n",
      "iteration 246 / 300: loss 0.581382\n",
      "iteration 246 / 300: loss 0.609580\n",
      "iteration 247 / 300: loss 0.578384\n",
      "iteration 247 / 300: loss 0.596214\n",
      "iteration 247 / 300: loss 0.569455\n",
      "iteration 247 / 300: loss 0.597849\n",
      "iteration 247 / 300: loss 0.598940\n",
      "iteration 247 / 300: loss 0.603876\n",
      "iteration 247 / 300: loss 0.615261\n",
      "iteration 247 / 300: loss 0.588227\n",
      "iteration 247 / 300: loss 0.627171\n",
      "iteration 247 / 300: loss 0.592600\n",
      "iteration 247 / 300: loss 0.621500\n",
      "iteration 247 / 300: loss 0.593093\n",
      "iteration 247 / 300: loss 0.600541\n",
      "iteration 247 / 300: loss 0.571000\n",
      "iteration 247 / 300: loss 0.592911\n",
      "iteration 247 / 300: loss 0.600043\n",
      "iteration 247 / 300: loss 0.598053\n",
      "iteration 247 / 300: loss 0.583712\n",
      "iteration 247 / 300: loss 0.614355\n",
      "iteration 247 / 300: loss 0.591285\n",
      "iteration 247 / 300: loss 0.591391\n",
      "iteration 247 / 300: loss 0.594005\n",
      "iteration 247 / 300: loss 0.596735\n",
      "iteration 247 / 300: loss 0.596712\n",
      "iteration 247 / 300: loss 0.611735\n",
      "iteration 247 / 300: loss 0.607258\n",
      "iteration 247 / 300: loss 0.597031\n",
      "iteration 247 / 300: loss 0.596301\n",
      "iteration 247 / 300: loss 0.627391\n",
      "iteration 247 / 300: loss 0.601584\n",
      "iteration 247 / 300: loss 0.599923\n",
      "iteration 247 / 300: loss 0.621952\n",
      "iteration 247 / 300: loss 0.581435\n",
      "iteration 247 / 300: loss 0.599604\n",
      "iteration 247 / 300: loss 0.591182\n",
      "iteration 247 / 300: loss 0.599919\n",
      "iteration 247 / 300: loss 0.596015\n",
      "iteration 247 / 300: loss 0.590760\n",
      "iteration 247 / 300: loss 0.591961\n",
      "iteration 247 / 300: loss 0.615468\n",
      "iteration 247 / 300: loss 0.621360\n",
      "iteration 247 / 300: loss 0.587267\n",
      "iteration 247 / 300: loss 0.582483\n",
      "iteration 247 / 300: loss 0.585572\n",
      "iteration 247 / 300: loss 0.603666\n",
      "iteration 247 / 300: loss 0.585192\n",
      "iteration 247 / 300: loss 0.578880\n",
      "iteration 247 / 300: loss 0.576418\n",
      "iteration 247 / 300: loss 0.574097\n",
      "iteration 247 / 300: loss 0.600500\n",
      "iteration 247 / 300: loss 0.584490\n",
      "iteration 247 / 300: loss 0.584834\n",
      "iteration 247 / 300: loss 0.568323\n",
      "iteration 247 / 300: loss 0.592025\n",
      "iteration 247 / 300: loss 0.612116\n",
      "iteration 247 / 300: loss 0.608923\n",
      "iteration 247 / 300: loss 0.607613\n",
      "iteration 247 / 300: loss 0.595533\n",
      "iteration 247 / 300: loss 0.592837\n",
      "iteration 247 / 300: loss 0.597988\n",
      "iteration 247 / 300: loss 0.597677\n",
      "iteration 247 / 300: loss 0.600953\n",
      "iteration 247 / 300: loss 0.597422\n",
      "iteration 247 / 300: loss 0.598776\n",
      "iteration 247 / 300: loss 0.587806\n",
      "iteration 247 / 300: loss 0.600499\n",
      "iteration 247 / 300: loss 0.599650\n",
      "iteration 247 / 300: loss 0.617540\n",
      "iteration 247 / 300: loss 0.598875\n",
      "iteration 247 / 300: loss 0.600801\n",
      "iteration 247 / 300: loss 0.605305\n",
      "iteration 247 / 300: loss 0.598592\n",
      "iteration 247 / 300: loss 0.591474\n",
      "iteration 247 / 300: loss 0.580382\n",
      "iteration 247 / 300: loss 0.598221\n",
      "iteration 247 / 300: loss 0.611685\n",
      "iteration 247 / 300: loss 0.613219\n",
      "iteration 247 / 300: loss 0.582214\n",
      "iteration 247 / 300: loss 0.601955\n",
      "iteration 247 / 300: loss 0.608956\n",
      "iteration 247 / 300: loss 0.601794\n",
      "iteration 247 / 300: loss 0.607944\n",
      "iteration 247 / 300: loss 0.620236\n",
      "iteration 247 / 300: loss 0.584817\n",
      "iteration 247 / 300: loss 0.583721\n",
      "iteration 247 / 300: loss 0.628849\n",
      "iteration 247 / 300: loss 0.609399\n",
      "iteration 247 / 300: loss 0.606265\n",
      "iteration 247 / 300: loss 0.599034\n",
      "iteration 247 / 300: loss 0.615876\n",
      "iteration 247 / 300: loss 0.596489\n",
      "iteration 247 / 300: loss 0.581430\n",
      "iteration 247 / 300: loss 0.609807\n",
      "iteration 247 / 300: loss 0.608125\n",
      "iteration 247 / 300: loss 0.598224\n",
      "iteration 247 / 300: loss 0.592022\n",
      "iteration 247 / 300: loss 0.611031\n",
      "iteration 247 / 300: loss 0.598550\n",
      "iteration 247 / 300: loss 0.581382\n",
      "iteration 247 / 300: loss 0.609580\n",
      "iteration 248 / 300: loss 0.578384\n",
      "iteration 248 / 300: loss 0.596214\n",
      "iteration 248 / 300: loss 0.569455\n",
      "iteration 248 / 300: loss 0.597849\n",
      "iteration 248 / 300: loss 0.598940\n",
      "iteration 248 / 300: loss 0.603876\n",
      "iteration 248 / 300: loss 0.615261\n",
      "iteration 248 / 300: loss 0.588227\n",
      "iteration 248 / 300: loss 0.627171\n",
      "iteration 248 / 300: loss 0.592600\n",
      "iteration 248 / 300: loss 0.621500\n",
      "iteration 248 / 300: loss 0.593093\n",
      "iteration 248 / 300: loss 0.600541\n",
      "iteration 248 / 300: loss 0.571000\n",
      "iteration 248 / 300: loss 0.592911\n",
      "iteration 248 / 300: loss 0.600043\n",
      "iteration 248 / 300: loss 0.598053\n",
      "iteration 248 / 300: loss 0.583712\n",
      "iteration 248 / 300: loss 0.614355\n",
      "iteration 248 / 300: loss 0.591285\n",
      "iteration 248 / 300: loss 0.591391\n",
      "iteration 248 / 300: loss 0.594005\n",
      "iteration 248 / 300: loss 0.596735\n",
      "iteration 248 / 300: loss 0.596712\n",
      "iteration 248 / 300: loss 0.611735\n",
      "iteration 248 / 300: loss 0.607258\n",
      "iteration 248 / 300: loss 0.597031\n",
      "iteration 248 / 300: loss 0.596301\n",
      "iteration 248 / 300: loss 0.627391\n",
      "iteration 248 / 300: loss 0.601584\n",
      "iteration 248 / 300: loss 0.599923\n",
      "iteration 248 / 300: loss 0.621952\n",
      "iteration 248 / 300: loss 0.581435\n",
      "iteration 248 / 300: loss 0.599604\n",
      "iteration 248 / 300: loss 0.591182\n",
      "iteration 248 / 300: loss 0.599919\n",
      "iteration 248 / 300: loss 0.596015\n",
      "iteration 248 / 300: loss 0.590760\n",
      "iteration 248 / 300: loss 0.591961\n",
      "iteration 248 / 300: loss 0.615468\n",
      "iteration 248 / 300: loss 0.621360\n",
      "iteration 248 / 300: loss 0.587267\n",
      "iteration 248 / 300: loss 0.582483\n",
      "iteration 248 / 300: loss 0.585572\n",
      "iteration 248 / 300: loss 0.603666\n",
      "iteration 248 / 300: loss 0.585192\n",
      "iteration 248 / 300: loss 0.578880\n",
      "iteration 248 / 300: loss 0.576418\n",
      "iteration 248 / 300: loss 0.574097\n",
      "iteration 248 / 300: loss 0.600500\n",
      "iteration 248 / 300: loss 0.584490\n",
      "iteration 248 / 300: loss 0.584834\n",
      "iteration 248 / 300: loss 0.568323\n",
      "iteration 248 / 300: loss 0.592025\n",
      "iteration 248 / 300: loss 0.612116\n",
      "iteration 248 / 300: loss 0.608923\n",
      "iteration 248 / 300: loss 0.607613\n",
      "iteration 248 / 300: loss 0.595533\n",
      "iteration 248 / 300: loss 0.592837\n",
      "iteration 248 / 300: loss 0.597988\n",
      "iteration 248 / 300: loss 0.597677\n",
      "iteration 248 / 300: loss 0.600953\n",
      "iteration 248 / 300: loss 0.597422\n",
      "iteration 248 / 300: loss 0.598776\n",
      "iteration 248 / 300: loss 0.587806\n",
      "iteration 248 / 300: loss 0.600499\n",
      "iteration 248 / 300: loss 0.599650\n",
      "iteration 248 / 300: loss 0.617540\n",
      "iteration 248 / 300: loss 0.598875\n",
      "iteration 248 / 300: loss 0.600801\n",
      "iteration 248 / 300: loss 0.605305\n",
      "iteration 248 / 300: loss 0.598592\n",
      "iteration 248 / 300: loss 0.591474\n",
      "iteration 248 / 300: loss 0.580382\n",
      "iteration 248 / 300: loss 0.598221\n",
      "iteration 248 / 300: loss 0.611685\n",
      "iteration 248 / 300: loss 0.613219\n",
      "iteration 248 / 300: loss 0.582214\n",
      "iteration 248 / 300: loss 0.601955\n",
      "iteration 248 / 300: loss 0.608956\n",
      "iteration 248 / 300: loss 0.601794\n",
      "iteration 248 / 300: loss 0.607944\n",
      "iteration 248 / 300: loss 0.620236\n",
      "iteration 248 / 300: loss 0.584817\n",
      "iteration 248 / 300: loss 0.583721\n",
      "iteration 248 / 300: loss 0.628849\n",
      "iteration 248 / 300: loss 0.609399\n",
      "iteration 248 / 300: loss 0.606265\n",
      "iteration 248 / 300: loss 0.599034\n",
      "iteration 248 / 300: loss 0.615876\n",
      "iteration 248 / 300: loss 0.596489\n",
      "iteration 248 / 300: loss 0.581430\n",
      "iteration 248 / 300: loss 0.609807\n",
      "iteration 248 / 300: loss 0.608125\n",
      "iteration 248 / 300: loss 0.598224\n",
      "iteration 248 / 300: loss 0.592022\n",
      "iteration 248 / 300: loss 0.611031\n",
      "iteration 248 / 300: loss 0.598550\n",
      "iteration 248 / 300: loss 0.581382\n",
      "iteration 248 / 300: loss 0.609580\n",
      "iteration 249 / 300: loss 0.578384\n",
      "iteration 249 / 300: loss 0.596214\n",
      "iteration 249 / 300: loss 0.569455\n",
      "iteration 249 / 300: loss 0.597849\n",
      "iteration 249 / 300: loss 0.598940\n",
      "iteration 249 / 300: loss 0.603876\n",
      "iteration 249 / 300: loss 0.615261\n",
      "iteration 249 / 300: loss 0.588227\n",
      "iteration 249 / 300: loss 0.627171\n",
      "iteration 249 / 300: loss 0.592600\n",
      "iteration 249 / 300: loss 0.621500\n",
      "iteration 249 / 300: loss 0.593093\n",
      "iteration 249 / 300: loss 0.600541\n",
      "iteration 249 / 300: loss 0.571000\n",
      "iteration 249 / 300: loss 0.592911\n",
      "iteration 249 / 300: loss 0.600043\n",
      "iteration 249 / 300: loss 0.598053\n",
      "iteration 249 / 300: loss 0.583712\n",
      "iteration 249 / 300: loss 0.614355\n",
      "iteration 249 / 300: loss 0.591285\n",
      "iteration 249 / 300: loss 0.591391\n",
      "iteration 249 / 300: loss 0.594005\n",
      "iteration 249 / 300: loss 0.596735\n",
      "iteration 249 / 300: loss 0.596712\n",
      "iteration 249 / 300: loss 0.611735\n",
      "iteration 249 / 300: loss 0.607258\n",
      "iteration 249 / 300: loss 0.597031\n",
      "iteration 249 / 300: loss 0.596301\n",
      "iteration 249 / 300: loss 0.627391\n",
      "iteration 249 / 300: loss 0.601584\n",
      "iteration 249 / 300: loss 0.599923\n",
      "iteration 249 / 300: loss 0.621952\n",
      "iteration 249 / 300: loss 0.581435\n",
      "iteration 249 / 300: loss 0.599604\n",
      "iteration 249 / 300: loss 0.591182\n",
      "iteration 249 / 300: loss 0.599919\n",
      "iteration 249 / 300: loss 0.596015\n",
      "iteration 249 / 300: loss 0.590760\n",
      "iteration 249 / 300: loss 0.591961\n",
      "iteration 249 / 300: loss 0.615468\n",
      "iteration 249 / 300: loss 0.621360\n",
      "iteration 249 / 300: loss 0.587267\n",
      "iteration 249 / 300: loss 0.582483\n",
      "iteration 249 / 300: loss 0.585572\n",
      "iteration 249 / 300: loss 0.603666\n",
      "iteration 249 / 300: loss 0.585192\n",
      "iteration 249 / 300: loss 0.578880\n",
      "iteration 249 / 300: loss 0.576418\n",
      "iteration 249 / 300: loss 0.574097\n",
      "iteration 249 / 300: loss 0.600500\n",
      "iteration 249 / 300: loss 0.584490\n",
      "iteration 249 / 300: loss 0.584834\n",
      "iteration 249 / 300: loss 0.568323\n",
      "iteration 249 / 300: loss 0.592025\n",
      "iteration 249 / 300: loss 0.612116\n",
      "iteration 249 / 300: loss 0.608923\n",
      "iteration 249 / 300: loss 0.607613\n",
      "iteration 249 / 300: loss 0.595533\n",
      "iteration 249 / 300: loss 0.592837\n",
      "iteration 249 / 300: loss 0.597988\n",
      "iteration 249 / 300: loss 0.597677\n",
      "iteration 249 / 300: loss 0.600953\n",
      "iteration 249 / 300: loss 0.597422\n",
      "iteration 249 / 300: loss 0.598776\n",
      "iteration 249 / 300: loss 0.587806\n",
      "iteration 249 / 300: loss 0.600499\n",
      "iteration 249 / 300: loss 0.599650\n",
      "iteration 249 / 300: loss 0.617540\n",
      "iteration 249 / 300: loss 0.598875\n",
      "iteration 249 / 300: loss 0.600801\n",
      "iteration 249 / 300: loss 0.605305\n",
      "iteration 249 / 300: loss 0.598592\n",
      "iteration 249 / 300: loss 0.591474\n",
      "iteration 249 / 300: loss 0.580382\n",
      "iteration 249 / 300: loss 0.598221\n",
      "iteration 249 / 300: loss 0.611685\n",
      "iteration 249 / 300: loss 0.613219\n",
      "iteration 249 / 300: loss 0.582214\n",
      "iteration 249 / 300: loss 0.601955\n",
      "iteration 249 / 300: loss 0.608956\n",
      "iteration 249 / 300: loss 0.601794\n",
      "iteration 249 / 300: loss 0.607944\n",
      "iteration 249 / 300: loss 0.620236\n",
      "iteration 249 / 300: loss 0.584817\n",
      "iteration 249 / 300: loss 0.583721\n",
      "iteration 249 / 300: loss 0.628849\n",
      "iteration 249 / 300: loss 0.609399\n",
      "iteration 249 / 300: loss 0.606265\n",
      "iteration 249 / 300: loss 0.599034\n",
      "iteration 249 / 300: loss 0.615876\n",
      "iteration 249 / 300: loss 0.596489\n",
      "iteration 249 / 300: loss 0.581430\n",
      "iteration 249 / 300: loss 0.609807\n",
      "iteration 249 / 300: loss 0.608125\n",
      "iteration 249 / 300: loss 0.598224\n",
      "iteration 249 / 300: loss 0.592022\n",
      "iteration 249 / 300: loss 0.611031\n",
      "iteration 249 / 300: loss 0.598550\n",
      "iteration 249 / 300: loss 0.581382\n",
      "iteration 249 / 300: loss 0.609580\n",
      "iteration 250 / 300: loss 0.578384\n",
      "iteration 250 / 300: loss 0.596214\n",
      "iteration 250 / 300: loss 0.569455\n",
      "iteration 250 / 300: loss 0.597849\n",
      "iteration 250 / 300: loss 0.598940\n",
      "iteration 250 / 300: loss 0.603876\n",
      "iteration 250 / 300: loss 0.615261\n",
      "iteration 250 / 300: loss 0.588227\n",
      "iteration 250 / 300: loss 0.627171\n",
      "iteration 250 / 300: loss 0.592600\n",
      "iteration 250 / 300: loss 0.621500\n",
      "iteration 250 / 300: loss 0.593093\n",
      "iteration 250 / 300: loss 0.600541\n",
      "iteration 250 / 300: loss 0.571000\n",
      "iteration 250 / 300: loss 0.592911\n",
      "iteration 250 / 300: loss 0.600043\n",
      "iteration 250 / 300: loss 0.598053\n",
      "iteration 250 / 300: loss 0.583712\n",
      "iteration 250 / 300: loss 0.614355\n",
      "iteration 250 / 300: loss 0.591285\n",
      "iteration 250 / 300: loss 0.591391\n",
      "iteration 250 / 300: loss 0.594005\n",
      "iteration 250 / 300: loss 0.596735\n",
      "iteration 250 / 300: loss 0.596712\n",
      "iteration 250 / 300: loss 0.611735\n",
      "iteration 250 / 300: loss 0.607258\n",
      "iteration 250 / 300: loss 0.597031\n",
      "iteration 250 / 300: loss 0.596301\n",
      "iteration 250 / 300: loss 0.627391\n",
      "iteration 250 / 300: loss 0.601584\n",
      "iteration 250 / 300: loss 0.599923\n",
      "iteration 250 / 300: loss 0.621952\n",
      "iteration 250 / 300: loss 0.581435\n",
      "iteration 250 / 300: loss 0.599604\n",
      "iteration 250 / 300: loss 0.591182\n",
      "iteration 250 / 300: loss 0.599919\n",
      "iteration 250 / 300: loss 0.596015\n",
      "iteration 250 / 300: loss 0.590760\n",
      "iteration 250 / 300: loss 0.591961\n",
      "iteration 250 / 300: loss 0.615468\n",
      "iteration 250 / 300: loss 0.621360\n",
      "iteration 250 / 300: loss 0.587267\n",
      "iteration 250 / 300: loss 0.582483\n",
      "iteration 250 / 300: loss 0.585572\n",
      "iteration 250 / 300: loss 0.603666\n",
      "iteration 250 / 300: loss 0.585192\n",
      "iteration 250 / 300: loss 0.578880\n",
      "iteration 250 / 300: loss 0.576418\n",
      "iteration 250 / 300: loss 0.574097\n",
      "iteration 250 / 300: loss 0.600500\n",
      "iteration 250 / 300: loss 0.584490\n",
      "iteration 250 / 300: loss 0.584834\n",
      "iteration 250 / 300: loss 0.568323\n",
      "iteration 250 / 300: loss 0.592025\n",
      "iteration 250 / 300: loss 0.612116\n",
      "iteration 250 / 300: loss 0.608923\n",
      "iteration 250 / 300: loss 0.607613\n",
      "iteration 250 / 300: loss 0.595533\n",
      "iteration 250 / 300: loss 0.592837\n",
      "iteration 250 / 300: loss 0.597988\n",
      "iteration 250 / 300: loss 0.597677\n",
      "iteration 250 / 300: loss 0.600953\n",
      "iteration 250 / 300: loss 0.597422\n",
      "iteration 250 / 300: loss 0.598776\n",
      "iteration 250 / 300: loss 0.587806\n",
      "iteration 250 / 300: loss 0.600499\n",
      "iteration 250 / 300: loss 0.599650\n",
      "iteration 250 / 300: loss 0.617540\n",
      "iteration 250 / 300: loss 0.598875\n",
      "iteration 250 / 300: loss 0.600801\n",
      "iteration 250 / 300: loss 0.605305\n",
      "iteration 250 / 300: loss 0.598592\n",
      "iteration 250 / 300: loss 0.591474\n",
      "iteration 250 / 300: loss 0.580382\n",
      "iteration 250 / 300: loss 0.598221\n",
      "iteration 250 / 300: loss 0.611685\n",
      "iteration 250 / 300: loss 0.613219\n",
      "iteration 250 / 300: loss 0.582214\n",
      "iteration 250 / 300: loss 0.601955\n",
      "iteration 250 / 300: loss 0.608956\n",
      "iteration 250 / 300: loss 0.601794\n",
      "iteration 250 / 300: loss 0.607944\n",
      "iteration 250 / 300: loss 0.620236\n",
      "iteration 250 / 300: loss 0.584817\n",
      "iteration 250 / 300: loss 0.583721\n",
      "iteration 250 / 300: loss 0.628849\n",
      "iteration 250 / 300: loss 0.609399\n",
      "iteration 250 / 300: loss 0.606265\n",
      "iteration 250 / 300: loss 0.599034\n",
      "iteration 250 / 300: loss 0.615876\n",
      "iteration 250 / 300: loss 0.596489\n",
      "iteration 250 / 300: loss 0.581430\n",
      "iteration 250 / 300: loss 0.609807\n",
      "iteration 250 / 300: loss 0.608125\n",
      "iteration 250 / 300: loss 0.598224\n",
      "iteration 250 / 300: loss 0.592022\n",
      "iteration 250 / 300: loss 0.611031\n",
      "iteration 250 / 300: loss 0.598550\n",
      "iteration 250 / 300: loss 0.581382\n",
      "iteration 250 / 300: loss 0.609580\n",
      "iteration 251 / 300: loss 0.578384\n",
      "iteration 251 / 300: loss 0.596214\n",
      "iteration 251 / 300: loss 0.569455\n",
      "iteration 251 / 300: loss 0.597849\n",
      "iteration 251 / 300: loss 0.598940\n",
      "iteration 251 / 300: loss 0.603876\n",
      "iteration 251 / 300: loss 0.615261\n",
      "iteration 251 / 300: loss 0.588227\n",
      "iteration 251 / 300: loss 0.627171\n",
      "iteration 251 / 300: loss 0.592600\n",
      "iteration 251 / 300: loss 0.621500\n",
      "iteration 251 / 300: loss 0.593093\n",
      "iteration 251 / 300: loss 0.600541\n",
      "iteration 251 / 300: loss 0.571000\n",
      "iteration 251 / 300: loss 0.592911\n",
      "iteration 251 / 300: loss 0.600043\n",
      "iteration 251 / 300: loss 0.598053\n",
      "iteration 251 / 300: loss 0.583712\n",
      "iteration 251 / 300: loss 0.614355\n",
      "iteration 251 / 300: loss 0.591285\n",
      "iteration 251 / 300: loss 0.591391\n",
      "iteration 251 / 300: loss 0.594005\n",
      "iteration 251 / 300: loss 0.596735\n",
      "iteration 251 / 300: loss 0.596712\n",
      "iteration 251 / 300: loss 0.611735\n",
      "iteration 251 / 300: loss 0.607258\n",
      "iteration 251 / 300: loss 0.597031\n",
      "iteration 251 / 300: loss 0.596301\n",
      "iteration 251 / 300: loss 0.627391\n",
      "iteration 251 / 300: loss 0.601584\n",
      "iteration 251 / 300: loss 0.599923\n",
      "iteration 251 / 300: loss 0.621952\n",
      "iteration 251 / 300: loss 0.581435\n",
      "iteration 251 / 300: loss 0.599604\n",
      "iteration 251 / 300: loss 0.591182\n",
      "iteration 251 / 300: loss 0.599919\n",
      "iteration 251 / 300: loss 0.596015\n",
      "iteration 251 / 300: loss 0.590760\n",
      "iteration 251 / 300: loss 0.591961\n",
      "iteration 251 / 300: loss 0.615468\n",
      "iteration 251 / 300: loss 0.621360\n",
      "iteration 251 / 300: loss 0.587267\n",
      "iteration 251 / 300: loss 0.582483\n",
      "iteration 251 / 300: loss 0.585572\n",
      "iteration 251 / 300: loss 0.603666\n",
      "iteration 251 / 300: loss 0.585192\n",
      "iteration 251 / 300: loss 0.578880\n",
      "iteration 251 / 300: loss 0.576418\n",
      "iteration 251 / 300: loss 0.574097\n",
      "iteration 251 / 300: loss 0.600500\n",
      "iteration 251 / 300: loss 0.584490\n",
      "iteration 251 / 300: loss 0.584834\n",
      "iteration 251 / 300: loss 0.568323\n",
      "iteration 251 / 300: loss 0.592025\n",
      "iteration 251 / 300: loss 0.612116\n",
      "iteration 251 / 300: loss 0.608923\n",
      "iteration 251 / 300: loss 0.607613\n",
      "iteration 251 / 300: loss 0.595533\n",
      "iteration 251 / 300: loss 0.592837\n",
      "iteration 251 / 300: loss 0.597988\n",
      "iteration 251 / 300: loss 0.597677\n",
      "iteration 251 / 300: loss 0.600953\n",
      "iteration 251 / 300: loss 0.597422\n",
      "iteration 251 / 300: loss 0.598776\n",
      "iteration 251 / 300: loss 0.587806\n",
      "iteration 251 / 300: loss 0.600499\n",
      "iteration 251 / 300: loss 0.599650\n",
      "iteration 251 / 300: loss 0.617540\n",
      "iteration 251 / 300: loss 0.598875\n",
      "iteration 251 / 300: loss 0.600801\n",
      "iteration 251 / 300: loss 0.605305\n",
      "iteration 251 / 300: loss 0.598592\n",
      "iteration 251 / 300: loss 0.591474\n",
      "iteration 251 / 300: loss 0.580382\n",
      "iteration 251 / 300: loss 0.598221\n",
      "iteration 251 / 300: loss 0.611685\n",
      "iteration 251 / 300: loss 0.613219\n",
      "iteration 251 / 300: loss 0.582214\n",
      "iteration 251 / 300: loss 0.601955\n",
      "iteration 251 / 300: loss 0.608956\n",
      "iteration 251 / 300: loss 0.601794\n",
      "iteration 251 / 300: loss 0.607944\n",
      "iteration 251 / 300: loss 0.620236\n",
      "iteration 251 / 300: loss 0.584817\n",
      "iteration 251 / 300: loss 0.583721\n",
      "iteration 251 / 300: loss 0.628849\n",
      "iteration 251 / 300: loss 0.609399\n",
      "iteration 251 / 300: loss 0.606265\n",
      "iteration 251 / 300: loss 0.599034\n",
      "iteration 251 / 300: loss 0.615876\n",
      "iteration 251 / 300: loss 0.596489\n",
      "iteration 251 / 300: loss 0.581430\n",
      "iteration 251 / 300: loss 0.609807\n",
      "iteration 251 / 300: loss 0.608125\n",
      "iteration 251 / 300: loss 0.598224\n",
      "iteration 251 / 300: loss 0.592022\n",
      "iteration 251 / 300: loss 0.611031\n",
      "iteration 251 / 300: loss 0.598550\n",
      "iteration 251 / 300: loss 0.581382\n",
      "iteration 251 / 300: loss 0.609580\n",
      "iteration 252 / 300: loss 0.578384\n",
      "iteration 252 / 300: loss 0.596214\n",
      "iteration 252 / 300: loss 0.569455\n",
      "iteration 252 / 300: loss 0.597849\n",
      "iteration 252 / 300: loss 0.598940\n",
      "iteration 252 / 300: loss 0.603876\n",
      "iteration 252 / 300: loss 0.615261\n",
      "iteration 252 / 300: loss 0.588227\n",
      "iteration 252 / 300: loss 0.627171\n",
      "iteration 252 / 300: loss 0.592600\n",
      "iteration 252 / 300: loss 0.621500\n",
      "iteration 252 / 300: loss 0.593093\n",
      "iteration 252 / 300: loss 0.600541\n",
      "iteration 252 / 300: loss 0.571000\n",
      "iteration 252 / 300: loss 0.592911\n",
      "iteration 252 / 300: loss 0.600043\n",
      "iteration 252 / 300: loss 0.598053\n",
      "iteration 252 / 300: loss 0.583712\n",
      "iteration 252 / 300: loss 0.614355\n",
      "iteration 252 / 300: loss 0.591285\n",
      "iteration 252 / 300: loss 0.591391\n",
      "iteration 252 / 300: loss 0.594005\n",
      "iteration 252 / 300: loss 0.596735\n",
      "iteration 252 / 300: loss 0.596712\n",
      "iteration 252 / 300: loss 0.611735\n",
      "iteration 252 / 300: loss 0.607258\n",
      "iteration 252 / 300: loss 0.597031\n",
      "iteration 252 / 300: loss 0.596301\n",
      "iteration 252 / 300: loss 0.627391\n",
      "iteration 252 / 300: loss 0.601584\n",
      "iteration 252 / 300: loss 0.599923\n",
      "iteration 252 / 300: loss 0.621952\n",
      "iteration 252 / 300: loss 0.581435\n",
      "iteration 252 / 300: loss 0.599604\n",
      "iteration 252 / 300: loss 0.591182\n",
      "iteration 252 / 300: loss 0.599919\n",
      "iteration 252 / 300: loss 0.596015\n",
      "iteration 252 / 300: loss 0.590760\n",
      "iteration 252 / 300: loss 0.591961\n",
      "iteration 252 / 300: loss 0.615468\n",
      "iteration 252 / 300: loss 0.621360\n",
      "iteration 252 / 300: loss 0.587267\n",
      "iteration 252 / 300: loss 0.582483\n",
      "iteration 252 / 300: loss 0.585572\n",
      "iteration 252 / 300: loss 0.603666\n",
      "iteration 252 / 300: loss 0.585192\n",
      "iteration 252 / 300: loss 0.578880\n",
      "iteration 252 / 300: loss 0.576418\n",
      "iteration 252 / 300: loss 0.574097\n",
      "iteration 252 / 300: loss 0.600500\n",
      "iteration 252 / 300: loss 0.584490\n",
      "iteration 252 / 300: loss 0.584834\n",
      "iteration 252 / 300: loss 0.568323\n",
      "iteration 252 / 300: loss 0.592025\n",
      "iteration 252 / 300: loss 0.612116\n",
      "iteration 252 / 300: loss 0.608923\n",
      "iteration 252 / 300: loss 0.607613\n",
      "iteration 252 / 300: loss 0.595533\n",
      "iteration 252 / 300: loss 0.592837\n",
      "iteration 252 / 300: loss 0.597988\n",
      "iteration 252 / 300: loss 0.597677\n",
      "iteration 252 / 300: loss 0.600953\n",
      "iteration 252 / 300: loss 0.597422\n",
      "iteration 252 / 300: loss 0.598776\n",
      "iteration 252 / 300: loss 0.587806\n",
      "iteration 252 / 300: loss 0.600499\n",
      "iteration 252 / 300: loss 0.599650\n",
      "iteration 252 / 300: loss 0.617540\n",
      "iteration 252 / 300: loss 0.598875\n",
      "iteration 252 / 300: loss 0.600801\n",
      "iteration 252 / 300: loss 0.605305\n",
      "iteration 252 / 300: loss 0.598592\n",
      "iteration 252 / 300: loss 0.591474\n",
      "iteration 252 / 300: loss 0.580382\n",
      "iteration 252 / 300: loss 0.598221\n",
      "iteration 252 / 300: loss 0.611685\n",
      "iteration 252 / 300: loss 0.613219\n",
      "iteration 252 / 300: loss 0.582214\n",
      "iteration 252 / 300: loss 0.601955\n",
      "iteration 252 / 300: loss 0.608956\n",
      "iteration 252 / 300: loss 0.601794\n",
      "iteration 252 / 300: loss 0.607944\n",
      "iteration 252 / 300: loss 0.620236\n",
      "iteration 252 / 300: loss 0.584817\n",
      "iteration 252 / 300: loss 0.583721\n",
      "iteration 252 / 300: loss 0.628849\n",
      "iteration 252 / 300: loss 0.609399\n",
      "iteration 252 / 300: loss 0.606265\n",
      "iteration 252 / 300: loss 0.599034\n",
      "iteration 252 / 300: loss 0.615876\n",
      "iteration 252 / 300: loss 0.596489\n",
      "iteration 252 / 300: loss 0.581430\n",
      "iteration 252 / 300: loss 0.609807\n",
      "iteration 252 / 300: loss 0.608125\n",
      "iteration 252 / 300: loss 0.598224\n",
      "iteration 252 / 300: loss 0.592022\n",
      "iteration 252 / 300: loss 0.611031\n",
      "iteration 252 / 300: loss 0.598550\n",
      "iteration 252 / 300: loss 0.581382\n",
      "iteration 252 / 300: loss 0.609580\n",
      "iteration 253 / 300: loss 0.578384\n",
      "iteration 253 / 300: loss 0.596214\n",
      "iteration 253 / 300: loss 0.569455\n",
      "iteration 253 / 300: loss 0.597849\n",
      "iteration 253 / 300: loss 0.598940\n",
      "iteration 253 / 300: loss 0.603876\n",
      "iteration 253 / 300: loss 0.615261\n",
      "iteration 253 / 300: loss 0.588227\n",
      "iteration 253 / 300: loss 0.627171\n",
      "iteration 253 / 300: loss 0.592600\n",
      "iteration 253 / 300: loss 0.621500\n",
      "iteration 253 / 300: loss 0.593093\n",
      "iteration 253 / 300: loss 0.600541\n",
      "iteration 253 / 300: loss 0.571000\n",
      "iteration 253 / 300: loss 0.592911\n",
      "iteration 253 / 300: loss 0.600043\n",
      "iteration 253 / 300: loss 0.598053\n",
      "iteration 253 / 300: loss 0.583712\n",
      "iteration 253 / 300: loss 0.614355\n",
      "iteration 253 / 300: loss 0.591285\n",
      "iteration 253 / 300: loss 0.591391\n",
      "iteration 253 / 300: loss 0.594005\n",
      "iteration 253 / 300: loss 0.596735\n",
      "iteration 253 / 300: loss 0.596712\n",
      "iteration 253 / 300: loss 0.611735\n",
      "iteration 253 / 300: loss 0.607258\n",
      "iteration 253 / 300: loss 0.597031\n",
      "iteration 253 / 300: loss 0.596301\n",
      "iteration 253 / 300: loss 0.627391\n",
      "iteration 253 / 300: loss 0.601584\n",
      "iteration 253 / 300: loss 0.599923\n",
      "iteration 253 / 300: loss 0.621952\n",
      "iteration 253 / 300: loss 0.581435\n",
      "iteration 253 / 300: loss 0.599604\n",
      "iteration 253 / 300: loss 0.591182\n",
      "iteration 253 / 300: loss 0.599919\n",
      "iteration 253 / 300: loss 0.596015\n",
      "iteration 253 / 300: loss 0.590760\n",
      "iteration 253 / 300: loss 0.591961\n",
      "iteration 253 / 300: loss 0.615468\n",
      "iteration 253 / 300: loss 0.621360\n",
      "iteration 253 / 300: loss 0.587267\n",
      "iteration 253 / 300: loss 0.582483\n",
      "iteration 253 / 300: loss 0.585572\n",
      "iteration 253 / 300: loss 0.603666\n",
      "iteration 253 / 300: loss 0.585192\n",
      "iteration 253 / 300: loss 0.578880\n",
      "iteration 253 / 300: loss 0.576418\n",
      "iteration 253 / 300: loss 0.574097\n",
      "iteration 253 / 300: loss 0.600500\n",
      "iteration 253 / 300: loss 0.584490\n",
      "iteration 253 / 300: loss 0.584834\n",
      "iteration 253 / 300: loss 0.568323\n",
      "iteration 253 / 300: loss 0.592025\n",
      "iteration 253 / 300: loss 0.612116\n",
      "iteration 253 / 300: loss 0.608923\n",
      "iteration 253 / 300: loss 0.607613\n",
      "iteration 253 / 300: loss 0.595533\n",
      "iteration 253 / 300: loss 0.592837\n",
      "iteration 253 / 300: loss 0.597988\n",
      "iteration 253 / 300: loss 0.597677\n",
      "iteration 253 / 300: loss 0.600953\n",
      "iteration 253 / 300: loss 0.597422\n",
      "iteration 253 / 300: loss 0.598776\n",
      "iteration 253 / 300: loss 0.587806\n",
      "iteration 253 / 300: loss 0.600499\n",
      "iteration 253 / 300: loss 0.599650\n",
      "iteration 253 / 300: loss 0.617540\n",
      "iteration 253 / 300: loss 0.598875\n",
      "iteration 253 / 300: loss 0.600801\n",
      "iteration 253 / 300: loss 0.605305\n",
      "iteration 253 / 300: loss 0.598592\n",
      "iteration 253 / 300: loss 0.591474\n",
      "iteration 253 / 300: loss 0.580382\n",
      "iteration 253 / 300: loss 0.598221\n",
      "iteration 253 / 300: loss 0.611685\n",
      "iteration 253 / 300: loss 0.613219\n",
      "iteration 253 / 300: loss 0.582214\n",
      "iteration 253 / 300: loss 0.601955\n",
      "iteration 253 / 300: loss 0.608956\n",
      "iteration 253 / 300: loss 0.601794\n",
      "iteration 253 / 300: loss 0.607944\n",
      "iteration 253 / 300: loss 0.620236\n",
      "iteration 253 / 300: loss 0.584817\n",
      "iteration 253 / 300: loss 0.583721\n",
      "iteration 253 / 300: loss 0.628849\n",
      "iteration 253 / 300: loss 0.609399\n",
      "iteration 253 / 300: loss 0.606265\n",
      "iteration 253 / 300: loss 0.599034\n",
      "iteration 253 / 300: loss 0.615876\n",
      "iteration 253 / 300: loss 0.596489\n",
      "iteration 253 / 300: loss 0.581430\n",
      "iteration 253 / 300: loss 0.609807\n",
      "iteration 253 / 300: loss 0.608125\n",
      "iteration 253 / 300: loss 0.598224\n",
      "iteration 253 / 300: loss 0.592022\n",
      "iteration 253 / 300: loss 0.611031\n",
      "iteration 253 / 300: loss 0.598550\n",
      "iteration 253 / 300: loss 0.581382\n",
      "iteration 253 / 300: loss 0.609580\n",
      "iteration 254 / 300: loss 0.578384\n",
      "iteration 254 / 300: loss 0.596214\n",
      "iteration 254 / 300: loss 0.569455\n",
      "iteration 254 / 300: loss 0.597849\n",
      "iteration 254 / 300: loss 0.598940\n",
      "iteration 254 / 300: loss 0.603876\n",
      "iteration 254 / 300: loss 0.615261\n",
      "iteration 254 / 300: loss 0.588227\n",
      "iteration 254 / 300: loss 0.627171\n",
      "iteration 254 / 300: loss 0.592600\n",
      "iteration 254 / 300: loss 0.621500\n",
      "iteration 254 / 300: loss 0.593093\n",
      "iteration 254 / 300: loss 0.600541\n",
      "iteration 254 / 300: loss 0.571000\n",
      "iteration 254 / 300: loss 0.592911\n",
      "iteration 254 / 300: loss 0.600043\n",
      "iteration 254 / 300: loss 0.598053\n",
      "iteration 254 / 300: loss 0.583712\n",
      "iteration 254 / 300: loss 0.614355\n",
      "iteration 254 / 300: loss 0.591285\n",
      "iteration 254 / 300: loss 0.591391\n",
      "iteration 254 / 300: loss 0.594005\n",
      "iteration 254 / 300: loss 0.596735\n",
      "iteration 254 / 300: loss 0.596712\n",
      "iteration 254 / 300: loss 0.611735\n",
      "iteration 254 / 300: loss 0.607258\n",
      "iteration 254 / 300: loss 0.597031\n",
      "iteration 254 / 300: loss 0.596301\n",
      "iteration 254 / 300: loss 0.627391\n",
      "iteration 254 / 300: loss 0.601584\n",
      "iteration 254 / 300: loss 0.599923\n",
      "iteration 254 / 300: loss 0.621952\n",
      "iteration 254 / 300: loss 0.581435\n",
      "iteration 254 / 300: loss 0.599604\n",
      "iteration 254 / 300: loss 0.591182\n",
      "iteration 254 / 300: loss 0.599919\n",
      "iteration 254 / 300: loss 0.596015\n",
      "iteration 254 / 300: loss 0.590760\n",
      "iteration 254 / 300: loss 0.591961\n",
      "iteration 254 / 300: loss 0.615468\n",
      "iteration 254 / 300: loss 0.621360\n",
      "iteration 254 / 300: loss 0.587267\n",
      "iteration 254 / 300: loss 0.582483\n",
      "iteration 254 / 300: loss 0.585572\n",
      "iteration 254 / 300: loss 0.603666\n",
      "iteration 254 / 300: loss 0.585192\n",
      "iteration 254 / 300: loss 0.578880\n",
      "iteration 254 / 300: loss 0.576418\n",
      "iteration 254 / 300: loss 0.574097\n",
      "iteration 254 / 300: loss 0.600500\n",
      "iteration 254 / 300: loss 0.584490\n",
      "iteration 254 / 300: loss 0.584834\n",
      "iteration 254 / 300: loss 0.568323\n",
      "iteration 254 / 300: loss 0.592025\n",
      "iteration 254 / 300: loss 0.612116\n",
      "iteration 254 / 300: loss 0.608923\n",
      "iteration 254 / 300: loss 0.607613\n",
      "iteration 254 / 300: loss 0.595533\n",
      "iteration 254 / 300: loss 0.592837\n",
      "iteration 254 / 300: loss 0.597988\n",
      "iteration 254 / 300: loss 0.597677\n",
      "iteration 254 / 300: loss 0.600953\n",
      "iteration 254 / 300: loss 0.597422\n",
      "iteration 254 / 300: loss 0.598776\n",
      "iteration 254 / 300: loss 0.587806\n",
      "iteration 254 / 300: loss 0.600499\n",
      "iteration 254 / 300: loss 0.599650\n",
      "iteration 254 / 300: loss 0.617540\n",
      "iteration 254 / 300: loss 0.598875\n",
      "iteration 254 / 300: loss 0.600801\n",
      "iteration 254 / 300: loss 0.605305\n",
      "iteration 254 / 300: loss 0.598592\n",
      "iteration 254 / 300: loss 0.591474\n",
      "iteration 254 / 300: loss 0.580382\n",
      "iteration 254 / 300: loss 0.598221\n",
      "iteration 254 / 300: loss 0.611685\n",
      "iteration 254 / 300: loss 0.613219\n",
      "iteration 254 / 300: loss 0.582214\n",
      "iteration 254 / 300: loss 0.601955\n",
      "iteration 254 / 300: loss 0.608956\n",
      "iteration 254 / 300: loss 0.601794\n",
      "iteration 254 / 300: loss 0.607944\n",
      "iteration 254 / 300: loss 0.620236\n",
      "iteration 254 / 300: loss 0.584817\n",
      "iteration 254 / 300: loss 0.583721\n",
      "iteration 254 / 300: loss 0.628849\n",
      "iteration 254 / 300: loss 0.609399\n",
      "iteration 254 / 300: loss 0.606265\n",
      "iteration 254 / 300: loss 0.599034\n",
      "iteration 254 / 300: loss 0.615876\n",
      "iteration 254 / 300: loss 0.596489\n",
      "iteration 254 / 300: loss 0.581430\n",
      "iteration 254 / 300: loss 0.609807\n",
      "iteration 254 / 300: loss 0.608125\n",
      "iteration 254 / 300: loss 0.598224\n",
      "iteration 254 / 300: loss 0.592022\n",
      "iteration 254 / 300: loss 0.611031\n",
      "iteration 254 / 300: loss 0.598550\n",
      "iteration 254 / 300: loss 0.581382\n",
      "iteration 254 / 300: loss 0.609580\n",
      "iteration 255 / 300: loss 0.578384\n",
      "iteration 255 / 300: loss 0.596214\n",
      "iteration 255 / 300: loss 0.569455\n",
      "iteration 255 / 300: loss 0.597849\n",
      "iteration 255 / 300: loss 0.598940\n",
      "iteration 255 / 300: loss 0.603876\n",
      "iteration 255 / 300: loss 0.615261\n",
      "iteration 255 / 300: loss 0.588227\n",
      "iteration 255 / 300: loss 0.627171\n",
      "iteration 255 / 300: loss 0.592600\n",
      "iteration 255 / 300: loss 0.621500\n",
      "iteration 255 / 300: loss 0.593093\n",
      "iteration 255 / 300: loss 0.600541\n",
      "iteration 255 / 300: loss 0.571000\n",
      "iteration 255 / 300: loss 0.592911\n",
      "iteration 255 / 300: loss 0.600043\n",
      "iteration 255 / 300: loss 0.598053\n",
      "iteration 255 / 300: loss 0.583712\n",
      "iteration 255 / 300: loss 0.614355\n",
      "iteration 255 / 300: loss 0.591285\n",
      "iteration 255 / 300: loss 0.591391\n",
      "iteration 255 / 300: loss 0.594005\n",
      "iteration 255 / 300: loss 0.596735\n",
      "iteration 255 / 300: loss 0.596712\n",
      "iteration 255 / 300: loss 0.611735\n",
      "iteration 255 / 300: loss 0.607258\n",
      "iteration 255 / 300: loss 0.597031\n",
      "iteration 255 / 300: loss 0.596301\n",
      "iteration 255 / 300: loss 0.627391\n",
      "iteration 255 / 300: loss 0.601584\n",
      "iteration 255 / 300: loss 0.599923\n",
      "iteration 255 / 300: loss 0.621952\n",
      "iteration 255 / 300: loss 0.581435\n",
      "iteration 255 / 300: loss 0.599604\n",
      "iteration 255 / 300: loss 0.591182\n",
      "iteration 255 / 300: loss 0.599919\n",
      "iteration 255 / 300: loss 0.596015\n",
      "iteration 255 / 300: loss 0.590760\n",
      "iteration 255 / 300: loss 0.591961\n",
      "iteration 255 / 300: loss 0.615468\n",
      "iteration 255 / 300: loss 0.621360\n",
      "iteration 255 / 300: loss 0.587267\n",
      "iteration 255 / 300: loss 0.582483\n",
      "iteration 255 / 300: loss 0.585572\n",
      "iteration 255 / 300: loss 0.603666\n",
      "iteration 255 / 300: loss 0.585192\n",
      "iteration 255 / 300: loss 0.578880\n",
      "iteration 255 / 300: loss 0.576418\n",
      "iteration 255 / 300: loss 0.574097\n",
      "iteration 255 / 300: loss 0.600500\n",
      "iteration 255 / 300: loss 0.584490\n",
      "iteration 255 / 300: loss 0.584834\n",
      "iteration 255 / 300: loss 0.568323\n",
      "iteration 255 / 300: loss 0.592025\n",
      "iteration 255 / 300: loss 0.612116\n",
      "iteration 255 / 300: loss 0.608923\n",
      "iteration 255 / 300: loss 0.607613\n",
      "iteration 255 / 300: loss 0.595533\n",
      "iteration 255 / 300: loss 0.592837\n",
      "iteration 255 / 300: loss 0.597988\n",
      "iteration 255 / 300: loss 0.597677\n",
      "iteration 255 / 300: loss 0.600953\n",
      "iteration 255 / 300: loss 0.597422\n",
      "iteration 255 / 300: loss 0.598776\n",
      "iteration 255 / 300: loss 0.587806\n",
      "iteration 255 / 300: loss 0.600499\n",
      "iteration 255 / 300: loss 0.599650\n",
      "iteration 255 / 300: loss 0.617540\n",
      "iteration 255 / 300: loss 0.598875\n",
      "iteration 255 / 300: loss 0.600801\n",
      "iteration 255 / 300: loss 0.605305\n",
      "iteration 255 / 300: loss 0.598592\n",
      "iteration 255 / 300: loss 0.591474\n",
      "iteration 255 / 300: loss 0.580382\n",
      "iteration 255 / 300: loss 0.598221\n",
      "iteration 255 / 300: loss 0.611685\n",
      "iteration 255 / 300: loss 0.613219\n",
      "iteration 255 / 300: loss 0.582214\n",
      "iteration 255 / 300: loss 0.601955\n",
      "iteration 255 / 300: loss 0.608956\n",
      "iteration 255 / 300: loss 0.601794\n",
      "iteration 255 / 300: loss 0.607944\n",
      "iteration 255 / 300: loss 0.620236\n",
      "iteration 255 / 300: loss 0.584817\n",
      "iteration 255 / 300: loss 0.583721\n",
      "iteration 255 / 300: loss 0.628849\n",
      "iteration 255 / 300: loss 0.609399\n",
      "iteration 255 / 300: loss 0.606265\n",
      "iteration 255 / 300: loss 0.599034\n",
      "iteration 255 / 300: loss 0.615876\n",
      "iteration 255 / 300: loss 0.596489\n",
      "iteration 255 / 300: loss 0.581430\n",
      "iteration 255 / 300: loss 0.609807\n",
      "iteration 255 / 300: loss 0.608125\n",
      "iteration 255 / 300: loss 0.598224\n",
      "iteration 255 / 300: loss 0.592022\n",
      "iteration 255 / 300: loss 0.611031\n",
      "iteration 255 / 300: loss 0.598550\n",
      "iteration 255 / 300: loss 0.581382\n",
      "iteration 255 / 300: loss 0.609580\n",
      "iteration 256 / 300: loss 0.578384\n",
      "iteration 256 / 300: loss 0.596214\n",
      "iteration 256 / 300: loss 0.569455\n",
      "iteration 256 / 300: loss 0.597849\n",
      "iteration 256 / 300: loss 0.598940\n",
      "iteration 256 / 300: loss 0.603876\n",
      "iteration 256 / 300: loss 0.615261\n",
      "iteration 256 / 300: loss 0.588227\n",
      "iteration 256 / 300: loss 0.627171\n",
      "iteration 256 / 300: loss 0.592600\n",
      "iteration 256 / 300: loss 0.621500\n",
      "iteration 256 / 300: loss 0.593093\n",
      "iteration 256 / 300: loss 0.600541\n",
      "iteration 256 / 300: loss 0.571000\n",
      "iteration 256 / 300: loss 0.592911\n",
      "iteration 256 / 300: loss 0.600043\n",
      "iteration 256 / 300: loss 0.598053\n",
      "iteration 256 / 300: loss 0.583712\n",
      "iteration 256 / 300: loss 0.614355\n",
      "iteration 256 / 300: loss 0.591285\n",
      "iteration 256 / 300: loss 0.591391\n",
      "iteration 256 / 300: loss 0.594005\n",
      "iteration 256 / 300: loss 0.596735\n",
      "iteration 256 / 300: loss 0.596712\n",
      "iteration 256 / 300: loss 0.611735\n",
      "iteration 256 / 300: loss 0.607258\n",
      "iteration 256 / 300: loss 0.597031\n",
      "iteration 256 / 300: loss 0.596301\n",
      "iteration 256 / 300: loss 0.627391\n",
      "iteration 256 / 300: loss 0.601584\n",
      "iteration 256 / 300: loss 0.599923\n",
      "iteration 256 / 300: loss 0.621952\n",
      "iteration 256 / 300: loss 0.581435\n",
      "iteration 256 / 300: loss 0.599604\n",
      "iteration 256 / 300: loss 0.591182\n",
      "iteration 256 / 300: loss 0.599919\n",
      "iteration 256 / 300: loss 0.596015\n",
      "iteration 256 / 300: loss 0.590760\n",
      "iteration 256 / 300: loss 0.591961\n",
      "iteration 256 / 300: loss 0.615468\n",
      "iteration 256 / 300: loss 0.621360\n",
      "iteration 256 / 300: loss 0.587267\n",
      "iteration 256 / 300: loss 0.582483\n",
      "iteration 256 / 300: loss 0.585572\n",
      "iteration 256 / 300: loss 0.603666\n",
      "iteration 256 / 300: loss 0.585192\n",
      "iteration 256 / 300: loss 0.578880\n",
      "iteration 256 / 300: loss 0.576418\n",
      "iteration 256 / 300: loss 0.574097\n",
      "iteration 256 / 300: loss 0.600500\n",
      "iteration 256 / 300: loss 0.584490\n",
      "iteration 256 / 300: loss 0.584834\n",
      "iteration 256 / 300: loss 0.568323\n",
      "iteration 256 / 300: loss 0.592025\n",
      "iteration 256 / 300: loss 0.612116\n",
      "iteration 256 / 300: loss 0.608923\n",
      "iteration 256 / 300: loss 0.607613\n",
      "iteration 256 / 300: loss 0.595533\n",
      "iteration 256 / 300: loss 0.592837\n",
      "iteration 256 / 300: loss 0.597988\n",
      "iteration 256 / 300: loss 0.597677\n",
      "iteration 256 / 300: loss 0.600953\n",
      "iteration 256 / 300: loss 0.597422\n",
      "iteration 256 / 300: loss 0.598776\n",
      "iteration 256 / 300: loss 0.587806\n",
      "iteration 256 / 300: loss 0.600499\n",
      "iteration 256 / 300: loss 0.599650\n",
      "iteration 256 / 300: loss 0.617540\n",
      "iteration 256 / 300: loss 0.598875\n",
      "iteration 256 / 300: loss 0.600801\n",
      "iteration 256 / 300: loss 0.605305\n",
      "iteration 256 / 300: loss 0.598592\n",
      "iteration 256 / 300: loss 0.591474\n",
      "iteration 256 / 300: loss 0.580382\n",
      "iteration 256 / 300: loss 0.598221\n",
      "iteration 256 / 300: loss 0.611685\n",
      "iteration 256 / 300: loss 0.613219\n",
      "iteration 256 / 300: loss 0.582214\n",
      "iteration 256 / 300: loss 0.601955\n",
      "iteration 256 / 300: loss 0.608956\n",
      "iteration 256 / 300: loss 0.601794\n",
      "iteration 256 / 300: loss 0.607944\n",
      "iteration 256 / 300: loss 0.620236\n",
      "iteration 256 / 300: loss 0.584817\n",
      "iteration 256 / 300: loss 0.583721\n",
      "iteration 256 / 300: loss 0.628849\n",
      "iteration 256 / 300: loss 0.609399\n",
      "iteration 256 / 300: loss 0.606265\n",
      "iteration 256 / 300: loss 0.599034\n",
      "iteration 256 / 300: loss 0.615876\n",
      "iteration 256 / 300: loss 0.596489\n",
      "iteration 256 / 300: loss 0.581430\n",
      "iteration 256 / 300: loss 0.609807\n",
      "iteration 256 / 300: loss 0.608125\n",
      "iteration 256 / 300: loss 0.598224\n",
      "iteration 256 / 300: loss 0.592022\n",
      "iteration 256 / 300: loss 0.611031\n",
      "iteration 256 / 300: loss 0.598550\n",
      "iteration 256 / 300: loss 0.581382\n",
      "iteration 256 / 300: loss 0.609580\n",
      "iteration 257 / 300: loss 0.578384\n",
      "iteration 257 / 300: loss 0.596214\n",
      "iteration 257 / 300: loss 0.569455\n",
      "iteration 257 / 300: loss 0.597849\n",
      "iteration 257 / 300: loss 0.598940\n",
      "iteration 257 / 300: loss 0.603876\n",
      "iteration 257 / 300: loss 0.615261\n",
      "iteration 257 / 300: loss 0.588227\n",
      "iteration 257 / 300: loss 0.627171\n",
      "iteration 257 / 300: loss 0.592600\n",
      "iteration 257 / 300: loss 0.621500\n",
      "iteration 257 / 300: loss 0.593093\n",
      "iteration 257 / 300: loss 0.600541\n",
      "iteration 257 / 300: loss 0.571000\n",
      "iteration 257 / 300: loss 0.592911\n",
      "iteration 257 / 300: loss 0.600043\n",
      "iteration 257 / 300: loss 0.598053\n",
      "iteration 257 / 300: loss 0.583712\n",
      "iteration 257 / 300: loss 0.614355\n",
      "iteration 257 / 300: loss 0.591285\n",
      "iteration 257 / 300: loss 0.591391\n",
      "iteration 257 / 300: loss 0.594005\n",
      "iteration 257 / 300: loss 0.596735\n",
      "iteration 257 / 300: loss 0.596712\n",
      "iteration 257 / 300: loss 0.611735\n",
      "iteration 257 / 300: loss 0.607258\n",
      "iteration 257 / 300: loss 0.597031\n",
      "iteration 257 / 300: loss 0.596301\n",
      "iteration 257 / 300: loss 0.627391\n",
      "iteration 257 / 300: loss 0.601584\n",
      "iteration 257 / 300: loss 0.599923\n",
      "iteration 257 / 300: loss 0.621952\n",
      "iteration 257 / 300: loss 0.581435\n",
      "iteration 257 / 300: loss 0.599604\n",
      "iteration 257 / 300: loss 0.591182\n",
      "iteration 257 / 300: loss 0.599919\n",
      "iteration 257 / 300: loss 0.596015\n",
      "iteration 257 / 300: loss 0.590760\n",
      "iteration 257 / 300: loss 0.591961\n",
      "iteration 257 / 300: loss 0.615468\n",
      "iteration 257 / 300: loss 0.621360\n",
      "iteration 257 / 300: loss 0.587267\n",
      "iteration 257 / 300: loss 0.582483\n",
      "iteration 257 / 300: loss 0.585572\n",
      "iteration 257 / 300: loss 0.603666\n",
      "iteration 257 / 300: loss 0.585192\n",
      "iteration 257 / 300: loss 0.578880\n",
      "iteration 257 / 300: loss 0.576418\n",
      "iteration 257 / 300: loss 0.574097\n",
      "iteration 257 / 300: loss 0.600500\n",
      "iteration 257 / 300: loss 0.584490\n",
      "iteration 257 / 300: loss 0.584834\n",
      "iteration 257 / 300: loss 0.568323\n",
      "iteration 257 / 300: loss 0.592025\n",
      "iteration 257 / 300: loss 0.612116\n",
      "iteration 257 / 300: loss 0.608923\n",
      "iteration 257 / 300: loss 0.607613\n",
      "iteration 257 / 300: loss 0.595533\n",
      "iteration 257 / 300: loss 0.592837\n",
      "iteration 257 / 300: loss 0.597988\n",
      "iteration 257 / 300: loss 0.597677\n",
      "iteration 257 / 300: loss 0.600953\n",
      "iteration 257 / 300: loss 0.597422\n",
      "iteration 257 / 300: loss 0.598776\n",
      "iteration 257 / 300: loss 0.587806\n",
      "iteration 257 / 300: loss 0.600499\n",
      "iteration 257 / 300: loss 0.599650\n",
      "iteration 257 / 300: loss 0.617540\n",
      "iteration 257 / 300: loss 0.598875\n",
      "iteration 257 / 300: loss 0.600801\n",
      "iteration 257 / 300: loss 0.605305\n",
      "iteration 257 / 300: loss 0.598592\n",
      "iteration 257 / 300: loss 0.591474\n",
      "iteration 257 / 300: loss 0.580382\n",
      "iteration 257 / 300: loss 0.598221\n",
      "iteration 257 / 300: loss 0.611685\n",
      "iteration 257 / 300: loss 0.613219\n",
      "iteration 257 / 300: loss 0.582214\n",
      "iteration 257 / 300: loss 0.601955\n",
      "iteration 257 / 300: loss 0.608956\n",
      "iteration 257 / 300: loss 0.601794\n",
      "iteration 257 / 300: loss 0.607944\n",
      "iteration 257 / 300: loss 0.620236\n",
      "iteration 257 / 300: loss 0.584817\n",
      "iteration 257 / 300: loss 0.583721\n",
      "iteration 257 / 300: loss 0.628849\n",
      "iteration 257 / 300: loss 0.609399\n",
      "iteration 257 / 300: loss 0.606265\n",
      "iteration 257 / 300: loss 0.599034\n",
      "iteration 257 / 300: loss 0.615876\n",
      "iteration 257 / 300: loss 0.596489\n",
      "iteration 257 / 300: loss 0.581430\n",
      "iteration 257 / 300: loss 0.609807\n",
      "iteration 257 / 300: loss 0.608125\n",
      "iteration 257 / 300: loss 0.598224\n",
      "iteration 257 / 300: loss 0.592022\n",
      "iteration 257 / 300: loss 0.611031\n",
      "iteration 257 / 300: loss 0.598550\n",
      "iteration 257 / 300: loss 0.581382\n",
      "iteration 257 / 300: loss 0.609580\n",
      "iteration 258 / 300: loss 0.578384\n",
      "iteration 258 / 300: loss 0.596214\n",
      "iteration 258 / 300: loss 0.569455\n",
      "iteration 258 / 300: loss 0.597849\n",
      "iteration 258 / 300: loss 0.598940\n",
      "iteration 258 / 300: loss 0.603876\n",
      "iteration 258 / 300: loss 0.615261\n",
      "iteration 258 / 300: loss 0.588227\n",
      "iteration 258 / 300: loss 0.627171\n",
      "iteration 258 / 300: loss 0.592600\n",
      "iteration 258 / 300: loss 0.621500\n",
      "iteration 258 / 300: loss 0.593093\n",
      "iteration 258 / 300: loss 0.600541\n",
      "iteration 258 / 300: loss 0.571000\n",
      "iteration 258 / 300: loss 0.592911\n",
      "iteration 258 / 300: loss 0.600043\n",
      "iteration 258 / 300: loss 0.598053\n",
      "iteration 258 / 300: loss 0.583712\n",
      "iteration 258 / 300: loss 0.614355\n",
      "iteration 258 / 300: loss 0.591285\n",
      "iteration 258 / 300: loss 0.591391\n",
      "iteration 258 / 300: loss 0.594005\n",
      "iteration 258 / 300: loss 0.596735\n",
      "iteration 258 / 300: loss 0.596712\n",
      "iteration 258 / 300: loss 0.611735\n",
      "iteration 258 / 300: loss 0.607258\n",
      "iteration 258 / 300: loss 0.597031\n",
      "iteration 258 / 300: loss 0.596301\n",
      "iteration 258 / 300: loss 0.627391\n",
      "iteration 258 / 300: loss 0.601584\n",
      "iteration 258 / 300: loss 0.599923\n",
      "iteration 258 / 300: loss 0.621952\n",
      "iteration 258 / 300: loss 0.581435\n",
      "iteration 258 / 300: loss 0.599604\n",
      "iteration 258 / 300: loss 0.591182\n",
      "iteration 258 / 300: loss 0.599919\n",
      "iteration 258 / 300: loss 0.596015\n",
      "iteration 258 / 300: loss 0.590760\n",
      "iteration 258 / 300: loss 0.591961\n",
      "iteration 258 / 300: loss 0.615468\n",
      "iteration 258 / 300: loss 0.621360\n",
      "iteration 258 / 300: loss 0.587267\n",
      "iteration 258 / 300: loss 0.582483\n",
      "iteration 258 / 300: loss 0.585572\n",
      "iteration 258 / 300: loss 0.603666\n",
      "iteration 258 / 300: loss 0.585192\n",
      "iteration 258 / 300: loss 0.578880\n",
      "iteration 258 / 300: loss 0.576418\n",
      "iteration 258 / 300: loss 0.574097\n",
      "iteration 258 / 300: loss 0.600500\n",
      "iteration 258 / 300: loss 0.584490\n",
      "iteration 258 / 300: loss 0.584834\n",
      "iteration 258 / 300: loss 0.568323\n",
      "iteration 258 / 300: loss 0.592025\n",
      "iteration 258 / 300: loss 0.612116\n",
      "iteration 258 / 300: loss 0.608923\n",
      "iteration 258 / 300: loss 0.607613\n",
      "iteration 258 / 300: loss 0.595533\n",
      "iteration 258 / 300: loss 0.592837\n",
      "iteration 258 / 300: loss 0.597988\n",
      "iteration 258 / 300: loss 0.597677\n",
      "iteration 258 / 300: loss 0.600953\n",
      "iteration 258 / 300: loss 0.597422\n",
      "iteration 258 / 300: loss 0.598776\n",
      "iteration 258 / 300: loss 0.587806\n",
      "iteration 258 / 300: loss 0.600499\n",
      "iteration 258 / 300: loss 0.599650\n",
      "iteration 258 / 300: loss 0.617540\n",
      "iteration 258 / 300: loss 0.598875\n",
      "iteration 258 / 300: loss 0.600801\n",
      "iteration 258 / 300: loss 0.605305\n",
      "iteration 258 / 300: loss 0.598592\n",
      "iteration 258 / 300: loss 0.591474\n",
      "iteration 258 / 300: loss 0.580382\n",
      "iteration 258 / 300: loss 0.598221\n",
      "iteration 258 / 300: loss 0.611685\n",
      "iteration 258 / 300: loss 0.613219\n",
      "iteration 258 / 300: loss 0.582214\n",
      "iteration 258 / 300: loss 0.601955\n",
      "iteration 258 / 300: loss 0.608956\n",
      "iteration 258 / 300: loss 0.601794\n",
      "iteration 258 / 300: loss 0.607944\n",
      "iteration 258 / 300: loss 0.620236\n",
      "iteration 258 / 300: loss 0.584817\n",
      "iteration 258 / 300: loss 0.583721\n",
      "iteration 258 / 300: loss 0.628849\n",
      "iteration 258 / 300: loss 0.609399\n",
      "iteration 258 / 300: loss 0.606265\n",
      "iteration 258 / 300: loss 0.599034\n",
      "iteration 258 / 300: loss 0.615876\n",
      "iteration 258 / 300: loss 0.596489\n",
      "iteration 258 / 300: loss 0.581430\n",
      "iteration 258 / 300: loss 0.609807\n",
      "iteration 258 / 300: loss 0.608125\n",
      "iteration 258 / 300: loss 0.598224\n",
      "iteration 258 / 300: loss 0.592022\n",
      "iteration 258 / 300: loss 0.611031\n",
      "iteration 258 / 300: loss 0.598550\n",
      "iteration 258 / 300: loss 0.581382\n",
      "iteration 258 / 300: loss 0.609580\n",
      "iteration 259 / 300: loss 0.578384\n",
      "iteration 259 / 300: loss 0.596214\n",
      "iteration 259 / 300: loss 0.569455\n",
      "iteration 259 / 300: loss 0.597849\n",
      "iteration 259 / 300: loss 0.598940\n",
      "iteration 259 / 300: loss 0.603876\n",
      "iteration 259 / 300: loss 0.615261\n",
      "iteration 259 / 300: loss 0.588227\n",
      "iteration 259 / 300: loss 0.627171\n",
      "iteration 259 / 300: loss 0.592600\n",
      "iteration 259 / 300: loss 0.621500\n",
      "iteration 259 / 300: loss 0.593093\n",
      "iteration 259 / 300: loss 0.600541\n",
      "iteration 259 / 300: loss 0.571000\n",
      "iteration 259 / 300: loss 0.592911\n",
      "iteration 259 / 300: loss 0.600043\n",
      "iteration 259 / 300: loss 0.598053\n",
      "iteration 259 / 300: loss 0.583712\n",
      "iteration 259 / 300: loss 0.614355\n",
      "iteration 259 / 300: loss 0.591285\n",
      "iteration 259 / 300: loss 0.591391\n",
      "iteration 259 / 300: loss 0.594005\n",
      "iteration 259 / 300: loss 0.596735\n",
      "iteration 259 / 300: loss 0.596712\n",
      "iteration 259 / 300: loss 0.611735\n",
      "iteration 259 / 300: loss 0.607258\n",
      "iteration 259 / 300: loss 0.597031\n",
      "iteration 259 / 300: loss 0.596301\n",
      "iteration 259 / 300: loss 0.627391\n",
      "iteration 259 / 300: loss 0.601584\n",
      "iteration 259 / 300: loss 0.599923\n",
      "iteration 259 / 300: loss 0.621952\n",
      "iteration 259 / 300: loss 0.581435\n",
      "iteration 259 / 300: loss 0.599604\n",
      "iteration 259 / 300: loss 0.591182\n",
      "iteration 259 / 300: loss 0.599919\n",
      "iteration 259 / 300: loss 0.596015\n",
      "iteration 259 / 300: loss 0.590760\n",
      "iteration 259 / 300: loss 0.591961\n",
      "iteration 259 / 300: loss 0.615468\n",
      "iteration 259 / 300: loss 0.621360\n",
      "iteration 259 / 300: loss 0.587267\n",
      "iteration 259 / 300: loss 0.582483\n",
      "iteration 259 / 300: loss 0.585572\n",
      "iteration 259 / 300: loss 0.603666\n",
      "iteration 259 / 300: loss 0.585192\n",
      "iteration 259 / 300: loss 0.578880\n",
      "iteration 259 / 300: loss 0.576418\n",
      "iteration 259 / 300: loss 0.574097\n",
      "iteration 259 / 300: loss 0.600500\n",
      "iteration 259 / 300: loss 0.584490\n",
      "iteration 259 / 300: loss 0.584834\n",
      "iteration 259 / 300: loss 0.568323\n",
      "iteration 259 / 300: loss 0.592025\n",
      "iteration 259 / 300: loss 0.612116\n",
      "iteration 259 / 300: loss 0.608923\n",
      "iteration 259 / 300: loss 0.607613\n",
      "iteration 259 / 300: loss 0.595533\n",
      "iteration 259 / 300: loss 0.592837\n",
      "iteration 259 / 300: loss 0.597988\n",
      "iteration 259 / 300: loss 0.597677\n",
      "iteration 259 / 300: loss 0.600953\n",
      "iteration 259 / 300: loss 0.597422\n",
      "iteration 259 / 300: loss 0.598776\n",
      "iteration 259 / 300: loss 0.587806\n",
      "iteration 259 / 300: loss 0.600499\n",
      "iteration 259 / 300: loss 0.599650\n",
      "iteration 259 / 300: loss 0.617540\n",
      "iteration 259 / 300: loss 0.598875\n",
      "iteration 259 / 300: loss 0.600801\n",
      "iteration 259 / 300: loss 0.605305\n",
      "iteration 259 / 300: loss 0.598592\n",
      "iteration 259 / 300: loss 0.591474\n",
      "iteration 259 / 300: loss 0.580382\n",
      "iteration 259 / 300: loss 0.598221\n",
      "iteration 259 / 300: loss 0.611685\n",
      "iteration 259 / 300: loss 0.613219\n",
      "iteration 259 / 300: loss 0.582214\n",
      "iteration 259 / 300: loss 0.601955\n",
      "iteration 259 / 300: loss 0.608956\n",
      "iteration 259 / 300: loss 0.601794\n",
      "iteration 259 / 300: loss 0.607944\n",
      "iteration 259 / 300: loss 0.620236\n",
      "iteration 259 / 300: loss 0.584817\n",
      "iteration 259 / 300: loss 0.583721\n",
      "iteration 259 / 300: loss 0.628849\n",
      "iteration 259 / 300: loss 0.609399\n",
      "iteration 259 / 300: loss 0.606265\n",
      "iteration 259 / 300: loss 0.599034\n",
      "iteration 259 / 300: loss 0.615876\n",
      "iteration 259 / 300: loss 0.596489\n",
      "iteration 259 / 300: loss 0.581430\n",
      "iteration 259 / 300: loss 0.609807\n",
      "iteration 259 / 300: loss 0.608125\n",
      "iteration 259 / 300: loss 0.598224\n",
      "iteration 259 / 300: loss 0.592022\n",
      "iteration 259 / 300: loss 0.611031\n",
      "iteration 259 / 300: loss 0.598550\n",
      "iteration 259 / 300: loss 0.581382\n",
      "iteration 259 / 300: loss 0.609580\n",
      "iteration 260 / 300: loss 0.578384\n",
      "iteration 260 / 300: loss 0.596214\n",
      "iteration 260 / 300: loss 0.569455\n",
      "iteration 260 / 300: loss 0.597849\n",
      "iteration 260 / 300: loss 0.598940\n",
      "iteration 260 / 300: loss 0.603876\n",
      "iteration 260 / 300: loss 0.615261\n",
      "iteration 260 / 300: loss 0.588227\n",
      "iteration 260 / 300: loss 0.627171\n",
      "iteration 260 / 300: loss 0.592600\n",
      "iteration 260 / 300: loss 0.621500\n",
      "iteration 260 / 300: loss 0.593093\n",
      "iteration 260 / 300: loss 0.600541\n",
      "iteration 260 / 300: loss 0.571000\n",
      "iteration 260 / 300: loss 0.592911\n",
      "iteration 260 / 300: loss 0.600043\n",
      "iteration 260 / 300: loss 0.598053\n",
      "iteration 260 / 300: loss 0.583712\n",
      "iteration 260 / 300: loss 0.614355\n",
      "iteration 260 / 300: loss 0.591285\n",
      "iteration 260 / 300: loss 0.591391\n",
      "iteration 260 / 300: loss 0.594005\n",
      "iteration 260 / 300: loss 0.596735\n",
      "iteration 260 / 300: loss 0.596712\n",
      "iteration 260 / 300: loss 0.611735\n",
      "iteration 260 / 300: loss 0.607258\n",
      "iteration 260 / 300: loss 0.597031\n",
      "iteration 260 / 300: loss 0.596301\n",
      "iteration 260 / 300: loss 0.627391\n",
      "iteration 260 / 300: loss 0.601584\n",
      "iteration 260 / 300: loss 0.599923\n",
      "iteration 260 / 300: loss 0.621952\n",
      "iteration 260 / 300: loss 0.581435\n",
      "iteration 260 / 300: loss 0.599604\n",
      "iteration 260 / 300: loss 0.591182\n",
      "iteration 260 / 300: loss 0.599919\n",
      "iteration 260 / 300: loss 0.596015\n",
      "iteration 260 / 300: loss 0.590760\n",
      "iteration 260 / 300: loss 0.591961\n",
      "iteration 260 / 300: loss 0.615468\n",
      "iteration 260 / 300: loss 0.621360\n",
      "iteration 260 / 300: loss 0.587267\n",
      "iteration 260 / 300: loss 0.582483\n",
      "iteration 260 / 300: loss 0.585572\n",
      "iteration 260 / 300: loss 0.603666\n",
      "iteration 260 / 300: loss 0.585192\n",
      "iteration 260 / 300: loss 0.578880\n",
      "iteration 260 / 300: loss 0.576418\n",
      "iteration 260 / 300: loss 0.574097\n",
      "iteration 260 / 300: loss 0.600500\n",
      "iteration 260 / 300: loss 0.584490\n",
      "iteration 260 / 300: loss 0.584834\n",
      "iteration 260 / 300: loss 0.568323\n",
      "iteration 260 / 300: loss 0.592025\n",
      "iteration 260 / 300: loss 0.612116\n",
      "iteration 260 / 300: loss 0.608923\n",
      "iteration 260 / 300: loss 0.607613\n",
      "iteration 260 / 300: loss 0.595533\n",
      "iteration 260 / 300: loss 0.592837\n",
      "iteration 260 / 300: loss 0.597988\n",
      "iteration 260 / 300: loss 0.597677\n",
      "iteration 260 / 300: loss 0.600953\n",
      "iteration 260 / 300: loss 0.597422\n",
      "iteration 260 / 300: loss 0.598776\n",
      "iteration 260 / 300: loss 0.587806\n",
      "iteration 260 / 300: loss 0.600499\n",
      "iteration 260 / 300: loss 0.599650\n",
      "iteration 260 / 300: loss 0.617540\n",
      "iteration 260 / 300: loss 0.598875\n",
      "iteration 260 / 300: loss 0.600801\n",
      "iteration 260 / 300: loss 0.605305\n",
      "iteration 260 / 300: loss 0.598592\n",
      "iteration 260 / 300: loss 0.591474\n",
      "iteration 260 / 300: loss 0.580382\n",
      "iteration 260 / 300: loss 0.598221\n",
      "iteration 260 / 300: loss 0.611685\n",
      "iteration 260 / 300: loss 0.613219\n",
      "iteration 260 / 300: loss 0.582214\n",
      "iteration 260 / 300: loss 0.601955\n",
      "iteration 260 / 300: loss 0.608956\n",
      "iteration 260 / 300: loss 0.601794\n",
      "iteration 260 / 300: loss 0.607944\n",
      "iteration 260 / 300: loss 0.620236\n",
      "iteration 260 / 300: loss 0.584817\n",
      "iteration 260 / 300: loss 0.583721\n",
      "iteration 260 / 300: loss 0.628849\n",
      "iteration 260 / 300: loss 0.609399\n",
      "iteration 260 / 300: loss 0.606265\n",
      "iteration 260 / 300: loss 0.599034\n",
      "iteration 260 / 300: loss 0.615876\n",
      "iteration 260 / 300: loss 0.596489\n",
      "iteration 260 / 300: loss 0.581430\n",
      "iteration 260 / 300: loss 0.609807\n",
      "iteration 260 / 300: loss 0.608125\n",
      "iteration 260 / 300: loss 0.598224\n",
      "iteration 260 / 300: loss 0.592022\n",
      "iteration 260 / 300: loss 0.611031\n",
      "iteration 260 / 300: loss 0.598550\n",
      "iteration 260 / 300: loss 0.581382\n",
      "iteration 260 / 300: loss 0.609580\n",
      "iteration 261 / 300: loss 0.578384\n",
      "iteration 261 / 300: loss 0.596214\n",
      "iteration 261 / 300: loss 0.569455\n",
      "iteration 261 / 300: loss 0.597849\n",
      "iteration 261 / 300: loss 0.598940\n",
      "iteration 261 / 300: loss 0.603876\n",
      "iteration 261 / 300: loss 0.615261\n",
      "iteration 261 / 300: loss 0.588227\n",
      "iteration 261 / 300: loss 0.627171\n",
      "iteration 261 / 300: loss 0.592600\n",
      "iteration 261 / 300: loss 0.621500\n",
      "iteration 261 / 300: loss 0.593093\n",
      "iteration 261 / 300: loss 0.600541\n",
      "iteration 261 / 300: loss 0.571000\n",
      "iteration 261 / 300: loss 0.592911\n",
      "iteration 261 / 300: loss 0.600043\n",
      "iteration 261 / 300: loss 0.598053\n",
      "iteration 261 / 300: loss 0.583712\n",
      "iteration 261 / 300: loss 0.614355\n",
      "iteration 261 / 300: loss 0.591285\n",
      "iteration 261 / 300: loss 0.591391\n",
      "iteration 261 / 300: loss 0.594005\n",
      "iteration 261 / 300: loss 0.596735\n",
      "iteration 261 / 300: loss 0.596712\n",
      "iteration 261 / 300: loss 0.611735\n",
      "iteration 261 / 300: loss 0.607258\n",
      "iteration 261 / 300: loss 0.597031\n",
      "iteration 261 / 300: loss 0.596301\n",
      "iteration 261 / 300: loss 0.627391\n",
      "iteration 261 / 300: loss 0.601584\n",
      "iteration 261 / 300: loss 0.599923\n",
      "iteration 261 / 300: loss 0.621952\n",
      "iteration 261 / 300: loss 0.581435\n",
      "iteration 261 / 300: loss 0.599604\n",
      "iteration 261 / 300: loss 0.591182\n",
      "iteration 261 / 300: loss 0.599919\n",
      "iteration 261 / 300: loss 0.596015\n",
      "iteration 261 / 300: loss 0.590760\n",
      "iteration 261 / 300: loss 0.591961\n",
      "iteration 261 / 300: loss 0.615468\n",
      "iteration 261 / 300: loss 0.621360\n",
      "iteration 261 / 300: loss 0.587267\n",
      "iteration 261 / 300: loss 0.582483\n",
      "iteration 261 / 300: loss 0.585572\n",
      "iteration 261 / 300: loss 0.603666\n",
      "iteration 261 / 300: loss 0.585192\n",
      "iteration 261 / 300: loss 0.578880\n",
      "iteration 261 / 300: loss 0.576418\n",
      "iteration 261 / 300: loss 0.574097\n",
      "iteration 261 / 300: loss 0.600500\n",
      "iteration 261 / 300: loss 0.584490\n",
      "iteration 261 / 300: loss 0.584834\n",
      "iteration 261 / 300: loss 0.568323\n",
      "iteration 261 / 300: loss 0.592025\n",
      "iteration 261 / 300: loss 0.612116\n",
      "iteration 261 / 300: loss 0.608923\n",
      "iteration 261 / 300: loss 0.607613\n",
      "iteration 261 / 300: loss 0.595533\n",
      "iteration 261 / 300: loss 0.592837\n",
      "iteration 261 / 300: loss 0.597988\n",
      "iteration 261 / 300: loss 0.597677\n",
      "iteration 261 / 300: loss 0.600953\n",
      "iteration 261 / 300: loss 0.597422\n",
      "iteration 261 / 300: loss 0.598776\n",
      "iteration 261 / 300: loss 0.587806\n",
      "iteration 261 / 300: loss 0.600499\n",
      "iteration 261 / 300: loss 0.599650\n",
      "iteration 261 / 300: loss 0.617540\n",
      "iteration 261 / 300: loss 0.598875\n",
      "iteration 261 / 300: loss 0.600801\n",
      "iteration 261 / 300: loss 0.605305\n",
      "iteration 261 / 300: loss 0.598592\n",
      "iteration 261 / 300: loss 0.591474\n",
      "iteration 261 / 300: loss 0.580382\n",
      "iteration 261 / 300: loss 0.598221\n",
      "iteration 261 / 300: loss 0.611685\n",
      "iteration 261 / 300: loss 0.613219\n",
      "iteration 261 / 300: loss 0.582214\n",
      "iteration 261 / 300: loss 0.601955\n",
      "iteration 261 / 300: loss 0.608956\n",
      "iteration 261 / 300: loss 0.601794\n",
      "iteration 261 / 300: loss 0.607944\n",
      "iteration 261 / 300: loss 0.620236\n",
      "iteration 261 / 300: loss 0.584817\n",
      "iteration 261 / 300: loss 0.583721\n",
      "iteration 261 / 300: loss 0.628849\n",
      "iteration 261 / 300: loss 0.609399\n",
      "iteration 261 / 300: loss 0.606265\n",
      "iteration 261 / 300: loss 0.599034\n",
      "iteration 261 / 300: loss 0.615876\n",
      "iteration 261 / 300: loss 0.596489\n",
      "iteration 261 / 300: loss 0.581430\n",
      "iteration 261 / 300: loss 0.609807\n",
      "iteration 261 / 300: loss 0.608125\n",
      "iteration 261 / 300: loss 0.598224\n",
      "iteration 261 / 300: loss 0.592022\n",
      "iteration 261 / 300: loss 0.611031\n",
      "iteration 261 / 300: loss 0.598550\n",
      "iteration 261 / 300: loss 0.581382\n",
      "iteration 261 / 300: loss 0.609580\n",
      "iteration 262 / 300: loss 0.578384\n",
      "iteration 262 / 300: loss 0.596214\n",
      "iteration 262 / 300: loss 0.569455\n",
      "iteration 262 / 300: loss 0.597849\n",
      "iteration 262 / 300: loss 0.598940\n",
      "iteration 262 / 300: loss 0.603876\n",
      "iteration 262 / 300: loss 0.615261\n",
      "iteration 262 / 300: loss 0.588227\n",
      "iteration 262 / 300: loss 0.627171\n",
      "iteration 262 / 300: loss 0.592600\n",
      "iteration 262 / 300: loss 0.621500\n",
      "iteration 262 / 300: loss 0.593093\n",
      "iteration 262 / 300: loss 0.600541\n",
      "iteration 262 / 300: loss 0.571000\n",
      "iteration 262 / 300: loss 0.592911\n",
      "iteration 262 / 300: loss 0.600043\n",
      "iteration 262 / 300: loss 0.598053\n",
      "iteration 262 / 300: loss 0.583712\n",
      "iteration 262 / 300: loss 0.614355\n",
      "iteration 262 / 300: loss 0.591285\n",
      "iteration 262 / 300: loss 0.591391\n",
      "iteration 262 / 300: loss 0.594005\n",
      "iteration 262 / 300: loss 0.596735\n",
      "iteration 262 / 300: loss 0.596712\n",
      "iteration 262 / 300: loss 0.611735\n",
      "iteration 262 / 300: loss 0.607258\n",
      "iteration 262 / 300: loss 0.597031\n",
      "iteration 262 / 300: loss 0.596301\n",
      "iteration 262 / 300: loss 0.627391\n",
      "iteration 262 / 300: loss 0.601584\n",
      "iteration 262 / 300: loss 0.599923\n",
      "iteration 262 / 300: loss 0.621952\n",
      "iteration 262 / 300: loss 0.581435\n",
      "iteration 262 / 300: loss 0.599604\n",
      "iteration 262 / 300: loss 0.591182\n",
      "iteration 262 / 300: loss 0.599919\n",
      "iteration 262 / 300: loss 0.596015\n",
      "iteration 262 / 300: loss 0.590760\n",
      "iteration 262 / 300: loss 0.591961\n",
      "iteration 262 / 300: loss 0.615468\n",
      "iteration 262 / 300: loss 0.621360\n",
      "iteration 262 / 300: loss 0.587267\n",
      "iteration 262 / 300: loss 0.582483\n",
      "iteration 262 / 300: loss 0.585572\n",
      "iteration 262 / 300: loss 0.603666\n",
      "iteration 262 / 300: loss 0.585192\n",
      "iteration 262 / 300: loss 0.578880\n",
      "iteration 262 / 300: loss 0.576418\n",
      "iteration 262 / 300: loss 0.574097\n",
      "iteration 262 / 300: loss 0.600500\n",
      "iteration 262 / 300: loss 0.584490\n",
      "iteration 262 / 300: loss 0.584834\n",
      "iteration 262 / 300: loss 0.568323\n",
      "iteration 262 / 300: loss 0.592025\n",
      "iteration 262 / 300: loss 0.612116\n",
      "iteration 262 / 300: loss 0.608923\n",
      "iteration 262 / 300: loss 0.607613\n",
      "iteration 262 / 300: loss 0.595533\n",
      "iteration 262 / 300: loss 0.592837\n",
      "iteration 262 / 300: loss 0.597988\n",
      "iteration 262 / 300: loss 0.597677\n",
      "iteration 262 / 300: loss 0.600953\n",
      "iteration 262 / 300: loss 0.597422\n",
      "iteration 262 / 300: loss 0.598776\n",
      "iteration 262 / 300: loss 0.587806\n",
      "iteration 262 / 300: loss 0.600499\n",
      "iteration 262 / 300: loss 0.599650\n",
      "iteration 262 / 300: loss 0.617540\n",
      "iteration 262 / 300: loss 0.598875\n",
      "iteration 262 / 300: loss 0.600801\n",
      "iteration 262 / 300: loss 0.605305\n",
      "iteration 262 / 300: loss 0.598592\n",
      "iteration 262 / 300: loss 0.591474\n",
      "iteration 262 / 300: loss 0.580382\n",
      "iteration 262 / 300: loss 0.598221\n",
      "iteration 262 / 300: loss 0.611685\n",
      "iteration 262 / 300: loss 0.613219\n",
      "iteration 262 / 300: loss 0.582214\n",
      "iteration 262 / 300: loss 0.601955\n",
      "iteration 262 / 300: loss 0.608956\n",
      "iteration 262 / 300: loss 0.601794\n",
      "iteration 262 / 300: loss 0.607944\n",
      "iteration 262 / 300: loss 0.620236\n",
      "iteration 262 / 300: loss 0.584817\n",
      "iteration 262 / 300: loss 0.583721\n",
      "iteration 262 / 300: loss 0.628849\n",
      "iteration 262 / 300: loss 0.609399\n",
      "iteration 262 / 300: loss 0.606265\n",
      "iteration 262 / 300: loss 0.599034\n",
      "iteration 262 / 300: loss 0.615876\n",
      "iteration 262 / 300: loss 0.596489\n",
      "iteration 262 / 300: loss 0.581430\n",
      "iteration 262 / 300: loss 0.609807\n",
      "iteration 262 / 300: loss 0.608125\n",
      "iteration 262 / 300: loss 0.598224\n",
      "iteration 262 / 300: loss 0.592022\n",
      "iteration 262 / 300: loss 0.611031\n",
      "iteration 262 / 300: loss 0.598550\n",
      "iteration 262 / 300: loss 0.581382\n",
      "iteration 262 / 300: loss 0.609580\n",
      "iteration 263 / 300: loss 0.578384\n",
      "iteration 263 / 300: loss 0.596214\n",
      "iteration 263 / 300: loss 0.569455\n",
      "iteration 263 / 300: loss 0.597849\n",
      "iteration 263 / 300: loss 0.598940\n",
      "iteration 263 / 300: loss 0.603876\n",
      "iteration 263 / 300: loss 0.615261\n",
      "iteration 263 / 300: loss 0.588227\n",
      "iteration 263 / 300: loss 0.627171\n",
      "iteration 263 / 300: loss 0.592600\n",
      "iteration 263 / 300: loss 0.621500\n",
      "iteration 263 / 300: loss 0.593093\n",
      "iteration 263 / 300: loss 0.600541\n",
      "iteration 263 / 300: loss 0.571000\n",
      "iteration 263 / 300: loss 0.592911\n",
      "iteration 263 / 300: loss 0.600043\n",
      "iteration 263 / 300: loss 0.598053\n",
      "iteration 263 / 300: loss 0.583712\n",
      "iteration 263 / 300: loss 0.614355\n",
      "iteration 263 / 300: loss 0.591285\n",
      "iteration 263 / 300: loss 0.591391\n",
      "iteration 263 / 300: loss 0.594005\n",
      "iteration 263 / 300: loss 0.596735\n",
      "iteration 263 / 300: loss 0.596712\n",
      "iteration 263 / 300: loss 0.611735\n",
      "iteration 263 / 300: loss 0.607258\n",
      "iteration 263 / 300: loss 0.597031\n",
      "iteration 263 / 300: loss 0.596301\n",
      "iteration 263 / 300: loss 0.627391\n",
      "iteration 263 / 300: loss 0.601584\n",
      "iteration 263 / 300: loss 0.599923\n",
      "iteration 263 / 300: loss 0.621952\n",
      "iteration 263 / 300: loss 0.581435\n",
      "iteration 263 / 300: loss 0.599604\n",
      "iteration 263 / 300: loss 0.591182\n",
      "iteration 263 / 300: loss 0.599919\n",
      "iteration 263 / 300: loss 0.596015\n",
      "iteration 263 / 300: loss 0.590760\n",
      "iteration 263 / 300: loss 0.591961\n",
      "iteration 263 / 300: loss 0.615468\n",
      "iteration 263 / 300: loss 0.621360\n",
      "iteration 263 / 300: loss 0.587267\n",
      "iteration 263 / 300: loss 0.582483\n",
      "iteration 263 / 300: loss 0.585572\n",
      "iteration 263 / 300: loss 0.603666\n",
      "iteration 263 / 300: loss 0.585192\n",
      "iteration 263 / 300: loss 0.578880\n",
      "iteration 263 / 300: loss 0.576418\n",
      "iteration 263 / 300: loss 0.574097\n",
      "iteration 263 / 300: loss 0.600500\n",
      "iteration 263 / 300: loss 0.584490\n",
      "iteration 263 / 300: loss 0.584834\n",
      "iteration 263 / 300: loss 0.568323\n",
      "iteration 263 / 300: loss 0.592025\n",
      "iteration 263 / 300: loss 0.612116\n",
      "iteration 263 / 300: loss 0.608923\n",
      "iteration 263 / 300: loss 0.607613\n",
      "iteration 263 / 300: loss 0.595533\n",
      "iteration 263 / 300: loss 0.592837\n",
      "iteration 263 / 300: loss 0.597988\n",
      "iteration 263 / 300: loss 0.597677\n",
      "iteration 263 / 300: loss 0.600953\n",
      "iteration 263 / 300: loss 0.597422\n",
      "iteration 263 / 300: loss 0.598776\n",
      "iteration 263 / 300: loss 0.587806\n",
      "iteration 263 / 300: loss 0.600499\n",
      "iteration 263 / 300: loss 0.599650\n",
      "iteration 263 / 300: loss 0.617540\n",
      "iteration 263 / 300: loss 0.598875\n",
      "iteration 263 / 300: loss 0.600801\n",
      "iteration 263 / 300: loss 0.605305\n",
      "iteration 263 / 300: loss 0.598592\n",
      "iteration 263 / 300: loss 0.591474\n",
      "iteration 263 / 300: loss 0.580382\n",
      "iteration 263 / 300: loss 0.598221\n",
      "iteration 263 / 300: loss 0.611685\n",
      "iteration 263 / 300: loss 0.613219\n",
      "iteration 263 / 300: loss 0.582214\n",
      "iteration 263 / 300: loss 0.601955\n",
      "iteration 263 / 300: loss 0.608956\n",
      "iteration 263 / 300: loss 0.601794\n",
      "iteration 263 / 300: loss 0.607944\n",
      "iteration 263 / 300: loss 0.620236\n",
      "iteration 263 / 300: loss 0.584817\n",
      "iteration 263 / 300: loss 0.583721\n",
      "iteration 263 / 300: loss 0.628849\n",
      "iteration 263 / 300: loss 0.609399\n",
      "iteration 263 / 300: loss 0.606265\n",
      "iteration 263 / 300: loss 0.599034\n",
      "iteration 263 / 300: loss 0.615876\n",
      "iteration 263 / 300: loss 0.596489\n",
      "iteration 263 / 300: loss 0.581430\n",
      "iteration 263 / 300: loss 0.609807\n",
      "iteration 263 / 300: loss 0.608125\n",
      "iteration 263 / 300: loss 0.598224\n",
      "iteration 263 / 300: loss 0.592022\n",
      "iteration 263 / 300: loss 0.611031\n",
      "iteration 263 / 300: loss 0.598550\n",
      "iteration 263 / 300: loss 0.581382\n",
      "iteration 263 / 300: loss 0.609580\n",
      "iteration 264 / 300: loss 0.578384\n",
      "iteration 264 / 300: loss 0.596214\n",
      "iteration 264 / 300: loss 0.569455\n",
      "iteration 264 / 300: loss 0.597849\n",
      "iteration 264 / 300: loss 0.598940\n",
      "iteration 264 / 300: loss 0.603876\n",
      "iteration 264 / 300: loss 0.615261\n",
      "iteration 264 / 300: loss 0.588227\n",
      "iteration 264 / 300: loss 0.627171\n",
      "iteration 264 / 300: loss 0.592600\n",
      "iteration 264 / 300: loss 0.621500\n",
      "iteration 264 / 300: loss 0.593093\n",
      "iteration 264 / 300: loss 0.600541\n",
      "iteration 264 / 300: loss 0.571000\n",
      "iteration 264 / 300: loss 0.592911\n",
      "iteration 264 / 300: loss 0.600043\n",
      "iteration 264 / 300: loss 0.598053\n",
      "iteration 264 / 300: loss 0.583712\n",
      "iteration 264 / 300: loss 0.614355\n",
      "iteration 264 / 300: loss 0.591285\n",
      "iteration 264 / 300: loss 0.591391\n",
      "iteration 264 / 300: loss 0.594005\n",
      "iteration 264 / 300: loss 0.596735\n",
      "iteration 264 / 300: loss 0.596712\n",
      "iteration 264 / 300: loss 0.611735\n",
      "iteration 264 / 300: loss 0.607258\n",
      "iteration 264 / 300: loss 0.597031\n",
      "iteration 264 / 300: loss 0.596301\n",
      "iteration 264 / 300: loss 0.627391\n",
      "iteration 264 / 300: loss 0.601584\n",
      "iteration 264 / 300: loss 0.599923\n",
      "iteration 264 / 300: loss 0.621952\n",
      "iteration 264 / 300: loss 0.581435\n",
      "iteration 264 / 300: loss 0.599604\n",
      "iteration 264 / 300: loss 0.591182\n",
      "iteration 264 / 300: loss 0.599919\n",
      "iteration 264 / 300: loss 0.596015\n",
      "iteration 264 / 300: loss 0.590760\n",
      "iteration 264 / 300: loss 0.591961\n",
      "iteration 264 / 300: loss 0.615468\n",
      "iteration 264 / 300: loss 0.621360\n",
      "iteration 264 / 300: loss 0.587267\n",
      "iteration 264 / 300: loss 0.582483\n",
      "iteration 264 / 300: loss 0.585572\n",
      "iteration 264 / 300: loss 0.603666\n",
      "iteration 264 / 300: loss 0.585192\n",
      "iteration 264 / 300: loss 0.578880\n",
      "iteration 264 / 300: loss 0.576418\n",
      "iteration 264 / 300: loss 0.574097\n",
      "iteration 264 / 300: loss 0.600500\n",
      "iteration 264 / 300: loss 0.584490\n",
      "iteration 264 / 300: loss 0.584834\n",
      "iteration 264 / 300: loss 0.568323\n",
      "iteration 264 / 300: loss 0.592025\n",
      "iteration 264 / 300: loss 0.612116\n",
      "iteration 264 / 300: loss 0.608923\n",
      "iteration 264 / 300: loss 0.607613\n",
      "iteration 264 / 300: loss 0.595533\n",
      "iteration 264 / 300: loss 0.592837\n",
      "iteration 264 / 300: loss 0.597988\n",
      "iteration 264 / 300: loss 0.597677\n",
      "iteration 264 / 300: loss 0.600953\n",
      "iteration 264 / 300: loss 0.597422\n",
      "iteration 264 / 300: loss 0.598776\n",
      "iteration 264 / 300: loss 0.587806\n",
      "iteration 264 / 300: loss 0.600499\n",
      "iteration 264 / 300: loss 0.599650\n",
      "iteration 264 / 300: loss 0.617540\n",
      "iteration 264 / 300: loss 0.598875\n",
      "iteration 264 / 300: loss 0.600801\n",
      "iteration 264 / 300: loss 0.605305\n",
      "iteration 264 / 300: loss 0.598592\n",
      "iteration 264 / 300: loss 0.591474\n",
      "iteration 264 / 300: loss 0.580382\n",
      "iteration 264 / 300: loss 0.598221\n",
      "iteration 264 / 300: loss 0.611685\n",
      "iteration 264 / 300: loss 0.613219\n",
      "iteration 264 / 300: loss 0.582214\n",
      "iteration 264 / 300: loss 0.601955\n",
      "iteration 264 / 300: loss 0.608956\n",
      "iteration 264 / 300: loss 0.601794\n",
      "iteration 264 / 300: loss 0.607944\n",
      "iteration 264 / 300: loss 0.620236\n",
      "iteration 264 / 300: loss 0.584817\n",
      "iteration 264 / 300: loss 0.583721\n",
      "iteration 264 / 300: loss 0.628849\n",
      "iteration 264 / 300: loss 0.609399\n",
      "iteration 264 / 300: loss 0.606265\n",
      "iteration 264 / 300: loss 0.599034\n",
      "iteration 264 / 300: loss 0.615876\n",
      "iteration 264 / 300: loss 0.596489\n",
      "iteration 264 / 300: loss 0.581430\n",
      "iteration 264 / 300: loss 0.609807\n",
      "iteration 264 / 300: loss 0.608125\n",
      "iteration 264 / 300: loss 0.598224\n",
      "iteration 264 / 300: loss 0.592022\n",
      "iteration 264 / 300: loss 0.611031\n",
      "iteration 264 / 300: loss 0.598550\n",
      "iteration 264 / 300: loss 0.581382\n",
      "iteration 264 / 300: loss 0.609580\n",
      "iteration 265 / 300: loss 0.578384\n",
      "iteration 265 / 300: loss 0.596214\n",
      "iteration 265 / 300: loss 0.569455\n",
      "iteration 265 / 300: loss 0.597849\n",
      "iteration 265 / 300: loss 0.598940\n",
      "iteration 265 / 300: loss 0.603876\n",
      "iteration 265 / 300: loss 0.615261\n",
      "iteration 265 / 300: loss 0.588227\n",
      "iteration 265 / 300: loss 0.627171\n",
      "iteration 265 / 300: loss 0.592600\n",
      "iteration 265 / 300: loss 0.621500\n",
      "iteration 265 / 300: loss 0.593093\n",
      "iteration 265 / 300: loss 0.600541\n",
      "iteration 265 / 300: loss 0.571000\n",
      "iteration 265 / 300: loss 0.592911\n",
      "iteration 265 / 300: loss 0.600043\n",
      "iteration 265 / 300: loss 0.598053\n",
      "iteration 265 / 300: loss 0.583712\n",
      "iteration 265 / 300: loss 0.614355\n",
      "iteration 265 / 300: loss 0.591285\n",
      "iteration 265 / 300: loss 0.591391\n",
      "iteration 265 / 300: loss 0.594005\n",
      "iteration 265 / 300: loss 0.596735\n",
      "iteration 265 / 300: loss 0.596712\n",
      "iteration 265 / 300: loss 0.611735\n",
      "iteration 265 / 300: loss 0.607258\n",
      "iteration 265 / 300: loss 0.597031\n",
      "iteration 265 / 300: loss 0.596301\n",
      "iteration 265 / 300: loss 0.627391\n",
      "iteration 265 / 300: loss 0.601584\n",
      "iteration 265 / 300: loss 0.599923\n",
      "iteration 265 / 300: loss 0.621952\n",
      "iteration 265 / 300: loss 0.581435\n",
      "iteration 265 / 300: loss 0.599604\n",
      "iteration 265 / 300: loss 0.591182\n",
      "iteration 265 / 300: loss 0.599919\n",
      "iteration 265 / 300: loss 0.596015\n",
      "iteration 265 / 300: loss 0.590760\n",
      "iteration 265 / 300: loss 0.591961\n",
      "iteration 265 / 300: loss 0.615468\n",
      "iteration 265 / 300: loss 0.621360\n",
      "iteration 265 / 300: loss 0.587267\n",
      "iteration 265 / 300: loss 0.582483\n",
      "iteration 265 / 300: loss 0.585572\n",
      "iteration 265 / 300: loss 0.603666\n",
      "iteration 265 / 300: loss 0.585192\n",
      "iteration 265 / 300: loss 0.578880\n",
      "iteration 265 / 300: loss 0.576418\n",
      "iteration 265 / 300: loss 0.574097\n",
      "iteration 265 / 300: loss 0.600500\n",
      "iteration 265 / 300: loss 0.584490\n",
      "iteration 265 / 300: loss 0.584834\n",
      "iteration 265 / 300: loss 0.568323\n",
      "iteration 265 / 300: loss 0.592025\n",
      "iteration 265 / 300: loss 0.612116\n",
      "iteration 265 / 300: loss 0.608923\n",
      "iteration 265 / 300: loss 0.607613\n",
      "iteration 265 / 300: loss 0.595533\n",
      "iteration 265 / 300: loss 0.592837\n",
      "iteration 265 / 300: loss 0.597988\n",
      "iteration 265 / 300: loss 0.597677\n",
      "iteration 265 / 300: loss 0.600953\n",
      "iteration 265 / 300: loss 0.597422\n",
      "iteration 265 / 300: loss 0.598776\n",
      "iteration 265 / 300: loss 0.587806\n",
      "iteration 265 / 300: loss 0.600499\n",
      "iteration 265 / 300: loss 0.599650\n",
      "iteration 265 / 300: loss 0.617540\n",
      "iteration 265 / 300: loss 0.598875\n",
      "iteration 265 / 300: loss 0.600801\n",
      "iteration 265 / 300: loss 0.605305\n",
      "iteration 265 / 300: loss 0.598592\n",
      "iteration 265 / 300: loss 0.591474\n",
      "iteration 265 / 300: loss 0.580382\n",
      "iteration 265 / 300: loss 0.598221\n",
      "iteration 265 / 300: loss 0.611685\n",
      "iteration 265 / 300: loss 0.613219\n",
      "iteration 265 / 300: loss 0.582214\n",
      "iteration 265 / 300: loss 0.601955\n",
      "iteration 265 / 300: loss 0.608956\n",
      "iteration 265 / 300: loss 0.601794\n",
      "iteration 265 / 300: loss 0.607944\n",
      "iteration 265 / 300: loss 0.620236\n",
      "iteration 265 / 300: loss 0.584817\n",
      "iteration 265 / 300: loss 0.583721\n",
      "iteration 265 / 300: loss 0.628849\n",
      "iteration 265 / 300: loss 0.609399\n",
      "iteration 265 / 300: loss 0.606265\n",
      "iteration 265 / 300: loss 0.599034\n",
      "iteration 265 / 300: loss 0.615876\n",
      "iteration 265 / 300: loss 0.596489\n",
      "iteration 265 / 300: loss 0.581430\n",
      "iteration 265 / 300: loss 0.609807\n",
      "iteration 265 / 300: loss 0.608125\n",
      "iteration 265 / 300: loss 0.598224\n",
      "iteration 265 / 300: loss 0.592022\n",
      "iteration 265 / 300: loss 0.611031\n",
      "iteration 265 / 300: loss 0.598550\n",
      "iteration 265 / 300: loss 0.581382\n",
      "iteration 265 / 300: loss 0.609580\n",
      "iteration 266 / 300: loss 0.578384\n",
      "iteration 266 / 300: loss 0.596214\n",
      "iteration 266 / 300: loss 0.569455\n",
      "iteration 266 / 300: loss 0.597849\n",
      "iteration 266 / 300: loss 0.598940\n",
      "iteration 266 / 300: loss 0.603876\n",
      "iteration 266 / 300: loss 0.615261\n",
      "iteration 266 / 300: loss 0.588227\n",
      "iteration 266 / 300: loss 0.627171\n",
      "iteration 266 / 300: loss 0.592600\n",
      "iteration 266 / 300: loss 0.621500\n",
      "iteration 266 / 300: loss 0.593093\n",
      "iteration 266 / 300: loss 0.600541\n",
      "iteration 266 / 300: loss 0.571000\n",
      "iteration 266 / 300: loss 0.592911\n",
      "iteration 266 / 300: loss 0.600043\n",
      "iteration 266 / 300: loss 0.598053\n",
      "iteration 266 / 300: loss 0.583712\n",
      "iteration 266 / 300: loss 0.614355\n",
      "iteration 266 / 300: loss 0.591285\n",
      "iteration 266 / 300: loss 0.591391\n",
      "iteration 266 / 300: loss 0.594005\n",
      "iteration 266 / 300: loss 0.596735\n",
      "iteration 266 / 300: loss 0.596712\n",
      "iteration 266 / 300: loss 0.611735\n",
      "iteration 266 / 300: loss 0.607258\n",
      "iteration 266 / 300: loss 0.597031\n",
      "iteration 266 / 300: loss 0.596301\n",
      "iteration 266 / 300: loss 0.627391\n",
      "iteration 266 / 300: loss 0.601584\n",
      "iteration 266 / 300: loss 0.599923\n",
      "iteration 266 / 300: loss 0.621952\n",
      "iteration 266 / 300: loss 0.581435\n",
      "iteration 266 / 300: loss 0.599604\n",
      "iteration 266 / 300: loss 0.591182\n",
      "iteration 266 / 300: loss 0.599919\n",
      "iteration 266 / 300: loss 0.596015\n",
      "iteration 266 / 300: loss 0.590760\n",
      "iteration 266 / 300: loss 0.591961\n",
      "iteration 266 / 300: loss 0.615468\n",
      "iteration 266 / 300: loss 0.621360\n",
      "iteration 266 / 300: loss 0.587267\n",
      "iteration 266 / 300: loss 0.582483\n",
      "iteration 266 / 300: loss 0.585572\n",
      "iteration 266 / 300: loss 0.603666\n",
      "iteration 266 / 300: loss 0.585192\n",
      "iteration 266 / 300: loss 0.578880\n",
      "iteration 266 / 300: loss 0.576418\n",
      "iteration 266 / 300: loss 0.574097\n",
      "iteration 266 / 300: loss 0.600500\n",
      "iteration 266 / 300: loss 0.584490\n",
      "iteration 266 / 300: loss 0.584834\n",
      "iteration 266 / 300: loss 0.568323\n",
      "iteration 266 / 300: loss 0.592025\n",
      "iteration 266 / 300: loss 0.612116\n",
      "iteration 266 / 300: loss 0.608923\n",
      "iteration 266 / 300: loss 0.607613\n",
      "iteration 266 / 300: loss 0.595533\n",
      "iteration 266 / 300: loss 0.592837\n",
      "iteration 266 / 300: loss 0.597988\n",
      "iteration 266 / 300: loss 0.597677\n",
      "iteration 266 / 300: loss 0.600953\n",
      "iteration 266 / 300: loss 0.597422\n",
      "iteration 266 / 300: loss 0.598776\n",
      "iteration 266 / 300: loss 0.587806\n",
      "iteration 266 / 300: loss 0.600499\n",
      "iteration 266 / 300: loss 0.599650\n",
      "iteration 266 / 300: loss 0.617540\n",
      "iteration 266 / 300: loss 0.598875\n",
      "iteration 266 / 300: loss 0.600801\n",
      "iteration 266 / 300: loss 0.605305\n",
      "iteration 266 / 300: loss 0.598592\n",
      "iteration 266 / 300: loss 0.591474\n",
      "iteration 266 / 300: loss 0.580382\n",
      "iteration 266 / 300: loss 0.598221\n",
      "iteration 266 / 300: loss 0.611685\n",
      "iteration 266 / 300: loss 0.613219\n",
      "iteration 266 / 300: loss 0.582214\n",
      "iteration 266 / 300: loss 0.601955\n",
      "iteration 266 / 300: loss 0.608956\n",
      "iteration 266 / 300: loss 0.601794\n",
      "iteration 266 / 300: loss 0.607944\n",
      "iteration 266 / 300: loss 0.620236\n",
      "iteration 266 / 300: loss 0.584817\n",
      "iteration 266 / 300: loss 0.583721\n",
      "iteration 266 / 300: loss 0.628849\n",
      "iteration 266 / 300: loss 0.609399\n",
      "iteration 266 / 300: loss 0.606265\n",
      "iteration 266 / 300: loss 0.599034\n",
      "iteration 266 / 300: loss 0.615876\n",
      "iteration 266 / 300: loss 0.596489\n",
      "iteration 266 / 300: loss 0.581430\n",
      "iteration 266 / 300: loss 0.609807\n",
      "iteration 266 / 300: loss 0.608125\n",
      "iteration 266 / 300: loss 0.598224\n",
      "iteration 266 / 300: loss 0.592022\n",
      "iteration 266 / 300: loss 0.611031\n",
      "iteration 266 / 300: loss 0.598550\n",
      "iteration 266 / 300: loss 0.581382\n",
      "iteration 266 / 300: loss 0.609580\n",
      "iteration 267 / 300: loss 0.578384\n",
      "iteration 267 / 300: loss 0.596214\n",
      "iteration 267 / 300: loss 0.569455\n",
      "iteration 267 / 300: loss 0.597849\n",
      "iteration 267 / 300: loss 0.598940\n",
      "iteration 267 / 300: loss 0.603876\n",
      "iteration 267 / 300: loss 0.615261\n",
      "iteration 267 / 300: loss 0.588227\n",
      "iteration 267 / 300: loss 0.627171\n",
      "iteration 267 / 300: loss 0.592600\n",
      "iteration 267 / 300: loss 0.621500\n",
      "iteration 267 / 300: loss 0.593093\n",
      "iteration 267 / 300: loss 0.600541\n",
      "iteration 267 / 300: loss 0.571000\n",
      "iteration 267 / 300: loss 0.592911\n",
      "iteration 267 / 300: loss 0.600043\n",
      "iteration 267 / 300: loss 0.598053\n",
      "iteration 267 / 300: loss 0.583712\n",
      "iteration 267 / 300: loss 0.614355\n",
      "iteration 267 / 300: loss 0.591285\n",
      "iteration 267 / 300: loss 0.591391\n",
      "iteration 267 / 300: loss 0.594005\n",
      "iteration 267 / 300: loss 0.596735\n",
      "iteration 267 / 300: loss 0.596712\n",
      "iteration 267 / 300: loss 0.611735\n",
      "iteration 267 / 300: loss 0.607258\n",
      "iteration 267 / 300: loss 0.597031\n",
      "iteration 267 / 300: loss 0.596301\n",
      "iteration 267 / 300: loss 0.627391\n",
      "iteration 267 / 300: loss 0.601584\n",
      "iteration 267 / 300: loss 0.599923\n",
      "iteration 267 / 300: loss 0.621952\n",
      "iteration 267 / 300: loss 0.581435\n",
      "iteration 267 / 300: loss 0.599604\n",
      "iteration 267 / 300: loss 0.591182\n",
      "iteration 267 / 300: loss 0.599919\n",
      "iteration 267 / 300: loss 0.596015\n",
      "iteration 267 / 300: loss 0.590760\n",
      "iteration 267 / 300: loss 0.591961\n",
      "iteration 267 / 300: loss 0.615468\n",
      "iteration 267 / 300: loss 0.621360\n",
      "iteration 267 / 300: loss 0.587267\n",
      "iteration 267 / 300: loss 0.582483\n",
      "iteration 267 / 300: loss 0.585572\n",
      "iteration 267 / 300: loss 0.603666\n",
      "iteration 267 / 300: loss 0.585192\n",
      "iteration 267 / 300: loss 0.578880\n",
      "iteration 267 / 300: loss 0.576418\n",
      "iteration 267 / 300: loss 0.574097\n",
      "iteration 267 / 300: loss 0.600500\n",
      "iteration 267 / 300: loss 0.584490\n",
      "iteration 267 / 300: loss 0.584834\n",
      "iteration 267 / 300: loss 0.568323\n",
      "iteration 267 / 300: loss 0.592025\n",
      "iteration 267 / 300: loss 0.612116\n",
      "iteration 267 / 300: loss 0.608923\n",
      "iteration 267 / 300: loss 0.607613\n",
      "iteration 267 / 300: loss 0.595533\n",
      "iteration 267 / 300: loss 0.592837\n",
      "iteration 267 / 300: loss 0.597988\n",
      "iteration 267 / 300: loss 0.597677\n",
      "iteration 267 / 300: loss 0.600953\n",
      "iteration 267 / 300: loss 0.597422\n",
      "iteration 267 / 300: loss 0.598776\n",
      "iteration 267 / 300: loss 0.587806\n",
      "iteration 267 / 300: loss 0.600499\n",
      "iteration 267 / 300: loss 0.599650\n",
      "iteration 267 / 300: loss 0.617540\n",
      "iteration 267 / 300: loss 0.598875\n",
      "iteration 267 / 300: loss 0.600801\n",
      "iteration 267 / 300: loss 0.605305\n",
      "iteration 267 / 300: loss 0.598592\n",
      "iteration 267 / 300: loss 0.591474\n",
      "iteration 267 / 300: loss 0.580382\n",
      "iteration 267 / 300: loss 0.598221\n",
      "iteration 267 / 300: loss 0.611685\n",
      "iteration 267 / 300: loss 0.613219\n",
      "iteration 267 / 300: loss 0.582214\n",
      "iteration 267 / 300: loss 0.601955\n",
      "iteration 267 / 300: loss 0.608956\n",
      "iteration 267 / 300: loss 0.601794\n",
      "iteration 267 / 300: loss 0.607944\n",
      "iteration 267 / 300: loss 0.620236\n",
      "iteration 267 / 300: loss 0.584817\n",
      "iteration 267 / 300: loss 0.583721\n",
      "iteration 267 / 300: loss 0.628849\n",
      "iteration 267 / 300: loss 0.609399\n",
      "iteration 267 / 300: loss 0.606265\n",
      "iteration 267 / 300: loss 0.599034\n",
      "iteration 267 / 300: loss 0.615876\n",
      "iteration 267 / 300: loss 0.596489\n",
      "iteration 267 / 300: loss 0.581430\n",
      "iteration 267 / 300: loss 0.609807\n",
      "iteration 267 / 300: loss 0.608125\n",
      "iteration 267 / 300: loss 0.598224\n",
      "iteration 267 / 300: loss 0.592022\n",
      "iteration 267 / 300: loss 0.611031\n",
      "iteration 267 / 300: loss 0.598550\n",
      "iteration 267 / 300: loss 0.581382\n",
      "iteration 267 / 300: loss 0.609580\n",
      "iteration 268 / 300: loss 0.578384\n",
      "iteration 268 / 300: loss 0.596214\n",
      "iteration 268 / 300: loss 0.569455\n",
      "iteration 268 / 300: loss 0.597849\n",
      "iteration 268 / 300: loss 0.598940\n",
      "iteration 268 / 300: loss 0.603876\n",
      "iteration 268 / 300: loss 0.615261\n",
      "iteration 268 / 300: loss 0.588227\n",
      "iteration 268 / 300: loss 0.627171\n",
      "iteration 268 / 300: loss 0.592600\n",
      "iteration 268 / 300: loss 0.621500\n",
      "iteration 268 / 300: loss 0.593093\n",
      "iteration 268 / 300: loss 0.600541\n",
      "iteration 268 / 300: loss 0.571000\n",
      "iteration 268 / 300: loss 0.592911\n",
      "iteration 268 / 300: loss 0.600043\n",
      "iteration 268 / 300: loss 0.598053\n",
      "iteration 268 / 300: loss 0.583712\n",
      "iteration 268 / 300: loss 0.614355\n",
      "iteration 268 / 300: loss 0.591285\n",
      "iteration 268 / 300: loss 0.591391\n",
      "iteration 268 / 300: loss 0.594005\n",
      "iteration 268 / 300: loss 0.596735\n",
      "iteration 268 / 300: loss 0.596712\n",
      "iteration 268 / 300: loss 0.611735\n",
      "iteration 268 / 300: loss 0.607258\n",
      "iteration 268 / 300: loss 0.597031\n",
      "iteration 268 / 300: loss 0.596301\n",
      "iteration 268 / 300: loss 0.627391\n",
      "iteration 268 / 300: loss 0.601584\n",
      "iteration 268 / 300: loss 0.599923\n",
      "iteration 268 / 300: loss 0.621952\n",
      "iteration 268 / 300: loss 0.581435\n",
      "iteration 268 / 300: loss 0.599604\n",
      "iteration 268 / 300: loss 0.591182\n",
      "iteration 268 / 300: loss 0.599919\n",
      "iteration 268 / 300: loss 0.596015\n",
      "iteration 268 / 300: loss 0.590760\n",
      "iteration 268 / 300: loss 0.591961\n",
      "iteration 268 / 300: loss 0.615468\n",
      "iteration 268 / 300: loss 0.621360\n",
      "iteration 268 / 300: loss 0.587267\n",
      "iteration 268 / 300: loss 0.582483\n",
      "iteration 268 / 300: loss 0.585572\n",
      "iteration 268 / 300: loss 0.603666\n",
      "iteration 268 / 300: loss 0.585192\n",
      "iteration 268 / 300: loss 0.578880\n",
      "iteration 268 / 300: loss 0.576418\n",
      "iteration 268 / 300: loss 0.574097\n",
      "iteration 268 / 300: loss 0.600500\n",
      "iteration 268 / 300: loss 0.584490\n",
      "iteration 268 / 300: loss 0.584834\n",
      "iteration 268 / 300: loss 0.568323\n",
      "iteration 268 / 300: loss 0.592025\n",
      "iteration 268 / 300: loss 0.612116\n",
      "iteration 268 / 300: loss 0.608923\n",
      "iteration 268 / 300: loss 0.607613\n",
      "iteration 268 / 300: loss 0.595533\n",
      "iteration 268 / 300: loss 0.592837\n",
      "iteration 268 / 300: loss 0.597988\n",
      "iteration 268 / 300: loss 0.597677\n",
      "iteration 268 / 300: loss 0.600953\n",
      "iteration 268 / 300: loss 0.597422\n",
      "iteration 268 / 300: loss 0.598776\n",
      "iteration 268 / 300: loss 0.587806\n",
      "iteration 268 / 300: loss 0.600499\n",
      "iteration 268 / 300: loss 0.599650\n",
      "iteration 268 / 300: loss 0.617540\n",
      "iteration 268 / 300: loss 0.598875\n",
      "iteration 268 / 300: loss 0.600801\n",
      "iteration 268 / 300: loss 0.605305\n",
      "iteration 268 / 300: loss 0.598592\n",
      "iteration 268 / 300: loss 0.591474\n",
      "iteration 268 / 300: loss 0.580382\n",
      "iteration 268 / 300: loss 0.598221\n",
      "iteration 268 / 300: loss 0.611685\n",
      "iteration 268 / 300: loss 0.613219\n",
      "iteration 268 / 300: loss 0.582214\n",
      "iteration 268 / 300: loss 0.601955\n",
      "iteration 268 / 300: loss 0.608956\n",
      "iteration 268 / 300: loss 0.601794\n",
      "iteration 268 / 300: loss 0.607944\n",
      "iteration 268 / 300: loss 0.620236\n",
      "iteration 268 / 300: loss 0.584817\n",
      "iteration 268 / 300: loss 0.583721\n",
      "iteration 268 / 300: loss 0.628849\n",
      "iteration 268 / 300: loss 0.609399\n",
      "iteration 268 / 300: loss 0.606265\n",
      "iteration 268 / 300: loss 0.599034\n",
      "iteration 268 / 300: loss 0.615876\n",
      "iteration 268 / 300: loss 0.596489\n",
      "iteration 268 / 300: loss 0.581430\n",
      "iteration 268 / 300: loss 0.609807\n",
      "iteration 268 / 300: loss 0.608125\n",
      "iteration 268 / 300: loss 0.598224\n",
      "iteration 268 / 300: loss 0.592022\n",
      "iteration 268 / 300: loss 0.611031\n",
      "iteration 268 / 300: loss 0.598550\n",
      "iteration 268 / 300: loss 0.581382\n",
      "iteration 268 / 300: loss 0.609580\n",
      "iteration 269 / 300: loss 0.578384\n",
      "iteration 269 / 300: loss 0.596214\n",
      "iteration 269 / 300: loss 0.569455\n",
      "iteration 269 / 300: loss 0.597849\n",
      "iteration 269 / 300: loss 0.598940\n",
      "iteration 269 / 300: loss 0.603876\n",
      "iteration 269 / 300: loss 0.615261\n",
      "iteration 269 / 300: loss 0.588227\n",
      "iteration 269 / 300: loss 0.627171\n",
      "iteration 269 / 300: loss 0.592600\n",
      "iteration 269 / 300: loss 0.621500\n",
      "iteration 269 / 300: loss 0.593093\n",
      "iteration 269 / 300: loss 0.600541\n",
      "iteration 269 / 300: loss 0.571000\n",
      "iteration 269 / 300: loss 0.592911\n",
      "iteration 269 / 300: loss 0.600043\n",
      "iteration 269 / 300: loss 0.598053\n",
      "iteration 269 / 300: loss 0.583712\n",
      "iteration 269 / 300: loss 0.614355\n",
      "iteration 269 / 300: loss 0.591285\n",
      "iteration 269 / 300: loss 0.591391\n",
      "iteration 269 / 300: loss 0.594005\n",
      "iteration 269 / 300: loss 0.596735\n",
      "iteration 269 / 300: loss 0.596712\n",
      "iteration 269 / 300: loss 0.611735\n",
      "iteration 269 / 300: loss 0.607258\n",
      "iteration 269 / 300: loss 0.597031\n",
      "iteration 269 / 300: loss 0.596301\n",
      "iteration 269 / 300: loss 0.627391\n",
      "iteration 269 / 300: loss 0.601584\n",
      "iteration 269 / 300: loss 0.599923\n",
      "iteration 269 / 300: loss 0.621952\n",
      "iteration 269 / 300: loss 0.581435\n",
      "iteration 269 / 300: loss 0.599604\n",
      "iteration 269 / 300: loss 0.591182\n",
      "iteration 269 / 300: loss 0.599919\n",
      "iteration 269 / 300: loss 0.596015\n",
      "iteration 269 / 300: loss 0.590760\n",
      "iteration 269 / 300: loss 0.591961\n",
      "iteration 269 / 300: loss 0.615468\n",
      "iteration 269 / 300: loss 0.621360\n",
      "iteration 269 / 300: loss 0.587267\n",
      "iteration 269 / 300: loss 0.582483\n",
      "iteration 269 / 300: loss 0.585572\n",
      "iteration 269 / 300: loss 0.603666\n",
      "iteration 269 / 300: loss 0.585192\n",
      "iteration 269 / 300: loss 0.578880\n",
      "iteration 269 / 300: loss 0.576418\n",
      "iteration 269 / 300: loss 0.574097\n",
      "iteration 269 / 300: loss 0.600500\n",
      "iteration 269 / 300: loss 0.584490\n",
      "iteration 269 / 300: loss 0.584834\n",
      "iteration 269 / 300: loss 0.568323\n",
      "iteration 269 / 300: loss 0.592025\n",
      "iteration 269 / 300: loss 0.612116\n",
      "iteration 269 / 300: loss 0.608923\n",
      "iteration 269 / 300: loss 0.607613\n",
      "iteration 269 / 300: loss 0.595533\n",
      "iteration 269 / 300: loss 0.592837\n",
      "iteration 269 / 300: loss 0.597988\n",
      "iteration 269 / 300: loss 0.597677\n",
      "iteration 269 / 300: loss 0.600953\n",
      "iteration 269 / 300: loss 0.597422\n",
      "iteration 269 / 300: loss 0.598776\n",
      "iteration 269 / 300: loss 0.587806\n",
      "iteration 269 / 300: loss 0.600499\n",
      "iteration 269 / 300: loss 0.599650\n",
      "iteration 269 / 300: loss 0.617540\n",
      "iteration 269 / 300: loss 0.598875\n",
      "iteration 269 / 300: loss 0.600801\n",
      "iteration 269 / 300: loss 0.605305\n",
      "iteration 269 / 300: loss 0.598592\n",
      "iteration 269 / 300: loss 0.591474\n",
      "iteration 269 / 300: loss 0.580382\n",
      "iteration 269 / 300: loss 0.598221\n",
      "iteration 269 / 300: loss 0.611685\n",
      "iteration 269 / 300: loss 0.613219\n",
      "iteration 269 / 300: loss 0.582214\n",
      "iteration 269 / 300: loss 0.601955\n",
      "iteration 269 / 300: loss 0.608956\n",
      "iteration 269 / 300: loss 0.601794\n",
      "iteration 269 / 300: loss 0.607944\n",
      "iteration 269 / 300: loss 0.620236\n",
      "iteration 269 / 300: loss 0.584817\n",
      "iteration 269 / 300: loss 0.583721\n",
      "iteration 269 / 300: loss 0.628849\n",
      "iteration 269 / 300: loss 0.609399\n",
      "iteration 269 / 300: loss 0.606265\n",
      "iteration 269 / 300: loss 0.599034\n",
      "iteration 269 / 300: loss 0.615876\n",
      "iteration 269 / 300: loss 0.596489\n",
      "iteration 269 / 300: loss 0.581430\n",
      "iteration 269 / 300: loss 0.609807\n",
      "iteration 269 / 300: loss 0.608125\n",
      "iteration 269 / 300: loss 0.598224\n",
      "iteration 269 / 300: loss 0.592022\n",
      "iteration 269 / 300: loss 0.611031\n",
      "iteration 269 / 300: loss 0.598550\n",
      "iteration 269 / 300: loss 0.581382\n",
      "iteration 269 / 300: loss 0.609580\n",
      "iteration 270 / 300: loss 0.578384\n",
      "iteration 270 / 300: loss 0.596214\n",
      "iteration 270 / 300: loss 0.569455\n",
      "iteration 270 / 300: loss 0.597849\n",
      "iteration 270 / 300: loss 0.598940\n",
      "iteration 270 / 300: loss 0.603876\n",
      "iteration 270 / 300: loss 0.615261\n",
      "iteration 270 / 300: loss 0.588227\n",
      "iteration 270 / 300: loss 0.627171\n",
      "iteration 270 / 300: loss 0.592600\n",
      "iteration 270 / 300: loss 0.621500\n",
      "iteration 270 / 300: loss 0.593093\n",
      "iteration 270 / 300: loss 0.600541\n",
      "iteration 270 / 300: loss 0.571000\n",
      "iteration 270 / 300: loss 0.592911\n",
      "iteration 270 / 300: loss 0.600043\n",
      "iteration 270 / 300: loss 0.598053\n",
      "iteration 270 / 300: loss 0.583712\n",
      "iteration 270 / 300: loss 0.614355\n",
      "iteration 270 / 300: loss 0.591285\n",
      "iteration 270 / 300: loss 0.591391\n",
      "iteration 270 / 300: loss 0.594005\n",
      "iteration 270 / 300: loss 0.596735\n",
      "iteration 270 / 300: loss 0.596712\n",
      "iteration 270 / 300: loss 0.611735\n",
      "iteration 270 / 300: loss 0.607258\n",
      "iteration 270 / 300: loss 0.597031\n",
      "iteration 270 / 300: loss 0.596301\n",
      "iteration 270 / 300: loss 0.627391\n",
      "iteration 270 / 300: loss 0.601584\n",
      "iteration 270 / 300: loss 0.599923\n",
      "iteration 270 / 300: loss 0.621952\n",
      "iteration 270 / 300: loss 0.581435\n",
      "iteration 270 / 300: loss 0.599604\n",
      "iteration 270 / 300: loss 0.591182\n",
      "iteration 270 / 300: loss 0.599919\n",
      "iteration 270 / 300: loss 0.596015\n",
      "iteration 270 / 300: loss 0.590760\n",
      "iteration 270 / 300: loss 0.591961\n",
      "iteration 270 / 300: loss 0.615468\n",
      "iteration 270 / 300: loss 0.621360\n",
      "iteration 270 / 300: loss 0.587267\n",
      "iteration 270 / 300: loss 0.582483\n",
      "iteration 270 / 300: loss 0.585572\n",
      "iteration 270 / 300: loss 0.603666\n",
      "iteration 270 / 300: loss 0.585192\n",
      "iteration 270 / 300: loss 0.578880\n",
      "iteration 270 / 300: loss 0.576418\n",
      "iteration 270 / 300: loss 0.574097\n",
      "iteration 270 / 300: loss 0.600500\n",
      "iteration 270 / 300: loss 0.584490\n",
      "iteration 270 / 300: loss 0.584834\n",
      "iteration 270 / 300: loss 0.568323\n",
      "iteration 270 / 300: loss 0.592025\n",
      "iteration 270 / 300: loss 0.612116\n",
      "iteration 270 / 300: loss 0.608923\n",
      "iteration 270 / 300: loss 0.607613\n",
      "iteration 270 / 300: loss 0.595533\n",
      "iteration 270 / 300: loss 0.592837\n",
      "iteration 270 / 300: loss 0.597988\n",
      "iteration 270 / 300: loss 0.597677\n",
      "iteration 270 / 300: loss 0.600953\n",
      "iteration 270 / 300: loss 0.597422\n",
      "iteration 270 / 300: loss 0.598776\n",
      "iteration 270 / 300: loss 0.587806\n",
      "iteration 270 / 300: loss 0.600499\n",
      "iteration 270 / 300: loss 0.599650\n",
      "iteration 270 / 300: loss 0.617540\n",
      "iteration 270 / 300: loss 0.598875\n",
      "iteration 270 / 300: loss 0.600801\n",
      "iteration 270 / 300: loss 0.605305\n",
      "iteration 270 / 300: loss 0.598592\n",
      "iteration 270 / 300: loss 0.591474\n",
      "iteration 270 / 300: loss 0.580382\n",
      "iteration 270 / 300: loss 0.598221\n",
      "iteration 270 / 300: loss 0.611685\n",
      "iteration 270 / 300: loss 0.613219\n",
      "iteration 270 / 300: loss 0.582214\n",
      "iteration 270 / 300: loss 0.601955\n",
      "iteration 270 / 300: loss 0.608956\n",
      "iteration 270 / 300: loss 0.601794\n",
      "iteration 270 / 300: loss 0.607944\n",
      "iteration 270 / 300: loss 0.620236\n",
      "iteration 270 / 300: loss 0.584817\n",
      "iteration 270 / 300: loss 0.583721\n",
      "iteration 270 / 300: loss 0.628849\n",
      "iteration 270 / 300: loss 0.609399\n",
      "iteration 270 / 300: loss 0.606265\n",
      "iteration 270 / 300: loss 0.599034\n",
      "iteration 270 / 300: loss 0.615876\n",
      "iteration 270 / 300: loss 0.596489\n",
      "iteration 270 / 300: loss 0.581430\n",
      "iteration 270 / 300: loss 0.609807\n",
      "iteration 270 / 300: loss 0.608125\n",
      "iteration 270 / 300: loss 0.598224\n",
      "iteration 270 / 300: loss 0.592022\n",
      "iteration 270 / 300: loss 0.611031\n",
      "iteration 270 / 300: loss 0.598550\n",
      "iteration 270 / 300: loss 0.581382\n",
      "iteration 270 / 300: loss 0.609580\n",
      "iteration 271 / 300: loss 0.578384\n",
      "iteration 271 / 300: loss 0.596214\n",
      "iteration 271 / 300: loss 0.569455\n",
      "iteration 271 / 300: loss 0.597849\n",
      "iteration 271 / 300: loss 0.598940\n",
      "iteration 271 / 300: loss 0.603876\n",
      "iteration 271 / 300: loss 0.615261\n",
      "iteration 271 / 300: loss 0.588227\n",
      "iteration 271 / 300: loss 0.627171\n",
      "iteration 271 / 300: loss 0.592600\n",
      "iteration 271 / 300: loss 0.621500\n",
      "iteration 271 / 300: loss 0.593093\n",
      "iteration 271 / 300: loss 0.600541\n",
      "iteration 271 / 300: loss 0.571000\n",
      "iteration 271 / 300: loss 0.592911\n",
      "iteration 271 / 300: loss 0.600043\n",
      "iteration 271 / 300: loss 0.598053\n",
      "iteration 271 / 300: loss 0.583712\n",
      "iteration 271 / 300: loss 0.614355\n",
      "iteration 271 / 300: loss 0.591285\n",
      "iteration 271 / 300: loss 0.591391\n",
      "iteration 271 / 300: loss 0.594005\n",
      "iteration 271 / 300: loss 0.596735\n",
      "iteration 271 / 300: loss 0.596712\n",
      "iteration 271 / 300: loss 0.611735\n",
      "iteration 271 / 300: loss 0.607258\n",
      "iteration 271 / 300: loss 0.597031\n",
      "iteration 271 / 300: loss 0.596301\n",
      "iteration 271 / 300: loss 0.627391\n",
      "iteration 271 / 300: loss 0.601584\n",
      "iteration 271 / 300: loss 0.599923\n",
      "iteration 271 / 300: loss 0.621952\n",
      "iteration 271 / 300: loss 0.581435\n",
      "iteration 271 / 300: loss 0.599604\n",
      "iteration 271 / 300: loss 0.591182\n",
      "iteration 271 / 300: loss 0.599919\n",
      "iteration 271 / 300: loss 0.596015\n",
      "iteration 271 / 300: loss 0.590760\n",
      "iteration 271 / 300: loss 0.591961\n",
      "iteration 271 / 300: loss 0.615468\n",
      "iteration 271 / 300: loss 0.621360\n",
      "iteration 271 / 300: loss 0.587267\n",
      "iteration 271 / 300: loss 0.582483\n",
      "iteration 271 / 300: loss 0.585572\n",
      "iteration 271 / 300: loss 0.603666\n",
      "iteration 271 / 300: loss 0.585192\n",
      "iteration 271 / 300: loss 0.578880\n",
      "iteration 271 / 300: loss 0.576418\n",
      "iteration 271 / 300: loss 0.574097\n",
      "iteration 271 / 300: loss 0.600500\n",
      "iteration 271 / 300: loss 0.584490\n",
      "iteration 271 / 300: loss 0.584834\n",
      "iteration 271 / 300: loss 0.568323\n",
      "iteration 271 / 300: loss 0.592025\n",
      "iteration 271 / 300: loss 0.612116\n",
      "iteration 271 / 300: loss 0.608923\n",
      "iteration 271 / 300: loss 0.607613\n",
      "iteration 271 / 300: loss 0.595533\n",
      "iteration 271 / 300: loss 0.592837\n",
      "iteration 271 / 300: loss 0.597988\n",
      "iteration 271 / 300: loss 0.597677\n",
      "iteration 271 / 300: loss 0.600953\n",
      "iteration 271 / 300: loss 0.597422\n",
      "iteration 271 / 300: loss 0.598776\n",
      "iteration 271 / 300: loss 0.587806\n",
      "iteration 271 / 300: loss 0.600499\n",
      "iteration 271 / 300: loss 0.599650\n",
      "iteration 271 / 300: loss 0.617540\n",
      "iteration 271 / 300: loss 0.598875\n",
      "iteration 271 / 300: loss 0.600801\n",
      "iteration 271 / 300: loss 0.605305\n",
      "iteration 271 / 300: loss 0.598592\n",
      "iteration 271 / 300: loss 0.591474\n",
      "iteration 271 / 300: loss 0.580382\n",
      "iteration 271 / 300: loss 0.598221\n",
      "iteration 271 / 300: loss 0.611685\n",
      "iteration 271 / 300: loss 0.613219\n",
      "iteration 271 / 300: loss 0.582214\n",
      "iteration 271 / 300: loss 0.601955\n",
      "iteration 271 / 300: loss 0.608956\n",
      "iteration 271 / 300: loss 0.601794\n",
      "iteration 271 / 300: loss 0.607944\n",
      "iteration 271 / 300: loss 0.620236\n",
      "iteration 271 / 300: loss 0.584817\n",
      "iteration 271 / 300: loss 0.583721\n",
      "iteration 271 / 300: loss 0.628849\n",
      "iteration 271 / 300: loss 0.609399\n",
      "iteration 271 / 300: loss 0.606265\n",
      "iteration 271 / 300: loss 0.599034\n",
      "iteration 271 / 300: loss 0.615876\n",
      "iteration 271 / 300: loss 0.596489\n",
      "iteration 271 / 300: loss 0.581430\n",
      "iteration 271 / 300: loss 0.609807\n",
      "iteration 271 / 300: loss 0.608125\n",
      "iteration 271 / 300: loss 0.598224\n",
      "iteration 271 / 300: loss 0.592022\n",
      "iteration 271 / 300: loss 0.611031\n",
      "iteration 271 / 300: loss 0.598550\n",
      "iteration 271 / 300: loss 0.581382\n",
      "iteration 271 / 300: loss 0.609580\n",
      "iteration 272 / 300: loss 0.578384\n",
      "iteration 272 / 300: loss 0.596214\n",
      "iteration 272 / 300: loss 0.569455\n",
      "iteration 272 / 300: loss 0.597849\n",
      "iteration 272 / 300: loss 0.598940\n",
      "iteration 272 / 300: loss 0.603876\n",
      "iteration 272 / 300: loss 0.615261\n",
      "iteration 272 / 300: loss 0.588227\n",
      "iteration 272 / 300: loss 0.627171\n",
      "iteration 272 / 300: loss 0.592600\n",
      "iteration 272 / 300: loss 0.621500\n",
      "iteration 272 / 300: loss 0.593093\n",
      "iteration 272 / 300: loss 0.600541\n",
      "iteration 272 / 300: loss 0.571000\n",
      "iteration 272 / 300: loss 0.592911\n",
      "iteration 272 / 300: loss 0.600043\n",
      "iteration 272 / 300: loss 0.598053\n",
      "iteration 272 / 300: loss 0.583712\n",
      "iteration 272 / 300: loss 0.614355\n",
      "iteration 272 / 300: loss 0.591285\n",
      "iteration 272 / 300: loss 0.591391\n",
      "iteration 272 / 300: loss 0.594005\n",
      "iteration 272 / 300: loss 0.596735\n",
      "iteration 272 / 300: loss 0.596712\n",
      "iteration 272 / 300: loss 0.611735\n",
      "iteration 272 / 300: loss 0.607258\n",
      "iteration 272 / 300: loss 0.597031\n",
      "iteration 272 / 300: loss 0.596301\n",
      "iteration 272 / 300: loss 0.627391\n",
      "iteration 272 / 300: loss 0.601584\n",
      "iteration 272 / 300: loss 0.599923\n",
      "iteration 272 / 300: loss 0.621952\n",
      "iteration 272 / 300: loss 0.581435\n",
      "iteration 272 / 300: loss 0.599604\n",
      "iteration 272 / 300: loss 0.591182\n",
      "iteration 272 / 300: loss 0.599919\n",
      "iteration 272 / 300: loss 0.596015\n",
      "iteration 272 / 300: loss 0.590760\n",
      "iteration 272 / 300: loss 0.591961\n",
      "iteration 272 / 300: loss 0.615468\n",
      "iteration 272 / 300: loss 0.621360\n",
      "iteration 272 / 300: loss 0.587267\n",
      "iteration 272 / 300: loss 0.582483\n",
      "iteration 272 / 300: loss 0.585572\n",
      "iteration 272 / 300: loss 0.603666\n",
      "iteration 272 / 300: loss 0.585192\n",
      "iteration 272 / 300: loss 0.578880\n",
      "iteration 272 / 300: loss 0.576418\n",
      "iteration 272 / 300: loss 0.574097\n",
      "iteration 272 / 300: loss 0.600500\n",
      "iteration 272 / 300: loss 0.584490\n",
      "iteration 272 / 300: loss 0.584834\n",
      "iteration 272 / 300: loss 0.568323\n",
      "iteration 272 / 300: loss 0.592025\n",
      "iteration 272 / 300: loss 0.612116\n",
      "iteration 272 / 300: loss 0.608923\n",
      "iteration 272 / 300: loss 0.607613\n",
      "iteration 272 / 300: loss 0.595533\n",
      "iteration 272 / 300: loss 0.592837\n",
      "iteration 272 / 300: loss 0.597988\n",
      "iteration 272 / 300: loss 0.597677\n",
      "iteration 272 / 300: loss 0.600953\n",
      "iteration 272 / 300: loss 0.597422\n",
      "iteration 272 / 300: loss 0.598776\n",
      "iteration 272 / 300: loss 0.587806\n",
      "iteration 272 / 300: loss 0.600499\n",
      "iteration 272 / 300: loss 0.599650\n",
      "iteration 272 / 300: loss 0.617540\n",
      "iteration 272 / 300: loss 0.598875\n",
      "iteration 272 / 300: loss 0.600801\n",
      "iteration 272 / 300: loss 0.605305\n",
      "iteration 272 / 300: loss 0.598592\n",
      "iteration 272 / 300: loss 0.591474\n",
      "iteration 272 / 300: loss 0.580382\n",
      "iteration 272 / 300: loss 0.598221\n",
      "iteration 272 / 300: loss 0.611685\n",
      "iteration 272 / 300: loss 0.613219\n",
      "iteration 272 / 300: loss 0.582214\n",
      "iteration 272 / 300: loss 0.601955\n",
      "iteration 272 / 300: loss 0.608956\n",
      "iteration 272 / 300: loss 0.601794\n",
      "iteration 272 / 300: loss 0.607944\n",
      "iteration 272 / 300: loss 0.620236\n",
      "iteration 272 / 300: loss 0.584817\n",
      "iteration 272 / 300: loss 0.583721\n",
      "iteration 272 / 300: loss 0.628849\n",
      "iteration 272 / 300: loss 0.609399\n",
      "iteration 272 / 300: loss 0.606265\n",
      "iteration 272 / 300: loss 0.599034\n",
      "iteration 272 / 300: loss 0.615876\n",
      "iteration 272 / 300: loss 0.596489\n",
      "iteration 272 / 300: loss 0.581430\n",
      "iteration 272 / 300: loss 0.609807\n",
      "iteration 272 / 300: loss 0.608125\n",
      "iteration 272 / 300: loss 0.598224\n",
      "iteration 272 / 300: loss 0.592022\n",
      "iteration 272 / 300: loss 0.611031\n",
      "iteration 272 / 300: loss 0.598550\n",
      "iteration 272 / 300: loss 0.581382\n",
      "iteration 272 / 300: loss 0.609580\n",
      "iteration 273 / 300: loss 0.578384\n",
      "iteration 273 / 300: loss 0.596214\n",
      "iteration 273 / 300: loss 0.569455\n",
      "iteration 273 / 300: loss 0.597849\n",
      "iteration 273 / 300: loss 0.598940\n",
      "iteration 273 / 300: loss 0.603876\n",
      "iteration 273 / 300: loss 0.615261\n",
      "iteration 273 / 300: loss 0.588227\n",
      "iteration 273 / 300: loss 0.627171\n",
      "iteration 273 / 300: loss 0.592600\n",
      "iteration 273 / 300: loss 0.621500\n",
      "iteration 273 / 300: loss 0.593093\n",
      "iteration 273 / 300: loss 0.600541\n",
      "iteration 273 / 300: loss 0.571000\n",
      "iteration 273 / 300: loss 0.592911\n",
      "iteration 273 / 300: loss 0.600043\n",
      "iteration 273 / 300: loss 0.598053\n",
      "iteration 273 / 300: loss 0.583712\n",
      "iteration 273 / 300: loss 0.614355\n",
      "iteration 273 / 300: loss 0.591285\n",
      "iteration 273 / 300: loss 0.591391\n",
      "iteration 273 / 300: loss 0.594005\n",
      "iteration 273 / 300: loss 0.596735\n",
      "iteration 273 / 300: loss 0.596712\n",
      "iteration 273 / 300: loss 0.611735\n",
      "iteration 273 / 300: loss 0.607258\n",
      "iteration 273 / 300: loss 0.597031\n",
      "iteration 273 / 300: loss 0.596301\n",
      "iteration 273 / 300: loss 0.627391\n",
      "iteration 273 / 300: loss 0.601584\n",
      "iteration 273 / 300: loss 0.599923\n",
      "iteration 273 / 300: loss 0.621952\n",
      "iteration 273 / 300: loss 0.581435\n",
      "iteration 273 / 300: loss 0.599604\n",
      "iteration 273 / 300: loss 0.591182\n",
      "iteration 273 / 300: loss 0.599919\n",
      "iteration 273 / 300: loss 0.596015\n",
      "iteration 273 / 300: loss 0.590760\n",
      "iteration 273 / 300: loss 0.591961\n",
      "iteration 273 / 300: loss 0.615468\n",
      "iteration 273 / 300: loss 0.621360\n",
      "iteration 273 / 300: loss 0.587267\n",
      "iteration 273 / 300: loss 0.582483\n",
      "iteration 273 / 300: loss 0.585572\n",
      "iteration 273 / 300: loss 0.603666\n",
      "iteration 273 / 300: loss 0.585192\n",
      "iteration 273 / 300: loss 0.578880\n",
      "iteration 273 / 300: loss 0.576418\n",
      "iteration 273 / 300: loss 0.574097\n",
      "iteration 273 / 300: loss 0.600500\n",
      "iteration 273 / 300: loss 0.584490\n",
      "iteration 273 / 300: loss 0.584834\n",
      "iteration 273 / 300: loss 0.568323\n",
      "iteration 273 / 300: loss 0.592025\n",
      "iteration 273 / 300: loss 0.612116\n",
      "iteration 273 / 300: loss 0.608923\n",
      "iteration 273 / 300: loss 0.607613\n",
      "iteration 273 / 300: loss 0.595533\n",
      "iteration 273 / 300: loss 0.592837\n",
      "iteration 273 / 300: loss 0.597988\n",
      "iteration 273 / 300: loss 0.597677\n",
      "iteration 273 / 300: loss 0.600953\n",
      "iteration 273 / 300: loss 0.597422\n",
      "iteration 273 / 300: loss 0.598776\n",
      "iteration 273 / 300: loss 0.587806\n",
      "iteration 273 / 300: loss 0.600499\n",
      "iteration 273 / 300: loss 0.599650\n",
      "iteration 273 / 300: loss 0.617540\n",
      "iteration 273 / 300: loss 0.598875\n",
      "iteration 273 / 300: loss 0.600801\n",
      "iteration 273 / 300: loss 0.605305\n",
      "iteration 273 / 300: loss 0.598592\n",
      "iteration 273 / 300: loss 0.591474\n",
      "iteration 273 / 300: loss 0.580382\n",
      "iteration 273 / 300: loss 0.598221\n",
      "iteration 273 / 300: loss 0.611685\n",
      "iteration 273 / 300: loss 0.613219\n",
      "iteration 273 / 300: loss 0.582214\n",
      "iteration 273 / 300: loss 0.601955\n",
      "iteration 273 / 300: loss 0.608956\n",
      "iteration 273 / 300: loss 0.601794\n",
      "iteration 273 / 300: loss 0.607944\n",
      "iteration 273 / 300: loss 0.620236\n",
      "iteration 273 / 300: loss 0.584817\n",
      "iteration 273 / 300: loss 0.583721\n",
      "iteration 273 / 300: loss 0.628849\n",
      "iteration 273 / 300: loss 0.609399\n",
      "iteration 273 / 300: loss 0.606265\n",
      "iteration 273 / 300: loss 0.599034\n",
      "iteration 273 / 300: loss 0.615876\n",
      "iteration 273 / 300: loss 0.596489\n",
      "iteration 273 / 300: loss 0.581430\n",
      "iteration 273 / 300: loss 0.609807\n",
      "iteration 273 / 300: loss 0.608125\n",
      "iteration 273 / 300: loss 0.598224\n",
      "iteration 273 / 300: loss 0.592022\n",
      "iteration 273 / 300: loss 0.611031\n",
      "iteration 273 / 300: loss 0.598550\n",
      "iteration 273 / 300: loss 0.581382\n",
      "iteration 273 / 300: loss 0.609580\n",
      "iteration 274 / 300: loss 0.578384\n",
      "iteration 274 / 300: loss 0.596214\n",
      "iteration 274 / 300: loss 0.569455\n",
      "iteration 274 / 300: loss 0.597849\n",
      "iteration 274 / 300: loss 0.598940\n",
      "iteration 274 / 300: loss 0.603876\n",
      "iteration 274 / 300: loss 0.615261\n",
      "iteration 274 / 300: loss 0.588227\n",
      "iteration 274 / 300: loss 0.627171\n",
      "iteration 274 / 300: loss 0.592600\n",
      "iteration 274 / 300: loss 0.621500\n",
      "iteration 274 / 300: loss 0.593093\n",
      "iteration 274 / 300: loss 0.600541\n",
      "iteration 274 / 300: loss 0.571000\n",
      "iteration 274 / 300: loss 0.592911\n",
      "iteration 274 / 300: loss 0.600043\n",
      "iteration 274 / 300: loss 0.598053\n",
      "iteration 274 / 300: loss 0.583712\n",
      "iteration 274 / 300: loss 0.614355\n",
      "iteration 274 / 300: loss 0.591285\n",
      "iteration 274 / 300: loss 0.591391\n",
      "iteration 274 / 300: loss 0.594005\n",
      "iteration 274 / 300: loss 0.596735\n",
      "iteration 274 / 300: loss 0.596712\n",
      "iteration 274 / 300: loss 0.611735\n",
      "iteration 274 / 300: loss 0.607258\n",
      "iteration 274 / 300: loss 0.597031\n",
      "iteration 274 / 300: loss 0.596301\n",
      "iteration 274 / 300: loss 0.627391\n",
      "iteration 274 / 300: loss 0.601584\n",
      "iteration 274 / 300: loss 0.599923\n",
      "iteration 274 / 300: loss 0.621952\n",
      "iteration 274 / 300: loss 0.581435\n",
      "iteration 274 / 300: loss 0.599604\n",
      "iteration 274 / 300: loss 0.591182\n",
      "iteration 274 / 300: loss 0.599919\n",
      "iteration 274 / 300: loss 0.596015\n",
      "iteration 274 / 300: loss 0.590760\n",
      "iteration 274 / 300: loss 0.591961\n",
      "iteration 274 / 300: loss 0.615468\n",
      "iteration 274 / 300: loss 0.621360\n",
      "iteration 274 / 300: loss 0.587267\n",
      "iteration 274 / 300: loss 0.582483\n",
      "iteration 274 / 300: loss 0.585572\n",
      "iteration 274 / 300: loss 0.603666\n",
      "iteration 274 / 300: loss 0.585192\n",
      "iteration 274 / 300: loss 0.578880\n",
      "iteration 274 / 300: loss 0.576418\n",
      "iteration 274 / 300: loss 0.574097\n",
      "iteration 274 / 300: loss 0.600500\n",
      "iteration 274 / 300: loss 0.584490\n",
      "iteration 274 / 300: loss 0.584834\n",
      "iteration 274 / 300: loss 0.568323\n",
      "iteration 274 / 300: loss 0.592025\n",
      "iteration 274 / 300: loss 0.612116\n",
      "iteration 274 / 300: loss 0.608923\n",
      "iteration 274 / 300: loss 0.607613\n",
      "iteration 274 / 300: loss 0.595533\n",
      "iteration 274 / 300: loss 0.592837\n",
      "iteration 274 / 300: loss 0.597988\n",
      "iteration 274 / 300: loss 0.597677\n",
      "iteration 274 / 300: loss 0.600953\n",
      "iteration 274 / 300: loss 0.597422\n",
      "iteration 274 / 300: loss 0.598776\n",
      "iteration 274 / 300: loss 0.587806\n",
      "iteration 274 / 300: loss 0.600499\n",
      "iteration 274 / 300: loss 0.599650\n",
      "iteration 274 / 300: loss 0.617540\n",
      "iteration 274 / 300: loss 0.598875\n",
      "iteration 274 / 300: loss 0.600801\n",
      "iteration 274 / 300: loss 0.605305\n",
      "iteration 274 / 300: loss 0.598592\n",
      "iteration 274 / 300: loss 0.591474\n",
      "iteration 274 / 300: loss 0.580382\n",
      "iteration 274 / 300: loss 0.598221\n",
      "iteration 274 / 300: loss 0.611685\n",
      "iteration 274 / 300: loss 0.613219\n",
      "iteration 274 / 300: loss 0.582214\n",
      "iteration 274 / 300: loss 0.601955\n",
      "iteration 274 / 300: loss 0.608956\n",
      "iteration 274 / 300: loss 0.601794\n",
      "iteration 274 / 300: loss 0.607944\n",
      "iteration 274 / 300: loss 0.620236\n",
      "iteration 274 / 300: loss 0.584817\n",
      "iteration 274 / 300: loss 0.583721\n",
      "iteration 274 / 300: loss 0.628849\n",
      "iteration 274 / 300: loss 0.609399\n",
      "iteration 274 / 300: loss 0.606265\n",
      "iteration 274 / 300: loss 0.599034\n",
      "iteration 274 / 300: loss 0.615876\n",
      "iteration 274 / 300: loss 0.596489\n",
      "iteration 274 / 300: loss 0.581430\n",
      "iteration 274 / 300: loss 0.609807\n",
      "iteration 274 / 300: loss 0.608125\n",
      "iteration 274 / 300: loss 0.598224\n",
      "iteration 274 / 300: loss 0.592022\n",
      "iteration 274 / 300: loss 0.611031\n",
      "iteration 274 / 300: loss 0.598550\n",
      "iteration 274 / 300: loss 0.581382\n",
      "iteration 274 / 300: loss 0.609580\n",
      "iteration 275 / 300: loss 0.578384\n",
      "iteration 275 / 300: loss 0.596214\n",
      "iteration 275 / 300: loss 0.569455\n",
      "iteration 275 / 300: loss 0.597849\n",
      "iteration 275 / 300: loss 0.598940\n",
      "iteration 275 / 300: loss 0.603876\n",
      "iteration 275 / 300: loss 0.615261\n",
      "iteration 275 / 300: loss 0.588227\n",
      "iteration 275 / 300: loss 0.627171\n",
      "iteration 275 / 300: loss 0.592600\n",
      "iteration 275 / 300: loss 0.621500\n",
      "iteration 275 / 300: loss 0.593093\n",
      "iteration 275 / 300: loss 0.600541\n",
      "iteration 275 / 300: loss 0.571000\n",
      "iteration 275 / 300: loss 0.592911\n",
      "iteration 275 / 300: loss 0.600043\n",
      "iteration 275 / 300: loss 0.598053\n",
      "iteration 275 / 300: loss 0.583712\n",
      "iteration 275 / 300: loss 0.614355\n",
      "iteration 275 / 300: loss 0.591285\n",
      "iteration 275 / 300: loss 0.591391\n",
      "iteration 275 / 300: loss 0.594005\n",
      "iteration 275 / 300: loss 0.596735\n",
      "iteration 275 / 300: loss 0.596712\n",
      "iteration 275 / 300: loss 0.611735\n",
      "iteration 275 / 300: loss 0.607258\n",
      "iteration 275 / 300: loss 0.597031\n",
      "iteration 275 / 300: loss 0.596301\n",
      "iteration 275 / 300: loss 0.627391\n",
      "iteration 275 / 300: loss 0.601584\n",
      "iteration 275 / 300: loss 0.599923\n",
      "iteration 275 / 300: loss 0.621952\n",
      "iteration 275 / 300: loss 0.581435\n",
      "iteration 275 / 300: loss 0.599604\n",
      "iteration 275 / 300: loss 0.591182\n",
      "iteration 275 / 300: loss 0.599919\n",
      "iteration 275 / 300: loss 0.596015\n",
      "iteration 275 / 300: loss 0.590760\n",
      "iteration 275 / 300: loss 0.591961\n",
      "iteration 275 / 300: loss 0.615468\n",
      "iteration 275 / 300: loss 0.621360\n",
      "iteration 275 / 300: loss 0.587267\n",
      "iteration 275 / 300: loss 0.582483\n",
      "iteration 275 / 300: loss 0.585572\n",
      "iteration 275 / 300: loss 0.603666\n",
      "iteration 275 / 300: loss 0.585192\n",
      "iteration 275 / 300: loss 0.578880\n",
      "iteration 275 / 300: loss 0.576418\n",
      "iteration 275 / 300: loss 0.574097\n",
      "iteration 275 / 300: loss 0.600500\n",
      "iteration 275 / 300: loss 0.584490\n",
      "iteration 275 / 300: loss 0.584834\n",
      "iteration 275 / 300: loss 0.568323\n",
      "iteration 275 / 300: loss 0.592025\n",
      "iteration 275 / 300: loss 0.612116\n",
      "iteration 275 / 300: loss 0.608923\n",
      "iteration 275 / 300: loss 0.607613\n",
      "iteration 275 / 300: loss 0.595533\n",
      "iteration 275 / 300: loss 0.592837\n",
      "iteration 275 / 300: loss 0.597988\n",
      "iteration 275 / 300: loss 0.597677\n",
      "iteration 275 / 300: loss 0.600953\n",
      "iteration 275 / 300: loss 0.597422\n",
      "iteration 275 / 300: loss 0.598776\n",
      "iteration 275 / 300: loss 0.587806\n",
      "iteration 275 / 300: loss 0.600499\n",
      "iteration 275 / 300: loss 0.599650\n",
      "iteration 275 / 300: loss 0.617540\n",
      "iteration 275 / 300: loss 0.598875\n",
      "iteration 275 / 300: loss 0.600801\n",
      "iteration 275 / 300: loss 0.605305\n",
      "iteration 275 / 300: loss 0.598592\n",
      "iteration 275 / 300: loss 0.591474\n",
      "iteration 275 / 300: loss 0.580382\n",
      "iteration 275 / 300: loss 0.598221\n",
      "iteration 275 / 300: loss 0.611685\n",
      "iteration 275 / 300: loss 0.613219\n",
      "iteration 275 / 300: loss 0.582214\n",
      "iteration 275 / 300: loss 0.601955\n",
      "iteration 275 / 300: loss 0.608956\n",
      "iteration 275 / 300: loss 0.601794\n",
      "iteration 275 / 300: loss 0.607944\n",
      "iteration 275 / 300: loss 0.620236\n",
      "iteration 275 / 300: loss 0.584817\n",
      "iteration 275 / 300: loss 0.583721\n",
      "iteration 275 / 300: loss 0.628849\n",
      "iteration 275 / 300: loss 0.609399\n",
      "iteration 275 / 300: loss 0.606265\n",
      "iteration 275 / 300: loss 0.599034\n",
      "iteration 275 / 300: loss 0.615876\n",
      "iteration 275 / 300: loss 0.596489\n",
      "iteration 275 / 300: loss 0.581430\n",
      "iteration 275 / 300: loss 0.609807\n",
      "iteration 275 / 300: loss 0.608125\n",
      "iteration 275 / 300: loss 0.598224\n",
      "iteration 275 / 300: loss 0.592022\n",
      "iteration 275 / 300: loss 0.611031\n",
      "iteration 275 / 300: loss 0.598550\n",
      "iteration 275 / 300: loss 0.581382\n",
      "iteration 275 / 300: loss 0.609580\n",
      "iteration 276 / 300: loss 0.578384\n",
      "iteration 276 / 300: loss 0.596214\n",
      "iteration 276 / 300: loss 0.569455\n",
      "iteration 276 / 300: loss 0.597849\n",
      "iteration 276 / 300: loss 0.598940\n",
      "iteration 276 / 300: loss 0.603876\n",
      "iteration 276 / 300: loss 0.615261\n",
      "iteration 276 / 300: loss 0.588227\n",
      "iteration 276 / 300: loss 0.627171\n",
      "iteration 276 / 300: loss 0.592600\n",
      "iteration 276 / 300: loss 0.621500\n",
      "iteration 276 / 300: loss 0.593093\n",
      "iteration 276 / 300: loss 0.600541\n",
      "iteration 276 / 300: loss 0.571000\n",
      "iteration 276 / 300: loss 0.592911\n",
      "iteration 276 / 300: loss 0.600043\n",
      "iteration 276 / 300: loss 0.598053\n",
      "iteration 276 / 300: loss 0.583712\n",
      "iteration 276 / 300: loss 0.614355\n",
      "iteration 276 / 300: loss 0.591285\n",
      "iteration 276 / 300: loss 0.591391\n",
      "iteration 276 / 300: loss 0.594005\n",
      "iteration 276 / 300: loss 0.596735\n",
      "iteration 276 / 300: loss 0.596712\n",
      "iteration 276 / 300: loss 0.611735\n",
      "iteration 276 / 300: loss 0.607258\n",
      "iteration 276 / 300: loss 0.597031\n",
      "iteration 276 / 300: loss 0.596301\n",
      "iteration 276 / 300: loss 0.627391\n",
      "iteration 276 / 300: loss 0.601584\n",
      "iteration 276 / 300: loss 0.599923\n",
      "iteration 276 / 300: loss 0.621952\n",
      "iteration 276 / 300: loss 0.581435\n",
      "iteration 276 / 300: loss 0.599604\n",
      "iteration 276 / 300: loss 0.591182\n",
      "iteration 276 / 300: loss 0.599919\n",
      "iteration 276 / 300: loss 0.596015\n",
      "iteration 276 / 300: loss 0.590760\n",
      "iteration 276 / 300: loss 0.591961\n",
      "iteration 276 / 300: loss 0.615468\n",
      "iteration 276 / 300: loss 0.621360\n",
      "iteration 276 / 300: loss 0.587267\n",
      "iteration 276 / 300: loss 0.582483\n",
      "iteration 276 / 300: loss 0.585572\n",
      "iteration 276 / 300: loss 0.603666\n",
      "iteration 276 / 300: loss 0.585192\n",
      "iteration 276 / 300: loss 0.578880\n",
      "iteration 276 / 300: loss 0.576418\n",
      "iteration 276 / 300: loss 0.574097\n",
      "iteration 276 / 300: loss 0.600500\n",
      "iteration 276 / 300: loss 0.584490\n",
      "iteration 276 / 300: loss 0.584834\n",
      "iteration 276 / 300: loss 0.568323\n",
      "iteration 276 / 300: loss 0.592025\n",
      "iteration 276 / 300: loss 0.612116\n",
      "iteration 276 / 300: loss 0.608923\n",
      "iteration 276 / 300: loss 0.607613\n",
      "iteration 276 / 300: loss 0.595533\n",
      "iteration 276 / 300: loss 0.592837\n",
      "iteration 276 / 300: loss 0.597988\n",
      "iteration 276 / 300: loss 0.597677\n",
      "iteration 276 / 300: loss 0.600953\n",
      "iteration 276 / 300: loss 0.597422\n",
      "iteration 276 / 300: loss 0.598776\n",
      "iteration 276 / 300: loss 0.587806\n",
      "iteration 276 / 300: loss 0.600499\n",
      "iteration 276 / 300: loss 0.599650\n",
      "iteration 276 / 300: loss 0.617540\n",
      "iteration 276 / 300: loss 0.598875\n",
      "iteration 276 / 300: loss 0.600801\n",
      "iteration 276 / 300: loss 0.605305\n",
      "iteration 276 / 300: loss 0.598592\n",
      "iteration 276 / 300: loss 0.591474\n",
      "iteration 276 / 300: loss 0.580382\n",
      "iteration 276 / 300: loss 0.598221\n",
      "iteration 276 / 300: loss 0.611685\n",
      "iteration 276 / 300: loss 0.613219\n",
      "iteration 276 / 300: loss 0.582214\n",
      "iteration 276 / 300: loss 0.601955\n",
      "iteration 276 / 300: loss 0.608956\n",
      "iteration 276 / 300: loss 0.601794\n",
      "iteration 276 / 300: loss 0.607944\n",
      "iteration 276 / 300: loss 0.620236\n",
      "iteration 276 / 300: loss 0.584817\n",
      "iteration 276 / 300: loss 0.583721\n",
      "iteration 276 / 300: loss 0.628849\n",
      "iteration 276 / 300: loss 0.609399\n",
      "iteration 276 / 300: loss 0.606265\n",
      "iteration 276 / 300: loss 0.599034\n",
      "iteration 276 / 300: loss 0.615876\n",
      "iteration 276 / 300: loss 0.596489\n",
      "iteration 276 / 300: loss 0.581430\n",
      "iteration 276 / 300: loss 0.609807\n",
      "iteration 276 / 300: loss 0.608125\n",
      "iteration 276 / 300: loss 0.598224\n",
      "iteration 276 / 300: loss 0.592022\n",
      "iteration 276 / 300: loss 0.611031\n",
      "iteration 276 / 300: loss 0.598550\n",
      "iteration 276 / 300: loss 0.581382\n",
      "iteration 276 / 300: loss 0.609580\n",
      "iteration 277 / 300: loss 0.578384\n",
      "iteration 277 / 300: loss 0.596214\n",
      "iteration 277 / 300: loss 0.569455\n",
      "iteration 277 / 300: loss 0.597849\n",
      "iteration 277 / 300: loss 0.598940\n",
      "iteration 277 / 300: loss 0.603876\n",
      "iteration 277 / 300: loss 0.615261\n",
      "iteration 277 / 300: loss 0.588227\n",
      "iteration 277 / 300: loss 0.627171\n",
      "iteration 277 / 300: loss 0.592600\n",
      "iteration 277 / 300: loss 0.621500\n",
      "iteration 277 / 300: loss 0.593093\n",
      "iteration 277 / 300: loss 0.600541\n",
      "iteration 277 / 300: loss 0.571000\n",
      "iteration 277 / 300: loss 0.592911\n",
      "iteration 277 / 300: loss 0.600043\n",
      "iteration 277 / 300: loss 0.598053\n",
      "iteration 277 / 300: loss 0.583712\n",
      "iteration 277 / 300: loss 0.614355\n",
      "iteration 277 / 300: loss 0.591285\n",
      "iteration 277 / 300: loss 0.591391\n",
      "iteration 277 / 300: loss 0.594005\n",
      "iteration 277 / 300: loss 0.596735\n",
      "iteration 277 / 300: loss 0.596712\n",
      "iteration 277 / 300: loss 0.611735\n",
      "iteration 277 / 300: loss 0.607258\n",
      "iteration 277 / 300: loss 0.597031\n",
      "iteration 277 / 300: loss 0.596301\n",
      "iteration 277 / 300: loss 0.627391\n",
      "iteration 277 / 300: loss 0.601584\n",
      "iteration 277 / 300: loss 0.599923\n",
      "iteration 277 / 300: loss 0.621952\n",
      "iteration 277 / 300: loss 0.581435\n",
      "iteration 277 / 300: loss 0.599604\n",
      "iteration 277 / 300: loss 0.591182\n",
      "iteration 277 / 300: loss 0.599919\n",
      "iteration 277 / 300: loss 0.596015\n",
      "iteration 277 / 300: loss 0.590760\n",
      "iteration 277 / 300: loss 0.591961\n",
      "iteration 277 / 300: loss 0.615468\n",
      "iteration 277 / 300: loss 0.621360\n",
      "iteration 277 / 300: loss 0.587267\n",
      "iteration 277 / 300: loss 0.582483\n",
      "iteration 277 / 300: loss 0.585572\n",
      "iteration 277 / 300: loss 0.603666\n",
      "iteration 277 / 300: loss 0.585192\n",
      "iteration 277 / 300: loss 0.578880\n",
      "iteration 277 / 300: loss 0.576418\n",
      "iteration 277 / 300: loss 0.574097\n",
      "iteration 277 / 300: loss 0.600500\n",
      "iteration 277 / 300: loss 0.584490\n",
      "iteration 277 / 300: loss 0.584834\n",
      "iteration 277 / 300: loss 0.568323\n",
      "iteration 277 / 300: loss 0.592025\n",
      "iteration 277 / 300: loss 0.612116\n",
      "iteration 277 / 300: loss 0.608923\n",
      "iteration 277 / 300: loss 0.607613\n",
      "iteration 277 / 300: loss 0.595533\n",
      "iteration 277 / 300: loss 0.592837\n",
      "iteration 277 / 300: loss 0.597988\n",
      "iteration 277 / 300: loss 0.597677\n",
      "iteration 277 / 300: loss 0.600953\n",
      "iteration 277 / 300: loss 0.597422\n",
      "iteration 277 / 300: loss 0.598776\n",
      "iteration 277 / 300: loss 0.587806\n",
      "iteration 277 / 300: loss 0.600499\n",
      "iteration 277 / 300: loss 0.599650\n",
      "iteration 277 / 300: loss 0.617540\n",
      "iteration 277 / 300: loss 0.598875\n",
      "iteration 277 / 300: loss 0.600801\n",
      "iteration 277 / 300: loss 0.605305\n",
      "iteration 277 / 300: loss 0.598592\n",
      "iteration 277 / 300: loss 0.591474\n",
      "iteration 277 / 300: loss 0.580382\n",
      "iteration 277 / 300: loss 0.598221\n",
      "iteration 277 / 300: loss 0.611685\n",
      "iteration 277 / 300: loss 0.613219\n",
      "iteration 277 / 300: loss 0.582214\n",
      "iteration 277 / 300: loss 0.601955\n",
      "iteration 277 / 300: loss 0.608956\n",
      "iteration 277 / 300: loss 0.601794\n",
      "iteration 277 / 300: loss 0.607944\n",
      "iteration 277 / 300: loss 0.620236\n",
      "iteration 277 / 300: loss 0.584817\n",
      "iteration 277 / 300: loss 0.583721\n",
      "iteration 277 / 300: loss 0.628849\n",
      "iteration 277 / 300: loss 0.609399\n",
      "iteration 277 / 300: loss 0.606265\n",
      "iteration 277 / 300: loss 0.599034\n",
      "iteration 277 / 300: loss 0.615876\n",
      "iteration 277 / 300: loss 0.596489\n",
      "iteration 277 / 300: loss 0.581430\n",
      "iteration 277 / 300: loss 0.609807\n",
      "iteration 277 / 300: loss 0.608125\n",
      "iteration 277 / 300: loss 0.598224\n",
      "iteration 277 / 300: loss 0.592022\n",
      "iteration 277 / 300: loss 0.611031\n",
      "iteration 277 / 300: loss 0.598550\n",
      "iteration 277 / 300: loss 0.581382\n",
      "iteration 277 / 300: loss 0.609580\n",
      "iteration 278 / 300: loss 0.578384\n",
      "iteration 278 / 300: loss 0.596214\n",
      "iteration 278 / 300: loss 0.569455\n",
      "iteration 278 / 300: loss 0.597849\n",
      "iteration 278 / 300: loss 0.598940\n",
      "iteration 278 / 300: loss 0.603876\n",
      "iteration 278 / 300: loss 0.615261\n",
      "iteration 278 / 300: loss 0.588227\n",
      "iteration 278 / 300: loss 0.627171\n",
      "iteration 278 / 300: loss 0.592600\n",
      "iteration 278 / 300: loss 0.621500\n",
      "iteration 278 / 300: loss 0.593093\n",
      "iteration 278 / 300: loss 0.600541\n",
      "iteration 278 / 300: loss 0.571000\n",
      "iteration 278 / 300: loss 0.592911\n",
      "iteration 278 / 300: loss 0.600043\n",
      "iteration 278 / 300: loss 0.598053\n",
      "iteration 278 / 300: loss 0.583712\n",
      "iteration 278 / 300: loss 0.614355\n",
      "iteration 278 / 300: loss 0.591285\n",
      "iteration 278 / 300: loss 0.591391\n",
      "iteration 278 / 300: loss 0.594005\n",
      "iteration 278 / 300: loss 0.596735\n",
      "iteration 278 / 300: loss 0.596712\n",
      "iteration 278 / 300: loss 0.611735\n",
      "iteration 278 / 300: loss 0.607258\n",
      "iteration 278 / 300: loss 0.597031\n",
      "iteration 278 / 300: loss 0.596301\n",
      "iteration 278 / 300: loss 0.627391\n",
      "iteration 278 / 300: loss 0.601584\n",
      "iteration 278 / 300: loss 0.599923\n",
      "iteration 278 / 300: loss 0.621952\n",
      "iteration 278 / 300: loss 0.581435\n",
      "iteration 278 / 300: loss 0.599604\n",
      "iteration 278 / 300: loss 0.591182\n",
      "iteration 278 / 300: loss 0.599919\n",
      "iteration 278 / 300: loss 0.596015\n",
      "iteration 278 / 300: loss 0.590760\n",
      "iteration 278 / 300: loss 0.591961\n",
      "iteration 278 / 300: loss 0.615468\n",
      "iteration 278 / 300: loss 0.621360\n",
      "iteration 278 / 300: loss 0.587267\n",
      "iteration 278 / 300: loss 0.582483\n",
      "iteration 278 / 300: loss 0.585572\n",
      "iteration 278 / 300: loss 0.603666\n",
      "iteration 278 / 300: loss 0.585192\n",
      "iteration 278 / 300: loss 0.578880\n",
      "iteration 278 / 300: loss 0.576418\n",
      "iteration 278 / 300: loss 0.574097\n",
      "iteration 278 / 300: loss 0.600500\n",
      "iteration 278 / 300: loss 0.584490\n",
      "iteration 278 / 300: loss 0.584834\n",
      "iteration 278 / 300: loss 0.568323\n",
      "iteration 278 / 300: loss 0.592025\n",
      "iteration 278 / 300: loss 0.612116\n",
      "iteration 278 / 300: loss 0.608923\n",
      "iteration 278 / 300: loss 0.607613\n",
      "iteration 278 / 300: loss 0.595533\n",
      "iteration 278 / 300: loss 0.592837\n",
      "iteration 278 / 300: loss 0.597988\n",
      "iteration 278 / 300: loss 0.597677\n",
      "iteration 278 / 300: loss 0.600953\n",
      "iteration 278 / 300: loss 0.597422\n",
      "iteration 278 / 300: loss 0.598776\n",
      "iteration 278 / 300: loss 0.587806\n",
      "iteration 278 / 300: loss 0.600499\n",
      "iteration 278 / 300: loss 0.599650\n",
      "iteration 278 / 300: loss 0.617540\n",
      "iteration 278 / 300: loss 0.598875\n",
      "iteration 278 / 300: loss 0.600801\n",
      "iteration 278 / 300: loss 0.605305\n",
      "iteration 278 / 300: loss 0.598592\n",
      "iteration 278 / 300: loss 0.591474\n",
      "iteration 278 / 300: loss 0.580382\n",
      "iteration 278 / 300: loss 0.598221\n",
      "iteration 278 / 300: loss 0.611685\n",
      "iteration 278 / 300: loss 0.613219\n",
      "iteration 278 / 300: loss 0.582214\n",
      "iteration 278 / 300: loss 0.601955\n",
      "iteration 278 / 300: loss 0.608956\n",
      "iteration 278 / 300: loss 0.601794\n",
      "iteration 278 / 300: loss 0.607944\n",
      "iteration 278 / 300: loss 0.620236\n",
      "iteration 278 / 300: loss 0.584817\n",
      "iteration 278 / 300: loss 0.583721\n",
      "iteration 278 / 300: loss 0.628849\n",
      "iteration 278 / 300: loss 0.609399\n",
      "iteration 278 / 300: loss 0.606265\n",
      "iteration 278 / 300: loss 0.599034\n",
      "iteration 278 / 300: loss 0.615876\n",
      "iteration 278 / 300: loss 0.596489\n",
      "iteration 278 / 300: loss 0.581430\n",
      "iteration 278 / 300: loss 0.609807\n",
      "iteration 278 / 300: loss 0.608125\n",
      "iteration 278 / 300: loss 0.598224\n",
      "iteration 278 / 300: loss 0.592022\n",
      "iteration 278 / 300: loss 0.611031\n",
      "iteration 278 / 300: loss 0.598550\n",
      "iteration 278 / 300: loss 0.581382\n",
      "iteration 278 / 300: loss 0.609580\n",
      "iteration 279 / 300: loss 0.578384\n",
      "iteration 279 / 300: loss 0.596214\n",
      "iteration 279 / 300: loss 0.569455\n",
      "iteration 279 / 300: loss 0.597849\n",
      "iteration 279 / 300: loss 0.598940\n",
      "iteration 279 / 300: loss 0.603876\n",
      "iteration 279 / 300: loss 0.615261\n",
      "iteration 279 / 300: loss 0.588227\n",
      "iteration 279 / 300: loss 0.627171\n",
      "iteration 279 / 300: loss 0.592600\n",
      "iteration 279 / 300: loss 0.621500\n",
      "iteration 279 / 300: loss 0.593093\n",
      "iteration 279 / 300: loss 0.600541\n",
      "iteration 279 / 300: loss 0.571000\n",
      "iteration 279 / 300: loss 0.592911\n",
      "iteration 279 / 300: loss 0.600043\n",
      "iteration 279 / 300: loss 0.598053\n",
      "iteration 279 / 300: loss 0.583712\n",
      "iteration 279 / 300: loss 0.614355\n",
      "iteration 279 / 300: loss 0.591285\n",
      "iteration 279 / 300: loss 0.591391\n",
      "iteration 279 / 300: loss 0.594005\n",
      "iteration 279 / 300: loss 0.596735\n",
      "iteration 279 / 300: loss 0.596712\n",
      "iteration 279 / 300: loss 0.611735\n",
      "iteration 279 / 300: loss 0.607258\n",
      "iteration 279 / 300: loss 0.597031\n",
      "iteration 279 / 300: loss 0.596301\n",
      "iteration 279 / 300: loss 0.627391\n",
      "iteration 279 / 300: loss 0.601584\n",
      "iteration 279 / 300: loss 0.599923\n",
      "iteration 279 / 300: loss 0.621952\n",
      "iteration 279 / 300: loss 0.581435\n",
      "iteration 279 / 300: loss 0.599604\n",
      "iteration 279 / 300: loss 0.591182\n",
      "iteration 279 / 300: loss 0.599919\n",
      "iteration 279 / 300: loss 0.596015\n",
      "iteration 279 / 300: loss 0.590760\n",
      "iteration 279 / 300: loss 0.591961\n",
      "iteration 279 / 300: loss 0.615468\n",
      "iteration 279 / 300: loss 0.621360\n",
      "iteration 279 / 300: loss 0.587267\n",
      "iteration 279 / 300: loss 0.582483\n",
      "iteration 279 / 300: loss 0.585572\n",
      "iteration 279 / 300: loss 0.603666\n",
      "iteration 279 / 300: loss 0.585192\n",
      "iteration 279 / 300: loss 0.578880\n",
      "iteration 279 / 300: loss 0.576418\n",
      "iteration 279 / 300: loss 0.574097\n",
      "iteration 279 / 300: loss 0.600500\n",
      "iteration 279 / 300: loss 0.584490\n",
      "iteration 279 / 300: loss 0.584834\n",
      "iteration 279 / 300: loss 0.568323\n",
      "iteration 279 / 300: loss 0.592025\n",
      "iteration 279 / 300: loss 0.612116\n",
      "iteration 279 / 300: loss 0.608923\n",
      "iteration 279 / 300: loss 0.607613\n",
      "iteration 279 / 300: loss 0.595533\n",
      "iteration 279 / 300: loss 0.592837\n",
      "iteration 279 / 300: loss 0.597988\n",
      "iteration 279 / 300: loss 0.597677\n",
      "iteration 279 / 300: loss 0.600953\n",
      "iteration 279 / 300: loss 0.597422\n",
      "iteration 279 / 300: loss 0.598776\n",
      "iteration 279 / 300: loss 0.587806\n",
      "iteration 279 / 300: loss 0.600499\n",
      "iteration 279 / 300: loss 0.599650\n",
      "iteration 279 / 300: loss 0.617540\n",
      "iteration 279 / 300: loss 0.598875\n",
      "iteration 279 / 300: loss 0.600801\n",
      "iteration 279 / 300: loss 0.605305\n",
      "iteration 279 / 300: loss 0.598592\n",
      "iteration 279 / 300: loss 0.591474\n",
      "iteration 279 / 300: loss 0.580382\n",
      "iteration 279 / 300: loss 0.598221\n",
      "iteration 279 / 300: loss 0.611685\n",
      "iteration 279 / 300: loss 0.613219\n",
      "iteration 279 / 300: loss 0.582214\n",
      "iteration 279 / 300: loss 0.601955\n",
      "iteration 279 / 300: loss 0.608956\n",
      "iteration 279 / 300: loss 0.601794\n",
      "iteration 279 / 300: loss 0.607944\n",
      "iteration 279 / 300: loss 0.620236\n",
      "iteration 279 / 300: loss 0.584817\n",
      "iteration 279 / 300: loss 0.583721\n",
      "iteration 279 / 300: loss 0.628849\n",
      "iteration 279 / 300: loss 0.609399\n",
      "iteration 279 / 300: loss 0.606265\n",
      "iteration 279 / 300: loss 0.599034\n",
      "iteration 279 / 300: loss 0.615876\n",
      "iteration 279 / 300: loss 0.596489\n",
      "iteration 279 / 300: loss 0.581430\n",
      "iteration 279 / 300: loss 0.609807\n",
      "iteration 279 / 300: loss 0.608125\n",
      "iteration 279 / 300: loss 0.598224\n",
      "iteration 279 / 300: loss 0.592022\n",
      "iteration 279 / 300: loss 0.611031\n",
      "iteration 279 / 300: loss 0.598550\n",
      "iteration 279 / 300: loss 0.581382\n",
      "iteration 279 / 300: loss 0.609580\n",
      "iteration 280 / 300: loss 0.578384\n",
      "iteration 280 / 300: loss 0.596214\n",
      "iteration 280 / 300: loss 0.569455\n",
      "iteration 280 / 300: loss 0.597849\n",
      "iteration 280 / 300: loss 0.598940\n",
      "iteration 280 / 300: loss 0.603876\n",
      "iteration 280 / 300: loss 0.615261\n",
      "iteration 280 / 300: loss 0.588227\n",
      "iteration 280 / 300: loss 0.627171\n",
      "iteration 280 / 300: loss 0.592600\n",
      "iteration 280 / 300: loss 0.621500\n",
      "iteration 280 / 300: loss 0.593093\n",
      "iteration 280 / 300: loss 0.600541\n",
      "iteration 280 / 300: loss 0.571000\n",
      "iteration 280 / 300: loss 0.592911\n",
      "iteration 280 / 300: loss 0.600043\n",
      "iteration 280 / 300: loss 0.598053\n",
      "iteration 280 / 300: loss 0.583712\n",
      "iteration 280 / 300: loss 0.614355\n",
      "iteration 280 / 300: loss 0.591285\n",
      "iteration 280 / 300: loss 0.591391\n",
      "iteration 280 / 300: loss 0.594005\n",
      "iteration 280 / 300: loss 0.596735\n",
      "iteration 280 / 300: loss 0.596712\n",
      "iteration 280 / 300: loss 0.611735\n",
      "iteration 280 / 300: loss 0.607258\n",
      "iteration 280 / 300: loss 0.597031\n",
      "iteration 280 / 300: loss 0.596301\n",
      "iteration 280 / 300: loss 0.627391\n",
      "iteration 280 / 300: loss 0.601584\n",
      "iteration 280 / 300: loss 0.599923\n",
      "iteration 280 / 300: loss 0.621952\n",
      "iteration 280 / 300: loss 0.581435\n",
      "iteration 280 / 300: loss 0.599604\n",
      "iteration 280 / 300: loss 0.591182\n",
      "iteration 280 / 300: loss 0.599919\n",
      "iteration 280 / 300: loss 0.596015\n",
      "iteration 280 / 300: loss 0.590760\n",
      "iteration 280 / 300: loss 0.591961\n",
      "iteration 280 / 300: loss 0.615468\n",
      "iteration 280 / 300: loss 0.621360\n",
      "iteration 280 / 300: loss 0.587267\n",
      "iteration 280 / 300: loss 0.582483\n",
      "iteration 280 / 300: loss 0.585572\n",
      "iteration 280 / 300: loss 0.603666\n",
      "iteration 280 / 300: loss 0.585192\n",
      "iteration 280 / 300: loss 0.578880\n",
      "iteration 280 / 300: loss 0.576418\n",
      "iteration 280 / 300: loss 0.574097\n",
      "iteration 280 / 300: loss 0.600500\n",
      "iteration 280 / 300: loss 0.584490\n",
      "iteration 280 / 300: loss 0.584834\n",
      "iteration 280 / 300: loss 0.568323\n",
      "iteration 280 / 300: loss 0.592025\n",
      "iteration 280 / 300: loss 0.612116\n",
      "iteration 280 / 300: loss 0.608923\n",
      "iteration 280 / 300: loss 0.607613\n",
      "iteration 280 / 300: loss 0.595533\n",
      "iteration 280 / 300: loss 0.592837\n",
      "iteration 280 / 300: loss 0.597988\n",
      "iteration 280 / 300: loss 0.597677\n",
      "iteration 280 / 300: loss 0.600953\n",
      "iteration 280 / 300: loss 0.597422\n",
      "iteration 280 / 300: loss 0.598776\n",
      "iteration 280 / 300: loss 0.587806\n",
      "iteration 280 / 300: loss 0.600499\n",
      "iteration 280 / 300: loss 0.599650\n",
      "iteration 280 / 300: loss 0.617540\n",
      "iteration 280 / 300: loss 0.598875\n",
      "iteration 280 / 300: loss 0.600801\n",
      "iteration 280 / 300: loss 0.605305\n",
      "iteration 280 / 300: loss 0.598592\n",
      "iteration 280 / 300: loss 0.591474\n",
      "iteration 280 / 300: loss 0.580382\n",
      "iteration 280 / 300: loss 0.598221\n",
      "iteration 280 / 300: loss 0.611685\n",
      "iteration 280 / 300: loss 0.613219\n",
      "iteration 280 / 300: loss 0.582214\n",
      "iteration 280 / 300: loss 0.601955\n",
      "iteration 280 / 300: loss 0.608956\n",
      "iteration 280 / 300: loss 0.601794\n",
      "iteration 280 / 300: loss 0.607944\n",
      "iteration 280 / 300: loss 0.620236\n",
      "iteration 280 / 300: loss 0.584817\n",
      "iteration 280 / 300: loss 0.583721\n",
      "iteration 280 / 300: loss 0.628849\n",
      "iteration 280 / 300: loss 0.609399\n",
      "iteration 280 / 300: loss 0.606265\n",
      "iteration 280 / 300: loss 0.599034\n",
      "iteration 280 / 300: loss 0.615876\n",
      "iteration 280 / 300: loss 0.596489\n",
      "iteration 280 / 300: loss 0.581430\n",
      "iteration 280 / 300: loss 0.609807\n",
      "iteration 280 / 300: loss 0.608125\n",
      "iteration 280 / 300: loss 0.598224\n",
      "iteration 280 / 300: loss 0.592022\n",
      "iteration 280 / 300: loss 0.611031\n",
      "iteration 280 / 300: loss 0.598550\n",
      "iteration 280 / 300: loss 0.581382\n",
      "iteration 280 / 300: loss 0.609580\n",
      "iteration 281 / 300: loss 0.578384\n",
      "iteration 281 / 300: loss 0.596214\n",
      "iteration 281 / 300: loss 0.569455\n",
      "iteration 281 / 300: loss 0.597849\n",
      "iteration 281 / 300: loss 0.598940\n",
      "iteration 281 / 300: loss 0.603876\n",
      "iteration 281 / 300: loss 0.615261\n",
      "iteration 281 / 300: loss 0.588227\n",
      "iteration 281 / 300: loss 0.627171\n",
      "iteration 281 / 300: loss 0.592600\n",
      "iteration 281 / 300: loss 0.621500\n",
      "iteration 281 / 300: loss 0.593093\n",
      "iteration 281 / 300: loss 0.600541\n",
      "iteration 281 / 300: loss 0.571000\n",
      "iteration 281 / 300: loss 0.592911\n",
      "iteration 281 / 300: loss 0.600043\n",
      "iteration 281 / 300: loss 0.598053\n",
      "iteration 281 / 300: loss 0.583712\n",
      "iteration 281 / 300: loss 0.614355\n",
      "iteration 281 / 300: loss 0.591285\n",
      "iteration 281 / 300: loss 0.591391\n",
      "iteration 281 / 300: loss 0.594005\n",
      "iteration 281 / 300: loss 0.596735\n",
      "iteration 281 / 300: loss 0.596712\n",
      "iteration 281 / 300: loss 0.611735\n",
      "iteration 281 / 300: loss 0.607258\n",
      "iteration 281 / 300: loss 0.597031\n",
      "iteration 281 / 300: loss 0.596301\n",
      "iteration 281 / 300: loss 0.627391\n",
      "iteration 281 / 300: loss 0.601584\n",
      "iteration 281 / 300: loss 0.599923\n",
      "iteration 281 / 300: loss 0.621952\n",
      "iteration 281 / 300: loss 0.581435\n",
      "iteration 281 / 300: loss 0.599604\n",
      "iteration 281 / 300: loss 0.591182\n",
      "iteration 281 / 300: loss 0.599919\n",
      "iteration 281 / 300: loss 0.596015\n",
      "iteration 281 / 300: loss 0.590760\n",
      "iteration 281 / 300: loss 0.591961\n",
      "iteration 281 / 300: loss 0.615468\n",
      "iteration 281 / 300: loss 0.621360\n",
      "iteration 281 / 300: loss 0.587267\n",
      "iteration 281 / 300: loss 0.582483\n",
      "iteration 281 / 300: loss 0.585572\n",
      "iteration 281 / 300: loss 0.603666\n",
      "iteration 281 / 300: loss 0.585192\n",
      "iteration 281 / 300: loss 0.578880\n",
      "iteration 281 / 300: loss 0.576418\n",
      "iteration 281 / 300: loss 0.574097\n",
      "iteration 281 / 300: loss 0.600500\n",
      "iteration 281 / 300: loss 0.584490\n",
      "iteration 281 / 300: loss 0.584834\n",
      "iteration 281 / 300: loss 0.568323\n",
      "iteration 281 / 300: loss 0.592025\n",
      "iteration 281 / 300: loss 0.612116\n",
      "iteration 281 / 300: loss 0.608923\n",
      "iteration 281 / 300: loss 0.607613\n",
      "iteration 281 / 300: loss 0.595533\n",
      "iteration 281 / 300: loss 0.592837\n",
      "iteration 281 / 300: loss 0.597988\n",
      "iteration 281 / 300: loss 0.597677\n",
      "iteration 281 / 300: loss 0.600953\n",
      "iteration 281 / 300: loss 0.597422\n",
      "iteration 281 / 300: loss 0.598776\n",
      "iteration 281 / 300: loss 0.587806\n",
      "iteration 281 / 300: loss 0.600499\n",
      "iteration 281 / 300: loss 0.599650\n",
      "iteration 281 / 300: loss 0.617540\n",
      "iteration 281 / 300: loss 0.598875\n",
      "iteration 281 / 300: loss 0.600801\n",
      "iteration 281 / 300: loss 0.605305\n",
      "iteration 281 / 300: loss 0.598592\n",
      "iteration 281 / 300: loss 0.591474\n",
      "iteration 281 / 300: loss 0.580382\n",
      "iteration 281 / 300: loss 0.598221\n",
      "iteration 281 / 300: loss 0.611685\n",
      "iteration 281 / 300: loss 0.613219\n",
      "iteration 281 / 300: loss 0.582214\n",
      "iteration 281 / 300: loss 0.601955\n",
      "iteration 281 / 300: loss 0.608956\n",
      "iteration 281 / 300: loss 0.601794\n",
      "iteration 281 / 300: loss 0.607944\n",
      "iteration 281 / 300: loss 0.620236\n",
      "iteration 281 / 300: loss 0.584817\n",
      "iteration 281 / 300: loss 0.583721\n",
      "iteration 281 / 300: loss 0.628849\n",
      "iteration 281 / 300: loss 0.609399\n",
      "iteration 281 / 300: loss 0.606265\n",
      "iteration 281 / 300: loss 0.599034\n",
      "iteration 281 / 300: loss 0.615876\n",
      "iteration 281 / 300: loss 0.596489\n",
      "iteration 281 / 300: loss 0.581430\n",
      "iteration 281 / 300: loss 0.609807\n",
      "iteration 281 / 300: loss 0.608125\n",
      "iteration 281 / 300: loss 0.598224\n",
      "iteration 281 / 300: loss 0.592022\n",
      "iteration 281 / 300: loss 0.611031\n",
      "iteration 281 / 300: loss 0.598550\n",
      "iteration 281 / 300: loss 0.581382\n",
      "iteration 281 / 300: loss 0.609580\n",
      "iteration 282 / 300: loss 0.578384\n",
      "iteration 282 / 300: loss 0.596214\n",
      "iteration 282 / 300: loss 0.569455\n",
      "iteration 282 / 300: loss 0.597849\n",
      "iteration 282 / 300: loss 0.598940\n",
      "iteration 282 / 300: loss 0.603876\n",
      "iteration 282 / 300: loss 0.615261\n",
      "iteration 282 / 300: loss 0.588227\n",
      "iteration 282 / 300: loss 0.627171\n",
      "iteration 282 / 300: loss 0.592600\n",
      "iteration 282 / 300: loss 0.621500\n",
      "iteration 282 / 300: loss 0.593093\n",
      "iteration 282 / 300: loss 0.600541\n",
      "iteration 282 / 300: loss 0.571000\n",
      "iteration 282 / 300: loss 0.592911\n",
      "iteration 282 / 300: loss 0.600043\n",
      "iteration 282 / 300: loss 0.598053\n",
      "iteration 282 / 300: loss 0.583712\n",
      "iteration 282 / 300: loss 0.614355\n",
      "iteration 282 / 300: loss 0.591285\n",
      "iteration 282 / 300: loss 0.591391\n",
      "iteration 282 / 300: loss 0.594005\n",
      "iteration 282 / 300: loss 0.596735\n",
      "iteration 282 / 300: loss 0.596712\n",
      "iteration 282 / 300: loss 0.611735\n",
      "iteration 282 / 300: loss 0.607258\n",
      "iteration 282 / 300: loss 0.597031\n",
      "iteration 282 / 300: loss 0.596301\n",
      "iteration 282 / 300: loss 0.627391\n",
      "iteration 282 / 300: loss 0.601584\n",
      "iteration 282 / 300: loss 0.599923\n",
      "iteration 282 / 300: loss 0.621952\n",
      "iteration 282 / 300: loss 0.581435\n",
      "iteration 282 / 300: loss 0.599604\n",
      "iteration 282 / 300: loss 0.591182\n",
      "iteration 282 / 300: loss 0.599919\n",
      "iteration 282 / 300: loss 0.596015\n",
      "iteration 282 / 300: loss 0.590760\n",
      "iteration 282 / 300: loss 0.591961\n",
      "iteration 282 / 300: loss 0.615468\n",
      "iteration 282 / 300: loss 0.621360\n",
      "iteration 282 / 300: loss 0.587267\n",
      "iteration 282 / 300: loss 0.582483\n",
      "iteration 282 / 300: loss 0.585572\n",
      "iteration 282 / 300: loss 0.603666\n",
      "iteration 282 / 300: loss 0.585192\n",
      "iteration 282 / 300: loss 0.578880\n",
      "iteration 282 / 300: loss 0.576418\n",
      "iteration 282 / 300: loss 0.574097\n",
      "iteration 282 / 300: loss 0.600500\n",
      "iteration 282 / 300: loss 0.584490\n",
      "iteration 282 / 300: loss 0.584834\n",
      "iteration 282 / 300: loss 0.568323\n",
      "iteration 282 / 300: loss 0.592025\n",
      "iteration 282 / 300: loss 0.612116\n",
      "iteration 282 / 300: loss 0.608923\n",
      "iteration 282 / 300: loss 0.607613\n",
      "iteration 282 / 300: loss 0.595533\n",
      "iteration 282 / 300: loss 0.592837\n",
      "iteration 282 / 300: loss 0.597988\n",
      "iteration 282 / 300: loss 0.597677\n",
      "iteration 282 / 300: loss 0.600953\n",
      "iteration 282 / 300: loss 0.597422\n",
      "iteration 282 / 300: loss 0.598776\n",
      "iteration 282 / 300: loss 0.587806\n",
      "iteration 282 / 300: loss 0.600499\n",
      "iteration 282 / 300: loss 0.599650\n",
      "iteration 282 / 300: loss 0.617540\n",
      "iteration 282 / 300: loss 0.598875\n",
      "iteration 282 / 300: loss 0.600801\n",
      "iteration 282 / 300: loss 0.605305\n",
      "iteration 282 / 300: loss 0.598592\n",
      "iteration 282 / 300: loss 0.591474\n",
      "iteration 282 / 300: loss 0.580382\n",
      "iteration 282 / 300: loss 0.598221\n",
      "iteration 282 / 300: loss 0.611685\n",
      "iteration 282 / 300: loss 0.613219\n",
      "iteration 282 / 300: loss 0.582214\n",
      "iteration 282 / 300: loss 0.601955\n",
      "iteration 282 / 300: loss 0.608956\n",
      "iteration 282 / 300: loss 0.601794\n",
      "iteration 282 / 300: loss 0.607944\n",
      "iteration 282 / 300: loss 0.620236\n",
      "iteration 282 / 300: loss 0.584817\n",
      "iteration 282 / 300: loss 0.583721\n",
      "iteration 282 / 300: loss 0.628849\n",
      "iteration 282 / 300: loss 0.609399\n",
      "iteration 282 / 300: loss 0.606265\n",
      "iteration 282 / 300: loss 0.599034\n",
      "iteration 282 / 300: loss 0.615876\n",
      "iteration 282 / 300: loss 0.596489\n",
      "iteration 282 / 300: loss 0.581430\n",
      "iteration 282 / 300: loss 0.609807\n",
      "iteration 282 / 300: loss 0.608125\n",
      "iteration 282 / 300: loss 0.598224\n",
      "iteration 282 / 300: loss 0.592022\n",
      "iteration 282 / 300: loss 0.611031\n",
      "iteration 282 / 300: loss 0.598550\n",
      "iteration 282 / 300: loss 0.581382\n",
      "iteration 282 / 300: loss 0.609580\n",
      "iteration 283 / 300: loss 0.578384\n",
      "iteration 283 / 300: loss 0.596214\n",
      "iteration 283 / 300: loss 0.569455\n",
      "iteration 283 / 300: loss 0.597849\n",
      "iteration 283 / 300: loss 0.598940\n",
      "iteration 283 / 300: loss 0.603876\n",
      "iteration 283 / 300: loss 0.615261\n",
      "iteration 283 / 300: loss 0.588227\n",
      "iteration 283 / 300: loss 0.627171\n",
      "iteration 283 / 300: loss 0.592600\n",
      "iteration 283 / 300: loss 0.621500\n",
      "iteration 283 / 300: loss 0.593093\n",
      "iteration 283 / 300: loss 0.600541\n",
      "iteration 283 / 300: loss 0.571000\n",
      "iteration 283 / 300: loss 0.592911\n",
      "iteration 283 / 300: loss 0.600043\n",
      "iteration 283 / 300: loss 0.598053\n",
      "iteration 283 / 300: loss 0.583712\n",
      "iteration 283 / 300: loss 0.614355\n",
      "iteration 283 / 300: loss 0.591285\n",
      "iteration 283 / 300: loss 0.591391\n",
      "iteration 283 / 300: loss 0.594005\n",
      "iteration 283 / 300: loss 0.596735\n",
      "iteration 283 / 300: loss 0.596712\n",
      "iteration 283 / 300: loss 0.611735\n",
      "iteration 283 / 300: loss 0.607258\n",
      "iteration 283 / 300: loss 0.597031\n",
      "iteration 283 / 300: loss 0.596301\n",
      "iteration 283 / 300: loss 0.627391\n",
      "iteration 283 / 300: loss 0.601584\n",
      "iteration 283 / 300: loss 0.599923\n",
      "iteration 283 / 300: loss 0.621952\n",
      "iteration 283 / 300: loss 0.581435\n",
      "iteration 283 / 300: loss 0.599604\n",
      "iteration 283 / 300: loss 0.591182\n",
      "iteration 283 / 300: loss 0.599919\n",
      "iteration 283 / 300: loss 0.596015\n",
      "iteration 283 / 300: loss 0.590760\n",
      "iteration 283 / 300: loss 0.591961\n",
      "iteration 283 / 300: loss 0.615468\n",
      "iteration 283 / 300: loss 0.621360\n",
      "iteration 283 / 300: loss 0.587267\n",
      "iteration 283 / 300: loss 0.582483\n",
      "iteration 283 / 300: loss 0.585572\n",
      "iteration 283 / 300: loss 0.603666\n",
      "iteration 283 / 300: loss 0.585192\n",
      "iteration 283 / 300: loss 0.578880\n",
      "iteration 283 / 300: loss 0.576418\n",
      "iteration 283 / 300: loss 0.574097\n",
      "iteration 283 / 300: loss 0.600500\n",
      "iteration 283 / 300: loss 0.584490\n",
      "iteration 283 / 300: loss 0.584834\n",
      "iteration 283 / 300: loss 0.568323\n",
      "iteration 283 / 300: loss 0.592025\n",
      "iteration 283 / 300: loss 0.612116\n",
      "iteration 283 / 300: loss 0.608923\n",
      "iteration 283 / 300: loss 0.607613\n",
      "iteration 283 / 300: loss 0.595533\n",
      "iteration 283 / 300: loss 0.592837\n",
      "iteration 283 / 300: loss 0.597988\n",
      "iteration 283 / 300: loss 0.597677\n",
      "iteration 283 / 300: loss 0.600953\n",
      "iteration 283 / 300: loss 0.597422\n",
      "iteration 283 / 300: loss 0.598776\n",
      "iteration 283 / 300: loss 0.587806\n",
      "iteration 283 / 300: loss 0.600499\n",
      "iteration 283 / 300: loss 0.599650\n",
      "iteration 283 / 300: loss 0.617540\n",
      "iteration 283 / 300: loss 0.598875\n",
      "iteration 283 / 300: loss 0.600801\n",
      "iteration 283 / 300: loss 0.605305\n",
      "iteration 283 / 300: loss 0.598592\n",
      "iteration 283 / 300: loss 0.591474\n",
      "iteration 283 / 300: loss 0.580382\n",
      "iteration 283 / 300: loss 0.598221\n",
      "iteration 283 / 300: loss 0.611685\n",
      "iteration 283 / 300: loss 0.613219\n",
      "iteration 283 / 300: loss 0.582214\n",
      "iteration 283 / 300: loss 0.601955\n",
      "iteration 283 / 300: loss 0.608956\n",
      "iteration 283 / 300: loss 0.601794\n",
      "iteration 283 / 300: loss 0.607944\n",
      "iteration 283 / 300: loss 0.620236\n",
      "iteration 283 / 300: loss 0.584817\n",
      "iteration 283 / 300: loss 0.583721\n",
      "iteration 283 / 300: loss 0.628849\n",
      "iteration 283 / 300: loss 0.609399\n",
      "iteration 283 / 300: loss 0.606265\n",
      "iteration 283 / 300: loss 0.599034\n",
      "iteration 283 / 300: loss 0.615876\n",
      "iteration 283 / 300: loss 0.596489\n",
      "iteration 283 / 300: loss 0.581430\n",
      "iteration 283 / 300: loss 0.609807\n",
      "iteration 283 / 300: loss 0.608125\n",
      "iteration 283 / 300: loss 0.598224\n",
      "iteration 283 / 300: loss 0.592022\n",
      "iteration 283 / 300: loss 0.611031\n",
      "iteration 283 / 300: loss 0.598550\n",
      "iteration 283 / 300: loss 0.581382\n",
      "iteration 283 / 300: loss 0.609580\n",
      "iteration 284 / 300: loss 0.578384\n",
      "iteration 284 / 300: loss 0.596214\n",
      "iteration 284 / 300: loss 0.569455\n",
      "iteration 284 / 300: loss 0.597849\n",
      "iteration 284 / 300: loss 0.598940\n",
      "iteration 284 / 300: loss 0.603876\n",
      "iteration 284 / 300: loss 0.615261\n",
      "iteration 284 / 300: loss 0.588227\n",
      "iteration 284 / 300: loss 0.627171\n",
      "iteration 284 / 300: loss 0.592600\n",
      "iteration 284 / 300: loss 0.621500\n",
      "iteration 284 / 300: loss 0.593093\n",
      "iteration 284 / 300: loss 0.600541\n",
      "iteration 284 / 300: loss 0.571000\n",
      "iteration 284 / 300: loss 0.592911\n",
      "iteration 284 / 300: loss 0.600043\n",
      "iteration 284 / 300: loss 0.598053\n",
      "iteration 284 / 300: loss 0.583712\n",
      "iteration 284 / 300: loss 0.614355\n",
      "iteration 284 / 300: loss 0.591285\n",
      "iteration 284 / 300: loss 0.591391\n",
      "iteration 284 / 300: loss 0.594005\n",
      "iteration 284 / 300: loss 0.596735\n",
      "iteration 284 / 300: loss 0.596712\n",
      "iteration 284 / 300: loss 0.611735\n",
      "iteration 284 / 300: loss 0.607258\n",
      "iteration 284 / 300: loss 0.597031\n",
      "iteration 284 / 300: loss 0.596301\n",
      "iteration 284 / 300: loss 0.627391\n",
      "iteration 284 / 300: loss 0.601584\n",
      "iteration 284 / 300: loss 0.599923\n",
      "iteration 284 / 300: loss 0.621952\n",
      "iteration 284 / 300: loss 0.581435\n",
      "iteration 284 / 300: loss 0.599604\n",
      "iteration 284 / 300: loss 0.591182\n",
      "iteration 284 / 300: loss 0.599919\n",
      "iteration 284 / 300: loss 0.596015\n",
      "iteration 284 / 300: loss 0.590760\n",
      "iteration 284 / 300: loss 0.591961\n",
      "iteration 284 / 300: loss 0.615468\n",
      "iteration 284 / 300: loss 0.621360\n",
      "iteration 284 / 300: loss 0.587267\n",
      "iteration 284 / 300: loss 0.582483\n",
      "iteration 284 / 300: loss 0.585572\n",
      "iteration 284 / 300: loss 0.603666\n",
      "iteration 284 / 300: loss 0.585192\n",
      "iteration 284 / 300: loss 0.578880\n",
      "iteration 284 / 300: loss 0.576418\n",
      "iteration 284 / 300: loss 0.574097\n",
      "iteration 284 / 300: loss 0.600500\n",
      "iteration 284 / 300: loss 0.584490\n",
      "iteration 284 / 300: loss 0.584834\n",
      "iteration 284 / 300: loss 0.568323\n",
      "iteration 284 / 300: loss 0.592025\n",
      "iteration 284 / 300: loss 0.612116\n",
      "iteration 284 / 300: loss 0.608923\n",
      "iteration 284 / 300: loss 0.607613\n",
      "iteration 284 / 300: loss 0.595533\n",
      "iteration 284 / 300: loss 0.592837\n",
      "iteration 284 / 300: loss 0.597988\n",
      "iteration 284 / 300: loss 0.597677\n",
      "iteration 284 / 300: loss 0.600953\n",
      "iteration 284 / 300: loss 0.597422\n",
      "iteration 284 / 300: loss 0.598776\n",
      "iteration 284 / 300: loss 0.587806\n",
      "iteration 284 / 300: loss 0.600499\n",
      "iteration 284 / 300: loss 0.599650\n",
      "iteration 284 / 300: loss 0.617540\n",
      "iteration 284 / 300: loss 0.598875\n",
      "iteration 284 / 300: loss 0.600801\n",
      "iteration 284 / 300: loss 0.605305\n",
      "iteration 284 / 300: loss 0.598592\n",
      "iteration 284 / 300: loss 0.591474\n",
      "iteration 284 / 300: loss 0.580382\n",
      "iteration 284 / 300: loss 0.598221\n",
      "iteration 284 / 300: loss 0.611685\n",
      "iteration 284 / 300: loss 0.613219\n",
      "iteration 284 / 300: loss 0.582214\n",
      "iteration 284 / 300: loss 0.601955\n",
      "iteration 284 / 300: loss 0.608956\n",
      "iteration 284 / 300: loss 0.601794\n",
      "iteration 284 / 300: loss 0.607944\n",
      "iteration 284 / 300: loss 0.620236\n",
      "iteration 284 / 300: loss 0.584817\n",
      "iteration 284 / 300: loss 0.583721\n",
      "iteration 284 / 300: loss 0.628849\n",
      "iteration 284 / 300: loss 0.609399\n",
      "iteration 284 / 300: loss 0.606265\n",
      "iteration 284 / 300: loss 0.599034\n",
      "iteration 284 / 300: loss 0.615876\n",
      "iteration 284 / 300: loss 0.596489\n",
      "iteration 284 / 300: loss 0.581430\n",
      "iteration 284 / 300: loss 0.609807\n",
      "iteration 284 / 300: loss 0.608125\n",
      "iteration 284 / 300: loss 0.598224\n",
      "iteration 284 / 300: loss 0.592022\n",
      "iteration 284 / 300: loss 0.611031\n",
      "iteration 284 / 300: loss 0.598550\n",
      "iteration 284 / 300: loss 0.581382\n",
      "iteration 284 / 300: loss 0.609580\n",
      "iteration 285 / 300: loss 0.578384\n",
      "iteration 285 / 300: loss 0.596214\n",
      "iteration 285 / 300: loss 0.569455\n",
      "iteration 285 / 300: loss 0.597849\n",
      "iteration 285 / 300: loss 0.598940\n",
      "iteration 285 / 300: loss 0.603876\n",
      "iteration 285 / 300: loss 0.615261\n",
      "iteration 285 / 300: loss 0.588227\n",
      "iteration 285 / 300: loss 0.627171\n",
      "iteration 285 / 300: loss 0.592600\n",
      "iteration 285 / 300: loss 0.621500\n",
      "iteration 285 / 300: loss 0.593093\n",
      "iteration 285 / 300: loss 0.600541\n",
      "iteration 285 / 300: loss 0.571000\n",
      "iteration 285 / 300: loss 0.592911\n",
      "iteration 285 / 300: loss 0.600043\n",
      "iteration 285 / 300: loss 0.598053\n",
      "iteration 285 / 300: loss 0.583712\n",
      "iteration 285 / 300: loss 0.614355\n",
      "iteration 285 / 300: loss 0.591285\n",
      "iteration 285 / 300: loss 0.591391\n",
      "iteration 285 / 300: loss 0.594005\n",
      "iteration 285 / 300: loss 0.596735\n",
      "iteration 285 / 300: loss 0.596712\n",
      "iteration 285 / 300: loss 0.611735\n",
      "iteration 285 / 300: loss 0.607258\n",
      "iteration 285 / 300: loss 0.597031\n",
      "iteration 285 / 300: loss 0.596301\n",
      "iteration 285 / 300: loss 0.627391\n",
      "iteration 285 / 300: loss 0.601584\n",
      "iteration 285 / 300: loss 0.599923\n",
      "iteration 285 / 300: loss 0.621952\n",
      "iteration 285 / 300: loss 0.581435\n",
      "iteration 285 / 300: loss 0.599604\n",
      "iteration 285 / 300: loss 0.591182\n",
      "iteration 285 / 300: loss 0.599919\n",
      "iteration 285 / 300: loss 0.596015\n",
      "iteration 285 / 300: loss 0.590760\n",
      "iteration 285 / 300: loss 0.591961\n",
      "iteration 285 / 300: loss 0.615468\n",
      "iteration 285 / 300: loss 0.621360\n",
      "iteration 285 / 300: loss 0.587267\n",
      "iteration 285 / 300: loss 0.582483\n",
      "iteration 285 / 300: loss 0.585572\n",
      "iteration 285 / 300: loss 0.603666\n",
      "iteration 285 / 300: loss 0.585192\n",
      "iteration 285 / 300: loss 0.578880\n",
      "iteration 285 / 300: loss 0.576418\n",
      "iteration 285 / 300: loss 0.574097\n",
      "iteration 285 / 300: loss 0.600500\n",
      "iteration 285 / 300: loss 0.584490\n",
      "iteration 285 / 300: loss 0.584834\n",
      "iteration 285 / 300: loss 0.568323\n",
      "iteration 285 / 300: loss 0.592025\n",
      "iteration 285 / 300: loss 0.612116\n",
      "iteration 285 / 300: loss 0.608923\n",
      "iteration 285 / 300: loss 0.607613\n",
      "iteration 285 / 300: loss 0.595533\n",
      "iteration 285 / 300: loss 0.592837\n",
      "iteration 285 / 300: loss 0.597988\n",
      "iteration 285 / 300: loss 0.597677\n",
      "iteration 285 / 300: loss 0.600953\n",
      "iteration 285 / 300: loss 0.597422\n",
      "iteration 285 / 300: loss 0.598776\n",
      "iteration 285 / 300: loss 0.587806\n",
      "iteration 285 / 300: loss 0.600499\n",
      "iteration 285 / 300: loss 0.599650\n",
      "iteration 285 / 300: loss 0.617540\n",
      "iteration 285 / 300: loss 0.598875\n",
      "iteration 285 / 300: loss 0.600801\n",
      "iteration 285 / 300: loss 0.605305\n",
      "iteration 285 / 300: loss 0.598592\n",
      "iteration 285 / 300: loss 0.591474\n",
      "iteration 285 / 300: loss 0.580382\n",
      "iteration 285 / 300: loss 0.598221\n",
      "iteration 285 / 300: loss 0.611685\n",
      "iteration 285 / 300: loss 0.613219\n",
      "iteration 285 / 300: loss 0.582214\n",
      "iteration 285 / 300: loss 0.601955\n",
      "iteration 285 / 300: loss 0.608956\n",
      "iteration 285 / 300: loss 0.601794\n",
      "iteration 285 / 300: loss 0.607944\n",
      "iteration 285 / 300: loss 0.620236\n",
      "iteration 285 / 300: loss 0.584817\n",
      "iteration 285 / 300: loss 0.583721\n",
      "iteration 285 / 300: loss 0.628849\n",
      "iteration 285 / 300: loss 0.609399\n",
      "iteration 285 / 300: loss 0.606265\n",
      "iteration 285 / 300: loss 0.599034\n",
      "iteration 285 / 300: loss 0.615876\n",
      "iteration 285 / 300: loss 0.596489\n",
      "iteration 285 / 300: loss 0.581430\n",
      "iteration 285 / 300: loss 0.609807\n",
      "iteration 285 / 300: loss 0.608125\n",
      "iteration 285 / 300: loss 0.598224\n",
      "iteration 285 / 300: loss 0.592022\n",
      "iteration 285 / 300: loss 0.611031\n",
      "iteration 285 / 300: loss 0.598550\n",
      "iteration 285 / 300: loss 0.581382\n",
      "iteration 285 / 300: loss 0.609580\n",
      "iteration 286 / 300: loss 0.578384\n",
      "iteration 286 / 300: loss 0.596214\n",
      "iteration 286 / 300: loss 0.569455\n",
      "iteration 286 / 300: loss 0.597849\n",
      "iteration 286 / 300: loss 0.598940\n",
      "iteration 286 / 300: loss 0.603876\n",
      "iteration 286 / 300: loss 0.615261\n",
      "iteration 286 / 300: loss 0.588227\n",
      "iteration 286 / 300: loss 0.627171\n",
      "iteration 286 / 300: loss 0.592600\n",
      "iteration 286 / 300: loss 0.621500\n",
      "iteration 286 / 300: loss 0.593093\n",
      "iteration 286 / 300: loss 0.600541\n",
      "iteration 286 / 300: loss 0.571000\n",
      "iteration 286 / 300: loss 0.592911\n",
      "iteration 286 / 300: loss 0.600043\n",
      "iteration 286 / 300: loss 0.598053\n",
      "iteration 286 / 300: loss 0.583712\n",
      "iteration 286 / 300: loss 0.614355\n",
      "iteration 286 / 300: loss 0.591285\n",
      "iteration 286 / 300: loss 0.591391\n",
      "iteration 286 / 300: loss 0.594005\n",
      "iteration 286 / 300: loss 0.596735\n",
      "iteration 286 / 300: loss 0.596712\n",
      "iteration 286 / 300: loss 0.611735\n",
      "iteration 286 / 300: loss 0.607258\n",
      "iteration 286 / 300: loss 0.597031\n",
      "iteration 286 / 300: loss 0.596301\n",
      "iteration 286 / 300: loss 0.627391\n",
      "iteration 286 / 300: loss 0.601584\n",
      "iteration 286 / 300: loss 0.599923\n",
      "iteration 286 / 300: loss 0.621952\n",
      "iteration 286 / 300: loss 0.581435\n",
      "iteration 286 / 300: loss 0.599604\n",
      "iteration 286 / 300: loss 0.591182\n",
      "iteration 286 / 300: loss 0.599919\n",
      "iteration 286 / 300: loss 0.596015\n",
      "iteration 286 / 300: loss 0.590760\n",
      "iteration 286 / 300: loss 0.591961\n",
      "iteration 286 / 300: loss 0.615468\n",
      "iteration 286 / 300: loss 0.621360\n",
      "iteration 286 / 300: loss 0.587267\n",
      "iteration 286 / 300: loss 0.582483\n",
      "iteration 286 / 300: loss 0.585572\n",
      "iteration 286 / 300: loss 0.603666\n",
      "iteration 286 / 300: loss 0.585192\n",
      "iteration 286 / 300: loss 0.578880\n",
      "iteration 286 / 300: loss 0.576418\n",
      "iteration 286 / 300: loss 0.574097\n",
      "iteration 286 / 300: loss 0.600500\n",
      "iteration 286 / 300: loss 0.584490\n",
      "iteration 286 / 300: loss 0.584834\n",
      "iteration 286 / 300: loss 0.568323\n",
      "iteration 286 / 300: loss 0.592025\n",
      "iteration 286 / 300: loss 0.612116\n",
      "iteration 286 / 300: loss 0.608923\n",
      "iteration 286 / 300: loss 0.607613\n",
      "iteration 286 / 300: loss 0.595533\n",
      "iteration 286 / 300: loss 0.592837\n",
      "iteration 286 / 300: loss 0.597988\n",
      "iteration 286 / 300: loss 0.597677\n",
      "iteration 286 / 300: loss 0.600953\n",
      "iteration 286 / 300: loss 0.597422\n",
      "iteration 286 / 300: loss 0.598776\n",
      "iteration 286 / 300: loss 0.587806\n",
      "iteration 286 / 300: loss 0.600499\n",
      "iteration 286 / 300: loss 0.599650\n",
      "iteration 286 / 300: loss 0.617540\n",
      "iteration 286 / 300: loss 0.598875\n",
      "iteration 286 / 300: loss 0.600801\n",
      "iteration 286 / 300: loss 0.605305\n",
      "iteration 286 / 300: loss 0.598592\n",
      "iteration 286 / 300: loss 0.591474\n",
      "iteration 286 / 300: loss 0.580382\n",
      "iteration 286 / 300: loss 0.598221\n",
      "iteration 286 / 300: loss 0.611685\n",
      "iteration 286 / 300: loss 0.613219\n",
      "iteration 286 / 300: loss 0.582214\n",
      "iteration 286 / 300: loss 0.601955\n",
      "iteration 286 / 300: loss 0.608956\n",
      "iteration 286 / 300: loss 0.601794\n",
      "iteration 286 / 300: loss 0.607944\n",
      "iteration 286 / 300: loss 0.620236\n",
      "iteration 286 / 300: loss 0.584817\n",
      "iteration 286 / 300: loss 0.583721\n",
      "iteration 286 / 300: loss 0.628849\n",
      "iteration 286 / 300: loss 0.609399\n",
      "iteration 286 / 300: loss 0.606265\n",
      "iteration 286 / 300: loss 0.599034\n",
      "iteration 286 / 300: loss 0.615876\n",
      "iteration 286 / 300: loss 0.596489\n",
      "iteration 286 / 300: loss 0.581430\n",
      "iteration 286 / 300: loss 0.609807\n",
      "iteration 286 / 300: loss 0.608125\n",
      "iteration 286 / 300: loss 0.598224\n",
      "iteration 286 / 300: loss 0.592022\n",
      "iteration 286 / 300: loss 0.611031\n",
      "iteration 286 / 300: loss 0.598550\n",
      "iteration 286 / 300: loss 0.581382\n",
      "iteration 286 / 300: loss 0.609580\n",
      "iteration 287 / 300: loss 0.578384\n",
      "iteration 287 / 300: loss 0.596214\n",
      "iteration 287 / 300: loss 0.569455\n",
      "iteration 287 / 300: loss 0.597849\n",
      "iteration 287 / 300: loss 0.598940\n",
      "iteration 287 / 300: loss 0.603876\n",
      "iteration 287 / 300: loss 0.615261\n",
      "iteration 287 / 300: loss 0.588227\n",
      "iteration 287 / 300: loss 0.627171\n",
      "iteration 287 / 300: loss 0.592600\n",
      "iteration 287 / 300: loss 0.621500\n",
      "iteration 287 / 300: loss 0.593093\n",
      "iteration 287 / 300: loss 0.600541\n",
      "iteration 287 / 300: loss 0.571000\n",
      "iteration 287 / 300: loss 0.592911\n",
      "iteration 287 / 300: loss 0.600043\n",
      "iteration 287 / 300: loss 0.598053\n",
      "iteration 287 / 300: loss 0.583712\n",
      "iteration 287 / 300: loss 0.614355\n",
      "iteration 287 / 300: loss 0.591285\n",
      "iteration 287 / 300: loss 0.591391\n",
      "iteration 287 / 300: loss 0.594005\n",
      "iteration 287 / 300: loss 0.596735\n",
      "iteration 287 / 300: loss 0.596712\n",
      "iteration 287 / 300: loss 0.611735\n",
      "iteration 287 / 300: loss 0.607258\n",
      "iteration 287 / 300: loss 0.597031\n",
      "iteration 287 / 300: loss 0.596301\n",
      "iteration 287 / 300: loss 0.627391\n",
      "iteration 287 / 300: loss 0.601584\n",
      "iteration 287 / 300: loss 0.599923\n",
      "iteration 287 / 300: loss 0.621952\n",
      "iteration 287 / 300: loss 0.581435\n",
      "iteration 287 / 300: loss 0.599604\n",
      "iteration 287 / 300: loss 0.591182\n",
      "iteration 287 / 300: loss 0.599919\n",
      "iteration 287 / 300: loss 0.596015\n",
      "iteration 287 / 300: loss 0.590760\n",
      "iteration 287 / 300: loss 0.591961\n",
      "iteration 287 / 300: loss 0.615468\n",
      "iteration 287 / 300: loss 0.621360\n",
      "iteration 287 / 300: loss 0.587267\n",
      "iteration 287 / 300: loss 0.582483\n",
      "iteration 287 / 300: loss 0.585572\n",
      "iteration 287 / 300: loss 0.603666\n",
      "iteration 287 / 300: loss 0.585192\n",
      "iteration 287 / 300: loss 0.578880\n",
      "iteration 287 / 300: loss 0.576418\n",
      "iteration 287 / 300: loss 0.574097\n",
      "iteration 287 / 300: loss 0.600500\n",
      "iteration 287 / 300: loss 0.584490\n",
      "iteration 287 / 300: loss 0.584834\n",
      "iteration 287 / 300: loss 0.568323\n",
      "iteration 287 / 300: loss 0.592025\n",
      "iteration 287 / 300: loss 0.612116\n",
      "iteration 287 / 300: loss 0.608923\n",
      "iteration 287 / 300: loss 0.607613\n",
      "iteration 287 / 300: loss 0.595533\n",
      "iteration 287 / 300: loss 0.592837\n",
      "iteration 287 / 300: loss 0.597988\n",
      "iteration 287 / 300: loss 0.597677\n",
      "iteration 287 / 300: loss 0.600953\n",
      "iteration 287 / 300: loss 0.597422\n",
      "iteration 287 / 300: loss 0.598776\n",
      "iteration 287 / 300: loss 0.587806\n",
      "iteration 287 / 300: loss 0.600499\n",
      "iteration 287 / 300: loss 0.599650\n",
      "iteration 287 / 300: loss 0.617540\n",
      "iteration 287 / 300: loss 0.598875\n",
      "iteration 287 / 300: loss 0.600801\n",
      "iteration 287 / 300: loss 0.605305\n",
      "iteration 287 / 300: loss 0.598592\n",
      "iteration 287 / 300: loss 0.591474\n",
      "iteration 287 / 300: loss 0.580382\n",
      "iteration 287 / 300: loss 0.598221\n",
      "iteration 287 / 300: loss 0.611685\n",
      "iteration 287 / 300: loss 0.613219\n",
      "iteration 287 / 300: loss 0.582214\n",
      "iteration 287 / 300: loss 0.601955\n",
      "iteration 287 / 300: loss 0.608956\n",
      "iteration 287 / 300: loss 0.601794\n",
      "iteration 287 / 300: loss 0.607944\n",
      "iteration 287 / 300: loss 0.620236\n",
      "iteration 287 / 300: loss 0.584817\n",
      "iteration 287 / 300: loss 0.583721\n",
      "iteration 287 / 300: loss 0.628849\n",
      "iteration 287 / 300: loss 0.609399\n",
      "iteration 287 / 300: loss 0.606265\n",
      "iteration 287 / 300: loss 0.599034\n",
      "iteration 287 / 300: loss 0.615876\n",
      "iteration 287 / 300: loss 0.596489\n",
      "iteration 287 / 300: loss 0.581430\n",
      "iteration 287 / 300: loss 0.609807\n",
      "iteration 287 / 300: loss 0.608125\n",
      "iteration 287 / 300: loss 0.598224\n",
      "iteration 287 / 300: loss 0.592022\n",
      "iteration 287 / 300: loss 0.611031\n",
      "iteration 287 / 300: loss 0.598550\n",
      "iteration 287 / 300: loss 0.581382\n",
      "iteration 287 / 300: loss 0.609580\n",
      "iteration 288 / 300: loss 0.578384\n",
      "iteration 288 / 300: loss 0.596214\n",
      "iteration 288 / 300: loss 0.569455\n",
      "iteration 288 / 300: loss 0.597849\n",
      "iteration 288 / 300: loss 0.598940\n",
      "iteration 288 / 300: loss 0.603876\n",
      "iteration 288 / 300: loss 0.615261\n",
      "iteration 288 / 300: loss 0.588227\n",
      "iteration 288 / 300: loss 0.627171\n",
      "iteration 288 / 300: loss 0.592600\n",
      "iteration 288 / 300: loss 0.621500\n",
      "iteration 288 / 300: loss 0.593093\n",
      "iteration 288 / 300: loss 0.600541\n",
      "iteration 288 / 300: loss 0.571000\n",
      "iteration 288 / 300: loss 0.592911\n",
      "iteration 288 / 300: loss 0.600043\n",
      "iteration 288 / 300: loss 0.598053\n",
      "iteration 288 / 300: loss 0.583712\n",
      "iteration 288 / 300: loss 0.614355\n",
      "iteration 288 / 300: loss 0.591285\n",
      "iteration 288 / 300: loss 0.591391\n",
      "iteration 288 / 300: loss 0.594005\n",
      "iteration 288 / 300: loss 0.596735\n",
      "iteration 288 / 300: loss 0.596712\n",
      "iteration 288 / 300: loss 0.611735\n",
      "iteration 288 / 300: loss 0.607258\n",
      "iteration 288 / 300: loss 0.597031\n",
      "iteration 288 / 300: loss 0.596301\n",
      "iteration 288 / 300: loss 0.627391\n",
      "iteration 288 / 300: loss 0.601584\n",
      "iteration 288 / 300: loss 0.599923\n",
      "iteration 288 / 300: loss 0.621952\n",
      "iteration 288 / 300: loss 0.581435\n",
      "iteration 288 / 300: loss 0.599604\n",
      "iteration 288 / 300: loss 0.591182\n",
      "iteration 288 / 300: loss 0.599919\n",
      "iteration 288 / 300: loss 0.596015\n",
      "iteration 288 / 300: loss 0.590760\n",
      "iteration 288 / 300: loss 0.591961\n",
      "iteration 288 / 300: loss 0.615468\n",
      "iteration 288 / 300: loss 0.621360\n",
      "iteration 288 / 300: loss 0.587267\n",
      "iteration 288 / 300: loss 0.582483\n",
      "iteration 288 / 300: loss 0.585572\n",
      "iteration 288 / 300: loss 0.603666\n",
      "iteration 288 / 300: loss 0.585192\n",
      "iteration 288 / 300: loss 0.578880\n",
      "iteration 288 / 300: loss 0.576418\n",
      "iteration 288 / 300: loss 0.574097\n",
      "iteration 288 / 300: loss 0.600500\n",
      "iteration 288 / 300: loss 0.584490\n",
      "iteration 288 / 300: loss 0.584834\n",
      "iteration 288 / 300: loss 0.568323\n",
      "iteration 288 / 300: loss 0.592025\n",
      "iteration 288 / 300: loss 0.612116\n",
      "iteration 288 / 300: loss 0.608923\n",
      "iteration 288 / 300: loss 0.607613\n",
      "iteration 288 / 300: loss 0.595533\n",
      "iteration 288 / 300: loss 0.592837\n",
      "iteration 288 / 300: loss 0.597988\n",
      "iteration 288 / 300: loss 0.597677\n",
      "iteration 288 / 300: loss 0.600953\n",
      "iteration 288 / 300: loss 0.597422\n",
      "iteration 288 / 300: loss 0.598776\n",
      "iteration 288 / 300: loss 0.587806\n",
      "iteration 288 / 300: loss 0.600499\n",
      "iteration 288 / 300: loss 0.599650\n",
      "iteration 288 / 300: loss 0.617540\n",
      "iteration 288 / 300: loss 0.598875\n",
      "iteration 288 / 300: loss 0.600801\n",
      "iteration 288 / 300: loss 0.605305\n",
      "iteration 288 / 300: loss 0.598592\n",
      "iteration 288 / 300: loss 0.591474\n",
      "iteration 288 / 300: loss 0.580382\n",
      "iteration 288 / 300: loss 0.598221\n",
      "iteration 288 / 300: loss 0.611685\n",
      "iteration 288 / 300: loss 0.613219\n",
      "iteration 288 / 300: loss 0.582214\n",
      "iteration 288 / 300: loss 0.601955\n",
      "iteration 288 / 300: loss 0.608956\n",
      "iteration 288 / 300: loss 0.601794\n",
      "iteration 288 / 300: loss 0.607944\n",
      "iteration 288 / 300: loss 0.620236\n",
      "iteration 288 / 300: loss 0.584817\n",
      "iteration 288 / 300: loss 0.583721\n",
      "iteration 288 / 300: loss 0.628849\n",
      "iteration 288 / 300: loss 0.609399\n",
      "iteration 288 / 300: loss 0.606265\n",
      "iteration 288 / 300: loss 0.599034\n",
      "iteration 288 / 300: loss 0.615876\n",
      "iteration 288 / 300: loss 0.596489\n",
      "iteration 288 / 300: loss 0.581430\n",
      "iteration 288 / 300: loss 0.609807\n",
      "iteration 288 / 300: loss 0.608125\n",
      "iteration 288 / 300: loss 0.598224\n",
      "iteration 288 / 300: loss 0.592022\n",
      "iteration 288 / 300: loss 0.611031\n",
      "iteration 288 / 300: loss 0.598550\n",
      "iteration 288 / 300: loss 0.581382\n",
      "iteration 288 / 300: loss 0.609580\n",
      "iteration 289 / 300: loss 0.578384\n",
      "iteration 289 / 300: loss 0.596214\n",
      "iteration 289 / 300: loss 0.569455\n",
      "iteration 289 / 300: loss 0.597849\n",
      "iteration 289 / 300: loss 0.598940\n",
      "iteration 289 / 300: loss 0.603876\n",
      "iteration 289 / 300: loss 0.615261\n",
      "iteration 289 / 300: loss 0.588227\n",
      "iteration 289 / 300: loss 0.627171\n",
      "iteration 289 / 300: loss 0.592600\n",
      "iteration 289 / 300: loss 0.621500\n",
      "iteration 289 / 300: loss 0.593093\n",
      "iteration 289 / 300: loss 0.600541\n",
      "iteration 289 / 300: loss 0.571000\n",
      "iteration 289 / 300: loss 0.592911\n",
      "iteration 289 / 300: loss 0.600043\n",
      "iteration 289 / 300: loss 0.598053\n",
      "iteration 289 / 300: loss 0.583712\n",
      "iteration 289 / 300: loss 0.614355\n",
      "iteration 289 / 300: loss 0.591285\n",
      "iteration 289 / 300: loss 0.591391\n",
      "iteration 289 / 300: loss 0.594005\n",
      "iteration 289 / 300: loss 0.596735\n",
      "iteration 289 / 300: loss 0.596712\n",
      "iteration 289 / 300: loss 0.611735\n",
      "iteration 289 / 300: loss 0.607258\n",
      "iteration 289 / 300: loss 0.597031\n",
      "iteration 289 / 300: loss 0.596301\n",
      "iteration 289 / 300: loss 0.627391\n",
      "iteration 289 / 300: loss 0.601584\n",
      "iteration 289 / 300: loss 0.599923\n",
      "iteration 289 / 300: loss 0.621952\n",
      "iteration 289 / 300: loss 0.581435\n",
      "iteration 289 / 300: loss 0.599604\n",
      "iteration 289 / 300: loss 0.591182\n",
      "iteration 289 / 300: loss 0.599919\n",
      "iteration 289 / 300: loss 0.596015\n",
      "iteration 289 / 300: loss 0.590760\n",
      "iteration 289 / 300: loss 0.591961\n",
      "iteration 289 / 300: loss 0.615468\n",
      "iteration 289 / 300: loss 0.621360\n",
      "iteration 289 / 300: loss 0.587267\n",
      "iteration 289 / 300: loss 0.582483\n",
      "iteration 289 / 300: loss 0.585572\n",
      "iteration 289 / 300: loss 0.603666\n",
      "iteration 289 / 300: loss 0.585192\n",
      "iteration 289 / 300: loss 0.578880\n",
      "iteration 289 / 300: loss 0.576418\n",
      "iteration 289 / 300: loss 0.574097\n",
      "iteration 289 / 300: loss 0.600500\n",
      "iteration 289 / 300: loss 0.584490\n",
      "iteration 289 / 300: loss 0.584834\n",
      "iteration 289 / 300: loss 0.568323\n",
      "iteration 289 / 300: loss 0.592025\n",
      "iteration 289 / 300: loss 0.612116\n",
      "iteration 289 / 300: loss 0.608923\n",
      "iteration 289 / 300: loss 0.607613\n",
      "iteration 289 / 300: loss 0.595533\n",
      "iteration 289 / 300: loss 0.592837\n",
      "iteration 289 / 300: loss 0.597988\n",
      "iteration 289 / 300: loss 0.597677\n",
      "iteration 289 / 300: loss 0.600953\n",
      "iteration 289 / 300: loss 0.597422\n",
      "iteration 289 / 300: loss 0.598776\n",
      "iteration 289 / 300: loss 0.587806\n",
      "iteration 289 / 300: loss 0.600499\n",
      "iteration 289 / 300: loss 0.599650\n",
      "iteration 289 / 300: loss 0.617540\n",
      "iteration 289 / 300: loss 0.598875\n",
      "iteration 289 / 300: loss 0.600801\n",
      "iteration 289 / 300: loss 0.605305\n",
      "iteration 289 / 300: loss 0.598592\n",
      "iteration 289 / 300: loss 0.591474\n",
      "iteration 289 / 300: loss 0.580382\n",
      "iteration 289 / 300: loss 0.598221\n",
      "iteration 289 / 300: loss 0.611685\n",
      "iteration 289 / 300: loss 0.613219\n",
      "iteration 289 / 300: loss 0.582214\n",
      "iteration 289 / 300: loss 0.601955\n",
      "iteration 289 / 300: loss 0.608956\n",
      "iteration 289 / 300: loss 0.601794\n",
      "iteration 289 / 300: loss 0.607944\n",
      "iteration 289 / 300: loss 0.620236\n",
      "iteration 289 / 300: loss 0.584817\n",
      "iteration 289 / 300: loss 0.583721\n",
      "iteration 289 / 300: loss 0.628849\n",
      "iteration 289 / 300: loss 0.609399\n",
      "iteration 289 / 300: loss 0.606265\n",
      "iteration 289 / 300: loss 0.599034\n",
      "iteration 289 / 300: loss 0.615876\n",
      "iteration 289 / 300: loss 0.596489\n",
      "iteration 289 / 300: loss 0.581430\n",
      "iteration 289 / 300: loss 0.609807\n",
      "iteration 289 / 300: loss 0.608125\n",
      "iteration 289 / 300: loss 0.598224\n",
      "iteration 289 / 300: loss 0.592022\n",
      "iteration 289 / 300: loss 0.611031\n",
      "iteration 289 / 300: loss 0.598550\n",
      "iteration 289 / 300: loss 0.581382\n",
      "iteration 289 / 300: loss 0.609580\n",
      "iteration 290 / 300: loss 0.578384\n",
      "iteration 290 / 300: loss 0.596214\n",
      "iteration 290 / 300: loss 0.569455\n",
      "iteration 290 / 300: loss 0.597849\n",
      "iteration 290 / 300: loss 0.598940\n",
      "iteration 290 / 300: loss 0.603876\n",
      "iteration 290 / 300: loss 0.615261\n",
      "iteration 290 / 300: loss 0.588227\n",
      "iteration 290 / 300: loss 0.627171\n",
      "iteration 290 / 300: loss 0.592600\n",
      "iteration 290 / 300: loss 0.621500\n",
      "iteration 290 / 300: loss 0.593093\n",
      "iteration 290 / 300: loss 0.600541\n",
      "iteration 290 / 300: loss 0.571000\n",
      "iteration 290 / 300: loss 0.592911\n",
      "iteration 290 / 300: loss 0.600043\n",
      "iteration 290 / 300: loss 0.598053\n",
      "iteration 290 / 300: loss 0.583712\n",
      "iteration 290 / 300: loss 0.614355\n",
      "iteration 290 / 300: loss 0.591285\n",
      "iteration 290 / 300: loss 0.591391\n",
      "iteration 290 / 300: loss 0.594005\n",
      "iteration 290 / 300: loss 0.596735\n",
      "iteration 290 / 300: loss 0.596712\n",
      "iteration 290 / 300: loss 0.611735\n",
      "iteration 290 / 300: loss 0.607258\n",
      "iteration 290 / 300: loss 0.597031\n",
      "iteration 290 / 300: loss 0.596301\n",
      "iteration 290 / 300: loss 0.627391\n",
      "iteration 290 / 300: loss 0.601584\n",
      "iteration 290 / 300: loss 0.599923\n",
      "iteration 290 / 300: loss 0.621952\n",
      "iteration 290 / 300: loss 0.581435\n",
      "iteration 290 / 300: loss 0.599604\n",
      "iteration 290 / 300: loss 0.591182\n",
      "iteration 290 / 300: loss 0.599919\n",
      "iteration 290 / 300: loss 0.596015\n",
      "iteration 290 / 300: loss 0.590760\n",
      "iteration 290 / 300: loss 0.591961\n",
      "iteration 290 / 300: loss 0.615468\n",
      "iteration 290 / 300: loss 0.621360\n",
      "iteration 290 / 300: loss 0.587267\n",
      "iteration 290 / 300: loss 0.582483\n",
      "iteration 290 / 300: loss 0.585572\n",
      "iteration 290 / 300: loss 0.603666\n",
      "iteration 290 / 300: loss 0.585192\n",
      "iteration 290 / 300: loss 0.578880\n",
      "iteration 290 / 300: loss 0.576418\n",
      "iteration 290 / 300: loss 0.574097\n",
      "iteration 290 / 300: loss 0.600500\n",
      "iteration 290 / 300: loss 0.584490\n",
      "iteration 290 / 300: loss 0.584834\n",
      "iteration 290 / 300: loss 0.568323\n",
      "iteration 290 / 300: loss 0.592025\n",
      "iteration 290 / 300: loss 0.612116\n",
      "iteration 290 / 300: loss 0.608923\n",
      "iteration 290 / 300: loss 0.607613\n",
      "iteration 290 / 300: loss 0.595533\n",
      "iteration 290 / 300: loss 0.592837\n",
      "iteration 290 / 300: loss 0.597988\n",
      "iteration 290 / 300: loss 0.597677\n",
      "iteration 290 / 300: loss 0.600953\n",
      "iteration 290 / 300: loss 0.597422\n",
      "iteration 290 / 300: loss 0.598776\n",
      "iteration 290 / 300: loss 0.587806\n",
      "iteration 290 / 300: loss 0.600499\n",
      "iteration 290 / 300: loss 0.599650\n",
      "iteration 290 / 300: loss 0.617540\n",
      "iteration 290 / 300: loss 0.598875\n",
      "iteration 290 / 300: loss 0.600801\n",
      "iteration 290 / 300: loss 0.605305\n",
      "iteration 290 / 300: loss 0.598592\n",
      "iteration 290 / 300: loss 0.591474\n",
      "iteration 290 / 300: loss 0.580382\n",
      "iteration 290 / 300: loss 0.598221\n",
      "iteration 290 / 300: loss 0.611685\n",
      "iteration 290 / 300: loss 0.613219\n",
      "iteration 290 / 300: loss 0.582214\n",
      "iteration 290 / 300: loss 0.601955\n",
      "iteration 290 / 300: loss 0.608956\n",
      "iteration 290 / 300: loss 0.601794\n",
      "iteration 290 / 300: loss 0.607944\n",
      "iteration 290 / 300: loss 0.620236\n",
      "iteration 290 / 300: loss 0.584817\n",
      "iteration 290 / 300: loss 0.583721\n",
      "iteration 290 / 300: loss 0.628849\n",
      "iteration 290 / 300: loss 0.609399\n",
      "iteration 290 / 300: loss 0.606265\n",
      "iteration 290 / 300: loss 0.599034\n",
      "iteration 290 / 300: loss 0.615876\n",
      "iteration 290 / 300: loss 0.596489\n",
      "iteration 290 / 300: loss 0.581430\n",
      "iteration 290 / 300: loss 0.609807\n",
      "iteration 290 / 300: loss 0.608125\n",
      "iteration 290 / 300: loss 0.598224\n",
      "iteration 290 / 300: loss 0.592022\n",
      "iteration 290 / 300: loss 0.611031\n",
      "iteration 290 / 300: loss 0.598550\n",
      "iteration 290 / 300: loss 0.581382\n",
      "iteration 290 / 300: loss 0.609580\n",
      "iteration 291 / 300: loss 0.578384\n",
      "iteration 291 / 300: loss 0.596214\n",
      "iteration 291 / 300: loss 0.569455\n",
      "iteration 291 / 300: loss 0.597849\n",
      "iteration 291 / 300: loss 0.598940\n",
      "iteration 291 / 300: loss 0.603876\n",
      "iteration 291 / 300: loss 0.615261\n",
      "iteration 291 / 300: loss 0.588227\n",
      "iteration 291 / 300: loss 0.627171\n",
      "iteration 291 / 300: loss 0.592600\n",
      "iteration 291 / 300: loss 0.621500\n",
      "iteration 291 / 300: loss 0.593093\n",
      "iteration 291 / 300: loss 0.600541\n",
      "iteration 291 / 300: loss 0.571000\n",
      "iteration 291 / 300: loss 0.592911\n",
      "iteration 291 / 300: loss 0.600043\n",
      "iteration 291 / 300: loss 0.598053\n",
      "iteration 291 / 300: loss 0.583712\n",
      "iteration 291 / 300: loss 0.614355\n",
      "iteration 291 / 300: loss 0.591285\n",
      "iteration 291 / 300: loss 0.591391\n",
      "iteration 291 / 300: loss 0.594005\n",
      "iteration 291 / 300: loss 0.596735\n",
      "iteration 291 / 300: loss 0.596712\n",
      "iteration 291 / 300: loss 0.611735\n",
      "iteration 291 / 300: loss 0.607258\n",
      "iteration 291 / 300: loss 0.597031\n",
      "iteration 291 / 300: loss 0.596301\n",
      "iteration 291 / 300: loss 0.627391\n",
      "iteration 291 / 300: loss 0.601584\n",
      "iteration 291 / 300: loss 0.599923\n",
      "iteration 291 / 300: loss 0.621952\n",
      "iteration 291 / 300: loss 0.581435\n",
      "iteration 291 / 300: loss 0.599604\n",
      "iteration 291 / 300: loss 0.591182\n",
      "iteration 291 / 300: loss 0.599919\n",
      "iteration 291 / 300: loss 0.596015\n",
      "iteration 291 / 300: loss 0.590760\n",
      "iteration 291 / 300: loss 0.591961\n",
      "iteration 291 / 300: loss 0.615468\n",
      "iteration 291 / 300: loss 0.621360\n",
      "iteration 291 / 300: loss 0.587267\n",
      "iteration 291 / 300: loss 0.582483\n",
      "iteration 291 / 300: loss 0.585572\n",
      "iteration 291 / 300: loss 0.603666\n",
      "iteration 291 / 300: loss 0.585192\n",
      "iteration 291 / 300: loss 0.578880\n",
      "iteration 291 / 300: loss 0.576418\n",
      "iteration 291 / 300: loss 0.574097\n",
      "iteration 291 / 300: loss 0.600500\n",
      "iteration 291 / 300: loss 0.584490\n",
      "iteration 291 / 300: loss 0.584834\n",
      "iteration 291 / 300: loss 0.568323\n",
      "iteration 291 / 300: loss 0.592025\n",
      "iteration 291 / 300: loss 0.612116\n",
      "iteration 291 / 300: loss 0.608923\n",
      "iteration 291 / 300: loss 0.607613\n",
      "iteration 291 / 300: loss 0.595533\n",
      "iteration 291 / 300: loss 0.592837\n",
      "iteration 291 / 300: loss 0.597988\n",
      "iteration 291 / 300: loss 0.597677\n",
      "iteration 291 / 300: loss 0.600953\n",
      "iteration 291 / 300: loss 0.597422\n",
      "iteration 291 / 300: loss 0.598776\n",
      "iteration 291 / 300: loss 0.587806\n",
      "iteration 291 / 300: loss 0.600499\n",
      "iteration 291 / 300: loss 0.599650\n",
      "iteration 291 / 300: loss 0.617540\n",
      "iteration 291 / 300: loss 0.598875\n",
      "iteration 291 / 300: loss 0.600801\n",
      "iteration 291 / 300: loss 0.605305\n",
      "iteration 291 / 300: loss 0.598592\n",
      "iteration 291 / 300: loss 0.591474\n",
      "iteration 291 / 300: loss 0.580382\n",
      "iteration 291 / 300: loss 0.598221\n",
      "iteration 291 / 300: loss 0.611685\n",
      "iteration 291 / 300: loss 0.613219\n",
      "iteration 291 / 300: loss 0.582214\n",
      "iteration 291 / 300: loss 0.601955\n",
      "iteration 291 / 300: loss 0.608956\n",
      "iteration 291 / 300: loss 0.601794\n",
      "iteration 291 / 300: loss 0.607944\n",
      "iteration 291 / 300: loss 0.620236\n",
      "iteration 291 / 300: loss 0.584817\n",
      "iteration 291 / 300: loss 0.583721\n",
      "iteration 291 / 300: loss 0.628849\n",
      "iteration 291 / 300: loss 0.609399\n",
      "iteration 291 / 300: loss 0.606265\n",
      "iteration 291 / 300: loss 0.599034\n",
      "iteration 291 / 300: loss 0.615876\n",
      "iteration 291 / 300: loss 0.596489\n",
      "iteration 291 / 300: loss 0.581430\n",
      "iteration 291 / 300: loss 0.609807\n",
      "iteration 291 / 300: loss 0.608125\n",
      "iteration 291 / 300: loss 0.598224\n",
      "iteration 291 / 300: loss 0.592022\n",
      "iteration 291 / 300: loss 0.611031\n",
      "iteration 291 / 300: loss 0.598550\n",
      "iteration 291 / 300: loss 0.581382\n",
      "iteration 291 / 300: loss 0.609580\n",
      "iteration 292 / 300: loss 0.578384\n",
      "iteration 292 / 300: loss 0.596214\n",
      "iteration 292 / 300: loss 0.569455\n",
      "iteration 292 / 300: loss 0.597849\n",
      "iteration 292 / 300: loss 0.598940\n",
      "iteration 292 / 300: loss 0.603876\n",
      "iteration 292 / 300: loss 0.615261\n",
      "iteration 292 / 300: loss 0.588227\n",
      "iteration 292 / 300: loss 0.627171\n",
      "iteration 292 / 300: loss 0.592600\n",
      "iteration 292 / 300: loss 0.621500\n",
      "iteration 292 / 300: loss 0.593093\n",
      "iteration 292 / 300: loss 0.600541\n",
      "iteration 292 / 300: loss 0.571000\n",
      "iteration 292 / 300: loss 0.592911\n",
      "iteration 292 / 300: loss 0.600043\n",
      "iteration 292 / 300: loss 0.598053\n",
      "iteration 292 / 300: loss 0.583712\n",
      "iteration 292 / 300: loss 0.614355\n",
      "iteration 292 / 300: loss 0.591285\n",
      "iteration 292 / 300: loss 0.591391\n",
      "iteration 292 / 300: loss 0.594005\n",
      "iteration 292 / 300: loss 0.596735\n",
      "iteration 292 / 300: loss 0.596712\n",
      "iteration 292 / 300: loss 0.611735\n",
      "iteration 292 / 300: loss 0.607258\n",
      "iteration 292 / 300: loss 0.597031\n",
      "iteration 292 / 300: loss 0.596301\n",
      "iteration 292 / 300: loss 0.627391\n",
      "iteration 292 / 300: loss 0.601584\n",
      "iteration 292 / 300: loss 0.599923\n",
      "iteration 292 / 300: loss 0.621952\n",
      "iteration 292 / 300: loss 0.581435\n",
      "iteration 292 / 300: loss 0.599604\n",
      "iteration 292 / 300: loss 0.591182\n",
      "iteration 292 / 300: loss 0.599919\n",
      "iteration 292 / 300: loss 0.596015\n",
      "iteration 292 / 300: loss 0.590760\n",
      "iteration 292 / 300: loss 0.591961\n",
      "iteration 292 / 300: loss 0.615468\n",
      "iteration 292 / 300: loss 0.621360\n",
      "iteration 292 / 300: loss 0.587267\n",
      "iteration 292 / 300: loss 0.582483\n",
      "iteration 292 / 300: loss 0.585572\n",
      "iteration 292 / 300: loss 0.603666\n",
      "iteration 292 / 300: loss 0.585192\n",
      "iteration 292 / 300: loss 0.578880\n",
      "iteration 292 / 300: loss 0.576418\n",
      "iteration 292 / 300: loss 0.574097\n",
      "iteration 292 / 300: loss 0.600500\n",
      "iteration 292 / 300: loss 0.584490\n",
      "iteration 292 / 300: loss 0.584834\n",
      "iteration 292 / 300: loss 0.568323\n",
      "iteration 292 / 300: loss 0.592025\n",
      "iteration 292 / 300: loss 0.612116\n",
      "iteration 292 / 300: loss 0.608923\n",
      "iteration 292 / 300: loss 0.607613\n",
      "iteration 292 / 300: loss 0.595533\n",
      "iteration 292 / 300: loss 0.592837\n",
      "iteration 292 / 300: loss 0.597988\n",
      "iteration 292 / 300: loss 0.597677\n",
      "iteration 292 / 300: loss 0.600953\n",
      "iteration 292 / 300: loss 0.597422\n",
      "iteration 292 / 300: loss 0.598776\n",
      "iteration 292 / 300: loss 0.587806\n",
      "iteration 292 / 300: loss 0.600499\n",
      "iteration 292 / 300: loss 0.599650\n",
      "iteration 292 / 300: loss 0.617540\n",
      "iteration 292 / 300: loss 0.598875\n",
      "iteration 292 / 300: loss 0.600801\n",
      "iteration 292 / 300: loss 0.605305\n",
      "iteration 292 / 300: loss 0.598592\n",
      "iteration 292 / 300: loss 0.591474\n",
      "iteration 292 / 300: loss 0.580382\n",
      "iteration 292 / 300: loss 0.598221\n",
      "iteration 292 / 300: loss 0.611685\n",
      "iteration 292 / 300: loss 0.613219\n",
      "iteration 292 / 300: loss 0.582214\n",
      "iteration 292 / 300: loss 0.601955\n",
      "iteration 292 / 300: loss 0.608956\n",
      "iteration 292 / 300: loss 0.601794\n",
      "iteration 292 / 300: loss 0.607944\n",
      "iteration 292 / 300: loss 0.620236\n",
      "iteration 292 / 300: loss 0.584817\n",
      "iteration 292 / 300: loss 0.583721\n",
      "iteration 292 / 300: loss 0.628849\n",
      "iteration 292 / 300: loss 0.609399\n",
      "iteration 292 / 300: loss 0.606265\n",
      "iteration 292 / 300: loss 0.599034\n",
      "iteration 292 / 300: loss 0.615876\n",
      "iteration 292 / 300: loss 0.596489\n",
      "iteration 292 / 300: loss 0.581430\n",
      "iteration 292 / 300: loss 0.609807\n",
      "iteration 292 / 300: loss 0.608125\n",
      "iteration 292 / 300: loss 0.598224\n",
      "iteration 292 / 300: loss 0.592022\n",
      "iteration 292 / 300: loss 0.611031\n",
      "iteration 292 / 300: loss 0.598550\n",
      "iteration 292 / 300: loss 0.581382\n",
      "iteration 292 / 300: loss 0.609580\n",
      "iteration 293 / 300: loss 0.578384\n",
      "iteration 293 / 300: loss 0.596214\n",
      "iteration 293 / 300: loss 0.569455\n",
      "iteration 293 / 300: loss 0.597849\n",
      "iteration 293 / 300: loss 0.598940\n",
      "iteration 293 / 300: loss 0.603876\n",
      "iteration 293 / 300: loss 0.615261\n",
      "iteration 293 / 300: loss 0.588227\n",
      "iteration 293 / 300: loss 0.627171\n",
      "iteration 293 / 300: loss 0.592600\n",
      "iteration 293 / 300: loss 0.621500\n",
      "iteration 293 / 300: loss 0.593093\n",
      "iteration 293 / 300: loss 0.600541\n",
      "iteration 293 / 300: loss 0.571000\n",
      "iteration 293 / 300: loss 0.592911\n",
      "iteration 293 / 300: loss 0.600043\n",
      "iteration 293 / 300: loss 0.598053\n",
      "iteration 293 / 300: loss 0.583712\n",
      "iteration 293 / 300: loss 0.614355\n",
      "iteration 293 / 300: loss 0.591285\n",
      "iteration 293 / 300: loss 0.591391\n",
      "iteration 293 / 300: loss 0.594005\n",
      "iteration 293 / 300: loss 0.596735\n",
      "iteration 293 / 300: loss 0.596712\n",
      "iteration 293 / 300: loss 0.611735\n",
      "iteration 293 / 300: loss 0.607258\n",
      "iteration 293 / 300: loss 0.597031\n",
      "iteration 293 / 300: loss 0.596301\n",
      "iteration 293 / 300: loss 0.627391\n",
      "iteration 293 / 300: loss 0.601584\n",
      "iteration 293 / 300: loss 0.599923\n",
      "iteration 293 / 300: loss 0.621952\n",
      "iteration 293 / 300: loss 0.581435\n",
      "iteration 293 / 300: loss 0.599604\n",
      "iteration 293 / 300: loss 0.591182\n",
      "iteration 293 / 300: loss 0.599919\n",
      "iteration 293 / 300: loss 0.596015\n",
      "iteration 293 / 300: loss 0.590760\n",
      "iteration 293 / 300: loss 0.591961\n",
      "iteration 293 / 300: loss 0.615468\n",
      "iteration 293 / 300: loss 0.621360\n",
      "iteration 293 / 300: loss 0.587267\n",
      "iteration 293 / 300: loss 0.582483\n",
      "iteration 293 / 300: loss 0.585572\n",
      "iteration 293 / 300: loss 0.603666\n",
      "iteration 293 / 300: loss 0.585192\n",
      "iteration 293 / 300: loss 0.578880\n",
      "iteration 293 / 300: loss 0.576418\n",
      "iteration 293 / 300: loss 0.574097\n",
      "iteration 293 / 300: loss 0.600500\n",
      "iteration 293 / 300: loss 0.584490\n",
      "iteration 293 / 300: loss 0.584834\n",
      "iteration 293 / 300: loss 0.568323\n",
      "iteration 293 / 300: loss 0.592025\n",
      "iteration 293 / 300: loss 0.612116\n",
      "iteration 293 / 300: loss 0.608923\n",
      "iteration 293 / 300: loss 0.607613\n",
      "iteration 293 / 300: loss 0.595533\n",
      "iteration 293 / 300: loss 0.592837\n",
      "iteration 293 / 300: loss 0.597988\n",
      "iteration 293 / 300: loss 0.597677\n",
      "iteration 293 / 300: loss 0.600953\n",
      "iteration 293 / 300: loss 0.597422\n",
      "iteration 293 / 300: loss 0.598776\n",
      "iteration 293 / 300: loss 0.587806\n",
      "iteration 293 / 300: loss 0.600499\n",
      "iteration 293 / 300: loss 0.599650\n",
      "iteration 293 / 300: loss 0.617540\n",
      "iteration 293 / 300: loss 0.598875\n",
      "iteration 293 / 300: loss 0.600801\n",
      "iteration 293 / 300: loss 0.605305\n",
      "iteration 293 / 300: loss 0.598592\n",
      "iteration 293 / 300: loss 0.591474\n",
      "iteration 293 / 300: loss 0.580382\n",
      "iteration 293 / 300: loss 0.598221\n",
      "iteration 293 / 300: loss 0.611685\n",
      "iteration 293 / 300: loss 0.613219\n",
      "iteration 293 / 300: loss 0.582214\n",
      "iteration 293 / 300: loss 0.601955\n",
      "iteration 293 / 300: loss 0.608956\n",
      "iteration 293 / 300: loss 0.601794\n",
      "iteration 293 / 300: loss 0.607944\n",
      "iteration 293 / 300: loss 0.620236\n",
      "iteration 293 / 300: loss 0.584817\n",
      "iteration 293 / 300: loss 0.583721\n",
      "iteration 293 / 300: loss 0.628849\n",
      "iteration 293 / 300: loss 0.609399\n",
      "iteration 293 / 300: loss 0.606265\n",
      "iteration 293 / 300: loss 0.599034\n",
      "iteration 293 / 300: loss 0.615876\n",
      "iteration 293 / 300: loss 0.596489\n",
      "iteration 293 / 300: loss 0.581430\n",
      "iteration 293 / 300: loss 0.609807\n",
      "iteration 293 / 300: loss 0.608125\n",
      "iteration 293 / 300: loss 0.598224\n",
      "iteration 293 / 300: loss 0.592022\n",
      "iteration 293 / 300: loss 0.611031\n",
      "iteration 293 / 300: loss 0.598550\n",
      "iteration 293 / 300: loss 0.581382\n",
      "iteration 293 / 300: loss 0.609580\n",
      "iteration 294 / 300: loss 0.578384\n",
      "iteration 294 / 300: loss 0.596214\n",
      "iteration 294 / 300: loss 0.569455\n",
      "iteration 294 / 300: loss 0.597849\n",
      "iteration 294 / 300: loss 0.598940\n",
      "iteration 294 / 300: loss 0.603876\n",
      "iteration 294 / 300: loss 0.615261\n",
      "iteration 294 / 300: loss 0.588227\n",
      "iteration 294 / 300: loss 0.627171\n",
      "iteration 294 / 300: loss 0.592600\n",
      "iteration 294 / 300: loss 0.621500\n",
      "iteration 294 / 300: loss 0.593093\n",
      "iteration 294 / 300: loss 0.600541\n",
      "iteration 294 / 300: loss 0.571000\n",
      "iteration 294 / 300: loss 0.592911\n",
      "iteration 294 / 300: loss 0.600043\n",
      "iteration 294 / 300: loss 0.598053\n",
      "iteration 294 / 300: loss 0.583712\n",
      "iteration 294 / 300: loss 0.614355\n",
      "iteration 294 / 300: loss 0.591285\n",
      "iteration 294 / 300: loss 0.591391\n",
      "iteration 294 / 300: loss 0.594005\n",
      "iteration 294 / 300: loss 0.596735\n",
      "iteration 294 / 300: loss 0.596712\n",
      "iteration 294 / 300: loss 0.611735\n",
      "iteration 294 / 300: loss 0.607258\n",
      "iteration 294 / 300: loss 0.597031\n",
      "iteration 294 / 300: loss 0.596301\n",
      "iteration 294 / 300: loss 0.627391\n",
      "iteration 294 / 300: loss 0.601584\n",
      "iteration 294 / 300: loss 0.599923\n",
      "iteration 294 / 300: loss 0.621952\n",
      "iteration 294 / 300: loss 0.581435\n",
      "iteration 294 / 300: loss 0.599604\n",
      "iteration 294 / 300: loss 0.591182\n",
      "iteration 294 / 300: loss 0.599919\n",
      "iteration 294 / 300: loss 0.596015\n",
      "iteration 294 / 300: loss 0.590760\n",
      "iteration 294 / 300: loss 0.591961\n",
      "iteration 294 / 300: loss 0.615468\n",
      "iteration 294 / 300: loss 0.621360\n",
      "iteration 294 / 300: loss 0.587267\n",
      "iteration 294 / 300: loss 0.582483\n",
      "iteration 294 / 300: loss 0.585572\n",
      "iteration 294 / 300: loss 0.603666\n",
      "iteration 294 / 300: loss 0.585192\n",
      "iteration 294 / 300: loss 0.578880\n",
      "iteration 294 / 300: loss 0.576418\n",
      "iteration 294 / 300: loss 0.574097\n",
      "iteration 294 / 300: loss 0.600500\n",
      "iteration 294 / 300: loss 0.584490\n",
      "iteration 294 / 300: loss 0.584834\n",
      "iteration 294 / 300: loss 0.568323\n",
      "iteration 294 / 300: loss 0.592025\n",
      "iteration 294 / 300: loss 0.612116\n",
      "iteration 294 / 300: loss 0.608923\n",
      "iteration 294 / 300: loss 0.607613\n",
      "iteration 294 / 300: loss 0.595533\n",
      "iteration 294 / 300: loss 0.592837\n",
      "iteration 294 / 300: loss 0.597988\n",
      "iteration 294 / 300: loss 0.597677\n",
      "iteration 294 / 300: loss 0.600953\n",
      "iteration 294 / 300: loss 0.597422\n",
      "iteration 294 / 300: loss 0.598776\n",
      "iteration 294 / 300: loss 0.587806\n",
      "iteration 294 / 300: loss 0.600499\n",
      "iteration 294 / 300: loss 0.599650\n",
      "iteration 294 / 300: loss 0.617540\n",
      "iteration 294 / 300: loss 0.598875\n",
      "iteration 294 / 300: loss 0.600801\n",
      "iteration 294 / 300: loss 0.605305\n",
      "iteration 294 / 300: loss 0.598592\n",
      "iteration 294 / 300: loss 0.591474\n",
      "iteration 294 / 300: loss 0.580382\n",
      "iteration 294 / 300: loss 0.598221\n",
      "iteration 294 / 300: loss 0.611685\n",
      "iteration 294 / 300: loss 0.613219\n",
      "iteration 294 / 300: loss 0.582214\n",
      "iteration 294 / 300: loss 0.601955\n",
      "iteration 294 / 300: loss 0.608956\n",
      "iteration 294 / 300: loss 0.601794\n",
      "iteration 294 / 300: loss 0.607944\n",
      "iteration 294 / 300: loss 0.620236\n",
      "iteration 294 / 300: loss 0.584817\n",
      "iteration 294 / 300: loss 0.583721\n",
      "iteration 294 / 300: loss 0.628849\n",
      "iteration 294 / 300: loss 0.609399\n",
      "iteration 294 / 300: loss 0.606265\n",
      "iteration 294 / 300: loss 0.599034\n",
      "iteration 294 / 300: loss 0.615876\n",
      "iteration 294 / 300: loss 0.596489\n",
      "iteration 294 / 300: loss 0.581430\n",
      "iteration 294 / 300: loss 0.609807\n",
      "iteration 294 / 300: loss 0.608125\n",
      "iteration 294 / 300: loss 0.598224\n",
      "iteration 294 / 300: loss 0.592022\n",
      "iteration 294 / 300: loss 0.611031\n",
      "iteration 294 / 300: loss 0.598550\n",
      "iteration 294 / 300: loss 0.581382\n",
      "iteration 294 / 300: loss 0.609580\n",
      "iteration 295 / 300: loss 0.578384\n",
      "iteration 295 / 300: loss 0.596214\n",
      "iteration 295 / 300: loss 0.569455\n",
      "iteration 295 / 300: loss 0.597849\n",
      "iteration 295 / 300: loss 0.598940\n",
      "iteration 295 / 300: loss 0.603876\n",
      "iteration 295 / 300: loss 0.615261\n",
      "iteration 295 / 300: loss 0.588227\n",
      "iteration 295 / 300: loss 0.627171\n",
      "iteration 295 / 300: loss 0.592600\n",
      "iteration 295 / 300: loss 0.621500\n",
      "iteration 295 / 300: loss 0.593093\n",
      "iteration 295 / 300: loss 0.600541\n",
      "iteration 295 / 300: loss 0.571000\n",
      "iteration 295 / 300: loss 0.592911\n",
      "iteration 295 / 300: loss 0.600043\n",
      "iteration 295 / 300: loss 0.598053\n",
      "iteration 295 / 300: loss 0.583712\n",
      "iteration 295 / 300: loss 0.614355\n",
      "iteration 295 / 300: loss 0.591285\n",
      "iteration 295 / 300: loss 0.591391\n",
      "iteration 295 / 300: loss 0.594005\n",
      "iteration 295 / 300: loss 0.596735\n",
      "iteration 295 / 300: loss 0.596712\n",
      "iteration 295 / 300: loss 0.611735\n",
      "iteration 295 / 300: loss 0.607258\n",
      "iteration 295 / 300: loss 0.597031\n",
      "iteration 295 / 300: loss 0.596301\n",
      "iteration 295 / 300: loss 0.627391\n",
      "iteration 295 / 300: loss 0.601584\n",
      "iteration 295 / 300: loss 0.599923\n",
      "iteration 295 / 300: loss 0.621952\n",
      "iteration 295 / 300: loss 0.581435\n",
      "iteration 295 / 300: loss 0.599604\n",
      "iteration 295 / 300: loss 0.591182\n",
      "iteration 295 / 300: loss 0.599919\n",
      "iteration 295 / 300: loss 0.596015\n",
      "iteration 295 / 300: loss 0.590760\n",
      "iteration 295 / 300: loss 0.591961\n",
      "iteration 295 / 300: loss 0.615468\n",
      "iteration 295 / 300: loss 0.621360\n",
      "iteration 295 / 300: loss 0.587267\n",
      "iteration 295 / 300: loss 0.582483\n",
      "iteration 295 / 300: loss 0.585572\n",
      "iteration 295 / 300: loss 0.603666\n",
      "iteration 295 / 300: loss 0.585192\n",
      "iteration 295 / 300: loss 0.578880\n",
      "iteration 295 / 300: loss 0.576418\n",
      "iteration 295 / 300: loss 0.574097\n",
      "iteration 295 / 300: loss 0.600500\n",
      "iteration 295 / 300: loss 0.584490\n",
      "iteration 295 / 300: loss 0.584834\n",
      "iteration 295 / 300: loss 0.568323\n",
      "iteration 295 / 300: loss 0.592025\n",
      "iteration 295 / 300: loss 0.612116\n",
      "iteration 295 / 300: loss 0.608923\n",
      "iteration 295 / 300: loss 0.607613\n",
      "iteration 295 / 300: loss 0.595533\n",
      "iteration 295 / 300: loss 0.592837\n",
      "iteration 295 / 300: loss 0.597988\n",
      "iteration 295 / 300: loss 0.597677\n",
      "iteration 295 / 300: loss 0.600953\n",
      "iteration 295 / 300: loss 0.597422\n",
      "iteration 295 / 300: loss 0.598776\n",
      "iteration 295 / 300: loss 0.587806\n",
      "iteration 295 / 300: loss 0.600499\n",
      "iteration 295 / 300: loss 0.599650\n",
      "iteration 295 / 300: loss 0.617540\n",
      "iteration 295 / 300: loss 0.598875\n",
      "iteration 295 / 300: loss 0.600801\n",
      "iteration 295 / 300: loss 0.605305\n",
      "iteration 295 / 300: loss 0.598592\n",
      "iteration 295 / 300: loss 0.591474\n",
      "iteration 295 / 300: loss 0.580382\n",
      "iteration 295 / 300: loss 0.598221\n",
      "iteration 295 / 300: loss 0.611685\n",
      "iteration 295 / 300: loss 0.613219\n",
      "iteration 295 / 300: loss 0.582214\n",
      "iteration 295 / 300: loss 0.601955\n",
      "iteration 295 / 300: loss 0.608956\n",
      "iteration 295 / 300: loss 0.601794\n",
      "iteration 295 / 300: loss 0.607944\n",
      "iteration 295 / 300: loss 0.620236\n",
      "iteration 295 / 300: loss 0.584817\n",
      "iteration 295 / 300: loss 0.583721\n",
      "iteration 295 / 300: loss 0.628849\n",
      "iteration 295 / 300: loss 0.609399\n",
      "iteration 295 / 300: loss 0.606265\n",
      "iteration 295 / 300: loss 0.599034\n",
      "iteration 295 / 300: loss 0.615876\n",
      "iteration 295 / 300: loss 0.596489\n",
      "iteration 295 / 300: loss 0.581430\n",
      "iteration 295 / 300: loss 0.609807\n",
      "iteration 295 / 300: loss 0.608125\n",
      "iteration 295 / 300: loss 0.598224\n",
      "iteration 295 / 300: loss 0.592022\n",
      "iteration 295 / 300: loss 0.611031\n",
      "iteration 295 / 300: loss 0.598550\n",
      "iteration 295 / 300: loss 0.581382\n",
      "iteration 295 / 300: loss 0.609580\n",
      "iteration 296 / 300: loss 0.578384\n",
      "iteration 296 / 300: loss 0.596214\n",
      "iteration 296 / 300: loss 0.569455\n",
      "iteration 296 / 300: loss 0.597849\n",
      "iteration 296 / 300: loss 0.598940\n",
      "iteration 296 / 300: loss 0.603876\n",
      "iteration 296 / 300: loss 0.615261\n",
      "iteration 296 / 300: loss 0.588227\n",
      "iteration 296 / 300: loss 0.627171\n",
      "iteration 296 / 300: loss 0.592600\n",
      "iteration 296 / 300: loss 0.621500\n",
      "iteration 296 / 300: loss 0.593093\n",
      "iteration 296 / 300: loss 0.600541\n",
      "iteration 296 / 300: loss 0.571000\n",
      "iteration 296 / 300: loss 0.592911\n",
      "iteration 296 / 300: loss 0.600043\n",
      "iteration 296 / 300: loss 0.598053\n",
      "iteration 296 / 300: loss 0.583712\n",
      "iteration 296 / 300: loss 0.614355\n",
      "iteration 296 / 300: loss 0.591285\n",
      "iteration 296 / 300: loss 0.591391\n",
      "iteration 296 / 300: loss 0.594005\n",
      "iteration 296 / 300: loss 0.596735\n",
      "iteration 296 / 300: loss 0.596712\n",
      "iteration 296 / 300: loss 0.611735\n",
      "iteration 296 / 300: loss 0.607258\n",
      "iteration 296 / 300: loss 0.597031\n",
      "iteration 296 / 300: loss 0.596301\n",
      "iteration 296 / 300: loss 0.627391\n",
      "iteration 296 / 300: loss 0.601584\n",
      "iteration 296 / 300: loss 0.599923\n",
      "iteration 296 / 300: loss 0.621952\n",
      "iteration 296 / 300: loss 0.581435\n",
      "iteration 296 / 300: loss 0.599604\n",
      "iteration 296 / 300: loss 0.591182\n",
      "iteration 296 / 300: loss 0.599919\n",
      "iteration 296 / 300: loss 0.596015\n",
      "iteration 296 / 300: loss 0.590760\n",
      "iteration 296 / 300: loss 0.591961\n",
      "iteration 296 / 300: loss 0.615468\n",
      "iteration 296 / 300: loss 0.621360\n",
      "iteration 296 / 300: loss 0.587267\n",
      "iteration 296 / 300: loss 0.582483\n",
      "iteration 296 / 300: loss 0.585572\n",
      "iteration 296 / 300: loss 0.603666\n",
      "iteration 296 / 300: loss 0.585192\n",
      "iteration 296 / 300: loss 0.578880\n",
      "iteration 296 / 300: loss 0.576418\n",
      "iteration 296 / 300: loss 0.574097\n",
      "iteration 296 / 300: loss 0.600500\n",
      "iteration 296 / 300: loss 0.584490\n",
      "iteration 296 / 300: loss 0.584834\n",
      "iteration 296 / 300: loss 0.568323\n",
      "iteration 296 / 300: loss 0.592025\n",
      "iteration 296 / 300: loss 0.612116\n",
      "iteration 296 / 300: loss 0.608923\n",
      "iteration 296 / 300: loss 0.607613\n",
      "iteration 296 / 300: loss 0.595533\n",
      "iteration 296 / 300: loss 0.592837\n",
      "iteration 296 / 300: loss 0.597988\n",
      "iteration 296 / 300: loss 0.597677\n",
      "iteration 296 / 300: loss 0.600953\n",
      "iteration 296 / 300: loss 0.597422\n",
      "iteration 296 / 300: loss 0.598776\n",
      "iteration 296 / 300: loss 0.587806\n",
      "iteration 296 / 300: loss 0.600499\n",
      "iteration 296 / 300: loss 0.599650\n",
      "iteration 296 / 300: loss 0.617540\n",
      "iteration 296 / 300: loss 0.598875\n",
      "iteration 296 / 300: loss 0.600801\n",
      "iteration 296 / 300: loss 0.605305\n",
      "iteration 296 / 300: loss 0.598592\n",
      "iteration 296 / 300: loss 0.591474\n",
      "iteration 296 / 300: loss 0.580382\n",
      "iteration 296 / 300: loss 0.598221\n",
      "iteration 296 / 300: loss 0.611685\n",
      "iteration 296 / 300: loss 0.613219\n",
      "iteration 296 / 300: loss 0.582214\n",
      "iteration 296 / 300: loss 0.601955\n",
      "iteration 296 / 300: loss 0.608956\n",
      "iteration 296 / 300: loss 0.601794\n",
      "iteration 296 / 300: loss 0.607944\n",
      "iteration 296 / 300: loss 0.620236\n",
      "iteration 296 / 300: loss 0.584817\n",
      "iteration 296 / 300: loss 0.583721\n",
      "iteration 296 / 300: loss 0.628849\n",
      "iteration 296 / 300: loss 0.609399\n",
      "iteration 296 / 300: loss 0.606265\n",
      "iteration 296 / 300: loss 0.599034\n",
      "iteration 296 / 300: loss 0.615876\n",
      "iteration 296 / 300: loss 0.596489\n",
      "iteration 296 / 300: loss 0.581430\n",
      "iteration 296 / 300: loss 0.609807\n",
      "iteration 296 / 300: loss 0.608125\n",
      "iteration 296 / 300: loss 0.598224\n",
      "iteration 296 / 300: loss 0.592022\n",
      "iteration 296 / 300: loss 0.611031\n",
      "iteration 296 / 300: loss 0.598550\n",
      "iteration 296 / 300: loss 0.581382\n",
      "iteration 296 / 300: loss 0.609580\n",
      "iteration 297 / 300: loss 0.578384\n",
      "iteration 297 / 300: loss 0.596214\n",
      "iteration 297 / 300: loss 0.569455\n",
      "iteration 297 / 300: loss 0.597849\n",
      "iteration 297 / 300: loss 0.598940\n",
      "iteration 297 / 300: loss 0.603876\n",
      "iteration 297 / 300: loss 0.615261\n",
      "iteration 297 / 300: loss 0.588227\n",
      "iteration 297 / 300: loss 0.627171\n",
      "iteration 297 / 300: loss 0.592600\n",
      "iteration 297 / 300: loss 0.621500\n",
      "iteration 297 / 300: loss 0.593093\n",
      "iteration 297 / 300: loss 0.600541\n",
      "iteration 297 / 300: loss 0.571000\n",
      "iteration 297 / 300: loss 0.592911\n",
      "iteration 297 / 300: loss 0.600043\n",
      "iteration 297 / 300: loss 0.598053\n",
      "iteration 297 / 300: loss 0.583712\n",
      "iteration 297 / 300: loss 0.614355\n",
      "iteration 297 / 300: loss 0.591285\n",
      "iteration 297 / 300: loss 0.591391\n",
      "iteration 297 / 300: loss 0.594005\n",
      "iteration 297 / 300: loss 0.596735\n",
      "iteration 297 / 300: loss 0.596712\n",
      "iteration 297 / 300: loss 0.611735\n",
      "iteration 297 / 300: loss 0.607258\n",
      "iteration 297 / 300: loss 0.597031\n",
      "iteration 297 / 300: loss 0.596301\n",
      "iteration 297 / 300: loss 0.627391\n",
      "iteration 297 / 300: loss 0.601584\n",
      "iteration 297 / 300: loss 0.599923\n",
      "iteration 297 / 300: loss 0.621952\n",
      "iteration 297 / 300: loss 0.581435\n",
      "iteration 297 / 300: loss 0.599604\n",
      "iteration 297 / 300: loss 0.591182\n",
      "iteration 297 / 300: loss 0.599919\n",
      "iteration 297 / 300: loss 0.596015\n",
      "iteration 297 / 300: loss 0.590760\n",
      "iteration 297 / 300: loss 0.591961\n",
      "iteration 297 / 300: loss 0.615468\n",
      "iteration 297 / 300: loss 0.621360\n",
      "iteration 297 / 300: loss 0.587267\n",
      "iteration 297 / 300: loss 0.582483\n",
      "iteration 297 / 300: loss 0.585572\n",
      "iteration 297 / 300: loss 0.603666\n",
      "iteration 297 / 300: loss 0.585192\n",
      "iteration 297 / 300: loss 0.578880\n",
      "iteration 297 / 300: loss 0.576418\n",
      "iteration 297 / 300: loss 0.574097\n",
      "iteration 297 / 300: loss 0.600500\n",
      "iteration 297 / 300: loss 0.584490\n",
      "iteration 297 / 300: loss 0.584834\n",
      "iteration 297 / 300: loss 0.568323\n",
      "iteration 297 / 300: loss 0.592025\n",
      "iteration 297 / 300: loss 0.612116\n",
      "iteration 297 / 300: loss 0.608923\n",
      "iteration 297 / 300: loss 0.607613\n",
      "iteration 297 / 300: loss 0.595533\n",
      "iteration 297 / 300: loss 0.592837\n",
      "iteration 297 / 300: loss 0.597988\n",
      "iteration 297 / 300: loss 0.597677\n",
      "iteration 297 / 300: loss 0.600953\n",
      "iteration 297 / 300: loss 0.597422\n",
      "iteration 297 / 300: loss 0.598776\n",
      "iteration 297 / 300: loss 0.587806\n",
      "iteration 297 / 300: loss 0.600499\n",
      "iteration 297 / 300: loss 0.599650\n",
      "iteration 297 / 300: loss 0.617540\n",
      "iteration 297 / 300: loss 0.598875\n",
      "iteration 297 / 300: loss 0.600801\n",
      "iteration 297 / 300: loss 0.605305\n",
      "iteration 297 / 300: loss 0.598592\n",
      "iteration 297 / 300: loss 0.591474\n",
      "iteration 297 / 300: loss 0.580382\n",
      "iteration 297 / 300: loss 0.598221\n",
      "iteration 297 / 300: loss 0.611685\n",
      "iteration 297 / 300: loss 0.613219\n",
      "iteration 297 / 300: loss 0.582214\n",
      "iteration 297 / 300: loss 0.601955\n",
      "iteration 297 / 300: loss 0.608956\n",
      "iteration 297 / 300: loss 0.601794\n",
      "iteration 297 / 300: loss 0.607944\n",
      "iteration 297 / 300: loss 0.620236\n",
      "iteration 297 / 300: loss 0.584817\n",
      "iteration 297 / 300: loss 0.583721\n",
      "iteration 297 / 300: loss 0.628849\n",
      "iteration 297 / 300: loss 0.609399\n",
      "iteration 297 / 300: loss 0.606265\n",
      "iteration 297 / 300: loss 0.599034\n",
      "iteration 297 / 300: loss 0.615876\n",
      "iteration 297 / 300: loss 0.596489\n",
      "iteration 297 / 300: loss 0.581430\n",
      "iteration 297 / 300: loss 0.609807\n",
      "iteration 297 / 300: loss 0.608125\n",
      "iteration 297 / 300: loss 0.598224\n",
      "iteration 297 / 300: loss 0.592022\n",
      "iteration 297 / 300: loss 0.611031\n",
      "iteration 297 / 300: loss 0.598550\n",
      "iteration 297 / 300: loss 0.581382\n",
      "iteration 297 / 300: loss 0.609580\n",
      "iteration 298 / 300: loss 0.578384\n",
      "iteration 298 / 300: loss 0.596214\n",
      "iteration 298 / 300: loss 0.569455\n",
      "iteration 298 / 300: loss 0.597849\n",
      "iteration 298 / 300: loss 0.598940\n",
      "iteration 298 / 300: loss 0.603876\n",
      "iteration 298 / 300: loss 0.615261\n",
      "iteration 298 / 300: loss 0.588227\n",
      "iteration 298 / 300: loss 0.627171\n",
      "iteration 298 / 300: loss 0.592600\n",
      "iteration 298 / 300: loss 0.621500\n",
      "iteration 298 / 300: loss 0.593093\n",
      "iteration 298 / 300: loss 0.600541\n",
      "iteration 298 / 300: loss 0.571000\n",
      "iteration 298 / 300: loss 0.592911\n",
      "iteration 298 / 300: loss 0.600043\n",
      "iteration 298 / 300: loss 0.598053\n",
      "iteration 298 / 300: loss 0.583712\n",
      "iteration 298 / 300: loss 0.614355\n",
      "iteration 298 / 300: loss 0.591285\n",
      "iteration 298 / 300: loss 0.591391\n",
      "iteration 298 / 300: loss 0.594005\n",
      "iteration 298 / 300: loss 0.596735\n",
      "iteration 298 / 300: loss 0.596712\n",
      "iteration 298 / 300: loss 0.611735\n",
      "iteration 298 / 300: loss 0.607258\n",
      "iteration 298 / 300: loss 0.597031\n",
      "iteration 298 / 300: loss 0.596301\n",
      "iteration 298 / 300: loss 0.627391\n",
      "iteration 298 / 300: loss 0.601584\n",
      "iteration 298 / 300: loss 0.599923\n",
      "iteration 298 / 300: loss 0.621952\n",
      "iteration 298 / 300: loss 0.581435\n",
      "iteration 298 / 300: loss 0.599604\n",
      "iteration 298 / 300: loss 0.591182\n",
      "iteration 298 / 300: loss 0.599919\n",
      "iteration 298 / 300: loss 0.596015\n",
      "iteration 298 / 300: loss 0.590760\n",
      "iteration 298 / 300: loss 0.591961\n",
      "iteration 298 / 300: loss 0.615468\n",
      "iteration 298 / 300: loss 0.621360\n",
      "iteration 298 / 300: loss 0.587267\n",
      "iteration 298 / 300: loss 0.582483\n",
      "iteration 298 / 300: loss 0.585572\n",
      "iteration 298 / 300: loss 0.603666\n",
      "iteration 298 / 300: loss 0.585192\n",
      "iteration 298 / 300: loss 0.578880\n",
      "iteration 298 / 300: loss 0.576418\n",
      "iteration 298 / 300: loss 0.574097\n",
      "iteration 298 / 300: loss 0.600500\n",
      "iteration 298 / 300: loss 0.584490\n",
      "iteration 298 / 300: loss 0.584834\n",
      "iteration 298 / 300: loss 0.568323\n",
      "iteration 298 / 300: loss 0.592025\n",
      "iteration 298 / 300: loss 0.612116\n",
      "iteration 298 / 300: loss 0.608923\n",
      "iteration 298 / 300: loss 0.607613\n",
      "iteration 298 / 300: loss 0.595533\n",
      "iteration 298 / 300: loss 0.592837\n",
      "iteration 298 / 300: loss 0.597988\n",
      "iteration 298 / 300: loss 0.597677\n",
      "iteration 298 / 300: loss 0.600953\n",
      "iteration 298 / 300: loss 0.597422\n",
      "iteration 298 / 300: loss 0.598776\n",
      "iteration 298 / 300: loss 0.587806\n",
      "iteration 298 / 300: loss 0.600499\n",
      "iteration 298 / 300: loss 0.599650\n",
      "iteration 298 / 300: loss 0.617540\n",
      "iteration 298 / 300: loss 0.598875\n",
      "iteration 298 / 300: loss 0.600801\n",
      "iteration 298 / 300: loss 0.605305\n",
      "iteration 298 / 300: loss 0.598592\n",
      "iteration 298 / 300: loss 0.591474\n",
      "iteration 298 / 300: loss 0.580382\n",
      "iteration 298 / 300: loss 0.598221\n",
      "iteration 298 / 300: loss 0.611685\n",
      "iteration 298 / 300: loss 0.613219\n",
      "iteration 298 / 300: loss 0.582214\n",
      "iteration 298 / 300: loss 0.601955\n",
      "iteration 298 / 300: loss 0.608956\n",
      "iteration 298 / 300: loss 0.601794\n",
      "iteration 298 / 300: loss 0.607944\n",
      "iteration 298 / 300: loss 0.620236\n",
      "iteration 298 / 300: loss 0.584817\n",
      "iteration 298 / 300: loss 0.583721\n",
      "iteration 298 / 300: loss 0.628849\n",
      "iteration 298 / 300: loss 0.609399\n",
      "iteration 298 / 300: loss 0.606265\n",
      "iteration 298 / 300: loss 0.599034\n",
      "iteration 298 / 300: loss 0.615876\n",
      "iteration 298 / 300: loss 0.596489\n",
      "iteration 298 / 300: loss 0.581430\n",
      "iteration 298 / 300: loss 0.609807\n",
      "iteration 298 / 300: loss 0.608125\n",
      "iteration 298 / 300: loss 0.598224\n",
      "iteration 298 / 300: loss 0.592022\n",
      "iteration 298 / 300: loss 0.611031\n",
      "iteration 298 / 300: loss 0.598550\n",
      "iteration 298 / 300: loss 0.581382\n",
      "iteration 298 / 300: loss 0.609580\n",
      "iteration 299 / 300: loss 0.578384\n",
      "iteration 299 / 300: loss 0.596214\n",
      "iteration 299 / 300: loss 0.569455\n",
      "iteration 299 / 300: loss 0.597849\n",
      "iteration 299 / 300: loss 0.598940\n",
      "iteration 299 / 300: loss 0.603876\n",
      "iteration 299 / 300: loss 0.615261\n",
      "iteration 299 / 300: loss 0.588227\n",
      "iteration 299 / 300: loss 0.627171\n",
      "iteration 299 / 300: loss 0.592600\n",
      "iteration 299 / 300: loss 0.621500\n",
      "iteration 299 / 300: loss 0.593093\n",
      "iteration 299 / 300: loss 0.600541\n",
      "iteration 299 / 300: loss 0.571000\n",
      "iteration 299 / 300: loss 0.592911\n",
      "iteration 299 / 300: loss 0.600043\n",
      "iteration 299 / 300: loss 0.598053\n",
      "iteration 299 / 300: loss 0.583712\n",
      "iteration 299 / 300: loss 0.614355\n",
      "iteration 299 / 300: loss 0.591285\n",
      "iteration 299 / 300: loss 0.591391\n",
      "iteration 299 / 300: loss 0.594005\n",
      "iteration 299 / 300: loss 0.596735\n",
      "iteration 299 / 300: loss 0.596712\n",
      "iteration 299 / 300: loss 0.611735\n",
      "iteration 299 / 300: loss 0.607258\n",
      "iteration 299 / 300: loss 0.597031\n",
      "iteration 299 / 300: loss 0.596301\n",
      "iteration 299 / 300: loss 0.627391\n",
      "iteration 299 / 300: loss 0.601584\n",
      "iteration 299 / 300: loss 0.599923\n",
      "iteration 299 / 300: loss 0.621952\n",
      "iteration 299 / 300: loss 0.581435\n",
      "iteration 299 / 300: loss 0.599604\n",
      "iteration 299 / 300: loss 0.591182\n",
      "iteration 299 / 300: loss 0.599919\n",
      "iteration 299 / 300: loss 0.596015\n",
      "iteration 299 / 300: loss 0.590760\n",
      "iteration 299 / 300: loss 0.591961\n",
      "iteration 299 / 300: loss 0.615468\n",
      "iteration 299 / 300: loss 0.621360\n",
      "iteration 299 / 300: loss 0.587267\n",
      "iteration 299 / 300: loss 0.582483\n",
      "iteration 299 / 300: loss 0.585572\n",
      "iteration 299 / 300: loss 0.603666\n",
      "iteration 299 / 300: loss 0.585192\n",
      "iteration 299 / 300: loss 0.578880\n",
      "iteration 299 / 300: loss 0.576418\n",
      "iteration 299 / 300: loss 0.574097\n",
      "iteration 299 / 300: loss 0.600500\n",
      "iteration 299 / 300: loss 0.584490\n",
      "iteration 299 / 300: loss 0.584834\n",
      "iteration 299 / 300: loss 0.568323\n",
      "iteration 299 / 300: loss 0.592025\n",
      "iteration 299 / 300: loss 0.612116\n",
      "iteration 299 / 300: loss 0.608923\n",
      "iteration 299 / 300: loss 0.607613\n",
      "iteration 299 / 300: loss 0.595533\n",
      "iteration 299 / 300: loss 0.592837\n",
      "iteration 299 / 300: loss 0.597988\n",
      "iteration 299 / 300: loss 0.597677\n",
      "iteration 299 / 300: loss 0.600953\n",
      "iteration 299 / 300: loss 0.597422\n",
      "iteration 299 / 300: loss 0.598776\n",
      "iteration 299 / 300: loss 0.587806\n",
      "iteration 299 / 300: loss 0.600499\n",
      "iteration 299 / 300: loss 0.599650\n",
      "iteration 299 / 300: loss 0.617540\n",
      "iteration 299 / 300: loss 0.598875\n",
      "iteration 299 / 300: loss 0.600801\n",
      "iteration 299 / 300: loss 0.605305\n",
      "iteration 299 / 300: loss 0.598592\n",
      "iteration 299 / 300: loss 0.591474\n",
      "iteration 299 / 300: loss 0.580382\n",
      "iteration 299 / 300: loss 0.598221\n",
      "iteration 299 / 300: loss 0.611685\n",
      "iteration 299 / 300: loss 0.613219\n",
      "iteration 299 / 300: loss 0.582214\n",
      "iteration 299 / 300: loss 0.601955\n",
      "iteration 299 / 300: loss 0.608956\n",
      "iteration 299 / 300: loss 0.601794\n",
      "iteration 299 / 300: loss 0.607944\n",
      "iteration 299 / 300: loss 0.620236\n",
      "iteration 299 / 300: loss 0.584817\n",
      "iteration 299 / 300: loss 0.583721\n",
      "iteration 299 / 300: loss 0.628849\n",
      "iteration 299 / 300: loss 0.609399\n",
      "iteration 299 / 300: loss 0.606265\n",
      "iteration 299 / 300: loss 0.599034\n",
      "iteration 299 / 300: loss 0.615876\n",
      "iteration 299 / 300: loss 0.596489\n",
      "iteration 299 / 300: loss 0.581430\n",
      "iteration 299 / 300: loss 0.609807\n",
      "iteration 299 / 300: loss 0.608125\n",
      "iteration 299 / 300: loss 0.598224\n",
      "iteration 299 / 300: loss 0.592022\n",
      "iteration 299 / 300: loss 0.611031\n",
      "iteration 299 / 300: loss 0.598550\n",
      "iteration 299 / 300: loss 0.581382\n",
      "iteration 299 / 300: loss 0.609580\n"
     ]
    }
   ],
   "source": [
    "iterations = 300\n",
    "lr = 0.015\n",
    "lr_decay=0.999\n",
    "reg = 5e-6\n",
    "loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "for t in range(iterations):\n",
    "    indices = np.arange(Ntr)\n",
    "    indices = np.split(indices,100) \n",
    "    for i in indices:\n",
    "        rng.shuffle(i)\n",
    "        x = x_train[i]\t\n",
    "        y = y_train[i]\n",
    "        h = 1.0/(1.0 + np.exp(-(x.dot(w1) + b1)))\n",
    "        y_pred = h.dot(w2) +b2\n",
    "        loss = 1./batch_size*np.square(y_pred - y).sum() + reg * (np.sum(w2 * w2) + np.sum(w1 * w1))\n",
    "        loss_history.append(loss)\n",
    "        #if t%10 ==0:\n",
    "        print('iteration %d / %d: loss %f' %(t, iterations, loss))\n",
    "        dy_pred = 1./batch_size*2.0*(y_pred -y) # partial derivative of L w.r.t y_hat backward\n",
    "        dw2 = h.T.dot(dy_pred) + reg*w2\n",
    "        db2 = dy_pred.sum(axis=0)\n",
    "        dh = dy_pred.dot(w2.T)\n",
    "        dw1 = x.T.dot(dh*h*(1-h)) + reg*w1\n",
    "        db1 = (dh*h*(1-h)).sum(axis=0)\n",
    "        w1 -= lr*dw1\n",
    "        w2 -= lr*dw2\n",
    "        b1 -= lr*db1\n",
    "        b2 -= lr*db2\n",
    "        lr *= lr_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "designing-shower",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAW30lEQVR4nO3dfZRU9X3H8c93n3gSedqVKBAeFGMgjYobj4nWh9hUIDliapLCaRpjcsJJIm3z2OpJaoxN2lRtmtoarTmxxpxGQmyaQ1MSNImPFZVFAUXOwoIgIMoCgorCsjvf/jF3ycwwuzssd+bO7877dc6evfd379z7/e0dP/64d+4dc3cBAMJXl3QBAIB4EOgAkBIEOgCkBIEOAClBoANASjQktePm5mafMmVKUrsHgCCtWrVqt7u3FFuWWKBPmTJFbW1tSe0eAIJkZlv7WsYpFwBICQIdAFKCQAeAlCDQASAlCHQASIkBA93M7jKzXWb2XB/LzcxuNbMOM1trZrPiLxMAMJBSRuh3S5rdz/I5kqZHPwsl3X78ZQEAjtWAge7uj0ja288q8yTd41lPSBptZifHVWChlVv26rv3t6urO1OuXQBAkOI4hz5B0rac+e1R21HMbKGZtZlZW2dn56B29vTWV3Xr7zrUnSHQASBXRS+Kuvud7t7q7q0tLUXvXD2GbcVUFACkRByBvkPSpJz5iVFbWZiVa8sAELY4An2ppE9En3Y5T9J+d98Zw3b7xQAdAPIN+HAuM7tX0sWSms1su6RvSGqUJHe/Q9IySXMldUh6U9LV5SpWkkwM0QGgmAED3d0XDLDcJV0TW0Ul4sutASBfcHeKcg4dAIoLLtABAMUFG+iccAGAfMEGOgAgX7CBzjVRAMgXXKAbV0UBoKjgAv0IRugAkCe4QGd8DgDFBRfovZwhOgDkCS7QOYUOAMUFF+i9+JQLAOQLLtAZoANAccEFei8G6ACQL7hA53PoAFBccIEOACgu2EDneegAkC+4QOeMCwAUF1yg92J8DgD5ggt0BugAUFxwgd6LU+gAkC+8QOckOgAUFV6gR3g4FwDkCy7QGZ8DQHHBBfoRDNABIE9wgc4pdAAoLrhA78UAHQDyBRfoxll0ACgquEAHABQXbKBzYxEA5Asu0LkoCgDFBRfovbixCADyBRfoDNABoLjgAr0X59ABIF9wgc45dAAoLrhA78UAHQDyBRfo3FgEAMUFF+i9+JJoAMhXUqCb2WwzazezDjO7tsjyyWb2WzNba2YPmdnE+Evt3VnZtgwAQRsw0M2sXtJtkuZImiFpgZnNKFjtFkn3uPu7Jd0o6R/iLrQQA3QAyFfKCP1cSR3uvtnduyQtljSvYJ0Zkn4XTT9YZHlsGKADQHGlBPoESdty5rdHbbnWSPqTaPrDkkaa2bjCDZnZQjNrM7O2zs7OwdQLAOhDXBdFvyLpIjN7RtJFknZI6ilcyd3vdPdWd29taWkZ1I6MD6IDQFENJayzQ9KknPmJUdsR7v6SohG6mZ0g6Up33xdTjQCAEpQyQl8pabqZTTWzJknzJS3NXcHMms2sd1vXSbor3jKPxkVRAMg3YKC7e7ekRZKWS1ovaYm7rzOzG83s8mi1iyW1m9kGSeMlfbtM9XJRFAD6UMopF7n7MknLCtquz5m+T9J98ZY2QE3c/A8AeYK7U5RrogBQXHCB3otz6ACQL7hAZ4QOAMUFF+i9GKADQL7gAp3H5wJAccEFei8enwsA+YILdM6hA0BxwQX6oe6MJM6hA0Ch4AL95uXtkqSH2nlaIwDkCi7QO18/JEl6/eDhhCsBgOoSXKB/+QOnS5IuOK054UoAoLoEF+innXSCJGnEkJIeQwMANSO4QH9k425J0upt+5ItBACqTHCB/nD7LknSqq2vJlwJAFSX4AJ9eHSqZVhjfcKVAEB1CS7Q/2b2GZKkC08f3HeSAkBaBRfoz+7YL0n65v+sS7gSAKguwQX6ocM9kn7/eXQAQFZwgV5Xl32YS4aHcwFAnuACvSEK9J4MgQ4AuYIL9DrrHaEnXAgAVJngAr2+jufnAkAxBDoApERwgX7yqKGSpEljhyVcCQBUl+AC/fzoKYtnThydbCEAUGWCC/TeEy6/XLsz0ToAoNoEF+h8uAUAigsu0HfseyvpEgCgKgUX6N09jNEBoJjgAn3yuOFJlwAAVSm4QB81rDHpEgCgKgUX6EP5YgsAKCq4QAcAFEegA0BKBB3oXd2ZpEsAgKoRdKB3Zwh0AOgVeKDzmXQA6FVSoJvZbDNrN7MOM7u2yPK3m9mDZvaMma01s7nxl3q0ti17K7EbAAjCgIFuZvWSbpM0R9IMSQvMbEbBal+XtMTdz5Y0X9L34y60mE/d3VaJ3QBAEEoZoZ8rqcPdN7t7l6TFkuYVrOOSToymR0l6Kb4SAQClKCXQJ0jaljO/PWrLdYOkj5vZdknLJP1FsQ2Z2UIzazOzts7OzkGUCwDoS1wXRRdIutvdJ0qaK+nHZnbUtt39TndvdffWlpaWmHYNAJBKC/QdkiblzE+M2nJ9WtISSXL3FZKGSmqOo8CBuPNJFwCQSgv0lZKmm9lUM2tS9qLn0oJ1XpR0qSSZ2TuVDfSKnFN5dOPuSuwGAKregIHu7t2SFklaLmm9sp9mWWdmN5rZ5dFqX5b0GTNbI+leSZ/0Cg2duVsUALIaSlnJ3Zcpe7Ezt+36nOnnJZ0fb2mlee3g4SR2CwBVJ+g7RSVpSdu2gVcCgBoQfKA/sZm7RQFASkGgAwCyUhHoKzbtSboEAEhcKgJ974GupEsAgMQFGejt35qddAkAUHWCDPQhDflfFH3NT55OqBIAqB5BBjoA4GgEOgCkRGoCvbuHRwAAqG2pCfQ/vOnBpEsAgESlJtB37j+YdAkAkKjUBLrEs9EB1LZUBfqvn3s56RIAIDGpCvSblrcnXQIAJCZVgf7C7gNJlwAAiQk20B/6ysVF2wl1ALUq2ECf0jyiaPujGyvyVaYAUHWCDXQAQL7UBfqvnuWTLgBqU+oCfcVmvuwCQG1KXaBLPNcFQG1KZaB//RfPJV0CAFRc0IH+rgknFm1fvHJbhSsBgOQFHehnTxrT57JMhue6AKgtQQf6335oRp/LenhQF4AaE3SgNzX0Xf7a7fsqVwgAVIGgA70/V96+Qof5tAuAGpLaQJekrm4CHUDtSHWgZziPDqCGBB/o500b2+eyvQe6KlgJACQr+EC/5aNn9rmMG4wA1JLgA33imOF9Lnt0424+jw6gZgQf6AN58oW9SZcAABWR+kBf8IMnGKUDqAmpD3RJ2v3GoaRLAICyKynQzWy2mbWbWYeZXVtk+T+b2eroZ4OZ7Yu90n68e+Kofpc/tYXTLgDSb8BAN7N6SbdJmiNphqQFZpb3EBV3/6K7n+XuZ0n6V0k/L0OtfVq66IJ+ly97dmeFKgGA5JQyQj9XUoe7b3b3LkmLJc3rZ/0Fku6No7i4LONr6QDUgFICfYKk3AeMb4/ajmJmkyVNlfS74y8tXr95/pWkSwCAsor7ouh8Sfe5e0+xhWa20MzazKyts7Mz1h3/x9Xv6Xf5PU9sjXV/AFBtSgn0HZIm5cxPjNqKma9+Tre4+53u3ururS0tLaVXWYJL3nFSv8u37X0z1v0BQLUpJdBXSppuZlPNrEnZ0F5auJKZnSFpjKQV8ZYYjxd2H9AjG+L9VwEAVJMBA93duyUtkrRc0npJS9x9nZndaGaX56w6X9Ji9+p9xOG3/3d90iUAQNk0lLKSuy+TtKyg7fqC+RviK6s82l95Xe4uM0u6FACIXaruFD1p5JAB17l5eXsFKgGAyktVoP/dFe8acJ17VvBpFwDplKpAv2zm2wZc541D3dqx760KVAMAlZWqQC/VJ374ZNIlAEDsUhfol595yoDrbOo8oJcYpQNImdQFeqn++r61SZcAALFKXaBfcfbAI3RJeqxjt7bsPlDmagCgclIX6O8/Y7yunDWxpHU//aOVZa4GACondYEuSZPGDitpvU2dB7Rq66tlrgYAKiOVgb7oktNKXvfK2x9Xd0+mjNUAQGWkMtAb6o+tW7fcv6FMlQBA5aQy0I/VHQ9v0i/XvpR0GQBwXFIb6Pd/8cJjWn/RT57RMy9yPh1AuFIb6KePH3nMr/nw9x/XrtcPlqEaACi/1Ab6YM353qPq6uYiKYDwEOgF9hzo0vw7VyiTqdrv6QCAolId6Ld89MxBve7pF/fp6rtXEuoAgpLqQP/IOaXdMVrMwxs69ZE7+Iw6gHCkOtCP19Mv7tOM65frwKHupEsBgAGlPtDfM2XMcb2+qyejmd9Yrkc3dqqKv/8aANIf6N/92FmxbOfPf/iUpl63TFv3HCDYAVSl1Af6pLHDY93eRTc/pKnXLdNjG3erh4umAKpIQ9IFhOrj0dfYXXBasz5z4TSdN22shjTUJ1wVgFpWE4F+64Kz9Zf3PlOWbT/WsVuPdew+Mn/mxFG65IyTNPOUUTq1ZYQmjhmupobU/0MIQBWoiUC//MxTyhbohdZs36812/cXXTZ75tt09ttHa/r4EzR53AhNGD1MQxsZ1QOIR00EerX49bqX9et1LxddNmXccM2aPEaTx47QKaOHqmXkEDWfMESjhjVq5NAGDW9qYKQPoF81E+hf+sDp+u4D1fvc8y173tSWPW8O6rWN9XYk/EcNa9Twpno1NdSpob5OTfV1qq8zNdab6utM9Waqr6tTnUn1dSYzU51JddFvmcmUnTeTLNqHmWRmR/bZO2mywnLyXlfYHgeTyeV5v4FQmElXvW+KGo/xextKUTOB/rmLT63qQD8eh3tcO/cf1M79PCkSCMHhHtfnLj419u3WzL/hG+vrNPOUE5MuAwD0+sHDZdluzQS6JN3zqXOTLgEAYjv9WKimAn3cCUOSLgEAynbdp6YCXZKuPn9K0iUAqHF1jNDj8dXL3pF0CQBq3CuvHSrLdmsu0Ic3NTBKB5Cotw73lGW7NRfoknTpGeOTLgFADVuxeU9ZtluTgX7B9GadM/n4npMOAIPV+TqnXGK18MJpSZcAALEqKdDNbLaZtZtZh5ld28c6HzOz581snZn9JN4y4/eBd47XpLHDki4DAGIzYKCbWb2k2yTNkTRD0gIzm1GwznRJ10k6391nSvpC/KXGq67O9L0/PTvpMgAgNqWM0M+V1OHum929S9JiSfMK1vmMpNvc/VVJcvdd8ZZZHudMHqPPXhT/8xQAIAmlBPoESdty5rdHbblOl3S6mf2fmT1hZrOLbcjMFppZm5m1dXZ2Dq7imF1zCYEOoLJOGTW0LNuN66Jog6Tpki6WtEDSD8xsdOFK7n6nu7e6e2tLS0tMuz4+I4c2asV170+6DAA15KUyPRm1lEDfIWlSzvzEqC3XdklL3f2wu78gaYOyAR+Ek0cN0yNfvSTpMgDguJQS6CslTTezqWbWJGm+pKUF6/xC2dG5zKxZ2VMwm+Mrs/zePm64fv759yVdBgAM2oCB7u7dkhZJWi5pvaQl7r7OzG40s8uj1ZZL2mNmz0t6UNJX3b08t0KV0ay3j9F9n31v0mUAwKCYuyey49bWVm9ra0tk3wNZv/M1zfmXR5MuA0CKbfnOBwf1OjNb5e6txZbV7J2i/XnnySdq09/P1bDG+qRLAYCSEeh9qK8zrf+72frWFe9KuhQAKAmBPoCPnzdZ7d+arVNbRiRdCgD0i0AvwZCGev32yxdr5df+KOlSAKTA4oXnlWW7BPoxaBk5RFu+80Gtuf6PNfcP3pZ0OQACdd60cWXZbkNZtppyo4Y36vt/do66ujNatfVVfWnJau0s051fAFAqAv04NDXU6b2njtOK6y5VJuPauvdNPbKhU//+8Kay3doLAH0h0GNSV2ea2jxCU5tH6Kr3TZEkdXVn9PzO17T6xVd1//Ov6PFNwd1rBSAgBHoZNTXU6axJo3XWpNH65PlTj7R392S0c/9B7dx/UC/te0vb9r6pTZ1vaM32/Xph94EEKwYQMgI9AQ31dZo0drgmjR1e0vpvdfXorcM9OnjkJ6ND3T061J3Roe6MDndndLgno66ejA73uLp7MurO/P53T8bV465MxtWTkXrc5e7KuCvjUsZd7lImkzvvcinbnjMtKbvMpWxrb5uUe89x7g3IrhLvRvb8Sctvytm2y8wG9Xug3VuJ87nbza2pcLp3vvc1xZbH6Xjv/B7obzCQ3D7mtvV1LEL4m5S8H5X2fplVxu8zJtADMKypXsOauGsVQP/42CIApASBDgApQaADQEoQ6ACQEgQ6AKQEgQ4AKUGgA0BKEOgAkBKJfaeomXVK2jrIlzdL2h1jOUmiL9UnLf2Q6Eu1Op6+THb3lmILEgv042FmbX19SWpo6Ev1SUs/JPpSrcrVF065AEBKEOgAkBKhBvqdSRcQI/pSfdLSD4m+VKuy9CXIc+gAgKOFOkIHABQg0AEgJYILdDObbWbtZtZhZtcmXU8xZrbFzJ41s9Vm1ha1jTWzB8xsY/R7TNRuZnZr1J+1ZjYrZztXRetvNLOrKlT7XWa2y8yey2mLrXYzOyf623REry3P19T03ZcbzGxHdGxWm9ncnGXXRXW1m9llOe1F33NmNtXMnozaf2pmTWXqxyQze9DMnjezdWb2V1F7cMeln76EeFyGmtlTZrYm6ss3+9u/mQ2J5jui5VMG28c+ee/XjQXwI6le0iZJ0yQ1SVojaUbSdRWpc4uk5oK2myRdG01fK+kfo+m5kn6l7LdVnSfpyah9rKTN0e8x0fSYCtR+oaRZkp4rR+2SnorWtei1cyrclxskfaXIujOi99MQSVOj91l9f+85SUskzY+m75D0uTL142RJs6LpkZI2RPUGd1z66UuIx8UknRBNN0p6MvobFt2/pM9LuiOani/pp4PtY18/oY3Qz5XU4e6b3b1L0mJJ8xKuqVTzJP0omv6RpCty2u/xrCckjTazkyVdJukBd9/r7q9KekDS7HIX6e6PSNpbjtqjZSe6+xOefSffk7OtSvWlL/MkLXb3Q+7+gqQOZd9vRd9z0Qj2/ZLui16f+3eJlbvvdPeno+nXJa2XNEEBHpd++tKXaj4u7u5vRLON0Y/3s//c43WfpEujeo+pj/3VFFqgT5C0LWd+u/p/MyTFJd1vZqvMbGHUNt7dd0bTL0saH0331adq6mtctU+IpgvbK21RdCrirt7TFDr2voyTtM/duwvayyr6Z/rZyo4Ggz4uBX2RAjwuZlZvZqsl7VL2f5Cb+tn/kZqj5fujemPLgNACPRQXuPssSXMkXWNmF+YujEZBQX5eNOTaI7dLOlXSWZJ2SvqnRKs5BmZ2gqT/kvQFd38td1lox6VIX4I8Lu7e4+5nSZqo7Ij6jCTrCS3Qd0ialDM/MWqrKu6+I/q9S9J/K3ugX4n+aavo965o9b76VE19jav2HdF0YXvFuPsr0X+EGUk/UPbYSMfelz3KnspoKGgvCzNrVDYA/9Pdfx41B3lcivUl1OPSy933SXpQ0nv72f+RmqPlo6J648uAclwsKNePpAZlL+RM1e8vEsxMuq6CGkdIGpkz/biy575vVv4FrJui6Q8q/wLWU1H7WEkvKHvxakw0PbZCfZii/AuJsdWuoy++za1wX07Omf6isucuJWmm8i9MbVb2olSf7zlJP1P+xa/Pl6kPpux57e8VtAd3XPrpS4jHpUXS6Gh6mKRHJX2or/1Lukb5F0WXDLaPfdZUzv+YyvRHnKvslfFNkr6WdD1F6psW/eHXSFrXW6Oy58p+K2mjpN/k/Idkkm6L+vOspNacbX1K2QskHZKurlD99yr7T97Dyp6z+3SctUtqlfRc9Jp/U3S3cgX78uOo1rWSlhYEydeiutqV8ymPvt5z0bF+KurjzyQNKVM/LlD2dMpaSaujn7khHpd++hLicXm3pGeimp+TdH1/+5c0NJrviJZPG2wf+/rh1n8ASInQzqEDAPpAoANAShDoAJASBDoApASBDgApQaADQEoQ6ACQEv8Pa6irmTC7MJIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train -> (50000, 3072)\n",
      "train_acc =  0.8629688888888889\n",
      "train_loss =  0.924381258630517\n",
      "x_test -> (10000, 3072)\n",
      "test_acc =  0.7790333333333334\n",
      "test_loss =  0.8714155796181713\n"
     ]
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "f, axarr = plt.subplots(1,10)\n",
    "f.set_size_inches(16, 6)\n",
    "\n",
    "for i in range(10):\n",
    "    img = w1[:, i].reshape(32, 32, 3) # CIFAR10\n",
    "    #img = w1[:, i].reshape(28, 28) # MNIST\n",
    "    axarr[i].imshow(img*100000)\n",
    "plt.show()\n",
    "\n",
    "x_t = x_train\n",
    "print(\"x_train ->\", x_t.shape)\n",
    "h = 1.0/(1.0 + np.exp(-(x_t.dot(w1) + b1))) #sigmoid\n",
    "y_pred = h.dot(w2) + b2\n",
    "train_acc = 1.0 -1/(9*Ntr)*(np.abs(np.argmax(y_train,axis=1) - np.argmax(y_pred, axis=1))).sum()\n",
    "train_loss = 1.0 -1/(81*Ntr)*np.square(np.argmax(y_train,axis=1) - np.argmax(y_pred, axis=1)).sum() + reg*(np.sum(w2*w2)+np.sum(w1*w1))\n",
    "print(\"train_acc = \", train_acc)\n",
    "print(\"train_loss = \", train_loss)\n",
    "\n",
    "x_t = x_test\n",
    "print(\"x_test ->\", x_t.shape)\n",
    "h = 1.0/(1.0 + np.exp(-(x_t.dot(w1) + b1))) #sigmoid\n",
    "y_pred= h.dot(w2) + b2\n",
    "test_acc = 1.0 - 1/(9*Nte)*(np.abs(np.argmax(y_test,axis=1) - np.argmax(y_pred, axis=1))).sum()\n",
    "test_loss = 1.0 -1/(81*Nte)*np.square(np.argmax(y_test,axis=1) - np.argmax(y_pred, axis=1)).sum() + reg*(np.sum(w2*w2)+np.sum(w1*w1))\n",
    "print(\"test_acc = \", test_acc)\n",
    "print(\"test_loss = \", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-typing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
